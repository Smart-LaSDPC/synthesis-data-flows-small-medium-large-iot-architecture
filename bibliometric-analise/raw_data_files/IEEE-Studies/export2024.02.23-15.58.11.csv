"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Revisiting the Frontiers of Analog and Mixed-Signal Integrated Circuits Architectures and Techniques towards the future Internet of Everything (IoE) Applications","R. P. Martins; P. -I. Mak; S. -W. Sin; M. -K. Law; Y. Zhu; Y. Lu; J. Yin; C. -H. Chan; Y. Chen; K. -F. Un; M. Huang; M. Zhang; Y. Jiang; W. -H. Yu",NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA,"Revisiting the Frontiers of Analog and Mixed-Signal Integrated Circuits Architectures and Techniques towards the future Internet of Everything (IoE) Applications","","2021","","","","","Technology-assisted People-to-People (P2P) interactions, embedded in a global environment, will be at the core of 21st century communications and will command the technological development of the forthcoming future. The intelligent interactivity of people, process (delivering the right information to the right person/machine at the right time), data and things, incorporates the Internet-of-Everything (IoE) that expands itself beyond the Internet-of-Things (IoT). In general, IoT comprises all physical or cyber objects (things) with an address that can transmit data (without human-to-machine interactions), while the IoE also involves communications among the users and the whole universe of electronic gadgets. Further, they both operate with data acquired from analog sources, thus connecting two different realities, the analog (physical/real) and the digital (cyber/virtual) worlds. Since the interface between the two realms deals with analog signals, its mandatory functions integrate several analog and mixed-signal sub-systems that include signal sensing, transmission and reception, frequency generation, energy harvesting, in-memory processing, data and power conversion. This publication presents state-of-the-art designs of the most critical building blocks of the analog/digital interface highlighting new and innovative circuit architectures and techniques. It addresses capacitive sensor interfaces, ultra-low-power wireless transceivers, key technologies for wireline transceivers, oscillators and frequency generators, integrated energy harvesting interfaces, in-memory processing, as well as, data and power converters, all exhibiting high quality performance with low power consumption, high energy-efficiency and high speed, thus enabling a reliable and consistent development of the IoE while enlarging its frontiers. In the coming decades, with the continuous evolution of electronics downscaling, the challenges that the above-mentioned sub-systems face will be tremendous in terms of the requirements for ultra-low power and ultra-high speed, obtained with the maximum energy-efficiency. Thus, the analog and mixed-signal very large scale integration area of work will continue to be an attractive field for research for design engineers both in the academia and in the industry, as it has been always the case since the emergence of silicon planar electronics 6 decades ago.","","9781680838930","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9604004.pdf&bkn=9604003&pdfType=book","","","","","","","","5 Nov 2021","","","now","Now Foundations and Trends Books"
"Designing Production-Grade and Large-Scale IoT Solutions: A comprehensive and practical guide to implementing end-to-end IoT solutions","M. Abdelaziz",NA,"Designing Production-Grade and Large-Scale IoT Solutions: A comprehensive and practical guide to implementing end-to-end IoT solutions","","2022","","","","","Get to grips with key IoT aspects along with modern trends, architectures, and technologies that support IoT solutions, such as cloud computing, modern app architecture paradigms, and data analyticsKey FeaturesUnderstand the big picture of designing production-grade IoT solutions from an industry expertGet up and running with the development and designing aspects of the Internet of ThingsSolve business problems specific to your domain using different IoT platforms and technologiesBook DescriptionWith the rising demand for and recent enhancements in IoT, a developer with sound knowledge of IoT is the need of the hour. This book will help you design, build, and operate large-scale E2E IoT solutions to transform your business and products, increase revenue, and reduce operational costs. Starting with an overview of how IoT technologies can help you solve your business problems, this book will be a useful guide to helping you implement end-to-end IoT solution architecture. You'll learn to select IoT devices; real-time operating systems; IoT Edge covering Edge location, software, and hardware; and the best IoT connectivity for your IoT solution. As you progress, you'll work with IoT device management, IoT data analytics, IoT platforms, and put these components to work as part of your IoT solution. You'll also be able to build IoT backend cloud from scratch by leveraging the modern app architecture paradigms and cloud-native technologies such as containers and microservices. Finally, you'll discover best practices for different operational excellence pillars, including high availability, resiliency, reliability, security, cost optimization, and high performance, which should be applied for large-scale production-grade IoT solutions. By the end of this IoT book, you'll be confident in designing, building, and operating IoT solutions.What you will learnUnderstand the detailed anatomy of IoT solutions and explore their building blocksExplore IoT connectivity options and protocols used in designing IoT solutionsUnderstand the value of IoT platforms in building IoT solutionsExplore real-time operating systems used in microcontrollersAutomate device administration tasks with IoT device managementMaster different architecture paradigms and decisions in IoT solutionsBuild and gain insights from IoT analytics solutionsGet an overview of IoT solution operational excellence pillarsWho this book is forThis book is for E2E solution architects, systems and technical architects, and IoT developers looking to design, build, and operate E2E IoT applications and solutions. Basic knowledge of cloud computing, software engineering, and distributed system design will help you get the most out of this book.","","9781838827182","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10163358.pdf&bkn=10163357&pdfType=book","","","","","","","","27 Jun 2023","","","Packt Publishing","Packt Publishing eBooks"
"Beyond 5G Communication Networks Enabling Massive IOT","R. Sharma; A. Sharma; G. Chandel; V. Goyal","University Institute of computing, Chandigarh University, Mojhali, Punjab; Electrical Engineeing Department, Chandigarh University, Mohali, India; Department of Electronics Engineering, Chandigarh University, Mohali, India; Electronics and Communication Engineering, GLA University, Mathura, India","2023 International Conference on Power, Instrumentation, Control and Computing (PICC)","8 Jun 2023","2023","","","1","6","The future of humanity is dependent upon the IOT(Internet of things) and 5G network, which means most of the machine and mobile phones and devices are operating through the IOT(Internet of things) and to transfer the data from one port to another port through the 5G network and it is seen that it play an very crucial role in this area. To use this IOT(Internet of things) have to create an advanced intelligent environment into the world which is running through the human command, voice like example amazon ALEXA device, most of AC system which operated with the phone and audio. When a large number of the device is operated with some device then some large number interaction between the heterogonous device and increase the demand like strong connection, exceptionally high data throughput, low latency, creating applications that play critical roles in IOT(Internet of things), as a result of this need 5G technology is an important facilitator for IOT(Internet of things) technology. this work gives all the theoretical information about the IOT(Internet of things) and 5G technology, also give the detail that how the technology is changing day by day due to this technology and it is going to be large scale in future for every single child and old person, so this work helps all gathering information about Latest technologies and work in this field.","","979-8-3503-3446-3","10.1109/PICC57976.2023.10142732","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10142732","IOT(Internet of things);wireless technologies;D2D communication;M2M wave Technique","5G mobile communication;Law;Virtual assistants;Turning;Throughput;Mobile handsets;Internet of Things","","1","","28","IEEE","8 Jun 2023","","","IEEE","IEEE Conferences"
"Deep learning for internet of things in fog computing: Survey and Open Issues","J. Tmamna; E. B. Ayed; M. B. Ayed","REGIM-Lab.:REsearch Groups in Intelligent Machines, University of Sfax, National Engineering School of Sfax; REGIM-Lab.:REsearch Groups in Intelligent Machines, University of Sfax, National Engineering School of Sfax; REGIM-Lab.:REsearch Groups in Intelligent Machines, University of Sfax, National Engineering School of Sfax","2020 5th International Conference on Advanced Technologies for Signal and Image Processing (ATSIP)","20 Oct 2020","2020","","","1","6","In recent years, the internet of things is getting very popular where it arose in several areas such as education, and healthcare to enhance our live. This popularity has led to an increase number of IoT devices and thus generates massive volume of data. However, this data requires efficient methods of analysis to provide intelligent services. Recently, the deep learning can meet the requirements of IoT data analysis by providing techniques for large scale data analysis and meaningful feature extraction. The deep learning implementation is traditionally delivered to cloud computing due to its high compute resources provisioning. However, given the sheer volume of IoT data, the cloud computing fall to meet the IoT requirements, it presents many issues in term of time response, large data transmission, energy consumption, etc. To address this challenges the fog computing, new layer between cloud computing and internet of things devices, appears. So, moving the implementation of deep learning to fog computing can achieve the requirements of internet of things systems and enhance their performances. In this paper, we introduce deep learning for internet of things, next the application of deep learning in internet of things. We address fog computing for the internet of things. Finally, we present the deep learning in fog computing.","2687-878X","978-1-7281-7513-3","10.1109/ATSIP49331.2020.9231685","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9231685","internet of things;deep learning;fog computing","Internet of Things;Cloud computing;Edge computing;Deep learning;Data analysis;Real-time systems;Feature extraction","","10","","54","IEEE","20 Oct 2020","","","IEEE","IEEE Conferences"
"Research on Parallel Computing Algorithm in Internet of Things System","Y. Li","Guangdong Peizheng College, Guangzhou, China","2021 International Conference on Internet, Education and Information Technology (IEIT)","7 Sep 2021","2021","","","40","43","The parallel computing algorithm is applied to the application layer of the Internet of things, which aims to improve the computing speed, expand the scale of problem solving and solve the large and complex computing problems of the Internet of things system. Parallel computing can be divided into time parallel and spatial parallel. Time parallelism is pipeline technology, while spatial parallelism refers to the concurrent execution of computation with multiple processors to reduce the time needed to solve complex problems. The software platform of the application layer of the Internet of things is built, the window structure of the application layer of the Internet of things is established, and the complex and diverse programming methods of parallel computing are completed in the application layer of the Internet of things. By using parallel algorithm and parallel programming, some complex computing is transformed into simple calculation which satisfies the accuracy through algorithm analysis. Parallel computing algorithm is used in Internet of things, and many kinds of computing resources are used to solve the computing problems, and the computing speed and data processing ability of Internet of things system are improved.","","978-1-6654-2563-6","10.1109/IEIT53597.2021.00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9525948","parallel;algorithm;time;space","Program processors;Parallel programming;Pipelines;Parallel processing;Software;Internet of Things;Problem-solving","","","","8","IEEE","7 Sep 2021","","","IEEE","IEEE Conferences"
"Automated Solar Plant using IoT Technology","S. Gochhait; H. Patil; T. Hasarmani; V. Patin; O. Maslova","Symbiosis Inst.of Digital & Telecom Mangmt, Symbiosis International (DeemedUniversity), Pune, India; Symbiosis Inst.of Digital & Telecom Mangmt, Symbiosis International (DeemedUniversity), Pune, India; Bharati Vidyapeeth College of Engineering, Savitribai Phule Pune University, Pune, India; Neurosciences Research Institute, Samara State Medical University, Samara, Russia; Neurosciences Research Institute, Samara State Medical University, Samara, Russia","2022 4th International Conference on Electrical, Control and Instrumentation Engineering (ICECIE)","5 Jan 2023","2022","","","1","6","The Internet of Things is an evolving technology that effectively and efficiently enhances everyday activities. Reduce your living expenses by performing the necessary procedures. For synchronized communication, the tools and materials are integrated via the Internet. The price of electricity is continuously increasing, so we need natural sources of electricity that can generate power without cost. In this case, photovoltaic panels produce electricity naturally from the sun. Photovoltaic cells are used in these systems that convert sunlight into electricity. In the power sector, renewable energy sources are currently an exceptional solution for filling the gap in supply. Since solar energy is widely available, unlike some resources that are geographically restricted, it is very beneficial for all renewable energy resources. An advanced plant-based monitoring system coupled with a web-based visual interface is required for this large-scale PV system distribution. In most cases, they are placed in inaccessible places so self-monitoring is impossible in a particular area. Internet of Things (IoT) enabled devices can be used to build control systems. By using the Internet of Things, objects can be detected and controlled remotely over a fixed network, offering opportunities for virtually integrating physical objects into computer-based systems. The use of IoT appears to be beneficial in monitoring renewable energy production. An Arduino-based system is used in this IoT app for tracking the parameters of solar panels. The system continuously monitors the solar panel, and the output power is transmitted over the Internet to the IoT Network A solar photovoltaic power generation plant can be significantly enhanced by using Internet of Things technology for monitoring, analysing, and maintaining its performance. Technology advancements are making renewable energy equipment more affordable worldwide, encouraging the installation of large-scale solar photovoltaic systems. In this paper, an IoT-based approach to solar energy and monitoring is proposed that allows users to monitor and control their solar cells.","2832-9848","978-1-6654-8076-5","10.1109/ICECIE55199.2022.10000287","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10000287","Arduino;Internet of Thing;Solar PV System","Renewable energy sources;Visualization;Costs;Uncertainty;Photovoltaic cells;Solar energy;Internet of Things","","1","","23","IEEE","5 Jan 2023","","","IEEE","IEEE Conferences"
"Research on Collaboration Method of Edge IoT Agent Based on Actor Model","B. Zhang; W. Miao; L. Wei","Key Laboratory of Networked Control Systems, Chinese Academy of Sciences, Shenyang, China; Information & Telecommunication Branch, State Grid Jiangsu Electric Power Co., Ltd., Nanjing, China; State Grid Jiangsu Electric Power Co., Ltd., Nanjing, China","2021 5th International Conference on Power and Energy Engineering (ICPEE)","3 Jan 2022","2021","","","233","238","Focusing on the resource constrained IoT agent collaboration requirements at the edge of the power Internet of things, this paper proposes an edge agent collaborative computation method based on Actor model to satisfy the rapid processing and response requirements of large-scale data in the perception layer of the power Internet of things. Through a unified programming model, this paper can divide the collection and analysis of sensing data in the sensing layer of the power Internet of things into functional components, which can be deployed in different edge IoT agents, to improve the rapid processing ability of edge-side data. At the same time, the components achieve the function cooperation through the message passing mechanism. Finally, this paper implements the proposed scheme based on Akka framework, and designs the edge IoT agent collaborative computing prototype. The prototype system experiments show that the proposed scheme can split the complex services with high resource requirements into different components and deploy them in different edge IoT agents. The proposed method can improve the resource utilization and data processing capacity of the edge IoT agent of the power Internet of things, while ensuring the real-time requirements of edge service analysis.","","978-1-6654-2046-4","10.1109/ICPEE54380.2021.9662600","State Grid Corporation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9662600","Power IoT;Internet of things;Collaborative computing;Actor model;Akka framework","Computational modeling;Message passing;Collaboration;Prototypes;Programming;Data models;Real-time systems","","","","13","IEEE","3 Jan 2022","","","IEEE","IEEE Conferences"
"Research on the Identifier Technology of Electric Internet of Things Based on IPv6","W. Bai; Y. Lu; Y. Wen; F. Tao; X. Xv","Electric Power Intelligent Sensing Technology and Application State Grid Corporation Joint Laboratory, Global Energy Interconnection Research Institute Co., Ltd. (GEIRI), Beijing, China; Electric Power Intelligent Sensing Technology and Application State Grid Corporation Joint Laboratory, Global Energy Interconnection Research Institute Co., Ltd. (GEIRI), Beijing, China; Electric Power Intelligent Sensing Technology and Application State Grid Corporation Joint Laboratory, Global Energy Interconnection Research Institute Co., Ltd. (GEIRI), Beijing, China; Electric Power Intelligent Sensing Technology and Application State Grid Corporation Joint Laboratory, Global Energy Interconnection Research Institute Co., Ltd. (GEIRI), Beijing, China; State Grid Chongqing Electric Power Co. Electric Power Research Institute, Chongqing, China","2021 2nd Information Communication Technologies Conference (ICTC)","31 May 2021","2021","","","230","234","The Internet of Things identifier is the basic supporting technology to realize the precise interaction between things. With the advancement of the construction of the electric Internet of Things, the number of various terminal devices connected to the network has increased sharply, and the types are complex and diverse. There are many types of existing electric equipment identifier systems, and their compatibility is poor. With the access of a large number of terminal devices of the electric Internet of Things, the amount of data in the identifier system is huge, which will cause huge operation and maintenance costs and resource occupation. In response to the above problems, this paper proposes an IPv6 identifier scheme that supports large-scale electric equipment of the electric Internet of Things, designs the registration and network access procedures of the identifier, and then proposes an optimization mechanism for electric Internet of Things communication service transmission based on the ipv6 identifier. Experiments have proved that the identifier scheme and transmission optimization mechanism proposed in this paper can effectively reduce the communication delay and packet loss rate of the business in the electric Internet of Things, and achieve efficient support for the electric Internet of Things business.","","978-1-6654-0474-7","10.1109/ICTC51749.2021.9441625","State Grid Corporation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9441625","identifier;IPv6;identifier coding;transmission optimization mechanism;electric Internet of Things","Chaotic communication;Packet loss;Maintenance engineering;Communications technology;Delays;Internet of Things;Object recognition","","1","","11","IEEE","31 May 2021","","","IEEE","IEEE Conferences"
"Mongoose OS Prototyped ESP8266 Based Weather Forecaster","S. R. Pillutla; G. Suryanarayana; A. S. Kumar; S. E. Mathe; B. N. Rao","School of Electronics Engineering, VIT-AP University, Andhra Pradesh, India; Department of ECE, V R Siddhartha Engineering College, Kanuru, Vijayawada, India; Department of ECE, VNR VJIET, Bachupally, Hyderabad, India; School of Electronics Engineering, VIT-AP University, Andhra Pradesh, India; Department of ECE, NIT Warangal, Telangana, India","2022 International Conference on Recent Trends in Microelectronics, Automation, Computing and Communications Systems (ICMACC)","17 Apr 2023","2022","","","371","375","Internet of Things (IoT) enables many things like car, dustbin, and gas cylinder to be connected, communicated, and controlled. Furthermore, advances in Internet of Things makes home automation smarter. In the contemporary connected world it is highly required and comfortable to get a timely information which is priceless as it gets things accomplished smoothly and avoids many difficulties. Internet of Things, being the state of the art technology, features many capabilities such as facilitating a timely information. Many low power wireless devices and communication technologies are making Internet of Things based solutions available at a large scale. Internet of Things featured devices like ESP8266 and ESP32 become more popular to be end devices for the IoT network. The wireless capability of ESP8266 can be exploited to use it as a smart device to get data/information that can be utilized for applications such as a home automation. In this paper, an ESP8266 based weather forecaster prototype is implemented which communicates with an Open Weather Map web API to bring weather forecast information to assist people at home. In addition, the firmware for ESP8266 is developed using a platform called ‘Mongoose OS’ which efficiently provides lightweight OS/firmware for resource constrained devices such as ESP8266. The presented weather forecaster system is amenable with home environment.","","978-1-6654-9604-9","10.1109/ICMACC54824.2022.10093640","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10093640","Internet of Things;home automation;javascript;nodeMcu;open weather MAP API","Computers;Home automation;Weather forecasting;Prototypes;User interfaces;Market research;Microelectronics","","10","","26","IEEE","17 Apr 2023","","","IEEE","IEEE Conferences"
"Applications of Internet of Things(IoT) in Agriculture: The Need and Implementation","A. Anand; N. K. Trivedi; V. Gautam; R. G. Tiwari; D. Witarsyah; A. Misra","Apex Institute of Technology (CSE) Chandigarh University Gharuan, Mohali, Punjab, India; Chitkara University Institute of Engineering and Technology, Chitkara University, Punjab, India; Chitkara University Institute of Engineering and Technology, Chitkara University, Punjab, India; Chitkara University Institute of Engineering and Technology, Chitkara University, Punjab, India; Information System Departement, Telkom University, Bandung, Indonesia; Chitkara University Institute of Engineering and Technology, Chitkara University, Himachal, India","2022 International Conference Advancement in Data Science, E-learning and Information Systems (ICADEIS)","10 Feb 2023","2022","","","01","05","Humans are motivated to improve agricultural yields by implementing new technologies due to the world's growing population. Precision agriculture, which is expected to raise crops considerably, could be achieved via the Internet of Things (IoT). However, a significant investment in IoT systems for agriculture and farmers who are not computer aware make the large-scale implementation of IoT systems in agriculture problematic. As a result, it is advocated that the focus on the deployment of agriculture IoT systems be widened to include the entire life cycle of agriproducts. While adopting agricultural IoT systems, energy factor must be in consideration. Farmers' interest in IoT technologies will rise significantly if green IoT systems are used throughout the agri-product life cycle. Regarding IoT-based agricultural network technologies, several aspects, including network architecture and layers, network topologies, and network protocols, have been investigated. This research investigates the ways in which Internet of Things (IoT)-based agricultural systems may be combined with other important technologies, such as cloud computing, large amounts of data storage, and analytics. This study also discovers security issues in IoT agriculture. There have also been a few examples of successful IoT-based agriculture rules and policies that various countries have implemented. However, there are still many unanswered questions about IoT agriculture research.","","978-1-6654-6387-4","10.1109/ICADEIS56544.2022.10037505","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10037505","IoT;Smart Agriculture;Application;Management;Security","Protocols;Sociology;Crops;Production;Network architecture;Agriculture;Internet of Things","","7","","14","IEEE","10 Feb 2023","","","IEEE","IEEE Conferences"
"Large-scale heterogeneous terminal management technology for power Internet of Things platform","H. Hong; Z. Suo; H. Wu; D. Li; J. Wang; H. Lu; Y. Zhang; H. Lu","Guangzhou Power Supply Bureau, China Southern Power Grid, Guangdong, China; Guangzhou Power Supply Bureau, China Southern Power Grid, Guangdong, China; Guangzhou Power Supply Bureau, China Southern Power Grid, Guangdong, China; Guangzhou Power Supply Bureau, China Southern Power Grid, Guangdong, China; Guangzhou Power Supply Bureau, China Southern Power Grid, Guangdong, China; Guangzhou Power Supply Bureau, China Southern Power Grid, Guangdong, China; Guangzhou Power Supply Bureau, China Southern Power Grid, Guangdong, China; Guangzhou Power Supply Bureau, China Southern Power Grid, Guangdong, China","2022 2nd International Conference on Consumer Electronics and Computer Engineering (ICCECE)","21 Feb 2022","2022","","","161","164","This paper studies the large-scale management, large-concurrency, and high-reliability of the Internet of Things platform for heterogeneous terminals in the power grid. It sorts out the management framework of different intelligent terminals, intelligent gateways and other heterogeneous terminal equipment in professional fields such as power transmission, power transformation, and distribution, and relies on flexible expansion. Strategies and technologies to meet the management needs of the Internet of Things platform for large-scale terminals; study the container management technology of smart terminals and smart gateways based on the Internet of Things platform, and propose the Internet of Things for the information collection and equipment management requirements of smart terminals and smart gateways by containers. The management technology of micro-applications between the platform and smart terminals and smart gateway containers; research the OTA operation and maintenance service capabilities such as terminal file distribution, terminal file encryption, and terminal update plan release of the Internet of Things platform, and realize the remote upgrade of smart terminal and smart gateway device software.","","978-1-6654-0886-8","10.1109/ICCECE54139.2022.9712797","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9712797","Power system Internet of Things;Heterogeneous terminals;Container management technology","Scalability;Power transmission;Logic gates;Containers;Power grids;Software;Real-time systems","","","","12","IEEE","21 Feb 2022","","","IEEE","IEEE Conferences"
"Internet of Everything (IoE) - From Molecules to the Universe","O. B. Akan; E. Dinc; M. Kuscu; O. Cetinkaya; B. A. Bilgin","University of Cambridge, UK; University of Cambridge, UK; Koç University, Turkey; Koç University, Turkey; University of Cambridge, UK","IEEE Communications Magazine","26 Oct 2023","2023","61","10","122","128","As the Internet of Things (IoT) technologies continue to advance, they are becoming increasingly specialized and compartmentalized into non-interacting application domains, which we call IoXs with X referring to the particular application areas, e.g., Internet of Energy (IoEn), Internet of Vehicles (IoV). This trend has also led to the emergence of unconventional IoXs, such as the Internet of Nano Things (IoNT), further increasing the heterogeneity of the future IoT landscape, in terms of not only the underlying technologies but also the spatiotemporal scale and medium of applications, as well as the material nature of things and the type and semantics of data produced and exchanged. This article explores the potential synergies and opportunities that may arise from such diversity through the interactions between heterogeneous IoXs, enabling unprecedented applications beyond the current confines of IoT. Inspired by the ubiquitous connectivity and seamless interoperability of the universe, which is a vast network of heterogeneous entities interconnected through various forms of interactions (e.g., chemical, electromagnetic, acoustic, and gravitational), we propose the Internet of Everything (IoE) framework. The IoE framework aims to facilitate cooperation of both existing and future IoXs on a diverse scale ranging from molecules to the universe. We discuss potential IoE applications that can be enabled by such synergies and identify the unique challenges for bringing this holistic IoE picture into reality. To address some of these challenges, we propose a layered network architecture for IoE, which includes an IoE middleware that provides a semantic interface among IoXs based on the introduced concept of “IoX-as-a-Service.” Lastly, we recommend future research directions for enabling the IoE applications.","1558-1896","","10.1109/MCOM.001.2200594","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10121570","","Internet;Internet of Things;Industrial Internet of Things;Monitoring;Graphene;Semantics;Nanoscale devices","","3","","15","IEEE","8 May 2023","","","IEEE","IEEE Magazines"
"An Outlook of Narrowband IoT for Industry 4.0","S. K. Routray; K. P. Sharmila; A. Javali; A. D. Ghosh; S. Sarangi","Department of Electrical and Computer Engineering, Bule Hora University, Bule Hora, Ethiopia; Department of Electronics and Commuication Engineering, CMRIT, Bangalore, India; Department of Electronics and Commuication Engineering, RUAS / CMRIT, Bangalore, India; Department of Electronics and Commuication Engineering, CMR Institute of Technology, Bangalore, India; Department of Electronics and Commuication Engineering, Institute of Technical Education & Research, Bhubanswar, India","2020 Second International Conference on Inventive Research in Computing Applications (ICIRCA)","1 Sep 2020","2020","","","923","926","Internet of things (IoT) is a pervasive technology and now it has applications in every technology sector. A new industrial revolution has been started through the connected technologies enabled by the IoT. It is commonly known as Industry 4.0. This is certainly very much different from the previous versions of the industrial revolutions. In fact, IoT will provide a connected framework for large scale manufacturing and production which is going to be very efficient, fast, cost effective, and free from the traditional manufacturing faults. In Industry 4.0 a large number of sensors will be deployed to provide a transparent picture of the whole process. The main goal of Industry 4.0 is to make the manufacturing and production autonomous. Therefore, it is predicted that the majority of the large scale production processes will use IoT to become autonomous. However, Industry 4.0 has also a lot of scopes for the small and medium scale industries. Large scale deployment of IoTs has to be energy efficient and sustainable in the long term. Narrowband IoT (NBIoT) is a right choice in this direction. This paper provides the main issues and challenges of NBIoT for Industry 4.0.","","978-1-7281-5374-2","10.1109/ICIRCA48905.2020.9182803","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9182803","Industry 4.0;autonomous manufacturing;energy efficient manufacturing;narrowband IoT;NBIoT for Industry 4.0","Industries;Sensors;Manufacturing;Production;Energy efficiency;Cellular networks;Monitoring","","12","","15","IEEE","1 Sep 2020","","","IEEE","IEEE Conferences"
"A Survey on Energy Efficient, Harvesting & Optimization Approaches in IoT system","C. Thiagarajan; P. Samundiswary","Department of Electronics Engineering, Pondicherry University, Puducherry, India; Department of Electronics Engineering, Pondicherry University, Puducherry, India","2022 International Conference on Computing, Communication and Power Technology (IC3P)","14 Jun 2022","2022","","","129","132","The Internet of Things (IoT) is a ubiquitous modern technology that consists of multiple key components such as sensors, cloud storage, humans, and so on. Sensors, intelligent computing devices, self-powered devices and data storage units form the foundation of an IoT network’s system architecture. The Internet of Things (IoT) aims to combine as much of our world as possible. In current era, everybody and everywhere started to use & deploy the internet enabled services. Such embedded systems, Multimedia Pod casts, Smart Microwave ovens, home appliances, Global positioning systems & Health Monitoring devices called as biochips etc., In order to eventually automate all sectors, IoT provides sophisticated communication (through the internet) between a list of services, systems, or services. The IoT links all conceivable items to interact with one another in order to provide people with a safe environment & comfortable living. According to recent studies, we wm have over 35 billion IoT devices by 2030. However, these vast fields present issues such as a paucity of IP addresses, as well as the development of suitable and functional protocols and environments. The several places where IoT can be deployed like Building and Home Automation, Industrial Applications, Infrastructure Management, Environmental Monitoring, Large Scale Deployments, Medical and Healthcare Systems, Transport Systems, Energy Management. In this arena, energy conservation or consumption is critical for real-time applications that must operate for longer periods of time. This review article examines and surveys the important energy efficiency, energy harvesting, and other tactics that are used in the IoT to achieve optimal energy use. Also, based on its technological classification, the major aims of this survey article are to propose distinctive approaches, particularly for energy saving. Each section category will be covered in its own parametric.","","978-1-6654-2525-4","10.1109/IC3P52835.2022.00034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793437","Energy Efficiency;Energy Harvesting;optimization of Energy;IoT etc","Protocols;Systems architecture;Microwave theory and techniques;Energy efficiency;Sensor systems;Real-time systems;Internet of Things","","2","","18","IEEE","14 Jun 2022","","","IEEE","IEEE Conferences"
"A Plain Low Threshold IoT Platform for Enabling New IoT Products from SMEs","S. Forsström; U. Jennehag; X. Guan","Institution of Information Systems and Technology, Mid Sweden University, Sundsvall, Sweden; Institution of Information Systems and Technology, Mid Sweden University, Sundsvall, Sweden; Institution of Information Systems and Technology, Mid Sweden University, Sundsvall, Sweden","2020 IEEE International Workshop on Metrology for Industry 4.0 & IoT","10 Jul 2020","2020","","","390","394","Many small and medium enterprises have existing products that they want to innovate on and move into the new era of Internet of Things. Because of this, we have developed a plain Internet of Things platform aimed towards businesses who wants to try out these new systems but does not have the resources to develop or maintain a full platform from the traditional providers. We have developed an open source solution that can be run on cheap off the shelf hardware and employs today's de facto standards for Internet of Things systems. Our solution also provides adequate functionality for an initial effort and innovation, including taking security and privacy concerns into consideration. We have also evaluated our implementation in terms of scale, which shows that the system scales well in scenarios with up to 50 sensor values per second. Which should be enough for a small business first effort to try out their products as an Internet of Things service.","","978-1-7281-4892-2","10.1109/MetroInd4.0IoT48571.2020.9138303","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138303","Internet of Things;IoT;SME;open source;radon;ventilation","Technological innovation;Privacy;Cloud computing;Costs;Hardware;Security;Standards","","6","","12","IEEE","10 Jul 2020","","","IEEE","IEEE Conferences"
"An IoT Based Smart Water Quality Monitoring System using Cloud","J. B. Ajith; R. Manimegalai; V. Ilayaraja","Department of CSE, PSG Institute of Technology and Applied Research, Coimbatore, India; Department of CSE, PSG Institute of Technology and Applied Research, Coimbatore, India; Department of CSE, PSG Institute of Technology and Applied Research, Coimbatore, India","2020 International Conference on Emerging Trends in Information Technology and Engineering (ic-ETITE)","27 Apr 2020","2020","","","1","7","The Internet of Things (IoT) is the network of physical devices, vehicles, home appliances, and other items embedded with electronics, software, sensors, actuators and connectivity which enables these things to connect and exchange data. The number of IoT devices has increased 31% year-over-year to 8.4 billion in 2017 and it is estimated that there will be 30 billion devices by 2020. Water pollution is a major environmental problem in India. The largest source of water pollution in India is untreated sewage. Other sources of pollution include agricultural runoff and unregulated small scale industry that results in polluting, most of the rivers, lakes and surface water in India. In this paper, An IoT Based Smart Water Quality Monitoring System using Cloud and Deep Learningis proposedto monitor the quality of the water in water-bodies. In conventional systems, the monitoring process involves the manual collection of sample water from various regions, followed by laboratory testing and analysis. This process is ineffective, as this process is arduous and time-consuming and it does not provide real-time results. The quality of water should be monitored continuously, to ensure the safe supply of water from any water bodies and water resources. Hence, the design and development of a low-cost system for real-time monitoring of water quality using the Internet of Things (IoT) is essential. Monitoring water quality in water bodies using Internet of Things (IoT) helps in combating environmental issues and improving the health and living standards of all living things. The proposed system monitors the quality of water relentlessly with the help of IoT devices, such as, NodeMCU. The in-built Wi-Fi module is attached in NodeMCU which enables internet connectivity transfers the measured data from sensors to the Cloud. The prototype is designed in such a way that it can monitor the number of pollutants in the water. Multiple sensors are used to measure various parameters to assess the quality of water from water bodies. The results are stored in the Cloud, deep learning techniques are used to predict whether the water suitable or not.","","978-1-7281-4142-8","10.1109/ic-ETITE47903.2020.450","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9077792","Water Quality Monitoring;Internet of Things (IoT);ESP8266;Wi-Fi protocol;Firebase Cloud","Cloud computing;Water quality;Water pollution;Real-time systems;Pollution measurement;Internet of Things;Monitoring","","27","","20","IEEE","27 Apr 2020","","","IEEE","IEEE Conferences"
"Multistage Deep Transfer Learning for EmIoT-Enabled Human–Computer Interaction","R. Liu; Q. Liu; H. Zhu; H. Cao","Department of Computer Science, Inner Mongolia University, Hohhot, China; School of Future Technology, Guangzhou International Campus, South China University of Technology, Guangzhou, China; Department of Electrical and Computer Engineering, National University of Singapore, Singapore; School of Information Engineering, Wuhan University of Technology, Wuhan, China","IEEE Internet of Things Journal","8 Aug 2022","2022","9","16","15128","15137","Emotional Internet of Things (EmIoT), which provides Internet of Things (IoT) devices cognitive and socialization capabilities, has been regarded as a future direction to improve users’ experiences. With the development of intelligent techniques, the requirement of EmIoT is not only sensing the users’ emotional states but also providing emotional feedbacks. Human–computer interaction has been studied to achieve speech interaction with IoT devices. The recent advances in neural text-to-speech (TTS) have made “human parity” synthesized speech possible for IoT-enabled human–computer interaction. Furthermore, emotion control can be achieved by using the emotional codes in a unified model, referred to as emotional TTS (or ETTS for short). Such ETTS models have achieved promising emotional expressiveness using large-scale emotion-annotated English data set; however, they are not practical in IoT environments with other mainstream languages, especially for Chinese. In fact, the limited available large-scale emotion-annotated data set is challenging the development of Chinese ETTS. To address that we propose a multistage deep transfer learning scheme to design a high-quality Chinese ETTS system under a small-scale training corpus to achieve EmIoT in Mandarin environments. In this scheme, the pretrained knowledge from the former stages corresponding to a large-scale neutral English and a medium-scale emotional English corpora is transferred to a Mandarin ETTS model. Thereby, the trained model can achieve high-quality emotional speech with limited available emotional corpus, which is able to serve various EmIoT-oriented applications. The experiments have been conducted to demonstrate the effectiveness and superiority of the proposed model as compared to other counterparts in terms of naturalness and emotional expressiveness. We refer readers to visit our demo Webpage1 enjoy the synthesized speech samples.","2327-4662","","10.1109/JIOT.2022.3148766","High-Level Talents Introduction Project of Steed Program of Inner Mongolia University (presided over by Rui Liu); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9702532","Emotional expressiveness;emotional Internet of Things (EmIoT);human–computer interaction (HCI);transfer learning","Speech recognition;Transfer learning;Internet of Things;Bidirectional control;Hidden Markov models;Human computer interaction;Task analysis","","6","","70","IEEE","3 Feb 2022","","","IEEE","IEEE Journals"
"Role of VLSI Design To Build Trusted And Secured IOT Devices- A Methodological Approach","B. N; K. Jayavel","Department of Computer Science, SRM Institute of Science and Technology, Vadapalani, Chennai, India; Department of Information Technology, SRM Institute of Science and Technology, Chennai, India","2021 5th International Conference on Electronics, Communication and Aerospace Technology (ICECA)","20 Jan 2022","2021","","","473","479","Internet of Things is quite a old technology finding new spaces with almost exponential spread rates. This has opened up new avenues and integrative approaches across technologies. One classical pair which possess close association is Very Large-Scale Integration (VLS I) and Internet of Things (IoT). Internet of Things is interconnection of living and non living things with Internet as background. The two different perspective of proposed methodology to integrate VLSI and IoT is (i) configuring the entire application as a system on Chip and (ii) embedding the VLS I capability to each layer of the IoT application and the capability can be used as and when required. This proposed work identifies the gaps between the VLSI and IoT and enables the possibilities of bridging the goodness of both to enjoy the hybrid fruit of technology. One such possibility is security to amalgamate the IoT and VLSI technologies. The security can be handled efficiently and effectively by integrating the circuits of VLSI with the services of IoT. Security is demonstrated using finite state machine-based hardware lock to make use of the IoT service. The functionality as such can be efficiently scaled up based the sensitivity of the IoT application.","","978-1-6654-3524-6","10.1109/ICECA52323.2021.9675878","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9675878","Internet of Things;Field Programmable Gate Array (FPGA);Security;Hardware Lock","Sensitivity;Space technology;Integrated circuit interconnections;Very large scale integration;Logic gates;Hardware;System-on-chip","","","","27","IEEE","20 Jan 2022","","","IEEE","IEEE Conferences"
"Security risks in MQTT-based Industrial IoT Applications","T. K. Boppana; P. Bagade","Dept. of Computer Science and Engineering, Indian Institute of Technology, Kanpur, India; Dept. of Computer Science and Engineering, Indian Institute of Technology, Kanpur, India","2022 IEEE International Conference on Omni-layer Intelligent Systems (COINS)","18 Aug 2022","2022","","","1","5","Internet of Things (IoT) plays a crucial role in improving the quality of life. In recent years, IoT systems have proliferated in almost every industry, including manufacturing, automobiles, agriculture, and energy. IoT is the key enabling technology for Industry 4.0. This growing reliance on IoT devices piqued the interest of several adversaries attempting to gain unauthorized access to IoT systems for illicit purposes. So, it is essential to identify any potential security risks in IoT systems. Numerous Industrial Internet of Things (IIoT) applications, including wind turbines, agriculture, and warehouses, deploy hundreds of IoT devices in remote locations. These IoT devices are not physically monitored since it requires extensive human effort. Instead, the IoT devices are monitored by web applications that collect sensor data from remote devices. IoT application-layer protocols are responsible for communication between web applications and IoT devices in such large-scale IoT systems. Any communication flaw could put the entire IoT system at risk. The publish/subscribe-based MQTT protocol is a widely used IoT messaging standard. In this paper, we present a threat model and demonstrate a specific weakness in unencrypted MQTT-based IoT systems that enables an attacker to gain unauthorized access to the entire system by launching a combination of man-in-the-middle (MITM) and cross-site scripting (XSS) attacks. We also discuss steps to be taken and future directions for research in the security of industrial IoT systems using the MQTT communication protocol to avoid the possibility of such attacks.","","978-1-6654-8356-8","10.1109/COINS54846.2022.9854993","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9854993","Industrial IoT;Industry 4.0;Man-in-the-Middle attack;Cross-Site Scripting attack;MQTT","Protocols;Cross-site scripting;Agriculture;Wind turbines;Fourth Industrial Revolution;Security;Intelligent systems","","3","","31","IEEE","18 Aug 2022","","","IEEE","IEEE Conferences"
"EZPlugIn: Plug-n-Play Framework for a Heterogeneous Iot Infrastructure for Smart Home","P. Kar; H. Wang","The University of Nottingham Ningbo China, China; Norwegian University of Science and Technology, Norway","IEEE Internet of Things Magazine","27 Sep 2021","2021","4","3","104","108","Internet of Things (IoT) introduces a very large scale of technologies. An IoT system is comprised of a large number of smart devices and sensors connected together that are often non-intrusive, transparent, and invisible. Current IoT networks using IP-based Internet architecture are facing limitations in scalability and interoperability among the devices. In this work, we propose a plug-n-play IoT framework to significantly improve the interoperability among devices so as to obtain a more flexible IoT infrastructure. To achieve the plug-n-play feature in an IoT network, we propose to modify the notion of communication among the devices by adapting the Named Data Networking (NDN) communication paradigm in the IoT infrastructure. In NDN, a device communicates with other devices and sends data requests by the name of the accessing component instead of their physical locations. Security issues in such a framework can be more easily handled than in the current Internet. But adaptation of NDN in the current communication model is a challenging task. So we have modified data structures as well as the format of exchanged messages to fit the NDN with the service based communication model. The proposed framework has been studied in a smart home environment. Simulation results show that the proposed framework has less transmission delay and better throughput compared to IP-based systems.","2576-3199","","10.1109/IOTM.0001.2000172","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9474921","","Internet of Things;Smart homes;Interoperability;IP networks;Computer architecture;Logic gates;Intelligent sensors","","","","15","IEEE","5 Jul 2021","","","IEEE","IEEE Magazines"
"Smart Home Automation System Methodologies-A Review","P. Sivagami; D. Jamunarani; P. Abirami; M. Pushpavalli; V. Geetha; R. Harikrishnan","EEE, Sathyabama Institute Of Science &Technology, Chennai, India; E&I, Sathyabama Institute Of Science &Technology, Chennai, India; EEE, Sathyabama Institute Of Science &Technology, Chennai, India; EEE, Sathyabama Institute Of Science &Technology, Chennai, India; EEE, Sathyabama Institute Of Science &Technology, Chennai, India; Symbiosis Institute Of Technology, Symbiosis International Deemed University, Pune, India","2021 Third International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV)","31 Mar 2021","2021","","","1386","1390","Emerging network paradigm that connects billions of devices to the internet and to the users to meliorate the facet of life of the people is IoT-Internet of Things. In IoT internet depicts inter networking of things that is it focuses on devices whereas things exemplify physical devices, virtual services, functions, machines. IoT allows devices to interact directly with each other to make decisions and exchange data as an evolution of machine-to-machine communication. The power of data collection, artificial intelligence, wireless sensor networks, embedded systems, control, and automation systems makes IoT smart. IoT devices generating data are from different vendors and different domains. For the size of machines from small scale to large scale, shares data and execute an action without the intervention of individuals by the advancement of automation technology using IoT. Nowadays, IoT becomes one of the essential and integral components in our daily life. For sectors like academics and industry, the area of interest is IoT. So, it becomes necessary to find new methodologies to associate different devices over the internet. Thus, the IoT concept makes a road map for many sectors in the community such as health care, home automation, industrial automation, smart grid, smart building, agriculture, energy management system.","","978-1-6654-1960-4","10.1109/ICICV50876.2021.9388491","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9388491","Internet of things-IoT;GSM-Global System for Mobile Communication;GPRS-General packet radio service;DTMF- Dual tone multifrequency signaling;HAS-Home Automation System","Wireless sensor networks;Automation;Smart buildings;Smart homes;Smart grids;Safety;Internet of Things","","5","","15","IEEE","31 Mar 2021","","","IEEE","IEEE Conferences"
"Design and Implement Adaptive Tree Topology Mechanism For Wi-Fi Wireless Network","J. -C. Chiu; C. -L. Tsai; Z. -Y. Lee","Department of Electrical Engineering, National Sun Yat-sen University, Republic of China; Department of Electrical Engineering, National Sun Yat-sen University, Republic of China; Department of Electrical Engineering, National Sun Yat-sen University, Republic of China","2020 International Computer Symposium (ICS)","23 Feb 2021","2020","","","278","282","As the demand for the Internet of Things increases, wireless network protocols applied to the Large-Scale Internet of Things (LS-IoT) is the future development direction. Although 5G technology is a recent development trend, its signal coverage and cost will be key issues. However, the Wi-Fi protocols have many protocol-related modules that are quite mature and relatively inexpensive. And it has the advantages of low latency and high transmission efficiency. We implement Adaptive Tree Topology Algorithm in the Wi-Fi tree network system for Internet of Things data collection and make appropriate design corrections to overcome the influence of environmental factors. In the implementation and testing, it was found that multiple problems caused by environmental factors. First, signal interference in the environment will cause packet loss in the system. Cause the routing mechanism to collapse. Second, the strength of the packet signal is weakened due to obstacles. In addition, the previously designed hop selection mechanism may cause unstable data paths and increase the probability of disconnection. Third, the signal interference affects the transmission of update routing-related packets, which causes the routing data of the node and the gateway to be out of sync. In order to overcome the above-mentioned influence, we designed a Resend Queue retransmission mechanism to effectively solve packet loss, and improve the retransmission time interval to reduce the probability of packet collision due to frequent retransmissions when the interference is high. In addition to the hop selection mechanism, increase the signal strength as another routing metric to ensure the establishment of a network chain with a smaller hopping with stable signal. The maintenance mechanism is designed to update the data in real time and gather it to the gateway to provide more stable routing maintenance and eliminate routing maintenance errors. Furthermore, we implement our algorithm on CC3220MODA. After testing, we offer three objective function for this system. Confirm the feasibility of the network mechanism design in this paper, and provide setting objective functions and setting suggestions for key parameters in the system.","","978-1-7281-9255-0","10.1109/ICS51289.2020.00062","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9359039","Large-Scale Internet of Things (LS-IoT);media access control(MAC);Tree topology;Wireless network;Wi-Fi","Adaptive systems;Network topology;Interference;Maintenance engineering;Logic gates;Routing;Wireless fidelity","","","","18","IEEE","23 Feb 2021","","","IEEE","IEEE Conferences"
"ROOF (Realtime Onsite Operations Facilitation) Computing Framework","S. Madanapalli; N. Krishna; S. Solanke; A. P; A. Jakka; A. Jasti; A. Das; A. Meloni",NA; NA; NA; NA; NA; NA; NA; NA,"ROOF (Realtime Onsite Operations Facilitation) Computing Framework","14 Apr 2022","2022","","","1","48","Real-Time Operations Facilitations or ROOF is a class of computational framework for Edge Computing with Internet of Things (IoT). The ROOF framework provides support for building scalable, secure, and robust Internet of Things applications with limited tools in resource constrained situations. The ROOF helps in developing federated architecture for large scale IoT operations. At the same time, it can provide micro-models for rapid prototyping and quick decision making. It also provides autonomic architectural support for spatio-temporal events handling. The ROOF framework has been designed to provide innovation, reuse, better user experience, security by design, for harmonizing horizontal as well as vertical integration for the Internet of Things ecosystem.","","978-1-5044-8605-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757900","","","","","","","","14 Apr 2022","","","IEEE","IEEE Standards"
"Real-Time Dynamic Configuration of Firewall Rules for High-Speed IoT Networks","Y. -A. Shao; C. -S. Chao","Communications Engineering, Feng Chia University, Taichung, Taiwan; Communications Engineering, Feng Chia University, Taichung, Taiwan","2022 IEEE 4th Eurasia Conference on IOT, Communication and Engineering (ECICE)","20 Feb 2023","2022","","","89","94","The Internet of Things (IoT) is indispensable to modern society. It has entered the mainstream trend recently owing to its ability to read data and connect systems. IoT network platforms comprise various applications, leading to an influx of heavy and varying network traffic, allowing hackers to launch large-scale network attacks easily. When hackers gain control of an IoT device, they can initiate large-scale botnet attacks even through nonconventional computing devices such as cameras and routers. For example, Dyn, a domain name system provider, experienced large-scale distributed denial-of-service attacks on its IoT devices in 2016, causing companies, such as Twitter and Amazon, to suffer the consequences. Therefore, adapting to large-scale changes in network traffic in real-time is imperative. Firewalls are the foundation of device security. Therefore, when large-scale changes in network traffic occur, it is necessary to ensure the effectiveness of firewalls to reduce the probability of successful attacks. This study proposes a system that can adjust the order of firewall rules in real-time to monitor the traffic in high-speed IoT networks. When the system detects a sudden increase in the number of packets, the firewall rules are reordered and applied immediately to ensure security. Additionally, the original filtering effect of the firewall is maintained without being compromised. The test results indicate that high-speed network firewall performance has improved significantly with no abnormality detected in the filtering effect.","","978-1-6654-8208-0","10.1109/ECICE55674.2022.10042899","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10042899","The Internet of Things;reordering of firewall rules in real-time;firewall filtering effect;real-time dynamic rule configuration","Visualization;Firewalls (computing);Filtering;Computer hacking;Social networking (online);Telecommunication traffic;Real-time systems","","","","8","IEEE","20 Feb 2023","","","IEEE","IEEE Conferences"
"Application of dynamic decision method for automatic allocation of address in airport IoT node-device","N. He; Y. Yu; W. Ye","Research and Development Center, The Second Research Institute of CAAC, Chengdu, China; Research and Development Center, The Second Research Institute of CAAC, Chengdu, China; Research and Development Center, The Second Research Institute of CAAC, Chengdu, China","2020 IEEE International Conference on Advances in Electrical Engineering and Computer Applications( AEECA)","6 Oct 2020","2020","","","137","136","With the rapid development of the airport, the application of the Internet of things is becoming more and more popular. And the scale of the Internet of things (IoT) system is also becoming larger, in order to better manage and monitor all node-device in IoT system, the node-device is required to provide a unique access address. Since all node-devices are set according to the default factory address, in the early stage of the construction of the IoT system, the address of the node device needs to be modified one by one, which is with large workload, error and inefficient. In the later maintenance of the system, the address of all node-device needs to be reconfigured in different ways, which not only requires huge workload, but also needs to suspend the operation of the device. The method described in this paper, which can make each node-device configure its address by itself with dynamic intelligent address allocation strategy and in the case of not suspending the equipment, Improving the efficiency of system construction and equipment maintenance in the later stage, and also provide technical support for the construction of smart airport. The method in this paper effectively complete a series of work of automatic address allocation and modification, through the functional verification of practical application, and improve the efficiency of node-device address setting and maintenance of the IoT system in the initial and later stages of construction.","","978-1-7281-6521-9","10.1109/AEECA49918.2020.9213628","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9213628","IoT;Node-device;Address allocation;Intelligence decision","Internet of Things;Servers;Airports;Maintenance engineering;Resource management;Navigation;Research and development","","","","9","IEEE","6 Oct 2020","","","IEEE","IEEE Conferences"
"An Architecture to Support the Development of Collaborative Systems in IoT Context","M. G. Do Nascimento; J. M. N. David; M. A. R. Dantas; R. M. M. B. Villela; V. S. de Andrade Menezes; F. A. B. Colugnati","Department of Computer Science (DCC), Federal University of Juiz de Fora, Juiz de Fora, Brazil; Department of Computer Science (DCC), Federal University of Juiz de Fora, Juiz de Fora, Brazil; Department of Computer Science (DCC), Federal University of Juiz de Fora, Juiz de Fora, Brazil; Department of Computer Science (DCC), Federal University of Juiz de Fora, Juiz de Fora, Brazil; Department of Computer Science (DCC), Federal University of Juiz de Fora, Juiz de Fora, Brazil; Medical Intership Department, Federal University of Juiz de Fora, Juiz de Fora, Brazil","2023 26th International Conference on Computer Supported Cooperative Work in Design (CSCWD)","22 Jun 2023","2023","","","1722","1727","In the Internet of Things (IoT) era, technologies have become even more immersive and ubiquitous in people’s lives. Therefore, developing collaborative systems becomes a more complex task involving different factors and actors. The nature of these applications encompasses different stakeholders and interests. The software development process encompasses large-scale sensors and actuators to characterize appropriated the Internet of Things (IoT). The introduction of this technology in the scenario of collaborative systems and IoT increased the complexity of software development. This work presents a computational architecture based on middleware to deal with the challenges of developing collaborative systems in the context of IoT. As a contribution, results acquired from the case study demonstrate how the architecture supports IoT application development in the context of collaborative systems.","2768-1904","979-8-3503-3168-4","10.1109/CSCWD57460.2023.10152672","EMI; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10152672","Collaborative systems;IoT;Internet of Things;Middleware","Actuators;Federated learning;Collaboration;Computer architecture;Sensor phenomena and characterization;Complexity theory;Internet of Things","","","","22","IEEE","22 Jun 2023","","","IEEE","IEEE Conferences"
"A Cost-Effective Multilayer Authentication Framework for Large-Scale IoT Deployments","S. Almajali; T. Hamad","Department of Computer Science, Princess Sumaya University for Technology, Amman, Jordan; Information Security Department, Umniah, Amman, Jordan","2022 International Conference on Engineering and Emerging Technologies (ICEET)","11 Jan 2023","2022","","","1","6","Security is a fundamental requirement for Internet of Things (IoT) devices to avoid threats. Authentication is one common security control used to prevent and mitigate threats. Different authentication frameworks for various IoT environments exist. Some IoT applications require mutual authentication to enable two-way trust. Supporting mutual authentication in a cost-effective and practical way for IoT environment is a challenge. The primary objective of this paper is to compare the most efficient authentication techniques in IoT and propose a new cost-effective mutual authentication framework. The proposed framework includes several advantages, such as multi-layer authentication, two-way authentication between IoT devices and servers, protection against replay attacks, protection against message modification attacks, and behavior-based authentication. The proposed framework is suitable for small-scale and large-scale IoT applications.","2831-3682","978-1-6654-9106-8","10.1109/ICEET56468.2022.10007309","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10007309","","Costs;Data integrity;Authentication;Manuals;Nonhomogeneous media;Behavioral sciences;Internet of Things","","","","8","IEEE","11 Jan 2023","","","IEEE","IEEE Conferences"
"Smart Farm Based on Six-Domain Model","W. Xu; Z. Kaili; W. Tianlei","Faculty of SmartManufacturing, Wuyi University, Jiangmen, China; Faculty of SmartManufacturing, Wuyi University, Jiangmen, China; Faculty of SmartManufacturing, Wuyi University, Jiangmen, China","2021 IEEE 4th International Conference on Electronics Technology (ICET)","16 Jun 2021","2021","","","417","421","Architecture design is the top-level design of the Internet of Things (IoT). Based on the conceptual model of IoT, its reference architecture based on six-domain model is defined in international standards. It is necessary to establish the system architecture for smart farm suitable for international standards. Through the comprehensive analysis of the agricultural production and management process and the in-depth study of the international standards for the IoT reference architecture, the entity integration of user domain, physical entity domain, sensing & controlling domain, application & service domain, operations & management domain and resource access & interchange domain of the smart farm are determined. The six-domain model reference architecture of smart farm is proposed. There are advantages of compatibility, flexibility and scalability, etc. As an example, it is applied in the system architecture design for the open field vegetable smart planting subsystem. It can provide effective, reliable and scalable framework design guidance for each subsystem of smart farm. It is conducive to the formation of a collaborative ecosystem of smart farm, so as to realize its large-scale applications.","","978-1-7281-7673-4","10.1109/ICET51757.2021.9451003","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9451003","smart farm;reference architecture;six-domain model;Internet of Things;smart planting","Systematics;Scalability;Ecosystems;Systems architecture;Collaboration;Reliability engineering;Sensors","","1","","7","IEEE","16 Jun 2021","","","IEEE","IEEE Conferences"
"Impact of high permeability EV charging load on distribution network and its layout planning method","H. Yibo; R. DongHong; Q. Tao; C. HongWei","State Grid ShangLuo power supply company, Shangluo, China; State Grid ShangLuo power supply company, Shangluo, China; State Grid ShangLuo power supply company, Shangluo, China; State Grid ShangLuo power supply company, Shangluo, China","The 16th IET International Conference on AC and DC Power Transmission (ACDC 2020)","15 Sep 2021","2020","2020","","2293","2299","In the current ubiquitous electric Internet of things background, as the representative of new energy load, the research and production of EV have been widely concerned. Accurately and comprehensive analysis of the impact of large-scale EVcharging on the power grid will provide theoretical preparation for the development and application of EV, and provide basic guarantee for a large number of EV charging stations to access the power grid.Therefore, this report studies the typical simulation system, and studies the impact of large-scale EV charging load on the power grid from the aspects of safe operation, planning and constructionas well as economy of the power grid. The simulation verifies the impact of large-scale charging load on distribution network voltage and load rate. And analyzes the influence of different access locations and access capacities of large-scale EV charging on the power grid, puts forward the layout planning method of charging stations, and explores the typical structure and operation mode of distribution network suitable for EV charging load access. It provides theoretical preparation for the large-scale EV to be connected to the power grid and has important guiding significance for promoting the development of the power grid technology suitable for the large-scale application of EV.","","","10.1049/icp.2020.0347","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9538234","","","","2","","","","15 Sep 2021","","","IET","IET Conferences"
"Developing a Smartphone App for Arecanut Farmers and Integrating it with an IoT Enabled Smart Weighing Scale","A. Ramkumar; M. Kangotra; M. Mehta; S. V. Sathish Kumar","Department of Mechatronics Engineering, Kumaraguru College of Technology, Coimbatore, India; Department of Mechatronics Engineering, Kumaraguru College of Technology, Coimbatore, India; Department of Mechatronics Engineering, Kumaraguru College of Technology, Coimbatore, India; Department of Mechatronics Engineering, Kumaraguru College of Technology, Coimbatore, India","2021 International Conference on Advancements in Electrical, Electronics, Communication, Computing and Automation (ICAECA)","18 Jan 2022","2021","","","1","14","Areca nut production in India is the largest in the world accounting for approximately 52% (according to 2019 production volumes) of its world output, and still is a very tedious and time consuming process as to the scale of the product [1]. Smart Sensors and the Internet of Things (IoT) are two new technologies that can help to resolve this issue. This paper will show how smart sensors, the Internet of Things (IoT), and a smartphone application may be used to oversee the entire process. We are proposing a smart weighing scale integrated to our smartphone application using Internet of Things (IoT). The smart weight scale’s purpose is to measure weight of Areca nuts in real time and send the data to our smartphone application by using the ESP8266 Wi-Fi module for wireless communication. This method employs a mechanical framework and a 50 kg load cell as sensing elements, along with an HX711 amplifier.","","978-1-6654-2829-3","10.1109/ICAECA52838.2021.9675626","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9675626","Areca nut;smartphone application;smart weighing scale;Internet of Things","Wireless communication;Weight measurement;Crops;Production;Real-time systems;Time measurement;Internet of Things","","","","24","IEEE","18 Jan 2022","","","IEEE","IEEE Conferences"
"Aqua Monitoring System using AWS","R. K. Kodali; A. C. Sabu","Dept. of Electronics and Communication Engineering, National Institute of Technology, Warangal, Warangal, India; Dept. of Electronics and Communication Engineering, National Institute of Technology, Warangal, Warangal, India","2022 International Conference on Computer Communication and Informatics (ICCCI)","31 Mar 2022","2022","","","1","5","Internet of Things (IoT) is a technology which is rapidly growing, the future of IoT is limitless as the data streams have quadrupled over the years. Future markets are going to shift from traditional data processing techniques to Big Data Analytics and Cloud computing as businesses worldwide are shifting to cloud based work approaches which was largely boosted by the Covid-19 pandemic. Fishes are well known to be highly sensitive to the environment, hence they require proper care and attention from their owners. Many a times they forget to feed the fish, change the water, check the pH levels etc. these problems look simple but when it comes to tracking hundreds of fishes it can be difficult, these issues can be easily resolved by using IoT. An IoT system that can be highly beneficial for small to large scale aquariums is necessary e.g. Dubai Aquarium (where hundreds of fishes are constantly monitored). The System can be used to create the ideal conditions required for high yield. The aquaculture sector is going to play a crucial role in the future economy as fishes are getting scarce all over the world. Steps must be taken to streamline processes and by which increase efficiency while improving fish health. IoT based Aquariums can save Ocean Wildlife by building reliable systems that are capable of real-time data processing. Massive tanks can be built for endangered species in remote locations further increasing biodiversity and building a balanced ecosystem. Larger fishes can be monitored using technologies such as RFID, transmitters, etc. since it can be difficult to monitor them in large tanks. Data received from sensors can be stored in some cloud platform and analyzed for future predictions and redundant storage, all sorts of smart devices are able to communicate with each other regardless of hardware and operating system used. The IoT based Aquarium Monitoring device is capable of capturing the water levels inside the aquarium and notifies the user by email when its low. It can switch on/off the lights of the aquarium, control the automatic feeder using and record the room temperature and humidity readings with the help of AWS technologies. The fish feeder is controlled by the user using a voice application or web/app interface. Parameters used in this project are Room Temperature, Humidity, Water Level, LED status and Feeder status. Sensor acquisition is performed by ESP-32, it is also used as data processing device as well as local server/controller. User can monitor the conditions of the aquarium locally or remotely from any part of the world as long as he/she has an Internet connection since data is processed through AWS Lambda, stored in DynamoDB and hosted in AWS API. Data is further visualized using AWS IoT Analytics and QuickSight for proper decision making. Every feature in this model works effortlessly and is highly accurate. A wide scale Industrial Application of this Project can be included in Aquaponics fish management, fish farming, Zoo keeping, etc. The data received can be used to take necessary actions and are stored for future studies. They are highly beneficial for farmers raising a certain species of fishes and for maintaining a balanced ecology.","2329-7190","978-1-6654-8035-2","10.1109/ICCCI54379.2022.9740798","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9740798","IoT;ESP32;AWS IoT Core;AWS IoT Analytics;AWS QuickSight;AWS Lambda;AWS DynamoDB;AWS API Instance;IFTTT;Amazon Alexa","Temperature sensors;Temperature measurement;Cloud computing;Data visualization;Data processing;Internet of Things;Marine animals","","9","","6","IEEE","31 Mar 2022","","","IEEE","IEEE Conferences"
"Implementation and Analysis of IoT Based Automation Using MQTT","M. Kashyap; V. Sharma; G. Verma","Gautam Buddha University, Greater Noida, India; Gautam Buddha University, Greater Noida, India; Graphic Era University, Dehradun, India","2021 IEEE 4th International Conference on Computing, Power and Communication Technologies (GUCON)","2 Nov 2021","2021","","","1","5","Internet of Things (IoT) allows the communication among various technology and devices that employing the internet with both the capacity to assemble and trade the information. Various devices have been frequently used small-scale controllers like Arduino. Communication between a set of devices connected over a network to communicate under the domain of the “Internet of Things” can deploy various communication models for information exchange. Internet of thing uses several protocol (e.g. HTTP, CoAP, MQTT etc.) in application layers for the transmission of data. MQTT is a protocol that uses the Publisher subscriber concept for communication. MQTT is used to perform several number of tasks to explore its functionality further. In IoT, Energy management in the buildings is an open challenge to the researcher. As a result, the IoT-based Automation system is constructed in this work using the MQTT protocol, in which the energy management is the basic key feature. Further an investigations have been carried out with communication between devices in IoT environment. A setup is established with the connection of devices with complex functionally such as RaspberryPi and NodeMCU (Wi-Fi) to analyze the performance of MQTT when several devices with high request/response ratio are connected to it. This paper is based on the communication between the RaspberryPi and NodeMCU using the MQTT protocol. Here, RaspberryPi act as a server and NodeMCU acts as the client. These devices control each other's devices with the help of MQTT protocol. This proposed system allows the users to remotely monitor their device form anywhere. It will help to save, monitor and control the light and energy in any type of buildings.","","978-1-7281-9951-1","10.1109/GUCON50781.2021.9573857","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9573857","Internet of Things(IoT);NodeMCU;RaspberryPi;Automation;Message Queuing Telemetry Transport protocol (MQTT)","Transport protocols;Protocols;Automation;Buildings;Real-time systems;Servers;Internet of Things","","2","","22","IEEE","2 Nov 2021","","","IEEE","IEEE Conferences"
"Designing an IoT-Based Information System for Improving Efficiency and Productivity in Small-Scale Manufacturing Industries","A. F. Riady; G. M. Tara; S. G. Rabiha","Information Systems Department, BINUS Online Learning Bina Nusantara University, Jakarta, Indonesia; Information Systems Department, BINUS Online Learning Bina Nusantara University, Jakarta, Indonesia; Information Systems Department, BINUS Online Learning Bina Nusantara University, Jakarta, Indonesia","2023 IEEE 9th International Conference on Computing, Engineering and Design (ICCED)","13 Feb 2024","2023","","","1","6","The Internet of Things (IoT) had become a focus in the manufacturing industry. The presence of IoT technology was expected to address challenges in efforts to improve efficiency and productivity in the production process in both small-scale and large-scale manufacturing industries. In this research, using the problems that existed in small-scale manufacturing industries, the problems often faced were material delays, absent operators, and machines that could not operate. In this research, we designed an information system that included system architecture, use case diagrams, activity diagrams, sequence diagrams, class diagrams, and mockup applications. Our focus was on the information system for processes in the production line, where each machine used was equipped with IoT devices along with power and vibration measuring sensors. From this design, it was expected to help manufacturing companies in creating an information system for collecting data related to the production machines used. So that in the future it could be used in making business process decisions for the company.","2767-7826","979-8-3503-7012-6","10.1109/ICCED60214.2023.10425435","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10425435","internet of things;manufacturing industry;information system;efficiency;productivity","Manufacturing industries;Productivity;Machining;Planning;Internet of Things;Monitoring;Information systems","","","","18","IEEE","13 Feb 2024","","","IEEE","IEEE Conferences"
"Antennas and Other Peripherals for IoT","S. K. Routray; M. K. Jha; A. Javali; M. Pappa","Department of Computer Science and Engineering, CMR University, Bangalore, India; Department of Electronics and Communication Engineering, CMR Institute of Technology, Bangalore, India; Department of Electronics and Communication Engineering, CMR Institute of Technology, Bangalore, India; Department of Electronics and Communication Engineering, CMR Institute of Technology, Bangalore, India","2023 8th International Conference on Communication and Electronics Systems (ICCES)","1 Aug 2023","2023","","","415","419","Internet of things (IoT) is predominantly wireless in nature and thus it utilizes the main principles of wireless communication and networking. In order to design and deploy IoT networks, several wireless network components are needed. The common among them are the antennas, antenna support systems, edge computing facilities, gateways, and data centers. However, IoT nodes and sensors are small in size and they are exposed to limited resource environments. Keeping that in mind, the wireless components needed for IoT are designed according to their matching applications and demanded characteristics. This study analyzes the antennas and other peripheral devices required in IoT deployment. Also, this study discusses about the issues related to the architecture used for large scale and small scale deployments.","","979-8-3503-9663-8","10.1109/ICCES57224.2023.10192810","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10192810","Internet of things;antenna;antennas for IoT;peripherals for IoT;gateway for IoT","Wireless sensor networks;Data centers;Wireless networks;Logic gates;Sensor phenomena and characterization;Internet of Things;Broadband antennas","","","","24","IEEE","1 Aug 2023","","","IEEE","IEEE Conferences"
"Trust2Vec: Large-Scale IoT Trust Management System Based on Signed Network Embeddings","S. Dhelim; N. Aung; M. T. Kechadi; H. Ning; L. Chen; A. Lakas","School of Computer Science, University College Dublin, Dublin 4, Ireland; School of Computer Science, University College Dublin, Dublin 4, Ireland; School of Computer Science, University College Dublin, Dublin 4, Ireland; School of Information Technology and Engineering, Jinzhong University, Jinzhong, Shanxi, China; School of Computing, Ulster University, Belfast, U.K; College of Information Technology, United Arab Emirates University, Al Ain, UAE","IEEE Internet of Things Journal","22 Dec 2022","2023","10","1","553","562","A trust management system (TMS) is an integral component of any Internet of Things (IoT) network. A reliable TMS must guarantee the network security, data integrity, and act as a referee that promotes legitimate devices, and punishes any malicious activities. Trust scores assigned by TMSs reflect devices’ reputations, which can help predict the future behaviors of network entities and subsequently judge the reliability of different entities in the IoT networks. Many TMSs have been proposed in the literature, these systems are designed for small-scale trust attacks and can deal with attacks where a malicious device tries to undermine TMS by spreading fake trust reports. However, these systems are prone to large-scale trust attacks. To address this problem, in this article, we propose a TMS for large-scale IoT systems called Trust2Vec, which can manage trust relationships in large-scale IoT systems and can mitigate large-scale trust attacks that are performed by hundreds of malicious devices. Trust2Vec leverages a random-walk network exploration algorithm that navigates the trust relationship among devices and computes trust network embeddings, which enables it to analyze the latent network structure of trust relationships, even if there is no direct trust rating between two malicious devices. To detect large-scale attacks, such as self-promoting and bad-mouthing, we propose a network embeddings community detection algorithm that detects and blocks communities of malicious nodes. The effectiveness of Trust2Vec is validated through large-scale IoT network simulation. The results show that Trust2Vec can achieve up to 94% mitigation rate in various network settings.","2327-4662","","10.1109/JIOT.2022.3201772","Insight Centre for Data Analytics funded by Science Foundation Ireland(grant numbers:12/RC/2289 P2); CONSUS Project funded by the SFI Strategic Partnerships Programme(grant numbers:16/SPP/3296); Origin Enterprises Plc; National Natural Science Foundation of China(grant numbers:61872038); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9866814","Bad-mouthing;device trust;Internet of Things (IoT);network embedding;self-promoting;trust management","Internet of Things;Trust management;Performance evaluation;Computational modeling;Reliability;Data collection;Smart cities","","22","","33","IEEE","25 Aug 2022","","","IEEE","IEEE Journals"
"A MEC-Based Architecture to Secure IoT Applications using Federated Deep Learning","Z. A. El Houda; B. Brik; A. Ksentini; L. Khoukhi","L@bISEN, France; University of Bourgogne Franche-Comté, France; EURECOM, France; Normandie Univ, France","IEEE Internet of Things Magazine","14 Mar 2023","2023","6","1","60","63","Internet of Things (IoT) is a promising paradigm that is considered as major enabler of smart cities. However, with the emergence of IoT botnets, the number of unsecured IoT devices is increasing rapidly. This can give attackers more advanced tools to carry out large scale damaging IoT attacks. Advanced Machine Learning (ML) techniques can help enhance the effectiveness of conventional intrusion detection systems (IDS) to accurately detect IoT attacks. But there are ongoing challenges with centralized learning as well as the lack of up-to-date/ new datasets, covering key IoT attacks. In this context, we design a novel Multiple access Edge Computing (MEC) architecture to secure IoT applications with Federated Learning (FL). In particular, we propose a promising eDge-based architEcTure to sEcure IoT appliCations using FL, called DETECT. DETECT allows multiple MEC domains to collaboratively and securely mitigate IoT attacks, while ensuring the privacy of the MEC collaborator and consequently the privacy of IoT devices. The in-depth experiments results with well- known IoT attack using, the Edge-IIoTset and NSL-KDD datastets, show the significant accuracy of DETECT in terms of Accuracy (86 percent in NSL-KDD and 99 percent in Edge-IIoTset) and F1 score (87 percent in NSL-KDD and 99 percent in Edge-IIoTset).","2576-3199","","10.1109/IOTM.001.2100238","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10070397","","Measurement;Deep learning;Privacy;Smart cities;Federated learning;Image edge detection;Intrusion detection","","8","","15","IEEE","14 Mar 2023","","","IEEE","IEEE Magazines"
"Analysis and Configuration of IoT Sensors in Smart Structure by Employing QR Code Generator","K. Agarwal; G. Nagarkoti; V. Chauhan; Papita","IEEE, New Delhi, India; Department of Computer Science, Greater Noida Institute of Technology, Greater Noida, India; Department of Computer Science, G L Bajaj Institute of Management, Greater Noida, India; Department of Computer Science, G L Bajaj Institute of Management, Greater Noida, India","2023 6th International Conference on Contemporary Computing and Informatics (IC3I)","26 Jan 2024","2023","6","","2467","2471","The Internet of Things (IoT) has transformed many different industries, but its effects on building automation stand out in particular. Building IoT sensor networks are essential for maximizing energy use, boosting security, and raising tenant comfort. Large-scale smart structures, however, can make manual configuration of a large number of IoT devices time-consuming and error-prone. In this study, we introduce a novel architecture based on QR codes that is intended to speed up the autoconfiguration of IoT sensor networks in smart structures. The suggested framework intends to ensure resilience and security while streamlining the deployment, configuration, and maintenance of IoT devices. Through study and actual analysis, we assess the framework's performance and show its usefulness and potential for real-world applications. Overall, our suggestion offers an automatic and economical energy management system that offers a sustainable approach to energy conservation and reduced carbon emissions and can be used in both newly constructed smart structures and existing ones.","","979-8-3503-0448-0","10.1109/IC3I59117.2023.10397813","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10397813","Smart structure;Energy management systems;Internet of Things;Auto-configuration;QR codes;two-dimensional matrix barcode","Wireless communication;Wireless sensor networks;Smart buildings;QR codes;Internet of Things;Intelligent structures;Security","","","","10","IEEE","26 Jan 2024","","","IEEE","IEEE Conferences"
"A Comprehensive Analysis on the Adoption of IoT with Logistics and Supply Chain Management","B. Aljabhan","Ports and Maritime Transportation Department, Faculty of Maritime Studies, King Abdul Aziz University, Jeddah, Saudi Arabia","2022 Second International Conference on Computer Science, Engineering and Applications (ICCSEA)","7 Nov 2022","2022","","","1","6","Adoption of Internet of Things (IoT) in logistics and supply chain management is one of the complicated process, because the different types of industries have various expectations in accepting the new technologies. According to the recent reports, it is analyzed that most of industrial organizations increasingly deployed the IoT technology for improving their supply chain management. But, the expectations of both small and large scale industries are differ in adopting the new technologies like Radio Frequency Identification (RFID) and Electronic Product Code (EPC) global network. Hence, this work intends to analyze the major impacts of adopting the IoT technology with the supply chain management systems of organizations. For this purpose, a comprehensive survey is conducted in this work, where the factors influencing the supply chain management are examined. Moreover, the challenges and issues faced by the conventional works in adopting the IoT technology have been discussed with its possible solutions. In addition to that, the conceptual framework is presented for analyzing the development of IoT based logistics and supply chain management system. From this study, it is observed that the IoT is identified as one of the most suitable option for resolving the complex business management problems with innovative solutions. Also, it supports for improving the supply chain of organization with increased profit returns and customer satisfaction.","","978-1-6654-5834-4","10.1109/ICCSEA54677.2022.9936196","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9936196","Logistics;Supply Chain Management;Internet of Things (IoT);Product Manufacturing;Data Communication;Transportation.","Industries;Supply chain management;Costs;Supply chains;Organizations;Quality of service;Internet of Things","","2","","40","IEEE","7 Nov 2022","","","IEEE","IEEE Conferences"
"A Software-Defined Networking based Simulation Framework for Internet of Space Things","A. A. Shah","School of Computing Sciences, University of Glasgow, UK","2023 IEEE 97th Vehicular Technology Conference (VTC2023-Spring)","14 Aug 2023","2023","","","1","4","The last decade witnessed proliferating in the adaptation of smart devices, sensors, autonomous vehicles, drones, and robots etc for daily human use under the umbrella of Internet of Things (IoT) paradigm. The next wave of IoT devices will demand for increased connectivity with minimum delay and higher availability to ensure quality of service along with energy efficiency. The current IoT deployments are carried out using 4G/5G/wireless and optical transport networks. Remote areas, such as animal farms, agricultural land, forests, seas, and so on are facing challenges with the IoT deployments due to poor or no network connectivity. Satellite communications aim to resolve these issues but due to huge amount of costs it is an ambitious task. Moreover, the existing satellites won’t be able to serve the huge amount of IoT deployments in near future. In this context, Internet of Space Things (IoST) emerged as a game changer that allows deployment of small sized Satellites in the lower orbit around the earth which would enable the IoT deployments to directly communicate through space with enhanced quality of service and would eventually resolve the current challenges faced in the remote areas. This paper presents an SDN-based simulation framework for orchestrating large scale satellites using a multi-level of SDN controller and a centeralized orchestrator.","2577-2465","979-8-3503-1114-3","10.1109/VTC2023-Spring57618.2023.10200384","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10200384","Internet of Space Things;Software-Defined Networks;Internet of Things;CubeSats","Space vehicles;Vehicular and wireless technologies;Satellites;Quality of service;Aerospace electronics;User experience;Internet of Things","","","","20","IEEE","14 Aug 2023","","","IEEE","IEEE Conferences"
"Mathematics and Security","",,"2021 International Conference on Advanced Computer Applications (ACA)","3 Dec 2021","2021","","","i","i","Summary form only given. The complete presentation was not made available for publication as part of the conference proceedings. In the field of cryptography, quantum computing is expected to be able to successfully attack most of the currently used cryptographic algorithms, especially public-key designs, so the academic community has been working on quantum-resistant primitives and algorithms. However, practical computers that can be used for breaking highly secure systems are not expected to be available in the near term. This means that, in the next few years, prequantum and quantum algorithms will coexist, and in the meantime, new threats against existing security algorithms will appear, which affects deployments in contexts as different as blockchain technology, electronic voting, or implantable medical devices. Experience in the mathematics of security provides a wide range of exciting career opportunities for mathematics graduates. Security expertise is required by a wide variety of government and business sectors, including retail, airlines, telecommunications, defense, utilities, manufacturing, software, and financial companies. Another consolidated trend in today's technology is IoT, i.e., the Internet of Things. Systems, where computing devices are interrelated and can transfer data between themselves over a network, are permeating all sectors of our society; thus, securing those devices is paramount. Given the limited resources available in some cases to IoT devices, cryptographic implementations in this context must be powerful but at the same time feasible, which provides a challenge for security designers. The curriculums have been developed to include a broad variety of units, from strands of pure mathematics and data science to computer science and statistics. One will work at scale on large datasets to implement real-world security solutions, gaining a qualification and experience in a field that has a recognized skills shortage.","","978-1-6654-3503-1","10.1109/ACA52198.2021.9626812","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9626812","","Mathematics;Internet of Things;Algebra;Data science;Computer security;Computer applications;Telecommunications","","","","","IEEE","3 Dec 2021","","","IEEE","IEEE Conferences"
"A Systematic Literature Review on IoT-based Smart Grid","N. Sartika; Y. Sukmana; M. R. Effendi; I. Rusliana; K. Khomisah; Y. Yuningsih","Electrical Engineering Department, Universitas Islam Negeri Sunan Gunung Djati, Bandung, Indonesia; School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia; Electrical Engineering Department, Universitas Islam Negeri Sunan Gunung Djati, Bandung, Indonesia; Faculty of Ushuluddin, Universitas Islam Negeri Sunan Gunung Djati, Bandung, Indonesia; Faculty of Adab and Humanities, Universitas Islam Negeri Sunan Gunung Djati, Bandung, Indonesia; Faculty of Da'wah and Communication Department, Universitas Islam Negeri Sunan Gunung Djati, Bandung, Indonesia","2021 7th International Conference on Wireless and Telematics (ICWT)","18 Jan 2022","2021","","","1","5","The largest potential of IoT implementation is in the smart grid. IoT technology is critical to the smart grid because it allows for large-scale communication between different components of the smart grid on a two-way basis. The Internet of Things can be used in all aspects of the smart grid by accessing real-time data from the power system and then monitoring and analyzing it. A Systematic Literature Review was used in this study to better understand the benefits, architectures, applications, and challenges of IoT-based smart grids. Several steps are taken to produce related articles. There are thirty-four research articles that related to research questions, then reviewed. It can be concluded that the most benefits of implementing IoT in smart grid will be improved reliability, efficiency, and stability of power systems. The major architectures of IoT-based smart grids consists of three layers which are perception, network, and application layers. IoT-based smart grid application can be implemented in every aspect of the power system, right from power generation to end consumer. Some challenges present when IoT is integrated into the smart grid, privacy and security issues become most challenging.","","978-1-6654-4402-6","10.1109/ICWT52862.2021.9678415","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9678415","systematic literature review;IoT;smart grid","Privacy;Systematics;Bibliographies;Stability criteria;Power system stability;Smart grids;Power system reliability","","","","35","IEEE","18 Jan 2022","","","IEEE","IEEE Conferences"
"FLITC: A Novel Federated Learning-Based Method for IoT Traffic Classification","M. Abbasi; A. Taherkordi; A. Shahraki","University of Salamanca, Salamanca, Spain; NTNU, Trondheim, Norway; Fraunhofer IIS, Erlangen, Germany","2022 IEEE International Conference on Smart Computing (SMARTCOMP)","14 Jul 2022","2022","","","206","212","Internet of Things (IoT) systems are rightly receiving considerable interest for many real-world applications, from in-body networks to satellite networks. Such a massive-scale system generates a considerable amount of traffic data, making IoT systems a distributed data source generator. For many reasons, such as the functionality of IoT applications and Quality of Service (QoS) provisioning, classifying these traffic data is of high importance. In the last few years, widespread interest has been expressed in applying Machine Learning (ML)-based techniques for Network Traffic Classification (NTC) tasks. However, the traditional centralized learning-based traffic classifiers pose serious challenges, especially in IoT networks. The centralized ML techniques call for collecting a large amount of data from various IoT devices, which in turn introduces data governance and privacy challenges. Furthermore, in the centralized ML, training data need to be transferred to the Cloud, which increases communication cost and latency. To address these problems, we propose Federated Learning (FL) Internet of Things (IoT) Traffic Classifier (FLITC)-a Federated Learning (FL)-based IoT traffic classification method which is based on the Multi-Layer Perception (MLP) neural network and holds the local data unimpaired on IoT devices by sending only the learned parameters to the aggregation server. Our experimental results show that the FLITC beats centralized learning in preserving the privacy of sensitive data and offers a better degree of accuracy at the cost of a longer training time.","2693-8340","978-1-6654-8152-6","10.1109/SMARTCOMP55677.2022.00055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9821087","Internet of Things;Federated Learning;Traffic Classification;Privacy;Network Traffic Analysis","Training;Data privacy;Costs;Soft sensors;Training data;Quality of service;Telecommunication traffic","","3","","21","IEEE","14 Jul 2022","","","IEEE","IEEE Conferences"
"Delegated Anonymous Credentials With Revocation Capability for IoT Service Chains (DANCIS)","S. K. Pinjala; S. S. Vivek; K. M. Sivalingam","Department of Computer Science and Engineering, Indian Institute of Technology Madras, Chennai, India; Indian Institute of Technology Madras, Chennai, India; Department of Computer Science and Engineering, Indian Institute of Technology Madras, Chennai, India","IEEE Internet of Things Journal","21 Feb 2022","2022","9","5","3729","3742","This article deals with providing privacy-preserving access control in Internet of Things (IoT) systems. Here, a user/IoT device requests access to services provided by other IoT devices and multiple requests are combined to a request-specific service chain. An anonymous delegated credential-based system architecture is proposed, where the requester’s identity is not exposed to the services. The article presents the proposed architecture’s various components including the security aspects. Various options for implementing the architecture on resource-full and resource-constrained services are presented. A prototype of the proposed architecture is then implemented using Linux-based containers to emulate the services. Two representative systems, namely, a small-scale home automation system using a short service chain and a large-scale industrial automation system using a long service chain are considered. Timing measurements from the implementation are presented to demonstrate that the architecture is feasible and can be adapted for practical use in large-scale IoT systems.","2327-4662","","10.1109/JIOT.2021.3099089","Mid-Career Institute Research and Development Award (IRDA) from IIT Madras (2017–2020); DST Grant from the Government of India (2017–2020)(grant numbers:EMR/2016/003016); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9493760","Anonymous credentials;credential delegation;credential revocation;Internet of Things (IoT);IoT service chain;security and privacy","Internet of Things;Privacy;Security;Monitoring;Temperature sensors;Smart manufacturing;Computer architecture","","2","","30","IEEE","26 Jul 2021","","","IEEE","IEEE Journals"
"A Floating Calculation Revamp For the Ethereum Blockchain-Based IoT Systems","C. Yiyang; K. Takashio","Graduate School of Media and Governance, Keio University, Fujisawa, Japan; Graduate School of Media and Governance, Keio University, Fujisawa, Japan","2022 IEEE 8th World Forum on Internet of Things (WF-IoT)","22 Jun 2023","2022","","","1","6","It has become an industry consensus to integrate blockchain with other technologies to create a complete solution. Among the combinations, the Internet of Things can collect data on a large scale at a low cost, and the blockchain can trust data on a large scale at a low cost. With the development of Internet of Things(IoT) technology, the trend of networking of furniture is more apparent. The following security issues have also received more and more attention. Blockchain technology and smart contracts are widely regarded as a solution that can solve the networking of large scale terminals. But at the same time, due to the features of the blockchain, the floating calculation of smart contracts is unavoidable. This paper proposes a calculation revamp for the Ethereum-based smart contracts. Firstly, we verified the behaviour of our smart contract on Remix. Secondly, we implemented the smart contract on a blockchain-based IoT system. We confirmed the availability and reliability of our revamped smart contract.","","978-1-6654-9153-2","10.1109/WF-IoT54382.2022.10152068","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10152068","blockchain;smart contract;IoT;floating-calculation;smart home","Industries;Costs;Smart contracts;Market research;Blockchains;Internet of Things;Security","","1","","8","IEEE","22 Jun 2023","","","IEEE","IEEE Conferences"
"The Safety Management System Using Q-Learning Algorithm in IoT Environment","S. A. Dolas; S. A. Jain; A. N. Bhute","MIT Academy of Engineering, Alandi, Savitribai Phule Pune University; MIT Academy of Engineering, Alandi, Savitribai Phule Pune University; MIT Academy of Engineering, Alandi, Savitribai Phule Pune University","2021 7th International Conference on Advanced Computing and Communication Systems (ICACCS)","3 Jun 2021","2021","1","","1024","1028","The Industrial Internet of Things (IIoT) is the framework in which a large number of devices are connected and synchronized for handling different processes and machinery in industry, to remove the risk of human error and improve safety. Many IoT-based worker's safety systems contain a network of different sensors and assessable mobile information center. Such as, workers wear sensors that monitor the heart rate, activity, toxic gases, and other factors that are affecting worker's safety. The initial investment for such automation is very high and it is not affordable for small industries therefore, mostly high-level manufacturing industries install automation in the workplace. The purpose of this paper is to design a safety management architecture for workers in the small-scale candy manufacturing industry using IoT and Q-learning mechanism. Also, to provide the benefits of automation at a low-cost. The system consists of gas, temperature, humidity, and flame sensor. ADC is used to convert recorded sensor values from analog to digital form and these converted values are received by the raspberry pi board and simultaneously stored in a database. The Q-learning approach is used to identify crucial situations using database values and execute the output appliances like a fan and buzzer.","2575-7288","978-1-6654-0521-8","10.1109/ICACCS51430.2021.9441931","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9441931","Worker’s Safety management;industrial internet of things (IIoT);sensors;q-learning algorithm","Temperature sensors;Manufacturing industries;Temperature measurement;Automation;Databases;Safety management;Sensor systems","","","","12","IEEE","3 Jun 2021","","","IEEE","IEEE Conferences"
"Secure Smart Healthcare Surveillance Framework Using Fuzzy C-Means Clustering with Effective Ant Colony Optimization in Internet of Things","J. Karuppaiah; C. Aarthi; Girirajan; M. Jananai; P. B. D.","Biomedical Engineering Kalaigar karunanidhi Institute of Technology, Coimbatore, India; Sengunthar Engineering College, Thiruchengode, India; Department of ECE, SR University, Warangal, India; Computer science and Engineering, KPR Instiute of Engineering and Technology, Coimbatore, India; Department of Electronics and Communication Engineering, Nitte Meenakshi Institute of Technology, Bengaluru, India","2022 International Conference on Knowledge Engineering and Communication Systems (ICKES)","17 Mar 2023","2022","","","1","5","The emergence of IoT device networks is not limited to a specific industry, application, or environment; instead, they are assisting in the development of the country in a number of sectors, including industries, cities, agriculture, and defense. But IoT device networks have some restrictions, including those related to bandwidth, energy resources, and other resources, as well as restrictions based on the environment. The fast growth of the Internet of Things (IoT) has brought to light significant privacy protection problems. This has a tremendous impact on the large-scale IoT applications. In this study, a ground-breaking IOT computing platform for secure and knowledgeable healthcare monitoring services is introduced. Within an IoT architecture, fully homomorphism encryption (FHE), which protects data privacy, is handled and kept. For the proposed IoT framework, a distributed method for clustering-based approaches is created with the scalability to gather and independently analyse massive amounts of hetrogeneous data in distributed IoT devices before it is transferred to the cloud. In this study, the Cluster Heads (CHs) were chosen from the available IoT devices using a brand-new Efficient Ant Colony Optimization (EACO) technique. For healthcare surveillance, fuzzy C-Means clustering (FCMC) is employed. FCM allows us to recognise regular (typical) bio signal patterns.","","978-1-6654-5637-1","10.1109/ICKECS56523.2022.10060099","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10060099","Efficient Ant Colony Optimization;Fully Homomorphism Encryption;Internet of Things;Fuzzy C-Means clustering","Cloud computing;Ant colony optimization;Data privacy;Smart cities;Surveillance;Wireless networks;Scalability","","","","10","IEEE","17 Mar 2023","","","IEEE","IEEE Conferences"
"Large-Scale IoT Network Offloading to Cloud and Fog Computing: a Fluid Limit Model","G. Belcredi; L. Aspirot; P. Monzón; P. Belzarena","Facultad de Ingeniería, Universidad de la República; Facultad de Ciencias Económicas y de Administración, Universidad de la República; Facultad de Ingeniería, Universidad de la República; Facultad de Ingeniería, Universidad de la República","2021 IEEE URUCON","27 Dec 2021","2021","","","377","381","This paper models a large-scale Internet of Things (IoT) network as a stochastic system that offloads computing towards Fog and Cloud via a shared access medium. The analysis of this large IoT system by stochastic methods is a challenging problem, if possible, to solve. This paper proposes the approximation of the dynamic of the IoT network via the fluid limit of the stochastic process. This method allows the analysis of the large-scale system and also allows finding the equilibrium point of the system. The results obtained with stochastic simulations show that the fluid model is an excellent approximation of the stochastic system.","","978-1-6654-2443-1","10.1109/URUCON53396.2021.9647124","ANII(grant numbers:POS-NAC-2018-1-151203); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9647124","Edge Computing;Fog Computing;Cloud Computing;Computation Offloading;Markov Process;Fluid Limit;Switched Systems;Wireless Communications;Internet of Things","Cloud computing;Computational modeling;Stochastic systems;Fluid dynamics;Stochastic processes;Large-scale systems;Internet of Things","","1","","12","IEEE","27 Dec 2021","","","IEEE","IEEE Conferences"
"Towards a Proactive Lightweight Serverless Edge Cloud for Internet-of-Things Applications","I. -C. Wang; S. Qi; E. Liri; K. K. Ramakrishnan","University of California, Riverside; University of California, Riverside; University of California, Riverside; University of California, Riverside","2021 IEEE International Conference on Networking, Architecture and Storage (NAS)","22 Nov 2021","2021","","","1","4","Edge cloud solutions that bring the cloud closer to the sensors can be very useful to meet the low latency requirements of many Internet-of-Things (IoT) applications. However, IoT traffic can also be intermittent, so running applications constantly can be wasteful. Therefore, having a serverless edge cloud that is responsive and provides low-latency features is a very attractive option for a resource and cost-efficient IoT application environment.In this paper, we discuss the key components needed to support IoT traffic in the serverless edge cloud and identify the critical challenges that make it difficult to directly use existing serverless solutions such as Knative, for IoT applications. These include overhead from heavyweight components for managing the overall system and software adaptors for communication protocol translation used in off-the-shelf serverless platforms that are designed for large-scale centralized clouds. The latency imposed by ‘cold start’ is a further deterrent.To address these challenges we redesign several components of the Knative serverless framework. We use a streamlined protocol adaptor to leverage the MQTT IoT protocol in our serverless framework for IoT event processing. We also create a novel, event-driven proxy based on the extended Berkeley Packet Filter (eBPF), to replace the regular heavyweight Knative queue proxy. Our preliminary experimental results show that the event-driven proxy is a suitable replacement for the queue proxy in an IoT serverless environment and results in lower CPU usage and a higher request throughput.","","978-1-7281-7744-1","10.1109/NAS51552.2021.9605384","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9605384","Internet-of-Things;serverless;edge cloud","Energy consumption;Protocols;Conferences;Computer architecture;Throughput;Software;Sensors","","3","","17","IEEE","22 Nov 2021","","","IEEE","IEEE Conferences"
"Power Evaluation of IOT Application Layer Protocols","A. Shahrokhi; M. Ahmadi","Computer and Information Technology Department, Razi University, Kermanshah, Iran; Computer and Information Technology Department, Razi University, Kermanshah, Iran","2023 7th International Conference on Internet of Things and Applications (IoT)","22 Dec 2023","2023","","","1","7","The Internet of Things has affected all aspects of daily life, and the number of IoT devices is increasing day by day. According to forecasts, the number of Internet of Things devices will reach one trillion devices by 2035. The increase in the number of devices connected to the Internet will cause various concerns. One of the most important concerns is the energy and power consumption of these devices. Although Internet of Things modules are low in energy consumption, their widespread and large-scale use has made the issue of power consumption become the most important challenge in this field. For this reason, it is necessary to use communication protocols that, in addition to establishing efficient communication, impose minimal power consumption on the network. In this paper, application layer protocols such as MQTT, MQTT-SN, CoAP, and HTTP are simulated using the tools available in the Contiki operating system, including COOJA and Powertrace, and they are evaluated and compared with each other in terms of power consumption. According to the simulations performed by the mentioned tools, the MQTT-SN protocol was the least consuming protocol in terms of power consumption. After that, the CoAP protocol is placed, and with a slight difference, the MQTT protocol consumes more than MQTT-SN. Finally, the HTTP protocol consumes the most power, which makes it unsuitable for communication in the Internet of Things","","979-8-3503-6941-0","10.1109/IoT60973.2023.10365351","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10365351","Internet of Things;MQTT;Application layer protocols;COAP","Performance evaluation;Energy consumption;Protocols;Power demand;Operating systems;Batteries;Internet of Things","","","","12","IEEE","22 Dec 2023","","","IEEE","IEEE Conferences"
"Edge Computing for IoT Security: Integrating Machine Learning with Key Agreement","T. Shen; L. Ding; J. Sun; C. Jing; F. Guo; C. Wu","School of information science and engineering, Linyi University, Linyi, China; School of information science and engineering, Linyi University, Linyi, China; School of information science and engineering, Linyi University, Linyi, China; School of information science and engineering, Linyi University, Linyi, China; School of information science and engineering, Linyi University, Linyi, China; School of information science and engineering, Linyi University, Linyi, China","2023 3rd International Conference on Consumer Electronics and Computer Engineering (ICCECE)","2 Jun 2023","2023","","","474","483","The Internet of Things (IoT) is one of the most widely used technologies today, the number of IoT connections growing by 18% to 14.4 Billion active endpoints globally. Thus, with such a large scale IoT application, security becomes the focus. The issue of intrusion and interception has been a controversial and much disputed subject within the field of IoT security. The main limitation of IoT security, however, is a single security technology cannot ensure security of the IoT system. The Internet of Things requires diverse technologies applied at different layers to work together to ensure security. Based on these problems, proposed a security solution with integrity is necessary. Edge computing is a great way to solve security problems for resource-constrained devices. This paper proposes a machine learning and cryptography combined IoT security scheme at edge computing, achieves monitoring and detection abnormal behaviors of IoT system and automatically responds at an early stage. Designed a lightweight key management scheme without third-party involvement. The combination of active detection and passive protection for IoT security is achieved. Meanwhile, data for this study were collected using Edge-IIoTset dataset for the prediction of IoT security threats in edge computing networks. In this paper, experiments offers some important insights into the model selection for the prediction of time series data. The models selected include Support Vector Machine(SVM), K-Nearest Neighbor(KNN), and Long Short-Term Memory(LSTM) models. The significance of the comparison of several models is to assess their accuracy in detecting IoT communication data. To compares the performance of models, the following performance evaluation parameters were used: Precision, Recall and F1-Score. This study has identified LSTM has better precision in time series data such as communication data, 10% more precision than the other models used in this paper.","","979-8-3503-3157-8","10.1109/ICCECE58074.2023.10135211","National Natural Science Foundation of China(grant numbers:61901206); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10135211","IoT Security;Edge Computing;Time Series Data;Long short-term memory;Intrusion detection;Key Agreement","Adaptation models;Computational modeling;Image edge detection;Intrusion detection;Machine learning;Data models;Mathematical models","","1","","41","IEEE","2 Jun 2023","","","IEEE","IEEE Conferences"
"Design of Multifunctional Seedbed Planting Robot Based on MobileNetV2-SSD","X. Li; X. Du; B. Chen; L. Gong; C. Liu; Q. Zhou; L. He","Institute of Mechatronics & Logistic Equipment, Shanghai Jiao Tong University, Shanghai, China; Institute of Mechatronics & Logistic Equipment, Shanghai Jiao Tong University, Shanghai, China; Institute of Mechatronics & Logistic Equipment, Shanghai Jiao Tong University, Shanghai, China; Institute of Mechatronics & Logistic Equipment, Shanghai Jiao Tong University, Shanghai, China; Institute of Mechatronics & Logistic Equipment, Shanghai Jiao Tong University, Shanghai, China; Institute of Mechatronics & Logistic Equipment, Shanghai Jiao Tong University, Shanghai, China; Institute of Mechatronics & Logistic Equipment, Shanghai Jiao Tong University, Shanghai, China","2021 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA)","2 Aug 2021","2021","","","272","278","As a new generation of intelligent agricultural machinery, agricultural robots have become a research hotspot in agricultural equipment technology. Deep learning and Internet of Things technologies are gradually being applied to agricultural robots to optimize the production process and improve production efficiency. Currently, most of the execution systems and sensors of agricultural robots are installed on movable platforms. This arrangement makes the function of the robot relatively single, the manufacturing cost is high, and it is difficult to promote. For large-scale production facilities, there is currently a lack of modular, intelligent, and networked robotic production equipment. In response to this problem, this paper designs a modularized CNC seedbed planting management robot. For large-scale production facilities, there is currently a lack of modular, intelligent, and networked robots. In response to this problem, this paper designs a seedbed planting management robot with a structure similar to a gantry milling machine. The robot realizes a variety of basic functions such as seeding, irrigation, weeding, and light supplementation, and realizes the Internet of Things and autonomous operation functions based on the embedded system. The robot realizes basic functions such as seeding, irrigation, weeding, and light supplementation, and realizes the Internet of Things and autonomous operation functions based on the embedded system. In terms of weed recognition algorithm, through the application of MobileNetV2-SSD network and color threshold segmentation algorithm, the accuracy of robot weed recognition reaches 94%. The effectiveness of the robot as a production unit of a large- scale agricultural production facility is proved, and an open- source design scheme is given at the end of the article.","","978-1-6654-1867-6","10.1109/ICAICA52286.2021.9498205","Royal Society; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9498205","multifunctional;modularity;deep learning;machine vision;internet of things","Training;Irrigation;Agricultural robots;Embedded systems;Neural networks;Robot sensing systems;Production facilities","","2","","27","IEEE","2 Aug 2021","","","IEEE","IEEE Conferences"
"Trust-driven Distributed Self-collaborative Security Architecture of IoT Based on Blockchain and Smart Contracts","H. Li; S. Xu; S. Li; G. Sun; X. Zhang; L. Yan","School of Information and Technology, Southwest Jiaotong University, Chengdu, China; Department of R&D, AgilePhotonics Technology Co., Ltd, Chengdu, China; School of Information and Technology, Southwest Jiaotong University, Chengdu, China; School of Information and Technology, Southwest Jiaotong University, Chengdu, China; School of Information and Technology, Southwest Jiaotong University, Chengdu, China; School of Information and Technology, Southwest Jiaotong University, Chengdu, China","2020 IEEE 92nd Vehicular Technology Conference (VTC2020-Fall)","15 Feb 2021","2020","","","1","5","As Internet of Things (IoT) technology is growing fast, it is clearly forseen that the number of IoT devices and the scale of connections will be further expanded. IoT is capable of taking advantage of the existing network infrastructure effectively, so as to achieve data sharing between devices. However, the large scale and complexity of the network structure will bring potential security risks to IoT system. The traditional access control model is more complex and centralized. This paper aims to build a trust-driven distributed self-collaborative security architecture of IoT based on blockchain and smart contracts, which could overcome the single-point failure problem of centralized entities. Implementation of the security architecture shows that it still possesses characteristics including scalability, lightweight, and fine granularity, while the secure access control preserves the privacy of IoT devices.","2577-2465","978-1-7281-9484-4","10.1109/VTC2020-Fall49728.2020.9348760","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9348760","Blockchain;Internet of Things;Access Control;Smart Contrats;Decentralized;Security Architecture","Access control;Privacy;Vehicular and wireless technologies;Smart contracts;Blockchain;Throughput;Internet of Things","","1","","11","IEEE","15 Feb 2021","","","IEEE","IEEE Conferences"
"IoT Based Smart Agriculture Monitoring System Using Renewable Energy Sources","P. Palniladevi; T. Sabapathi; D. A. Kanth; B. P. Kumar","Department of ECE, Mepco Schlenk Engineering college, Sivakasi, India; Department of ECE, Mepco Schlenk Engineering college, Sivakasi, India; Department of ECE, Mepco Schlenk Engineering college, Sivakasi, India; Department of ECE, Mepco Schlenk Engineering college, Sivakasi, India","2023 2nd International Conference on Vision Towards Emerging Trends in Communication and Networking Technologies (ViTECoN)","26 Jun 2023","2023","","","1","6","A revolutionary strategy for enhancing agricultural practices and reducing agriculture's carbon footprint is an internet of things (IoT)-based smart agricultural observation system driven by energy from renewable sources. This system uses energy from renewable sources such as solar power along with sensors, automation, and data analytics to monitor and improve the growth of crops while minimizing resource loss. The system collects data on soil moisture, temperature, humidity, and other environmental parameters using sensors, which are then sent to a centralized platform for analysis. Based on the data analysis, the system can automate irrigation, fertilization, and pest control, reducing the need for manual intervention and the utilization of energy from non-renewable sources. The integration of energy from renewable sources into the internet of things (IoT)-based smart agricultural observationsystem increases its sustainability and cost-effectiveness. Using solar or wind power to power the system reducesreliance on traditional power sources, resulting in lower energy costs and lower carbon emissions. Because of its scalability, the system is also suitable for small-scale farmers who may not have access to conventional power sources. In summary, an IoT-based smart agriculture monitoring systempowered by solar energy is a promising approach to improving agricultural practices while promoting sustainability. This system has the potential to revolutionize agriculture by increasing crop yields, reducing resource waste, and promoting environmentally friendly practices.","","979-8-3503-4798-2","10.1109/ViTECoN58111.2023.10157010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10157010","IoT;agriculture;renewable source;sensors;environmental parameters","Temperature sensors;Smart agriculture;Renewable energy sources;Data analysis;Crops;Wind power generation;Sensor systems","","2","","18","IEEE","26 Jun 2023","","","IEEE","IEEE Conferences"
"Edge Node Data Replica Management Method For Distribution Internet Of Things","R. Liu; S. Feng; S. Sun; M. Liu","NARI Group Co., Ltd. (State Grid Electric Power Research Institute), Nanjing, China; NARI Group Co., Ltd. (State Grid Electric Power Research Institute), Nanjing, China; NARI Group Co., Ltd. (State Grid Electric Power Research Institute), Nanjing, China; NARI Group Co., Ltd. (State Grid Electric Power Research Institute), Nanjing, China","2020 4th International Conference on HVDC (HVDC)","29 Dec 2020","2020","","","830","832","Under the background of distribution Internet of things (D-IoT), the traditional cloud computing method is difficult to adapt to larger scale data backup, and there is a high demand for power data center computing capacity. Firstly, the data processing architecture of distribution Internet of things based on edge computing is constructed. Then, under this architecture, the management method of edge computing data copy is designed to realize the effective backup of distribution IoT data. Simulation results show that for the same data set, the proposed replica management method combining local management and cluster management has a shorter average processing time than the traditional data replica management method, and can effectively improve the processing performance of massive D-IoT data.","","978-1-7281-7593-5","10.1109/HVDC50696.2020.9292819","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9292819","Power Internet of Things(P-IoT);Edge Computing;Data replica management;Big Data","Peer-to-peer computing;Edge computing;Internet of Things;Power systems;Cloud computing;Data centers;Time factors","","2","","8","IEEE","29 Dec 2020","","","IEEE","IEEE Conferences"
"Simulation framework for performance analysis in multi-tier IoT Systems","H. Turkmanović; I. Popović; Z. Čiča; D. Drajić","Department of electronics, School of Electrical engineering, University of Belgrade, Belgrade, Serbia; Department of electronics, School of Electrical engineering, University of Belgrade, Belgrade, Serbia; Departmant of Telecommunications, School of electrical engineering, University of Belgrade, Belgrade, Serbia; Departmant of Telecommunications, School of electrical engineering, University of Belgrade, Belgrade, Serbia","2021 29th Telecommunications Forum (TELFOR)","29 Dec 2021","2021","","","1","4","The accelerated development of technologies, especially in the field of telecommunications has enabled the easier integration of embedded devices within various IoT applications. Modern IoT applications involve the integration of multiple embedded devices that collect and process data but also communicate with other tiers of the IoT system architecture. Designing multi-tier IoT system, even in the case of architecture involving a small number of intelligent embedded devices, can be a very demanding process especially when it is necessary to meet the strict requirements of IoT application. In this paper, an open-source simulation framework that allows the performance analysis of an arbitrary multi-tiered IoT system is presented and evaluated. Framework enables insight into the data availability within each tier of IoT system architecture which allows designers to analyze the performance of IoT application. Developed simulation framework enables analyzes of different performance parameters such as real-time performance, energy consumption, architecture scalability, and others. The example of a large-scale IoT application is used to demonstrate the potential of the developed open-source simulator when it is necessary to quantify scalability of the selected architecture of the IoT system.","","978-1-6654-2585-8","10.1109/TELFOR52709.2021.9653170","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9653170","IoT;Simulation framework;Large Scale;Scalability","Analytical models;Energy consumption;Scalability;Systems architecture;User interfaces;Real-time systems;Telecommunications","","2","","22","IEEE","29 Dec 2021","","","IEEE","IEEE Conferences"
"Secure and Privacy-preserving Data-sharing Framework based on Blockchain Technology for Al-Najaf/Iraq Oil Refinery","S. M. Umran; S. Lu; Z. A. Abduljabbar; Z. Lu; B. Feng; L. Zheng","Hubei Key Laboratory of Distributed System Security Hubei Engineering Research Center on Big Data Security School of Cyber Science and Engineering, Huazhong University of Science and Technology, Wuhan, China; Hubei Key Laboratory of Distributed System Security Hubei Engineering Research Center on Big Data Security School of Cyber Science and Engineering, Huazhong University of Science and Technology, Wuhan, China; College of Education for Pure Sciences, University of Basrah; School of Cyber Science and Engineering, Huazhong University of Science and Technology, Wuhan, China; Wuhan Huazhong Numerical Control Co., Ltd, Industrial Internet Research Institute, Wuhan, China; College of Computer Science, South-Central University for Nationalities, Wuhan, China","2022 IEEE Smartworld, Ubiquitous Intelligence & Computing, Scalable Computing & Communications, Digital Twin, Privacy Computing, Metaverse, Autonomous & Trusted Vehicles (SmartWorld/UIC/ScalCom/DigitalTwin/PriComp/Meta)","27 Jul 2023","2022","","","2284","2292","The Industrial Internet of Things or Industry 4.0 efficiently enhances the manufacturing process in terms of raising productivity, system performance, cost reduction, and building large-scale systems. It enables the connection of numerous heterogeneous devices and sensors into the internet network through the utilization of revolutionary techniques that transfer the manufacturing paradigm to intelligent processes. The traditional industrial internet of things adopts centralized architectures and complex encryption algorithms that suffer from several cyber-security threats and lead to data leakage, privacy disclosure, and high computational and communicational costs. In our work, we proposed a decentralized, efficient, low-power, scalable, secure, privacy-preserving, and trusting architecture based on a private blockchain network/smart contract and interplanetary file system technology for the Al-NajafyIraq oil refinery factory. That enables autonomous working and provides a high level of security authentication and privacy preservation, P2P communication, remote access, immutability and information backtracking. Traditional blockchain technology has storage limitation issues, most recent works adopted external servers or the cloud for storage purposes. Our proposed scheme addresses the limitations of blockchain data storage by adopting an interplanetary file system (IPFS) network; provides an efficient data encryption mechanism at the perceptual layer by adopting a lightweight encryption algorithm, high-performance, and ultra-low-power consumption ARM Cortex-M microcontroller. In addition, our architecture succeeds in merging blockchain technology, IoTs, and an IPFS with the oil refinery as an industrial application area. Moreover, it provides an efficient framework that resists common cyber-security attacks and realizes cyber-security requirements represented by data availability, integrity, and confidentiality.","","979-8-3503-4655-8","10.1109/SmartWorld-UIC-ATC-ScalCom-DigitalTwin-PriComp-Metaverse56740.2022.00325","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10189750","Industrial IoT;Industry 4.0;cybersecurity;cryptography;decentralized app;Blockchain technology;IPFS;private blockchain;embedded system.","Costs;Architecture;System performance;Memory;Computer architecture;Blockchains;Oil refineries","","","","31","IEEE","27 Jul 2023","","","IEEE","IEEE Conferences"
"AIoT-based Smart Home Energy Management System","A. K. Salama; M. M. Abdellatif","Electrical Engineering Department, The British University in Egypt, Cairo, Egypt; Electrical Engineering Department, The British University in Egypt, Cairo, Egypt","2022 IEEE Global Conference on Artificial Intelligence and Internet of Things (GCAIoT)","25 Jan 2023","2022","","","177","181","Artificial Intelligence of Things (AIoT) is a relatively new technology that combines Artificial Intelligence and Internet of Things. IoT devices can be integrated into large-scale systems for many modern applications. This results in a large amount of collected data, which needs efficient, and intelligent data processing for optimal use. Data can be processed and utilized for problem solving, decision making, and data prediction using AI. AI can increase the value of IoT, while IoT can improve AI's intel-ligence and learning. However, there are many obstacles to AIoT implementation such as complexity, precision, and efficiency. This study focuses on AI-powered IoT devices, where machine learning and neural network algorithms are implemented on an IoT based smart home energy management system (SHEMS). The AI is used to predict the future power consumption of the SHEMS, and using that prediction, turns off one or more devices in order to reduce the overall consumption at the end of the month. The results demonstrate that the system can save the user a large amount of money at the end of the year by keeping the consumption below a certain threshold.","","979-8-3503-0984-3","10.1109/GCAIoT57150.2022.10019091","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10019091","IoT;AI;AIoT;Energy Management;Smart Home","Power demand;Corporate acquisitions;Smart homes;Prediction methods;Prediction algorithms;Internet of Things;Problem-solving","","1","","8","IEEE","25 Jan 2023","","","IEEE","IEEE Conferences"
"STAR-RIS-Aided Full-Duplex Communication for Massive MIMO IoT Systems","R. Sultan; A. Shamseldeen","Physics and Engineering Department, University of St. Thomas, Houston, TX; PROSE Technologies, New Jersey, USA","2023 IEEE 15th International Conference on Computational Intelligence and Communication Networks (CICN)","30 Jan 2024","2023","","","50","55","With the increase in the internet-of-things (IoT) users numbers, the upcoming 6G network is required to deploy smart and efficient connectivity optimization algorithms. These algorithms should guarantee that the cellular network can support more IoT users while maintaining the macro-users' quality of service (QoS). In this paper, we exploit simultaneous transmitting and reflecting reconfigurable intelligent surfaces (STAR-RIS) in optimizing IoT users' connectivity in full-duplex massive multiple-input-multiple-output (MIMO) networks. Different from Conventional RIS, STAR-RIS can support a full-space smart radio environment, which allows for joint full-duplex self-interference (SI) cancellation in the reflection sub-space and IoT Connectivity optimization in the transmission subspace. Accordingly, we examine a single-cell network with a full-duplex base station (BS). The BS deploys a very large scale, i.e., massive MIMO to serve multiple downlink IoT users with the existing uplink and downlink macro users. The joint SI cancellation and IoT connectivity optimization problem is divided into two subproblems. The first subproblem is to optimize the STAR-RIS reflection, minimizing the SI level. The second is to optimize the IoT connectivity and the RIS transmission coefficients, maximizing the downlink rate. The effectiveness of the proposed STAR-RIS optimization framework is validated by numerical results. It is shown that the STAR-RIS-assisted systems outperform the conventional RIS systems and RIS systems with random phase assignments,","2472-7555","979-8-3503-2443-3","10.1109/CICN59264.2023.10402254","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10402254","Cellular Networks;Full-Duplex Communication;IoT;Massive MIMO;Optimization;Reconfigurable Intelligent surfaces;STAR-RIS;Self-Interference Cancellation","Interference cancellation;Full-duplex system;Massive MIMO;Downlink;Reflection;Uplink;Optimization","","","","17","IEEE","30 Jan 2024","","","IEEE","IEEE Conferences"
"A Fast Hierarchical Physical Topology Update Scheme for Edge-Cloud Collaborative IoT Systems","T. Yu; X. Wang; J. Hu","School of Electronic and Information Engineering, Soochow University, Suzhou, China; Department of Electrical and Computer Engineering, Western University, London, ON, Canada; School of Electronic and Information Engineering, Soochow University, Suzhou, China","IEEE/ACM Transactions on Networking","14 Oct 2021","2021","29","5","2254","2266","The awareness of physical network topology in a large-scale Internet of Things (IoT) system is critical to enable location-based service provisioning and performance optimization. However, due to the dynamics and complexity of IoT networks, it is usually very difficult to discover and update the physical topology of the large-scale IoT systems in real-time. Considering the stringent latency requirements in IoT systems, while the initial processing time for topology discovery can be tolerated, latency due to real-time topology update constitutes an even higher level of challenge. In this paper, a novel fast hierarchical topology update scheme is proposed for the large-scale IoT systems enabled by using the edge-cloud collaborative architecture. Specifically, an event-driven neighbor update algorithm, termed as TriggerOn, is firstly developed to update the local neighbor table of the end devices when device association or disassociation occurs. Based on the updated neighbor tables, the physical topology update of the subnet is conducted at the coordinated edge device, where a hybrid multidimensional scaling (MDS) based 3D localization algorithm is developed to locate the newly associated devices. Simulation results have indicated that as compared to the benchmark methods, the neighbor discovery latency has been reduced dramatically, and the 3D localization accuracy has been improved. Furthermore, the overall latency incurred by the proposed hierarchical physical topology update scheme is significantly lower than the distributed consensus-based update scheme, especially for the large-scale IoT subnets.","1558-2566","","10.1109/TNET.2021.3085031","Natural Science Foundation of Jiangsu Province, China(grant numbers:BK20200858); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9447172","Neighbor discovery;physical topology update;edge-cloud collaboration;the Internet of Things","Topology;Network topology;Location awareness;Three-dimensional displays;Internet of Things;Wireless sensor networks;Protocols","","6","","36","IEEE","4 Jun 2021","","","IEEE","IEEE Journals"
"Convergence of mobile broadband and broadcast services: A cognitive radio sensing and sharing perspective","K. Rapetswa; L. Cheng","School of Electrical and Information Engineering, University of the Witwatersrand, Johannesburg, South Africa; School of Electrical and Information Engineering, University of the Witwatersrand, Johannesburg, South Africa","Intelligent and Converged Networks","21 Sep 2020","2020","1","1","99","114","With next generation networks driving the confluence of multi-media, broadband, and broadcast services, Cognitive Radio (CR) networks are positioned as a preferred paradigm to address spectrum capacity challenges. CRs address these issues through dynamic spectrum access. However, the main challenges faced by the CR pertain to achieving spectrum efficiency. As a result, spectrum efficiency improvement models based on spectrum sensing and sharing models have attracted a lot of research attention in recent years, including CR learning models, network densification architectures, and massive Multiple Input Multiple Output (MIMO), and beamforming techniques. This paper provides a survey of recent CR spectrum efficiency improvement models and techniques, developed to support ultra-reliable low latency communications that are resilient to surges in traffic and competition for spectrum. These models and techniques, broadly speaking, enable a wide range of functionality ranging from enhanced mobile broadband to large scale Internet of Things (IoT) type communications. In addition and given the strong correlation between the typical size of a spectrum block and the achievable data rate, the models studied in this paper are applicable in ultra-high frequency band. This study therefore provides a good review of CRs and direction for future investigations into newly identified 5G research areas, applicable in industry and in academia.","2708-6240","","10.23919/ICN.2020.0003","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9198059","cognitive radio;distributed networks;spectrum sensing and sharing;next generation networks","Sensors;Next generation networking;Narrowband;Broadband communication;Cognitive radio;Interference;Wideband","","16","","","","21 Sep 2020","","","TUP","TUP Journals"
"Integration of Wireless Sensor Networks with IoT in Smart Transportation Systems and Traffic Management","A. C. S. Sheela; B. S. Ahamed; D. Poornima; C. S. A. C","Department of Computer Science and Engineering, Sathyabama Institute of Science & Technology, Chennai, India; Department of Computer Science and Engineering, Sathyabama Institute of Science & Technology, Chennai, India; Department of Computer Science and Engineering, Sathyabama Institute of Science & Technology, Chennai, India; Department of Mathematics, Rajalakshmi Engineering College, Chennai, India","2023 International Conference on Emerging Research in Computational Science (ICERCS)","21 Feb 2024","2023","","","1","6","The increasing industrialization and overpopulation in recent decades have necessitated the development of new, more environmentally friendly modes of transportation. Problems with sensors might arise in terms of dependability, security, scalability, and privacy of collected data. Wireless sensor networks (WSNs) that function with the Internet of Things (IoT) have emerged as a feasible alternative for handling this problem. With the assist of the Internet of Things (IoT), Wi-Fi sensor networks can accumulate records in real-time from sensors set up in homes, automobiles, and different urban infrastructure. This statistics may be easily accumulated, analyzed, and communicated to centralized control centers through IoT, enabling visitor’s management government to make well-knowledgeable picks in actual-time. Hence, this look at proposes IoT-enabled Wireless Sensor Networks for Smart Transportation Systems (IoT-WSN-STS) for monitoring visitors instances, using styles, environmental variables, and extra. The paper appears into this holistic method to sell environmentally pleasant transportation networks by encouraging inexperienced riding behavior and reducing fuel fees. Large-scale deployment and control of WSNs and IoT structures in smart transportation networks provide specific troubles discussed on this have a look at. As a result, there is considerable capacity for reinforcing city mobility's efficacy, protection, and sustainability via incorporating WSNs with IoT in smart transportation systems and site visitor’s enforcement.","","979-8-3503-5976-3","10.1109/ICERCS57948.2023.10433998","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10433998","Wireless Sensor Networks;Internet of Things;Smart Transportation System;Traffic Management","Wireless communication;Wireless sensor networks;Urban areas;Smart transportation;Internet of Things;Intelligent sensors;Wireless fidelity","","","","23","IEEE","21 Feb 2024","","","IEEE","IEEE Conferences"
"Application of Cryptographic Technology Based on Certificateless System in Electricity Internet of Things","H. Liao; L. Li; J. Xuan; H. Wang","Technology Department, State Grid Electronic Commerce Co., LTD, State Grid Xiong'an Financial Technology Group Co., LTD., State Grid Blockchain Technology (Beijing) Co., Ltd., Beijing, China; Technology Department, State Grid Electronic Commerce Co., LTD, State Grid Xiong'an Financial Technology Group Co., LTD., State Grid Blockchain Technology (Beijing) Co., Ltd., Beijing, China; Technology Department, State Grid Electronic Commerce Co., LTD, State Grid Xiong'an Financial Technology Group Co., LTD., State Grid Blockchain Technology (Beijing) Co., Ltd., Beijing, China; Technology Department, State Grid Shanxi Marketing Service Center, Taiyuan, China","2020 3rd International Conference on Advanced Electronic Materials, Computers and Software Engineering (AEMCSE)","2 Jul 2020","2020","","","417","423","With the construction of Internet of things, relying on big data, cloud computing, artificial intelligence, Internet of things and blockchain and other new technologies, data integration between various network systems has been accelerated and the gap between data islands has been broken. However, due to the large scale of terminal access, complex business operation relationship, network system vulnerability and more and more loopholes, the traditional network security technology is difficult to ensure the security of the system. This paper proposes to solve the security problems caused by large-scale terminal access by using the certificate-free security mechanism based on domestic cryptography, so as to provide security guarantee for the construction of electricity internet of things. At the same time, in order to meet the security requirements of energy Internet information interaction, this paper proposes a decentralized key management idea to solve the traditional IBC (identity based Cryptograph) algorithm key update problem, improve the security management and control ability of the system, and comprehensively support the construction of world-class energy Internet enterprises with excellent competitiveness.","","978-1-7281-8143-1","10.1109/AEMCSE50948.2020.00097","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9131178","component;Electricity Internet of Things;network security;identity authentication;domestic password","","","1","","14","IEEE","2 Jul 2020","","","IEEE","IEEE Conferences"
"A Multi-tiered Social IoT Architecture for Scalable and Trusted Service Provisioning","G. Sciddurlo; I. Huso; D. Striccoli; G. Piro; G. Boggia","Dept. of Electrical and Information Engineering, Politecnico di Bari, Bari, Italy; Dept. of Electrical and Information Engineering, Politecnico di Bari, Bari, Italy; Dept. of Electrical and Information Engineering, Politecnico di Bari, Bari, Italy; Dept. of Electrical and Information Engineering, Politecnico di Bari, Bari, Italy; Dept. of Electrical and Information Engineering, Politecnico di Bari, Bari, Italy","2021 IEEE Global Communications Conference (GLOBECOM)","2 Feb 2022","2021","","","1","6","In the Social Internet of Things paradigm, the Trust Management System computes trust values of involved social objects, identifies trusted relationships, and selects the most suitable object able to provide a target service. State-of-the-art mechanisms conceived to address these tasks generally avoid considering the actual availability of social objects and demand the implementation of complex algorithms to constrained nodes. This work presents a novel multi-tiered and fog-based Social Internet of Things architecture to solve these open issues, ensuring fast service provisioning, high scalability, fault tolerance, and security. On the one hand, the Trust Management System hosted at the first fog layer of the architecture jointly addresses the trustworthiness of service providers and monitors the re-source availability exposed by social objects, thus simplifying the forwarding of service requests to trusted and unloaded nodes. From another hand, to securely implement advanced services at a large scale, a second fog layer exploits a Blockchain-based storage for sharing services, relationships, and trust values across organizations and service domains. Computer simulations demonstrate the effectiveness of the proposed architecture in a realistic Social Internet of Things while showing the performance gain obtained against a baseline approach.","","978-1-7281-8104-2","10.1109/GLOBECOM46510.2021.9685084","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9685084","Social Internet of Things;Trust Management System;multi-tiered architecture;resource management","Scalability;Computer architecture;Quality of service;Social factors;Service-oriented architecture;Internet of Things;Security","","3","","13","IEEE","2 Feb 2022","","","IEEE","IEEE Conferences"
"Advanced Ultra Low-Power Deep Learning Applications with Neuromorphic Computing","M. Barnell; C. Raymond; L. Loomis; D. Isereau; D. Brown; F. Vidal; S. Smiley","Air Force Research Laboratory, Information Directorate, Rome, NY, USA; Air Force Research Laboratory, Information Directorate, Rome, NY, USA; Air Force Research Laboratory, Information Directorate, Rome, NY, USA; Defense Systems & Solutions, SRC, Inc., North Syracuse, NY, USA; Defense Systems & Solutions, SRC, Inc., North Syracuse, NY, USA; Defense Systems & Solutions, SRC, Inc., North Syracuse, NY, USA; Defense Systems & Solutions, SRC, Inc., North Syracuse, NY, USA","2023 IEEE High Performance Extreme Computing Conference (HPEC)","25 Dec 2023","2023","","","1","4","The latest Intel neuromorphic processor, Loihi 2, provides a breakthrough in Artificial Intelligence (AI) for computing at the edge, where sensor information is collected. The computing architecture does this by leveraging computations at the transistor level in a fashion analogous to the human brain's biological neural networks (vs. a Von Neumann compute architecture). The Loihi 2's high performance, small form factor, and low-power consumption makes it a unique capability that is well suited for use in devices. Our technical approach and findings support extreme computing needs for the internet of things (IoT) and various airborne platforms' applications. The recently released Loihi 2 and the novel research completed on this effort were combined to accelerate development and demonstration of a new concept of operation for machine learning at the edge. This research included the development of spiking neural networks (SNN) on sensor data representative of information sources from a small research platform. Our concept uses the representative sensor data to predict the platform mode through machine learning. Importantly, our technical approach allowed us to rapidly scale from IBM's TrueNorth Corelet framework to the Lava framework, which Intel's Loihi 2 neuromorphic processor utilizes. The use of the Lava framework demonstrates the art-of-the-possible in edge computing by demonstrating capabilities on small airborne platform sensor data and wide extensibility to other domains that can use this neuromorphic compute hardware. In summary, this research included the use of new compute frameworks, novel processing algorithms, and a unique concept of operation. This technical approach resulted in the classification of the platform mode given the sensor information with accuracies up to 97.6%.","2643-1971","979-8-3503-0860-0","10.1109/HPEC58863.2023.10363561","Air Force Research Laboratory (AFRL); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10363561","Extreme Computing;Machine Learning;High Performance Embedded Computing;Neuromorphic Computing;Deep Learning;Intel Loihi 2;Autonomous Operation","Performance evaluation;Neuromorphic engineering;Lava;Computer architecture;Hardware;Extensibility;Internet of Things","","","","20","IEEE","25 Dec 2023","","","IEEE","IEEE Conferences"
"A planning framework for QoS based composition services in IoT environment","A. BenDahmene; O. Kazar; K. Rezeg; A. e. Merizig","Department of computer science, University of Biskra, Biskra, Algeria; Department of computer science, University of Biskra, Biskra, Algeria; Department of computer science, University of Biskra, Biskra, Algeria; Department of computer science, University of Biskra, Biskra, Algeria","2022 International Symposium on iNnovative Informatics of Biskra (ISNIB)","28 Mar 2023","2022","","","1","5","Recently, Internet has developed into a new technology known as Internet of Things (IoT), enabling the interconnection of billions sensors, actuators, devices, as well as users, which are applied for huge data generating. Moreover, due to the numerous and heterogeneous included devices, and services delivered, the IoT service discovery, selection, and composition is a challenging task. Given that several services have the same functionality but different non-functional criteria (QoS). Thus it is interesting to create an automatic, dynamic, and optimal IoT service composition system to respond on real time to large scale of services, including QoS. Accordingly, we propose, in this paper, an approach for IoT service composition based automatic planning (AP) enhanced by genetic algorithm (GA). The objective is to produce a plan composition satisfying the optimal QoS. In addition, we employ the cloud technology to establish an optimal IoT service composition with less memory consumption, and expanded scalability of our suggested framework. The simulation results have illustrated the efficiency of our approach to resolve the composition problem in a distributed and dynamic IoT system.","","979-8-3503-2065-7","10.1109/ISNIB57382.2022.10075687","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10075687","service composition;AI planning;QoS;IoT;cloud computing","Cloud computing;Scalability;Simulation;Quality of service;Planning;Sensors;Internet of Things","","","","20","IEEE","28 Mar 2023","","","IEEE","IEEE Conferences"
"Graph Neural Networks-based Clustering for Social Internet of Things","A. Khanfor; A. Nammouchi; H. Ghazzai; Y. Yang; M. R. Haider; Y. Massoud","School of Systems & Enterprises, Stevens Institute of Technology, Hoboken, NJ, USA; School of Systems & Enterprises, Stevens Institute of Technology, Hoboken, NJ, USA; School of Systems & Enterprises, Stevens Institute of Technology, Hoboken, NJ, USA; School of Systems & Enterprises, Stevens Institute of Technology, Hoboken, NJ, USA; University of Alabama, Birmingham, AL, USA; School of Systems & Enterprises, Stevens Institute of Technology, Hoboken, NJ, USA","2020 IEEE 63rd International Midwest Symposium on Circuits and Systems (MWSCAS)","2 Sep 2020","2020","","","1056","1059","In this paper, we propose a machine learning process for clustering large-scale social Internet-of-things (SIoT) devices into several groups of related devices sharing strong relations. To this end, we generate undirected weighted graphs based on the historical dataset of IoT devices and their social relations. Using the adjacency matrices of these graphs and the IoT devices' features, we embed the graphs' nodes using a Graph Neural Network (GNN) to obtain numerical vector representations of the IoT devices. The vector representation does not only reflect the characteristics of the device but also its relations with its peers. The obtained node embeddings are then fed to a conventional unsupervised learning algorithm to determine the clusters accordingly. We showcase the obtained IoT groups using two well-known clustering algorithms, specifically the K-means and the density-based algorithm for discovering clusters (DBSCAN). Finally, we compare the performances of the proposed GNN-based clustering approach in terms of coverage and modularity to those of the deterministic Louvain community detection algorithm applied solely on the graphs created from the different relations. It is shown that the framework achieves promising preliminary results in clustering large-scale IoT systems.","1558-3899","978-1-7281-8058-8","10.1109/MWSCAS48704.2020.9184643","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9184643","Internet of Things (IoT);clustering;deep learning;graph neural networks","Clustering algorithms;Machine learning;Neural networks;Peer-to-peer computing;Machine learning algorithms;Unsupervised learning;Complexity theory","","16","","12","IEEE","2 Sep 2020","","","IEEE","IEEE Conferences"
"A decision Support System for Managerial Decision in Cultural Heritage Sites","M. A. Benatia; M. Messaadia","LINEACT Lab., Cesi-Engineering School, Rouen, FRANCE; LINEACT Lab., Cesi-Engineering School, Rouen, FRANCE","2021 1st International Conference On Cyber Management And Engineering (CyMaEn)","30 Jul 2021","2021","","","1","4","the number of connected objects used in our daily lives (smartphones, smart watches, etc.) is constantly increasing. These smart and connected objects usually have a unique identifier and communication, processing and networking capabilities. These smart devices can connect to the Internet, creating a vast network of objects called the ""Internet of Things"" (IoT). Thus, they can interact (detect and act) with their physical environment.However, the IoT raises many challenges related to its very large scale and high dynamicity, as well as the large variety of the generated data. These issues require the design and development of new systems and techniques to (i) collect and store data from the different smart objects, (ii) process and analyse these data, (iii) assist managers in the decision making process through simplified information. This paper proposes a data stream management system that collect, store, manage, analyse and visualize cultural heritage data. We propose a new data management architecture based on Big Data and cloud computing technologies. The proposed architecture consists of a distributed data management system for the tourism IoT. The proposed architecture addresses the problems of deploying continuous processing tasks automatically and simplify the access to the collected data.","","978-1-6654-3200-9","10.1109/CyMaEn50288.2021.9497302","Interreg; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9497302","Big Data;Business Intelligence;Decision Support Systems;IoT","Decision support systems;Decision making;Distributed databases;Computer architecture;Internet of Things;Cultural differences;Object recognition","","","","9","IEEE","30 Jul 2021","","","IEEE","IEEE Conferences"
"Design and Implementation of Real-Time Monitoring System for Building-integrated Photovoltaic System","A. Ftirich; B. Bouaziz; F. Bacha","Labo of Computing for Industrial Systems (LISI), INSAT University Carthage (LR11ES26), Tunis, Tunis; (LISI), INSAT University Carthage (LR11ES26), Tunis, Tunis; (LISI), INSAT University Carthage (LR11ES26), Tunis, Tunis","2023 IEEE International Conference on Advanced Systems and Emergent Technologies (IC_ASET)","20 Jun 2023","2023","","","1","6","Photovoltaic systems are used to provide electricity to people who are difficult to reach by the grid due to their location in inaccessible places or who consume very little energy. The need to provide all of the users' energy demands characterizes an independent installation. Photovoltaic modules, a charge controller, a storage system (rechargeable batteries), and a voltage inverter are among its components. In recent years, the Building integrated photovoltaic (BIPV) systems have the most used in home electrification. To make a easy BIPV system, there is a need to adopt digital technologies such as the internet of things (IoT), artificial intelligence (AI) and edge computing. In this study, we present the design and implementation of a real-time monitoring solution applicable to photovoltaic self-consumption or the BIPV system using the IoT technology. A detailed description of the proposed system at the hardware level is provided, and extended information on the communication characteristics and sensors data is also included. We will present a low-cost system to monitor solar energy production and the battery energy. This method based on open source internet of things solution that could collect in intelligent manner and monitor in real-time the produced power and environmental conditions via a mobile application and local web server for remote user. The solution is designed as a prototype test bench that could be extended to monitor large scale photovoltaic stations.","","979-8-3503-2102-9","10.1109/IC_ASET58101.2023.10151167","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10151167","Building integrated photovoltaic;photovoltaic self-consumption;IoT real-time monitoring;Web sever monotoring","Wireless communication;Wireless sensor networks;Building integrated photovoltaics;Real-time systems;Web servers;Batteries;Internet of Things","","","","9","IEEE","20 Jun 2023","","","IEEE","IEEE Conferences"
"MemTorch: A Simulation Framework for Deep Memristive Cross-Bar Architectures","C. Lammie; M. R. Azghadi","College of Science and Engineering, James Cook University, Townsville, QLD, Australia; College of Science and Engineering, James Cook University, Townsville, QLD, Australia","2020 IEEE International Symposium on Circuits and Systems (ISCAS)","28 Sep 2020","2020","","","1","5","Memristive devices arranged in cross-bar architectures have shown great promise to facilitate the acceleration and improve the power efficiency of Deep Learning (DL) systems for deployment in resource-constrained platforms, such as the Internet-of-Things (IoT) edge devices. These cross-bar architectures can be used to implement various in-memory computing operations, such as Multiply-Accumulate (MAC) and convolution, which are used extensively in Deep Neural Networks (DNNs) and Convolutional Neural Networks (CNNs). Currently, there is a lack of an open source, general, high-level simulation platform that can fully integrate any behavioral or experimental memristive device model into cross-bar architectures. This paper presents such a framework named MemTorch, which integrates directly with the well-known PyTorch Machine Learning (ML) library. To demonstrate an example practical use of MemTorch, we use it to simulate the performance degradation that non-ideal devices introduce to a typical Memristive DNN (MDNN) implementing VGG-16 for CIFAR-10. Our open source1 MemTorch framework can be used by circuit and system designers to conveniently build customized large-scale simulation platforms, as a preliminary step before circuit-level realization.","2158-1525","978-1-7281-3320-1","10.1109/ISCAS45731.2020.9180810","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9180810","Memristors;ReRAM;Deep Learning;PyTorch","Performance evaluation;Memristors;Graphics processing units;Python;C++ languages;Computer architecture;Mathematical model","","14","","30","IEEE","28 Sep 2020","","","IEEE","IEEE Conferences"
"Research and Design of Sensor Data Management System Based on Distributed Storage","J. Yang; X. Chi; M. Zhu; W. Wang","MoE Engineering Research Center for Software/Hardware Co-design Technology and Application, East China Normal University, Shanghai, China; MoE Engineering Research Center for Software/Hardware Co-design Technology and Application, East China Normal University, Shanghai, China; MoE Engineering Research Center for Software/Hardware Co-design Technology and Application, East China Normal University, Shanghai, China; MoE Engineering Research Center for Software/Hardware Co-design Technology and Application, East China Normal University, Shanghai, China","2020 International Conference on Computer Science and Management Technology (ICCSMT)","3 Jun 2021","2020","","","128","132","Sensor data is one of the basic source of big data in the Internet of Things(IoT). It is the data that is sensed, measured, and transmitted by sensors with real-time and dynamic characteristics. With the development of the IoT and big data technologies, new industries such as smart transportation, smart cities, and smart agriculture have gradually formed, resulting in an increasing demand for large-scale data analysis and calculations. However, the storage architecture based on relational databases has been unable to meet the current needs in terms of data storage and data read and write speed. Therefore, this paper mainly studies the sensor data management system based on distributed storage, builds a Hadoop cluster, proposes a storage structure that combines the relational database MySQL with the distributed database HBase, designs a data migration module to satisfy real-time sensor data monitoring and massive data storage requirements. In order to meet the needs of enterprises in actual production, SSM framework technology is used to build a sensor data management platform, covering the functions of system management, sensor data management, data exception management, sensor data real-time monitoring, sensor node status monitoring, data statistical analysis, etc. The platform has good security and reliability, and can effectively improve the management efficiency of the enterprise. Finally, the experiment provides that the system has obvious advantages in data upload and query ability compared with the traditional storage architecture. It provides a good data environment for data analysis and data mining in the future.","","978-1-7281-8668-9","10.1109/ICCSMT51754.2020.00032","East China Normal University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9443971","sensor data;distributed storage;HBase;SSM","Data analysis;Statistical analysis;Distributed databases;Memory;Relational databases;Big Data;Real-time systems","","","","12","IEEE","3 Jun 2021","","","IEEE","IEEE Conferences"
"Power IoT security protection architecture based on zero trust framework","Z. Xiaojian; C. Liandong; F. Jie; W. Xiangqun; W. Qi","Global Energy Interconnection Research Institute co. Ltd, State Grid Key Laboratory of Information & Network Security, Nanjing, Jiangsu, China; Department Name State Grid Hebei Information & Telecommunication Branch, State Grid Hebei Electric Power Co., Nanjing, Jiangsu, China; Global Energy Interconnection Research Institute co. Ltd, State Grid Key Laboratory of Information & Network Security, Nanjing, Jiangsu, China; Global Energy Interconnection Research Institute co. Ltd, State Grid Key Laboratory of Information & Network Security, Nanjing, Jiangsu, China; Global Energy Interconnection Research Institute co. Ltd, State Grid Key Laboratory of Information & Network Security, Nanjing, Jiangsu, China","2021 IEEE 5th International Conference on Cryptography, Security and Privacy (CSP)","25 Feb 2021","2021","","","166","170","The construction of the power Internet of Things has led various terminals to access the corporate network on a large scale. The internal and external business interaction and data exchange are more extensive. The current security protection system is based on border isolation protection. This is difficult to meet the needs of the power Internet of Things connection and open shared services. This paper studies the application scheme of the “zero trust” typical business scenario of the power Internet of Things with “Continuous Identity Authentication and Dynamic Access Control” as the core, and designs the power internet security protection architecture based on zero trust.","","978-1-7281-8621-4","10.1109/CSP51677.2021.9357607","science and technology project of State Grid Corporation of China: “End-to-End Security threat analysis and accurate protection of Ubiquitous power Internet of things(grant numbers:5700-201958466A-0-0-00); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9357607","POWER IO;ZERO TRUST;DYNAMIC ACCESS CONTROL","Privacy;Conferences;Internet security;Authentication;Internet of Things;Cryptography;Business","","7","","9","IEEE","25 Feb 2021","","","IEEE","IEEE Conferences"
"Power grid optimization planning based on DG acceptance capability evaluation of hybrid AC/DC transmission system","H. Yibo; R. DongHong; Q. Tao; C. HongWei","State Grid ShangLuo power supply company, Shangluo, China; State Grid ShangLuo power supply company, Shangluo, China; State Grid ShangLuo power supply company, Shangluo, China; State Grid ShangLuo power supply company, Shangluo, China","The 16th IET International Conference on AC and DC Power Transmission (ACDC 2020)","15 Sep 2021","2020","2020","","404","411","Under the current background of the ubiquitous power Internet of things and strong smart grid, high-permeability DG is an important feature of the future power energy internet, which may cause problems such as voltage over limit flicker, increased network loss, bidirectional variation of power flow, and increased grid coupling[1-2]. In this paper, the operation state interval set of power system is proposed. Considering the influence of power supply capacity on the system security boundary and stability boundary after the DG is connected to the grid, the influence of the access location of the DG on the power system power quality is qualitatively analyzed. At the same time, on the premise of satisfying the consistency of interaction information between multi-source transmission and distribution system and load[3], the problem is decomposed into the acceptance capacity of power side and the optimization planning of power side. The interval mathematics method is adopted to analyze and calculate the DG acceptance capacity of the power grid, and explores the maximum capacity of DG under the condition of safe operation of the system. It also puts forward the optimization planning method of distribution network based on the improved PSO algorithm Considering the output power interval and load level interval of distributed power supply under any possible scenario, and exploring the hybrid transmission and distribution system optimization planning method from the transmission, transmission and distribution systems. It improves the reliability and flexibility of power grid operation, and provides a theoretical basis for a large number of new energy access, and has an important guiding significance for promoting the large-scale development of new energy.","","","10.1049/icp.2020.0114","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9538221","","","","1","","","","15 Sep 2021","","","IET","IET Conferences"
"An Application Based Comparative Study of LPWAN Technologies for IoT Environment","M. Iqbal; A. Y. M. Abdullah; F. Shabnam","Department of Electrical and Electronic Engineering, BRAC University, Dhaka, Bangladesh; Department of Electrical and Electronic Engineering, BRAC University, Dhaka, Bangladesh; Department of Electrical and Electronic Engineering, BRAC University, Dhaka, Bangladesh","2020 IEEE Region 10 Symposium (TENSYMP)","2 Nov 2020","2020","","","1857","1860","The Internet of Things (IoT) is a prospect of communication that defines the framework of physical objects, embedded with sensors, programs, and other innovations for transferring data across the internet to other devices and networks. LPWAN (Low Power Wide Area Network) has become a significant part for the implementation of a large-scale IoT paradigm. Recently, new protocols of LPWAN technologies have been introduced, such as LoRa, NB-IoT and Sigfox. They are considered as the leading protocols as they have wide range accessibility, low power consumption and highly cost-efficient in communication proficiency. Our major objective with this review paper is to furnish a descriptive and comparative survey of these technologies to emphasize the significance of LPWAN technology in the development and improvement of IoT based applications. Our focal point of study is to specialize the technical deviation of LPWAN protocols in terms of their features, which include pros and cons, architectural view of networking system and their applications in usage. This study shows the benefits of Sigfox and LoRa provides with long term battery life, efficient power usage, and low expense over NB-IoT. It also explains the advantages of NB-IoT in terms of latency and service quality (QoS). The whole study was done with to reach a conclusion where we ensure their best uses in different scenarios.","2642-6102","978-1-7281-7366-5","10.1109/TENSYMP50017.2020.9230597","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9230597","IoT (Internet of things);LPWAN (Low Power Wide Area Network);LoRa;Sigfox;NB-IoT","Internet of Things;Sensors;Cloud computing;Protocols;Servers;Base stations;Modulation","","21","","14","IEEE","2 Nov 2020","","","IEEE","IEEE Conferences"
"Demonstration of Integration of Blockchain in IoT","S. S. Mahapatra; C. Kumar Jha","School of Electronics Engineering, Kalinga Institute of Industrial Technology (KIIT), Bhubaneswar, India; Dept. of Electronics & Communication Engineering, Indian Institute of Information Technology Bhagalpur, Bhagalpur, India","2021 4th International Conference on Recent Trends in Computer Science and Technology (ICRTCST)","27 May 2022","2022","","","16","22","In the modern era, blockchain technology has achieved a substantial growth with rapid research developments. Blockchain technology is widely used in the field of cryptocur-rency. However, it can also be applied in other field such as internet of things (IoT). In IoT, data security and integrity is a prime concern where many problems exist such as data reliability and unauthorized access. It creates huge problem in deploying an IoT system on a smaller or larger scale. Hence, this paper reports a possible integration of blockchain technology in IoT to create a secure network. To demonstrate this, the game of Tic-Tac-Toe is implemented by following the rules of blockchain. The main goal of this implementation is to explore the application of blockchain in IoT and practically merge these two fields to get the service of IoT with the security and integrity that the blockchain technology promises.","","978-1-6654-6633-2","10.1109/ICRTCST54752.2022.9781887","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9781887","Cryptocurrency;Blockchain;IoT;Proof of work;Merkle tree","Performance evaluation;Costs;Data security;Merging;Games;Market research;Regulation","","","","16","IEEE","27 May 2022","","","IEEE","IEEE Conferences"
"Securing Photovoltaic System Deployments with Data Diodes","R. D. Larkin; T. J. Wagner; B. E. Mullins","Department of Electrical and Computer Engineering, Air Force Institute of Technology, WPAFB, USA; Department of Systems Engineering and Management, Air Force Institute of Technology, WPAFB, USA; Department of Electrical and Computer Engineering, Air Force Institute of Technology, WPAFB, USA","2020 47th IEEE Photovoltaic Specialists Conference (PVSC)","5 Jan 2021","2020","","","2525","2531","A survey of a typical photovoltaic (PV) system with and without the cybersecurity protections of a data diode is explored. This survey includes a brief overview of Industrial Control Systems (ICS) and their relationship to the Internet of Things (IoT), Industrial Internet of Things (IIoT), and Industry 4.0 terminology. The cybersecurity features of eight data diodes are compared, and the cyber attack surface, attack scenarios, and mitigations of a typical PV system are discussed. After assessing cybersecurity, the economic considerations to purchase a data diode are considered. At 13.19 cents/kWh, the sale of 227,445 kWh is needed to fund one $30,000 data diode. On average, a military installation, similar to a small city, requires approximately 48,516 kWh every hour and could fund a $30,000 data diode in 4.7 hours. Comparatively, a 25 kW communityscale PV system costing $75,000 and generating an excess of 20 kW annually (approx. 36,000 kWh), requires 6.3 years to fund a $30,000 data diode. Weighing the economic considerations, the employment of data diodes for cybersecurity protection is not economically feasible for residential or community-scale PV system deployment, but might be for large-scale utility providers. Finally, a discussion on the different communities involved in the design, cybersecurity, and operations of an ICS show that further work is needed to bridge the communities of systems engineers, cybersecurity specialists, and industrial operators.","0160-8371","978-1-7281-6115-0","10.1109/PVSC45281.2020.9300863","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9300863","Cybersecurity;PV Systems;Data Diodes;ICS;SCADA;IOT;Industrial IOT;Industry 4.0","Sun;Integrated circuits;Meters;Internet;Cyberattack;Photovoltaic systems;Economics","","3","","37","USGov","5 Jan 2021","","","IEEE","IEEE Conferences"
"A Condition-Action Rule-Based Integration Platform for the Internet of Things","C. -Y. Chen; R. -S. Ko","Department of Computer Science and Information Engineering, National Chung Cheng University, Chiayi, Taiwan; Department of Computer Science and Information Engineering, National Chung Cheng University, Chiayi, Taiwan","2020 Indo – Taiwan 2nd International Conference on Computing, Analytics and Networks (Indo-Taiwan ICAN)","1 Sep 2020","2020","","","104","107","The vigorous development of micro-electro-mechanical systems has enabled the possibility of Internet of Things that envisions interactions between tens of, or possibly hundreds of, smart things such as computers, sensors, and actuators to realize a cyber-physical environment. With the number of devices, it will become tedious and difficult to configure and management the interactions between these things. Therefore, this paper presents an integration platform which allows smart things to be plug-and-play and condition-action rules to be established between things visually. We describe the specifications and architecture of the proposed platform, and also illustrate the implementation. We believe our work will alleviate the complexity of managing and configuring medium-scale of smart things, and pave the way for the solution of large-scale Internet of Things.","","978-1-7281-4999-8","10.1109/Indo-TaiwanICAN48429.2020.9181347","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9181347","","Actuators;Intelligent sensors;Internet of Things;Software;Computer architecture;XML","","","","9","IEEE","1 Sep 2020","","","IEEE","IEEE Conferences"
"Accurate Deep Net Crowd Counting for Smart IoT Video acquisition devices","A. Khadka; V. Argyriou; P. Remagnino","Computer Science Department, Kingston University London, London, UK; Computer Science Department, Kingston University London, London, UK; Computer Science Department, Kingston University London, London, UK","2020 16th International Conference on Distributed Computing in Sensor Systems (DCOSS)","1 Sep 2020","2020","","","260","264","A novel deep neural network is proposed, for accurate and robust crowd counting. Crowd counting is a complex task, as it strongly depends on the deployed camera characteristics and, above all, the scene perspective. Crowd counting is essential in security applications where Internet of Things (IoT) cameras are deployed to help with crowd management tasks. The complexity of a scene varies greatly, and a medium to large scale security system based on IoT cameras must cater for changes in perspective and how people appear from different vantage points. To address this, our deep architecture extracts multi-scale features with a pyramid contextual module to provide long-range contextual information and enlarge the receptive field. Experiments were run on three major crowd counting datasets, to test our proposed method. Results demonstrate our method supersedes the performance of state-of-the-art methods.","2325-2944","978-1-7281-4351-4","10.1109/DCOSS49796.2020.00049","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9183637","IoT cameras;Crowd density estimation;Self attention network;Consistency","Feature extraction;Kernel;Computer architecture;Estimation;Robustness;Cameras;Security","","1","","34","IEEE","1 Sep 2020","","","IEEE","IEEE Conferences"
"An Evolutionary Reinforcement Learning Scheme for IoT Robustness","X. Yang; N. Chen; S. Zhang; X. Zhou; L. Zhang; T. Qiu","College of Intelligence and Computing, Tianjin University, Tianjin, China; College of Intelligence and Computing, Tianjin University, Tianjin, China; College of Intelligence and Computing, Tianjin University, Tianjin, China; College of Intelligence and Computing, Tianjin University, Tianjin, China; Cyberspace Institute Advanced Technology, Guangzhou University, Guangzhou, China; College of Intelligence and Computing, Tianjin University, Tianjin, China","2023 26th International Conference on Computer Supported Cooperative Work in Design (CSCWD)","22 Jun 2023","2023","","","756","761","With the rapid scale expansion of the Internet of Things (IoT), the probability of system failure increases. Frequent system failures degrade the quality of service (QoS) of IoT. Existing optimization strategies utilize reinforcement learning (RL) to enhance the robustness of IoT topology. However, due to the increasing scale of the IoT environment, the unbalanced exploration and exploitation of RL agents make it prone to premature convergence at the local optimum. Large-scale action spaces and state spaces lead to a sparse reward problem, which reduces the convergence efficiency of the algorithm. This paper proposes an evolutionary reinforcement learning scheme for IoT robustness to solve the above problems. We design a multi- agent evolution mechanism to provide multiple experiences for RL, which strengthens exploration capability. We present new evolution operators to promote convergence, which combine dis- tillation crossover and Gaussian mutation. Extensive experiments show that our scheme has a strong exploration capability, and the optimization rate of IoT topology robustness reaches 81.15%, which outperforms other robustness optimization algorithms.","2768-1904","979-8-3503-3168-4","10.1109/CSCWD57460.2023.10152704","National Natural Science Foundation of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10152704","Internet of Things;network topology;robustness optimization;evolutionary reinforcement learning","Federated learning;Reinforcement learning;Quality of service;Robustness;Topology;Internet of Things;Distributed algorithms","","","","24","IEEE","22 Jun 2023","","","IEEE","IEEE Conferences"
"A Blockchain-Assisted Massive IoT Data Collection Intelligent Framework","L. Zhang; F. Li; P. Wang; R. Su; Z. Chi","Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, Dalian University of Technology, Dalian, China; Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, Dalian University of Technology, Dalian, China; Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, Dalian University of Technology, Dalian, China; Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, Dalian University of Technology, Dalian, China; Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, Dalian University of Technology, Dalian, China","IEEE Internet of Things Journal","8 Aug 2022","2022","9","16","14708","14722","Due to the vigorous development of wireless communication technology, massive sensors have been gradually connected to the Internet of Things (IoT) and generate a massive quantity of valuable IoT data from large-scale wireless sensor networks (WSNs) controlled by different owners. Massive IoT data need to be collected and circulated among multiple data owners and data users. However, existing data collection frameworks may cause heavy computational overhead or rely on trusted third parties, since sensors have constrained resources. Consequently, massive IoT data are transformed among different parties, causing severe trust and security issues. In this article, we propose a blockchain-assisted massive IoT data collection (MIDC) intelligent framework to support the security, trust and efficiency of massive data collection for large-scale heterogeneous WSNs. In particular, we propose a series of novel technologies for the framework: 1) we design a large-scale heterogeneous WSNs collaborative identity verification protocol to ensure reliable data sources; 2) we build a hierarchical massive data aggregation scheme to collect massive IoT data efficiently and securely; and 3) we depict a blockchain-based massive IoT data management method to construct trust among different parties. Extensive simulation and prototype experimental results prove the effectiveness of our framework.","2327-4662","","10.1109/JIOT.2021.3049674","Key Research and Development Program of Liaoning Province(grant numbers:2020JH2/10100038); Fundamental Research Funds for the Central Universities(grant numbers:DUT19ZD209); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9316679","Blockchain;data collection;identity verification;Internet of Things (IoT);privacy protection","Sensors;Wireless sensor networks;Peer-to-peer computing;Blockchain;Data collection;Security;Internet of Things","","17","","29","IEEE","8 Jan 2021","","","IEEE","IEEE Journals"
"IoT Platform: Technology, Use Cases, and Standardization","T. Yokotani; S. Giordano","Kanazawa Institute of Technology, Nonoichi, Ishikawa, Japan; The University of Pisa, Pisa, Italy","2022 IEEE 8th World Forum on Internet of Things (WF-IoT)","22 Jun 2023","2022","","","1","2","Summary form only. Edge Intelligence is a synergy that seems to be imperative to conclude the convergence of the Edge Computing and Internet of Things to support intelligent application very close to end users. IoT has pervaded our daily life by making things, interconnected through the Internet, smarter, distributed and more autonomous. The emerging development of intelligent applications in IoT has now started to gain significant attention. Cloud provides many benefits to IoT devices, including high-performance computing, a storage infrastructure, processing and analysis of large-scale data giving to IoT the opportunity to be robust, smart and self-configuring. The forthcoming emergence of Edge AI will extend the capabilities of the ‘legacy’ IoT, its potentials, the number of devices and the volumes of data. However, Cloud technologies face some accessibility challenges when providing services to end-users. For instance, mobile clients can move among different places, yet require Cloud services with minimum cost and short response time. The unstable connection between Cloud and mobile devices is expected to prevent providers from achieving the optimal performance. To cope with these limitations, we aspire that Edge AI converged with IoT environments materializes the desired AI-led distributed and ubiquitous intelligence in real computing systems. We then need additional effort to establish and deliver the convergence of Edge AI and IoT in formatting the future Intelligent IoT. The Intelligent IoT is envisioned to involve numerous autonomous & distributed computing and AI-driven entities capable of understanding their internal status (context), the status of their environment and peers (collaborative context) and take timely optimized actions to efficiently serve modern applications, like tactile internet and augmented AI-led gaming.","","978-1-6654-9153-2","10.1109/WF-IoT54382.2022.10152042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10152042","Edge AI;Intelligent Edge;Collaborative Context Aware Applications;Distributed AI;Edge AI Infrastructure Modelling;Computational Intelligence","Internet of Things;Edge computing;Artificial intelligence;Cloud computing;Telecommunications;Standardization;Performance evaluation","","","","","IEEE","22 Jun 2023","","","IEEE","IEEE Conferences"
"Investigation on Wireless Communication for Sensors in IoT Cold Chain","N. Dilillo; R. Ferrero; F. Gandino; M. Rebaudengo","Department of Control and Computer Engineering, Politecnico di Torino, Torino, Italy; Department of Control and Computer Engineering, Politecnico di Torino, Torino, Italy; Department of Control and Computer Engineering, Politecnico di Torino, Torino, Italy; Department of Control and Computer Engineering, Politecnico di Torino, Torino, Italy","2023 IEEE Conference on AgriFood Electronics (CAFE)","30 Oct 2023","2023","","","89","93","Thermal monitoring is a key requirement for cold chain management. In this context, the Internet of Things (IoT) offers new opportunities for dense and/or large-scale deployment of sensors, which need to collect data to effectively control the cooling system. Various technologies are used for data transmission. Although Bluetooth is widely exploited for transmitting data in IoT applications, its use in the cold chain management is rare. In this paper, the architecture of an IoT temperature monitoring system is studied and the technological choices of its components are analyzed and compared. In particular, the paper focuses on IoT node boards with Bluetooth, in order to highlight the opportunities of a currently undervalued technology. A theoretical analysis highlights its benefits for the application context and evaluates its suitability for monitoring systems suitable for cold rooms. The theoretical results are supported by an experimental analysis based on the implementation of different systems.","","979-8-3503-2711-3","10.1109/CAFE58535.2023.10291686","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10291686","cold chain;Internet of Things;RFID;Bluetooth;sensors;communications technology;computers and information processing","Temperature sensors;Wireless communication;Temperature measurement;Bluetooth;Thermal management;Sensors;Internet of Things","","","","31","IEEE","30 Oct 2023","","","IEEE","IEEE Conferences"
"IoT Based Control System for Home Automation","A. S. Abhishek; M. Bhasker; A. S. Ponraj","Vellore Institute of Technology, Chennai, India; Vellore Institute of Technology, Chennai, India; Vellore Institute of Technology, Chennai, India","2021 IEEE 2nd International Conference on Technology, Engineering, Management for Societal impact using Marketing, Entrepreneurship and Talent (TEMSMET)","9 May 2022","2021","","","1","5","We are currently living in the Information Age, an era that’s characterized by rapid changes and huge technological developments. Perhaps, two of the most important breakthroughs in this century have been in the field of Automation and Internet of Things. In today’s world we are surrounded by devices that have the ability to access the internet and communicate with other such devices. In this paper the authors propose a method to couple the power of Automation and the functionality of Internet of Things, to control hardware systems and peripherals through a custom-built web server. The embedded controller used in the proposed system is a Raspberry Pi 3b+. This project aims at making home automation and other related automated tasks simple to build, execute, automate and monitor the usage through the World Wide Web. By using the proposed system, it will help the end user to curb electricity costs, by monitoring and saving the units consumed by the different peripherals in the system, and also have a positive impact on the environment. The framework used for implementing the back-end is a micro framework called Flask. Flask enables the user to build and deploy seamless Python based web applications. To demonstrate the real-time working of the proposed system, the Authors have built a small-scale electrical system which is controlled by the Raspberry Pi through a web-server running in the Local Area Network. The software is also programmed to generate a detailed data sheet containing various data such as running time, the consumption rates of these devices, and finally the units consumed by these devices.","","978-1-6654-2778-4","10.1109/TEMSMET53515.2021.9768686","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9768686","Internet of Things;Home Automation;Control system monitoring;Smart home automation;Embedded Systems","Costs;Automation;Smart homes;Control systems;Web servers;Internet of Things;Web sites","","1","","20","IEEE","9 May 2022","","","IEEE","IEEE Conferences"
"Vehicle to Infrastructure in a Semi Dynamic Environment Based on A Novell IoT 7th Layers Framework","S. H. Al-Awami; M. F. Al-Najar","Department of Data Communications and Computer Networks, University of Benghazi, Benghazi, Libya; Department of Data Communications and Computer Networks, University of Benghazi, Benghazi, Libya","2022 International Conference on Engineering & MIS (ICEMIS)","13 Oct 2022","2022","","","1","6","A large number of accidents and the resulting injuries are a common problem all over the world, especially in populated cities, and one of the main causes of deaths is the inability of the police and hospital to know the exact location of the accident. The system aims to reduce death rates from accidents and improve the speed of response in police stations and hospitals to provide the necessary assistance. A survey of relevant works in this paper has been studied and their work is explained. Accordingly, we proposed a framework consisting of multi-layers which is the measurement that all platforms will use. It uses Global System of Mobile (GSM) media access to collect specific information about a car accident on the road, it is used to send a message from the location to the server and then to the police and hospital, based on the Internet of Things (IoT) and uses The Global Positioning System (GPS) to locate the accident. The proposed model is implemented by simulating real situations and different scenarios using the CupCarbon simulator to illustrate the working of the system that simulates and deals with the police and ambulance response to the accident scene. the proposed IoT framework architecture contains of 7th layers that shall be used by developers to implement IoT based applications. This proposed IoT architecture has shown the well interoperability between its different layers, easily to follow up, easily to integrated with intelligent systems and machine learning, and easily to scale into other IoT platforms.","","978-1-6654-5436-0","10.1109/ICEMIS56295.2022.9914013","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9914013","Standard IoT 7th Layers;GPS;CupCarpon;GSM;Internet of Things;Car Accident System","Law enforcement;Hospitals;Machine learning;Servers;Internet of Things;Intelligent systems;Standards","","","","26","IEEE","13 Oct 2022","","","IEEE","IEEE Conferences"
"A Novel Architectural Framework on IoT Ecosystem, Security Aspects and Mechanisms: A Comprehensive Survey","M. Bouzidi; N. Gupta; F. A. Cheikh; A. Shalaginov; M. Derawi","Department of Electronic Systems, Faculty of Information Technology and Electrical Engineering, Norwegian University of Science and Technology, Gjøvik, Norway; Department of Electronic Systems, Faculty of Information Technology and Electrical Engineering, Norwegian University of Science and Technology, Gjøvik, Norway; Department of Computer Science, Faculty of Information Technology and Electrical Engineering, Norwegian University of Science and Technology, Gjøvik, Norway; School of Economics, Innovation and Technology, Kristiania University College, Oslo, Norway; Department of Electronic Systems, Faculty of Information Technology and Electrical Engineering, Norwegian University of Science and Technology, Gjøvik, Norway","IEEE Access","30 Sep 2022","2022","10","","101362","101384","For the past few years, the Internet of Things (IoT) technology continues to not only gain popularity and importance, but also witnesses the true realization of everything being smart. With the advent of the concept of smart everything, IoT has emerged as an area of great potential and incredible growth. An IoT ecosystem centers around innovation perspective which is considered as its fundamental core. Accordingly, IoT enabling technologies such as hardware and software platforms as well as standards become the core of the IoT ecosystem. However, any large-scale technological integration such as the IoT development poses the challenge to ensure secure data transmission. Perhaps, the ubiquitous and the resource-constrained nature of IoT devices and the sensitive and private data being generated by IoT systems make them highly vulnerable to physical and cyber threats. In this paper, we re-define an IoT ecosystem from the core technologies view point. We propose a modified three layer IoT architecture by dividing the perception layer into elementary blocks based on their attributed functions. Enabling technologies, attacks and security countermeasures are classified under each layer of the proposed architecture. Additionally, to give the readers a broader perspective of the research area, we discuss the role of various state-of-the-art emerging technologies in the IoT security. We present the security aspects of the most prominent standards and other recently developed technologies for IoT which might have the potential to form the yet undefined IoT architecture. Among the technologies presented in this article, we give a special interest to one recent technology in IoT domain. This technology is named IQRF that stands for Intelligent Connectivity using Radio Frequency. It is an emerging technology for wireless packet-oriented communication that operates in sub-GHz ISM band (868 MHz) and which is intended for general use where wireless connectivity is needed, either in a mesh network or point-to-point (P2P) configuration. We also highlighted the security aspects implemented in this technology and we compare it with the other already known technologies. Moreover, a detailed discussion on the possible attacks is presented. These attacks are projected on the IoT technologies presented in this article including IQRF. In addition, lightweight security solutions, implemented in these technologies, to counter these threats in the proposed IoT ecosystem architecture are also presented. Lastly, we summarize the survey by listing out some common challenges and the future research directions in this field.","2169-3536","","10.1109/ACCESS.2022.3207472","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9894427","Cyber attacks;IoT architecture;Internet of Things (IoT) ecosystem;IQRF;network security","Internet of Things;Security;Ecosystems;Computer architecture;Wireless sensor networks;Wireless communication;Communication system security;Cyberattack;Network security","","7","","143","CCBY","16 Sep 2022","","","IEEE","IEEE Journals"
"Research on Network Access Control in the Open Internet of Things Environment","P. Zhai; J. He; N. Zhu","Department of Computer Science, Jining University, Jining, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China","2020 IEEE Conference on Telecommunications, Optics and Computer Science (TOCS)","8 Feb 2021","2020","","","80","84","With the continuous deepening of social informatization, the Internet of Things (IoT) devices are used in large quantities. Traditional centralized access control cannot meet the network access control requirements of large-scale IoT environments. Access control is one of the importation technology of information security. This paper establishes the dynamic game access control model which encourages interactive entities to rationally choose strategies expected by the system driven by its own benefits through the designed mechanism. Taking benefits as the driven force, the mechanism rewards the honest nodes and punishes and restrains the non-honest nodes, and then reaches the general state of equalization between entities which meets the goal. Finally, experiments prove that this method is effective in the open Internet of Things, which can greatly enhance the security of data access between IoT sensors, and can effectively protect the privacy of network entity data.","","978-1-7281-8117-2","10.1109/TOCS50858.2020.9339621","National Natural Science Foundation of China(grant numbers:61602456); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9339621","Internet of Things;Game theory;Access control","Access control;Information security;Games;Optics;Telecommunications;Sensors;Internet of Things","","","","24","IEEE","8 Feb 2021","","","IEEE","IEEE Conferences"
"Energy Efficient Offloading Mechanism for Blocks in Blockchain-Assist IoT System","H. Su; J. Zhou; B. Lei; Z. He","School of Computer and Software Engineering, Xihua University, Chengdu, China; School of Computer and Software Engineering, Xihua University, Chengdu, China; School of Computer and Software Engineering, Xihua University, Chengdu, China; School of Computer and Software Engineering, Xihua University, Chengdu, China","2023 11th International Conference on Intelligent Computing and Wireless Optical Communications (ICWOC)","7 Aug 2023","2023","","","123","131","With the development and large-scale application of the Internet of Things (IoT), security issues in IoT systems have received widespread attention. Applying blockchain technology can effectively solve the security risks faced by IoT systems. However, the deployment of blockchain in the IoT system also faces a series of challenges. For example, fast and large-scale data in the IoTs must be stored on the blockchain and maintained by some IoT devices, but constrained IoT devices usually cannot store the complete blockchain. In this regard, we design a strategy for deploying blockchain in the IoT system with limited resources. Specifically, we propose an energy-efficient block offloading strategy to release storage space when the storage resources of IoT devices are exhausted in the long-term dimension. In this process, the offloading of blocks is closely related to the subsequent query process, and a large amount of energy consumption accompanies it. We design a corresponding offloading algorithm by collaboratively considering the block offloading process and the block query process, which can minimize the average energy in the IoT system while satisfying the block storage and data query services. Simulation results show that our proposed offloading algorithm can effectively reduce the total average energy consumption of the system.","","979-8-3503-2179-1","10.1109/ICWOC57905.2023.10199760","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10199760","block offloading;energy consumption;Successive Convex Approximation (SCA);Internet-of-Things (IoT) system","Wireless communication;Energy consumption;Query processing;Simulation;Energy efficiency;Optical fiber communication;Blockchains","","","","13","IEEE","7 Aug 2023","","","IEEE","IEEE Conferences"
"Accumulator-Based 16-Bit Processor for Wireless Sensor Nodes","T. -K. Dang; K. -D. Nguyen; C. -K. Pham; T. -T. Hoang","Department of Computer and Network Engineering, The University of Electro-Communications, Chofu, Japan; Department of Computer and Network Engineering, The University of Electro-Communications, Chofu, Japan; Department of Computer and Network Engineering, The University of Electro-Communications, Chofu, Japan; Department of Computer and Network Engineering, The University of Electro-Communications, Chofu, Japan","IEEE Transactions on Circuits and Systems II: Express Briefs","","2024","PP","99","1","1","Wireless sensor network (WSN) has emerged as a significant application among Internet-of-Things (IoT) applications. Energy harvesting systems have a high potential for deployment in WSN to monitor natural environments and industrial equipment. With limited resources, including power and chip area, an energy harvesting system demands thorough resource allocation to several circuits like a control system, sensors, and a transceiver. Also, such systems are required to function with low-peak power to adapt to the fluctuation of harvested energy. This research presents a System-on-Chip (SoC) featuring a tiny 16-bit processor for batteryless systems. The processor is implemented using an accumulator-based instruction set architecture, realizing a small-scale design. The SoC integrates the 16-bit processor, two static random-access-memory blocks (1KB and 512B) for instruction, and data memory and peripherals for communication. It is fabricated on general-purpose CMOS 180nm and Silicon On-Thin-Buried Oxide (SOTB) 65nm process. Implemented results show the total area cost of the SoC is 241,036μm2 and 52,558μm2 on CMOS 180nm and SOTB. The SoC design achieves low-peak power consumption at 0.6μW and on the CMOS 180nm chip. Power consumption can decline further with a key technique in varying the back body bias by SOTB technology to 21.56nW. The minimum energy point is observed to be 10.38μW/MHz and 0.64μW/MHz in CMOS 180nm and SOTB 65nm chips, respectively. The small-scale features in size and power dissipation make the proposed SoC suitable for energy harvesting applications.","1558-3791","","10.1109/TCSII.2024.3366776","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10438843","Wireless Sensor Network;Internet-of-Things;low-power;System-on-Chip","Internet of Things;System-on-chip;Power demand;Energy harvesting;Pipelines;Temperature sensors;Registers","","","","","IEEE","16 Feb 2024","","","IEEE","IEEE Early Access Articles"
"Optimal Allocation of Real Time Measurement in Distribution Network Considering Network Observability","Z. Wu; D. Fan; K. Li; Z. Zhang","School of Electrical Engineering, Beijing Jiaotong University, Beijing, China; School of Electrical Engineering, Beijing Jiaotong University, Beijing, China; State Grid Henan Maintenance Company, Zhengzhou, China; School of Electrical Engineering, Beijing Jiaotong University, Beijing, China","2022 5th International Conference on Energy, Electrical and Power Engineering (CEEPE)","1 Jun 2022","2022","","","618","623","Power Internet of things measurement terminal device is a new type of information distribution network equipment. If all nodes in the distribution system are equipped with measuring devices, the state estimation problem will be greatly simplified, but this configuration method is difficult to achieve due to economic constraints, so it is necessary to study the optimal distribution scheme of measuring devices. This paper presents an optimized distribution scheme for new distribution measurement terminals, establishes the mathematical model of terminal distribution based on 0-1 integer programming, and formulates the principle and process of node configuration based on tree graph search technology. Based on the measurement characteristics of the Internet of things measurement terminal device applied to power distribution, the calculation methods to make the zero injection nodes and connected nodes observable in the network are deduced, and the terminal distribution methods suitable for large and small-scale systems are proposed. In order to meet the requirements of complete observability and economy of power distribution system, the proposed two methods are configured and compared in different common network architectures.","","978-1-6654-7905-9","10.1109/CEEPE55110.2022.9783368","Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9783368","optimize the distribution of points;measurement terminal;economy","Integer programming;Power measurement;Tree graphs;Redundancy;Power distribution;Distribution networks;Network architecture","","","","10","IEEE","1 Jun 2022","","","IEEE","IEEE Conferences"
"Machine Learning based framework to predict the Network Usage in Smart Parking Applications","A. Kumar; B. A. Mohan; G. Patil; K. B. Surekha","Department of ISE, BMSIT & M, Yelahanka, India; Department of ISE, BMSIT & M, Yelahanka, India; Department of ISE, BMSIT & M, Yelahanka, India; Department of ISE, BMSIT & M, Yelahanka, India","2022 4th International Conference on Circuits, Control, Communication and Computing (I4C)","7 Mar 2023","2022","","","432","435","The automotive industry is growing daily, as many people prefer personal vehicles for many reasons. Due to the increased usage of private cars, especially in growing cities, parking space availability has become short and poses a big challenge. It also leads to further cascaded issues like traffic congestion, wasting time in finding free space, polluting the environment, and especially unnecessary wastage of fuel. Therefore inventing a smart parking system has become the need of the hour. Many researchers have attempted to design solutions to this issue by utilizing state-of-the-art technology in prominent areas like Wireless Sensor Networks, Cloud Computing, and Internet of Things. However, there is still scope for improvement in smart parking system performance. In this research work, we are simulating a smart parking system to get the parameters like network usage, transmission time, number of areas, and number of cameras used. The simulator works better for a small number of areas, but for larger-scale simulations, it takes more time. Hence, we propose a framework that can predict/analyze the performance of smart parking systems at an enormous scale using an ML algorithm. The experimental results show that predicting network usage of large-scale smart parking systems using an ML framework is 1500x faster than the simulation time of the CloudSim simulator.","2381-4128","979-8-3503-9747-5","10.1109/I4C57141.2022.10057657","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10057657","Cloud computing;CloudSim;Network usage;Machine Learning;Regression;Decision Tree","Cloud computing;Wireless sensor networks;Machine learning algorithms;System performance;Urban areas;Machine learning;Prediction algorithms","","","","18","IEEE","7 Mar 2023","","","IEEE","IEEE Conferences"
"Towards a Scalable and Trustworthy Blockchain: IoT Use Case","H. Moudoud; S. Cherkaoui; L. Khoukhi","Department of Electrical and Computer Engineering, Université de Sherbrooke, Canada; Department of Electrical and Computer Engineering, Université de Sherbrooke, Canada; GREYC CNRS, ENSICAEN, Normandie University, France","ICC 2021 - IEEE International Conference on Communications","6 Aug 2021","2021","","","1","6","Recently, blockchain has gained momentum as a novel technology that gives rise to a plethora of new decentralized applications (e.g., Internet of Things (IoT)). However, its integration with the IoT is still facing several problems (e.g., scalability, flexibility). Provisioning resources to enable a large number of connected IoT devices implies having a scalable and flexible blockchain. To address these issues, we propose a scalable and trustworthy blockchain (STB) architecture that is suitable for the IoT; which uses blockchain sharding and oracles to establish trust among unreliable IoT devices in a fully distributed and trustworthy manner. In particular, we design a Peer-To-Peer oracle network that ensures data reliability, scalability, flexibility, and trustworthiness. Furthermore, we introduce a new lightweight consensus algorithm that scales the blockchain dramatically while ensuring the interoperability among participants of the blockchain. The results show that our proposed STB architecture achieves flexibility, efficiency, and scalability making it a promising solution that is suitable for the IoT context.","1938-1883","978-1-7281-7122-7","10.1109/ICC42927.2021.9500535","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9500535","Blockchain;Internet of Things (IoT);Oracle;Sharding;Consensus","Scalability;Simulation;Conferences;Consensus algorithm;Reliability engineering;Blockchains;Peer-to-peer computing","","13","","24","IEEE","6 Aug 2021","","","IEEE","IEEE Conferences"
"Privacy-Preserved Computation Offloading Scheme in 5G enabled IoT Based on Smart blockchain","J. Wang; Z. Lu; B. Mao; L. Song","School of Electronic Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Electronic Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Electronic Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of economics and management, Beijing Information Science and Technology University, Beijing, China","2022 IEEE 10th International Conference on Computer Science and Network Technology (ICCSNT)","19 Dec 2022","2022","","","94","98","To effectively utilize multiple 5G resources (such as computing, communication, storage and service resources), provide low delay offload decisions, and meet data privacy, we propose a framework to integrate blockchain, federated learning (FL), and mobile-edge computing (MEC) into the Internet of Things (IoT) system. However, the insufficient throughput of the blockchain may hinder the efficiency of the overall system. At the same time, due to the dynamic characteristics of IoT and MEC systems, the whole framework involves high-dimensional features and large-scale actions, and the optimization problem is very complex and challenging. Therefore, we design the whole system flow process as a Markov decision process (MDP) sequence by defining state space, action space, and reward function. The deep deterministic policy gradient (DDPG) algorithm is adopted to dynamically select and adjust action to ensure the maximum long-term return of the system. Finally, the simulation results show that our scheme can significantly improve the performance of system.","2690-5892","978-1-6654-7061-2","10.1109/ICCSNT56096.2022.9972878","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9972878","IoT;Task-Offloading;MEC;federated learning;blockchain;DDPG algorithm","Data privacy;Federated learning;5G mobile communication;Heuristic algorithms;Simulation;Throughput;Blockchains","","","","11","IEEE","19 Dec 2022","","","IEEE","IEEE Conferences"
"Systematically Quantifying IoT Privacy Leakage in Mobile Networks","S. Hui; Z. Wang; X. Hou; X. Wang; H. Wang; Y. Li; D. Jin","Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China; Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China; Department of Electrical and Computer Engineering, University of California at San Diego, San Diego, CA, USA; Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China; Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China; Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China; Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China","IEEE Internet of Things Journal","23 Apr 2021","2021","8","9","7115","7125","Privacy leakage of Internet of Things (IoT) has become a great challenge with the popularity of IoT services through mobile networks, such as smart homes, wearables, and healthcare. While previous work summarized general structures to analyze IoT privacy and provide case studies of specific devices or scenarios, it is still challenging to conduct a comprehensive and systematic quantification study of large-scale IoT privacy leakage in real world. To combine systematic analyses with real-world measurements, we provide a method to quantify IoT privacy leakage on a large-scale mobile network traffic data set containing 47651 IoT devices. We generate privacy fingerprints and attribute them to a privacy quantification framework. The framework is constructed based on the semantics of multiple privacy sensitive markers selected from the traffic along with the involved network entity types in IoT (i.e., user, device, and platform), and the fingerprints are generated from sensitive information extracted in the traffic via their markers. Our quantification shows that IoT users, devices, and platforms have considerable risks, respectively. Moreover, IoT devices have a larger scale of privacy leakage than users and platforms, and they perform different daily patterns on privacy leakage following their working conditions. In addition, we present three case studies on the leakage of location information, application calling, and voice service, which illustrate that a third party can profile a network entity in both cyberspace and physical space.","2327-4662","","10.1109/JIOT.2020.3038639","Beijing Natural Science Foundation(grant numbers:L182038); The National Key Research and Development Program of China(grant numbers:2018YFB1800804); National Natural Science Foundation of China(grant numbers:U1936217,61971267,61972223,61941117,61861136003); Research Fund of Tsinghua University - Tencent Joint Laboratory for Internet Innovation Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9261361","Internet of Things (IoT);mobile network;privacy;security","Internet of Things;Privacy;Data privacy;Security;Systematics;Smart homes;Cyberspace","","4","","44","IEEE","17 Nov 2020","","","IEEE","IEEE Journals"
"Smart Planter: A Controlled Environment Agriculture System Prioritizing Usability for Urban Home Owner","K. Teoh; S. Ng","Faculty of Arts and Science, International University of Malaya-Wales, Kuala Lumpur, Malaysia; Faculty of Arts and Science, International University of Malaya-Wales, Kuala Lumpur, Malaysia","2021 3rd International Conference on Robotics and Computer Vision (ICRCV)","28 Sep 2021","2021","","","86","90","Controlled Environment Agriculture (CEA) in the urban setting are often conducted on the medium to large scale. These CEA setups are often touted as a potential solution to the food desert problem, and as a method to reduce the distance from the farm to plate. Sometimes, the CEA setup could act as a piece of Green Architecture in the city, as is the case for Rooftop Gardens. This study proposed an IoT (Internet of Things) enabled agricultural setups called the Smart Planter, to be comfortably used by home owners that may have problems with growing edible food and herbs within their homes. The system design of the Smart Planter maintains several operational functions and automation from the larger CEA setups, bringing to the urban home owners the opportunity to grow from produce. The Smart Planter intended to bring to the urban home owners the benefits of a recreational activity, an educational experience and ease of access to nutrition. The result of this study is a physical model of the automated system that can detect and regulate the environment.","","978-1-6654-3628-1","10.1109/ICRCV52986.2021.9546959","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9546959","Controlled Environment Agriculture (CEA);Internet of Things (IoT);Cyber physical system;sensors and actuators","Urban areas;Green products;Robot sensing systems;Control systems;Agriculture;Sensor systems;Internet of Things","","4","","9","IEEE","28 Sep 2021","","","IEEE","IEEE Conferences"
"IIoDT: Industrial Internet of Digital Twins for Hierarchical Asset Management in Manufacturing","B. Sicard; Q. Butler; P. Kosierb; Y. Wu; Y. Ziada; S. A. Gadsden","Department of Mechanical Engineering, McMaster University, Hamilton, Ontario, Canada; Department of Mechanical Engineering, McMaster University, Hamilton, Ontario, Canada; Department of Mechanical Engineering, McMaster University, Hamilton, Ontario, Canada; Department of Mechanical Engineering, McMaster University, Hamilton, Ontario, Canada; Global Manufacturing Engineering, Ford Motor Company, Livonia, Michigan, USA; Department of Mechanical Engineering, McMaster University, Hamilton, Ontario, Canada","2023 IEEE International Conference on Artificial Intelligence, Blockchain, and Internet of Things (AIBThings)","30 Oct 2023","2023","","","1","5","The Internet of Things (IoT) and digital twins (DT) are emerging technologies in the industry 4.0 landscape. Both technologies offer the capabilities of collecting and analyzing large quantities of data and utilizing this data for intelligent decision-making. These technologies together form the Industrial Internet of Digital Twins (IIoDT). Currently most works on DTs in literature focus on a single level of the manufacturing hierarchy without considering the interactions among levels. It is important to understand how these different scales of DTs can interact together in order to create a scalable system. The various assets in a manufacturing environment exist in a hierarchy with information flowing up from the lowest level to the highest. Additionally, information flows from various levels to a central database and data processing center. DTs connected in an IoT network can provide various services for asset management in manufacturing such as condition monitoring, health assessment, simulation, forecasting, and visualization. It is important to understand the various capabilities and interactions between the various DTs. This work examined DTs at multiple levels along the manufacturing hierarchy, what value they can provide, examples in the literature of DTs at each level, and how they can interact with other DTs along the hierarchy. This IIoDT system can be used to analyze both vertically along the hierarchy and horizontally across assets of the same level. This framework can help bridge link the various levels of DTs that exist to better integrate them in a manufacturing system.","","979-8-3503-2234-7","10.1109/AIBThings58340.2023.10292454","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10292454","asset management;digital twin;internet of things;manufacturing","Decision making;Manufacturing;Digital twins;Asset management;Mechanical products;Machine tools;Feeds;Forecasting;Industrial Internet of Things;Manufacturing systems","","","","23","IEEE","30 Oct 2023","","","IEEE","IEEE Conferences"
"An Efficient Data Communication Framework for Named Data Networking in IoT-Edge Ecosystem","R. K. Dudeja; R. Singh Bali; G. S. Aujla","Computer Science & Engineering Department, Chandigarh University, Mohali, Punjab, India; Computer Science & Engineering Department, Chandigarh University, Mohali, Punjab, India; Department of Computer Science, Durham University, Durham, UK","2021 IEEE Globecom Workshops (GC Wkshps)","24 Jan 2022","2021","","","1","6","Internet of Things (IoT) has evolved as a revolutionary technology that allows smart devices and sensors to monitor the environment (like smart agriculture, fleet management, smart healthcare, intelligent transportation, etc) wherein they are deployed. Thus, a huge volume of multidimensional data is generated that must be processed promptly for the success of the underlying IoT applications. However, the traditional communication technologies (like TCP/IP) are rigid and limit the scalability of large-scale IoT deployments. Thus, a data-centric framework is required to provide flexible connectivity and data availability for IoT applications. Named Data Network (NDN) is a data-centric network paradigm that does not rely on conventional IP-based technologies and can provide answers to several challenges of IoT applications that are otherwise not resolved by conventional communication technologies. However, it requires an efficient mechanism to handle the large volume of data and store it on the cache of the NDN node. Edge Computing provides the compute (and caching) capability for handling IoT data at a location closer to its origin. Thus, the idea is to utilize the benefits of edge computing and NDN to design an efficient data communication framework. The proposed framework utilizes the edge computing nodes as a cluster head for numerous IoT devices deployed in a specific IoT application (like healthcare). It works as two subsystems, a) a sensor data processing and recommendation system, and b) an NDN-based data storage and delivery system. It was validated using ndnSIM for a hybrid topology concerning the delay, throughput, and packet rate.","","978-1-6654-2390-8","10.1109/GCWkshps52748.2021.9681976","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9681976","Internet of Things;Named Data Network;Edge Computing;Cluster Head;Periodic Data","Transportation;Bandwidth;Medical services;TCPIP;Throughput;Delays;Topology","","1","","17","IEEE","24 Jan 2022","","","IEEE","IEEE Conferences"
"An Integrated Collaborative Filtering Framework With Location-Aware Graph Embedding in Intelligent Internet of Things Systems","Y. Sun; W. Tan; L. Huang; N. Xie; L. Ruan; L. Da Xu","Anhui Engineering Laboratory of Geo-information Smart Sensing and Services, Chuzhou University, Chuzhou, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; Key Laboratory of Virtual Geographic Environment, Nanjing Normal University, Nanjing, China; Department of Information Technology and Decision Sciences, Old Dominion University, Norfolk, VA, USA","IEEE Transactions on Aerospace and Electronic Systems","5 Dec 2022","2022","58","6","5089","5104","Reliable Internet of Things (IoT) service discovery is a significant task in intelligent service-oriented IoT systems. Collaborative filtering (CF) turns out to be an effective solution to IoT service discovery. However, the traditional CF framework is facing the following challenges: inefficiency in learning the high-order interactions between users and IoT services and ineffectively making use of geographical location information. Moreover, deploying a CF framework in real-world distributed IoT systems poses another significant challenge in terms of reliability assurance and privacy protection. For bridging this gap, we propose an innovative integrated collaborative filtering framework (ICF) with incorporating the location-aware quality of IoT services into a heterogeneous graph embedding model. Meanwhile, a Geohash-based privacy-preservation mechanism is introduced to encoding the location information into a short string for protecting the sensitive location information. The proposed ICF framework is an integrated architecture combining advanced graph embedding learning and heterogeneous side information. And a joint objective optimization function is designed in the graph embedding learning to qualify automatic IoT service features. In this way, the hidden user-service interaction information and location-aware quality semantic features can be explored in an effective and reliable way. Furthermore, the learned location-aware quality embedding vector is incorporated to discover the reliable services among all IoT services with the mini-batch online clustering-based CF algorithm. The experimental findings illustrate the significant efficacy and reliability of our proposed ICF framework in large scale IoT service discovery scenarios.","1557-9603","","10.1109/TAES.2022.3213631","National Natural Science Foundation of China(grant numbers:61672022); Natural Science Foundation of Anhui Province(grant numbers:1908085MF191); University Outstanding Talent Cultivation Program of Anhui Province(grant numbers:gxgnfx20200102); Key Program of University Natural Science Foundation of Anhui Province(grant numbers:KJ2020A0704); Key Program of Natural Science Foundation of Chuzhou University(grant numbers:2022XJZD06); University Natural Science Foundation of Jiangsu Province(grant numbers:18KJB520008); Foundation of Anhui Province Key Laboratory of Physical Geographic Environment; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9916118","Graph network embedding;integration information systems;intelligent systems;Internet of Things (IoT);reliable IoT service discovery","Internet of Things;Reliability;Semantics;Security;Task analysis;Privacy;Collaborative filtering","","","","52","IEEE","11 Oct 2022","","","IEEE","IEEE Journals"
"An optimal workflow scheduling method in cloud-fog computing using three-objective Harris-Hawks algorithm","A. Montazerolghaem; M. Khosravi; F. Rezaee; M. R. Khayyambashi","Department of Computer Engineering, University of Isfahan, Isfahan, Iran; Department of Computer Engineering, University of Isfahan, Isfahan, Iran; Department of Computer Engineering, University of Isfahan, Isfahan, Iran; Department of Computer Engineering, University of Isfahan, Isfahan, Iran","2022 12th International Conference on Computer and Knowledge Engineering (ICCKE)","29 Nov 2022","2022","","","300","306","Today, the Internet of Things (IoT) use to collect data by sensors, and store and process them. As the IoT has limited processing and computing power, we are turning to integration of cloud and IoT. Cloud computing processes large data at high speed, but sending this large data requires a lot of bandwidth. Therefore, we use fog computing, which is close to IoT devices. In this case, the delay is reduced. Both cloud and fog computing are used to increasing performance of IoT. Job scheduling of IoT workflow requests based on cloud-fog computing plays a key role in responding to these requests. Job scheduling in order to reduce makespan time, is very important in realtime system. Also, one way to improve system performance is to reduce energy consumption. In this article, three-objective Harris Hawks Optimizer (HHO) scheduling algorithm is proposed in order to reduce makespan time, energy consumption and increase reliability. Also, dynamic voltage frequency scaling (DVFS) has been used to reduce energy consumption, which reduces frequency of the processor. Then HHO is compared with other algorithms such as Whale Optimization Algorithm (WOA), Firefly Algorithm (FA) and Particle Swarm Optimization (PSO) and proposed algorithm shows better performance on experimental data. The proposed method has achieved an average reliability of 83%, energy consumption of 14.95 KJ, and makespan of 272.5 seconds.","2643-279X","978-1-6654-7613-3","10.1109/ICCKE57176.2022.9960123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9960123","Internet of Things;Cloud-Fog computing;Harris hawks optimization algorithm;Workflow scheduling;DVFS","Energy consumption;Cloud computing;Heuristic algorithms;Whales;Voltage;Scheduling;Whale optimization algorithms","","2","","32","IEEE","29 Nov 2022","","","IEEE","IEEE Conferences"
"Research on Key Management Method for New Energy Power System Interconnection Terminals","Y. Feng; F. Zhai; X. Liang; L. Zhang; Y. Fang; X. Cai","China Electric Power Research Institute, Beijing, China; China Electric Power Research Institute, Beijing, China; China Electric Power Research Institute, Beijing, China; Information Communication Branch of State Grid Anhui Electric Power Co., Ltd, Hefei, China; Information Communication Branch of State Grid Anhui Electric Power Co., Ltd, Hefei, China; State Grid Anhui Electric Power Co., Ltd, Hefei, China","2023 3rd International Conference on Intelligent Power and Systems (ICIPS)","1 Feb 2024","2023","","","650","654","With the rapid development of new power systems, the power grid is evolving towards a more open, integrated, and intelligent direction of the power Internet of Things, introducing a large number of power IoT terminals for data collection and state perception. The number of IoT terminals is huge, and sensors are the main equipment types, which are relatively limited in storage, computing, and communication resources. Currently, digital certificate technology is the core means to achieve secure access to IoT terminals. However, traditional digital certificate technology is mostly based on foreign algorithms and standards, and highly relies on third-party CA performance. It is difficult to meet the ultra-high concurrent secure access needs of current live network resource limited sensing terminals in terms of autonomous controllability, resource occupancy, and efficiency performance. Therefore, based on domestic cryptographic algorithms, this article designs a secret key management method for new power system IoT terminals, which is used for identification management of IoT terminals in different application stages. This saves the process of managing, transmitting, and verifying digital certificates, and is more suitable for massive IoT terminals. The large-scale application of identification encryption algorithms in massive power IoT terminals has effectively improved the application efficiency of digital certificates in power perception terminals.","","979-8-3503-2869-1","10.1109/ICIPS59254.2023.10404354","State Grid Corporation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10404354","secret key;secret key distribution;new power systems;IoT terminals","Power system interconnection;Public key;Production;Power grids;Internet of Things;Object recognition;Standards","","","","9","IEEE","1 Feb 2024","","","IEEE","IEEE Conferences"
"Complementing IoT Services Using Software-Defined Information Centric Networks: A Comprehensive Survey","W. Rafique; A. S. Hafid; S. Cherkaoui","Department of Computer Science and Operations Research, University of Montreal, Montreal, Canada; Department of Computer Science and Operations Research, University of Montreal, Montreal, Canada; Department of Electrical and Computer Engineering, University of Sherbrooke, Sherbrooke, Canada","IEEE Internet of Things Journal","18 Nov 2022","2022","9","23","23545","23569","IoT connects a large number of physical objects with the Internet that capture and exchange real-time information for service provisioning. Traditional network management schemes face challenges to manage vast amounts of network traffic generated by IoT services. Software-defined networking (SDN) and information-centric networking (ICN) are two complementary technologies that could be integrated to solve the challenges of different aspects of IoT service provisioning. ICN offers a clean-slate design to accommodate continuously increasing network traffic by considering content as a network primitive. It provides a novel solution for information propagation and delivery for large-scale IoT services. On the other hand, SDN allocates overall network management responsibilities to a central controller, where network elements act merely as traffic forwarding components. An SDN-enabled network supports ICN without deploying ICN-capable hardware. Therefore, the integration of SDN and ICN provides benefits for large-scale IoT services. This article provides a comprehensive survey on software-defined information-centric Internet of Things (SDIC-IoT) for IoT service provisioning. We present critical enabling technologies of SDIC-IoT, discuss its architecture, and describe its benefits for IoT service provisioning. We elaborate on key IoT service provisioning requirements and discuss how SDIC-IoT supports different aspects of IoT services. We define different taxonomies of SDIC-IoT literature based on various performance parameters. Furthermore, we extensively discuss different use cases, synergies, and advances to realize the SDIC-IoT concept. Finally, we present current challenges and future research directions of IoT service provisioning using SDIC-IoT.","2327-4662","","10.1109/JIOT.2022.3206146","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9888774","Information-centric networking (ICN);Internet of Things (IoT);service provisioning;software-defined networking (SDN)","Internet of Things;Real-time systems;Software defined networking;Faces;Temperature sensors;Telecommunication traffic;Taxonomy","","8","","156","IEEE","13 Sep 2022","","","IEEE","IEEE Journals"
"eMUD: Enhanced Manufacturer Usage Description for IoT Botnets Prevention on Home WiFi Routers","S. M. Sajjad; M. Yousaf; H. Afzal; M. R. Mufti","Riphah Institute of Systems Engineering, Riphah International University, Islamabad, Pakistan; Riphah Institute of Systems Engineering, Riphah International University, Islamabad, Pakistan; Department of Computer Science, Bahauddin Zakariya University, Multan, Pakistan; Department of Computer Science, COMSATS University Islamabad, Islamabad, Pakistan","IEEE Access","17 Sep 2020","2020","8","","164200","164213","Distributed Denial of Service (DDoS) attacks have caused significant disruptions in the operations of Internet-based services. These DDoS attacks use large scale botnets, which often exploit millions of compromised Internet of Things (IoT) devices worldwide. IoT devices are traditionally less secure and are easy to be exploited. The extent of these exploitations has increased after the publication of the Mirai botnet source code on GitHub that provided a foundation for the attackers to develop and launch Mirai botnet variants. The Internet Engineering Task Force (IETF) proposed RFC 8520 Manufacturer Usage Description (MUD) so that an IoT device can convey to the network the level of network access it requires to accomplish its standard functionality. Though MUD is a promising effort, there is a need to evaluate its effectiveness, identify its limitations, and enhance its architecture to overcome its weakness and improve its efficiency. The latest Mirai variant malware is exploiting vulnerabilities of Internet of Things devices. As MUD does not consider identifying and patching vulnerabilities present in the device before the issuance of the MUD profile, a device can be compromised even in the presence of the Manufacturer Usage Description profile by exploiting either the configuration vulnerabilities or firmware vulnerabilities present in the device. This paper presents an evaluation study of the Manufacturer Usage Description (MUD), identifies its weaknesses, and proposed enhancements in its architecture. This research proposed a mechanism for identifying and eliminating the configuration vulnerabilities before creating the MUD profile for a device to minimize the attack surface. This research adopts the OWASP firmware testing methodology for discovering vulnerabilities in the firmware of WiFi home routers. The device is allowed to request the MUD profile only if the identified firmware vulnerabilities are low. The identified firmware vulnerabilities are patched in case the score of the identified firmware vulnerabilities is moderate or high. The device is allowed to request the MUD profile after the vulnerabilities are patched. The firmware vulnerabilities are shared with other peers using blockchain smart contracts. There is a possibility that the MUD URL might be pointing to a corrupted or malicious MUD profile hosted at the attacker file server due to the absence of an authentication mechanism in the MUD process. This research also proposed an authentication mechanism for device MUD profile, MUD file generator, and MUD file server. Implementation results show that proposed enhancements improve the security services provided by the Manufacturer Usage Description (MUD).","2169-3536","","10.1109/ACCESS.2020.3022272","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9187209","Authentication;blockchain;botnet prevention;DDoS;ethereum virtual machine;hyperledger;the IoT;Mirai;manufacturer usage description;OWASP;vulnerabilities","Multiuser detection;Wireless fidelity;Servers;Home automation;Malware;Botnet;Security","","15","","49","CCBY","7 Sep 2020","","","IEEE","IEEE Journals"
"BCGeo: Blockchain-Assisted Geospatial Web Service for Smart Healthcare System","S. R. Mallick; R. K. Lenka; V. Goswami; S. Sharma; A. K. Dalai; H. Das; R. K. Barik","Department of Computer Science and Engineering, International Institute of Information Technology, Bhubaneswar, India; Department of Computer Science and Engineering, International Institute of Information Technology, Bhubaneswar, India; School of Computer Applications, KIIT Deemed to be University, Bhubaneswar, India; Department of Computer Science and Engineering, Guru Ghasidas Vishwavidhalaya, Chhattisgarh, Bilaspur, India; School of Computer Science and Engineering, Vellore Institute of Technology--AP University, Amaravati, India; School of Computer Engineering, KIIT Deemed to be University, Bhubaneswar, India; School of Computer Applications, KIIT Deemed to be University, Bhubaneswar, India","IEEE Access","19 Jun 2023","2023","11","","58610","58623","Most recent research on healthcare systems has focused on integrating the Internet of Things (IoT), Blockchain technology, and cloud computing to enhance the performance of IoT devices with limited resource availability, create smart healthcare platforms, and offer patients the best possible healthcare service. Modern healthcare systems use large-scale sensor devices to address many challenges brought on by the conventional delivery of healthcare services. Most studies have lately identified data collection, massive data processing, geolocating, access management, device prioritization, and storing as primary issues in most IoT healthcare systems. Decentralization, privacy, security, scalability, trust, anonymity, and building geospatial-based intelligent healthcare systems for patient care are significant difficulties that most healthcare systems today must overcome. Blockchain technology in healthcare platforms is noteworthy and innovative since it opens platforms for data privacy, anonymity, and validity through the consensus process. In this work, we proposed a novel decentralized Blockchain-enabled geospatial service architecture for smart healthcare systems called BCGeo. The proposed framework offers an online geospatial healthcare service for residents of Bhubaneswar, a city in India, who are newcomers to the city and are less familiar with its local healthcare organizations. An analytical queueing method prioritizes serving Critical patients more than other patients. In contrast to previously proposed frameworks, the proposed framework includes immutability, scalability, geospatial mapping, patient prioritizing, and decentralized privacy protection policies for addressing the technical challenges in most of the current healthcare systems. Additionally, it explains the performance analysis of BCGeo. It includes graphs showing the various possible outcomes of arithmetic operations, performance measurement, and experimental results on the proposed architecture.","2169-3536","","10.1109/ACCESS.2023.3283776","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10145459","Blockchain;geospatial web services;medical data;healthcare;queueing model;IoT","Medical services;Blockchains;Internet of Things;Geospatial analysis;Hospitals;Urban areas;Privacy","","5","","50","CCBYNCND","7 Jun 2023","","","IEEE","IEEE Journals"
"Data Quality Estimation in a Smart City's Air Quality Monitoring IoT Application","J. H. Buelvas P.; F. E. Avila B.; N. Gaviria G.; D. A. Munera R.","Faculty of Engineering, Universidad de Antioquia, Medellin, Colombia; Faculty of Engineering, Universidad de Antioquia, Medellin, Colombia; Faculty of Engineering, Universidad de Antioquia, Medellin, Colombia; Faculty of Engineering, Universidad de Antioquia, Medellin, Colombia","2021 2nd Sustainable Cities Latin America Conference (SCLA)","23 Sep 2021","2021","","","1","6","With the upcoming growth of the Internet of Things (IoT), which is translated into millions of interconnected devices reporting a high volume of data coming from heterogeneous sources (sensors), it is necessary to assess the confidence of data in order to provide the system with trustable information that can be used to get real insights from the physical world and thus take proper decisions or actions over it. Having in mind that ensuring data quality is key to ease user engagement, acceptance of IoT services and large scale deployments [1], a new critical issue arises which is related to the quality of the data in IoT. Some applications might have a different definitions and indicators for data quality (DQ) and thus different threshold for acceptance of the data. In this work, we explore a smart city application in the field of environmental monitoring and identify the related DQ indicators that apply within this context. Our approach is evaluated over a real dataset retrieved from SIATA's citizen scientist low-cost sensor network, an air quality monitoring system that can be encompassed within the IoT paradigm and that is composed by more than 200 nodes deployed all over the Aburra Valley in Antioquia, Colombia. The results show that feasibility assessing data quality and importance data quality awareness for an IoT application, as a tool for it to take proper actions on the real world. Our approach is evaluated over a real dataset retrieved from SIATA's citizen scientist low-cost sensor network, an air quality monitoring system that can be encompassed within the IoT paradigm and that is composed by more than 200 nodes deployed all over the Aburra Valley in Antioquia, Colombia. The results show that feasibility assessing data quality and importance data quality awareness for an IoT application, as a tool for it to take proper actions on the real world.","","978-1-6654-3768-4","10.1109/SCLA53004.2021.9540154","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9540154","Smart City;Internet of Things;Air Quality;Environmental Monitoring;Low-cost Sensor;Data Quality","Smart cities;Data integrity;Estimation;Tools;Air quality;Sensor systems;Internet of Things","","4","","14","IEEE","23 Sep 2021","","","IEEE","IEEE Conferences"
"Large-Scale Multiobjective Federated Neuroevolution for Privacy and Security in the Internet of Things","X. Liu; J. Zhao; J. Li; D. Xu; S. Tian; B. Cao","Hebei University of Technology, China; Hebei University of Technology, China; Hebei University of Technology, China; Hebei University of Technology, China; Hebei University of Technology, China; Hebei University of Technology, China","IEEE Internet of Things Magazine","13 Sep 2022","2022","5","2","74","77","With the development of communication techonologies, Internet of Things (IoT) devices will be deployed in more and more places and generate large amounts of data. The corresponding analysis of these newly available data will greatly improve our daily lives. However, these IoT devices can be attacked. Traditional intrusion detection systems (lDSs) usually use a centralized approach to transmit data to the cloud or a central server for analysis. This method has a great risk of privacy leakage. Federated learning (FL) is an excellent distributed learning stategy, which will have outstanding performance in preventing privacy leakage for lDSs in IoT. However, the FL-driven IDS is still in the infancy stage and needs further exploration. Therefore, we propose a large-scale multiobjective federated neuroevolution framework based on a deep fuzzy rough convolution neural network for IoT privacy and security.","2576-3199","","10.1109/IOTM.001.2100179","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9889264","","Performance evaluation;Privacy;Convolutional neural networks;Neural networks;Training data;Intrusion detection;Computer architecture;Security","","","","12","IEEE","13 Sep 2022","","","IEEE","IEEE Magazines"
"Design and Implementation of Raspberry House: An IoT Security Framework","W. Fei; H. Ohno; S. Sampalli","Faculty of Computer Science, Dalhousie University, Halifax, Canada; Information Media Center, Kanazawa University, Kanazawa, Japan; Faculty of Computer Science, Dalhousie University, Halifax, Canada","2020 IEEE International Conference on Internet of Things and Intelligence System (IoTaIS)","23 Feb 2021","2021","","","1","7","The rising popularity of the Internet of Things (IoT) on a global scale has led to an increase in cyber threats, and researchers are paying more attention to its security issues. So far, research on IoT security has focused on large-scale devices, but there is relatively less research on the security of small IoT devices. Therefore, our objective is to mainly study how to make the operation of small IoT devices safer. Raspberry House is a TCP/IP Layer 3 gateway built with Raspberry Pi, which can connect IoT devices to the private network generated by it, thereby preventing IoT devices from being exposed to outside networks. In addition, through a private network, IoT devices can also update their firmware wirelessly. This paper also studies the communication between IoT devices through different secure connections such as Secure Shell (SSH), and evaluates their results in different environments. Experimental evaluation of TCP/IP Layer 3 Gateway indicates that the proposed framework can provide security for small IoT devices.","","978-1-7281-9448-6","10.1109/IoTaIS50849.2021.9359722","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9359722","Internet of Things (IoT);IoT security;Raspberry Pi;Raspberry House Gateway;Over-the-air (OTA);small IoT device","Protocols;TCPIP;Logic gates;Security;Internet of Things;Servers;Microprogramming","","","","29","IEEE","23 Feb 2021","","","IEEE","IEEE Conferences"
"An IoT Solution for Multiple Sensors Control and Management","B. Bach-Gia; L. Luu-Trinh; M. Nguyen-Dinh; T. Pham-Dinh; C. Pham-Quoc","Ho Chi Minh City University of Technology (HCMUT), Ho Chi Minh City, Vietnam; Ho Chi Minh City University of Technology (HCMUT), Ho Chi Minh City, Vietnam; Ho Chi Minh City University of Technology (HCMUT), Ho Chi Minh City, Vietnam; Ho Chi Minh City University of Technology (HCMUT), Ho Chi Minh City, Vietnam; Ho Chi Minh City University of Technology (HCMUT), Ho Chi Minh City, Vietnam","2022 9th NAFOSTED Conference on Information and Computer Science (NICS)","20 Jan 2023","2022","","","117","122","The era of the fourth industrial revolution and the Covid-19 pandemic gives rise to the incredible growth of the IoT (Internet of Things) field. The trend of an immense amount of devices connected to specific networks brings up various problems, but most noticeable, control and management issues. In this paper, we propose a structural and efficient solution to solve this problem in a large-scale IoT system - along with two implementations of the proposed solution. The paper's main contribution is to present an overview of the architecture for an IoT system inspired by numerous IoT-based implementations. The design is expected to be dynamic, transparent, and easily deployed for newcomers. Furthermore, with the different implementations in health care and agriculture mentioned later, we want to demonstrate the flexibility and adaptability of the design to various fields.","","978-1-6654-5422-3","10.1109/NICS56915.2022.10013474","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10013474","IoT;Cloud computing;MQTT protocol;Embedded system","Wide area networks;Protocols;Pandemics;Scalability;Computer architecture;Quality of service;Sensors","","","","8","IEEE","20 Jan 2023","","","IEEE","IEEE Conferences"
"Mitigating Load-Altering Attacks Against Power Grids Using Cyber-Resilient Economic Dispatch","Z. Chu; S. Lakshminarayana; B. Chaudhuri; F. Teng",NA; NA; NA; NA,"2023 IEEE Belgrade PowerTech","9 Aug 2023","2023","","","1","1","Large-scale Load-Altering Attacks (LAAs) against Internet-of-Things (IoT) enabled high-wattage electrical appliances pose a serious threat to power system security and stability. This paper investigates, for the first time, the optimal mitigation strategy from a system perspective against such attacks. In particular, a Cyber-Resilient Economic Dispatch (CRED) concept is proposed and seamlessly integrated with attack detection and identification to form a cyber resiliency enhancement framework. Instead of only relying on local resources, CRED coordinates the frequency droop control gains of Inverter-Based Resources (IBRs) in the system to mitigate the destabilizing effect of LAAs while minimizing the overall operational cost. To achieve this, the LAA-inclusive system frequency dynamics is formulated and the corresponding system stability constraints are explicitly derived based on parametric sensitivities, which are further incorporated into the system scheduling model with minimum error through a novel recursive linearization method. In addition, a distributionally robust approach is proposed to account for the uncertainty associated with system dynamics driven by the LAA detection/parameter estimation errors. The overall performance of the proposed CRED model is demonstrated through extensive simulations in a modified IEEE reliability test system.","","978-1-6654-8778-8","10.1109/PowerTech55446.2023.10202796","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10202796","Economic dispatch;cyber-resilience;load altering attacks;system stability;sensitivity analysis","Stability criteria;Power system stability;Load modeling;Dynamic scheduling;Uncertainty;System dynamics;Sensitivity analysis","","","","","IEEE","9 Aug 2023","","","IEEE","IEEE Conferences"
"IoT based Automated Remote Monitoring System for Smart Farming","R. Maruthi; S. Nagarajan; R. Anitha; V. Jaitly","Department of Computer Applications, Hindustan Institute of Technology and Science, Chennai, Tamil Nadu, India; Department of Computer Applications, Hindustan Institute of Technology and Science, Chennai, Tamil Nadu, India; Department of Bio-Technology, Hindustan Institute of Technology and Science, Chennai, Tamil Nadu, India; Department of Computer Applications, Hindustan Institute of Technology and Science, Chennai, Tamil Nadu, India","2023 4th International Conference on Electronics and Sustainable Communication Systems (ICESC)","1 Aug 2023","2023","","","334","337","The population has increased over the years, which has affected the food supply and demand. Population growth, climate change and natural resource challenges are inter-linked factors that have affected the conventional way of farming. These challenging factors led to the introduction of Smart farming and Internet of Things (IoT) and climate-smart agriculture (CSA). This study explores an automated remote monitoring system using IoT in Smart farming. Irrigation is one of the main factors that directly affect crop growth, and up to 70 percent of the freshwater globally goes to agriculture. The proposed system uses moisture sensors to monitor the soil moisture levels for automated condition-based irrigation. The proposed system can be implemented in small-scale and large-scale farming; it will help farmers save costs and reduce water waste on a global scale. It uses 95 percent less water than conventional irrigation methods.","","979-8-3503-0009-3","10.1109/ICESC57686.2023.10193195","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10193195","Smart Farming;Internet of Things;Automated Irrigation;Moisture sensors.","Smart agriculture;Irrigation;Supply and demand;Sociology;Sensor systems;Internet of Things;Statistics;Climate change;Remote monitoring","","","","22","IEEE","1 Aug 2023","","","IEEE","IEEE Conferences"
"Research on Classification of Intrusion Detection in Internet of Things Network Layer Based on Machine Learning","J. Liu; D. Yang; M. Lian; M. Li","Shenyang Institute of Computing Technology, Chinese Academy of Sciences, Shenyang, China; Shenyang Institute of Computing Technology, Chinese Academy of Sciences, Shenyang, China; Shenyang Institute of Computing Technology, Chinese Academy of Sciences, Shenyang, China; Shenyang Institute of Computing Technology, Chinese Academy of Sciences, Shenyang, China","2021 IEEE International Conference on Intelligence and Safety for Robotics (ISR)","10 May 2021","2021","","","106","110","The emergence of the Internet of Things (IoT) is not only a global revolution in the information industry, but also brought tremendous changes to our lives. With the development of the technology and means of the IoT, information security issues have gradually emerged, and intrusion attacks have become one of the main problems of the IoT network security. The network layer of the IoT is the key connecting the platform and sensors or controllers of the IoT, and it is also the most standardized, the strongest and the most mature part of the whole physical network architecture. Its large-scale development has led to the network layer's security issues will receive more attention and face more challenges. This paper proposes an intrusion detection algorithm deployed on the network layer of the IoT, which uses the BPSO algorithm to extract features from the NSL-KDD dataset, and applies support vector machines (SVM) as the core model of the algorithm to detect and identify abnormal data, especially DoS attacks. Experimental results show that the model's detection rate of abnormal data and DoS attacks are significantly improved.","","978-1-6654-3862-9","10.1109/ISR50024.2021.9419529","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9419529","","Support vector machines;Intrusion detection;Network architecture;Feature extraction;Data models;Classification algorithms;Sensors","","","","17","IEEE","10 May 2021","","","IEEE","IEEE Conferences"
"Coexistence of Synchronous and Asynchronous MAC Protocols for Wireless IoT Systems in Sub-Gigaherz Band","K. Mizutani; R. Okumura; K. Mizutani; H. Harada","Graduate School of Informatics, Kyoto University, Kyoto, Japan; Graduate School of Informatics, Kyoto University, Kyoto, Japan; Graduate School of Informatics, Kyoto University, Kyoto, Japan; Graduate School of Informatics, Kyoto University, Kyoto, Japan","2020 IEEE 6th World Forum on Internet of Things (WF-IoT)","13 Oct 2020","2020","","","1","6","Recently, the sub-gigahertz band (e.g. 920 MHz in Japan) has been extensively used for the wireless Internet of Things (IoT) because of its advantages such as excellent radio wave reachability, less interference, and many developments and implementations of large-scale wireless multi-hop networks by using interference avoidance technologies such as the media access control (MAC) protocol and frequency hopping. There are two types of the wireless communication systems for IoT: Wi-SUN FAN, as an asynchronous wireless system, and MAC protocol with time-slotted channel hopping (TSCH), as a synchronous wireless system. Wi-SUN FAN and TSCH systems have already been commercialized and installed to the several IoT environments and are expected to expand in scale in the future. Since both systems are operated in the same frequency band of the sub-gigahertz band, the intersystem interference is a concern for the coexistence of systems. In this paper, the possibility of the coexistence between the systems is examined. The intrasystem and intersystem interferences are evaluated by computer simulations in the case of operating the two systems by themselves and that of operating the systems simultaneously in the same frequency channel.","","978-1-7281-5503-6","10.1109/WF-IoT48130.2020.9221436","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9221436","Sub-Gigahertz band;Wi-SUN;FAN;TSCH;MAC;coexistence","Fans;Wireless communication;IEEE 802.15 Standard;Media Access Protocol;Spread spectrum communication;Unicast;Wireless sensor networks","","4","","13","IEEE","13 Oct 2020","","","IEEE","IEEE Conferences"
"Amalgam: Distributed Network Control With Scalable Service Chaining","S. Chattopadhyay; S. Nandi; S. Chakraborty; A. S. Prasad","IIT Guwahati, Guwahati, India; IIT Guwahati, Guwahati, India; IIT Kharagpur, Kharagpur, India; NIE Mysuru, Karnataka, India","2020 IFIP Networking Conference (Networking)","17 Jul 2020","2020","","","519","523","Management of virtual network function (VNF) service chaining for a large scale network spanning across multiple administrative domains is difficult due to the decentralized nature of the underlying system. Existing session-based and software-defined networking (SDN) oriented approaches to manage service function chains (SFCs) fall short to cater to the plug-and-play nature of the constituent devices of a large scale eco-system such as the Internet of Things (IoT). In this paper, we propose Amalgam, a composition of a distributed SDN control plane along with a distributed SFC manager, that is capable of managing SFCs dynamically by exploiting the innetwork processing platform composed of plug-and-play devices. To ensure the distributed placement of VNFs in the in-network processing platform, we propose a greedy heuristic. Further, to test the performance, we develop a complete container driven emulation framework MiniDockNet on top of standard Mininet APIs. Our experiments on a large scale realistic topology reveal that Amalgam significantly reduces flow-setup time and exhibits better performance in terms of end-to-end delay for short flows.","","978-3-903176-28-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9142727","Service function chaining;Virtual network function;In-network processing;Programmable network;software defined network","Delays;Monitoring;Quality of service;Performance evaluation;Resource management;Internet of Things;Software","","","","16","","17 Jul 2020","","","IEEE","IEEE Conferences"
"Intelligent Control of Urban Lighting System Based on Video Image Processing Technology","Q. Yun; C. Leng","Art College, Anyang Normal University, Anyang, China; Art College, Anyang Normal University, Anyang, China","IEEE Access","2 Sep 2020","2020","8","","155506","155518","The rapid iterative development of information technology, computer technology and Internet of things technology promotes the construction of smart city, and the related concepts of smart city gradually move from theory to practice. As an important part of the development of smart city, the intelligent lighting and intelligent control of urban lighting system become increasingly urgent with the development of the latest Internet of things technology and video image processing technology. Based on the current Internet of things data communication and related processing technology as the background, this article constructs the overall control model of smart city lighting system, including GPRS wireless transmission technology and ZigBee technology. In the core algorithm, this article innovatively presents an improved video image processing technology based on Gaussian mixture algorithm, which mainly describes the background of a specific scene in multi-dimensional model, so as to improve the reliability of the whole scene judgment. At the level of noise suppression, the video image processing algorithm proposed in this article designs interference noise suppression technology based on the principle of mean filtering, so as to achieve the accuracy and integrity of urban traffic scene extraction. In order to solve the security problems of the whole video image processing technology in information extraction, storage and analysis, this article adds the electromagnetic information leakage prevention algorithm in the video image processing technology, which mainly processes the video image at the source, so as to reduce the electromagnetic radiation of the overall information. Based on this, this article completed the construction of the software and hardware of the city intelligent lighting system. On this basis, the software and hardware construction of urban intelligent lighting system is completed. At the same time, the experiment was carried out in a small-scale scene of a city. The experimental results show that the intelligent urban lighting system based on video image processing technology is feasible and can achieve the desired effect. At the same time, the lighting energy consumption level can be reduced by about 30%, and the corresponding failure rate can be reduced by about 30%.","2169-3536","","10.1109/ACCESS.2020.3019284","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9177121","Video image processing technology;smart city;Internet of Things technology;noise suppression;information leakage prevention technology","Lighting;Image processing;Smart cities;Internet of Things;Interference;Filtering","","11","","31","CCBY","25 Aug 2020","","","IEEE","IEEE Journals"
"Collaborative Edge Computing With FPGA-Based CNN Accelerators for Energy-Efficient and Time-Aware Face Tracking System","X. Liu; J. Yang; C. Zou; Q. Chen; X. Yan; Y. Chen; C. Cai","Hubei Key Laboratory of Transport Internet of Things, Wuhan University of Technology, Wuhan, China; School of Electronic Information, Wuhan University, Wuhan, China; Hubei Key Laboratory of Transport Internet of Things, Wuhan University of Technology, Wuhan, China; School of Electronic Information, Wuhan University, Wuhan, China; School of Computer Science and Technology, Wuhan University of Technology, Wuhan, China; School of Electronic Information, Wuhan University, Wuhan, China; School of Computer Science and Technology, Wuhan University of Technology, Wuhan, China","IEEE Transactions on Computational Social Systems","31 Jan 2022","2022","9","1","252","266","Convolutional neural networks (CNNs) have become the critical technology to realize face detection and face recognition in the face tracking (FT) system. However, traditional CNNs usually have nontrivial computational time and high energy consumption, making them inappropriate to be deployed in the large-scale time-sensitive FT system. To address this challenge, we design an artificial intelligence and Internet of Things (AIoT) empowered edge-cloud collaborative computing (ECCC) system based on the energy-efficient field-programmable gate array (FPGA)-based CNN accelerators for the purpose of realizing a low-latency and low-power FT. First, we present the AIoT-empowered ECCC system architecture, which consists of an intelligent computing subsystem, an Internet-of-Things (IoT) subsystem, an edge-cloud collaborative subsystem, and an application subsystem. In what follows, we investigate the enabling technologies for these subsystems. Thereafter, we develop an FPGA-based hardware accelerator dedicated to the compact MobileNet CNN by using the hardware design techniques, such as systolic array, matrix tiling, fixed-point precision, and parallelism. Furthermore, we integrate the FPGA accelerators with CPUs and GPUs to build a context-aware CPU/GPU/FPGA heterogeneous computing system. Finally, we implement a delay-aware energy-efficient scheduling algorithm dedicated to this heterogeneous system. With the above hardware and software codesign mechanism, the energy cost and execution time of CNNs can be decreased significantly. The real-world experiments on the CPU/GPU/FPGA-based ECCC system proved the effectiveness of the proposed schemes in reducing the latency and improving the power efficiency of the FT system.","2329-924X","","10.1109/TCSS.2021.3059318","Natural Science Foundation of Xinjiang Province of China(grant numbers:2020D01A130); National Natural Science Foundation of China(grant numbers:61702387,61771354); Hubei Provincial Key Research and Development Program(grant numbers:2020BAA001); National Innovation and Entrepreneurship Training Program for College Students(grant numbers:202010497040); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9363321","Accelerator;collaborative edge computing;convolutional neural network (CNN);face tracking (FT)","Face recognition;Face detection;Acceleration;Task analysis;Servers;Image edge detection;Hardware","","27","","41","IEEE","25 Feb 2021","","","IEEE","IEEE Journals"
"Smart Healthcare in IoT using Convolutional Based Cyber Physical System","S. Suganyadevi; S. S. Priya; R. Menaha; S. Sathiya; P. Jha; S. B. S","Department of ECE, KPR Institute of Engineering and Technology, Coimbatore, India; Department of CSE, Vel Tech Rangarajan Dr Sagunthala R&D, Institute of Science and Technology, Chennai, India; Department of IT, Sri Eshwar College of Engineering, Coimbatore, India; Department of Artificial Intelligence and Data Science, Sri Krishna College of Engineering and Technology, Coimbatore, India; Department of Electrical Engineering, Sandip University, Bihar, India; Department of Electrical Engineering, Sandip University, Bihar, India","2022 IEEE 2nd Mysore Sub Section International Conference (MysuruCon)","13 Dec 2022","2022","","","1","6","The intelligent Internet of Things (IoT) through infinite networking possibilities for medical data investigation is elevating the interaction between technology and healthcare society. Recent years have seen fruitful transformations in deep networks and the widespread use of health wearables. IoT enabled by Deep Neural Networks brought about novel societal advances in medicine and brought new possibilities to the study of healthcare data. Despite the improvements, there are still certain problems that need to be addressed in terms of service quality. In this research, we present Grey Filter Bayesian Convolution Neural Network (GFB-CNN), a Deep Neural Network-driven IoT smart healthcare approach that makes use of real-time data. Here, we suggested a comprehensive AI-driven Internet of Things (IoT) eHealth architecture using a GFB-CNN to improve accuracy and efficiency across critical quality of service criteria. In order to evaluate the method’s viability, a large-scale Mobile HEALTH (MHEALTH) dataset is analysed. From design ideas to matching accuracy, overheads, and time related to state-of-the-art approaches, this instructive example examines and addresses all relevant elements of the suggested method. The GFB-CNN approach has assessed beside state-of-the-art methods in a multiplicity of simulated settings. We demonstrate that our approach successfully analyses health information investigation for heart signs by efficiently differentiating among good and sick heart signals with low time and cost required for sensing and data collecting.","","978-1-6654-9790-9","10.1109/MysuruCon55714.2022.9972679","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9972679","healthcare;deep learning;Internet of Things (IoT);Convolution Neural Network;Grey Filter","Heart;Cloud computing;Technological innovation;Convolution;Wearable computers;Neural networks;Medical services","","11","","21","IEEE","13 Dec 2022","","","IEEE","IEEE Conferences"
"Cloud-based Web of Things: A Telemedicine Use Case","L. D'Agati; Z. Benomar; F. Longo; G. Merlino; A. Puliafito","Department of Engineering, University of Messina, Italy; MiMove team, National Institute for Research in Digital Science and Technology (INRIA), Paris, France; Department of Engineering, University of Messina, Italy; Department of Engineering, University of Messina, Italy; Department of Engineering, University of Messina, Italy","2023 IEEE 20th Consumer Communications & Networking Conference (CCNC)","17 Mar 2023","2023","","","1","6","To fully exploit the capabilities of the Internet of Things (IoT), it is expected to assemble large-scale networks made of heterogeneous IoT devices (e.g., embedded systems, sensors, and actuators) and smart systems. These devices and systems should interact in a seamless fashion regardless of the underlying protocols. Yet, most of the actual IoT deployments are based on proprietary technologies and tightly coupled systems. To overcome application layer interoperability issues, the Web of Things (WoT) paradigm aims at making smart things an integral part of the Web and, thus, enabling them to interact through Web protocols, in accordance to Web standards. In this paper, we extend our system for WoT meant for associating to the geographically distributed IoT resources publically resolvable URL/URI. In particular, we propose in this work a HATEOAS-enabled mechanism to discover IoT resources available on an IoT node. This approach makes developers, and users alike, able to discover available resources within a node without knowing them beforehand. A use case is also described, in the context of telemedicine.","2331-9860","978-1-6654-9734-3","10.1109/CCNC51644.2023.10060344","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10060344","Internet of Things;Cloud computing;Web of Things;REST;Cyber Physical Systems;OpenStack;Web services;Telemedicine;HATEOAS","Cloud computing;Actuators;Protocols;Embedded systems;Telemedicine;Sensor systems;Internet of Things","","1","","23","IEEE","17 Mar 2023","","","IEEE","IEEE Conferences"
"Hardware Based Data Security Techniques in IOT: A Review","J. Gopika Rajan.; R. S. Ganesh","ECE Dept, Noorul Islam Centre for Higher Education, Kumaracoil, Tamil Nadu, India; ECE Dept, R.M.K. Engineering College, Chennai, Tamil Nadu, India","2022 3rd International Conference on Smart Electronics and Communication (ICOSEC)","22 Nov 2022","2022","","","408","413","Internet Of Things has already started gaining acceptance and its implementation has begun from small scale to large scale in different applications like healthcare, industries, household, banking, etc. in the form of smart equipment being connected together to make life and work much easier. But due to its extensive work range and functionality the creators concentrate much over its efficient functionality and neglect to include efficient techniques to ensure data security in IOT which generate adverse data loss, theft resulting in loss of integrity. Hardware based data security systems works excellently with IOT in all its applications because of its flexible & adaptable features. In this paper, a survey has been done over the hardware-based data security systems in various applications and its possibility of implementing in IOT has been tested.","","978-1-6654-9764-0","10.1109/ICOSEC54921.2022.9952021","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9952021","Hardware Based Security (HBS);Internet of Things (IOT);Data Security;Crypto-Processor","Industries;Data security;Data integrity;Memory;Medical services;Hardware;Software","","2","","17","IEEE","22 Nov 2022","","","IEEE","IEEE Conferences"
"A Scalable Nested Blockchain Framework with Dynamic Node Selection Approach for IoT","X. He; Y. Zhang; X. Wang","Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China","2022 IEEE International Performance, Computing, and Communications Conference (IPCCC)","12 Oct 2022","2022","","","108","113","A high level of scalability is needed to support the large-scale Internet-of-Things (IoT) networks. To address the issue of distributed trust in different IoT devices, blockchain technology can be effectively used to safely manage IoT data due to its ability to provide transactions traceability and security. However, massive real-time IoT application data has brought huge challenges to the scalability of the integration framework of blockchain and IoT. This paper proposes a nested-chain architecture, which consists of one main chain and multiple sub chains to address the aforementioned challenges. The main chain stores identity credential used for distributed identity (DID) management, while the sub chain stores the IoT data. A notary module that involves access nodes from both chains is designed for cross-chain transactions. In addition, considering the transaction information, node characteristics, and network status, we further introduce a node selection algorithm based on Graph Convolutional Network (GCN), which can effectively reduce the cost of cross-chain communications. We implement and evaluate a prototype of our framework on the Hyperledger Fabric platform to demonstrate its feasibility and superiority. The analyzed results have shown that our proposed framework outperforms traditional schemes, by reducing system latency up to 23.2% and increasing system throughput up to 12.5%.","2374-9628","978-1-6654-8018-5","10.1109/IPCCC55026.2022.9894312","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9894312","IoT;Blockchain;Scalability;Machine Learning","Distributed ledger;Scalability;Prototypes;Machine learning;Throughput;Real-time systems;Fabrics","","2","","17","IEEE","12 Oct 2022","","","IEEE","IEEE Conferences"
"15.2 A 2.19µW Self-Powered SoC with Integrated Multimodal Energy Harvesting, Dual-Channel up to −92dBm WRX and Energy-Aware Subsystem","C. J. Lukas; F. B. Yahya; K. -K. Huang; J. Boley; D. S. Truesdell; J. Breiholz; A. Wokhlu; K. Craig; J. K. Brown; A. Fitting; W. Moore; A. Shih; A. Wang; A. Gravel; D. D. Wentzloff; B. H. Calhoun","Everactive, Charlottesville, VA, United States; Everactive, Charlottesville, VA, United States; Everactive, Santa Clara, CA, United States; Everactive, Santa Clara, CA, United States; Everactive, Charlottesville, VA, United States; Everactive, Charlottesville, VA, United States; Everactive, Santa Clara, CA, United States; Everactive, Charlottesville, VA, United States; Everactive, Ann Arbor, MI, United States; Everactive, Santa Clara, CA, United States; Everactive, Santa Clara, CA, United States; Everactive, Santa Clara, CA, United States; Everactive, Santa Clara, CA, United States; Everactive, Santa Clara, CA, United States; Everactive, Ann Arbor, MI, United States; Everactive, Charlottesville, VA, United States","2023 IEEE International Solid-State Circuits Conference (ISSCC)","23 Mar 2023","2023","","","238","240","Self-Powered Systems (SPSs) targeting the Internet-of-Things (IoT) have the potential to monitor an incredible array of environments and equipment, providing previously unavailable rich data and insights [1]. Unlike battery-powered systems that optimize for energy per operation, SPSs must scale their power consumption in response to environmental changes. This presents both a challenge and an opportunity for such systems: 1) they must have a low power floor to continuously operate at low harvested power (low $\mathrm{P}_{\mathrm{H}})$, but 2) they also can scale up their performance when harvesting conditions are favorable (high $\mathrm{P}_{\mathrm{H}})$. Many existing IoT SoCs and platforms have a power floor that is too high [2] or are too low performance [3]. We propose an SoC for SPSs that pushes the power floor down to $2.19\mu\mathrm{W}$, simultaneously harvests from multiple sources, cold starts from low $\mathrm{P}_{\mathrm{H}}(60\text{Lux},\ 8^{\mathrm{o}}\mathrm{C})$, scales system performance based on environmental conditions, and improves the wakeup receiver sensitivity to −92dBm, all while allowing the system to maintain a small form factor enabling data collection even in the most challenging environments without the use of a battery. With these features, the proposed SoC can take advantage of the near infinite energy available to SPSs to do far more work than can be done with battery-powered systems.","2376-8606","978-1-6654-9016-0","10.1109/ISSCC42615.2023.10067337","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10067337","","Sensitivity;Power demand;System performance;Receivers;Data collection;Batteries;Energy harvesting","","","","7","IEEE","23 Mar 2023","","","IEEE","IEEE Conferences"
"Integrating Mobile IoT Devices into the Arrowhead Framework Using Web of Things","C. Bonsignori; C. Puliafito; A. Virdis; E. Mingozzi; G. Iannaccone","Department of Information Engineering, University of Pisa, Pisa, Italy; Department of Information Engineering, University of Pisa, Pisa, Italy; Department of Information Engineering, University of Pisa, Pisa, Italy; Department of Information Engineering, University of Pisa, Pisa, Italy; Department of Information Engineering, University of Pisa, Pisa, Italy","2022 IEEE 19th Annual Consumer Communications & Networking Conference (CCNC)","10 Feb 2022","2022","","","1","6","Interoperability is one of the main issues concerning the Internet of Things (IoT). The Arrowhead Framework (AHF) is an open-source platform that aims at tackling this problem. In this work, we first integrate a set of legacy IoT devices (i.e., an ECG and a smart plug) into the AHF by leveraging W3C Web of Things (WoT) as an interface between the two worlds. The result is an architecture where AHF consumers are deployed in a local cloud and consume Web Things, which can be deployed on IoT devices as well as on servers at the network edge to provide edge computing services. In this context, IoT device mobility raises a problem. When the IoT device moves, indeed, the edge-hosted service needs to follow it to preserve proximity, which is key to edge computing. In this case, the IP addresses of both the Web Things (i.e., the one hosted on the IoT device and the one hosted at the edge) may change, causing problems of mutual reachability after mobility/migration. WoT does not currently handle this issue. In this work, we extend WoT in this direction and evaluate our approach over a small-scale edge computing testbed.","2331-9860","978-1-6654-3161-3","10.1109/CCNC49033.2022.9700685","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9700685","Web of Things;Arrowhead framework;Edge computing;interoperability;service continuity","W3C;Electrocardiography;Service-oriented architecture;Internet of Things;Servers;IP networks;Open source software","","","","14","IEEE","10 Feb 2022","","","IEEE","IEEE Conferences"
"IoT Based Plantation System for Smart Home Farming","V. Rai; S. Patidar","Department of Software Engineering, Delhi Technological University, Delhi; Department of Software Engineering, Delhi Technological University, Delhi","2023 International Conference on Electrical, Electronics, Communication and Computers (ELEXCOM)","1 Jan 2024","2023","","","1","5","Home smart farming is the area where Internet of things (IoT) applications are expanding. The effectiveness and quality of agricultural goods have been recommended to be increased by using various monitoring, controlling, and tracking systems. Many people would like to start their own small-scale farms at home to produce organic goods for their daily consumption, even if the majority of the existing systems concentrate on industrial farming. However, due to a lack of agricultural infrastructure and understanding, people are frequently unable to produce healthy agricultural goods and are also unable to safeguard their indoor plants from too much and too little sunshine. The IoT-based plantation system described in this research attempts to maximize plant growth while shielding plants from excessive or insufficient sunlight. The system uses sensors to assess important environmental variables such as light intensity, and temperature, integrating IoT technology with agriculture. The gathered data is processed, examined, and sent to a cloud server for archival and examination. Real-time data visualization, notifications, and user interaction are made possible through a user-friendly mobile application. The main focus is on protecting plants by keeping an eye on light levels to prevent harmful consequences of excessive or insufficient sunshine exposure. The system uses the IoT infrastructure to assure ideal circumstances for plant growth as well as remote monitoring and control, which results in effective resource management.","","979-8-3503-0511-1","10.1109/ELEXCOM58812.2023.10370530","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10370530","Internet of Things (IoT);Plantation System;Smart Home Farming;Light Intensity Monitoring;Plant Growth Optimization;Sunlight Protection","Temperature sensors;Temperature measurement;Smart agriculture;Smart homes;Sensor systems;Sensors;Internet of Things","","","","15","IEEE","1 Jan 2024","","","IEEE","IEEE Conferences"
"Device Activity Detection for the IoT Using Sparse Graph Codes","H. Zhou; C. Wang; W. Zeng; X. Zheng; S. Zou","College of Communications Engineering, Army Engineering University of PLA, Nanjing, China; College of Communications Engineering, Army Engineering University of PLA, Nanjing, China; College of Communications Engineering, Army Engineering University of PLA, Nanjing, China; College of Communications Engineering, Army Engineering University of PLA, Nanjing, China; College of Communications Engineering, Army Engineering University of PLA, Nanjing, China","2020 IEEE 20th International Conference on Communication Technology (ICCT)","24 Dec 2020","2020","","","851","857","Massive Machine Communication (mMTC) is one of the scenarios in which 5G Internet of Things is most widely used. Usually in a specific application scenario, at any given moment, only a small percentage of user devices are active. Therefore, one of the key challenges in achieving large-scale IoT device transmission is to first identify active user devices and then decode their data with low latency to ensure effective access to user devices. In response to this problem, we use a grant-free access mechanism to effectively simplify the signaling process and reduce delay. Meanwhile, we transform the active user detection problem in the grant-free access mechanism into single measurement vector (SMV) problems in compressed sensing theory and convert the pilot matrix design problem into the measurement matrix design problem. Finally, we use a sparse graph coding algorithm based on the combination of compressed sensing theory and sparse decoding problem in the communication system to solve the active user device detection problem in the 5G mMTC system. Experimental results show that the grant-free random access scheme and novel algorithm design significantly improve the effectiveness and accuracy of large-scale IoT connected user device activity detection.","2576-7828","978-1-7281-8141-7","10.1109/ICCT50939.2020.9295744","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9295744","mMTC;Active user device detection;SMV;grantfree;sparse graph code","Sparse matrices;Partial transmit sequences;Matrix converters;Antenna measurements;Sensors;Transforms;Random variables","","","","15","IEEE","24 Dec 2020","","","IEEE","IEEE Conferences"
"PervasiveFL: Pervasive Federated Learning for Heterogeneous IoT Systems","J. Xia; T. Liu; Z. Ling; T. Wang; X. Fu; M. Chen","MoE Engineering Research Center of Hardware/Software Co-Design Technology and Application, East China Normal University, Shanghai, China; MoE Engineering Research Center of Hardware/Software Co-Design Technology and Application, East China Normal University, Shanghai, China; MoE Engineering Research Center of Hardware/Software Co-Design Technology and Application, East China Normal University, Shanghai, China; MoE Engineering Research Center of Hardware/Software Co-Design Technology and Application, East China Normal University, Shanghai, China; ECE Department, University of Houston, Houston, TX, USA; MoE Engineering Research Center of Hardware/Software Co-Design Technology and Application, East China Normal University, Shanghai, China","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","25 Oct 2022","2022","41","11","4100","4111","Federated learning (FL) has been recognized as a promising collaborative on-device machine learning method in the design of Internet of Things (IoT) systems. However, most existing FL methods fail to deal with IoT applications that contain a variety of IoT devices equipped with different types of neural network (NN) models. This is because traditional FL methods assume that local models on devices should have the same architecture as the global model on cloud. To address this problem, we propose a novel framework named PervasiveFL that enables efficient and effective FL among heterogeneous IoT devices. Without modifying original local models, PervasiveFL installs one lightweight NN model named modellet on each device. By using the deep mutual learning (DML) and our entropy-based decision gating (EDG) method, modellets and local models can selectively learn from each other through soft labels using locally captured data. Meanwhile, since modellets are of the same architecture, the learned knowledge by modellets can be shared among devices in a traditional FL manner. In this way, PervasiveFL can be pervasively applied to any heterogeneous IoT system. Comprehensive experimental results on four well-known datasets show that PervasiveFL can not only pervasively enable FL among heterogeneous devices within a large-scale IoT system, but also significantly enhance the inference accuracy of heterogeneous IoT devices with low communication overhead.","1937-4151","","10.1109/TCAD.2022.3197491","National Key Research and Development Program of China(grant numbers:2018YFB2101300); Natural Science Foundation of China(grant numbers:61872147); Shanghai Trusted Industry Internet Software Collaborative Innovation Center; Fundamental Research Funds for the Central Universities(grant numbers:YBNLTS2022-008); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9925684","Deep mutual learning (DML);federated learning (FL);Internet of Things (IoT);model heterogeneity;neural network (NN)","Internet of Things;Data models;Computational modeling;Integrated circuit modeling;Computer architecture;Cloud computing;Training","","4","","33","IEEE","20 Oct 2022","","","IEEE","IEEE Journals"
"Combination of Task Allocation and Approximate Computing for Fog-Architecture-Based IoT","W. Yu; A. Najafi; Y. Huang; A. Garcia-Ortiz","Institute of Electrodynamics and Microelectronics, University of Bremen, Bremen, Germany; Institute of Electrodynamics and Microelectronics, University of Bremen, Bremen, Germany; Faculty of Electrical Engineering, Mathematics and Computer Science, University of Twente, Enschede, NH, The Netherlands; Institute of Electrodynamics and Microelectronics, University of Bremen, Bremen, Germany","IEEE Internet of Things Journal","23 Apr 2021","2021","8","9","7638","7648","Achieving energy efficiency is always a primary concern for fog-architecture-based Internet of Things (IoT) applications. As the IoT devices are typically of small sizes and powered by battery energy, it is essential to address the energy consumption at all levels from the circuit to the system. Two of the promising solutions at circuit and system levels are approximate computing and energy-aware task allocation, respectively. However, the existing task allocation approaches are designed without considering the aspect of approximate computing. In this work, we fill this gap and aim to maximize the network lifetime subject to the accuracy requirements of the applications. By considering both the approximate computing and task allocation simultaneously, a nonlinear problem is obtained to allocate the tasks for the devices (fog nodes and IoT end devices) and to select the corresponding execution modes (tasks in approximate or exact modes). To efficiently solve this problem, a centralized algorithm is first proposed by transferring the above nonlinear problem as a linear programming (LP) problem. As executing the centralized algorithm is a challenge for the resource-limited IoT devices, this work further proposes an optimal distributed algorithm based on Dantzig-Wolfe decomposition to solve the problem of tasks distribution and execution modes selection. The centralized large-scaled LP problem is decomposed into small-scaled subproblems, which can be efficiently solved by each IoT device. The proposed algorithms are tested by extensive simulations. The results demonstrate that the distributed algorithm achieves the same results as the centralized algorithm, and both of them significantly outperform the previous approaches.","2327-4662","","10.1109/JIOT.2020.3040892","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9272608","Approximate computing;fog/edge computing;Internet of Things (IoT);network lifetime;task allocation","Task analysis;Internet of Things;Resource management;Approximate computing;Approximation algorithms;Energy consumption;Computational modeling","","6","","35","IEEE","26 Nov 2020","","","IEEE","IEEE Journals"
"Implementing a Scalable Data Management System for Collected Data by Smart Meters","F. Farahani; F. Rezaei","Computer Engineering Department, K. N. Toosi University of Technology, Tehran, Iran; Computer Engineering Department, K. N. Toosi University of Technology, Tehran, Iran","2021 26th International Computer Conference, Computer Society of Iran (CSICC)","7 May 2021","2021","","","1","5","The Internet of things (IoT) is generating a huge amount of data and big data management is of key importance. One of the important applications of IoT is smart meter networks and one of the key issues in establishing smart meter networks is managing the large volume of data sent by the meters. In this paper, we present a data management system implemented for monitoring and managing the data collected from the smart meters and controlling them in a large-scale network. IoT infrastructure with LPWAN (Low Power Wide Area Network) class is considered in this system. Moreover, two methods are proposed to improve the performance in terms of scalability and response time. It is shown that the implemented data management system using the proposed methods achieves significant performance improvement in large scale networks.","","978-1-6654-1241-4","10.1109/CSICC52343.2021.9420619","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9420619","internet of things;big data;data management system;smart meter network;scalability;caching","Meters;Wide area networks;Databases;Scalability;Big Data;Smart meters;Software","","1","","18","IEEE","7 May 2021","","","IEEE","IEEE Conferences"
"A Global Manufacturing Big Data Ecosystem for Fault Detection in Predictive Maintenance","W. Yu; T. Dillon; F. Mostafa; W. Rahayu; Y. Liu","Department of Computer Science and Information Technology, La Trobe University, Melbourne, Australia; Department of Computer Science and Information Technology, La Trobe University, Melbourne, Australia; Department of Computer Science and Information Technology, La Trobe University, Melbourne, Australia; Department of Computer Science and Information Technology, La Trobe University, Melbourne, Australia; Department of Computer Science and Information Technology, La Trobe University, Melbourne, Australia","IEEE Transactions on Industrial Informatics","8 Jan 2020","2020","16","1","183","192","Artificial intelligence, big data, machine learning, cloud computing, and Internet of Things (IoT) are terms which have driven the fourth industrial revolution. The digital revolution has transformed the manufacturing industry into smart manufacturing through the development of intelligent systems. In this paper, a big data ecosystem is presented for the implementation of fault detection and diagnosis in predictive maintenance with real industrial big data gathered directly from large-scale global manufacturing plants, aiming to provide a complete architecture which could be used in industrial IoT-based smart manufacturing in an industrial 4.0 system. The proposed architecture overcomes multiple challenges including big data ingestion, integration, transformation, storage, analytics, and visualization in a real-time environment using various technologies such as the data lake, NoSQL database, Apache Spark, Apache Drill, Apache Hive, OPC Collector, and other techniques. Transformation protocols, authentication, and data encryption methods are also utilized to address data and network security issues. A MapReduce-based distributed PCA model is designed for fault detection and diagnosis. In a large-scale manufacturing system, not all kinds of failure data are accessible, and the absence of labels precludes all the supervised methods in the predictive phase. Furthermore, the proposed framework takes advantage of some of the characteristics of PCA such as its ease of implementation on Spark, its simple algorithmic structure, and its real-time processing ability. All these elements are essential for smart manufacturing in the evolution to Industry 4.0. The proposed detection system has been implemented into the real-time industrial production system in a cooperated company, running for several years, and the results successfully provide an alarm warning several days before the fault happens. A test case involving several outages in 2014 is reported and analyzed in detail during the experiment section.","1941-0050","","10.1109/TII.2019.2915846","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8710319","Big data analytics;cloud computing;fault detection;Internet of Things (IoT);Industry 4.0;manufacturing ecosystem;predictive maintenance (PdM)","Big Data;Manufacturing;Predictive maintenance;Ecosystems;Computer architecture;Real-time systems;Cloud computing","","116","","28","IEEE","9 May 2019","","","IEEE","IEEE Journals"
"Autonomic Faulty Node Replacement in UAV-Assisted Wireless Sensor Networks: a Test-bed","L. Montecchiari; A. Trotta; L. Bononi; M. Di Felice; E. Natalizio","Department of Computer Science and Engineering, University of Bologna, Italy; Department of Computer Science and Engineering, University of Bologna, Italy; Department of Computer Science and Engineering, University of Bologna, Italy; Department of Computer Science and Engineering, University of Bologna, Italy; Technology Innovation Institute (TII), United Arab Emirates","2023 IEEE 20th Consumer Communications & Networking Conference (CCNC)","17 Mar 2023","2023","","","1155","1158","Several use-cases of the Internet of Things (IoT) rely on the development of large-scale Wireless Sensor Networks (WSNs) in harsh environments characterized by limited Internet connectivity and battery-powered operations. In such scenarios, the failure of a single node due to energy depletion or hardware issues may cause network partitions and disrupt partially or completely the system operations until the intervention of a human operator. In this paper, we investigate the usage of Unmanned Aerial Networks (UAVs) to enable sensory data collection and support resilient communications in presence of faulty sensor nodes. More specifically, we study the possibility of replacing the ground devices with UAVs which are able to temporarily restore the multi-hop communication towards the WSN sink. To this aim, we extended the Uhura framework, a platform for robotic networking, with novel features for automatic network partition detection and UAV-sink coordination. Then, we created a small test-bed composed of a Bluetooth Mesh WSN and one drone, and characterized the performance of the UAV-assisted WSN system in terms of packet delivery ratio of the end-to-end data flows.","2331-9860","978-1-6654-9734-3","10.1109/CCNC51644.2023.10059801","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10059801","Unmanned Aerial Vehicles (UAVs);Wireless Sensor Networks (WSNs);Resilient communications;Test-bed","Wireless sensor networks;Systems operation;Robot kinematics;Spread spectrum communication;Data collection;Robot sensing systems;Feature extraction","","1","","13","IEEE","17 Mar 2023","","","IEEE","IEEE Conferences"
"Anonymous Key-Agreement Protocol for V2G Environment Within Social Internet of Vehicles","S. Ahmed; S. Kumari; M. A. Saleem; K. Agarwal; K. Mahmood; M. -H. Yang","Department of Computer Science, COMSATS University Islamabad–Sahiwal, Sahiwal, Pakistan; Department of Mathematics, Chaudhary Charan Singh University Meerut, Meerut, India; Department of Computer Science, COMSATS University Islamabad–Sahiwal, Sahiwal, Pakistan; Department of Computer Science and Engineering, Bhagwati Institute of Technology and Science, Ghaziabad, India; Department of Computer Science, COMSATS University Islamabad–Sahiwal, Sahiwal, Pakistan; Department of Information and Computer Engineering, Chung Yuan Christian University, Taoyuan City, Taiwan","IEEE Access","7 Jul 2020","2020","8","","119829","119839","The blend of Internet of Things (IoT) and social networking has introduced the emerging notion of social Internet of Things, which is bringing advancements in the operation of concerned industries. There are various prevailing applications of social internet of things; smart grid is one of them. The smart grid is considered as economical robust and intuitive replacement of the conventional grid. However, smart grid experiences two significant challenges, i.e. privacy and security. This article is dedicated to resolve the privacy and security concerns for the vehicle to grid networks to facilitate their large-scale integration with smart grids. As anticipation, a vigorous key agreement protocol is introduced to achieve mutual authentication with an aided feature of user anonymity. Moreover, efficiency in terms of computation, communication and storage needs to be taken care for resource-constrained infrastructure like vehicle to grid network. We have introduced a lightweight key agreement protocol using lightweight cryptographic operations such as exclusive-OR and hash etc. This protocol is validated through a formal security model. An informal security analysis is also elaborated to present the security strength of our protocol against well-known attacks. Furthermore, we have implemented all the cryptographic operations used at trusted agent's side on a desktop system, while the operations used at battery vehicle unit's side are implemented on an Arduino to get the experimental results. In the end, we have presented a performance analysis to compare the performance of our protocol with related ones. This comparison highlights that our protocol is not only lightweight but also efficient in terms of communication and storage cost of related protocols.","2169-3536","","10.1109/ACCESS.2020.3003298","Ministry of Science and Technology of Taiwan(grant numbers:MOST 108-2221-E-033-016); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9120016","Authentication;authentication protocol;V2G;SIoT;smart grid;electric vehicles","Vehicle-to-grid;Protocols;Privacy;Authentication;Internet of Things","","11","","43","CCBY","18 Jun 2020","","","IEEE","IEEE Journals"
"Development of an Algorithm for Positioning a Mobile Device Based on Sensor Networks from BLE Beacons for Building Autonomous Navigation Systems","A. V. Astafiev; A. A. Demidov; A. L. Zhiznyakov; I. A. Kondrushin","Department of Software Engineering, Vladimir State University, Murom, Russia; Department of Software Engineering, Vladimir State University, Murom, Russia; Department of Software Engineering, Vladimir State University, Murom, Russia; Department of Software Engineering, Vladimir State University, Murom, Russia","2021 International Russian Automation Conference (RusAutoCon)","17 Sep 2021","2021","","","1056","1061","The article provides an analysis of the market, which showed that such systems are necessary both for large companies and small businesses, which determines the urgency of the problem under consideration. The goal of the work is to develop an algorithm for positioning small-scale mechanization tools based on sensor networks from BLE beacons for building RTLS systems and autonomous navigation systems. Currently, the development of mobile technologies and the Internet of Things (Internet of Things) has given rise to technologies that allow more efficient organization of indoor positioning. Instead of more resource-intensive technologies, such as: GPS, GLONASS, Wi-Fi, UHF, Bluetooth, technologies came: ZigBee, Z-Wave, Thread and Bluetooth Low Energy (BLE). The article suggests using beacons based on BLE technology for building wireless sensor networks, which will allow developing a real-time positioning algorithm. The requirements for sensor networks based on BLE beacons are formulated. A description is given of the algorithm for internal positioning and experimental studies have been carried out that have shown an increase in the accuracy of determining the coordinates of the linking device compared to analogues.","","978-1-6654-1523-1","10.1109/RusAutoCon52004.2021.9537469","Russian Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9537469","positioning;Bluetooth Low Energy;RTLS;trilaceration;approximation","Training;Wireless sensor networks;Bluetooth;Operating systems;Buildings;Zigbee;Real-time systems","","2","","18","IEEE","17 Sep 2021","","","IEEE","IEEE Conferences"
"Enhancing Smart City and IoT Solutions with Deep Residual Bi-LSTM Model","M. S; S. P. Chander Rao; S. Yadav; S. G. Hashmi; J. Ahmad; Z. Syed","Department of Information Technology, Sri Krishna College of Technology, Tamilnadu, India; EEE Department, Geethanjali College of Engineering and Technology, Hyderabad, Telangana, India; Department of Commerce and Business Administration, University of Allahabad, Prayagraj, Uttar Pradesh, India; Department of Information Technology & Security, College of Computer Science & Information Technology, Jazan University, Jazan, Saudi Arabia; Information Technology & Security, College of Computer Science and Information Technology, Jazan University, Jazan, Saudi Arabia; Department of Computer Science, College of Computer Science and Information Technology, Jazan University, Jazan, Saudi Arabia","2023 International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS)","6 Dec 2023","2023","","","1277","1282","There is a limitless supply of useful information and services made available by IoT devices connected to the internet. The Internet of Things (IoT) refers to the vast network of interconnected devices seen in a smart city. The scattered and dynamic natures of entities such as sensing, actuating devices, humans, and computing resources make it challenging to design applications in such large-scale IoT systems, despite the promise nature of the new breed of data and resources. In this research study, the proposed approach takes a coordinated look at the process of creating Internet of Things apps for use in Smart Cities. The proposed approach demonstrates the need for a distributed coordination model capable of monitoring such a vast number of independently operating parts while constructing Smart City IoT applications. Preprocessing, feature selection, and model performance evaluation are all used in the suggested method. Normalization and standardization are used during preprocessing. It uses entropy HOA for feature selection. The model's effectiveness is measured with Deep Residual Bi-LSTM. When compared to BiLSTM and Residual LSTM, two existing approaches, the suggested methodology performs admirably.","","979-8-3503-0085-7","10.1109/ICSSAS57918.2023.10331792","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10331792","Normalization;Standardization;Bidirectional Long Short-Term Memory (Bi-LSTM);Internet of Things (IOT);Smart City (SC)","Performance evaluation;Smart cities;Standardization;Feature extraction;Sensors;Information and communication technology;Internet of Things","","","","25","IEEE","6 Dec 2023","","","IEEE","IEEE Conferences"
"MMDP: A Mobile-IoT Based Multi-Modal Reinforcement Learning Service Framework","P. Wang; L. T. Yang; J. Li; X. Li; X. Zhou","School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; Meituan-Dianping company, Beijing, China; School of Electronic Information Engineering, Henan Institute of Technology, Xinxiang, China; Faculty of Data Science, Shiga University, Hikone, Japan","IEEE Transactions on Services Computing","5 Aug 2020","2020","13","4","675","684","With the development of GPS technology, a new Mobile Internet of Things (M-IoT) is emerging, which perceives the city's rhythm and pulse day and night to collect a large scale of city data. It is urgent to innovate M-IoT service system for these large-scale and heterogeneous data. To cope with the problem, this article proposes a Mobile-IoT based multi-modal reinforcement learning service framework from data perspective, which has three highlights, i) Developing Action-aware High-order Transition Tensor ($AHTT$AHTT) to fuse the heterogeneous data from M-IoTs in a unified form. ii) Developing Multi-modal Markov Decision Process ($MMDP$MMDP) to model the multi-modal reinforcement learning for M-IoT service framework. iii) Developing Tensor Policy Iteration algorithm ($TPIA$TPIA) to solve the optimal tensor policy. Due to using tensor keeps the multi-modal relations of the context information in the process of solving the optimal policy. The proposed M-IoT service system provides more personalized service for taxi drivers. The experiment results shows that most taxi drivers earn more revenue according to the tensor policy.","1939-1374","","10.1109/TSC.2020.2964663","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951261","Multi-modal reinforcement learning;mobile Internet of Things;service framework;social sensors;multi-modal Markov decision process;action-aware high-order transition tensor;tensor policy iteration algorithm;optimal tensor policy","Tensors;Internet of Things;Markov processes;Reinforcement learning;Public transportation;Sensor systems","","8","","25","IEEE","7 Jan 2020","","","IEEE","IEEE Journals"
"The use of Bluetooth Mesh Networking in IoT-aware Applications","I. Sergi; T. Montanaro; M. C. Gammariello; L. Patrono","Dept. of Engineering for Innovation, University of Salento, Lecce, Italy; Dept. of Engineering for Innovation, University of Salento, Lecce, Italy; Dept. of Engineering for Innovation, University of Salento, Lecce, Italy; Dept. of Engineering for Innovation, University of Salento, Lecce, Italy","2021 6th International Conference on Smart and Sustainable Technologies (SpliTech)","21 Oct 2021","2021","","","01","06","Bluetooth is the most widely used short-range wireless technology today. It is present in many ubiquitous devices such as tablet, personal computers, smartphones, speakers, headphones, smartwatches, to name a few. It is also used as communication protocol in many medical devices and smart home devices. In addition, its unique broadcast feature makes it a leading choice in the beacon market. Bluetooth, especially the low-energy version, is also competing in the Internet of Things field where it is included in most so-called smart things. Furthermore, with the introduction of the Bluetooth Mesh standard, it has found space in even more Internet of Things products and applications. Bluetooth mesh can solve the problems of large-scale network systems, among which building automation is a good example. In this paper, the role of the Bluetooth Mesh Networking in Internet of Things applications is discussed, and an example of application of this emerging technology in the field of building automation is shown through the use of a commercial developer kit.","","978-953-290-112-2","10.23919/SpliTech52315.2021.9566430","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9566430","Bluetooth Low Energy;Bluetooth Mesh;embedded system;building automation;Internet of Things;Wireless Sensor Network","Wireless communication;Bluetooth;System performance;Smart homes;Lighting control;Internet of Things;Building automation","","2","","21","","21 Oct 2021","","","IEEE","IEEE Conferences"
"Intelligent Analysis of Correlation between Manufacturing Industry Upgrading and International Trade under Large-Scale Internet of Things in China","L. Yang","Zhejiang International Studies University, Zhejiang, Hangzhou","2021 Third International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV)","31 Mar 2021","2021","","","399","403","Intelligent analysis of the correlation between the manufacturing industry upgrading and international trade under large-scale Internet of Things in China is presented in this article. According to the fuzzy neural network, after having input and output the data of the Internet of Things, a fuzzy set of the data of the Internet of Things can be constructed by the logic of the fuzzy system. On this basis, the article suggests the 2 aspects of the inventions. (1) Considering maximization and also capacity as the main target, using statistical channel information along with the dustering with greedy algorithm. (2) Considering manufacturing value as an output indicator to highlight the role of factor distribution. Here, the data excluding production tax as manufacturing value and designed the novel standard for the accurate estimation. The experimental results have given us the support for the analysis.","","978-1-6654-1960-4","10.1109/ICICV50876.2021.9388581","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9388581","Intelligent System","Manufacturing industries;International trade;Correlation;Substations;Manufacturing;Internet of Things;Monitoring","","1","","18","IEEE","31 Mar 2021","","","IEEE","IEEE Conferences"
"A Design Scheme for Low-Power Narrowband Internet of Things Based on TDMA","S. MA; Z. HU","School of Electronic and Information Engineering, Tongji University, Shanghai, China; School of Electronic and Information Engineering, Tongji University, Shanghai, China","2021 IEEE 3rd International Conference on Frontiers Technology of Information and Computer (ICFTIC)","24 Dec 2021","2021","","","643","647","The narrowband Internet of Things is an important branch of the Internet of Things, the problem of power consumption and unit cost have always been the bottleneck of its large-scale application. According to the 3GPP LPWAN white paper, terminals should be used for ten years under the condition of one charge, but few terminals can meet the requirements at present. This article proposed a design scheme for narrowband Internet of Things which is based on Time Division Multiple Access(TDMA). Terminal and gateway state machines are designed to make the terminal wake up and communicate with the gateway at the specified time according to the rules. And taking wireless meter reading system as the application scenario, the hardware simulation of terminal is emphasized. Under the condition of collecting data 10 times and uploading data twice a day, the terminal sleep working current is 3.9µA and the average daily equivalent power consumption is 0.24mAh, which can theoretically meet the needs of working for ten years. Based on LoRa modulation, the relationship between packet length and time under different spread spectrum factors is measured and proposed the direction of further reducing power consumption.","","978-1-6654-0605-5","10.1109/ICFTIC54370.2021.9647275","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9647275","narrowband internet of things;low power;TDMA;LoRa","Wireless communication;Time division multiple access;Power demand;Power measurement;Modulation;Logic gates;Time measurement","","","","12","IEEE","24 Dec 2021","","","IEEE","IEEE Conferences"
"IoT-Based Cyber-Physical Distribution System Planning","S. Kayamboo; B. Ray; N. Das; M. Tom","Centre for Intelligent Systems (CIS), School of Engineering and Technology, Central Queensland University, Rockhampton, Australia; Centre for Intelligent Systems (CIS), School of Engineering and Technology, Central Queensland University, Rockhampton, Australia; Centre for Intelligent Systems (CIS), School of Engineering and Technology, Central Queensland University, Rockhampton, Australia; Centre for Intelligent Systems (CIS), School of Engineering and Technology, Central Queensland University, Rockhampton, Australia","2022 IEEE International IOT, Electronics and Mechatronics Conference (IEMTRONICS)","20 Jun 2022","2022","","","1","6","Recently, there has been a large-scale integration of renewable sources to keep pace with the enormous increment of consumers’ load demand. The integration of these devices on a large scale can violate the technical and regulatory constraints of the smart power grid. Therefore, a proper control system must be designed to increase their power output and maximize the system owners’ benefit while meeting power grid standards. This paper is a collection of information to provide its reader with a holistic view of the implementation of a cyber-physical system to aid in distribution system planning. The goal of this paper is to review the current literature and identify research gaps that have yet to be fully explored. This is followed by making proposals for areas to be researched in order to improve the knowledge bank surrounding this important topic. This paper will begin by addressing the concept of a cyberphysical system by elaborating on its structure through its various layers. It will also describe the role of the Internet of Things (IoT) in improving the monitoring and control abilities of cyber-physical distribution systems. Furthermore, a detailed literature review is given to highlight the current state of distribution system research being done surrounding the implementation of cyber-physical systems to improve system planning. Based on this review, an analysis is given to better explain how a successful cyber-physical based distribution system can be constructed to achieve automation. Finally, gaps in current research are discussed to provide an understanding on which aspects of cyber-physical based distribution system planning have not been fully explored yet and where more exploration needs to be done. A list of research questions are provided to help aid potential researchers dive deeper into the area of fully automating distribution systems that consist of both renewable and non-renewable sources of energy.","","978-1-6654-8684-2","10.1109/IEMTRONICS55184.2022.9795702","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9795702","","Renewable energy sources;Mechatronics;Cyber-physical systems;Large scale integration;Planning;Smart grids;Internet of Things","","","","20","IEEE","20 Jun 2022","","","IEEE","IEEE Conferences"
"An IoT data logging instrument for monitoring and early efficiency loss detection at a photovoltaic generation plant","N. Luwes; S. J. B. Lubbe","Centre for Sustainable Smart Cities, Central University of Technology, Bloemfontein, South-Africa; Centre for Sustainable Smart Cities, Central University of Technology, Bloemfontein, South-Africa","2020 5th International Conference on Cloud Computing and Artificial Intelligence: Technologies and Applications (CloudTech)","2 Mar 2021","2020","","","1","5","Photovoltaic generation is the proses used to convert solar radiation into electrical energy, at this stage in the development of photovoltaic technology the efficiency of such systems is low and any loss of efficiency should be prevented to create an optimal system. The proposal is an IoT (Internet of things) device that can be used to prevent power loss on large solar farms by monitoring each array separately and giving feedback on efficiency. It is also able to aid in the prevention of power loss by early detection of problematic arrays. A case study calculation is done on a 50MW solar farm to show the possible financial impact of the system, as well as describing the construction and operation of the system. The literature review section describes the equations to calculate the quality and accuracy of the instrument as well as a discussion on sensors and hardware used. It also discusses a real-world case study 50MW photovoltaic plant. The methodology explains the construction and evaluation of the instrument as well as how to calculate the cost impact if implemented on a photovoltaic generation station. The results explain what the relevance is of all the calculations. Conclusions are drawn discussing the outcome and overall relevance. and demonstrating the cost-saving that can be achieved at a typical 50 MW photovoltaic generation station. This instrument's low production cost could mean that it can be incorporated in large or small scale Photovoltaic generation systems.","","978-1-7281-6175-4","10.1109/CloudTech49835.2020.9365922","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9365922","IoT;data logging;solar farms;power saving;power production increase;solar production efficiency","Photovoltaic systems;Cloud computing;Instruments;Production;Hardware;Loss measurement;Monitoring","","1","","8","IEEE","2 Mar 2021","","","IEEE","IEEE Conferences"
"Delay-optimal random access in large-scale energy harvesting IoT networks based on mean field game","D. Wang; W. Wang; Z. Zhang; A. Huang","College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China","China Communications","25 Apr 2022","2022","19","4","121","136","With energy harvesting capability, the Internet of things (IoT) devices transmit data depending on their available energy, which leads to a more complicated coupling and brings new technical challenges to delay optimization. In this paper, we study the delay-optimal random access (RA) in large-scale energy harvesting IoT networks. We model a two-dimensional Markov decision process (MDP) to address the coupling between the data and energy queues, and adopt the mean field game (MFG) theory to reveal the coupling among the devices by utilizing the large-scale property. Specifically, to obtain the optimal access strategy for each device, we derive the Hamilton-Jacobi-Bellman (HJB) equation which requires the statistical information of other devices. Moreover, to model the evolution of the states distribution in the system, we derive the Fokker-Planck-Kolmogorov (FPK) equation based on the access strategy of devices. By solving the two coupled equations, we obtain the delay-optimal random access solution in an iterative manner with Lax-Friedrichs method. Finally, the simulation results show that the proposed scheme achieves significant performance gain compared with the conventional schemes.","1673-5447","","10.23919/JCC.2022.04.010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9762669","wireless communications;energy harvesting;random access;mean field game","Delays;Couplings;Mathematical models;Internet of Things;Optimization;Energy harvesting;Physical layer","","2","","","","25 Apr 2022","","","IEEE","IEEE Magazines"
"Skyline Pattern Mining by Quantity-Utility Constraints in Large-Scale Databases","J. M. -T. Wu; R. Li; J. C. -W. Lin","College of Computer Science and Engineering, Shandong University of Science and Technology, Qingdao, China; College of Computer Science and Engineering, Shandong University of Science and Technology, Qingdao, China; Department of Computer Science, Electrical Engineering and Mathematical Sciences, Western Norway University of Applied Sciences, Bergen, Norway","2022 IEEE International Conference on Data Mining Workshops (ICDMW)","8 Feb 2023","2022","","","547","552","In recent years, taking into account the problem from one side has increasingly failed to meet the needs of society. Therefore, skyline quantity utility pattern mining (SQUPM) is proposed to combine two dimensions, utility and quantity, to re-veal more important information. In previous studies, researchers have proposed algorithms for small datasets, however, with the technological improvements and developments, the Internet of Things (loT), Internet of Vehicles, cell phone users, shopping websites, etc., are generating large amounts of data every day, and previous algorithms cannot handle large-scale datasets. This paper designs a three-stage MapReduce framework based on Hadoop, a big data processing platform, to mine skyline quantity utility patterns from large datasets. Experimental result shows that the algorithm is able to handle large-scale datasets and shows good performance on Hadoop clusters.","2375-9259","979-8-3503-4609-1","10.1109/ICDMW58026.2022.00076","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10031147","skyline quantity utility pattern mining;Hadoop;Map Reduce","Databases;Conferences;Cellular phones;Clustering algorithms;Big Data;Search problems;Sparks;Data mining;Iterative methods;Internet of Vehicles","","","","27","IEEE","8 Feb 2023","","","IEEE","IEEE Conferences"
"A Cloud-based IoT-enabled framework for BCI applications","A. B. Baghestan; Z. Zali; F. Shayegh","Department of Electrical and Computer Engineering, Isfahan University of Technology, Isfahan, Iran; Department of Electrical and Computer Engineering, Isfahan University of Technology, Isfahan, Iran; Department of Electrical and Computer Engineering, Isfahan University of Technology, Isfahan, Iran","2023 7th International Conference on Internet of Things and Applications (IoT)","22 Dec 2023","2023","","","1","5","The interplay of brain signals and the Internet of Things (IoT) is an emerging area. The processing of electroencephalographic (EEG) signals is mainly divided into two categories: (1) signal analysis for diagnosis and (2) brain-computer interfaces that can control devices through brain signals. Some applications of EEG are early detection of seizures, wheelchair control, and smart homes. Processing EEG is a complex task that requires expertise in fields such as neuroscience and computer science. There are frameworks to facilitate EEG processing, such as MNE-Python. Utilizing distributed and parallel processing is crucial in dealing with large-scale EEG data or when requiring scalable models. We have looked into platforms like WeBrain and a Spark-based framework to understand their capabilities for the issue. Based on our findings, we suggest a cloud framework. It supports the main features of previous works. It includes EEG processing capability using common machine learning (ML) and deep learning (DL) approaches based on the user’s required action paradigm. Since it is possible to run some trained models on limited resources devices in fog computing, an IoT device with caching capability is proposed to send and receive data. Collaboration and data sharing among users are made possible in this system.","","979-8-3503-6941-0","10.1109/IoT60973.2023.10365372","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10365372","EEG;BCI;IoT;Big Data;Cloud Computing","Cloud computing;Computational modeling;Wheelchairs;Smart homes;Brain modeling;Electroencephalography;Data models","","","","11","IEEE","22 Dec 2023","","","IEEE","IEEE Conferences"
"Markov Chains for Fault-Tolerance Modeling of Stochastic Networks","A. Meyers; H. Yang","Harold and Inge Marcus Department of Industrial and Manufacturing Engineering, The Pennsylvania State University, University Park, PA, USA; Harold and Inge Marcus Department of Industrial and Manufacturing Engineering, The Pennsylvania State University, University Park, PA, USA","IEEE Transactions on Automation Science and Engineering","4 Jul 2022","2022","19","3","2591","2606","Most real-world networks are time-varying, and many are subject to the stochastic functioning of their nodes and edges. Examples can be seen in the human brain undergoing an epileptic seizure, spontaneous infection and recovery in epidemics, and intermittent functioning of devices in the Internet of Things. Moreover, such networks are becoming increasingly large due to rapid technological advances. However, little has been done to study time-varying, large-scale, stochastic networks (SNs) from a reliability engineering perspective. Toward this goal, this article develops a fault-tolerance model for a type of time-varying network in which nodes (and/or edges) stochastically switch between active and inactive states. It considers fault tolerance from a global connectivity point of view, which has applications in many natural and engineered networks. Specifically, this article presents a Markov chain framework that models the dynamic behavior of nodes and allows for the computation of quantitative measures, including availability and time-to-failure metrics. To accommodate large-scale networks and emphasize global connectivity, this framework utilizes percolation theory, which has recently been of interest in the reliability engineering discipline, to characterize network failure. This article makes several contributions: it proposes a Markov chain framework for computing fault-tolerance metrics that is tractable for large-scale networks, it shows the existence of a phase transition in network availability of a time-varying SN, and it accounts for finite-size effects of percolation in the fault-tolerance model. The proposed methodology is applied to Erdös–Rényi random graphs and a real, large-scale power grid. Experimental results provide insights into network design, maintenance, and failure prevention of time-varying SNs. Note to Practitioners—This work develops a fault-tolerance model for time-varying stochastic networks in which nodes (and/or edges) randomly switch between active and inactive states. To address increasingly large-scale networks that are being studied, this article appeals to percolation theory. Fault tolerance is, thus, studied from a global connectivity perspective where the existence of a large connected component containing most of the nodes characterizes the functioning of the network. Specifically, this article presents a continuous-time Markov chain (CTMC) framework that models node dynamics and allows for the computation of fault-tolerance metrics, including network availability and mean time to failure. The proposed framework computes metrics efficiently for large networks and allows for studying their asymptotics. The percolation threshold describing the dissolution of the large connected component is used as the failure criterion in the CTMC. The practitioner should note that several assumptions are made in the proposed CTMC framework: nodes possess identical and time-invariant failure and recovery rates, node failure and recovery times are exponentially distributed, and node dynamics are independent of one another. In addition, fault-tolerance metrics computed for finite networks are estimators of the true metric values. The proposed framework is advantageous for quantifying the fault tolerance of large-scale, time-varying networks where the combinatorial explosion and a changing network topology pose challenges to the use of traditional reliability methods. A case study of a power grid network shows how to apply the proposed methodology to real networks.","1558-3783","","10.1109/TASE.2021.3093035","National Science Foundation(grant numbers:CMMI-1617148); Harold and Inge Marcus Career Professorship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9481167","Markov chain;network reliability;percolation theory;random graph;stochastic network (SN);time-varying network","Fault tolerant systems;Fault tolerance;Markov processes;Reliability engineering;Measurement;Computational modeling;Erbium","","2","","62","IEEE","12 Jul 2021","","","IEEE","IEEE Journals"
"Lightweight IoT-based Authentication Scheme in 5G Circumstance","B. Hu; J. Cao; Z. Lin; Y. Zhu; D. Liang; X. Zhang; H. Liu","Electric Power Research Institute Co., Ltd, Beijing, China; Electric Power Research Institute Co., Ltd, Beijing, China; Electric Power Research Institute Co., Ltd, Beijing, China; Electric Power Research Institute Co., Ltd, Beijing, China; State Grid Shandong Electric Power Company, Jinan, China; Electric Power Research Institute Co., Ltd, Beijing, China; State Grid Shandong Electric Power Company, Jinan, China","2023 4th International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE)","17 Oct 2023","2023","","","395","398","With the popularization of internet devices and 5G technology, the Internet of Things has become one of the most popular technologies today. However, the massive amount of data generated by various intelligent devices is one of the biggest problems in IoT scenarios. In order to solve the problems of data theft and network congestion in large-scale IoT, scholars have quickly studied authentication technologies in IoT and 5G environments. However, there is currently no achievement that combines data security and low transmission latency. In this study, we propose an authentication scheme based on a combination of IoT architecture and 5G servers. To solve the problem of excessive authentication overhead caused by massive terminal access to the network, we adopt lightweight encryption modules such as one-way hash functions and XOR operations. This reduces the computational burden and makes the proposed authentication scheme suitable for objects with limited resources, such as sensors or IoT devices.","","979-8-3503-4361-8","10.1109/ICBAIE59714.2023.10281219","State Grid Corporation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10281219","5G;IoT;Lightweight authentication","Hash functions;Protocols;5G mobile communication;Data security;Authentication;Resists;Sensors","","","","12","IEEE","17 Oct 2023","","","IEEE","IEEE Conferences"
"Application research of computer monitoring system based on ubiquitous power Internet of things in substation","H. Liu","State Grid Hubei Electric Power Co., Ltd., Yichang, China","2022 2nd International Conference on Networking, Communications and Information Technology (NetCIT)","28 Mar 2023","2022","","","20","24","Uninterruptible power supply systems are widely used in substations. The scale configuration of uninterruptible power supply systems should be configured according to the actual scale of the substation computer monitoring system, relay protection device, and intelligent auxiliary system. The number of equipment in the actual design of uninterruptible power supply systems, there are a wide variety and a large number; under the new requirements of the power Internet of Things for substation equipment, the power sector needs to consider the development and application of the current ubiquitous power Internet of things new technology. We take the actual design and application of the substation as an example to analyze the requirements of the power grid networking for related equipment, the statistics of the load and the design of the uninterrupted power supply system. In order to meet the requirements of unmanned duty, all the newly built substations are comprehensive automatic substations. This paper analyzes the application of computer monitoring system in substation monitoring system.","","978-1-6654-9273-7","10.1109/NetCIT57419.2022.00012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10078987","component;ubiquitous power Internet of things;computer monitoring system;substation","Substations;Power supplies;Protective relaying;Imaging;Organizations;Power grids;Information and communication technology","","","","5","IEEE","28 Mar 2023","","","IEEE","IEEE Conferences"
"Quantization Backdoors to Deep Learning Commercial Frameworks","H. Ma; H. Qiu; Y. Gao; Z. Zhang; A. Abuadbba; M. Xue; A. Fu; J. Zhang; S. F. Al-Sarawi; D. Abbott","School of Electrical and Electronic Engineering, University of Adelaide, Australia; School of Computer Science and Engineering, Nanjing University of Science and Technology, China; Data61, CSIRO, Australia; University of Western Australia, Perth, Australia; Data61, CSIRO, Australia; Data61, CSIRO, Australia; School of Computer Science and Engineering, Nanjing University of Science and Technology, China; College of Semiconductors (College of Integrated Circuits), Hunan University, China; School of Electrical and Electronic Engineering, University of Adelaide, Australia; School of Electrical and Electronic Engineering, University of Adelaide, Australia","IEEE Transactions on Dependable and Secure Computing","","2023","PP","99","1","18","Due to their low latency and high privacy preservation, there is currently a burgeoning demand for deploying deep learning (DL) models on ubiquitous edge Internet of Things (IoT) devices. However, DL models are often large in size and require large-scale computation, which prevents them from being placed directly onto IoT devices, where resources are constrained, and 32-bit floating-point (float-32) operations are unavailable. Commercial framework (i.e., a set of toolkits) empowered model quantization is a pragmatic solution that enables DL deployment on mobile devices and embedded systems by effortlessly post-quantizing a large high-precision model (e.g., float-32) into a small low-precision model (e.g., int-8) while retaining the model inference accuracy. However, their usability might be threatened by security vulnerabilities. This work reveals that standard quantization toolkits can be abused to activate a backdoor. We demonstrate that a full-precision backdoored model which does not have any backdoor effect in the presence of a trigger—as the backdoor is dormant—can be activated by (i) TensorFlow-Lite (TFLite) quantization, the only product-ready quantization framework to date, and (ii) the beta released PyTorch Mobile framework. In our experiments, we employ three popular model architectures (VGG16, ResNet18, and ResNet50), and train each across three popular datasets: MNIST, CIFAR10 and GTSRB. We ascertain that all trained float-32 backdoored models exhibit no backdoor effect even in the presence of trigger inputs. Particularly, four influential backdoor defenses are evaluated, and they fail to identify a backdoor in the float-32 models. When each of the float-32 models is converted into an int-8 format model through the standard TFLite or PyTorch Mobile framework's post-training quantization, the backdoor is activated in the quantized model, which shows a stable attack success rate close to 100% upon inputs with the trigger, while it usually behaves upon non-trigger inputs. This work highlights that a stealthy security threat occurs when an end-user utilizes the on-device post-training model quantization frameworks, informing security researchers of a cross-platform overhaul of DL models post-quantization even if these models pass security-aware front-end backdoor inspections. Significantly, we have identified Gaussian noise injection into the malicious full-precision model as an easy-to-use preventative defense against the PQ backdoor. The attack source code is released at https://github.com/quantization-backdoor.","1941-0018","","10.1109/TDSC.2023.3271956","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10113762","Deep learning;PyTorch mobile;quantization backdoor attack;TensorFlow- lite","Quantization (signal);Computational modeling;Internet of Things;Australia;Training;Security;Inspection","","1","","","IEEE","1 May 2023","","","IEEE","IEEE Early Access Articles"
"Optimal Sizing of Solar Panel and Battery Storage for A Smart Aquaponic System","M. F. Mohd Ali; A. Asrul Ibrahim; M. H. Mohd Zaman","Dept. of Electrical, Electronic and Systems Engineering, Universiti Kebangsaan Malaysia UKM Bangi, Malaysia; Dept. of Electrical, Electronic and Systems Engineering, Universiti Kebangsaan Malaysia UKM Bangi, Malaysia; Dept. of Electrical, Electronic and Systems Engineering, Universiti Kebangsaan Malaysia UKM Bangi, Malaysia","2021 IEEE 19th Student Conference on Research and Development (SCOReD)","29 Dec 2021","2021","","","186","191","More attention has been given to developing a smart aquaponic system in recent years, mainly due to the shortage of food supplies and limited area for agriculture. The smart aquaponic system consists of internet of things (IoT) technology to enable continuous monitoring and autonomous operation. This, however, leads to higher power consumption as compared to the traditional system. Alternatively, the availability of solar resources in tropical countries, such as Malaysia can be utilized to reduce power consumption of the smart aquaponic system. Therefore, this study aims to determine the optimal size of a photovoltaic (PV) system to accommodate the power consumption. This study involves the development of the smart aquaponic using an IoT monitoring and control system. Then, a data logger is developed to collect the power consumption of the smart aquaponic system and measure the available solar energy resources in the area. After that, an optimal size of the PV system can be determined from the collected data. The results show that a 25 W solar panel with a 10 Ah lithium-ion battery is enough to accommodate the developed small-scale smart aquaponic system. It is clearly shown that an accurate size of the PV system for a particular aquaponic system at the identified installation site can be determined using the proposed approach.","2643-2447","978-1-6654-0193-7","10.1109/SCOReD53546.2021.9652782","Universiti Kebangsaan Malaysia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9652782","Internet of things;Optimal Sizing;Smart Aquaponic;Solar energy","Temperature measurement;Lithium-ion batteries;Power demand;Solar energy;Battery charge measurement;Storage tanks;Solar panels","","2","","11","IEEE","29 Dec 2021","","","IEEE","IEEE Conferences"
"Blockchain Security for 5G Network using Internet of Things Devices","O. O. Khalifa; M. Z. Ahmed; R. A. Saeed; S. Hussaini; A. H. A. Hashim; E. A. El-Khazmi","Elect. & Computer Engineering Dept., International Islamic University, Kuala Lumpur, Malaysia; Elect. & Computer Engineering Dept., International Islamic University, Kuala Lumpur, Malaysia; College of Computer and Information Technology, Taif University, Saudi Arabia; Computer Engineering, University of Maiduguri, Maiduguri, Nigeria; Elect. & Computer Engineering Dept., International Islamic University, Kuala Lumpur, Malaysia; College Of Electronic Technology, Bani Walid, Libya","2022 7th International Workshop on Big Data and Information Security (IWBIS)","25 Oct 2022","2022","","","101","106","Network of vehicles using Internet of Things (IoT) frameworks have efficient characteristics of modern intelligent transportation system with a few challenges in vehicular ad-hoc networks (VANETs). However, its security framework is required to manage trust management by preserving user privacy. Wireless mobile communication (5G) system is regarded as an outstanding technology that provide ultra-reliable with limited latency wireless communication services. By extension, integrating Software Defined Network (SDN) with 5G-VANET enhances global information gathering and network control. Therefore, real-time IoT application for monitoring transport services is efficiently supported. These ensures vehicular security on this framework. This paper provides a technical solution to a self-confidential framework for a smart transport system. This process exploiting IoT for vehicle communication by incorporating SDN and 5G technology. Due to some features of blockchain, this framework has been implemented to provide various alternative support for vehicular smart services. This involves real-time access to cloud to stream video information and protection management to vehicular network. The implemented framework presents a promising technique and reliable vehicular IoT environment while ensuring user privacy. Results of simulation presents that vehicular nodes/messages (malicious) and overhead is detected and the impact on network performance are satisfactory when deployed in large-scale network scenarios.","","978-1-6654-8950-8","10.1109/IWBIS56557.2022.9924937","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9924937","Blockchain;Vehicle;Cloud;and Smart","Wireless communication;Privacy;Cloud computing;5G mobile communication;Real-time systems;Ad hoc networks;Blockchains","","2","","9","IEEE","25 Oct 2022","","","IEEE","IEEE Conferences"
"Applying Aspect-Oriented Design Methodology to Manage Time-Validity of Information in Internet-of-Things Systems","V. O'Neill; B. Soh","Department of Computer Science and Information Technology, La Trobe University, Melbourne, Australia; Department of Computer Science and Information Technology, La Trobe University, Melbourne, Australia","2022 IEEE World AI IoT Congress (AIIoT)","13 Jul 2022","2022","","","749","752","The Internet of Things (IoT) is becoming increasingly ubiquitous, typified in software by large-scale multi-agent systems of heterogeneous agents. IoT devices are constrained in terms of memory and processing power, limiting their capacity to hold large sets of information upon which decision-making logic must execute. IoT devices are also frequently deployed as distributed sensors constrained in terms of time, location and communications bandwidth. These constraints demand a level of multi-agent communication and co-ordination to provide accurate, up-to-date information on-demand to different intelligent agents in the system. In this paper, we propose a novel method by which Aspect-Oriented Software Design can be applied to managing the validity of time-constrained data in IoT systems while decoupling the application code from this concern.","","978-1-6654-8453-4","10.1109/AIIoT54504.2022.9817345","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9817345","internet of things;multi-agent systems;software architecture;distributed computing;intelligent agents","Codes;Software design;Software architecture;Computational modeling;Data models;Software;Complexity theory","","1","","21","IEEE","13 Jul 2022","","","IEEE","IEEE Conferences"
"Invited: IoB: The Vision of the Internet of Bodies","A. Datta; S. Sen","Elmore Family School of Electrical and Computer Engineering, Purdue University, West Lafayette, USA; Elmore Family School of Electrical and Computer Engineering, Purdue University, West Lafayette, USA","2023 IEEE 66th International Midwest Symposium on Circuits and Systems (MWSCAS)","31 Jan 2024","2023","","","444","448","Over six decades of semiconductor technology scaling (Moore's Law) and subsequently system size scaling (Bell's Law) has reduced the size of unit computing to virtually zero. This has led to computing becoming ubiquitous in everything around us, making everyday things smart. Similarly, tremendous progress in communication capacity (Shannon's theorem) has made these smart things connected to the internet and forming the Internet of Things (IoT). Many of these smart, connected devices are present in, on, or around the human body. This subset of IoT around the human body has a distinguishing feature, that it has a common medium, i.e. the body itself. This subset is increasingly becoming popular as the Internet of Bodies (IoB). In this paper, we look into the need and growth of IoB devices, including the technological landscape, current challenges and the future that IoB will enable for empowering humans.","1558-3899","979-8-3503-0210-3","10.1109/MWSCAS57524.2023.10405903","National Science Foundation(grant numbers:CCSS 1944602); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10405903","Internet of Bodies (IoB);Body Area Network (BAN);Ubiquitous Computing;Internet of Things (IoT)","Semiconductor device modeling;Circuits and systems;Moore's Law;Internet of Things","","","","37","IEEE","31 Jan 2024","","","IEEE","IEEE Conferences"
"Real-Time Deep Anomaly Detection Framework for Multivariate Time-Series Data in Industrial IoT","H. Nizam; S. Zafar; Z. Lv; F. Wang; X. Hu","Department of Computer Science and Technology, Dalian University of Technology, Dalian, China; Department of Computer Science and Technology, Dalian University of Technology, Dalian, China; Department of Computer Science and Technology, Dalian University of Technology, Dalian, China; Department of Computer Science and Technology, Dalian University of Technology, Dalian, China; Department of Computer Science and Technology, Dalian University of Technology, Dalian, China","IEEE Sensors Journal","30 Nov 2022","2022","22","23","22836","22849","The data produced by millions of connected devices and smart sensors in the Industrial Internet of Things (IIoT) is highly dynamic, large-scale, heterogeneous, and time-stamped. These time-stamped data are the core of IIoT automation and have the potential to affect industrial processes intensely. It poses significant challenges to effectively detect anomalies from time-series data and deliver actionable insights in real time to drive improvements to industrial processes. In most practical applications, where data are used to make automated decisions, real-time anomaly detection is critical. With this focus, in this article, we advise a hybrid end-to-end deep anomaly detection (DAD) framework to accurately detect anomalies and extremely rare events on sensitive, Internet of Things (IoT) streaming data in real time or near real time. The proposed framework is based on a convolutional neural network (CNN) and a two-stage long short-term memory (LSTM)-based Autoencoder (AE). We exploit a two-stage LSTM AE in parallel to detect anomalies and extremely rare events hidden in massive sensor data by identifying short- and long-term variations in actual sensor values from the predicted values. We design and train a hybrid model using the Keras/TensorFlow framework as the backend. The experimental results on one simulation and two real datasets demonstrate that the proposed framework achieved better performance and outperforms other state-of-the-art competitive models. Moreover, to prove that the proposed model can be designed for the network edge, we train, optimize, and quantize the model to run-on resource-constrained (i.e., edge) devices. Further evaluation indicates that the training and inference time for each sample is short enough to carry out anomaly detection on edge.","1558-1748","","10.1109/JSEN.2022.3211874","National Key Research and Development Program of China(grant numbers:2018YFA0704605); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9915308","Anomaly detection;deep learning (DL);Industrial Internet of Things (IIoT);long short-term memory (LSTM) autoencoder (AE);machine learning (ML);multivariate time series;rare event detection;sensor data","Anomaly detection;Industrial Internet of Things;Image edge detection;Real-time systems;Feature extraction;Training;Intelligent sensors","","10","","46","IEEE","10 Oct 2022","","","IEEE","IEEE Journals"
"A Blockchain-Enabled Explainable Federated Learning for Securing Internet-of-Things-Based Social Media 3.0 Networks","S. Salim; B. Turnbull; N. Moustafa","School of Engineering and Information Technology, University of New South Wales, Canberra, ACT 2612, Australia (e-mail: s.salim@student.adfa.edu.au); School of Engineering and Information Technology, University of New South Wales, Canberra, ACT 2612, Australia.; School of Engineering and Information Technology, University of New South Wales, Canberra, ACT 2612, Australia.","IEEE Transactions on Computational Social Systems","","2021","PP","99","1","17","Social media (SM) 3.0 integrates SM platforms, such as Facebook and Twitter, with the Internet of Things (IoT), and has a great potential to change how we interact with mobile devices, online platforms, and the world around us. This integration with end users produces large-scale and heterogeneous data sources that demand machine learning (ML)-based data analytics for decision-making and to provide security against ML and data privacy attacks. The development of privacy-aware ML models within a federated learning (FL) ecosystem can empower an entire network to learn from data in a decentralized manner. In this article, we propose a differentially privacy blockchain-based explainable FL (DP-BFL) framework by harnessing the ever-evolving power of SM 3.0 networks. This framework permits any Internet empowered device to partake and contribute data to a global privacy preserved model. In this framework, participants will upload the differentially private local updates to the miners of blockchain, where the local updates will be evaluated and rewarded. The experimental results obtained from real-world datasets, namely, SM 3.0 and MNIST, demonstrated that the proposed framework could achieve high utility, enhanced privacy, and elevated efficiency. More Specifically, the experimental analysis of our proposed framework reveals the following two key properties. First, our proposed DP-BFL yields noticeable performance improvements in the applied learning models with high privacy and comparable utility levels, in terms of accuracy and f-measure metrics, to a standard FL and centralized learning approaches under the restriction of privacy preservation. Second, given a certain number of the malicious entities, DP-BFL allowed an enhanced recognition of users' preferences in the SM 3.0 dataset and precise prediction of images' class in the MNIST dataset while mitigating the impact of the malicious entities' poisoned updates. Moreover, as the proposed DP-BFL attains DP on the local model's update, it is considered the same as the standard FL-based setting, along with some kinds of privacy preservation on the uploaded model's updates.","2329-924X","","10.1109/TCSS.2021.3134463","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9663403","Blockchain technology;differential privacy;federated learning (FL);Internet of Things (IoT);privacy preservation;social media (SM) 3.0.","Data privacy;Data models;Blockchains;Privacy;Training;Social networking (online);Biological system modeling","","17","","","IEEE","28 Dec 2021","","","IEEE","IEEE Early Access Articles"
"Decision Support Platform for Production of Chili using IoT, Cloud Computing, and Machine Learning Approach","O. Elijah; S. K. A. Rahim; E. A. Abioye; M. J. Musa; Y. O. Salihu; A. A. Oremeyi","Wireless Communication Center School of Electrical Engineering Faculty of Engineering, Universiti Teknologi Malaysia, Johor Bahru, Malaysia; Wireless Communication Center School of Electrical Engineering Faculty of Engineering, Universiti Teknologi Malaysia, Johor Bahru, Malaysia; Dept. of Electrical Electronics Engineering, Akanu Ibiam Federal Polytechnic, Unwana, Ebonyi State, Nigeria; Dept. of Electronics and Telecommunications Engineering, Ahmadu Bello University, Zaria, Nigeria; Dept. of Computer Engineering, Kaduna Polytechnic, Kaduna, Nigeria; School of Engineering, Kogi State Polytechnic Lokoja, Nigeria","2022 IEEE Nigeria 4th International Conference on Disruptive Technologies for Sustainable Development (NIGERCON)","27 Jun 2022","2022","","","1","5","The chili crop is largely grown in several regions of the world, especially in Asian and African countries. It is a major source of income for both small- and large-scale farmers. Unfortunately, chili farmers have to contend with the challenge of pests and diseases and the need for timely decisions to have a bountiful production. To solve this problem, this paper proposes a chili-decision support platform (chili-DSP) that can help farmers detect diseases, and nutrient deficiency and make timely decisions. The proposed system integrates the internet of things, cloud computing, and data analytics technologies. The framework and architecture of the proposed chili-DSP are presented in this paper and the preliminary results using the convolutional neural network (CNN) for the classification of chili are presented. The result shows that CNN provides an accurate prediction of the learned data set and can be extended to larger data set for real-time classification of chili diseases. The chili-DSP is expected to provide a comprehensive feature and support that will help the chili farmers enhance the production of chili while minimizing losses.","2377-2697","978-1-6654-7978-3","10.1109/NIGERCON54645.2022.9803077","Universiti Teknologi Malaysia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9803077","chili;decision support platform;framework;machine learning;smart agriculture","Cloud computing;Production;Computer architecture;Object detection;Real-time systems;Convolutional neural networks;Sustainable development","","1","","16","IEEE","27 Jun 2022","","","IEEE","IEEE Conferences"
"Role of Neural Network, Fuzzy, and IoT in Integrating Artificial Intelligence as a Cyber Security System","P. Das; M. Illa; R. Pokhariyal; A. Latoria; Hemlata; D. J. B. Saini","School of Information Technology, AURO University, Surat, Gujarat; Artificial Intelligence & Data Science (AI&DS), Vignan's Institute Of Information Technology; Department of Computer Science & Engineering, Graphic Era Deemed to be University, Dehradun, Uttarakhand, India; School of Information Technology, AURO University, Surat, Gujarat; Department of Computer Science and Engineering, Central University of Haryana, Mahendergarh, Haryana; Department of Computer Science & Engineering, Sawmi Rama Himalayan University, Dehradun, India","2023 Second International Conference on Electronics and Renewable Systems (ICEARS)","5 Apr 2023","2023","","","652","658","The ""Internet of Things"" has a vast number interconnected devices. These interconnected devices collect vital data that may have a significant effect on the company, society, and the environment as a whole. IoT application has grown significantly in recent times, and with it, so do worries about cybersecurity. Artificial intelligence (AI) is at the forefront of the technology of cybersecurity and is employed to create intricate algorithms to safeguard systems and networks like IoT devices. But cybercriminals have learned how to take advantage of AI, and they have even started to deploy AI in analyzing cyberattacks. Due to the limited computing power and memory capacities of IoT systems, conventional high-end cybersecurity measures are inadequate to protect an IoT system. The need for accessible, distributed, and robust smart security systems is highlighted by this. Large- and small-scale heterogeneous datasets are no match for DL. In this research, a multilayer cybersecurity strategy based on DL is used to safeguard the TL of IoT systems. The developed framework tests the proposed multi-layer strategy using the intrusion identification statistics obtained from CIC-IDS (2018), ToN, and BoT-IoT. Consequently, depending on the analyzed parameters, the proposed model has outperformed the other approaches and achieved 98% accuracy.","","979-8-3503-4664-0","10.1109/ICEARS56392.2023.10084988","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10084988","Artificial intelligence;IoT;neural network;fuzzy;cybersecurity","Training;Renewable energy sources;Artificial neural networks;Nonhomogeneous media;Solids;Internet of Things;Artificial intelligence","","","","37","IEEE","5 Apr 2023","","","IEEE","IEEE Conferences"
"Large-Scale Environmental Sensing of Remote Areas on a Budget","D. Wu; A. S. Bogdan; J. Liebeherr","Spero Analytics, Canada; Advanced Micro Devices Inc., Canada; University of Toronto, Canada","IEEE Internet of Things Magazine","6 Jun 2023","2023","6","2","130","136","By enabling large-scale in-situ environmental monitoring of remote areas, the Internet-of-Things (IoT) can play a crucial role in quantifying and responding to climate change. Sensing of uninhabited and many rural regions creates a need for inexpensive battery-powered IoT systems that can be deployed across large areas. Today, such systems are woefully unavailable. This article presents a scalable IoT architecture for low-cost and low-power in-situ environmental sensing. The architecture is anchored by self-organizing LoRa mesh networks that can be scaled to a hundred nodes, covering a hundred or more square kilometers, at a cost of less than US$15 per node. A low-power design enables nodes to operate for years on two AA batteries in many sensing applications. LoRa mesh networks connect to a cloud-based IoT backend via a battery-powered modular gateway, which supports Internet access over a WiFi network, a cellular network, and a low-earth orbit satellite system.","2576-3199","","10.1109/IOTM.001.2200185","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10145041","","Mesh networks;Climate change;Costs;Satellites;Spread spectrum communication;Environmental management;Sensors;Soil measurements","","","","15","IEEE","6 Jun 2023","","","IEEE","IEEE Magazines"
"IoT based Smart Small Scale Solar Energy Planning using Evolutionary Fuzzy Association Rule Mining","W. Wedashwara; I. Wayan Agus Arimbawa; A. Hidayat Jatmika; A. Zubaidi; T. Mulyana","Dept of Informatics Engineering, Mataram University, Mataram, Indonesia; Dept of Technology Management, Economic, and Policy Seoul National University, Seoul, South Korea; Dept of Informatics Engineering, Mataram University, Mataram, Indonesia; Dept of Informatics Engineering, Mataram University, Mataram, Indonesia; Dept of Information System, Telkom University, Bandung, Indonesia","2020 International Conference on Advancement in Data Science, E-learning and Information Systems (ICADEIS)","11 Dec 2020","2020","","","1","6","Along-Track Stereo Sun Glitter (ATSSG) shows Indonesia especially Lombok has high solar energy potential, not only on large scale but also small scale such as for hybrid-based electricity savings. The amount of energy that can be saved through solar power is difficult to predict without measurement and planning. The paper proposed the Smart Small Scale Solar Energy Planning using Internet of Things (IoT) by collaborating Wireless Sensor Network (WSN) as data collector and Evolutionary Fuzzy Association Rule Mining (EFARM) as Decision Support System (DSS). WSN collects data generated solar energy by the solar panel and direct current (DC) energy usage by electrical devices. Then both collected data are processed by EFARM through an interpretation of tree-based fuzzy rule extractor to conclude the potential of energy efficiency. The Evaluation is carried out for two weeks using two solar panels with light intensity, temperature, and humidity sensors as a comparison for environment condition and generated energy. Through evaluation EFARM has shown the capability to Interpreted patterns of generated energy and energy consumption by achieving a high average of supports(0.247,0.236), confidence(0.393,0.219) and scores(0.335,0.127) for full-length rules; describe the rules correlation between generated energy and energy consumption to conclude the potential of energy efficiency, and make decision support for the number of panels and batteries to be added with relatively low mean square error (6.094).","","978-1-7281-8272-8","10.1109/ICADEIS49811.2020.9276905","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9276905","EFARM;Solar Energy;Genetic Programming;IoT","Batteries;Solar energy;Solar panels;Standards;Wireless sensor networks;Temperature measurement;Planning","","3","","16","IEEE","11 Dec 2020","","","IEEE","IEEE Conferences"
"Aloe: Fault-Tolerant Network Management and Orchestration Framework for IoT Applications","S. Chattopadhyay; S. Chatterjee; S. Nandi; S. Chakraborty","Department of CSE, Indian Institute of Technology Guwahati, Guwahati, India; Department of CSE, Indian Institute of Technology Kharagpur, Kharagpur, India; Department of CSE, Indian Institute of Technology Guwahati, Guwahati, India; Department of CSE, Indian Institute of Technology Kharagpur, Kharagpur, India","IEEE Transactions on Network and Service Management","9 Dec 2020","2020","17","4","2396","2409","Internet of Things (IoT) platforms use a large number of low-cost resource constrained devices and generates millions of short-flows. In-network processing is gaining popularity day by day to handle IoT applications and services. However, traditional software-defined networking (SDN) based management systems are not suitable to handle the plug and play nature of such systems. In this paper, we propose Aloe, an auto-scalable SDN orchestration framework. Aloe exploits in-network processing framework by using multiple lightweight controller instances in place of service grade SDN controller applications. The proposed framework ensures the availability and significant reduction in flow-setup delay by deploying instances in the vicinity the resource constraint IoT devices dynamically. Aloe supports fault-tolerance with recovery from network partitioning by employing self-stabilizing placement of migration capable controller instances. Aloe also provides resource reservation for micro-controllers so that they can ensure the quality of services (QoS). The performance of the proposed system is measured by using an in-house testbed along with a large scale deployment in Amazon Web services (AWS) cloud platform. The experimental results from these two testbeds show significant improvement in response time for standard IoT based services. This improvement of performance is due to the reduction in flow-setup time. We found that Aloe can improve flow-setup time by around 10%-30% in comparison to one of the states of the art orchestration framework.","1932-4537","","10.1109/TNSM.2020.3008426","Science and Engineering Research Board (SERB) Early Career Research Award, File number: ECR/2017/000121 Dated 18/07/2017; Department of Science and Technology, Government of India; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138447","Orchestration framework;fault-tolerance;programmable network;IoT;in-network processing;SDN","Internet of Things;Fault tolerance;Fault tolerant systems;Control systems;Delays;Computer architecture;Process control","","6","","40","IEEE","10 Jul 2020","","","IEEE","IEEE Journals"
"Towards avatar-based discovery for IoT services using social networking and clustering mechanisms","K. KHADIR; N. GUERMOUCHE; T. MONTEIL; A. GUITTOUM","LAAS-CNRS, Université de Toulouse, INSA, Toulouse, France; LAAS-CNRS, Université de Toulouse, INSA, Toulouse, France; LAAS-CNRS, Université de Toulouse, INSA, Toulouse, France; LAAS-CNRS, Université de Toulouse, INSA, Toulouse, France","2020 16th International Conference on Network and Service Management (CNSM)","30 Nov 2020","2020","","","1","7","The Internet of Things (IoT) paradigm is defined as a complex large scale and distributed, and dynamic infrastructure composed of a huge number of heterogeneous devices. Identifying particular services provided by a massive number of IoT devices remains a challenging problem. The classical centralized discovery approaches are no more suitable. In our previous work, we have proposed an avatar-based Fog-Cloud architecture to support IoT object management. The avatars are defined as virtual entities of heterogeneous IoT objects. They are endowed with reasoning capabilities that make them able to coordinate with each other to accomplish an IoT application. Through this paper, we propose to extend our previous work by a new distributed mechanism for efficient discovery of IoT services relying on Social Networking (SN) and clustering methods. This is particularly interesting in large scale IoT systems since it allows to reduce the search space so that only the neighboring social avatars most apt to participate in the collaboration to accomplish an IoT application are considered. The proposed solution has been evaluated in connected vehicles context.","2165-963X","978-3-903176-31-7","10.23919/CNSM50824.2020.9269040","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9269040","Avatars;Social Web of Things;Fuzzy c-means;IoT Services;Distributed discovery;Semantic","Internet of Things;Avatars;Social networking (online);Task analysis;Semantics;Vehicle dynamics;Scalability","","4","","24","","30 Nov 2020","","","IEEE","IEEE Conferences"
"IoT for Water Quality Categorization","H. Sastrohartono; A. W. Krisdiarto; A. I. Uktoro; R. Rahutomo; T. Suparyanto; B. Pardamean","Agricultural Engineering Department, Faculty of Agricultural Technology, Institute of Agriculture STIPER, Yogyakarta, Indonesia; Agricultural Engineering Department, Faculty of Agricultural Technology, Institute of Agriculture STIPER, Yogyakarta, Indonesia; Agricultural Engineering Department, Faculty of Agricultural Technology, Institute of Agriculture STIPER, Yogyakarta, Indonesia; Information System Department, School of Information Systems, Bina Nusantara University, Jakarta, Indonesia; Bioinformatics & Data Science Research Center, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, BINUS Graduate Program Master of Computer Science, Bina Nusantara University, Jakarta, Indonesia","2023 5th International Conference on Cybernetics and Intelligent System (ICORIS)","18 Dec 2023","2023","","","1","5","In agricultural water research, the adoption of Internet of Things (IoT) technology has emerged as a pivotal approach for large-scale data collection. Water availability in the context of water quality is very important, both for domestic and industrial purposes. For domestic purposes, drinking water and bathing water are separated. Meanwhile, for the palm oil industry, boiler filler is differentiated from additional process water (dilution water). Water quality parameters can be assessed from turbidity and Total Dissolve Solid (TDS). Measurements using measuring instruments separately and repeatedly require significant energy, time, and costs. This research was conducted with the primary objective of presenting a novel method for categorizing water quality with the approach of IoT sensor technology. The research methodology entailed the utilization of an integrated IoT water sensors system in conjunction with manual water categorization. The methods consist of (1) system design, (2) design and installation of sensor and IoT-based microcontrollers, and (3) accuracy and precision testing compared with laboratory measurements. The precision of the integrated IoT water sensors was assessed through a dedicated sensor precision test, resulting in an accuracy rate of 94.4% for the turbidity sensor and 97.5% for the TDS sensor. Notably, this approach successfully discriminated drinking water with valid categorization, while other water types, including groundwater, water with tea, and water with coffee, yielded null categorization results.","","979-8-3503-6948-9","10.1109/ICORIS60118.2023.10352234","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10352234","Internet of Things;water quality;water sensors;data categorization","Energy measurement;Turbidity;Solids;Time measurement;Sensor systems;Internet of Things;Petroleum industry","","","","29","IEEE","18 Dec 2023","","","IEEE","IEEE Conferences"
"Industry 4.0: Latin America SMEs Challenges","M. A. Mendoza P.; S. Cuellar","Catholic University, Bogota, Colombia; Catholic University, Bogota, Colombia","2020 Congreso Internacional de Innovación y Tendencias en Ingeniería (CONIITI)","2 Nov 2020","2020","","","1","6","In the light of several national advanced manufacturing strategies such as Industry 4.0, this article examines the challenges of Industry 4.0 adoption of Latin American small and medium-sized manufacturing firms (SMEs).The future of Industrial systems that has encompassed so many investigative processes in the last decade, surrounds the fourth industrial revolution, which covers the Internet of Things, Augmented Reality, real-time connection, Data Mining, Big Data, Cloud computing, Cyber Physical Systems (CPS), among others. The reality is that the majority of industries that have implemented these technologies are those large-scale companies with great leverage and long-term investment power. The development of this so-called Fourth Industrial Revolution is disconnected from the SMEs, despite the fact that in Latin America they represent more than 95% of registered companies. In this study, an analysis of scientific publications on small and medium-sized companies is carried out, in addition, some variables necessary for the real measurement of the application of Industry 4.0 in Latin America are proposed. Flexibility, quality, competitive advantage and cost benefit were key variables to create a suitable model to be implemented in SMEs.","","978-1-7281-9466-0","10.1109/CONIITI51147.2020.9240428","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9240428","Industry 4.0;SME;MSME;Latin America;IOT;CPS;Challenges 4.0","Industries;Productivity;Economics;Technological innovation;Companies;Sustainable development;Investment","","2","","40","IEEE","2 Nov 2020","","","IEEE","IEEE Conferences"
"Intelligent planning algorithm for time synchronization network for large-scale power IoT terminals","X. Libo; G. Ren; Z. Yu; D. Yawen; L. Yuxiang; W. Hui","Information & Telecommunication Branch, State Grid Liaoning Electric Power Co., Ltd., Shenyang, China; Shenyang Power Supply Company, State Grid Liaoning Electric Power Co., Ltd., Shenyang, China; Information & Telecommunication Branch, State Grid Liaoning Electric Power Co., Ltd., Shenyang, China; Anhui Jiyuan Software Co., Ltd., State Grid Information & Telecommunication Group Co., Ltd., Hefei, China; Anhui Jiyuan Software Co., Ltd., State Grid Information & Telecommunication Group Co., Ltd., Hefei, China; Anhui Jiyuan Software Co., Ltd., State Grid Information & Telecommunication Group Co., Ltd., Hefei, China","2022 IEEE 10th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)","3 Aug 2022","2022","10","","2405","2408","The power system is a real-time balance system. The large-scale power Internet of Things terminal can realize real-time state perception and instantaneous control, which can effectively guarantee the stable and safe operation of the power grid. Information perception, transmission, processing and decision-making are very dependent on the time synchronization of each link, so it is necessary to unify large-scale power IOT terminals and systems to the same time standard, which is crucial for power grid operation control, fault analysis and improvement of user service quality. This article in view of the large power content union time synchronization between terminals and systems link planning intelligent algorithm is put forward, in a given network topology, automatic planning time synchronization backup link, at the same time caused by asymmetric error elimination method for fashion design link, improving on large power league, the stability of the terminal time of wide-area synchronized and terminal pair precision.","2693-2865","978-1-6654-2207-9","10.1109/ITAIC54216.2022.9836536","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9836536","Minimum spanning tree;clock synchronization;Beidou navigation satellite system;power internet of thing","Protocols;Network topology;Power system stability;Real-time systems;Power grids;Planning;Delays","","","","9","IEEE","3 Aug 2022","","","IEEE","IEEE Conferences"
"A Smart Home Agriculture System Based on Internet of Things","V. K. Akram; M. Challenger","International Computer Institute, Ege University, Izmir, Bornova; University of Antwerp and Flanders Make, Flanders, Belgium","2021 10th Mediterranean Conference on Embedded Computing (MECO)","1 Jul 2021","2021","","","1","4","Internet of Things (IoT) has a growing application in agriculture and smart farming. Different monitoring, controlling and tracking systems have been proposed for increasing the efficiency and quality of agricultural products. While most of the existing systems focus on industrial farming, many people would like to create their own small-scale farms at home to produce organic products for their daily consumption. However, due to the lack of agricultural knowledge and infrastructures, people usually unable to produce healthy agricultural products at home. This paper proposes an IoT-based system for home agriculture to create small-scale farms in indoor locations. The proposed system uses ESP-32 devices and connected sensors to measure different quantities of the soil and air conditions to create a more suitable environment for growing the plants. Using the mobile application, the users can connect and configure the sensing devices over Bluetooth connections. The sensed data are sent to a web server over a WiFi connection. The web server stores the received data and provides real-time reports about the environment and plants. Based on the received data and the plant requirements, the webserver may send notification messages to the user's mobile phone.","2637-9511","978-1-6654-3912-1","10.1109/MECO52532.2021.9460276","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9460276","Internet of Things;Embedded Systems;Web Application;Smart Agriculture","Soil measurements;Smart homes;Soil;Web servers;Agricultural products;Sensor systems;Real-time systems","","2","","17","IEEE","1 Jul 2021","","","IEEE","IEEE Conferences"
"Deep Actor–Critic Learning-Based Robustness Enhancement of Internet of Things","N. Chen; T. Qiu; C. Mu; M. Han; P. Zhou","School of Computer Science and Technology, College of Intelligence and Computing, and the Tianjin Key Laboratory of Advanced Networking, Tianjin University, Tianjin, China; School of Computer Science and Technology, College of Intelligence and Computing, and the Tianjin Key Laboratory of Advanced Networking, Tianjin University, Tianjin, China; School of Electrical and Information Engineering, Tianjin University, Tianjin, China; Faculty of Electronic Information and Electrical Engineering, Dalian University of Technology, Dalian, China; School of Cyber Science and Engineering, Huazhong University of Science and Technology, Wuhan, China","IEEE Internet of Things Journal","10 Jul 2020","2020","7","7","6191","6200","The extensive applications in the Internet of Things (IoT) have inspired a growing network scale. However, due to the resource-limited IoT devices and the numerous cyber attacks against applications, maintaining the robustness and communication capabilities for the applications is increasingly challenging. In this article, we consider IoT network topologies that provide robust communication for heterogeneous networks and study the networking stability of IoT devices and the intelligent evolution computing in network architectures. We explicate the network robustness problem both for the network architecture and the resistance to cyber attacks. For the network architecture, we optimize the robustness of IoT network topology with a scale-free network model which has good performance in random attacks. In the case with the resistance to cyber attacks, a deep deterministic learning policy (DDLP) algorithm is proposed to improve the stability for large-scale IoT applications. Simulations show that the proposed algorithms greatly advance the robustness of IoT network topology compared to other algorithms, with a less computational cost.","2327-4662","","10.1109/JIOT.2019.2963499","National Natural Science Foundation of China(grant numbers:61672131,61773284,61773087,61972448); Innovation Foundation of Tianjin University and Tianjin Key Laboratory of Advanced Networking; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8948047","Deep neural network;Internet of Things (IoT);networking evolution;reinforcement learning;robustness optimization","Network topology;Internet of Things;Topology;Robustness;Reinforcement learning;Computational modeling;Optimization","","15","","31","IEEE","1 Jan 2020","","","IEEE","IEEE Journals"
"Design of Wearable Reconfigurable Antenna for IoT Applications","N. Haritha; E. Gowsika; P. Elangovan; K. Jayamani","Electronics And Communication Engineering, Rajalakshmi Institute Of Technology, Chennai, India; Electronics And Communication Engineering, Rajalakshmi Institute Of Technology, Chennai, India; Electronics And Communication Engineering, Rajalakshmi Institute Of Technology, Chennai, India; Electronics And Communication Engineering, Rajalakshmi Institute Of Technology, Chennai, India","2021 International Conference on Advancements in Electrical, Electronics, Communication, Computing and Automation (ICAECA)","18 Jan 2022","2021","","","1","5","Internet of things (IOT) basically provides a platform for devices to interact and collaborate with each other. Wearable antennas are a recent invention in antenna technology. These wearable antennas are playing an important role in applications such as the Internet of Things, energy harvesting systems, health care, and military applications. Antenna with a Wearable Reconfigurable Design is anticipated in this paper. This antenna is capable to reconFigure the frequency from one to another depending upon the requirement. The proposed design is a relatively tiny size of 40mm x 55mm, which is suitable for small-scale applications. Three switches are used to achieve four different operating frequencies. Roger 6002 is used as the substrate with dielectric value of 2.94. The resonation frequency is found between 2.5 GHz to 14.9 GHz.","","978-1-6654-2829-3","10.1109/ICAECA52838.2021.9675735","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9675735","Wearable antenna;IoT;Switches;Frequency Reconfiguration","Time-frequency analysis;Technological innovation;Wearable computers;Resonant frequency;Medical services;Dielectric resonator antennas;Telecommunication computing","","2","","9","IEEE","18 Jan 2022","","","IEEE","IEEE Conferences"
"Optimizing Efficient Personalized Federated Learning with Hypernetworks at Edge","R. Zhang; Y. Chen; C. Wu; F. Wang; J. Liu","Chinese University of Hong Kong, China; Chinese University of Hong Kong, China; Chinese University of Hong Kong, China; Chinese University of Hong Kong, China; Simon Fraser University, Canda","IEEE Network","24 Oct 2023","2023","37","4","120","126","The recent advances in 5G and mobile edge computing facilitate the rapid development of the Internet of Things (IoT), enabling collective intelligence with data support from a massive number of IoT devices. Meanwhile, federated learning (FL) has emerged as a promising solution for collaborative training while preserving user privacy, which, however, is prone to poor learning performance in large-scale IoT scenarios. On the one hand, due to the task heterogeneity in various IoT scenarios and data heterogeneity (non-IID) across different IoT clients, more than traditional FL models derived from a Uniform FL (UFL) learning architecture are required to satisfy the diversified demands of each client. On the other hand, with the proliferation of IoT devices, achieving low latency and low communication costs with traditional FL architectures becomes even more challenging. In this article, we argue that customizing a specific model for each client is an urgent requirement, calling for the development of UFL to Personalized FL (PFL). In addition, the confluence of PFL and edge computing further provides opportunities for practical implementation in the 5G IoT environment. Accordingly, we propose EdgeFHN, an edge computing-based personalized federated learning framework, which can strike a balance between collaborative FL training among different clients and efficient model personalization for each client. Experiments on image classification demonstrate the superiority of our framework in improving accuracy and reducing communication overhead compared with other state-of-the-art solutions.","1558-156X","","10.1109/MNET.008.2200654","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10293196","","Training;Federated learning;5G mobile communication;Smart cities;Image edge detection;Computational modeling;Collaboration;Machine learning","","","","15","IEEE","24 Oct 2023","","","IEEE","IEEE Magazines"
"Multi-Level IoT Device Identification","R. Jiao; Z. Liu; L. Liu; C. Ge; G. Hancke","Nanjing University of Aeronautics and Astronautics, Jiangsu, China; Nanjing University of Aeronautics and Astronautics, Jiangsu, China; Nanjing University of Aeronautics and Astronautics, Jiangsu, China; Nanjing University of Aeronautics and Astronautics, Jiangsu, China; City University of Hong Kong, Hong Kong, China","2021 IEEE 27th International Conference on Parallel and Distributed Systems (ICPADS)","3 May 2022","2021","","","538","547","The rapid development of the Internet of Things (IoT) has brought challenges to IoT platforms for high-efficiency deployments and low-budget management. Identifying IoT devices is the prerequisite for monitoring, protecting, and managing them. Considering different providers and IoT device renovation, centralized device identification solutions require large amounts of training data and frequent model updates. Traditional solutions based on machine learning cannot preserve identification precision for the long term at a low cost in reality. In this paper, we propose a multi-level IoT device identification framework, alleviating the problem of novel class detection and large-scale updating of IoT models in IoT device identification. The proposed framework improves the usability of device identification technology in the real world. We also designed an IoT device identification method, achieving an average identification accuracy of 93.37 %. With this proposed multi-level IoT device identification framework, IoT device identification can achieve a high precision over a long time.","2690-5965","978-1-6654-0878-3","10.1109/ICPADS53394.2021.00073","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9763819","Devices Identification;IoT Security;Device Fingerprinting","Performance evaluation;Training data;Software;Object recognition;Internet of Things;Task analysis;Usability","","2","","27","IEEE","3 May 2022","","","IEEE","IEEE Conferences"
"“IoT Based Battery Monitoring System”","M. S. Kale; B. N. Chaudhari","Electrical Engineering Department, P.E.S College of Engineering, Aurangabad, (MS), India; Electrical Engineering Department, P.E.S College of Engineering, Aurangabad, (MS), India","2022 International Conference on Advances in Computing, Communication and Materials (ICACCM)","12 Jan 2023","2022","","","1","5","Batteries are a need in modern life due to their versatility. Today's world's extensive use of gadgets necessitates the use of batteries. We believe that the most promising chemical storage technology for large-scale energy storage currently exists in the form of lead-acid batteries. When surge current is not necessary, lead-acid batteries are frequently utilized, and because they are less expensive than newer technologies, different designs may provide higher energy densities. Large-format lead-acid designs are utilized in stand-alone power systems, high-availability environments like hospitals, and backup power supplies in mobile phone towers etc. Because of their numerous uses and capacity to power a variety of devices, these batteries are crucial. To extend storage times and cut down on maintenance expenses, modified versions of the traditional cell may be used in a variety of applications. The VRLA (valve-regulated lead-acid) battery family, which includes gel-cell and absorbed glass-mat batteries, is frequently employed for these activities. Battery Management Systems (BMS) are used in numerous commercial and industrial systems to optimize battery performance and predict how long a battery will last in a non-destructive state. For this aim, a variety of monitoring systems are used to keep an eye on the battery's charge, temperature, and current. The Building Management System (BMS) of a data center is a crucial element. It offers centralized control of crucial infrastructure components and guarantees efficient and safe operation of operations. By utilizing current network infrastructures to transform physical resources into intelligent entities, the Internet of Things (IoT) acts as a technical tool for professionals. Its fundamental objective is to provide users with smooth, intelligent services without any downtime. This paper is aimed to developed a prototype for the modular battery management system and monitored it using the IoT-based protocol.","2642-7354","978-1-6654-7439-9","10.1109/ICACCM56405.2022.10009576","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10009576","Internet of Things (IoT);battery Management System (BMS);State of Charge (SOC);State of Health (SOH)","Lead acid batteries;Temperature sensors;Temperature measurement;Wireless LAN;Temperature;Prototypes;Battery management systems","","2","","22","IEEE","12 Jan 2023","","","IEEE","IEEE Conferences"
"An Efficient Blockchain-based Firmware Update Framework for IoT Environment","M. -H. Tsai; Y. -C. Hsu; N. -W. Lo","Department of Information Management, National Taiwan University of Science and Technology, Taipei, Taiwan; Department of Information Management, National Taiwan University of Science and Technology, Taipei, Taiwan; Department of Information Management, National Taiwan University of Science and Technology, Taipei, Taiwan","2020 15th Asia Joint Conference on Information Security (AsiaJCIS)","10 Sep 2020","2020","","","121","127","Recently, massive deployment of Internet of Things (IoT) devices has accelerated digital transformation of modern society in various aspects. Naturally, how to ensure security of deployed IoT devices has become an important and practical issue. Several successful large-scale DDoS attacks were utilized vulnerabilities of firmware on IoT devices in the past couple of years. Therefore, effective and efficient firmware update solution on IoT devices is in demand. In this study, an automatic real-time firmware update framework based on blockchain technology and MQTT protocol is proposed. To support automatic real-time firmware update operation on deployed IoT devices, multiple MQTT servers are installed in corresponding blockchain nodes to execute firmware patch delivery operation by the design of our framework. Blockchain technology is used to record the original manufacturer of a published firmware patch for a dedicated IoT device and smart contract is adopted to discover MQTT service nodes in a blockchain network. Data integrity of a newly generated firmware patch is preserved by distributing the patch with its hashed value. A framework prototype is constructed and experiments are conducted. Based on the experimental results, the proposed framework can efficiently and securely deliver firmware patches to targeted gateways in real-time scale.","","978-1-7281-9922-1","10.1109/AsiaJCIS50894.2020.00030","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9194134","firmware update;blockchain technology;smart contract;MQTT","Microprogramming;Logic gates;Contracts;Servers;Real-time systems;Portals","","2","","9","IEEE","10 Sep 2020","","","IEEE","IEEE Conferences"
"The AI-driven Permissioned Blockchain System for the Services of Future Internet of Things","D. Zhang; W. Shi","School of Information Technology, Carleton University, Ottawa, ON, Canada; School of Information Technology, Carleton University, Ottawa, ON, Canada","2023 IEEE 11th International Conference on Information, Communication and Networks (ICICN)","24 Jan 2024","2023","","","370","377","Recently, the Internet of Things (IoT) and blockchain technology have attracted more and more attention. However, given the characteristics of the current blockchain itself, many important issues prevent it from becoming a general platform for IoT to deploy large-scale services. The main problem is how to ensure the scalability of the blockchain system in the dynamically changing IoT scene. Despite numerous studies conducted to address this issue, they failed to account for the dynamic changes in IoT nodes, specifically the addition and deletion of nodes. Instead, they simply opted for a consensus protocol as the presumed optimal solution. In this paper, we employ a permissioned blockchain framework designed for current IoT services. In response to the Quality of Service (QoS) requirements of different IoT nodes, we propose different consensus protocols for different service qualities in the existing IoT architecture, aiming to enhance the adaptability of the blockchain to the different needs of users in the IoT system. First, we quantified several permissioned consensus protocols. Furthermore, IoT services require the selection of block producers possessing significant computing resources, along with the dynamic allocation of network bandwidth specifically for the blockchain. We present an approach where we formulate the joint optimization problem of the selection of consensus mechanism and block producer, and the allocation of available bandwidth. We employ the Dueling Deep Q-network (DDQN) method as a solution for this problem.","","979-8-3503-1401-4","10.1109/ICICN59530.2023.10392307","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10392307","Internet of Things;Quality of Service;blockchain;dueling deep Q-network","Scalability;Quality of service;Bandwidth;Computer architecture;Dynamic scheduling;Consensus protocol;Internet of Things","","","","18","IEEE","24 Jan 2024","","","IEEE","IEEE Conferences"
"Distributed-to-Centralized Data Management through Blockchain Technologies in Large-Scale IoT Networks of Multicampus University","A. Sinaeepourfard; A. Dorri","Department of Computer Science, Norwegian University of Science and Technology (NTNU), Trondheim, Norway; School of Computer Science, Queensland University of Technology (QUT), Brisbane, Australia","2020 IEEE 22nd International Conference on High Performance Computing and Communications; IEEE 18th International Conference on Smart City; IEEE 6th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)","26 Apr 2021","2020","","","1188","1194","Traditionally, blockchain technologies focus on data security and privacy issues in different business domains of smart cities. However, we believe that blockchain technologies can be beneficial for data and resource management in large-scale internet of things (IoT) networks of smart cities. Blockchain technologies and their related consensus algorithms and miners may apply through multilevel information communication technology (ICT) architecture in large-scale IoT networks of smart cities to organize the city-data and ICT resources. This position paper addresses an initial idea about the contribution of different smart cities and ICT concepts, including “blockchain technologies,” “distributed-to-centralized ICT architecture (D2C-ICT),” “distributed-to-centralized data management (D2CDM),” and “smart university.” We first present our D2C-ICT architecture in the smart university context using different distributed and centralized technologies, including cloudlet and cloud technologies. Finally, we show that the facilities of blockchain technologies for data and resource management through D2C-ICT architecture in large-scale IoT networks of smart cities.","","978-1-7281-7649-9","10.1109/HPCC-SmartCity-DSS50907.2020.00154","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9408072","Smart City;Smart University;large-scale IoT networks;blockchain technologies;distributed-to-centralized ICT architecture (D2C-ICT);distributed-to-centralized data management (D2C-DM)","Cloud computing;Smart cities;High performance computing;Data security;Distributed databases;Blockchain;Computer architecture","","","","60","IEEE","26 Apr 2021","","","IEEE","IEEE Conferences"
"Enabling Blind Area Coverage for the Smart Grids: Integrating Energy-efficient LoRa Technologies in the 5G","J. Zhang; Y. Li; J. Ma; H. Xue; J. Wu; M. Zhao; C. Han; X. Dang; S. Bi","Information Communication Branch Company, Shanxi Electric Power Company, Taiyuan, China; Information Communication Branch Company, Shanxi Electric Power Company, Taiyuan, China; Information Communication Branch Company, Shanxi Electric Power Company, Taiyuan, China; Information Communication Branch Company, Shanxi Electric Power Company, Taiyuan, China; Information Communication Branch Company, Shanxi Electric Power Company, Taiyuan, China; Information Communication Branch Company, Shanxi Electric Power Company, Taiyuan, China; Information Communication Branch Company, Shanxi Electric Power Company, Taiyuan, China; Information Communication Branch Company, Shanxi Electric Power Company, Taiyuan, China; Information Communication Branch Company, Shanxi Electric Power Company, Taiyuan, China","2021 6th International Conference on Intelligent Computing and Signal Processing (ICSP)","26 Apr 2021","2021","","","952","956","The convergence of the Internet of Things (IoT) and 5G will open a range of innovations for the deployment of enhanced sensing and novel applications, controlling and interactive systems. The current smart grid (SG) will be more reliable, secure, flexible and durable by implementing 5GIoT monitoring. However, 5GIoT, is inefficiently and costly to travel over large areas and penetrate physical structures. As a complement, the proposed 5G1oRa converged network can offer a low-cost and large scale of coverage without blind areas. There are notable concerns regarding certain energy conservation issues to be overcome in order to achieve a successful integration of multi-hop LoRa systems within 5G architectures. Based on the Charnes-Cooper transform and Lagrange Multiplier iteration algorithm, a non-convex relaxation optimization is proposed to allocate transmit power for multi-hop LoRa to further maximize the system energy efficiency. The solution has been deployed, implemented and validated in a real and integrated 5GLoRa testbed, showing its feasibility to meet the requirements of SG data collection, transmission, cloud storage, and calculation in a wide area. Simulation results also validate the efficiency of our proposed model, which significantly outperforms other benchmark algorithms in terms of energy efficiency and QoS requirements.","","978-1-6654-0413-6","10.1109/ICSP51882.2021.9408706","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9408706","smart grid;IoT monitoring;5G;LoRa;energy efficiency","5G mobile communication;Simulation;Signal processing algorithms;Transforms;Energy efficiency;Smart grids;Resource management","","1","","10","IEEE","26 Apr 2021","","","IEEE","IEEE Conferences"
"A High-speed Wi-SUN FAN Network by Highly-Dense Frequency Hopping","H. Ochiai; K. Mizutani; R. Okumura; K. Mizutani; H. Harada","Graduate School of Informatics, Kyoto University, Kyoto, Japan; Graduate School of Informatics, Kyoto University, Kyoto, Japan; Graduate School of Informatics, Kyoto University, Kyoto, Japan; Graduate School of Informatics, Kyoto University, Kyoto, Japan; Graduate School of Informatics, Kyoto University, Kyoto, Japan","2020 IEEE 92nd Vehicular Technology Conference (VTC2020-Fall)","15 Feb 2021","2020","","","1","5","The wireless smart ubiquitous network (Wi-SUN) field area network (FAN) attracts attention as a wireless communication standard for large-scale Internet of Things (IoT) systems. Currently, frequency shift keying (FSK) defined in IEEE 802.15.4 is adopted in the physical layer of the Wi-SUN FAN. To improve the network performance toward next-generation IoT systems, a data rate enhancement scheme for FSK has been proposed. However, there is no evaluation of data rate improvement effect by adopting the data rate enhanced FSK on the transmission characteristics of the Wi-SUN FAN. Besides, introducing the data rate enhanced FSK causes the bandwidth to increase. For multiple systems to coexist in limited frequency bands, it is necessary to achieve high spectral efficiency even when the Wi-SUN FAN adopts the data rate enhanced FSK. In this paper, we evaluate the transmission characteristics of the Wi-SUN FAN adopting the high-speed FSK of 600 kbps by computer simulations. The simulation results show that the system throughput improves by 2.5 times, but the bandwidth also increases by 2.5 times compared to the existing system. Furthermore, we propose highly-dense frequency hopping based on a novel channel arrangement scheme to improve spectral efficiency and compatibility with the existing system design while the data rate enhanced FSK is adopted. The evaluation results show that the system throughput in the proposed scheme is 2.4 times of the existing system while using less than half of the bandwidth compared to the conventional channel arrangement scheme.","2577-2465","978-1-7281-9484-4","10.1109/VTC2020-Fall49728.2020.9348472","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9348472","Wi-SUN FAN;FSK;Frequency Hopping;ARIB STD-T108;Throughput enhancement;Spectral efficiency","Wireless communication;Fans;Spectral efficiency;Frequency shift keying;Bandwidth;Throughput;System analysis and design","","4","","10","IEEE","15 Feb 2021","","","IEEE","IEEE Conferences"
"Task Scheduling and Load Balancing for Minimization of Response Time in IoT Assisted Cloud Environments","A. K. Singh; A. Kumar","Research Scholar Banasthali Vidyapeeth, Tonk, Rajasthan, India; Banasthali Vidyapeeth, Tonk, Rajasthan, India","2022 5th International Conference on Contemporary Computing and Informatics (IC3I)","22 Mar 2023","2022","","","144","148","The Internet of Things (IoT) necessitates a new processing paradigm that incorporates cloud scalability while reducing network latency by utilising resources closer to the network edge. On the one hand, it’s difficult to achieve such flexibility within the edge-to-cloud continuum, which consists of a distributed networked ecosystem of heterogeneous computing resources. IoT traffic dynamics, on the other hand, and the growing need for low-latency services necessitate decreasing reaction time and balancing service location. For cost-effective system administration and operations, fog computing load-balancing will become a cornerstone. Though virtualization attempts to instantaneously balance the load of the overall network, there’s still the possibility of capacity excessive usage or under development. Heavily loaded systems degrade efficiency, while undercharged systems use bandwidth inefficiently. Because of inadequate load distribution, overburdened systems emit additional energy, driving up the cost of coolers as well as adding significantly to the warming of the planet. Throughout most situations, cooling towers consume higher electricity than core IT technology. Despite the benefits of cloud computing as a distributed pool of resources and services, certain new IoT applications are not cloud-ready. Wind farms and smart traffic light systems, for example, have unique characteristics and requirements “(e.g., large-scale, geo-distribution) (e.g., very low and predictable latency)”. This research paper has considered secondary method of data collection to gather relevant and statistical data related to research topic.","","979-8-3503-9826-7","10.1109/IC3I56241.2022.10072488","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10072488","Load balancing;cloud computing;“Internet of Things or IoT”;Technology;Virtual Machines","Cloud computing;Costs;Processor scheduling;Scalability;Wind farms;Load management;Internet of Things","","","","20","IEEE","22 Mar 2023","","","IEEE","IEEE Conferences"
"Optimization of Sports Fitness Management System Based on Internet of Health Things","Y. Tang; D. Wang","School of Physical Education, Xinyang Normal University, Xinyang, China; School of Physical Education, Xinyang Normal University, Xinyang, China","IEEE Access","1 Dec 2020","2020","8","","209556","209569","Due to the huge scale of the Internet of Health Things (IoHT), various research methods currently applied in the field of Internet of Health Things are limited to the technical problems themselves, which lack a macro grasp of the entire Internet of Things (IoT) system. The verification of the proposed technical scheme requires the purchase of a large number of hardware devices, but as a result, only relatively limited research models can be constructed, which makes the entire system long management cycle and high management cost. Based on the research of particle swarm optimization algorithm, this paper finds its shortcomings and makes corresponding improvements. A new improved method of particle swarm optimization algorithm is proposed. By introducing the method of average particle distance and population distribution entropy in the algorithm search process, the inertia weight is dynamically changed. This is conducive to the improvement of the optimization efficiency of the particle swarm optimization algorithm, and has a good optimization accuracy. A IoHTs modeling method for component collaboration is proposed, and the IoHTs component library is designed according to the proposed modeling method. At the same time, this article discusses the XModel modeling simulation platform, and builds a IoHTs component model based on this platform, and has completed the verification of the validity of the proposed modeling method and the feasibility of the IoHTs IPv6 communication scheme. The component library designed in the XModel platform is based on the functions of IoT devices, and the components have more complete network communication features. The XModel platform specifically customizes the CMIoT component library, and supports the continuous expansion of the component library and the continuous refinement of component functions, providing a new method for communication research in the Internet of Health Things field.","2169-3536","","10.1109/ACCESS.2020.3039508","2020 National Social Science Fund (Research on the Construction and Practice of Physical Education Curriculum System from the Perspective of Teacher Professional Certification)(grant numbers:20BTY064); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9265214","Internet of Health Things;sports fitness management system;XModel platform;particle swarm optimization algorithm","Internet of Things;Resource management;Data models;Sports;Solid modeling;Optimization","","6","","37","CCBY","20 Nov 2020","","","IEEE","IEEE Journals"
"Large-scale heterogeneous terminal multi-domain joint fault diagnosis direction","Z. Suo; H. Hong; J. Wang; H. Wu; J. Song; S. Zou; X. Liang; X. Wu","Guangzhou Power Supply Bureau, China Southern Power Grid, Guangdong, China; Guangzhou Power Supply Bureau, China Southern Power Grid, Guangdong, China; Guangzhou Power Supply Bureau, China Southern Power Grid, Guangdong, China; Guangzhou Power Supply Bureau, China Southern Power Grid, Guangdong, China; Guangzhou Power Supply Bureau, China Southern Power Grid, Guangdong, China; Guangzhou Power Supply Bureau, China Southern Power Grid, Guangdong, China; Guangzhou Power Supply Bureau, China Southern Power Grid, Guangdong, China; Guangzhou Power Supply Bureau, China Southern Power Grid, Guangdong, China","2022 2nd International Conference on Consumer Electronics and Computer Engineering (ICCECE)","21 Feb 2022","2022","","","707","710","The safe and stable operation of the Internet of Things (IOT) system is strongly related to the economy and daily life. IOT equipment damage accidents have caused major economic losses, which impacted on people's lives, and endanger industrial and social safety. However, accidents caused by various accidental factors cannot be completely avoided, effective monitoring and fault diagnosis of the IOT system, in particular in power system are very important. From the perspective of large-scale heterogeneous terminals and heterogeneous terminals across domains, this paper conducts fault diagnosis on the operation of the IOT based on big data and artificial intelligence methods. Firstly, based on the data-driven method, the information collected by different sensors is processed through the deep neural network for dimensionality reduction and feature extraction. Secondly, the extracted multi-source information features are feature fused. Finally, the Softmax function is used to diagnose the faults of the fused features.","","978-1-6654-0886-8","10.1109/ICCECE54139.2022.9712777","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9712777","Fault diagnosis direction;IOT system;Fault diagnosis;Machine learning;Deep learning","Fault diagnosis;Vibrations;Deep learning;Neural networks;Time series analysis;Feature extraction;Power systems","","","","11","IEEE","21 Feb 2022","","","IEEE","IEEE Conferences"
"The Internet of Things(IoT) system for Bolt looseness detection in coal mines","B. Liu; X. Yang; Z. Chen; J. Liao; H. Zhao","Intelligent Mine Research Institute, China Coal Research Institute Co., Ltd, Beijing, China; Intelligent Mine Research Institute, China Coal Research Institute Co., Ltd, Beijing, China; Intelligent Mine Research Institute, China Coal Research Institute Co., Ltd, Beijing, China; Intelligent Mine Research Institute, China Coal Research Institute Co., Ltd, Beijing, China; Intelligent Mine Research Institute, China Coal Research Institute Co., Ltd, Beijing, China","2022 3rd International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE)","23 Dec 2022","2022","","","293","296","Intelligent industry was also called Industrial In-ternet of Things, which combines Internet of technology and traditional manufacturing modes, has played a positive role in Industrial production. Bolt connection plays an important role in coal mine machineries. A set of bolt looseness detection Internet of Things based on wireless Zigbee technology was designed in this article, and the three-dimensional finite element model of Hall sensor in COMSOL Multiphysics field is also established. We also design an installation method of the wireless Bolt Looseness sensor. ZigBee technology was adopted between end devices attached to bolts and the coordinator attached to bracket controller to establish a comprehensive monitoring platform conducive to timely decision-making and analysis. Hall sensors are deployed in the monitoring area in a certain number and scale, and the data monitored by sensor nodes are sent to the coordinator through wireless transmission. This sensor IoT system can detect bolt looseness in real time, which solves the problem that the large number of bolts to be monitored and difficulty in determining the position of looseness bolts.","","978-1-6654-5160-4","10.1109/ICBAIE56435.2022.9985855","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9985855","Internet of Things;Bolt looseness detection in coal mines;Zigbee;Finite element method","Wireless communication;Wireless sensor networks;Solid modeling;Zigbee;Fasteners;Real-time systems;Coal mining","","","","8","IEEE","23 Dec 2022","","","IEEE","IEEE Conferences"
"Energy and Throughput Management in Delay-Constrained Small-World UAV-IoT Network","S. R. Yeduri; N. S. Chilamkurthy; O. J. Pandey; L. R. Cenkeramaddi","ACPS Research Group, Department of Information and Communication Technology, University of Agder, Kristiansand, Norway; Department of Electronics and Communication Engineering, SRM University AP Andhra Pradesh, Amaravati, India; Department of Electronics Engineering, Indian Institute of Technology (BHU) Varanasi, Varanasi, India; ACPS Research Group, Department of Information and Communication Technology, University of Agder, Kristiansand, Norway","IEEE Internet of Things Journal","21 Apr 2023","2023","10","9","7922","7935","Multihop data routing over a large-scale Internet of Things (IoT) network results in energy imbalance and poor data throughput performance. In addition, data transmission using a large number of hops causes more delay. In light of this, in this work, a novel method of energy and throughput management in a delay-constrained small-world unmanned aerial vehicle (UAV)-IoT network is proposed. The proposed small-world framework optimizes the number of hops required for the data transmission leading to improved energy efficiency and quality of service. The method introduces optimal long-range links between device pairs resulting in low average path length and high clustering coefficient which are called as small-world characteristics. Therefore, in this work, UAVs are deployed to collect the data from IoT devices and forward it to the ground station (GS) utilizing the small world framework. It is shown through results that the network delays corresponding to the proposed method, conventional routing method, low-energy adaptive clustering hierarchy (LEACH) protocol, modified LEACH protocol, and canonical particle multiswarm (CPMS) method are 789.39, 1602.53, 1000.92, 873.63, and 999.79 s, respectively. It is also observed that the number of dead UAVs in case of the proposed method is reduced when compared to other existing methods. It is also noticed that the proposed method results in 100% packet delivery ratio (PDR) dominating LEACH and modified LEACH protocols. Thus, it is shown that the proposed method outperforms the other shortest path methods in terms of network latency, lifetime, and PDR. Further, the effect of location of GS, velocities of UAVs, and hovering heights of UAVs is considered for the performance evaluation of the proposed method. The obtained results validate the significance of utilization of the proposed method over various network scenarios.","2327-4662","","10.1109/JIOT.2022.3231644","Indo-Norwegian Collaboration in Autonomous Cyber-Physical Systems (INCAPS) Project of the INTPART Program(grant numbers:287918); Low-Altitude UAV Communication and Tracking (LUCAT) Project of the IKTPLUSS Program(grant numbers:280835); Norges Forskningsråd; Science and Engineering Research Board (SERB), Government of India, through the Project “Design and Development of Cognitive Small-World LPWANs for Internet of Things Towards Health Monitoring”(grant numbers:SRG/2021/000137); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9998008","Energy efficiency;multihop data routing;network latency;small-world unmanned aerial vehicle (UAV)-Internet of Things (IoT) network;throughput","Internet of Things;Delays;Throughput;Protocols;Data communication;Wireless networks;Routing","","5","","60","IEEE","23 Dec 2022","","","IEEE","IEEE Journals"
"Industrial Frameworks for Internet of Things: A Survey","C. Paniagua; J. Delsing","Department of Computer Science, Space and Electrical Engineering, Luleå University of Technology, Luleå, Sweden; Department of Computer Science, Space and Electrical Engineering, Luleå University of Technology, Luleå, Sweden","IEEE Systems Journal","9 Mar 2021","2021","15","1","1149","1159","The Internet of Things (IoT) has gained popularity and is increasingly used in large scale deployments for industrial applications. Such deployments rely on the flexibility and scalability of systems and devices. Heterogeneous systems need to be interoperable and work together seamlessly. In order to manage such system of systems, it is important to work with a framework that not only supports the flexible nature of IoT systems but also provides adequate support for industrial requirements, such as real-time and runtime features, architectural approaches, hardware constraints, standardization, industrial support, interoperability, and security. The selection of an appropriate framework results difficult due to the rising number of available frameworks and platforms, which offer different support for the aforementioned requirements. Therefore, this article investigates the features of seven prominent frameworks for the purpose of simplifying the selection of a suitable framework for an industrial application. The aim of this article is to present the recent developments and state-of-the-art of industrial IoT frameworks and provide a technical comparison of their features and characteristics.","1937-9234","","10.1109/JSYST.2020.2993323","European Commission(grant numbers:737459); Arrowhead Tools project Joint Undertaking(grant numbers:826452); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9099983","Frameworks;Industrial Internet of Things (IIoT);system of systems (SoS)","Industries;Automation;Internet of Things;Security;Interoperability;Production;Protocols","","69","","82","CCBY","26 May 2020","","","IEEE","IEEE Journals"
"Simulation Framework for 6LoWPAN Networks Using Mininet-WiFi","S. Buzura; V. Dadarlat; A. Peculea; H. Bertrand; R. Chevalier","Computer Science Department, Technical University of Cluj-Napoca, Cluj-Napoca, Romania; Computer Science Department, Technical University of Cluj-Napoca, Cluj-Napoca, Romania; Computer Science Department, Technical University of Cluj-Napoca, Cluj-Napoca, Romania; Computer Science Section CESI Engineering School, Rouen, France; Computer Science Section CESI Engineering School, Rouen, France","2022 IEEE International Conference on Automation, Quality and Testing, Robotics (AQTR)","23 Jun 2022","2022","","","1","5","The Internet of Things (IoT) continuously grows as applications require connectivity and sensor networks are being deployed in multiple application domains. With the increased applicability demand, the need for testing and development frameworks also increases. This paper presents a novel simulation framework for testing IPv6 over Low Power Wireless Personal Networks (6LoWPAN) networks using the Mininet-WiFi simulator. The goal of the simulation framework is to allow easier automation testing of large-scale networks and to also allow easy configuration. This framework is a starting point for many development scenarios targeting traffic management, Quality of Service (QoS) or security network features. A basic smart city simulation is presented which demonstrates the working principles of the framework.","","978-1-6654-7933-2","10.1109/AQTR55203.2022.9802017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9802017","6LoWPAN;Mininet-WiFi;network simulation and programmability;framework","Wireless communication;Wireless sensor networks;Automation;Smart cities;Quality of service;Writing;Robot sensing systems","","3","","11","IEEE","23 Jun 2022","","","IEEE","IEEE Conferences"
"Integration of Building Information Modeling and Artificial Intelligence Systems to Create a Digital Twin of the Construction Site","D. Chernyshev; S. Dolhopolov; T. Honcharenko; H. Haman; T. Ivanova; M. Zinchenko","First Vice-Rector, Kyiv National University of Construction and Architecture, Kyiv, Ukraine; Dept. of Information Technologies, Kyiv National University of Construction and Architecture, Kyiv, Ukraine; Dept. of Information Technologies, Kyiv National University of Construction and Architecture, Kyiv, Ukraine; Dept. of Economic Theory, Kyiv National University of Construction and Architecture, Kyiv, Ukraine; Dept. of Economic Theory, Kyiv National University of Construction and Architecture, Kyiv, Ukraine; Dept. of Economic Theory, Kyiv National University of Construction and Architecture, Kyiv, Ukraine","2022 IEEE 17th International Conference on Computer Sciences and Information Technologies (CSIT)","2 Jan 2023","2022","","","36","39","This study is devoted to the development of an information system for creating digital twins of construction sites by integrating Building Information Modeling (BIM) technologies and artificial intelligence systems. An artificial intelligence system has been developed that combines the Convolutional Neural Network (CNN) named “You Only Look Once” v3 (YOLOv3) and Feed-Forward Neural Network (FFNN) architectures as a comprehensive mechanism for detecting, classifying, and evaluating individual components, objects, systems and processes of the construction project at all stages of its life cycle. The article describes the inclusion of the Internet of Things (IoT) and Big Data Technologies for recognizing the physical representation of the large-scale array of construction objects used on a construction site in real-time. The effectiveness of identifying the correspondence of a set of BIM-model attributes that provide the circumstances for creating a digital twin of the construction site is determined. The reliability of object recognition by the YOLOv3 model is proved, which is confirmed by the map indicator – 90.04%, which additionally correlates the FFNN model with attributes of the reference BIM model. The results of this study can be used to further improve the concept of developing digital twins using other relevant and key components of the construction project and the latest information technologies.","2766-3639","979-8-3503-3431-9","10.1109/CSIT56902.2022.10000717","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10000717","artificial intelligence;YOLOv3;digital twin;BIM;internet of things;big data;construction;FFNN model","Buildings;Big Data;Real-time systems;Digital twins;Convolutional neural networks;Internet of Things;Arrays","","1","","14","IEEE","2 Jan 2023","","","IEEE","IEEE Conferences"
"Resource allocation algorithm for IoT communication based on ambient backscatter","Z. Chen; B. Ji","School of Information Engineering, Henan University of Science and Technology, China; School of Information Engineering, Henan University of Science and Technology, China","2021 IEEE 93rd Vehicular Technology Conference (VTC2021-Spring)","15 Jun 2021","2021","","","1","5","As an important part of the future network, Internet of Things (IoT) is becoming more and more heterogeneous, requiring high efficiency and new spectrum wireless communication technology. Symbiosis Radio (SR) has been developed, which uses cognitive radio and ambient backscattering communication technology to achieve spectrum sharing and highly reliable communication. This paper proposed an architecture model of multi-hop IoT communication system and designed a fusion algorithm based on wireless information and energy harvesting. Among them, the source and the receiving information node were equipped with multiple antennas, while the relay node and the energy harvesting node were single antennas. For the future large-scale transmission model, the relay node adopted the power splitting method to realize information transmission and energy harvesting. The high Signal to noise ratio (SNR) approximation method was used to realize the non-convex to convex conversion. Lagrange algorithm and Lambert W function are utilized to derive and obtain the transmission power of the optimal solution, so that the energy efficiency of the system can reach the optimal. The simulation results show that the scheme achieve obvious energy saving effect.","2577-2465","978-1-7281-8964-2","10.1109/VTC2021-Spring51267.2021.9448677","National Natural Science Foundation of China; Research and Development; China Postdoctoral Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9448677","Symbiotic radio;Ambient backscattering technology;Resource allocation;Convex optimization","Symbiosis;Simulation;Transmitting antennas;Receiving antennas;Energy harvesting;Resource management;Relays","","2","","14","IEEE","15 Jun 2021","","","IEEE","IEEE Conferences"
"A Computationally Intelligent Hierarchical Authentication and Key Establishment Framework for the Internet of Things","M. S. Haghighi; O. Nader; A. Jolfaei","IT Department, University of Tehran, Tehran, Iran; Engineering Degree in Networks and Information Systems, Al-baath University, Homs, Syria; Griffith University, Griffith, NSW, Australia","IEEE Internet of Things Magazine","11 Jan 2021","2020","3","4","36","39","Our high expectations for the Internet of Things (IoT) and how it will positively influence our lifestyles depend on a secure and trusted implementation of it, especially in sensitive sectors such as health and finance. IoT platforms and solutions must provide confidentiality, integrity, and availability (CIA) in a secure and transparent way. Due to the extremely large scales of IoT, traditional centralized solutions for security provisioning cannot be employed in their original form. This article discusses the authentication problem in IoT, which is fundamental to providing CIA. We propose a hierarchical security architecture for this problem and focus on computationally lightweight authentication protocols that can intelligently distribute the computational load across multiple levels and effectively push the load toward upper layers.","2576-3199","","10.1109/IOTM.0001.2000014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9319637","","Protocols;Authentication;Finance;Interconnected systems;Security;Internet of Things;Mediation","","4","","13","IEEE","11 Jan 2021","","","IEEE","IEEE Magazines"
"Whispering to Industrial IoT for converging multi-domain Network Programmability","E. Municio; S. Latré; J. M. Marquez-Barja","IDLab, University of Antwerp - IMEC, Faculty of Applied Engineering, Antwerp, Belgium; Department of Mathematics and Computer Science, IDLab, University of Antwerp - IMEC, Antwerp, Belgium; IDLab, University of Antwerp - IMEC, Faculty of Applied Engineering, Antwerp, Belgium","IEEE INFOCOM 2020 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)","10 Aug 2020","2020","","","1336","1337","Industrial Internet of Things (IoT) calls for not only highly reliable, quasi-deterministic and low-power networks, but also for more flexible and programmable networks to cope with operator's dynamics demands. Software Defined Networking (SDN) offers the high levels of flexibility and programmability that traditional distributed protocols cannot offer. In between a fully centralized SDN-on-IoT management solution and a traditional fully distributed one, Whisper stands out as a tradeoff solution that has the robustness, scalability and low-overhead of distributed solutions and the flexibility and programmability of centralized ones. In this demo we present a hands-on experience of how Whisper can be jointly used with traditional SDN solutions, such as ONOS, in order to extend the already existing network programmability in wired domains to 6TiSCH-based Industrial IoT segments. We deploy and test such architecture in real-world large-scale testbeds and demonstrate to be feasible and beneficial to provide an efficient and programmable end-to-end control over a heterogeneous network.","","978-1-7281-8695-5","10.1109/INFOCOMWKSHPS50562.2020.9162852","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9162852","IIoT;SDN;6TiSCH;RPL;ONOS;Whisper","Wireless sensor networks;Wireless communication;Internet of Things;Network topology;Topology;Robustness","","2","","5","IEEE","10 Aug 2020","","","IEEE","IEEE Conferences"
"Understanding Security in Smart City Domains From the ANT-Centric Perspective","J. Fan; W. Yang; Z. Liu; J. Kang; D. Niyato; K. -Y. Lam; H. Du","School of Computer Science and Engineering, Nanyang Technological University, Singapore, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore, Singapore; School of Automation, Guangdong University of Technology, Guangzhou, China; School of Computer Science and Engineering, Nanyang Technological University, Singapore, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore, Singapore","IEEE Internet of Things Journal","22 Jun 2023","2023","10","13","11199","11223","A city is a large human settlement that serves the people who live there, and a smart city is a concept of how cities might better serve their residents through new forms of technology. In this article, we focus on four major smart city domains according to Maslow’s hierarchy of needs: smart utility, smart transportation, smart homes, and smart healthcare. Numerous Internet of Things (IoT) applications have been developed to achieve the intelligence that we desire in our smart domains, ranging from personal gadgets, such as health trackers and smart watches to large-scale industrial IoT systems, such as nuclear and energy management systems. However, many of the existing smart city IoT solutions can be made better by considering the suitability of their security strategies. Inappropriate system security designs generally occur in two scenarios: first, system designers recognize the importance of security but are unsure of where, when, or how to implement it and second, system designers try to fit traditional security designs to meet the smart city security context. Thus, the objective of this article is to provide application designers with the missing security link they may need in order to improve their security designs. By evaluating the specific context of each smart city domain and the context-specific security requirements, we aim to provide directions on when, where, and how they should implement security strategies and the possible security challenges they need to consider. In addition, we present a new perspective on security issues in smart cities from a data-centric viewpoint by referring to the reference architecture, the activity-network-things (ANTs)-centric architecture. This architecture is built upon the concept of “security in a zero-trust environment,” to achieve end-to-end data security. By doing so, we reduce the security risks posed by new system interactions or unanticipated user behaviors while avoiding the hassle of regularly upgrading security models.","2327-4662","","10.1109/JIOT.2023.3252040","National Research Foundation, Singapore; Alibaba Group through Alibaba Innovative Research (AIR) Program and Alibaba--NTU Singapore Joint Research Institute (JRI), Nanyang Technological University, Singapore; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10058199","Cryptography;Internet of Things (IoT);IoT security;privacy;smart cities;survey;wireless communication","Security;Smart cities;Internet of Things;Computer architecture;Wireless communication;Smart homes;Medical services","","4","","131","IEEE","3 Mar 2023","","","IEEE","IEEE Journals"
"A Spatiotemporal Model for Peak AoI in Uplink IoT Networks: Time Versus Event-Triggered Traffic","M. Emara; H. Elsawy; G. Bauch","Germany Standards R&D Team, Next Generation and Standards, Intel Deutschland GmbH, Munich, Germany; Electrical Engineering Department, King Fahd University of Petroleum and Minerals, Dhahran, Saudi Arabia; Institute of Communications, Hamburg University of Technology, Hamburg, German","IEEE Internet of Things Journal","12 Aug 2020","2020","7","8","6762","6777","Timely message delivery is a key enabler for Internet of Things (IoT) and cyber-physical systems to support a wide range of context-dependent applications. Conventional time-related metrics (e.g., delay and jitter) fail to characterize the timeliness of the system update. Age of Information (AoI) is a time-evolving metric that accounts for the packet interarrival and waiting times to assess the freshness of information. In the foreseen large-scale IoT networks, mutual interference imposes a delicate relation between traffic generation patterns and transmission delays. To this end, we provide a spatiotemporal framework that captures the peak AoI (PAoI) for the large-scale IoT uplink network under time-triggered (TT) and event-triggered (ET) traffic. Tools from the stochastic geometry and queueing theory are utilized to account for the macroscopic and microscopic network scales. Simulations are conducted to validate the proposed mathematical framework and assess the effect of traffic load on the PAoI. The results unveil a counter-intuitive superiority of the ET traffic over the TT in terms of PAoI, which is due to the involved temporal interference correlations. Insights regarding the network stability frontiers and the location-dependent performance are presented. Key design recommendations regarding the traffic load and decoding thresholds are highlighted.","2327-4662","","10.1109/JIOT.2020.2981924","Deanship of Scientific Research, King Fahd University of Petroleum and Minerals(grant numbers:DF191052); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9042825","Age of Information (AoI);Internet of Things (IoT);queueing theory;spatiotemporal models;stochastic geometry","Spatiotemporal phenomena;Interference;Internet of Things;Stochastic processes;Geometry;Queueing analysis;Uplink","","57","","57","IEEE","19 Mar 2020","","","IEEE","IEEE Journals"
"IoT Based Solar Performance Monitoring System","N. D. Parappully; S. Joseph; P. S. Rajeswari; P. Immanuel Sabu; V. P. Madhanmohan","Dept. of EEE, Christ College of Engineering, Irinjalakuda, Thrissur, India; Dept. of EEE, Christ College of Engineering, Irinjalakuda, Thrissur, India; Dept. of EEE, Christ College of Engineering, Irinjalakuda, Thrissur, India; Dept. of EEE, Christ College of Engineering, Irinjalakuda, Thrissur, India; Dept. of EEE, Christ College of Engineering, Irinjalakuda, Thrissur, India","2023 9th International Conference on Smart Computing and Communications (ICSCC)","6 Dec 2023","2023","","","627","631","Sun is one of the biggest sources of renewable energy. This energy recieved from the sun could be easily converted into electricity with the help of semiconductor materials, primarily silicon. These materials are used to create solar panels. Over the years, Solar PV technology has become the go-to source of renewable electricity generation systems due to its advantages compared to other sources of energy. The increasing consciousness of the effects of fossil fuels has accelerated its adoption. With the exponential adoption of solar systems, the requirement of an efficient sub-processes for the same is increasing. A monitoring system, especially at a large scale, has become necessity due to the increasing scale and efficiency concerns. The paper aims to provide a solution for the same utilizing the advancements of Internet of Things technology (IoT), wherein the entire system is monitored using a central unit and data transfer reliant on internet connections. The proposed system automates the process of monitoring at panel level and assists in the maintenance and diagnosis routinely, by the inclusion of IoT reducing human interventions and at a low cost giving timely alerts whenever power generation issues arise.","","979-8-3503-1409-0","10.1109/ICSCC59169.2023.10334989","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10334989","IoT;solar energy;remote monitoring;solar panels","Productivity;Renewable energy sources;Costs;Solar energy;Silicon;Sensors;Solar panels","","","","10","IEEE","6 Dec 2023","","","IEEE","IEEE Conferences"
"Cloud-based Smart Parking System using Internet of Things","S. Tu; M. Ayaz; A. Arshad; U. Iftikhar; Y. Harrath; M. Waqas","Faculty of Information Technology, Beijing University of Technology, Beijing, China; College of Information Technology, University of Bahrain, Bahrain; School of Engineering, Edith Cowan University, Perth, WA, Australia; College of Information Technology, University of Bahrain, Bahrain; College of Information Technology, University of Bahrain, Bahrain; College of Information Technology, University of Bahrain, Bahrain","2023 International Wireless Communications and Mobile Computing (IWCMC)","21 Jul 2023","2023","","","1377","1382","This research aims to design a smart parking system using cloud and Internet of Things (IoT) technologies to improve the process of finding parking spaces in urban areas. The proposed system utilizes sensors and microcontrollers in each parking space to provide real-time data to users through a mobile application. The primary objective of our research is to address issues, such as time-consuming manual searches for parking spaces and reduce traffic congestion. This research suggests a system of reliable smart ultra-sonic sensors connected to a microcontroller for easy and remote parking automation. Users can select a parking space by clicking on the available slot in the mobile application. Additionally, the mobile application informs users about empty spots. This smart parking system can be implemented on both small and large-scale models, and the results suggest that it effectively replicates traditional automobile parking, with the added convenience of a mobile application, in urban areas.","2376-6506","979-8-3503-3339-8","10.1109/IWCMC58020.2023.10182770","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10182770","","Wireless communication;Cloud computing;Microcontrollers;Urban areas;Sensor systems;Real-time systems;Mobile applications","","","","22","IEEE","21 Jul 2023","","","IEEE","IEEE Conferences"
"Demo Abstract: An Internet of Plants System for Micro Gardens","V. K. Nguyen; Q. Z. Sheng; A. Mahmood; W. E. Zhang; M. -H. Phan; T. D. Vo","Macquarie University, NSW, Australia; Macquarie University, NSW, Australia; Macquarie University, NSW, Australia; The University of Adelaide, SA, Australia; University of Wollongong, NSW, Australia; CleverPal Pty. Ltd., NSW, Australia","2020 19th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)","9 Jun 2020","2020","","","355","356","The promising paradigm of the Internet of Things (IoT) has rapidly proliferated in a number of domains, e.g., energy monitoring, transportation, smart cities, healthcare, and the like. Leveraging on the same, in this paper, we proposed an Internet of Plants system to remotely monitor soil moisture level and automate watering control for the plants. The envisaged system not only facilitates in over watering or under watering of the plants but also provides data collection for the gardeners to understand the key features pertinent to healthy growth of plants. Such kind of system also encourages more people to grow their small-scale organic gardens in urban areas, thereby, increasing greenery in modern cities.","","978-1-7281-5497-8","10.1109/IPSN48710.2020.000-9","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9111020","• Computer systems organization → System on a chip;Firmware;Embedded software;Real-time system architecture","","","3","","5","IEEE","9 Jun 2020","","","IEEE","IEEE Conferences"
"Enhancing Node Fault Tolerance through High-Availability Clusters in Kubernetes","H. -C. Jang; S. -Y. Luo","Department of Computer Science, National Chengchi University, Taipei, Taiwan; Department of Computer Science, National Chengchi University, Taipei, Taiwan","2023 IEEE 3rd International Conference on Electronic Communications, Internet of Things and Big Data (ICEIB)","7 Jul 2023","2023","","","30","35","Microservices architecture and containerization technology have become ubiquitous recently. Docker containers have emerged as a standardized software packaging unit, offering rapid deployment, flexible scaling, and cross-platform operability. This enables the industry to focus on innovation and business needs while managing underlying infrastructure effortlessly. With the advent of technologies such as the Internet of Things, big data, and machine learning, there is a growing demand for parallel processing of large amounts of data across multiple hosts. Ensuring system resource availability and stability is essential, especially when services experience unexpected interruptions. As the number of containers increases, docker has introduced a container management platform called Docker Swarm to manage and schedule containers across multiple hosts and adjust their operational scale based on workload. If a container unexpectedly stops operating, the Docker Swarm cluster generates new containers automatically, ensuring the high availability of container services. Meanwhile, Google has introduced a container scheduling system called Kubernetes. The Horizontal Pod Autoscaler in Kubernetes automatically adjusts the number of service Pods based on node target memory usage, improving overall resource utilization. While Kubernetes can simplify application management and deployment, the cluster’s performance after deployment has yet to be effectively evaluated and compared. This study aims to optimize and adjust cluster node resource configuration and parameter settings using tools such as Vertical Pod Autoscaler, Descheduler, Ingress Controller, and Scheduling Framework. The performance of Kubernetes is compared with the Docker Swarm architecture to analyze the average response time, longest response time, connection success rate, success count, and failure count of the overall cluster’s web service traffic workload. The optimization is carried out to ensure the high availability of container services in case of node failures.","","979-8-3503-3386-2","10.1109/ICEIB57887.2023.10170110","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10170110","fault tolerance;Kubernetes;container;Autoscaler","Fault tolerance;Job shop scheduling;Fault tolerant systems;Computer architecture;Containers;Big Data;Stability analysis","","","","15","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Development of Interference Mitigation Techniques based Artificial Neural Network for IoT Network","N. Promsuk","Department of Computer Engineering, Faculty of Engineering, Chiang Mai University, Chiang Mai, Thailand","2021 18th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON)","18 Jun 2021","2021","","","374","377","Nowadays, many sectors and systems have applied the Internet of things (IoT) concept in their works such as operating the real-time service, increasing the performance of the machine to machine (M2M) communication, and avoiding human error. Therefore, the co-channel interference problem is taking into account because more devices are sharing the same communication channel. Also, the rapid increase of IoT devices is the major reason why the interference problem becomes serious. Moreover, overlapping and sharing the same channel can cause the corrupted signal which led to the retransmission of the signal. In this paper, the multi-layer perceptron (MLP) which is an artificial intelligence neural network (ANN) model applied to reduce the adjacent channel interference. These proposed interference mitigation techniques (IMTs) investigate the IoT network at 2.4 GHz. The results are compared between the interference mitigation based on MLP and the traditional minimum mean square error (MMSE) approach. In the MLP model, the fast Fourier transform (FFT) data and the amplitude data are used for the model's input. Moreover, the IoT network topology with the effect of path loss and small-scale fading is generated to make a more realistic system. According to the results, the performance of both IMTs with the MLP model can perform better than the MMSE filter. In addition, the accuracy of our proposed technique is up to 80% in all investigated scenarios.","","978-1-6654-0382-5","10.1109/ECTI-CON51831.2021.9454889","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9454889","Internet of things;neural network;multi-layer perceptron;interference mitigation","Performance evaluation;Fast Fourier transforms;Network topology;Artificial neural networks;Mean square error methods;Data models;Real-time systems","","6","","11","IEEE","18 Jun 2021","","","IEEE","IEEE Conferences"
"Performance Analysis of fog System with user’s impatient behaviour","P. Mukherjee; V. Goswami; S. S. Patra; G. B. Mund; J. Chakraborty; R. K. Barik","School of Computer Engineering, KIIT Deemed to be University, Bhubaneswar, India; School of Computer Applications, KIIT Deemed University, Bhubaneswar, India; School of Computer Applications, KIIT Deemed University, Bhubaneswar, India; School of Computer Engineering, KIIT Deemed to be University, Bhubaneswar, India; School of Computer Applications, KIIT Deemed University, Bhubaneswar, India; School of Computer Applications, KIIT Deemed University, Bhubaneswar, India","2022 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT)","30 Aug 2022","2022","","","1","6","The Industrial Internet of Things (IIoT) is rapidly expanding. The social media, wireless communication and digitization technology growing rapidly and creating a large amount of data. For handling and processing, the large amount of data storage fog computing is an emerging solution which assist the cloud computing. Fog Computing improves the QoS provided to users with the help of cloud computing, by giving service to the IoT devices at their nearby proximity.The fog nodes' virtual machines (VMs) are in charge of processing and analysing IoT applications in real time.. One of the unsolved research issues is scaling the fog system efficiently to limit the customer requests reneging from the system.. The fog nodes are assumed to be a finite queue-dependent multi-server system in which tasks share the VMs.This paper evaluates the performance of the fog system by considering a multi-server queueing system with balking and reneging policies.","2766-2101","978-1-6654-9781-7","10.1109/CONECCT55679.2022.9865809","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9865809","Fog computing;Cloud computing;Balking and reneging;Queueing model","Wireless communication;Cloud computing;Social networking (online);Computational modeling;Virtual machining;Real-time systems;Numerical models","","","","31","IEEE","30 Aug 2022","","","IEEE","IEEE Conferences"
"Performance Improvement of Blockchain-based IoT Applications using Deep Learning Techniques","R. Patan; R. M. Parizi","Dept. of Software Engineering & Game Development, Decentralized Science Lab, College of Computing and Software Engineering, Kennesaw State University, Marietta, GA, USA; Dept. of Software Engineering & Game Development, Decentralized Science Lab, College of Computing and Software Engineering, Kennesaw State University, Marietta, GA, USA","2022 Fourth International Conference on Blockchain Computing and Applications (BCCA)","31 Oct 2022","2022","","","151","158","Internet of Things (IoT) deployments have increased drastically based on third-party (fog-assisted architecture) mechanisms to store, process, and share sensor data. IoT environments are mostly vulnerable to security threats due to the lack of intrinsic security measures. Blockchain technology with an untrusty framework to establish trust communication among IoT devices becomes a major concern in lightweight IoT frameworks. To solve this trust issue, we propose a DeepIoT-Block model that combines the consensual deep learning (CDL) technique using the elliptic Diffihelman protocol to strengthen the blockchain-based data storage scheme (BDSS) and Directed Acyclic Graph (DAG) to construct the blockchain network. DeepIoT-Block has implemented using a blockchain system for IoT applications to address storage security issues. DeepIoT-Block guarantees simultaneous computational complexity and transaction efficiency. The performance of the proposed model was verified and validated for IoT-based smart road traffic data. The simulation outcomes show that our proposed model, DeepIoT-Block, is computationally efficient and secure for larger scale IoT applications.","","978-1-6654-9958-3","10.1109/BCCA55292.2022.9922342","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9922342","Internet of Things (IoT);Blockchain;Smart applications;Deep Learning;Consensual mechanism","Deep learning;Directed acyclic graph;Computational modeling;Roads;Memory;Elliptic curve cryptography;Data models","","1","","20","USGov","31 Oct 2022","","","IEEE","IEEE Conferences"
"A Conceptual Trust Management Framework under Uncertainty for Smart Vehicular Networks","V. Venkatraman; S. Pal; Z. Jadidi; A. Jolfaei","School of Computer Science, Queensland University of Technology, Brisbane, Australia; School of Computer Science, Queensland University of Technology, Brisbane, Australia; School of Information and Communication Technology, Griffith University, Gold Coast Campus, QLD, Australia; School of Computer Science, Macquarie University, Sydney, NSW, Australia","IEEE INFOCOM 2022 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)","20 Jun 2022","2022","","","1","7","Trust is a fundamental concept in large-scale distributed systems like the Internet of Things (IoT). Trust helps to resolve choices into a decision. However, the trust calculation depends on the amount of uncertainty present in data sources. Trust in an IoT network is proportional to the amount of uncertainty generated by such sources as hardware malfunctions, network stability, adversarial issues, and the nature of data exchanged between the entities. The relationship between trust and uncertainty warrants approaches designed to maximize the former quality whilst minimizing the latter. Unfortunately, there is no consensus on an approach to ensure the trustworthiness of IoT networks, in particular, addressing the uncertainty issues in a fine-grained way. This paper aims to explore a generalized framework designed to manage trust in IoT networks of varying scales. In the proposed framework, several sources of uncertainty are expressed as quantities, trust ratings are calculated for individual entities in an IoT network, and a network model capable of effectively distributing workloads to trustworthy nodes is proposed. We consider a practical use case of smart vehicular networks. By realizing this paper, a standardized approach to building trustworthy IoT networks can be established, which can further guide subsequent works in the field of trust management under uncertainty.","","978-1-6654-0926-1","10.1109/INFOCOMWKSHPS54753.2022.9797996","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9797996","Internet of Things;Uncertainty;Trust management framework;Smart vehicular networks.","Uncertainty;Conferences;Soft sensors;Buildings;Stability analysis;Hardware;Internet of Things","","","","38","IEEE","20 Jun 2022","","","IEEE","IEEE Conferences"
"IoT Augmented Physical Scale Model of a Suburban Home","T. Burns; G. Fichthorn; S. Zehtabian; S. S. Bacanli; M. Razghandi; L. Bölöni; D. Turgut","Department of Computer Science, Rutgers University; Department of Computer Science, Stetson University; Department of Computer Science, University of Central Florida; Department of Computer Science, University of Central Florida; Department of Computer Science, University of Central Florida; Department of Computer Science, University of Central Florida; Department of Computer Science, University of Central Florida","2020 IEEE International Conference on Communications Workshops (ICC Workshops)","21 Jul 2020","2020","","","1","5","Green homes require informed energy management decisions. For instance, it is preferable that a comfortable internal temperature is achieved through natural, energy-efficient means such as opening doors or lowering shades as opposed to turning on the air conditioning. This requires the control agent to understand the complex system dynamics of the home: will opening the window raise or lower the temperature in this particular situation? Unfortunately, developing mathematical models of a suburban home situated in its natural environment is a significant challenge, while performing real-world experiments is costly, takes a long time and depends on external circumstances beyond the control of the experimenter. In this paper, we describe the architecture of a physical, small scale model of a suburban home and its immediate exterior environment. Specific scenarios can be enacted using Internet of Things (IoT) actuators that control the doors and windows. We use a suite of IoT sensors to collect data during the scenario. We use deep learning-based temporal regression models to make predictions about the impact of specific actions on the temperature and humidity in the home.","2474-9133","978-1-7281-7440-2","10.1109/ICCWorkshops49005.2020.9145040","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9145040","Smart home modeling;internet of things;temperature regulation","Temperature sensors;Humidity;Smart homes;Predictive models;Fans;Intelligent sensors","","","","14","IEEE","21 Jul 2020","","","IEEE","IEEE Conferences"
"Galvatron: Monitoring and Controlling of Generator Systems Through Androids","M. Tahir; R. N. Enam; S. M. N. Mustafa; N. Ismat","Dept.of Software Engineering, Sir Syed University of Engineering and Technology, Karachi, Pakistan; Dept.of Software Engineering, Sir Syed University of Engineering and Technology, Karachi, Pakistan; Dept. of Computer Science & I.T, NED University of Engineering and Technology, Karachi, Pakistan; Dept.of Software Engineering, Sir Syed University of Engineering and Technology, Karachi, Pakistan","2022 Global Conference on Wireless and Optical Technologies (GCWOT)","17 May 2022","2022","","","1","5","The electric power generators prove to be handy when, it comes to power shortages. They are reliable but expect somebody to keep up them an opportunity to time. Electric power generators require continuous conservation to give a high performance. The manual monitoring and maintenance of the generators is a complex task. In the era of automation, the facility of generators can also be automated to minimize the human involvement and increase the life of the power generators. In this paper, we have introduced a system that is created to keep track of generators without requiring someone to manually monitor them on a regular basis. The concept is to design an app that uses the popular Android operating system to remotely monitor energy generators. The proposed system automatically monitors devices, update status and provide alarms. Simple banners are transmitted by the sensors, which offer reliable data on the generator's status. The model portrays the advancement of Generator parameter checking framework. The checking parameters of generator like fuel level, oil level, temperature, flow, voltage controls are educated to the approved faculty through by means of Internet of Things (IoT) application. Consequently, the Arduino smaller scale controller generates the results in its propelled condition and then converts the yield into a following banner. The banner is subsequently communicated to the Android phone via a switch, changes and updates these data. As a result, the generator's state may be monitored in real time.","","978-1-6654-7105-3","10.1109/GCWOT53057.2022.9772904","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9772904","Wireless monitoring;Android Application;Sensor monitoring;Generators;Monitoring and Controlling","Temperature sensors;Temperature measurement;Wireless communication;Wireless sensor networks;Optical switches;Generators;Power systems","","1","","19","IEEE","17 May 2022","","","IEEE","IEEE Conferences"
"Tiny-PIRATE: A Tiny model with Parallelized Intelligence for Real-time Analysis as a Traffic countEr","S. V. -U. Ha; N. M. Chung; T. -C. Nguyen; H. N. Phan","School of Computer Science and Engineering, International University, Ho Chi Minh City, Vietnam; School of Computer Science and Engineering, International University, Ho Chi Minh City, Vietnam; School of Computer Science and Engineering, International University, Ho Chi Minh City, Vietnam; School of Computer Science and Engineering, International University, Ho Chi Minh City, Vietnam","2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","1 Sep 2021","2021","","","4114","4123","Due to the rapid growth in the number of vehicles over the last decade, there has been a dramatic increase in demand for highway capacity analysis. Vehicle counting, in particular, has become a key element of vision-based intelligent traffic systems deployed across metropolitan areas. Most methods solved the vehicle counting problem under the assumption of state-of-the-art computing systems. However, large-scale deployment of such systems for multi-camera processing is very inefficient. With the recent advancement of cost-efficient Internet-of-Things (IoT) devices alongside machine learning methods developed specifically for such devices, solving the vehicle counting problem for real-time traffic analysis on IoT edge devices, and thereby facilitating its large-scale deployment have become highly favorable. In this paper, we propose a framework of vehicle counting designed specifically for IoT edge computers which follows the detection-tracking-counting (DTC) model. The proposed solution aims at addressing the multimodality of contextual dynamics in traffic scenes with a small detector model, a robust tracker and a counting process that accurately estimate both a vehicle's motion of interest and its exit time from observation areas. Experimental results on AI City 2021 Track-1 Dataset showed that ours outperformed related methods with promising results regarding both accuracy and execution speed.","2160-7516","978-1-6654-4899-4","10.1109/CVPRW53098.2021.00465","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9522996","","Road transportation;Tracking;Image edge detection;Computational modeling;Urban areas;Detectors;Real-time systems","","11","","36","IEEE","1 Sep 2021","","","IEEE","IEEE Conferences"
"The Impact of Internet of Things on the Domain Name System","K. Aucklah; A. Mungur; S. Armoogum; S. Pudaruth","Department of Information and Communication Technologies, Faculty of Information, Communication and Digital Technologies, University of Mauritius, Reduit, Mauritius; Department of Information and Communication Technologies, Faculty of Information, Communication and Digital Technologies, University of Mauritius, Reduit, Mauritius; Department of Information and Communication Technologies, Faculty of Information, Communication and Digital Technologies, University of Mauritius, Reduit, Mauritius; Department of Information and Communication Technologies, Faculty of Information, Communication and Digital Technologies, University of Mauritius, Reduit, Mauritius","2021 5th International Conference on Intelligent Computing and Control Systems (ICICCS)","26 May 2021","2021","","","449","454","The rise of connected objects known as the Internet of Things (IoT) has conquered the world. It is a platform for the functioning of various smart devices on a large scale. IoT devices can communicate with each other without interaction between the user and devices. Security stakeholders across the planet have confirmed that the growth of IoT has created the right set of circumstances for malicious users to attack the Domain Name System (DNS). Illicit users may threaten the frameworks with large-scale botnets and can also compromise the services provided by organizations. This paper has highlighted the impact of IoT systems on the domain name system. Also, this research work provides a cutting-edge overview of current solutions that can help to tackle the security and policy challenges in the domain name system.","","978-1-6654-1272-8","10.1109/ICICCS51141.2021.9432217","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9432217","Domain Name System (DNS);Internet of Things (IoT);Security;Protocols","Electric potential;Systematics;Planets;Green products;Organizations;Internet of Things;Security","","1","","30","IEEE","26 May 2021","","","IEEE","IEEE Conferences"
"iBoT: IoT Botnet Testbed","A. Beauchaine; M. Macchiaroli; M. Yun","Department of Computer Science and Networking, Wentworth Institute of Technology, Boston, MA, USA; Department of Computer Science and Networking, Wentworth Institute of Technology, Boston, MA, USA; Department of Computer Science and Networking, Wentworth Institute of Technology, Boston, MA, USA","2021 16th International Conference on Computer Science & Education (ICCSE)","21 Oct 2021","2021","","","822","827","Security in Internet-of-Things (IoT) devices has become increasingly relevant in the recent years. One of the driving reasons for the increased attention in this field is the fast-paced propagation of IoT botnet attacks. Botnet cyber-attacks refer to large scale distributed systems that maliciously exploit devices to perform tasks, such as DDoS attacks. IoT devices make easy attack vectors for such a system, given their tendency to be lightweight and insecure. Provided the increasing gravity of the subject, we have proposed a solution to produce a realistic testbed for the study of IoT botnets with low-cost and off-the-shelf devices. This testbed integrates layer 3 connectivity as well as home and business network topology. Special emphasis has been placed upon network and endpoint logging in this design, and testing has been documented with multiple styles of attacks.","2473-9464","978-1-6654-1468-5","10.1109/ICCSE51940.2021.9569298","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9569298","Botnet;Internet of Things;Testbed;DDoS attacks","Wireless communication;Performance evaluation;Knowledge engineering;Home appliances;Network topology;Botnet;Education","","","","13","IEEE","21 Oct 2021","","","IEEE","IEEE Conferences"
"Proposing A Cloud and Edge Computing Based Decision Supportive Consolidated Farming System By Sensing Various Effective Parameters Using IoT","M. A. Uddin; U. Kumar Dey; M. Akter","Electronics and Communication Engineering Discipline, Khulna University, Khulna, Bangladesh; Electronics and Communication Engineering Discipline, Khulna University, Khulna, Bangladesh; Electronics and Communication Engineering Discipline, Khulna University, Khulna, Bangladesh","2022 IEEE International IOT, Electronics and Mechatronics Conference (IEMTRONICS)","20 Jun 2022","2022","","","1","6","Now-a-days, we are facing significant challenges as a result of food shortages and a lack of large-scale food production utilizing traditional methods. As a result, global food supply rivalry has become the most pressing issue of the world. Cloud computing based on Internet of Things (IoT) and Wireless Sensor Networks (WSN) have become a comforting part of the solution to overcome this situation by replacing traditional methods in food production and monitoring systems. In this work, we represent a consolidated farming system with LED, SMS, E-mail, and website-based monitoring using WSN and IoT. To monitor a smart farm, several effective sensors are utilized in various industries, such as agriculture, aquaculture, livestock, air quality, weather monitoring, and health monitoring. All sensor’s data is reserved on the IoT cloud platform as well as our built website named Website for Consolidated Smart Farms Monitoring (WCSFM), allowing a concerned person to readily access all relevant data from anywhere on the planet. Our model notifies the end user of expected information based on predefined sensor values by sending SMS, E-mail notifications, and turning on LEDs. Moreover In remote places, our IoT and WSN-based approaches may be more useful.","","978-1-6654-8684-2","10.1109/IEMTRONICS55184.2022.9795733","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9795733","Internet of Things;Cloud Computing;Wireless Sensor Networks;Consolidated Farms Monitor;and Sensors","Wireless sensor networks;Cloud computing;Production;Turning;Sensor systems;Internet of Things;Monitoring","","","","17","IEEE","20 Jun 2022","","","IEEE","IEEE Conferences"
"SSIWM: Smart Secured IoT Framework for Integrated Water Resource Management System","A. Ray; H. Ray","A. K. C. School of Information Technology, University of Calcutta, Kolkata, India; Centre for Development of Advanced Computing, Kolkata, India","2020 IEEE Bangalore Humanitarian Technology Conference (B-HTC)","31 Dec 2020","2020","","","1","6","There is a global crisis looming over the world pertaining to the supply of fresh water which draws upon itself the need for developing a system that could cater to it. The developed system needs to be smart enough with use of machine learning so as detect excessive or normal water flow through a pipe, the data must always be end to end encrypted so as to ensure confidentiality and security to the water usage pattern, it must be able to be deployed in a large scale across a state or country for instance wherein each water pipeline must be connected in the network so as to maintain the water resource at large. This would make enough data flow in the connected network that would require for a computational intensive Cloud platform and yet have intelligence or distributed computing facilities in-built in the network to develop and deploy an integrated water resource management system. The basic construct of our design does abide by the aforementioned constraints and does allow for a large scale commercial deployment. There is a scarcity of such an integrated water resource management system in our country as well as abroad and our paper does bring to light an intelligent, low powered and commercial deployable device that could well fill up the void through an array of technologies in the system design which fundamentally lies on an Internet of Things framework.","","978-1-7281-8794-5","10.1109/B-HTC50970.2020.9298021","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9298021","Edge nodes;Fog nodes;Cloud Computing;Data Security;Machine Learning","Water resources;Encryption;Cloud computing;Data acquisition;Cryptography;Computer architecture;Monitoring","","5","","10","IEEE","31 Dec 2020","","","IEEE","IEEE Conferences"
"A Framework for the Design and Deployment of Large-Scale LPWAN Networks for Smart Cities Applications","B. A. Homssi; A. Al-Hourani; K. Magowe; J. Delaney; N. Tom; J. Ying; H. Wolf; S. Maselli; S. Kandeepan; K. Wang; K. M. Gomez","School of Engineering, RMIT University, Australia; School of Engineering, RMIT University, Australia; School of Engineering, RMIT University, Australia; School of Engineering, RMIT University, Australia; School of Engineering, RMIT University, Australia; City of Whittlesea Council and Banyule City Council, Australia; City of Whittlesea Council and Banyule City Council, Australia; Minnovation Australia, Australia; School of Engineering, RMIT University, Australia; School of Engineering, RMIT University, Australia; School of Engineering, RMIT University, Australia","IEEE Internet of Things Magazine","30 Mar 2021","2021","4","1","53","59","The Internet of Things (IoT) enables the connectivity of massive numbers of sensors to facilitate the delivery of immense sets of data. This valuable data promotes higher productivity, effectiveness, and sustainability. With the accelerating global urbanization, many cities and suburbs are expected to face increasing challenges related to urban planning, resources and livability. These challenges stimulate new opportunities for communities and governments to collaboratively incubate new planning and development strategies relying on the insightful IoT data. This concept is commonly referred to as smart cities. Accordingly, a wave of smart cities implementations is currently emerging. However, the underlying IoT network deployments are developed in silos, and thus require more harmonization. In this paper, we present a design and deployment framework for large-scale low power wireless access networks (LPWAN) in order to harmonize and guide the end-to-end process. This framework is derived from the acquired expertise and learned lessons from the largest open-access LPWAN deployment in Australia. The framework includes various aspects related to the state-of-the-art design techniques, smart cities use-case scenarios, project development and implementation, network management, and finally a robust performance testing mechanism for quality of service assurance. All these components were put into rigorous verification and testing under this realistic large-scale IoT network deployment.","2576-3199","","10.1109/IOTM.001.2000179","Australian Government(grant numbers:SCS69259); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9310563","","Sensors;Smart cities;Logic gates;Urban areas;Testing;Monitoring;Wireless networks;Sustainable development","","14","","13","IEEE","29 Dec 2020","","","IEEE","IEEE Magazines"
"NOMA-Aided UAV Data Collection System: Trajectory Optimization and Communication Design","J. Zhao; Y. Wang; Z. Fei; X. Wang; Z. Miao","State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China","IEEE Access","2 Sep 2020","2020","8","","155843","155858","Unmanned aerial vehicle (UAV) communication has been deemed as a promising technology to collect data for the Internet of Things (IoT) in inaccessible areas. However, due to the limited UAV flight time, traditional UAV communication may not be competent for large-scale IoT data collection. This paper considers integrating non-orthogonal multiple access (NOMA) into UAV communication systems to collect data for large-scale IoT devices within UAV flight time. We aim to minimize the total energy consumption of IoT devices while ensuring data collection, by jointly optimizing UAV trajectory, IoT device scheduling and transmit power. The formulated problem is a mixed integer non-convex problem, which is challenging to solve in general. We propose a data collection optimization algorithm (DCOA) to solve it by applying the Generalized Benders Decomposition (GBD) and successive convex approximation (SCA) techniques. Then, a greedy algorithm (GA) is also proposed to reduce complexity by simplifying the optimization of UAV trajectory and IoT device scheduling. Finally, the numerical results demonstrate that, compared with traditional UAV communication systems, the NOMA-aided UAV system performs better in terms of data collection and lower total energy consumption of IoT devices can be achieved by DCOA.","2169-3536","","10.1109/ACCESS.2020.3019080","Beijing Natural Science Fund-Haidian Original Innovation Joint Fund(grant numbers:L192003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9175017","Unmanned aerial vehicle (UAV) communication;non-orthogonal multiple access (NOMA);data collection;Internet of Things (IoT);energy consumption minimization","NOMA;Unmanned aerial vehicles;Data collection;Trajectory;Energy consumption;Scheduling","","19","","46","CCBY","24 Aug 2020","","","IEEE","IEEE Journals"
"EdgeLSTM: Towards Deep and Sequential Edge Computing for IoT Applications","D. Wu; H. Xu; Z. Jiang; W. Yu; X. Wei; J. Lu","School of Design, Hunan University, Changsha, China; Department of Electronic Engineering, Hunan University, Changsha, China; Key Laboratory for Embedded and Network Computing of Hunan Province, Hunan University, Changsha, China; Department of Computer Science, University of Warwick, Coventry, U.K.; Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China; School of Design, Hunan University, Changsha, China","IEEE/ACM Transactions on Networking","17 Aug 2021","2021","29","4","1895","1908","The time series data generated by massive sensors in Internet of Things (IoT) is extremely dynamic, heterogeneous, large scale and time-dependent. It poses great challenges (e.g. accuracy, reliability, stability) on the real-time analysis and decision making for different IoT applications. In this paper, we design, implement and evaluate EdgeLSTM, a unified data-driven system to enhance IoT computing at the network edge. The EdgeLSTM leverages the grid long short-term memory (Grid LSTM) to provide an agile solution for both deep and sequential computation, therefore can address important features such as large-scale, variety, time dependency and real time in IoT data. Our system exploits the advantages of Grid LSTM network and extends it with a multiclass support vector machine by rigorous regularization and optimization approaches, which not only has strong prediction capability of time series data, but also achieves fine-grained multiple classification through the predictive error. We deploy the EdgeLSTM into four IoT applications, including data prediction, anomaly detection, network maintenance and mobility management by extensive experiments. Our evaluation results of real-world time series data with different short-term and long-term time dependency from these typical IoT applications show that our EdgeLSTM system can guarantee robust performance in IoT computing.","1558-2566","","10.1109/TNET.2021.3075468","National Natural Science Foundation of China(grant numbers:61972145,61932010); National Key Research and Development Program of China(grant numbers:2019YFB1405703,2018YFB1305200); Huxiang Youth Talent Program(grant numbers:2018RS3040); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9422203","Time series;edge computing;Internet of Things","Internet of Things;Time series analysis;Data models;Sensors;Support vector machines;Predictive models;Image edge detection","","16","","50","IEEE","3 May 2021","","","IEEE","IEEE Journals"
"DFSat: Deep Federated Learning for Identifying Cyber Threats in IoT-based Satellite Networks","N. Moustafa; I. A. Khan; M. Hassanin; D. Ormrod; D. Pi; I. Razzak; J. Slay","School of Engineering and Information Technology, University of New South Wales at ADFA, Australia; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, People's Republic of China; University of South Australia, Australia; University of South Australia, Australia; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, People's Republic of China; University of New South Wales, Sydeny Australia; University of South Australia, Australia","IEEE Transactions on Industrial Informatics","","2022","PP","99","1","8","The integration of satellite systems with smart computing and networking technologies, such as the Internet of Things (IoT), has intensely augmented sophisticated cyberattacks against satellite environments. Resisting cyber threats to complex and large-scale satellite configurations has been enormously challenging, owing to the deficiency of high-quality samples of attack data collected from distributed satellite networks. This study proposes a novel federated learning-based deep learning framework for intrusion detection, named DFSat, to identify cyberattacks from IoT-integrated satellite networks. We develop a distributed deep learning-enabled attack detection method using a recurrent neural network. We then build a federated learning architecture which, utilizes several IoT-integrated satellite networks to preserve the privacy and security of DFSat's parameters throughout the learning process. Extensive experiments have been conducted using communication rounds on an IoT-based network dataset to validate the efficiency of DFSat. The results revealed that the proposed framework significantly distinguishes complex cyberattacks, outperforming recent state-of-the-art intrusion detection techniques, validating its usefulness as a viable deployment framework in IoT-integrated satellite networks.","1941-0050","","10.1109/TII.2022.3214652","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9925589","Cyber security;Smart Enterprise Systems;Federated learning;Intrusion Detection;Internet of Things (IoT);Satellite Systems","Satellites;Security;Internet of Things;Intrusion detection;Earth;Computer architecture;Low earth orbit satellites","","2","","","IEEE","20 Oct 2022","","","IEEE","IEEE Early Access Articles"
"Information Harvesting for Far-Field Wireless Power Transfer","M. C. Ilter; R. Wichman; M. Säily; J. Hämäläinen","Aalto University, Finland; Aalto University, Finland; Nokia Bell Labs, Finland; Aalto University, Finland","IEEE Internet of Things Magazine","13 Sep 2022","2022","5","2","127","132","In today's smart world, the Internet of Things (IoT) offers a very large scale of technologies and use cases. An IoT system comprises a huge amount of low-power IoT network elements, sensors, and smart devices connected to each other. For these devices, it is important to have a sufficient level of energy resource for communication and to receive software/firmware updates periodically. In this aspect, wireless power transfer is a popular paradigm to tackle energy limitations. Therein, the battery of IoT devices can be remotely replenished by means of radio-frequency-radiated signaling, referred to as far-field wireless power transfer. Furthermore, harvesting energy from ambient communication signals available in the environment introduces simultaneous wireless information and power transfer technology. These systems face the trade-off between information capacity and energy harvesting efficiency. Accordingly, various signaling design frameworks have been proposed to comply with different system preferences between power and information. In this work, aside from existing trends, we propose a novel concept, information harvesting (IH), which introduces a novel protocol that lies in transmitting information on top of the existing wireless power transfer mechanism. Considering the diversity of IoT networks and the availability of wireless power transfer infrastructure, the proposed IH principle may turn out to be a pivotal methodology that combines physical layer security with wireless power transfer, particularly for cases where a large number of IoT devices require software/firmware updates along with periodical battery recharging needs.","2576-3199","","10.1109/IOTM.002.2100058","Academy of Finland(grant numbers:334000); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9889296","","Protocols;Radio transmitters;Wireless power transfer;Physical layer security;Market research;Sensor systems;Batteries","","3","","15","IEEE","13 Sep 2022","","","IEEE","IEEE Magazines"
"Analysis of IoT-Based Load Altering Attacks Against Power Grids Using the Theory of Second-Order Dynamical Systems","S. Lakshminarayana; S. Adhikari; C. Maple","School of Engineering, University of Warwick; School of Engineering, University of Glasgow; Warwick Manufacturing Group, University of Warwick","2022 IEEE Power & Energy Society General Meeting (PESGM)","27 Oct 2022","2022","","","1","1","Recent research has shown that large-scale Internet of Things (loT)-based load altering attacks can have a serious impact on power grid operations such as causing unsafe frequency excursions and destabilizing the grid's control loops. In this work, we present an analytical framework to investigate the impact of loT-based static/dynamic load altering attacks (S/DLAAs) on the power grid's dynamic response. Existing work on this topic has mainly relied on numerical simulations and, to date, there is no analytical framework to identify the victim nodes from which that attacker can launch the most impactful attacks. To address these shortcomings, we use results from second-order dynamical systems to analyze the power grid frequency control loop under S/DLAAs. We use parametric sensitivity of the system's eigensolutions to identify victim nodes that correspond to the \emph{least-effort} destabilizing DLAAs. Further, to analyze the SLAAs, we present closed-form expression for the system's frequency response in terms of the attacker's inputs, helping us characterize the minimum load change required to cause unsafe frequency excursions. Using these results, we formulate the defense against S/DLAAs as a linear programming problem in which we determine the minimum amount of load that needs to be secured at the victim nodes to ensure system safety/stability. Extensive simulations conducted using benchmark IEEE-bus systems validate the accuracy and efficacy of our approach.","1944-9933","978-1-6654-0823-3","10.1109/PESGM48719.2022.9916879","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9916879","","Sensitivity;Power system dynamics;Numerical simulation;Linear programming;Power grids;Frequency response;Internet of Things","","1","","0","IEEE","27 Oct 2022","","","IEEE","IEEE Conferences"
"A Lightweight User Interface for Smart Charging of Electric Vehicles: A Real-World Application","S. Meisenbacher; K. Schwenk; J. Galenzowski; S. Waczowicz; R. Mikut; V. Hagenmeyer","Karlsruhe Institute of Technology, Institute for Automation and Applied Informatics, Karlsruhe, Germany; Karlsruhe Institute of Technology, Institute for Automation and Applied Informatics, Karlsruhe, Germany; Karlsruhe Institute of Technology, Institute for Automation and Applied Informatics, Karlsruhe, Germany; Karlsruhe Institute of Technology, Institute for Automation and Applied Informatics, Karlsruhe, Germany; Karlsruhe Institute of Technology, Institute for Automation and Applied Informatics, Karlsruhe, Germany; Karlsruhe Institute of Technology, Institute for Automation and Applied Informatics, Karlsruhe, Germany","2021 9th International Conference on Smart Grid and Clean Energy Technologies (ICSGCE)","26 Nov 2021","2021","","","57","61","Intelligent power management of Electric Vehicles (EVs) integrates them into the power system to support grid reliability. However, uncoordinated EV charging, where the battery is fully charged at maximum available power after plugging in, is still the common practice. Introducing smart charging on a large scale necessitates a high acceptance by users of EVs. Making the underlying charging system tangible to the user is therefore mandatory. We present the User Interface (UI) of the Smart Charging Wizard web app to start, adjust and monitor the charging process. The web app is integrated into an Internet of Things (IoT) architecture to connect with the charging station. We demonstrate the operation of the UI and show how the charging system responds to dynamic adjustments by the EV user. The UI is customizable and enables future field studies to involve EV users and their individual preferences.","2688-0857","978-1-6654-3551-2","10.1109/ICSGCE52779.2021.9621604","Helmholtz Association; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9621604","electric vehicles;smart charging;power distribution systems;mobile applications;internet of things;battery aging","Power system management;Power system dynamics;User interfaces;Batteries;Smart grids;Service-oriented architecture;Power system reliability","","5","","23","IEEE","26 Nov 2021","","","IEEE","IEEE Conferences"
"A Route Planing Proposal for Intelligent Amusement Parks","B. Zhou; L. Yajun; S. Yanqing","School of Information, Beijing City University, Beijing, China; School of Information, Beijing City University, Beijing, China, Beijing, China; School of Information, Beijing City University, Beijing, China, Beijing, China","2021 International Conference on Control, Automation and Information Sciences (ICCAIS)","9 Dec 2021","2021","","","590","594","Queueing at amusement parks have long been a problem for park managers. This essay proposes a intelligent amusement parks system model based on the architecture of the Internet of Things (IoT). The function of the system is divided into two aspects, one is the flow density detection; The second is intelligent route recommendation. The density detection on the flow of people relies on images collected by depth camera. Based on large-scale image data, the convolutional neural network training model and personnel statistics are used to control the error rate within 10% through multiple rounds of optimization. In terms of route recommendation, the map of the amusement park area is established, and the recommendation of the play area and destination query are realized by combining the results of the detection of the flow density and the distance between each area. Through the simulation test, the system has good application value.","2475-7896","978-1-6654-4029-5","10.1109/ICCAIS52680.2021.9624573","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9624573","intelligent amusement parks;density detection;IoT;CNN;route planing","Training;Planing;Error analysis;Cameras;Data models;Internet of Things;Convolutional neural networks","","","","11","IEEE","9 Dec 2021","","","IEEE","IEEE Conferences"
"A Real-Time Blockchain-Based State Estimation System for Battery Energy Storage Systems","F. Mohammadi; M. Sanjari; M. Saif","Department of Electrical and Computer Engineering, University of Windsor, Windsor, ON, Canada; School of Engineering and Built Environment, Griffith University, Brisbane, QLD, Australia; Department of Electrical and Computer Engineering, University of Windsor, Windsor, ON, Canada","2022 IEEE Kansas Power and Energy Conference (KPEC)","6 Jul 2022","2022","","","1","4","The main roles of an advanced Battery Management System (BMS) are to dynamically monitor the battery packs and ensure the efficiency and reliability of the Battery Energy Storage System (BESS). Estimating the State of Charge (SoC), State of Health (SoH), State of Power (SoP), State of Energy (SoE), State of Temperature (SoT), and State of Safety (SoS) depends on collecting, aggregating, and analyzing real-time data of the BESS. Based on the applications of BESSs and their sizes, there are several restrictions in accessing and sharing data between battery manufacturers, power grid operators, and electricity consumers, while building necessary communication infrastructure is required. To resolve such issues, a conceptual and technological Blockchain-based system is developed in this paper to securely share the real-time data collected from BESSs for monitoring and control purposes, i.e., state estimation. The proposed system benefits from integrating the Internet of Things (IoT) devices in a decentralized structure and connectivity of such IoT nodes, data privacy, and transparency and auditability. The proposed Blockchain-based system is capable of accurately estimating SoC, SoH, SoP, SoE, SoT, and SoS of BESSs in small-and grid-scales.","","978-1-6654-6591-5","10.1109/KPEC54747.2022.9814731","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9814731","Blockchain Technology;Battery Energy Storage System (BESS);Battery Management System (BMS);Internet of Things (IoT) Technology;State Estimation","Temperature sensors;Temperature measurement;Temperature distribution;Real-time systems;Batteries;Blockchains;Internet of Things","","6","","22","IEEE","6 Jul 2022","","","IEEE","IEEE Conferences"
"Research and Application of MES Technology Architecture in Tobacco Industry Based on Micro Service","W. Jin; J. Qian; Q. Zhang; X. Gao; Y. Xu","Ningbo Cigarette Factory, China Tobacco Zhejiang Industrial Co. Ltd., Ningbo, China; Ningbo Cigarette Factory, China Tobacco Zhejiang Industrial Co. Ltd., Ningbo, China; Ningbo Cigarette Factory, China Tobacco Zhejiang Industrial Co. Ltd., Ningbo, China; Ningbo Cigarette Factory, China Tobacco Zhejiang Industrial Co. Ltd., Ningbo, China; Ningbo Cigarette Factory, China Tobacco Zhejiang Industrial Co. Ltd., Ningbo, China","2021 IEEE International Conference on Power, Intelligent Computing and Systems (ICPICS)","2 Sep 2021","2021","","","222","225","At present, tobacco enterprises have basically built MES system. With the large-scale popularization and application of Internet of things, big data, industrial cloud and artificial intelligence technology, the original system technology architecture cannot be compatible with the latest information technology, so it needs to be upgraded. Microservice technology architecture is the most advanced information system technology architecture at present. This paper explores the microservice transformation design of MES system technology architecture, in order to keep up with the development of information technology and better improve the intelligent level of tobacco enterprises.","","978-1-6654-4130-8","10.1109/ICPICS52425.2021.9524169","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9524169","Micro service architecture;MES;cigarette production;intelligent manufacturing","Industries;Process control;Computer architecture;Reliability engineering;User experience;Manufacturing;Security","","","","5","IEEE","2 Sep 2021","","","IEEE","IEEE Conferences"
"Pursuit Model Development and Calibration Methodology for Automated Parking Function","D. Barbe; X. Yang; Z. Chen; H. Ye; T. Chen; S. Fan; X. Cai; Y. Guo; T. Yang","Department of Electrification, Transmission and Vehicle, AVL Technical Center (Shanghai) Co., Ltd, Shanghai; Department of Electrification, Transmission and Vehicle, AVL Technical Center (Shanghai) Co., Ltd, Shanghai; Department of Electrification, Transmission and Vehicle, AVL Technical Center (Shanghai) Co., Ltd, Shanghai; Department of Electrification, Transmission and Vehicle, AVL Technical Center (Shanghai) Co., Ltd, Shanghai; Department of Electrification, Transmission and Vehicle, AVL Technical Center (Shanghai) Co., Ltd, Shanghai; Department of Electrification, Transmission and Vehicle, AVL Technical Center (Shanghai) Co., Ltd, Shanghai; Department of Electrification, Transmission and Vehicle, AVL Technical Center (Shanghai) Co., Ltd, Shanghai; Department of Electrification, Transmission and Vehicle, AVL Technical Center (Shanghai) Co., Ltd, Shanghai; Department of Electrification, Transmission and Vehicle, AVL Technical Center (Shanghai) Co., Ltd, Shanghai","2020 Chinese Control And Decision Conference (CCDC)","11 Aug 2020","2020","","","72","78","Automated Valet Parking is foreseen as a highly automated function to be implemented on large scale in mass production in the near future. For such function, The authors have developed an innovative system concept using both real time kinematic sensing system and infrastructure IoT (Internet of things) camera to perform AVP function. As the driver activates the AVP function, the infrastructure identifies available parking spots by processing in real time camera frames and as the path is computed, the vehicle executes automated parking maneuvers. This paper introduces the system scheme and system engineering approach as well as key technology bricks to realize AVP function and proves the effectiveness and accuracy of the system through extensive vehicle testing. From system definition to final prototype validation, through Motion control algorithm description or deep learning algorithm tuning method, this paper covers a large spectrum of the engineering domains required to implement such function. Finally a specific Pursuit Model development and calibration approach is elicited for the motion control function and proven in use by AVL Vehicle Prototype platform.","1948-9447","978-1-7281-5855-6","10.1109/CCDC49329.2020.9164624","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9164624","Autonomous Driving;Vehicle Dynamic;Deep learning;Motion Control;Real Time Kinematic;Infrastructure;Connectivity;internet of Things","Turning;Monitoring;Motion control;Cost function;Automobiles;Optical character recognition software;Real-time systems","","","","12","IEEE","11 Aug 2020","","","IEEE","IEEE Conferences"
"Revocable and Privacy-Preserving Decentralized Data Sharing Framework for Fog-Assisted Internet of Things","J. Zhang; J. Ma; Y. Yang; X. Liu; N. N. Xiong","School of Cyber Engineering and the State Key Laboratory of Integrated Services Networks, Xidian University, Xi’an, China; School of Cyber Engineering and the State Key Laboratory of Integrated Services Networks, Xidian University, Xi’an, China; School of Information Engineering, Inner Mongolia University of Science and Technology, Baotou, China; College of Computer and Big Data, Fuzhou University, Fuzhou, China; Department of Mathematics and Computer Science, Northeastern State University, Tahlequah, OK, USA","IEEE Internet of Things Journal","17 Jun 2022","2022","9","13","10446","10463","Fog-assisted Internet of Things (IoT) can outsource the massive data of resource-constraint IoT devices to cloud and fog nodes (FNs). Meanwhile, it enables convenient and low time-delay data-sharing services, which relies heavily on high security of data confidentiality and fine-grained access control. Many efforts have been focused on this urgent requirement by leveraging ciphertext-policy attribute-based encryption (CP-ABE). However, when deployed in fog-assisted IoT systems for secure data sharing, it remains a challenging problem of how to preserve attribute privacy of access policy, and trace-then-revoke traitors (i.e., malicious users intending to leak decryption keys for illegal profits) efficiently and securely in such a large scale and decentralized environment with resource-constraint user devices, especially in consideration of misbehaving cloud and FNs. Therefore, in this article, we propose a revocable and privacy-preserving decentralized data-sharing framework (RPDDSF) by designing a large universe and multiauthority CP-ABE scheme with fully hidden access policy for secure data sharing in IoT systems to achieve user attribute privacy preserving with unbounded attribute universe and key escrow resistance suitable for large scale and decentralized environment. Based on this, with RPDDSF, anyone can efficiently expose the traitors and punish them by forward/backward secure revocation. Besides, RPDDSF is able to guarantee data integrity for both data owners (DOs) and users to resist misbehaving cloud and FNs, alongwith low computation overhead for resource-constraint devices. Finally, RPDDSF is proven to be secure with detailed security proofs, and its high efficiency and feasibility are demonstrated by extensive performance evaluations.","2327-4662","","10.1109/JIOT.2021.3122949","National Natural Science Foundation of China(grant numbers:62072109,U1804263); Natural Science Foundation of Fujian Province(grant numbers:2021J06013); Natural Science Foundation of Inner Mongolia, China, 2020(grant numbers:2020LH06007); Innovation Fund of Inner Mongolia University of Science and Technology, China(grant numbers:2019QDL-B51); Inner Mongolia Major Science and Technology Projects: Artificial Intelligence Application Technology and Product Research and Development—Application Research and Demonstration in Modern Pastures(grant numbers:2019ZD025); Inner Mongolia Discipline Inspection and Supervision Big Data Laboratory Opening Project—Application Research on Accurate Supervision of Big Data Based on Blockchain(grant numbers:IMDBD2020021); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585576","Attribute privacy preserving;attribute-based encryption;forward/backward security;multiauthority;online/offline;outsourced decryption","Internet of Things;Data integrity;Cloud computing;Encryption;Data privacy;Privacy;Costs","","6","","45","IEEE","26 Oct 2021","","","IEEE","IEEE Journals"
"Fog Based Architecture and Load Balancing Methodology for Health Monitoring Systems","A. Asghar; A. Abbas; H. A. Khattak; S. U. Khan","Department of Computer Science, COMSATS University at Islamabad, Islamabad, Pakistan; Department of Computer Science, COMSATS University at Islamabad, Islamabad, Pakistan; Department of Computing, School of Electrical Engineering and Computer Science, National University of Sciences and Technology (NUST), Islamabad, Pakistan; Department Electrical and Computer Engineering (ECE), Mississippi State University (MSU), Starkville, MS, USA","IEEE Access","13 Jul 2021","2021","9","","96189","96200","With the increased number of data and data-generating devices in healthcare settings, the health monitoring systems have started to experience issues, such as efficient processing and latency. Several health-monitoring systems have been designed using Wireless Sensors Networks (WSN), cloud computing, fog computing, and the Internet of Things (IoT). Most of the health monitoring systems have been designed using the cloud computing architecture. However, due to the high latency introduced by the cloud-based architecture while processing massive volumes of data, large-scale deployment of latency-sensitive healthcare applications is restricted. Fog computing that places computing servers closer to the users addresses the latency problems and increases the on-demand scaling, resource accessibility, and security dramatically. In this paper, we propose a fog-based health monitoring system architecture to minimize latency and network usage. We also present a new Load Balancing Scheme (LBS) to balance the load among fog nodes when the health monitoring system is deployed on a large scale. To validate the effectiveness of the proposed approach, we conducted extensive simulations in the iFogSim toolkit and compared the results with the cloud-only implementation, Fog Node Placement Algorithm (FNPA), and LoAd Balancing (LAB) scheme, in terms of latency and network usage. The proposed implementation of the health monitoring system significantly reduces latency and network usage compared to cloud-only, FNPA, and LAB Scheme.","2169-3536","","10.1109/ACCESS.2021.3094033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9469902","Internet of Things (IoT);fog computing;health monitoring system;load balancing","Monitoring;Computer architecture;Cloud computing;Medical services;Servers;Edge computing;Load management","","40","","40","CCBY","1 Jul 2021","","","IEEE","IEEE Journals"
"From Massive IoT Toward IoE: Evolution of Energy Efficient Autonomous Wireless Networks","H. Babbar; S. Rani; O. Bouachir; M. Aloqaily","Chitkara University, India; Chitkara University, India; Zayed University, UAE; Mohamed Bin Zayed University of Artificial Intelligence, UAE","IEEE Communications Standards Magazine","12 Jun 2023","2023","7","2","32","39","The challenge of the expansion of millions of data-intensive Internet of Things (IoT) devices has led to more restriction data rates in the 5G wireless communication network. A web server can make use of network features and functions in a variety of capacities by detecting digital records of human and object behaviors from the Internet of Everything (IoE) for autonomous networks and devices. While web server appears to be a potential option when used in conjunction with next-generation wireless communications, such as 5G technology, it introduces new issues at the edge of the network. In this article, we discuss the progression in the development of wireless technologies beyond IoT (i.e., IoE for autonomous networks), while explaining the key enabling technologies beyond 5G networks. A web server-based edge architecture has been proposed for managing a large-scale of IoE devices based on 6G-enabled technology for autonomous networks and a smart resource distribution approach. The proposed system allocates receiving work-loads from IoE devices based on their flexible service requirements using the Boltzmann machines approach designed for energy-efficient communications. In addition, at the edge network, an Artificial Intelligence (AI)-driven method, namely the Support Vector Machines (SVM) retrieval model, is used to assess the data and obtain accurate results. The proposed system has been simulated and compared with some of the existing algorithms considering different use case scenarios. An overview of the emerging challenges of the proposed architecture has been discussed.","2471-2833","","10.1109/MCOMSTD.0001.2100116","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10148972","","6G mobile communication;Support vector machines;5G mobile communication;Wireless networks;Web servers;Energy efficiency;Service-oriented architecture","","3","","15","IEEE","12 Jun 2023","","","IEEE","IEEE Magazines"
"DT-PBFT: A Double-Layer Group Consensus Algorithm of Credibility for IoT Blockchain","Y. Chen; Y. Jia","State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China","2023 2nd International Conference on Big Data, Information and Computer Network (BDICN)","28 Apr 2023","2023","","","292","299","Blockchain technology is becoming more and more popular, but performance problems have always troubled it, especially the scale of distributed networks is limited. Like Practical Byzantine consensus algorithm (PBFT), the main bottlenecks are concentrated in the scope of consensus too small, and the communication is too high. In order to implement PBFT in large-scale systems such as large-scale IoT ecosystems and blockchains, this paper proposes a reputation-based two-layer improved PBFT consensus computing model DT-PBFT. In order to better combine with the large -scale Internet of Things ecosystem, we give each node regional location, communication capacity, computing power and other related attributes to each involvement, so that Client nodes can input node attributes as parameters into the reputation calculation algorithm, to select the master node of each layer in the double-layer consensus model. Determining the master node through reputation improves the credibility of the consensus algorithm. At the same time, the DTPBFT cancels the Pre-Prepare stage, reducing communication complexity. Finally, this paper transforms the existing PBFT algorithm on the Fabric platform to implement the DT-PBFT consensus algorithm and compares its performance with traditional PBFT, proving that DT-PBFT has the best balance and excellent comprehensive performance in large-scale IoT application scenarios.","","979-8-3503-2136-4","10.1109/BDICN58493.2023.00068","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10109970","IoT;blockchain;PBFT;consensus","Scalability;Computational modeling;Ecosystems;Consensus algorithm;Transforms;Stability analysis;Blockchains","","","","18","IEEE","28 Apr 2023","","","IEEE","IEEE Conferences"
"A Large-scale Access Scheme for Internet of Things Based on Distributed Queuing","Y. Yongli; D. Jiang; Z. Gongsheng","School of Telecommunication Engineering, Beijing Polytechnic, Beijing, China; School of Telecommunication Engineering, Beijing Polytechnic, Beijing, China; School of Telecommunication Engineering, Beijing Polytechnic, Beijing, China","2020 7th International Conference on Information Science and Control Engineering (ICISCE)","20 Sep 2021","2020","","","31","35","Internet of Things will be one of the most important application scenarios of the future 5G technology. However, the competition solution mechanism of the traditional cellular network cannot satisfy the large-scale access demand. Under the traditional scheme, when there are too many devices switched in the stability of the whole system will be impaired, thus causing serious congestion and making it hard to guarantee the service quality. Concerning the above problems, this paper proposes a large-scale access scheme for Internet of Things that is based on the distributed column and the tree-splitting algorithm. Simulation results suggest that, when a large number of devices have the request of access, the access scheme proposed by this paper can reasonably balance the access time delay, access success rate, and other indexes.","","978-1-7281-6406-9","10.1109/ICISCE50968.2020.00017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9532306","distributed queuing;Internet of Things;access scheme;tree-splitting algorithm Introduction","Cellular networks;Delay effects;Simulation;Switches;Reliability theory;Reliability engineering;Stability analysis","","","","8","IEEE","20 Sep 2021","","","IEEE","IEEE Conferences"
"TON_IoT Telemetry Dataset: A New Generation Dataset of IoT and IIoT for Data-Driven Intrusion Detection Systems","A. Alsaedi; N. Moustafa; Z. Tari; A. Mahmood; A. Anwar","School of Science, RMIT University, Melbourne, Australia; School of Engineering and Information Technology, University of New South Wales at ADFA, Campbell, Australia; School of Science, RMIT University, Melbourne, Australia; School of Computer Science and Information Technology, La Trobe University, Bundoora, Australia; School of Information Technology, Centre for Cyber Security Research and Innovation (CSRI), Deakin University, Geelong, Australia","IEEE Access","18 Sep 2020","2020","8","","165130","165150","Although the Internet of Things (IoT) can increase efficiency and productivity through intelligent and remote management, it also increases the risk of cyber-attacks. The potential threats to IoT applications and the need to reduce risk have recently become an interesting research topic. It is crucial that effective Intrusion Detection Systems (IDSs) tailored to IoT applications be developed. Such IDSs require an updated and representative IoT dataset for training and evaluation. However, there is a lack of benchmark IoT and IIoT datasets for assessing IDSs-enabled IoT systems. This paper addresses this issue and proposes a new data-driven IoT/IIoT dataset with the ground truth that incorporates a label feature indicating normal and attack classes, as well as a type feature indicating the sub-classes of attacks targeting IoT/IIoT applications for multi-classification problems. The proposed dataset, which is named TON_IoT, includes Telemetry data of IoT/IIoT services, as well as Operating Systems logs and Network traffic of IoT network, collected from a realistic representation of a medium-scale network at the Cyber Range and IoT Labs at the UNSW Canberra (Australia). This paper also describes the proposed dataset of the Telemetry data of IoT/IIoT services and their characteristics. TON_IoT has various advantages that are currently lacking in the state-of-the-art datasets: i) it has various normal and attack events for different IoT/IIoT services, and ii) it includes heterogeneous data sources. We evaluated the performance of several popular Machine Learning (ML) methods and a Deep Learning model in both binary and multi-class classification problems for intrusion detection purposes using the proposed Telemetry dataset.","2169-3536","","10.1109/ACCESS.2020.3022862","Research grants of the Australian Research Data Commons (ARDC) RG192500 and UNSW Canberra PS51776; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9189760","Internet of Things (IoT);Industrial Internet of Things (IIoT);cybersecurity;intrusion detection systems (IDSs);dataset","Intrusion detection;Telemetry;Sensors;Internet of Things;Machine learning;Australia","","245","","88","CCBY","9 Sep 2020","","","IEEE","IEEE Journals"
"Software Engineering Approaches for TinyML based IoT Embedded Vision: A Systematic Literature Review","S. B. Lakshman; N. U. Eisty","Boise State University, Boise, ID, USA; Boise State University, Boise, ID, USA","2022 IEEE/ACM 4th International Workshop on Software Engineering Research and Practices for the IoT (SERP4IoT)","19 Jul 2022","2022","","","33","40","Internet of Things (IoT) has catapulted human ability to control our environments through ubiquitous sensing, communication, computation, and actuation. Over the past few years, IoT has joined forces with Machine Learning (ML) to embed deep intelligence at the far edge. TinyML (Tiny Machine Learning) has enabled the deployment of ML models for embedded vision on extremely lean edge hardware, bringing the power of IoT and ML together. However, TinyML powered embedded vision applications are still in a nascent stage, and they are just starting to scale to widespread real-world IoT deployment. To harness the true potential of IoT and ML, it is necessary to provide product developers with robust, easy-to-use software engineering (SE) frameworks and best practices that are customized for the unique challenges faced in TinyML engineering. Through this systematic literature review, we aggregated the key challenges reported by TinyML developers and identified state-of-art SE approaches in large-scale Computer Vision, Machine Learning, and Embedded Systems that can help address key challenges in TinyML based IoT embedded vision. In summary, our study draws synergies between SE expertise that embedded systems developers and ML developers have independently developed to help address the unique challenges in the engineering of TinyML based IoT embedded vision.","","978-1-4503-9332-4","10.1145/3528227.3528569","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9826176","Software Engineering;IoT;TinyML;Embedded Vision;Systematic Literature Review","Systematics;Embedded systems;Bibliographies;Machine learning;Feature extraction;Hardware;Software","","3","","33","","19 Jul 2022","","","IEEE","IEEE Conferences"
"On the Design of a Flexible Delegation Model for the Internet of Things Using Blockchain","S. Pal; T. Rabehaja; M. Hitchens; V. Varadharajan; A. Hill","Department of Computing, Macquarie University, Sydney, Australia; Macquarie University Cyber Security Hub, Sydney, Australia; Department of Computing, Macquarie University, Sydney, Australia; Advanced Cyber Security Engineering Research Centre (ACSRC), University of Newcastle, Newcastle, Australia; School of Computer Science and Engineering, The University of New South Wales (UNSW), Sydney, Australia","IEEE Transactions on Industrial Informatics","14 Feb 2020","2020","16","5","3521","3530","The Internet of things (IoT) presents new opportunities and challenges due to its scale and dynamic nature. One significant challenge for the IoT is the need for security, in particular access control solutions, that are designed to meet the characteristics of these systems. Delegation of rights, from one entity to another, is a crucial component of an access control system. The IoT requires a secure, flexible, and fine-grained delegation model. While there has been considerable work in the area of delegation, much of it assumes a centralized, well-resourced system and these solutions have limited capacity in the context of the IoT. Where delegation models for the IoT have been proposed they typically provide only coarse-grained control over the delegation of rights. Moreover, many of them require a centralized trusted authority, which can suffer from a single-point failure and is not an ideal base for a large and dynamic system like the IoT. In this paper, we propose an identity-less, asynchronous, and decentralized delegation model for the IoT based on blockchain technology. We describe system components, architecture, and key aspects related to the security of the system. We use attributes to validate an entity rather than depending upon unique identities. We demonstrate the feasibility of our model through use-case examples and analyze the performance with a proof of concept testbed implementation using Ethereum private blockchain.","1941-0050","","10.1109/TII.2019.2925898","International Macquarie University Research Excellence Scholarship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8752021","Access control;blockchain;delegation","Blockchain;Access control;Permission;Internet of Things;Australia;Dynamical systems","","33","","28","IEEE","1 Jul 2019","","","IEEE","IEEE Journals"
"Decentralized Access Control for IoT Based on Blockchain and Smart Contract","R. Xu; Y. Chen; E. Blasch","Department of Electrical and Computer Engineering, Binghamton University, SUNY, Binghamton, NY, USA; Department of Electrical and Computer Engineering, Binghamton University, SUNY, Binghamton, NY, USA; US Air Force Research Laboratory, Rome, NY, USA","Modeling and Design of Secure Internet of Things","","2020","","","505","528","The Internet of Things (IoT) technology has been widely recognized as an essential part of Smart Cities. However, the highly connected smart IoT devices with heterogeneous platforms also bring new challenges in terms of privacy and security. Access control (AC) is among the top security concerns, which is critical in resource sharing and information protection over IoT devices. Traditional AC approaches, like Access Control Lists (ACL), Role‐based Access Control (RBAC), and Attribute‐based Access Control (ABAC), are not able to provide a scalable, manageable, and efficient mechanism to meet the requirements of IoT systems. Another weakness in today's AC is the centralized authorization server, which can cause a performance bottleneck or be the single point of failure. Thanks to cryptographic and consensus mechanisms, the recently raised smart contract technology on top of a blockchain protocol provides a promising solution to implement more flexible and fine‐grained AC models. Given research of arts on security mechanisms for IoT system, this chapter discusses key issues of AC in IoT systems, which cover both AC models and architecture. As a case study, a BLockchain‐ENabled, Decentralized, Federated, Capability‐based Access Control (BlendCAC) scheme is introduced to enable effective protection for devices, services, and information in large‐scale IoT systems. The mechanism for delegate authorization and revocation is explored. A robust identity‐based capability token management strategy takes advantage of the smart contract for registration, propagation, and revocation of the access authorization. A proof‐of‐concept prototype has been implemented on both resources‐constrained devices (i.e. Raspberry PI nodes) and more powerful computing devices (i.e. laptops) and tested on a local private blockchain network. The experimental results demonstrate the feasibility of the BlendCAC to offer a decentralized, scalable, lightweight, and fine‐grained AC solution for IoT systems.","","9781119593379","10.1002/9781119593386.ch22","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9124024.pdf&bkn=9123990&pdfType=chapter","","Internet of Things;Blockchain;Smart contracts;Authorization;Computational modeling","","1","","","","24 Jun 2020","","","IEEE","Wiley-IEEE Press eBook Chapters"
"Machine Learning Systems in the IoT: Trustworthiness Trade-offs for Edge Intelligence","W. Toussaint; A. Y. Ding","Engineering Systems and Services, Delft University of Technology, Delft, Netherlands; Engineering Systems and Services, Delft University of Technology, Delft, Netherlands","2020 IEEE Second International Conference on Cognitive Machine Intelligence (CogMI)","20 Jan 2021","2020","","","177","184","Machine learning systems (MLSys) are emerging in the Internet of Things (IoT) to provision edge intelligence, which is paving our way towards the vision of ubiquitous intelligence. However, despite the maturity of machine learning systems and the IoT, we are facing severe challenges when integrating MLSys and IoT in practical context. For instance, many machine learning systems have been developed for large-scale production (e.g., cloud environments), but IoT introduces additional demands due to heterogeneous and resource-constrained devices and decentralized operation environment. To shed light on this convergence of MLSys and IoT, this paper analyzes the tradeoffs by covering the latest developments (up to 2020) on scaling and distributing ML across cloud, edge, and IoT devices. We position machine learning systems as a component of the IoT, and edge intelligence as a socio-technical system. On the challenges of designing trustworthy edge intelligence, we advocate a holistic design approach that takes multi-stakeholder concerns, design requirements and trade-offs into consideration, and highlight the future research opportunities in edge intelligence.","","978-1-7281-4144-2","10.1109/CogMI50398.2020.00030","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9319287","edge intelligence;machine learning systems;Internet of Things;trade-offs;trustworthiness;smart services","Machine learning;Data models;Training;Predictive models;Internet of Things;Adaptation models;Computational modeling","","5","","42","IEEE","20 Jan 2021","","","IEEE","IEEE Conferences"
"Big Data Analytics for 6G-Enabled Massive Internet of Things","Z. Lv; R. Lou; J. Li; A. K. Singh; H. Song","School of Data Science and Software Engineering, Qingdao University, Qingdao, China; School of Data Science and Software Engineering, Qingdao University, Qingdao, China; School of Data Science and Software Engineering, Qingdao University, Qingdao, China; Computer Science and Engineering Department, National Institute of Technology Patna, Patna, India; Department of Electrical, Computer, Software, and Systems Engineering, Embry–Riddle Aeronautical University, Daytona Beach, FL, USA","IEEE Internet of Things Journal","24 Mar 2021","2021","8","7","5350","5359","The purposes are to enable large-scale Internet of Things (IoT) devices to analyze data more effectively and provide high-efficiency, low-energy, and wide-coverage technical services for terminals. The channel model and energy loss model analyze the devices' access performance, data transmission path delay, energy consumption in the IoT, and large-scale devices' access in the cellular narrowband IoT (NB-IoT) based on big data analysis technology are also discussed. The results show that in the access success rate analysis, the access success rate is the highest with an access time ( T) of 5 s and a preamble resource number ( K) of 25. The restriction factor is inversely proportional to the access success rate. In the node utilization analysis, different transmission node priorities result in different node utilization, and priority 2's node utilization is better than that of priority 1. Moreover, local data makes data analysis and transmission faster. The search time is prolonged, and the corresponding energy consumption is also higher without local data. In the energy consumption analysis, with the 6-generation (6G) technology, different interference thresholds lead to the different energy efficiency of data transmission. The larger the interference threshold, the higher the energy efficiency. Therefore, the 6G-based big data analysis technology can significantly improve large-scale IoT devices' access success rate and enable the system to meet the requirements of low energy consumption and high access success rate, significant for research on more devices' access data analysis.","2327-4662","","10.1109/JIOT.2021.3056128","National Natural Science Foundation of China(grant numbers:61902203); Key Research and Development Plan—Major Scientific and Technological Innovation Projects of Shandong Province(grant numbers:2019JZZY020101); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9347464","6-generation (6G);data analysis;energy consumption;Internet of Things (IoT)","Internet of Things;Data communication;6G mobile communication;Industries;Energy consumption;Big Data;Bandwidth","","124","","26","IEEE","4 Feb 2021","","","IEEE","IEEE Journals"
"Chord-based distributed middleware architecture for Internet of Things","G. Fersi; A. Ben Hammouda; F. Derbel","Research Laboratory of Development and Control of Distributed Applications (ReDCAD) National School of Engineers of Sfax BP 1173-3038, University of Sfax, Tunisia; Research Laboratory of Development and Control of Distributed Applications (ReDCAD) National School of Engineers of Sfax BP 1173-3038, University of Sfax, Tunisia; Smart Diagnostic and Online Monitoring, Leipzig University of Applied Sciences, Leipzig, Germany","2023 International Wireless Communications and Mobile Computing (IWCMC)","21 Jul 2023","2023","","","812","817","The outstanding progress in the smart devices as well as the noticeable reduction in their cost has led to the invasion of the Internet of Things (IoT) in our real lives. The multiplicity of the IoT applications and the diversity and heterogeneity of the IoT devices present a real challenge in the IoT development. There is hence a need to have an intermediate layer between the physical layer including the smart devices and the application layer to facilitate the integration and the usage of the IoT devices in the IoT applications. This layer is the middleware layer. Most of the existing middleware are suitable for small-scale IoT networks including limited number of smart things. The performance of these middleware is reduced when the number of IoT devices increases. The main reason of the performance deterioration is the unsuitable middleware architecture that is unable to bear the increasing number of IoT devices. We present in this paper a distributed middleware architecture based on Chord protocol. Our architecture transforms any centralized middleware to a distributed one which improves its performance and makes it scalable. The performance evaluation have shown that our proposed approach has the ability to cope successfully with the increasing number of IoT devices and requests.","2376-6506","979-8-3503-3339-8","10.1109/IWCMC58020.2023.10182923","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10182923","Middleware;IoT;Distributed Hash Tables;Chord","Performance evaluation;Costs;Protocols;Scalability;Computer architecture;Transforms;Internet of Things","","","","12","IEEE","21 Jul 2023","","","IEEE","IEEE Conferences"
"A Self-Adaptive Bluetooth Indoor Localization System using LSTM-based Distance Estimator","Z. Li; J. Cao; X. Liu; J. Zhang; H. Hu; D. Yao","Department of Computing, The Hong Kong Polytechnic University, Hong Kong; Department of Computing, The Hong Kong Polytechnic University, Hong Kong; Department of Computing, The Hong Kong Polytechnic University, Hong Kong; Department of Computing, The Hong Kong Polytechnic University, Hong Kong; Alibaba Cainiao Network, Hangzhou, China; Alibaba Group, Hangzhou, China","2020 29th International Conference on Computer Communications and Networks (ICCCN)","30 Sep 2020","2020","","","1","9","In recent years, there is an increasing demand for indoor localization services with the aim to locate people and objects inside buildings. However, localization accuracy is susceptible to inaccurate and high variant sensor measurements due to the unpredictable fluctuations of received wireless signals and the sensitivity of hardware devices. To address this issue, in this paper, we establish a new Bluetooth indoor localization system, whose architecture can be basically decomposed into two parts: the internet-of-things (IoT) framework and the localization module. Concretely, the IoT platform uses the state-of-the-art light weight Spring Boot microservice framework consisting of multi-layer structure. In the localization module, it follows the general process of trilateration but significantly distinguished from it. A set of measures are adopted to strengthen the system's robustness when obtained measurements cannot be fully trusted. Specifically, in the first place, rather than using conventional propagation model to predict the distance between Bluetooth transmitter and receiver, we design a bran-new LSTM-based distance estimator which can better depict the nonlinearity of attenuation characteristics of radio signal. Moreover, we also employ a series of self-adaptive mechanisms, including elastic radius intersecting, multiple weighted centroid localization and self-adaptive Kalman tracking, to make the system robust against inaccurate measurements and unpredictable sudden variation of received wireless signal. A bunch of tests are conducted in both ideal lab environment and Alibaba's large-scale warehouse, and experimental results show our indoor localization system outperforms the state-of-the-art benchmarks by a large margin in both localization accuracy and stability.","2637-9430","978-1-7281-6607-0","10.1109/ICCCN49398.2020.9209674","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9209674","Bluetooth indoor localization;LSTM-based distance estimator;Self-adaptive Kalman tracking","Bluetooth;Wireless communication;Wireless sensor networks;Logic gates;Hardware;Position measurement;Business","","4","","33","IEEE","30 Sep 2020","","","IEEE","IEEE Conferences"
"Mean-Field Artificial Noise Assistance and Uplink Power Control in Covert IoT Systems","S. Feng; X. Lu; S. Sun; D. Niyato","Institute for Infocomm Research, Singapore; York University, Toronto, ON, Canada; Institute for Infocomm Research, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore","IEEE Transactions on Wireless Communications","9 Sep 2022","2022","21","9","7358","7373","In this paper, we study a covert Internet of Things (IoT) system. Compared with conventional IoT systems that apply cryptography and information-theoretic secrecy approaches to secure the transmission, our considered IoT system adopts the covertness technique and intends to hide the legitimate transmission from the observant adversaries. In the IoT system, the IoT devices randomly transmit the collected data to their associated IoT gateways (GWs). In the meantime, the adversaries attempt to detect the existence of legitimate transmission based on their received signal power and launch hostile attacks accordingly. To avoid being detected by the adversaries, the IoT system applies uplink power control to achieve covert legitimate transmission. Moreover, to distort the observation of the adversaries so as to mislead their decisions, we propose an artificial noise (AN)-assisted covert communication design, where the AN is transmitted by in-band full-duplex (IBFD) IoT GWs as a jamming operation. We formulate a Stackelberg game to study the interaction between the adversaries and the legitimate entities including the IoT GWs and IoT devices, where the legitimate entities, as the leaders, decide on the powers of legitimate and AN transmissions at the upper level and the adversaries, as the followers, aim to minimize their detection errors at the lower level. Thereafter, considering the large scale of IoT system, we further cast the Stackelberg game into a mean-field Stackelberg game and incorporate the stochastic geometry and statistical channel model to capture the location heterogeneity and channel dynamics among and of the system entities, respectively. In the performance evaluation, we verify the practicability of the mean-field Stackelberg game. Moreover, we demonstrate the effectiveness of AN in improving the transmission covertness.","1558-2248","","10.1109/TWC.2022.3157885","A*STAR 5G-AMSUS WP1 Project, under RIE2020 Advanced Manufacturing and Engineering (AME) Industry Alignment Fund-Pre-Positioning (IAF-PP)(grant numbers:A20F8a0044); Programme DesCartes and the National Research Foundation, Prime Minister’s Office, Singapore, under its Campus for Research Excellence and Technological Enterprise (CREATE) programme; Alibaba Group through Alibaba Innovative Research (AIR) Program and Alibaba-NTU Singapore Joint Research Institute (JRI); National Research Foundation, Singapore, under the AI Singapore Programme (AISG)(grant numbers:AISG2-RP-2020-019); Singapore Ministry of Education (MOE) Tier 1(grant numbers:RG16/20); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9736993","Covert communication;IoT system;artificial noise;Stackelberg game;mean-field approach","Security;Games;Stochastic processes;Performance evaluation;Wireless communication;Transmitters;Jamming","","10","","42","IEEE","16 Mar 2022","","","IEEE","IEEE Journals"
"Self-Adapting Model-Based SDSec For IoT Networks Using Machine Learning","H. Narayanankutty","Dept. Of Computer Science, Gran Sasso Science Institute, L’Aquila, Italy","2021 IEEE 18th International Conference on Software Architecture Companion (ICSA-C)","10 May 2021","2021","","","92","93","IoT networks today face a myriad of security vulnerabilities in their infrastructure due to its wide attack surface. Large-scale networks are increasingly adopting a Software-Defined Networking approach, it allows for simplified network control and management through network virtualization. Since traditional security mechanisms are incapable of handling virtualized environments, SDSec or Software-Defined Security is introduced as a solution to support virtualized infrastructure, specifically aimed at providing security solutions to SDN frameworks. To further aid large scale design and development of SDN frameworks, Model-Driven Engineering (MDE) has been proposed to be used at the design phase, since abstraction, automation and analysis are inherently key aspects of MDE. This provides an efficient approach to reducing large problems through models that abstract away the complex technicality of the total system. Making adaptations to these models to address security issues faced in IoT networks, largely reduces cost and improves efficiency. These models can be simulated, analysed and supports architecture model adaptation; model changes are then reflected back to the real system. We propose a model-driven security approach for SDSec networks that can self-adapt using machine learning to mitigate security threats. The overall design time changes can be monitored at run time through machine learning techniques (e.g. deep, reinforcement learning) for real time analysis. This approach can be tested in IoT simulation environments, for instance using the CAPS IoT modeling and simulation framework. Using self-adaptation of models and advanced machine learning for data analysis would ensure that the SDSec architecture adapts and improves over time. This largely reduces the overall attack surface to achieve improved end-to-end security in IoT environments.","","978-1-6654-3910-7","10.1109/ICSA-C52384.2021.00023","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9425853","Model-Driven Engineering;SDN;SDSec;IoT;Self-Adaptation;Machine Learning;Security","Adaptation models;Analytical models;Software architecture;Computer architecture;Reinforcement learning;Real-time systems;Model driven engineering","","","","17","IEEE","10 May 2021","","","IEEE","IEEE Conferences"
"A CoAP-based Communication Mapping Method for Power Distribution Internet of Things","L. Yinliang; L. Jinyong; Y. Zhiyong; X. Qiyuan; X. Quan; Y. Lei","Electric Power Research Institute of CSG, China Southern Grid, Guangzhou, China; Electric Power Research Institute of CSG, China Southern Grid, Guangzhou, China; Electric Power Research Institute of CSG, China Southern Grid, Guangzhou, China; Shenzhen Power Supply Bureau, China Southern Grid, Shenzhen, China; Electric Power Research Institute of CSG, China Southern Grid, Guangzhou, China; Electric Power Research Institute of CSG, China Southern Grid, Guangzhou, China","2022 China International Conference on Electricity Distribution (CICED)","2 Nov 2022","2022","","","243","248","1 This paper studies a constrained application protocol (CoAP) mapping method based on EEC61850 for achieving the abstract communication service interface (ACSI) to solve the problems of weak monitoring, poor equipment interconnection, and difficult maintenance in the low-voltage power distribution Internet of Things (IoT). It can realize the interconnection, interoperability and access of large-scale sensing terminal equipment. The requirements of power consumption, transmission rate, device performance and deployment cost of terminal devices in consideration of the resource-constrained operation scenarios of distribution IoT devices are analyzed to determine the subset of ACSI services. In addition, the communication service method adopted when the system is designed is directly mapped, which not only accelerates the speed of information transmission, but also greatly simplifies the conversion time between IEC61850 and data. In this paper, based on the operation process of CoAP distributed Internet technology, a new data resource access form is developed, which can not only quickly convert SCL files into URIs, but also access the flies. Further, considering the coding efficiency and cost of the existing coding methods in IEC61850 and the Internet of Things, the operation mode of the ASN.1BER data runtime is made, so as to construct a separate CoAP data mapping method. Finally, we also conducted detailed tests to verify the characteristic of CoAP mapping with help of data test platform, proving the feasibility of this method from multiple perspectives.","2161-749X","978-1-6654-5268-7","10.1109/CICED56215.2022.9928955","China Southern Power Grid; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9928955","ACSI;service mapping;power distribution;Internet of Things;CoAP","Costs;Runtime;Systems operation;Power distribution;Maintenance engineering;Encoding;Sensors","","","","17","IEEE","2 Nov 2022","","","IEEE","IEEE Conferences"
"Design and Deployment of Geoportal Systems to Provide Support for Management Decision-Making in Natural-Social-Production Systems","S. A. Yamashkin; A. A. Yamashkin","National Research, Mordovia State University, Saransk, Russia; National Research, Mordovia State University, Saransk, Russia","2023 16th International Conference Management of large-scale system development (MLSD)","3 Nov 2023","2023","","","1","5","The article describes of the solution to the problem of managing large-scale natural-social-production systems using geoportal technologies. A model for using a system for remote monitoring and control of spatially distributed objects based on the concept of the Internet of Things is proposed. The core of the system is geoportals, which function as a tool for dispatching and monitoring spatial objects. The authors describe a system for remote monitoring and control of spatially distributed objects based on the concept of the Internet of Things using LoRa network technology. The core of the presented system is geoportals that function as a tool for dispatching and monitoring spatial objects with the function of visualizing them on a digital map. The project operates based on web technologies, realizing the possibility of monitoring the transmitted state of objects and remote control (in particular, the function of controlling the microclimate, closing/opening doors, and automated irrigation).","","979-8-3503-3790-7","10.1109/MLSD58227.2023.10304050","Russian Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10304050","geoportal;natural-social-production systems;metageosystems;management;spatial data;Internet of Things","Irrigation;Decision making;Process control;Distributed databases;Spatial databases;Dispatching;Large-scale systems;Internet of Things;Remote monitoring;Remote control","","","","12","IEEE","3 Nov 2023","","","IEEE","IEEE Conferences"
"Indoor Intelligent IoT Datasets for Behavioral Learning and Autonomous Decision Making","H. Ye; H. Luo","College of Computer and Data Science, Fuzhou University, Fuzhou, China; College of Computer Science and Technology, Minjiang University, Fuzhou, China","2022 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)","23 Mar 2023","2022","","","862","869","The current indoor Internet of Things (IoT) system is mainly realized by presetting rules, voice interaction, or remote control, which fails to meet the need for systematic, global, and autonomous intelligence. The cost of high-quality large-scale data annotation is also too high, which hinders the effective application of supervised learning paradigm in such scenarios. Therefore, unsupervised or reinforcement learning is worthy of consideration for the future IoT system. In view of the large-scale organization and deployment, high dynamic coordination, and precise service requirement of the future IoT system, this study constructs a perceptual data acquisition platform to obtain the indoor intelligent IoT datasets suitable for unsupervised or reinforcement learning. First, various environment-aware and controllable electrical devices are deployed in a multi-person office area that is divided into multiple zones. The devices are connected to the edge gateway through long range radio (LoRa) wireless network, and an message queuing telemetry transport (MQTT) cloud server is constructed to realize the design of cloud edge collaborative architecture. Then, two kinds of information, namely, environment and controlled action, are collected in real time without human perception, which forms and publicizes complete datasets, including time, space, environmental parameters, and control actions. On the basis of the datasets, relevant data analysis is conducted and preliminary experimental results using unsupervised learning method are presented.","","978-1-6654-6497-0","10.1109/ISPA-BDCloud-SocialCom-SustainCom57177.2022.00115","Science Foundation of Fujian Province(grant numbers:2021J011015); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10070718","Indoor pe rception;Behavioral learning;Autonomous decision making;Datasets;Intelligent IoT","Cloud computing;Decision making;Data acquisition;Systems architecture;Reinforcement learning;Organizations;Real-time systems","","","","22","IEEE","23 Mar 2023","","","IEEE","IEEE Conferences"
"Smart and Sustainable Home Aquaponics System with Feature-Rich Internet of Things Mobile Application","R. Mahkeswaran; A. K. Ng","University of Glasgow Singapore, Singapore; Singapore Institute of Technology, Singapore","2020 6th International Conference on Control, Automation and Robotics (ICCAR)","4 Jun 2020","2020","","","607","611","Food security has been a recurring issue for many countries in the world including Singapore. This issue is exacerbated by growing world population and climate change, which inevitably leads to an increased demand for food. In recent years, large scale aquaponics has shown efficient production of edible fish and plants. This paper further exploits the design and development of an aquaponics system for home environment, with the notion that if every household within a country can generate its own fish and plants, the overall food demand of the country will be reduced. The proposed smart and sustainable home aquaponics system consists of various sensors, actuators, and microcontroller with internet connectivity to continuously monitor, control, and record fish tank water and ambient air quality. Healthy growth of fish and plants are ensured by sending an early warning to the user in the event of any abnormal system condition via a push notification in a feature-rich internet of things (IoT) mobile application. Furthermore, appropriate actuators are automatically operated to rectify abnormalities in a timely manner. Plant grow lights and fish feeder are also automatically controlled to optimize fish and plant growth. All sensor readings and actuator statuses are intuitively displayed to the user in real time through the IoT mobile application and securely sent to an online spreadsheet for storage and further analysis. Measurement results successfully demonstrate the efficacy of the proposed home aquaponics system to grow healthy fish and plants, with minimal operational costs and human intervention.","2251-2446","978-1-7281-6139-6","10.1109/ICCAR49639.2020.9108041","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9108041","aquaponics;automation and control;food security;internet of things;mobile application","Climate change;Security;Internet of Things;Automation;Sustainable development;Aquaculture","","11","","15","IEEE","4 Jun 2020","","","IEEE","IEEE Conferences"
"A Hybrid Blockchain-Based Authentication Scheme for Smart Home","X. Yang; B. Li; Y. Zhang; J. Wu; P. Yuan","School of Cyber Science and Engineering, Southeast University; School of Cyber Science and Engineering, Southeast University; School of Cyber Science and Engineering, Southeast University; School of Microelectronics, Southeast University; School of Microelectronics, Southeast University","2020 IEEE 5th International Conference on Signal and Image Processing (ICSIP)","4 Feb 2021","2020","","","893","897","With the development of the Internet of Things technology, the use of smart devices is ubiquitous, thereby making the smart home become an innovative IoT application to change our lives. However, the application of smart home should serve thousands of families and the number of edge servers and terminal devices s huge. Thus, it is difficult for a single central server or cluster to manage such large-scale devices with high efficiency. In addition, the structure of IoT is flexible and the edge or terminal devices can join a certain IoT system without strict restriction. The system may suffer from unauthorized access from malicious devices. In this paper, a physically secure authentication scheme for smart home based on a hybrid blockchain is proposed. A novel structure of the blockchain is leveraged to relieve the stress of the central server and storage device’s information permanently. Physical unclonable functions are used to provide identities for authorized devices. The security and evaluation analysis shows that our scheme has reliable security features and is the potential to improve the efficiency of the smart home system.","","978-1-7281-6896-8","10.1109/ICSIP49896.2020.9339278","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9339278","Blockchain;smart home;internet of things;security certification;physical unclonable functions","Authentication;Smart homes;Blockchain;Internet of Things;Servers;Security;Smart devices","","3","","16","IEEE","4 Feb 2021","","","IEEE","IEEE Conferences"
"IoT-Enabled Community Care for Ageing-in-Place: The Singapore Experience","H. -P. Tan","Information Systems (Practice), Singapore Management University","2020 7th International Conference on Electrical Engineering, Computer Sciences and Informatics (EECSI)","12 Nov 2020","2020","","","1","2","Summary form only given, as follows. The complete presentation was not made available for publication as part of the conference proceedings. The paradigm of ageing-in-place - where the elderly live and age in their own homes, independently and safely, with care provided by the community - is compelling, especially in societies that face both shortages in institutionalized eldercare resources, and rapidly ageing populations. When the number of elderly who live alone rises rapidly, support and care from their communities become increasing crucial. Internet of Things (IoT) technologies. They can become the fundamental enabler for smart community eldercare. In this presentation, I would like to share our experiences and learnings gathered from large-scale deployments of IoT systems in in-home and community spaces that elderly living alone interact with, focusing on the key insights as well as operational and usability aspects of such systems.","","978-602-0737-62-1","10.23919/EECSI50503.2020.9251307","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9251307","","Electrical engineering;Smart cities;Sociology;Focusing;Internet of Things;Older adults;Usability","","1","","0","","12 Nov 2020","","","IEEE","IEEE Conferences"
"PoBT: A Lightweight Consensus Algorithm for Scalable IoT Business Blockchain","S. Biswas; K. Sharif; F. Li; S. Maharjan; S. P. Mohanty; Y. Wang","School of Computer Science and the Beijing Engineering Research Center of High Volume Language Information Processing and Cloud Computing Applications, Beijing Institute of Technology, Beijing, China; School of Computer Science and the Beijing Engineering Research Center of High Volume Language Information Processing and Cloud Computing Applications, Beijing Institute of Technology, Beijing, China; School of Computer Science and the Beijing Engineering Research Center of High Volume Language Information Processing and Cloud Computing Applications, Beijing Institute of Technology, Beijing, China; Center for Resilient Networks and Applications, Simula Metropolitan Center for Digital Engineering, Oslo, Norway; Department of Computer Science and Engineering, University of North Texas, Denton, USA; Department of Computer and Information Sciences, Temple University, Philadelphia, USA","IEEE Internet of Things Journal","12 Mar 2020","2020","7","3","2343","2355","Efficient and smart business processes are heavily dependent on the Internet of Things (IoT) networks, where end-to-end optimization is critical to the success of the whole ecosystem. These systems, including industrial, healthcare, and others, are large scale complex networks of heterogeneous devices. This introduces many security and access control challenges. Blockchain has emerged as an effective solution for addressing several such challenges. However, the basic algorithms used in the business blockchain are not feasible for large scale IoT systems. To make them scalable for IoT, the complex consensus-based security has to be downgraded. In this article, we propose a novel lightweight proof of block and trade (PoBT) consensus algorithm for IoT blockchain and its integration framework. This solution allows the validation of trades as well as blocks with reduced computation time. Also, we present a ledger distribution mechanism to decrease the memory requirements of IoT nodes. The analysis and evaluation of security aspects, computation time, memory, and bandwidth requirements show significant improvement in the performance of the overall system.","2327-4662","","10.1109/JIOT.2019.2958077","National Natural Science Foundation of China(grant numbers:61772077,61432015); Natural Science Foundation of Beijing Municipality(grant numbers:4192051); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8926457","Blockchain;consensus;distributed ledger technology;Internet of Things (IoT);interoperability;ledger size;scalability;transaction rate","Business;Peer-to-peer computing;Internet of Things;Cryptography;Fabrics","","127","","37","IEEE","6 Dec 2019","","","IEEE","IEEE Journals"
"Modeling and Simulation of IoT Botnet Behaviors Using DEVS","G. Barakat; B. Al-Duwairi; M. Jarrah; M. Jaradat","Department of Computer Engineering, Jordan University of Science and Technology; Department of Network Engineering & Security, Jordan University of Science and Technology; Department of Computer Engineering, Jordan University of Science and Technology; Department of Computer Engineering, The Hashemite University, Zarqa, Jordan","2022 13th International Conference on Information and Communication Systems (ICICS)","4 Jul 2022","2022","","","42","47","The ubiquitous nature of the Internet of Things (IoT) devices and their wide-scale deployment have remarkably attracted hackers to exploit weakly-configured and vulnerable devices, allowing them to form large IoT botnets and launch unprecedented attacks. Modeling the behavior of IoT botnets leads to a better understanding of their spreading mechanisms and the state of the network at different levels of the attack. In this paper, we propose a generic model to capture the behavior of IoT botnets. The proposed model uses Markov Chains to study the botnet behavior. Discrete Event System Specifications environment is used to simulate the proposed model.","2573-3346","978-1-6654-8097-0","10.1109/ICICS55353.2022.9811164","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9811164","IoT Botnets;Discrete Event System Specification;Security;Markov Chains","Botnet;Simulation;Predictive models;Markov processes;Malware;Data models;Behavioral sciences","","2","","26","IEEE","4 Jul 2022","","","IEEE","IEEE Conferences"
"A Theoretical Model for Large-scale Wireless Self-organizing Networks","K. Deng; W. Liao; H. Ding",Science and Technology on Electronic Information Control Laboratory; Science and Technology on Electronic Information Control Laboratory; Science and Technology on Electronic Information Control Laboratory,"2020 IEEE 4th Information Technology, Networking, Electronic and Automation Control Conference (ITNEC)","4 May 2020","2020","1","","1668","1671","The existing large-scale wireless networks are facing the problem that the transmission efficiency is reduced due to the congestion of routing information caused by the increase in the number of nodes. This paper presents a theoretical model of a large-scale wireless self-organizing network architecture. The model adopts hierarchical architecture, coexistence of multiple subnets and supports decentralized wireless self-organizing networks, which effectively reduces bandwidth loss caused by increasing routing information, thus improving data transmission efficiency, solving the problem of large-scale and multi-node wireless data transmission, and providing a solution for field operations and urban internet of Things applications.","","978-1-7281-4390-3","10.1109/ITNEC48623.2020.9085153","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9085153","large-scale;wireless;self-organizing;network","Wireless communication;Satellites;Spread spectrum communication;Self-organizing networks;Routing;Propagation losses;Data communication","","","","7","IEEE","4 May 2020","","","IEEE","IEEE Conferences"
"Research on Intelligent rabbit culture system based on Internet of things","Y. Liu; S. Wu; F. Liu; H. Zhao; Z. Meng","Qingdao Kangda Rabbit Industry Development Co., Ltd, Qingdao, China; EDP Qingdao Kangda Rabbit Industry Development Co., Ltd, Qingdao, China; Qingdao Kangda Rabbit Industry Development Co., Ltd, Qingdao, China; Qingdao Kangda Rabbit Industry Development Co., Ltd, Qingdao, China; Qingdao Kangda Rabbit Industry Development Co., Ltd, Qingdao, China","2021 International Conference on Information Science, Parallel and Distributed Systems (ISPDS)","10 Jan 2022","2021","","","155","158","In view of the problems in the development of livestock and poultry breeding industry in China, such as tight constraints on production resources, rising costs, livestock and poultry epidemic, product quality and safety, environmental pollution, this study proposed a smart meat rabbit breeding system based on Internet of things technology for medium and large-scale meat rabbit farms and small-scale breeding investors. Through the monitoring of breeding environmental factors and the control of equipment, we can achieve fine feeding, disease early warning and scientific breeding, improve production efficiency and reduce breeding risk.","","978-1-6654-1738-9","10.1109/ISPDS54097.2021.00037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9668802","rabbit;culture;system","Rabbits;Pollution;Production;Mobile communication;Agriculture;Product design;Safety","","","","4","IEEE","10 Jan 2022","","","IEEE","IEEE Conferences"
"A Time-Series Process Event Log Preprocessing Approach for Data-Intensive and Predictive Operationalization of Smart Factories","M. Park; S. Park; T. -H. Nguyen; D. -L. Pham; D. Oh; K. -S. Kim; I. -K. Chun; K. P. Kim","Div. of Computer Information, DAELIM UNIVERSITY COLLEGE, Anyang Gyeonggi, Republic of Korea; Div. of AI Computer Science & Engineering, KYONGGI UNIVERSITY, Suwon Gyeonggi, Republic of Korea; Div. of AI Computer Science & Engineering, KYONGGI UNIVERSITY, Suwon Gyeonggi, Republic of Korea; Contents Convergence Software Research Institute, KYONGGI UNIVERSITY, Suwon Gyeonggi, Republic of Korea; Smart Factory Research Institute, IC&IT Co., Guro Seoul, Republic of Korea; Smart Factory Research Institute, IC&IT Co., Guro Seoul, Republic of Korea; Smart Factory Research Institute, IC&IT Co., Guro Seoul, Republic of Korea; Div. of AI Computer Science & Engineering, KYONGGI UNIVERSITY, Suwon Gyeonggi, Republic of Korea","2022 24th International Conference on Advanced Communication Technology (ICACT)","11 Mar 2022","2022","","","252","255","This paper proposes a time-series process event log preprocessing approach applied to realize data-intensive and predictive operationalization of IoT-supported smart factories. The advanced conceptual approach of the data-intensive and predictive operationalization processes is newly proposed for effectively and predictively operating very large-scale smart factories that are supported by the Internet of Things platforms with temporal operationalization processes and their time-series event log datasets. The authors’ research group is trying to develop a predictive smart factory operationalization system, which is characterized by the advanced conceptual approach, and the starting point of which is at acquiring the time-series process event log datasets with a proper data preprocessing approach. Hence, this paper devises a time-series process event log preprocessing approach with its algorithmic details to arrange the proper datasets to be used for concretizing the data-intensive and predictive operationalization in the very large-scale smart factories. Finally, we develop an XES-formatted event log preprocessing system based upon the devised preprocessing algorithms and apply to a real and nation-wide production smart factory in order to validate the operationality and feasibility of the developed system.","1738-9445","979-11-88428-08-3","10.23919/ICACT53585.2022.9728959","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9728959","Smart Factory;Internet of Things;Data-Intensive Smart Factory;Operationalization Process Automation;Digital Twin Platform;IoT-Sensed Dataset;Time-Series Dataset","Digital twin;Data preprocessing;Production;Prediction algorithms;Communications technology;Internet of Things;Smart manufacturing","","3","","7","","11 Mar 2022","","","IEEE","IEEE Conferences"
"A Spatiotemporal Framework for Information Freshness in IoT Uplink Networks","M. Emara; H. ElSawy; G. Bauch","Next Generation and Standards, Intel Deutschland GmbH, Neubiberg, Germany; Electrical Engineering Department, King Fahd University of Petroleum and Minerals, Dhahran, Saudi Arabia; Institute of Communications, Hamburg University of Technology, Hamburg, Germany","2020 IEEE 92nd Vehicular Technology Conference (VTC2020-Fall)","15 Feb 2021","2020","","","1","6","Timely message delivery is a key enabler for Internet of Things (IoT) and cyber-physical systems to support wide range of context-dependent applications. Conventional time-related metrics, such as delay, fails to characterize the timeliness of the system update or to capture the freshness of information from application perspective. Age of information (AoI) is a time-evolving measure of information freshness that has received considerable attention during the past years. In the foreseen large-scale and dense IoT networks, joint temporal (i.e., queue aware) and spatial (i.e., mutual interference aware) characterization of the AoI is required. In this work we provide a spatiotemporal framework that captures the peak AoI for large scale IoT uplink network. To this end, the paper quantifies the peak AoI for large-scale cellular network with Bernoulli uplink traffic. Simulation results are conducted to validate the proposed model and show the effect of traffic load and decoding threshold. Insights are driven to characterize the network stability frontiers and the location-dependent performance within the network.","2577-2465","978-1-7281-9484-4","10.1109/VTC2020-Fall49728.2020.9348865","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9348865","Age of information;spatiotemporal models;Internet of Things;queueing theory;stochastic geometry","Telecommunication traffic;Tools;Stability analysis;Spatiotemporal phenomena;Uplink;Queueing analysis;Load modeling","","4","","29","IEEE","15 Feb 2021","","","IEEE","IEEE Conferences"
"Joint Optimization of Deployment and Flight Planning of Multi-UAVs for Long-Distance Data Collection From Large-Scale IoT Devices","Y. Zhang; Y. Huang; C. Huang; H. Huang; A. -T. Nguyen","Department of Industrial and Systems Engineering, The Hong Kong Polytechnic University, Hong Kong, China; Data61, Commonwealth Scientific and Industrial Research Organisation, Melbourne, VIC, Australia; Department of Industrial and Systems Engineering, The Hong Kong Polytechnic University, Hong Kong, China; Department of Aeronautical and Aviation Engineering and the Research Institute for Sports Science and Technology, The Hong Kong Polytechnic University, Hong Kong, China; LAMIH Laboratory, UMR CNRS 8201, and INSA Hauts-de-France, Université Polytechnique Hauts-de-France, Valenciennes, France","IEEE Internet of Things Journal","27 Dec 2023","2024","11","1","791","804","Internet of Things (IoT) devices have been widely deployed to build smart cities. How to efficiently collect data from large-scale IoT devices is a valuable and challenging research topic. Benefiting from agility, flexibility, and deployability, an unmanned aerial vehicle (UAV) has great potential to be an aerial base station. However, given the limited battery capacity, the flight time of a UAV is limited. This article focuses on using multi-UAVs to execute long-distance data collection from large-scale IoT devices. We design a multi-UAVs-assisted large-scale IoT data collection system. The core facilities of this system are the data center and charging stations, which are equipped with a limited number of charging piles to provide charging services for UAVs. To ensure the efficient operation of the system, the problem of deployment and flight planning of UAVs is formulated as a joint optimization problem. To solve the problem, a population-based optimization algorithm with a three-layer structure, namely, EDDE-DPDE, is proposed. It includes two core components: 1) elite-driven differential evolution (EDDE) and 2) differential evolution with a dynamic population (DPDE), which are two variants of differential evolution. Thanks to ideas of reusing elite individuals and historical information, the proposed EDDE-DPDE shows an improvement of at least 11.11% compared with four powerful algorithms in terms of average travel time.","2327-4662","","10.1109/JIOT.2023.3285942","Department General Research(grant numbers:P0040253); Research Institute for Sports Science and Technology(grant numbers:P0043566); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10153427","Data collection;differential evolution (DE);flight planning (FP);Internet of Things (IoT);multi-UAVs","Internet of Things;Data collection;Autonomous aerial vehicles;Task analysis;Planning;Statistics;Sociology","","1","","38","IEEE","14 Jun 2023","","","IEEE","IEEE Journals"
"Hierarchical Adversarial Attacks Against Graph-Neural-Network-Based IoT Network Intrusion Detection System","X. Zhou; W. Liang; W. Li; K. Yan; S. Shimizu; K. I. -K. Wang","Faculty of Data Science, Shiga University, Hikone, Japan; Base of International Science and Technology Innovation and Cooperation on Big Data Technology and Management, Hunan University of Technology and Business, Changsha, China; School of Computer Engineering and Science, Shanghai University, Shanghai, China; Department of the Built Environment, College of Design and Engineering, National University of Singapore, Singapore; Faculty of Data Science, Shiga University, Hikone, Japan; Department of Electrical, Computer, Software Engineering, The University of Auckland, Auckland, New Zealand","IEEE Internet of Things Journal","7 Jun 2022","2022","9","12","9310","9319","The advancement of Internet of Things (IoT) technologies leads to a wide penetration and large-scale deployment of IoT systems across an entire city or even country. While IoT systems are capable of providing intelligent services, the large amount of data collected and processed in IoT systems also raises serious security concerns. Many research efforts have been devoted to design intelligent network intrusion detection system (NIDS) to prevent misuse of IoT data across smart applications. However, existing approaches may suffer from the issue of limited and imbalanced attack data when training the detection model, which make the system vulnerable especially for those unknown type attacks. In this study, a novel hierarchical adversarial attack (HAA) generation method is introduced to realize the level-aware black-box adversarial attack strategy, targeting the graph neural network (GNN)-based intrusion detection in IoT systems with a limited budget. By constructing a shadow GNN model, an intelligent mechanism based on a saliency map technique is designed to generate adversarial examples by effectively identifying and modifying the critical feature elements with minimal perturbations. A hierarchical node selection algorithm based on random walk with restart (RWR) is developed to select a set of more vulnerable nodes with high attack priority, considering their structural features, and overall loss changes within the targeted IoT network. The proposed HAA generation method is evaluated using the open-source data set UNSW-SOSR2019 with three baseline methods. Comparison results demonstrate its ability in degrading the classification precision by more than 30% in the two state-of-the-art GNN models, GCN and JK-Net, respectively, for NIDS in IoT environments.","2327-4662","","10.1109/JIOT.2021.3130434","National Key Research and Development Program of China(grant numbers:2017YFE0117500,2019YFE0190500); National Natural Science Foundation of China(grant numbers:62072171); Natural Science Foundation of Hunan Province of China(grant numbers:2020SK2089); Open Fund of Key Laboratory of Hunan Province(grant numbers:2017TP1026); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9626144","Adversarial attack;deep learning;graph neural network (GNN);Internet of Things (IoT);network intrusion detection","Internet of Things;Data models;Training;Deep learning;Feature extraction;Perturbation methods;Optimization","","127","","41","CCBY","24 Nov 2021","","","IEEE","IEEE Journals"
"Architecture and Key Technology of Intelligent Energy Service System Based on Industrial Internet","G. Shen; G. Chen; X. Dong; A. Geng; L. Sun; Y. Sun","Beijing Ke Dong company, NARI Group Corporation, Beijing, China; Beijing Ke Dong company, NARI Group Corporation, Beijing, China; Beijing Ke Dong company, NARI Group Corporation, Beijing, China; Beijing Ke Dong company, NARI Group Corporation, Beijing, China; Beijing Ke Dong company, NARI Group Corporation, Beijing, China; Beijing Ke Dong company, NARI Group Corporation, Beijing, China","2020 IEEE Sustainable Power and Energy Conference (iSPEC)","18 Feb 2021","2020","","","2077","2082","China's intelligent energy shows a good trend of diversified development. However, intelligent energy research is still in its infancy, and most projects are based on simulation software to study regional integrated energy management; the existing pilot applications focus on regional integrated energy management, and there is a relative lack of research on the comprehensive control of power grid energy-using device. In view of the above problems, an intelligent energy service system based on industrial Internet design concept is proposed. First, carry out research on key technologies of intelligent energy service system, and build an intelligent energy service system architecture based on “Internet + ubiquitous Internet of things”, It adopts the architecture design of terminal layer, network communication layer, platform layer and business application layer, and elaborates the design idea and composition of each layer architecture. The technical architecture, physical architecture and security architecture of the system are also described. Among them, technical architecture is divided into display layer, service layer, storage layer, collection layer and protocol layer, summarizing the key technologies used in each layer of architecture. The physical architecture adopts the internal and external network structure, which not only realizes information isolation but also meets the needs of information interaction and business expansion. The security architecture focuses on boundary security, application security, data security, password security, network security, terminal security and other aspects of design, through isolation device, wireless virtual private network, digital certificate and other means to achieve isolation protection and secure communication. Finally, the application of the system is introduced. The system has been deployed in the headquarters of State Grid, mainly covering business modules such as intelligent energy data access, asset management, operation monitoring and operation management. Comprehensively supervise the operation and operation of client side energy equipment, and interconnect with marketing business, intelligent vehicle networking platform and other systems, realizing data and resource sharing, and building an unified, open and integrated industrial Internet service platform. Build orderly charging, optical storage and charging business applications on the basis of the platform; adopt “peak load shaving” strategy to reduce the peak load of the power grid and the user electricity cost, achieving mutual benefit and win-win results between enterprises and customers. The system has made innovations in the real-time concurrent processing of massive data intelligent energy “cloud platform + micro-service” system architecture, the orderly charging strategy and scheduling algorithm of electric vehicles, and the collaborative optimization of large-scale source network storage equipment, which can improve the consumption level of renewable energy and the overall utilization efficiency of social resources, and can provide a better guarantee for the safe operation of the power grid. At the same time, the system supports the distribution and deployment of provinces and cities, and the pilot projects in Beijing, Shanghai, Jiangsu and other places have achieved good results, verifying the practicability and effectiveness of the system.","","978-1-7281-9164-5","10.1109/iSPEC50848.2020.9351094","State Grid Corporation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9351094","Intelligent Energy;Systems Architecture;Industry Internet;Electric Vehicle Orderly Charging","Energy consumption;Computer architecture;Power grids;Internet;Security;Business;Energy storage","","1","","11","IEEE","18 Feb 2021","","","IEEE","IEEE Conferences"
"Load Balanced Controller Association in Wireless Distributed SDNs","A. Starke; J. McNair","University of Florida, Gainesville, FL; University of Florida, Gainesville, FL","2020 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops)","4 Aug 2020","2020","","","1","2","Wireless infrastructure is steadily evolving into wireless access for all humans and most devices, from 5G to Internet-of-Things. This widespread access creates the expectation of custom and adaptive services from the personal network to the backbone network. In addition, challenges of scale and interoperability exist across networks, applications and services, requiring an effective wireless network management infrastructure. For this reason Software-Defined Networks (SDN) have become an attractive research area for wireless and mobile systems. SDN can respond to sporadic topology issues such as dropped packets, message latency, and/or conflicting resource management, to improved collaboration between mobile access points, reduced interference and increased security options. Until recently, the main focus on wireless SDN has been a more centralized approach, which has issues with scalability, fault tolerance, and security. In this work, we propose a state of the art WAM-SDN system for large-scale network management. We discuss requirements for large scale wireless distributed WAM-SDN and provide preliminary benchmarking and performance analysis based on our hybrid distributed and decentralized architecture.","","978-1-7281-4716-1","10.1109/PerComWorkshops48775.2020.9156178","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9156178","","Wireless communication;Communication system security;Process control;Control systems;Network topology;Adaptive systems;Topology","","1","","2","IEEE","4 Aug 2020","","","IEEE","IEEE Conferences"
"Fostering the relation and the connectivity between smart homes and grids – InterConnect project","J. M. Terras; T. Simão; D. Rua; F. Coelho; C. Gouveia; R. Bessa; J. Baumeister; R. -I. Prümm; O. Genest; A. Siarheyeva; J. Laarakkers; E. Rivero; E. Bosco; P. Nemcek; K. Glennung","EDP Distribuição, Lisbon, Portugal; EDP Distribuição, Lisbon, Portugal; INESC TEC, Porto, Portugal; INESC TEC, Porto, Portugal; INESC TEC, Porto, Portugal; INESC TEC, Porto, Portugal; EEBUS, Cologne, Germany; EEBUS, Cologne, Germany; Trialog, Paris, France; YNCREA, Toulon, France; TNO, Amsterdam, The Netherlands; VITO, Mol, Belgium; Politecnico Milano, Milano, Italy; CyberGrid, Vienna, Austria; EDSO, Brussels, Belgium","CIRED 2020 Berlin Workshop (CIRED 2020)","21 Oct 2021","2020","2020","","761","764","This study offers an overview of the H2020 InterConnect project, which targets the relation between smart homes and distribution grids. The project vision is to produce a digital marketplace, using an interoperable marketplace toolbox and Smart appliances REference Ontology (SAREF) compliant Internet of Things (IoT) reference architecture as the main backbone, through which all SAREF-ized services, compliant devices, platform enablers and applications can be downloaded onto IoT and smart grid digital platforms. Energy users in buildings, either residential or non-residential, manufacturers, distribution grid operators and the energy retailers will work together towards the demonstration of the smart energy management solutions in seven connected large-scale test-sites in Portugal, Belgium, Germany, the Netherlands, Italy, Greece and France. This study depicts how InterConnect project will enhance the relation and the interconnectivity between smart buildings and grids safeguarding the definition of the role of each stakeholder in energy and non-energy services.","","","10.1049/oap-cired.2021.0219","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9582943","","","","","","9","","21 Oct 2021","","","IET","IET Conferences"
"Privacy-preserving Aggregation Scheme for Blockchained Federated Learning in IoT","M. Fan; H. Yu; G. Sun","The School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; The School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; The School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China","2021 International Conference on UK-China Emerging Technologies (UCET)","19 Jan 2022","2021","","","129","132","The rapid increase in Internet of Things (IoT) connected devices and generated data has greatly promoted the development of artificial intelligence. Federated Learning (FL) provides strong support for the data-driven society by training the model locally without leaking the privacy of the client. However, due to the unreliability of IoT devices and the centralized training model of FL, there are still security risks such as privacy leakage in federated learning. Therefore, this paper proposes a decentralized and privacy-preserving aggregation scheme, named DPPA, for FL. DPPA leverages the blockchain to structure a decentralized FL architecture, and leverages Paillier cryptosystem to realize the privacy protection of local data and the safe aggregation of model parameters. Through security analysis, we demonstrate that DPPA resists various security threats and preserve client privacy. Experiments show that in the large-scale IoT device environment, DPPA has great advantages over the existing competing approaches in terms of computational overhead.","","978-1-6654-9575-2","10.1109/UCET54125.2021.9674950","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9674950","privacy-preserving;Blockchain;Federated learning (FL);Internet of Things (IoT)","Training;Privacy;Data privacy;Resists;Collaborative work;Data models;Blockchains","","","","21","IEEE","19 Jan 2022","","","IEEE","IEEE Conferences"
"Paddy Yield Monitoring System","M. L. Haqim Azman; I. Ahmad; A. M. Suhairi; K. Kadir; N. H. Abdul Kaharc; I. Alhamrouni","Intelligent Embedded Research Laboratory (IERL), Electronics Technology Section British Malaysian Institute Universiti Kuala Lumpur, Selangor, Malaysia; Intelligent Embedded Research Laboratory (IERL), Electronics Technology Section British Malaysian Institute Universiti Kuala Lumpur, Selangor, Malaysia; Intelligent Embedded Research Laboratory (IERL), Electronics Technology Section British Malaysian Institute Universiti Kuala Lumpur, Selangor, Malaysia; Intelligent Embedded Research Laboratory (IERL, British Malaysian Institute, Universiti Kuala Lumpur, Selangor, Malaysia; Intelligent Embedded Research Laboratory (IERL), Electronics Technology Section British Malaysian Institute Universiti Kuala Lumpur, Selangor, Malaysia; Electrical Engineering Section British Malaysian Institute, Universiti Kuala Lumpur, Selangor, Malaysia","2023 IEEE 9th International Conference on Smart Instrumentation, Measurement and Applications (ICSIMA)","3 Jan 2024","2023","","","252","256","Rice plays a vital role in the economies and cultures of many Asian countries, yet the inconsistency in paddy production poses challenges for small-scale farmers. To address these challenges, this study aimed to developed an Internet of Things (IoT) based system for monitoring paddy yields. The methodology involved integrating sensors to collect parameters such as pH, temperature, moisture, and soil nutrient levels, transmitting the data using LoRa technology, and storing it in a cloud database. Linear Regression was then applied to generate predictions. The results demonstrated successful data collection and visualization through the IoT system, providing valuable insights into the optimal growth parameters for paddy. Overall, this project offering a promising solution for enhancing paddy cultivation practices and decision-making processes through IoT technology.","2640-6535","979-8-3503-4338-0","10.1109/ICSIMA59853.2023.10373428","Universiti Kuala Lumpur; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10373428","paddy monitoring system;Internet of Things (IoT);LoRa technology;linear regression;smart farming","Temperature sensors;Cloud computing;Temperature distribution;Linear regression;Soil moisture;Real-time systems;Sensor systems","","","","10","IEEE","3 Jan 2024","","","IEEE","IEEE Conferences"
"Pinpointing Hidden IoT Devices via Spatial-temporal Traffic Fingerprinting","X. Ma; J. Qu; J. Li; J. C. S. Lui; Z. Li; X. Guan","MOE Key Lab for Intelligent Networks and Network Security, Xi’an Jiaotong University, Xi’an, China; MOE Key Lab for Intelligent Networks and Network Security, Xi’an Jiaotong University, Xi’an, China; MOE Key Lab for Intelligent Networks and Network Security, Xi’an Jiaotong University, Xi’an, China; Department of Computer Science & Engineering, The Chinese University of Hong Kong, Hong Kong; School of Software, Tsinghua University, Beijing, China; MOE Key Lab for Intelligent Networks and Network Security, Xi’an Jiaotong University, Xi’an, China","IEEE INFOCOM 2020 - IEEE Conference on Computer Communications","4 Aug 2020","2020","","","894","903","With the popularization of Internet of Things (IoT) devices in smart home and industry fields, a huge number of IoT devices are connected to the Internet. However, what devices are connected to a network may not be known by the Internet Service Provider (ISP), since many IoT devices are placed within small networks (e.g., home networks) and are hidden behind network address translation (NAT). Without pinpointing IoT devices in a network, it is unlikely for the ISP to appropriately configure security policies and effectively manage the network. In this paper, we design an efficient and scalable system via spatial-temporal traffic fingerprinting. Our system can accurately identify typical IoT devices in a network, with the additional capability of identifying what devices are hidden behind NAT and how many they are. Through extensive evaluation, we demonstrate that the system can generally identify IoT devices with an F-Score above 0.999, and estimate the number of the same type of IoT device behind NAT with an average error below 5%. We also perform small-scale (labor-intensive) experiments to show that our system is promising in detecting user-IoT interactions.","2641-9874","978-1-7281-6412-0","10.1109/INFOCOM41043.2020.9155346","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155346","","Cameras;Internet of Things;Feature extraction;Security;Object recognition;IP networks;Plugs","","20","","25","IEEE","4 Aug 2020","","","IEEE","IEEE Conferences"
"IoT-AD: A Framework to Detect Anomalies Among Interconnected IoT Devices","H. Zahan; M. W. Al Azad; I. Ali; S. Mastorakis","Department of Computer Science, University of Nebraska Omaha, Omaha, NE, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science, University of Nebraska Omaha, Omaha, NE, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA","IEEE Internet of Things Journal","27 Dec 2023","2024","11","1","478","489","In an Internet of Things (IoT) environment (e.g., smart home), several IoT devices may be available that are interconnected with each other. In such interconnected environments, a faulty or compromised IoT device could impact the operation of other IoT devices. In other words, anomalous behavior exhibited by an IoT device could propagate to other devices in an IoT environment. In this article, we argue that mitigating the propagation of the anomalous behavior exhibited by a device to other devices is equally important to detecting this behavior in the first place. In line with this observation, we present a framework, called IoT Anomaly Detector (IoT-AD), that can not only detect the anomalous behavior of IoT devices but also limit and recover from anomalous behavior that might have affected other devices. We implemented a prototype of IoT-AD, which we evaluated based on open-source IoT device data sets as well as through real-world deployment on a small-scale IoT testbed we have built. We have further evaluated IoT-AD in comparison to prior relevant approaches. Our evaluation results show that IoT-AD can identify anomalous behavior of IoT devices in less than 2.12 ms and with up to 98% of accuracy.","2327-4662","","10.1109/JIOT.2023.3285714","National Science Foundation(grant numbers:CNS-2104700,CNS-2306685,CNS-2016714,CBET-2124918); ACM SIGMOBILE; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10149430","Anomaly detection;device interaction anomalies;Internet of Things (IoT);network traffic anomalies","Internet of Things;Behavioral sciences;Anomaly detection;Smart homes;Object recognition;Telecommunication traffic;Feature extraction","","","","46","IEEE","13 Jun 2023","","","IEEE","IEEE Journals"
"An IoT Platform for Data Management in an Industrial-Scale Microalgae Cultivation Plant","M. Muñoz; J. L. Guzmán; M. Torres; F. G. Acién","Department of Computer Science, CIESOL-ceiA3, University of Almería, Almería, Spain; Department of Computer Science, CIESOL-ceiA3, University of Almería, Almería, Spain; Department of Computer Science, CIESOL-ceiA3, University of Almería, Almería, Spain; Department of Chemical Engineering, CIESOL-ceiA3, University of Almería, Almería, Spain","IEEE Access","9 Dec 2022","2022","10","","127128","127139","Microalgae biomass production technology is in continuous progress. One of the challenges deals with scaling up existing medium-scale facilities to industrial-scale production systems. This new expanding infrastructure requires adequate data management and data accessibility tools for all the process variables. In this sense, this work presents a novel solution for microalgae production systems based on Internet of Things (IoT) technology as an important ally in the digitalization of these industrial processes. The paper summarizes the development of an IoT-based platform for data management in a large-scale microalgae cultivation plant with more than 12 industrial photobioreactors. A cloud-based architecture is provided for a solution for data management and a graphical front-end for data access (real-time and historical data). Different profiles can be managed for technicians and researchers depending on their skills and needs.","2169-3536","","10.1109/ACCESS.2022.3226334","Spanish Ministry of Science(grant numbers:PID2020-112709RB-C21); Horizon Europe–the Framework Program for Research and Innovation (2021–2027)(grant numbers:101060991 REALM); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9968240","Cloud;data management;IoT;microalgae;photobioreactor","Data management;Cloud computing;Sensors;Monitoring;Germanium;Intelligent sensors;Algae;Bioreactors","","1","","50","CCBYNCND","1 Dec 2022","","","IEEE","IEEE Journals"
"Forest Fire Detection via the Internet of Things-Based Systems","P. Negi; S. Kathuria; R. Singh; V. Pachouri; N. Kathuria","Uttaranchal Institue of Technology, Uttaranchal University, Dehradun, India; Division of Research & Innovation, Uttaranchal University, Dehradun, India; Division of Research & Innovation, UIT, Uttaranchal University, Dehradun, India; Uttaranchal Institue of Technology, Uttaranchal University, Dehradun, India; Law College Dehradun, Uttaranchal University, Dehradun, India","2023 3rd International Conference on Pervasive Computing and Social Networking (ICPCSN)","4 Oct 2023","2023","","","1144","1149","One of the disasters caused by natural or human causes directly affect the economy, society, and environment on a large scale and makes it more difficult to meet some of the Sustainable Development Goals. The promotion of sustainable forest management help to achieve environmental sustainability, a goal that has gained international attention. Internet of Things (IoT), a revolutionary technology of the fourth industrial revolution, brings us toward achieving sustainable forest management by preventing hazards from occurring in the forest by employing a large number of smart devices to gather data, monitor the forest, and timely detection of fire. The current study extensively assesses how IoT is utilized to design various tools to promptly detect fire and manage it. Finally, based on the analysis, the challenges and suggestions for future improvement are made with regard to attaining forest sustainability by preventing forest fires and making the IoT based system more reliable.","","979-8-3503-2284-2","10.1109/ICPCSN58827.2023.00194","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10265970","Sustainable Development;Internet of Things (IoT);Internet of Forest Things (IoFT);Sensors;Sensing Nodes;Forest Fire","Pervasive computing;Social networking (online);Forestry;Real-time systems;Sensors;Internet of Things;Reliability","","","","19","IEEE","4 Oct 2023","","","IEEE","IEEE Conferences"
"Research on Key Technologies of Power Distribution Internet of Things","X. Ma; S. Shao; W. Zhang","NARI NANJING CONTROL SYSTEM CO., LTD, Nanjing, China; NARI NANJING CONTROL SYSTEM CO., LTD, Nanjing, China; NARI NANJING CONTROL SYSTEM CO., LTD, Nanjing, China","2020 12th IEEE PES Asia-Pacific Power and Energy Engineering Conference (APPEEC)","13 Oct 2020","2020","","","1","4","Due to the current large-scale grid architecture which is distributed, multi-load and multi-power, the operation and maintenance workload and operating safety pressure of the distribution network are increased, an intelligent distribution network based on the Internet of Things technology has been proposed to realize multiple perceptions of the fast convergence and effective processing of information of distribution network. In order to further develop the research and implementation of the smart distribution network, this paper describes the functional architecture of the power distribution Internet of Things, and discusses the three key technologies which are respectively building the distribution information model, the fast access of sensing terminals, and operating status analysis of distribution grid. This research lays the foundation for improving the reliability of distribution network operation and the ability to manage and control equipment status.","","978-1-7281-5748-1","10.1109/APPEEC48164.2020.9220649","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9220649","Internet of Things;distribution network;information perception;fast access strategy","Conferences;Power distribution;Distribution networks;Control equipment;Maintenance engineering;Sensors;Safety","","3","","11","IEEE","13 Oct 2020","","","IEEE","IEEE Conferences"
"A Fast Response DC-DC Converter with Programmable Ripple for Combined Distributed Computation and Communication","X. Cui; C. Deng; A. -T. Avestruz","Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, Ann Arbor, USA; Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, Ann Arbor, USA; Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, Ann Arbor, USA","2021 IEEE Applied Power Electronics Conference and Exposition (APEC)","21 Jul 2021","2021","","","468","473","DC-DC converters with low EMI and fast dynamic voltage scaling capability can significantly benefit the distributed computing and sensing devices in the Internet of things (IoT). However, the classic power converters have to tradeoff between fast transient response and small current ripple. We overcome this limitation by utilizing a programmable saturating inductor. In this paper, we investigate a ripple-programming architecture with compact volume, maximum power consumption of 1% of the power stage, and a ripple settling time below 1ms. The architecture includes a low-cost load estimation method with an error below 8% over the entire load range. We implement this ripple-programming architecture on a 1 MHz constant on-time buck converter prototype with a peak power of 30W. The inductor ripple can be effectively reduced by 40%.","2470-6647","978-1-7281-8949-9","10.1109/APEC42165.2021.9487391","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9487391","combined distributed computation and communication;dynamic voltage scaling;core saturation;programmable inductor;digital control","Transient response;Power demand;Electromagnetic interference;Estimation;Prototypes;Power electronics;Sensors","","","","20","IEEE","21 Jul 2021","","","IEEE","IEEE Conferences"
"Evolve from Traditional Power Grid Network to Blockchain and IoT Integrated Network","Q. Yang; D. Zhou; C. Yiheng; X. Zhang; Y. Su","Tsinghua University, Beijing, China; Science and Technology Research Institute, China Three Gorges Corporation, Beijing, China; Guangdong Power Grid Co Maoming, Power Supply Bureau, China Southern Power Grid, Maoming, China; Science and Technology Research Institute, China Three Gorges Corporation, Beijing, China; Science and Technology Research Institute, China Three Gorges Corporation, Beijing, China","2021 IEEE International Conference on Energy Internet (ICEI)","8 Feb 2022","2021","","","119","124","The carbon emission goals and the disruptive technologies development of the Internet of Things and Blockchain are expected to bring significant changes to the information and communication architecture for power grids. The security requirements, real-time operation of power systems, and legacy communication and interfaces development of power systems, as well as system and data silos of IoT and blockchain networks in the energy sector, contributed to the challenges of integration of IoT into the power systems, and blockchain-powered energy services in a larger scale. Blockchain technologies are expected to bring significant changes to energy consumption behaviors, demanding integration of P2P networks with Industrial IoT and IoT networks, and the OT&IT systems of the power grids to support millions of prosumers. The integration of these three domains is expected to support energy trading and new services to energy prosumers, maximize distributed energy resources consumption, improve overall energy efficiency, encourage flexibility aggregation and virtual power plant markets. This paper analyzes the IT&OT systems of the power grids, particularly the IEC series standards adopted by the electric industry, IoT integration and examples of integration, and blockchain peer-to-peer network. The paper analyzes the challenges of eco-development of these three relatively independent ICT domains, provides an analysis and an outlook of the integration of these three domains.","","978-1-6654-0734-2","10.1109/ICEI52466.2021.00027","China Three Gorges Corporation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9701130","Power grid;IT;OT systems;Internet of Things;IIoT;IEC 61850;OSI;Blockchain P2P network","Open systems;Virtual power plants;Power grids;Real-time systems;Blockchains;Peer-to-peer computing;Security","","","","11","IEEE","8 Feb 2022","","","IEEE","IEEE Conferences"
"Mist-Edge-Cloud (MEC) Computing: An Integrated Computing Architecture","F. Hensh; M. Gupta; M. J. Nene","Defence Institute of Advanced Technology,Department of Computer Science & Engineering,Pune,Maharashtra,India; Defence Institute of Advanced Technology,Department of Computer Science & Engineering,Pune,Maharashtra,India; Defence Institute of Advanced Technology,Department of Computer Science & Engineering,Pune,Maharashtra,India","2021 Second International Conference on Electronics and Sustainable Communication Systems (ICESC)","23 Sep 2021","2021","","","1035","1040","The present-day context of computation is driven by the voluminous data being generated and requirement of fast decision making. Internet of Things (IoT) is one such technology which thrives on such computational requirement. Cloud computing emerged as a revolutionary technology providing on demand usage, minimal operational costs and enhanced security mechanisms. However, long distance between user devices and cloud server creates some amount of delay in the computing network. Therefore, with large scale shift of capabilities and resources over the cloud, limitations and drawbacks of the technology have come to the forefront with technologies like IoT finding it difficult to work with the cloud computing architecture degrading users Quality of Services (QoS) and Quality of Experiences (QoE). The study reviews traditional cloud computing network and proposes a network architecture integrating cloud, mist and edge computing methods extending computational and communication capabilities right up to user devices thus improving the QoS. The study also involves carrying out an experimental analysis of the integrated approach to further ascertain practicability of the proposed model in existing networks.","","978-1-6654-2867-5","10.1109/ICESC51422.2021.9532929","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9532929","Internet of Things (IoT);Quality of Service (QoS);Quality of Experience (QoE);Mist-Edge-Cloud (MEC) Computing;Local Area Network (LAN);Transmission Delay (TD);Computational Delay (CD);Overall System Delay (OSD)","Cloud computing;Computational modeling;Computer architecture;Quality of service;Delays;Servers;Internet of Things","","6","","48","IEEE","23 Sep 2021","","","IEEE","IEEE Conferences"
"Privacy and Security of IoT based Skin Monitoring System using Blockchain Approach","S. Juyal; S. Sharma; A. Harbola; A. S. Shukla","Department of Computer Science and Engineering, Graphic Era Deemed to be University, Uttarakhand, India; Department of Computer Science and Engineering, Graphic Era Deemed to be University, Uttarakhand, India; School of Computing, Graphic Era Hill University, Uttarakhand, India; Department of Computer Science and Engineering, Graphic Era Deemed to be University, Uttarakhand, India","2020 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT)","16 Sep 2020","2020","","","1","5","Remote patient monitoring is a system that focuses on patients care and attention with the advent of the Internet of Things (IoT). The technology makes it easier to track distance, but also to diagnose and provide critical attention and service on demand so that billions of people are safer and more safe. Skincare monitoring is one of the growing fields of medical care which requires IoT monitoring, because there is an increasing number of patients, but cures are restricted to the number of available dermatologists. The IoT-based skin monitoring system produces and store volumes of private medical data at the cloud from which the skin experts can access it at remote locations. Such large-scale data are highly vulnerable and otherwise have catastrophic results for privacy and security mechanisms. Medical organizations currently do not concentrate much on maintaining safety and privacy, which are of major importance in the field. This paper provides an IoT based skin surveillance system based on a blockchain data protection and safety mechanism. A secure data transmission mechanism for IoT devices used in a distributed architecture is proposed. Privacy is assured through a unique key to identify each user when he registers. The principle of blockchain also addresses security issues through the generation of hash functions on every transaction variable. We use blockchain consortiums that meet our criteria in a decentralized environment for controlled access. The solutions proposed allow IoT based skin surveillance systems to privately and securely store and share medical data over the network without disturbance.","","978-1-7281-6828-9","10.1109/CONECCT50063.2020.9198409","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9198409","Internet of Things;Blockchain;privacy;security;Cloud","Skin;Peer-to-peer computing;Medical services;Cloud computing;Privacy","","18","","27","IEEE","16 Sep 2020","","","IEEE","IEEE Conferences"
"The Internet of Things: a domain-specific security requirement classification","A. Mukalazi; A. Boyaci","Department of Cyber Security, Istanbul Commerce University, Istanbul, Turkey; Department of Computer Engineering, Istanbul Commerce University, Istanbul, Turkey","2022 International Congress on Human-Computer Interaction, Optimization and Robotic Applications (HORA)","27 Jun 2022","2022","","","1","8","Worldwide, societies are rapidly becoming more connected, owing primarily to the growing number of intelligent things and smart applications (e.g, smart automobiles, smart wearable devices, etc.) These have occurred in tandem with the Internet Of Things, a new method of connecting the physical and virtual worlds. It is a new promising paradigm whereby every ‘thing’ can connect to anything via the Internet. However, with IoT systems being deployed even on large-scale, security concerns arise amongst other challenges. Hence the need to allocate appropriate protection of resources. The realization of secure IoT systems could only be accomplished with a comprehensive understanding of the particular needs of a specific system. How-ever, this paradigm lacks a proper and exhaustive classification of security requirements. This paper presents an approach towards understanding and classifying the security requirements of IoT devices. This effort is expected to play a role in designing cost-efficient and purposefully secured future IoT systems. During the coming up with and the classification of the requirements, We present a variety of set-ups and define possible attacks and threats within the scope of IoT. Considering the nature of IoT and security weaknesses as manifestations of unrealized security requirements, We put together possible attacks and threats in categories, assessed the existent IoT security requirements as seen in literature, added more in accordance with the applied domain of the IoT and then classified the security requirements. An IoT system can be secure, scalable, and flexible by following the proposed security requirement classification.","","978-1-6654-6835-0","10.1109/HORA55278.2022.9800035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9800035","Internet Of Things(IOT);security requirement classification;security;threats and attacks;architecture","Human computer interaction;Wearable computers;Internet of Things;Security;Automobiles;Robots;Optimization","","","","15","IEEE","27 Jun 2022","","","IEEE","IEEE Conferences"
"Design of Intelligent Energy-saving and Monitoring Management Cloud Platform for Urban Street Lamps Based on 5G Communication","Z. Han; X. Wang; J. Qin; M. Li; Q. Wang",NA; NA; NA; NA; NA,"EMIE 2022; The 2nd International Conference on Electronic Materials and Information Engineering","17 Feb 2023","2022","","","1","8","Urban road lighting system is one of the symbols of urbanization and it is also an important part of urban energy consumption. In order to reduce the energy waste of urban street lamps and realize the intelligent lighting of street lamps, this paper designed an intelligent energy saving and monitoring management system for urban street lamps based on 5G mobile communication and cloud platform. The system realizes long-distance and low-latency communication between terminal equipment and WISE-PaaS cloud platform through 5G CPE module and IoT cloud platform, and adopts fuzzy control algorithm realize Intelligent energy-saving control of city street lights. Compared with the existing traditional lighting system, this system can not only realize large-scale networking, but also use the advantages of cloud platform technology to realize remote monitoring and alarm functions on the mobile terminal. It has the characteristics of high security and good scalability, 5G and the Internet of Things can meet the requirements of application scenarios of system terminals.","","978-3-8007-5961-3","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10048452","","","","","","","","17 Feb 2023","","","VDE","VDE Conferences"
"Internet of Things Based Remote Sensing for Ornithological Monitoring","M. Khan; D. G. Barron; R. Patil; M. Nannemann; M. Courson","Department of Electrical Engineering, Arkansas Tech University, Russellville, AR; Department of Biological Sciences, Arkansas Tech University, Russellville, AR; Department of Computer and Information Systems, Arkansas Tech University, Russellville, AR; Department of Electrical Engineering, Arkansas Tech University, Russellville, AR; Department of Electrical Engineering, Arkansas Tech University, Russellville, AR","2020 IEEE Green Technologies Conference(GreenTech)","16 Dec 2020","2020","","","71","73","Biologists have long struggled to monitor the behavior of wild animals, though remote sensing technologies have allowed recent insights into otherwise cryptic animal behaviors. Traditional methods of animal tracking use radio- or GPS-transmitters that are expensive, large, and unable to track animal movements on a fine-scale. Radio-frequency identification (RFID) technology poses a cheap and unobtrusive solution to track activity of animals near antenna stations, though current data loggers face problems with energy supply, data format, and data access/storage. Internet of Things (IoT) holds promise as a tool to advance this type of zoological research through its integration of embedded systems, sensors, control systems and wireless communications. In this project we propose the structure of a system that combines RFID and IoT technologies to enable real-time tracking of feeder usage by wild birds in central Arkansas. The proposed system will replace existing data loggers and provide continuous, automated, and real-time data collection with minimal personnel oversight. The design will be superior to more expensive commercially-available units and will represent a breakthrough in wildlife monitoring technology.","2166-5478","978-1-7281-5017-8","10.1109/GreenTech46478.2020.9289727","Arkansas Tech University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9289727","remote sensing;IoT;RFID;ornithology;bird feeding;animal tracking;real-time data logging","Wireless communication;Tracking;Real-time systems;Internet of Things;Remote sensing;Monitoring;Radiofrequency identification","","4","","9","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"Measurement of ICT latency and full activation time for fast demand response of electric vehicle charging","M. Imanaka; H. Baba; K. Ogimoto","Institute of Industrial Science, The University of Tokyo, Tokyo, Japan; Institute of Industrial Science, The University of Tokyo, Tokyo, Japan; Institute of Industrial Science, The University of Tokyo, Tokyo, Japan","7th E-Mobility Power System Integration Symposium (EMOB 2023)","21 Nov 2023","2023","2023","","62","66","Flexibility of distributed energy resources (DERs) for fast demand response like secondary reserve has been highlighted to support large scale integration of renewable energy sources into the power system. To control such resources in real time, IoT (Internet of Things)-based demand response (DR) is necessary. One important issue with IoT-based DR is with regard to their full activation time (FAT) and its ICT latency. Although many studies have reported the inherent delay of various DERs, our research review has not found many integrated measurement results of both ICT latency and the inherent delay of the DER. The relationship between the ICT response time (IRT) of the DER and the FAT has not been clearly discussed. To the well understanding of both the ICT latency and FAT of DERs, an experimental system is constructed to measure both the ICT latency and the electrical delay of DERs, synchronously with the local timeserver. This paper reports the experimental system, the characteristics of measured IRT and the FAT of one electric vehicle charger as an example.","","978-1-83953-957-2","10.1049/icp.2023.2686","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10324566","","","","","","","","21 Nov 2023","","","IET","IET Conferences"
"Recommendation Based on Large-Scale Many-Objective Optimization for the Intelligent Internet of Things System","B. Cao; Y. Zhang; J. Zhao; X. Liu; Ł. Skonieczny; Z. Lv","State Key Laboratory of Reliability and Intelligence of Electrical Equipment, Hebei University of Technology, Tianjin, China; State Key Laboratory of Reliability and Intelligence of Electrical Equipment, Hebei University of Technology, Tianjin, China; State Key Laboratory of Reliability and Intelligence of Electrical Equipment, Hebei University of Technology, Tianjin, China; School of Economics and Management, Hebei University of Technology, Tianjin, China; Institute of Computer Science, Warsaw University of Technology, Warsaw, Poland; School of Data Science and Software Engineering, Qingdao University, Qingdao, China","IEEE Internet of Things Journal","8 Aug 2022","2022","9","16","15030","15038","Recommender systems are of great significance for mining the data generated by the Internet of Things (IoT) and are important for the intelligent IoT systems. The traditional recommendation algorithms only consider the accuracy as the optimization objective. In this article, a many-objective optimization model consisting of the F1 measure, recommendation novelty, recommendation coverage, customer satisfaction, landmark similarity, and overfitting is constructed for recommendation. Then, to improve the recommendation performance, we propose to use a large-scale many-objective optimization algorithm based on problem transformation (LSMaOA) to optimize the matrix factorization model for the recommender system in the intelligent IoT systems. The experimental results show that LSMaOA is robust and can effectively optimize the model’s six objectives. Compared with the knee point-driven evolutionary algorithm (KnEA), the grid-based evolutionary algorithm (GrEA), the large-scale multiobjective optimization framework (LSMOF), and the reference vector guided evolutionary algorithm (RVEA), the proposed algorithm can promote the F1 measure by 7.78%, 13.63%, 21.85%, and 28.63%, respectively.","2327-4662","","10.1109/JIOT.2021.3104661","National Natural Science Foundation of China(grant numbers:61976242,61902203); National Science Fund of Hebei Province for Distinguished Young Scholars(grant numbers:F2021202010); Fundamental Scientific Research Funds for Interdisciplinary Team of Hebei University of Technology(grant numbers:JBKYTD2002); Key Research and Development Plan—Major Scientific and Technological Innovation Projects of ShanDong Province(grant numbers:2019JZZY020101); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9513248","Intelligent Internet of Things (IoT) systems;Internet of Things (IoT);large-scale many-objective optimization;recommender system","Optimization;Recommender systems;Internet of Things;Matrix decomposition;Evolutionary computation;Pareto optimization;Convergence","","43","","37","IEEE","13 Aug 2021","","","IEEE","IEEE Journals"
"Federated Anomaly Detection on System Logs for the Internet of Things: A Customizable and Communication-Efficient Approach","B. Li; S. Ma; R. Deng; K. -K. R. Choo; J. Yang","School of Cyber Science and Engineering, Sichuan University, Chengdu, China; School of Cyber Science and Engineering, Sichuan University, Chengdu, China; State Key Laboratory of Industrial Control Technology and the College of Control Science and Engineering, Zhejiang University, Hangzhou, China; Department of Information Systems and Cyber Security, University of Texas at San Antonio, San Antonio, TX, USA; School of Cyber Science and Engineering, Sichuan University, Chengdu, China","IEEE Transactions on Network and Service Management","9 Jun 2022","2022","19","2","1705","1716","Runtime log-based anomaly detection is one of several key building blocks in ensuring system security, as well as post-incident forensic investigations. However, existing log-based anomaly detection approaches that are implemented on large-scale Internet of Things (IoT) systems generally upload local data from edge devices to a centralized (cloud) server for processing and analysis. Such a workflow incurs significant communication and computation overheads, with potential privacy implications. Hence, in this paper, we propose a customizable and communication-efficient federated anomaly detection scheme (hereafter referred to as FedLog), designed to facilitate the identification of abnormal log patterns in large-scale IoT systems. Specifically, we first craft a Temporal Convolutional Network-Attention Mechanism-based Convolutional Neural Network (TCN-ACNN) model, to effectively extract fine-grained features from system logs. Second, we develop a new federated learning framework to support IoT devices in establishing a comprehensive anomaly detection model in a collaborative and privacy-preserving manner. Third, a lottery ticket hypothesis based masking strategy is designed to achieve customizable and communication-efficient federated learning in handling non-Independent and Identically Distributed (non-IID) log datasets. We then evaluate the performance of our proposed scheme with those of DeepLog (published in CCS, 2017) and Loganomaly (published in IJCAI, 2019) in both centralized learning and federated learning settings, using two publicly available and widely used real-world datasets (i.e., HDFS and BGL). The findings demonstrate the utility of the proposed FedLog scheme, in terms of log-based anomaly detection.","1932-4537","","10.1109/TNSM.2022.3152620","National Key Research and Development Program of China(grant numbers:2020YFB1805400); National Natural Science Foundation of China(grant numbers:62002248,U19A2068,62073285,62061130220,61872254,62162057); Natural Science Foundation of Zhejiang Province(grant numbers:LZ21F020006); Cloud Technology Endowed Professorship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9716881","Log analysis;Internet of Things (IoT);federated learning;data privacy;artificial intelligence","Collaborative work;Anomaly detection;Servers;Data models;Feature extraction;Training;Distributed databases","","12","","38","IEEE","18 Feb 2022","","","IEEE","IEEE Journals"
"Inter-BIN: Interaction-Based Cross-Architecture IoT Binary Similarity Comparison","Q. Song; Y. Zhang; B. Wang; Y. Chen","Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China","IEEE Internet of Things Journal","6 Oct 2022","2022","9","20","20018","20033","The big wave of Internet of Things (IoT) malware reflects the fragility of the current IoT ecosystem. Research has found that IoT malware can spread quickly on devices of different processer architectures, which leads our attention to cross-architecture binary similarity comparison technology. The goal of binary similarity comparison is to determine whether the semantics of two binary snippets is similar. Existing learning-based approaches usually learn the representations of binary code snippets individually and perform similarity matching based on the distance metric, without considering interbinary semantic interactions. Moreover, they often rely on the large-scale external code corpus for instruction embeddings pretraining, which is heavyweight and easy to suffer the out-of-vocabulary (OOV) problem. In this article, we propose an interaction-based cross-architecture IoT binary similarity comparison system, Inter-BIN. Our key insight is to introduce interaction between instruction sequences by co-attention mechanism, which can flexibly perform soft alignment of semantically related instructions from different architectures. And we design a lightweight multifeature fusion-based instruction embedding method, which can avoid the heavy workload and the OOV problem of previous approaches. Extensive experiments show that Inter-BIN can significantly outperform state-of-the-art approaches on cross-architecture binary similarity comparison tasks of different input granularities. Furthermore, we present an IoT malware function matching data set from real network environments, CrossMal, containing 1878437 cross-architecture reuse function pairs. Experimental results on CrossMal prove that Inter-BIN is practical and scalable on real-world binary similarity comparison collections.","2327-4662","","10.1109/JIOT.2022.3170927","National Key Research and Development Program of China(grant numbers:2018YFB0804704); National Natural Science of China(grant numbers:U1736218); Beijing Municipal Science and Technology Commission(grant numbers:Z191100007119005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9764817","Binary analysis;code similarity comparison;cross-architecture interaction;deep neural network;Internet of Things (IoT) malware","Codes;Semantics;Malware;Internet of Things;Feature extraction;Computer architecture;Vocabulary","","4","","37","IEEE","28 Apr 2022","","","IEEE","IEEE Journals"
"Towards Developing a Global Federated Learning Platform for IoT","H. Safri; M. M. Kandi; Y. Miloudi; C. Bortolaso; D. Trystram; F. Desprez","Berger-Levrault, Toulouse, France; Berger-Levrault, Toulouse, France; CARL - Berger-Levrault, Toulouse, France; Berger-Levrault, Toulouse, France; INRIA-LIG, University Grenoble Alpes, Grenoble, France; INRIA, Grenoble, France","2022 IEEE 42nd International Conference on Distributed Computing Systems (ICDCS)","13 Oct 2022","2022","","","1312","1315","Federated learning (FL) is an approach that enables collaborative machine learning (ML) without sharing data over the network. Internet of Things (IoT) and Industry 4.0 are promising areas for FL adoption. Nevertheless, there are several challenges to overcome before the deployment of FL methods in existing large-scale IoT environments. In this paper, we present one step further toward the adoption of FL systems for IoT. More specifically, we developed a prototype that enables distributed ML model deployment, federated task orchestration, and monitoring of system state and model performance. We tested the prototype on a network that contains multiple Raspberry Pi for a use case of modeling the states of conveyors in an airport.","2575-8411","978-1-6654-7177-0","10.1109/ICDCS54860.2022.00145","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9912211","Internet of Things;Federated Learning;FL Task Orchestration;Deployed Model Monitoring","Training;Adaptation models;Federated learning;Atmospheric modeling;Prototypes;Information sharing;Fourth Industrial Revolution","","1","","5","IEEE","13 Oct 2022","","","IEEE","IEEE Conferences"
"Data Management Mechanisms for IoT: Architecture, Challenges and Solutions","B. Diène; O. Diallo; J. J. P. C. Rodrigues; E. H. M. Ndoye; C. Teodorov","Department of Informatics, University of Assane Seck, Ziguinchor, Senegal; Department of Informatics, University of Assane Seck, Ziguinchor, Senegal; Federal University of Piauí (UFPI), Teresina, PI, Brazil; Department of Informatics, University of Assane Seck, Ziguinchor, Senegal; Lab-STICC UMR CNRS 6285 ENSTA, Bretagne, France","2020 5th International Conference on Smart and Sustainable Technologies (SpliTech)","4 Nov 2020","2020","","","1","6","The current traditional database management mechanisms and analytics architectures are not generally suitable for addressing the intrinsic characteristics of diversity, heterogeneity, large-scale, dynamic and large amount of data generated by the Internet of Things (IoT) networks and various IoT applications needs. Then, it is challenging to provide efficient IoT data storage and query processing mechanisms for meeting the requirements of applications. This paper identifies the most relevant characteristics and mechanisms of IoT data management and categorizes them. Moreover, a new four layers fog-based architecture using the distributed approach is proposed for providing a secure storage infrastructure and efficient real-time IoT data discovering with better latency. Finally, this work shows advances on IoT data management mechanisms, highlights their advantages and limits, and discusses the challenging open research issues that need to be focused for providing guidelines for new contributions.","","978-953-290-105-4","10.23919/SpliTech49282.2020.9243728","Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9243728","Data management;Internet of Things;IoT data types;architecture;Key challenges;Solutions","Query processing;Memory;Distributed databases;Real-time systems;Internet of Things;Secure storage;Guidelines","","1","","19","","4 Nov 2020","","","IEEE","IEEE Conferences"
"Fully Automatic Gym Exercises Recording: An IoT Solution","S. Bian; A. Rupp; M. Magno","ETH Zürich PBL-DITET, Zürich, Switzerland; ETH Zürich PBL-DITET, Zürich, Switzerland; ETH Zürich PBL-DITET, Zürich, Switzerland","2023 IEEE International Workshop on Metrology for Industry 4.0 & IoT (MetroInd4.0&IoT)","18 Jul 2023","2023","","","310","314","In recent years, working out in the gym has gotten increasingly more data-focused and many gym enthusiasts are recording their exercises to have a better overview of their historical gym activities and to make a better exercise plan for the future. As a side effect, this recording process has led to a lot of time spent painstakingly operating these apps by plugging in used types of equipment and repetitions. This project aims to automate this process using an Internet of Things (IoT) approach. Specifically, beacons with embedded ultra-low-power inertial measurement units (IMUs) are attached to the types of equipment to recognize the usage and transmit the information to gym-goers and managers. We have created a small ecosystem composed of beacons, a gateway, smartwatches, android/iPhone applications, a firebase cloud server, and a dashboard, all communicating over a mixture of Bluetooth and Wifi to distribute collected data from machines to users and gym managers in a compact and meaningful way. The system we have implemented is a working prototype of a bigger end goal and is supposed to initialize progress toward a smarter, more efficient, and still privacy-respect gym environment in the future. A small-scale real-life test shows 94.6% accuracy in user gym session recording, which can reach up to 100% easily with a more suitable assembling of the beacons. This promising result shows the potential of a fully automatic exercise recording system, which enables comprehensive monitoring and analysis of the exercise sessions and frees the user from manual recording. The estimated battery life of the beacon is 400 days with a 210 mAh coin battery. We also discussed the shortcoming of the current demonstration system and the future work for a reliable and ready-to-deploy automatic gym workout recording system.","","979-8-3503-9657-7","10.1109/MetroInd4.0IoT57462.2023.10180177","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10180177","Workouts recording;Exercise recording;Internet of Things","Visualization;Logic gates;Recording;Batteries;Internet of Things;Servers;Reliability","","","","16","IEEE","18 Jul 2023","","","IEEE","IEEE Conferences"
"Large Scale Firmware Analysis For Open Source Components, Hard Coding and Weak Passwords","S. Quanjiang; S. Yan; Y. Xiaohu; L. Tinghui; H. Daojing; Y. Guisong","State Grid Shanghai Municipal Electrical Power Research Institute, Shanghai, China; State Grid Shanghai Municipal Electrical Power Research Institute, Shanghai, China; School of software engineering, East China Normal University, Shanghai, China; School of software engineering, East China Normal University, Shanghai, China; School of software engineering, East China Normal University, Shanghai, China; Department of Computer Science and Engineering, University of Shanghai for Science and Technology, Shanghai, China","2021 IEEE International Conference on Consumer Electronics and Computer Engineering (ICCECE)","5 Feb 2021","2021","","","232","236","In recent years, Internet of things security incidents occur frequently, which has threatened the stability of the country, society and personal privacy. As the core of Internet of things equipment system, the security of firmware is very important. In order to design a more reasonable and effective firmware security detection method, the firmware needs to be analyzed in detail. This paper describes the security objectives of firmware from three aspects of confidentiality, integrity and availability, summarizes and analyzes the firmware attack surface, and carries out relevant verification experiments for each attack surface. In order to solve the tedious steps of firmware format identification, unpacking and key information extraction in the process of large-scale firmware security analysis, a firmware security analysis tool is designed and implemented, and large-scale experimental analysis of firmware is carried out from the perspectives of open-source components, weak passwords and hard coding.","","978-1-7281-8319-0","10.1109/ICCECE51280.2021.9342303","National Natural Science Foundation of China; National Natural Science Foundation of China; Natural Science Foundation of Shanghai; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9342303","firmware;security;experimental analysis","Tools;Encoding;Security;Internet of Things;Surface treatment;Microprogramming;Password","","","","6","IEEE","5 Feb 2021","","","IEEE","IEEE Conferences"
"Energy-Efficient Resource Allocation of Wireless Energy Transfer for the Internet of Everything in Digital Twins","Z. Lv; L. Qiao; R. Nowak","Department of Game Design, Faculty of Arts, Uppsala University, Sweden; Qingdao University, China; Warsaw University of Technology, Poland","IEEE Communications Magazine","17 Aug 2022","2022","60","8","68","73","The work aims to improve the stability of wireless energy transfer (WET) in the Internet of Things (IoT), prolong the service life of wireless devices, and promote green communication. Based on a digital twins (DTs) IoT environment, we depict how to optimize the energy efficiency of large-scale multiple-input multiple-output (MIMO) systems under WET technology. The large-scale distributed antenna array is applied to the wireless sensor network. MIMO can produce extremely narrow beams so that the system reduces interference to other users. Our MIMO system's energy efficiency optimization uses fractional planning and the block coordinate descent algorithm. The simulation results show that the algorithm has the best throughput performance when the maximum transmission power reaches 19 dBm. The total energy consumption of the proposed resource allocation algorithm is only about 9 percent higher than that of the power minimization algorithm. In the case of different maximum transfer powers, the number of iterations in which the proposed algorithm is required to converge is within four. Changes in the number of users cannot affect the convergence performance of the proposed algorithm. After the antenna selection mechanism is introduced, the average power of the energy received by the user is improved notably compared to the case of simply using the largescale distributed antenna array. The research results can reference large-scale MIMO systems' energy efficiency optimization problems under WET conditions in the DTs IoT environment.","1558-1896","","10.1109/MCOM.004.2100990","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9779645","","Wireless sensor networks;Antenna arrays;Wireless communication;Internet of Things;Sensors;Resource management;MIMO communication","","22","","15","IEEE","20 May 2022","","","IEEE","IEEE Magazines"
"Operationalizing Solar Energy Predictions for Sustainable, Autonomous IoT Device Management","F. A. Kraemer; D. Palma; A. E. Braten; D. Ammar","Department of Information Security and Communication Technology, Norwegian University of Science and Technology (NTNU), Trondheim, Norway; Department of Information Security and Communication Technology, Norwegian University of Science and Technology (NTNU), Trondheim, Norway; Department of Information Security and Communication Technology, Norwegian University of Science and Technology (NTNU), Trondheim, Norway; Data Science Team, Emlyon Business School, Écully, France","IEEE Internet of Things Journal","10 Dec 2020","2020","7","12","11803","11814","For sustainable Internet-of-Things (IoT) systems, the solar power prediction is an essential element to optimize performance, allowing devices to schedule energy-intensive tasks in periods with excess energy. In regions with volatile weather, this requires taking the weather forecast into account. The problem is how to provide such solar energy predictions with high accuracy for large-scale IoT systems with various devices in an autonomous way, without manual adaptation effort. We present a detailed study on machine-learning approaches for the prediction of solar power intake for large-scale IoT systems. We examine which machine learning models, feature sets, and sampling rates gain the best results for a medium-term forecasting horizon. We also explore an operational setting in which devices are deployed without prior data and machine learning models are retrained for each sensor continuously as a form of online learning. Our results show that prediction errors can be reduced by 20 % compared to the state of the art, despite strong weather volatility.","2327-4662","","10.1109/JIOT.2020.3002330","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9116936","Device Management;energy harvesting;machine learning;solar energy","Solar energy;Machine learning;Predictive models;Internet of Things;Weather forecasting;Task analysis","","20","","44","IEEE","15 Jun 2020","","","IEEE","IEEE Journals"
"Multiplier Design for Digital Modulator for Wireless Communication Applications","R. Hosamani; T. Yerriswamy; Y. G. Praveen Kumar","Dept. of Electronics and Communication Engg, K.L.E. Institute of Technology, Hubballi, Karnataka, India; Dept. of Computer Science and Engg., K.L.E. Institute of Technology, Hubballi, Karnataka, India; Dept. of Electronics and Communication Engg, SSIT, Tumakuru","2023 IEEE 8th International Conference for Convergence in Technology (I2CT)","23 May 2023","2023","","","1","6","State-of-the-art technologies cannot be implemented without being expedited by very large-scale integration (VLSI) circuits because computational complexity is continuously increasing. For example, application-specific integrated circuits (ASICs) are required for 5G communications to attain data rates above tens of gigabits per second. Systems for the Internet of Things (IoT) must have extremely efficient hardware to support data transfer within a few milliseconds while operating within a constrained power budget. The digital design gives greater flexibility than the analog design since the digital communication modules are robust and also provide significant immunity to noise and interference. We have a multichannel technology known as orthogonal frequency division multiplexing (OFDM) that combines QAM and FDM (OFDM). To offer several bit streams with a high data rate, 64-QAM or 256-QAM are employed in separate frequency channels with OFDM in 5G. The proposed design, QAM is built utilizing several multiplier architectures, including Vedic multipliers and booth multipliers, and performance evaluation is done concerning area and power using ASIC and CMOS Technology. Aim of the proposed multipliers is that they require significantly fewer components as compared to the naive method. Further complexity reductions are achieved. The obtained result shows that the use of the multiplier module will outperform state-of-the-art modulator efficiency. Using cadence tool 32bit and 64bit QAM design and physical parameters area and power efficiency are estimated and tabulated respectively.","","979-8-3503-3401-2","10.1109/I2CT57861.2023.10126154","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10126154","ASIC;IoT;QAM;OFDM;Multipliers","Wireless communication;Power demand;Quadrature amplitude modulation;5G mobile communication;OFDM;Modulation;Very large scale integration","","","","25","IEEE","23 May 2023","","","IEEE","IEEE Conferences"
"Energy-Efficient Over-the-Air Computation for Relay-Assisted IoT Networks","J. Wan; J. Wen; K. Wang; Q. Wu; W. Chen","Shanghai Key Laboratory of Multidimensional Information Processing and the School of Communication and Electronic Engineering, East China Normal University, Shanghai, China; Guangxi Information Center, Guangxi Key Laboratory of Digital Infrastructure, Nanning, China; Shanghai Key Laboratory of Multidimensional Information Processing and the School of Communication and Electronic Engineering, East China Normal University, Shanghai, China; Department of Electronic Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Electronic Engineering, Shanghai Jiao Tong University, Shanghai, China","IEEE Wireless Communications Letters","8 Feb 2024","2024","13","2","481","485","Over-the-air computation (AirComp) utilizes the superposition of wireless multiple access channels (MAC) to achieve efficient data aggregation, which is a very effective way to achieve large-scale data transmission and edge intelligence in the intelligent Internet of Things (IoT). In this letter, we propose an amplify and forward (AF) relay-assisted two-hop AirComp system, where the AF relay is used for forwarding signals from sensors. We present the problem of minimizing the sum power (SP) of the sensors under the constraints of available relay transmit power and data aggregating mean square error (MSE). The original problem includes optimizing transmitter (Tx) scaling factor for the sensors, optimizing Tx scaling factor for the relay, and optimizing receiver (Rx) scaling factor for the fusion center (FC). To address the non-convexity of the objective function and constraints of the optimization problem, we transform the original problem into two sub-problems and solve it by iterative optimization algorithm, and each subproblem can be solved with a closed-form optimal solution. In simulations, our proposed SP minimization scheme outperforms benchmark schemes with different parameter settings.","2162-2345","","10.1109/LWC.2023.3332906","Open Project Program of Guangxi Key Laboratory of Digital Infrastructure(grant numbers:GXDIOP2023002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10318154","Over-the-air computation (AirComp);amplify-and-forward (AF) relay;multi-tier computing;optimization","Relays;Optimization;Power demand;Data communication;Wireless sensor networks;Transforms;Internet of Things","","","","14","IEEE","15 Nov 2023","","","IEEE","IEEE Journals"
"Photovoltaics Performance Evaluation Using IoT Technology","M. S. a. -l. B. Singh; N. M. Nor; T. B. Ibrahim; M. Z. Rahman","Electrical and Electronics Engineering, Universiti Teknologi PETRONAS, Seri Iskandar, Perak, Malaysia; Electrical and Electronics Engineering, Universiti Teknologi PETRONAS, Seri Iskandar, Perak, Malaysia; Electrical and Electronics Engineering, Universiti Teknologi PETRONAS, Seri Iskandar, Perak, Malaysia; Electrical and Electronics Engineering, Universiti Teknologi PETRONAS, Seri Iskandar, Perak, Malaysia","2022 International Conference on Future Trends in Smart Communities (ICFTSC)","10 Feb 2023","2022","","","176","181","The excessive utilization of non-renewable energy sources to fulfill the energy demands of the world, particularly in the electricity generation sector, has brought upon dire effects to the Earth’s ecosystems. To reduce the dependence on non-renewable energy sources, the Malaysian government has pushed for the utilization of solar photovoltaics (PV) to produce electricity for the nation. This initiative is present in both utility scale, via the Large-Scale Solar (LSS) scheme, and domestic scale via the Net Metering (NEM) scheme. Contained in this paper is the elaboration on the utilization of Internet-of-Things (IoT) technology to evaluate the performance of PV on the domestic scale. A prototype is designed to collect data, which will then feed the data into an algorithm which will provide an evaluation of the health of a PV system. Two experiments were conducted to determine the if the integration of the mathematical model, algorithm, software, and hardware would produce a prototype can provide accurate results. The experiments conducted provided conclusive results that the data collected by the prototype is accurate as it is able to detect PV performance issues, and the results were verified via manual measurements.","","979-8-3503-3454-8","10.1109/ICFTSC57269.2022.10040053","PETRONAS; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10040053","IoT;PV;solar;electricity;evaluation;renewable energy;green technology;photovoltaics","Photovoltaic systems;Renewable energy sources;Smart cities;Software algorithms;Prototypes;Mathematical models;Software","","","","7","IEEE","10 Feb 2023","","","IEEE","IEEE Conferences"
"Towards Scalable Optimization of Large-Scale IoT Access for Mobile Users with Diverse Requirements","V. Marbukh","National Institute of Standards & Technology, Gaithersburg, MD","2020 IEEE 31st Annual International Symposium on Personal, Indoor and Mobile Radio Communications","8 Oct 2020","2020","","","1","6","Fog computing is an emerging architecture, which extends the Cloud computing paradigm to the edge of the network, enabling new applications and services, including Internet of Things (IoT). End users have certain computation tasks, which can be completed either locally on the end device or remotely on an accessible Fog node via computation offloading. The access is wireless with severe physical limitations on the access network capacity to sustain stringent latency requirements for streaming and real-time applications. Robust access can be provided by maintaining connectivity to several Fog nodes. We propose a scalable access network management scheme, which intends to approximately maximizes the aggregate utility for large-scale networks comprised of a large number of Fog nodes and mobile users with vastly different bandwidth requirements and transmission power restrictions. Scalability is due to a two-level architecture, where each user only communicates with the ""closest"" Fog nodes, while different Fog nodes exchange aggregated information on the intercell interference. Future research should address accuracy and possible improvements to the approximations. We also plan to incorporate robustness constraints requiring connectivity to multiple Fog nodes.","2166-9589","978-1-7281-4490-0","10.1109/PIMRC48278.2020.9217226","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9217226","Fog network;mobile users;utility maximization;resource management;pricing;approximation","Interference;Computer architecture;Optimization;Edge computing;Signal to noise ratio;Land mobile radio;Cloud computing","","","","15","USGov","8 Oct 2020","","","IEEE","IEEE Conferences"
"Design and Analysis of IoT based Air Quality Monitoring System","A. Kumar; M. Kumari; H. Gupta","CEA Deaprtment, GLA University, Mathura, India; CEA Deaprtment, GLA University, Mathura, India; CEA Deaprtment, GLA University, Mathura, India","2020 International Conference on Power Electronics & IoT Applications in Renewable Energy and its Control (PARC)","7 May 2020","2020","","","242","245","Recent aggressive scientific and technological developments all these focus on a global environmental issue considering air quality system, reveals the fact that India is facing severe health hazards. In recent reports, more than 10 cities in India are listed on top. The air quality index (AQI) in India launched in 2014 under Swachh Bharat Abhiyan monitors air pollution on 10 scales ranging from low (green) to moderate (yellow) to serious (red) through data analysis of various air contaminating matters like pm 2.5, O3, NO2, SO2, CO. The present paper develops an Internet of Things (IoT) that enabled air quality monitoring system mobile in nature analyzing real-time surrounding data measuring Carbon Monoxide, Smoke and PM level. The system can measure local area air contamination and generate analyzed data based on which it alerts the people through a buzzer device integrated into the system. The user-friendly and easy handling of the system technology is such that it can be installed in houses and in small places.","","978-1-7281-6575-2","10.1109/PARC49193.2020.236600","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9087064","AQI;IoT;NodeMCU;MQ2;Air Monitoring;Air Quality Monitoring System","","","25","","10","IEEE","7 May 2020","","","IEEE","IEEE Conferences"
"Applying IoT Platform to Design a Data Collection System for Hybrid Power System","V. -T. Ngo; M. -S. Nguyen Thi; D. -N. Truong; A. -Q. Hoang; P. -N. Tran; N. -A. Bui","Hochiminh City University of Technology and Education, Ho Chi Minh City, Vietnam; Hochiminh City University of Technology and Education, Ho Chi Minh City, Vietnam; Hochiminh City University of Technology and Education, Ho Chi Minh City, Vietnam; Hochiminh City University of Technology and Education, Ho Chi Minh City, Vietnam; Hochiminh City Vocational College, Ho Chi Minh City, Vietnam; College of Technology II, Ho Chi Minh City, Vietnam","2021 International Conference on System Science and Engineering (ICSSE)","20 Sep 2021","2021","","","181","184","For monitoring the energy supply from the hybrid small-scale wind turbine generators and rooftop solar power systems, this paper presents the design of a management program for the studied system based on the Internet of Things (IoT) technology. The proposed system consists of digital power meters that communicate wirelessly to the Programmable Logic Controller (PLC) through the ZigBee communication standard. Using a free cloud platform will greatly facilitate the Supervisory Control and Data Acquisition (SCADA) interface design work for a Human Machine Interface (HMI) or mobile phone. This system configuration may be easy to be fit to collect electrical information such as voltage, current, power, frequency, and energy extract from the designed system to be monitored.","2325-0925","978-1-6654-4848-2","10.1109/ICSSE52999.2021.9538442","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9538442","ZigBee;IoT;SCADA;hybrid power system;wind turbine generators;rooftop solar power systems","Meters;Programmable logic devices;Zigbee;SCADA systems;Hybrid power systems;Mobile handsets;Wind turbines","","1","","14","IEEE","20 Sep 2021","","","IEEE","IEEE Conferences"
"An IoT based solar powered aquaponics system","A. P. Murdan; A. Joyram","Electrical and Electronics Engineering Dept, University of Mauritius, Réduit, Mauritius; Electrical and Electronics Engineering Dept, University of Mauritius, Réduit, Mauritius","2021 13th International Conference on Electronics, Computers and Artificial Intelligence (ECAI)","23 Aug 2021","2021","","","1","6","Aquaponics represent a viable and sustainable solution for food security for the whole world. Today, in the era of internet of things (IoT) and artificial intelligence (AI), smart, cloud-connected aquaponics have become a reality. Monitoring and control of aquaponics can be remotely done on mobile devices. In this paper, we present the design and implementation of a small-scale (domestic) solar-powered aquaponics system with wireless monitoring that allows the user monitor data from sensors and also remotely control a few actuators. The work is based on low cost microcontrollers and sensors as well as an open source online database. A notification system was set-up so that the user is informed whenever there is an emergency situation in the system. Since the power is derived from a PV panel, the system is totally independent in terms of power consumption, so it can be placed anywhere with sufficient solar irradiance. The system was thoroughly tested and results were conclusive.","","978-1-6654-2534-6","10.1109/ECAI52376.2021.9515023","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9515023","Aquaponics;Arduino;Integrated Development Environment;microcontroller;Android","Wireless communication;Wireless sensor networks;Power demand;Microcontrollers;Sensor systems;Mobile handsets;Internet of Things","","","","13","IEEE","23 Aug 2021","","","IEEE","IEEE Conferences"
"Variational Few-Shot Learning for Microservice-Oriented Intrusion Detection in Distributed Industrial IoT","W. Liang; Y. Hu; X. Zhou; Y. Pan; K. I. -K. Wang","School of Frontier Crossover Studies, Hunan University of Technology and Business, Changsha, China; School of Frontier Crossover Studies, Hunan University of Technology and Business, Changsha, China; Faculty of Data Science, Shiga University, Hikone, Japan; Department of Computer Science, Georgia State University, Atlanta, GA, USA; Department of Electrical, Computer, and Software Engineering, University of Auckland, Auckland, New Zealand","IEEE Transactions on Industrial Informatics","10 May 2022","2022","18","8","5087","5095","Along with the popularity of the Internet of Things (IoT) techniques with several computational paradigms, such as cloud and edge computing, microservice has been viewed as a promising architecture in large-scale application design and deployment. Due to the limited computing ability of edge devices in distributed IoT, only a small scale of data can be used for model training. In addition, most of the machine-learning-based intrusion detection methods are insufficient when dealing with imbalanced dataset under limited computing resources. In this article, we propose an optimized intra/inter-class-structure-based variational few-shot learning (OICS-VFSL) model to overcome a specific out-of-distribution problem in imbalanced learning, and to improve the microservice-oriented intrusion detection in distributed IoT systems. Following a newly designed VFSL framework, an intra/inter-class optimization scheme is developed using reconstructed feature embeddings, in which the intra-class distance is optimized based on the approximation during a variation Bayesian process, while the inter-class distance is optimized based on the maximization of similarities during a feature concatenation process. An intelligent intrusion detection algorithm is, then, introduced to improve the multiclass classification via a nonlinear neural network. Evaluation experiments are conducted using two public datasets to demonstrate the effectiveness of our proposed model, especially in detecting novel attacks with extremely imbalanced data, compared with four baseline methods.","1941-0050","","10.1109/TII.2021.3116085","National Natural Science Foundation of China(grant numbers:91846301,71790615,62072171); National Key R&D Program of China(grant numbers:2017YFE0117500,2019YFE0190500); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9551702","Distributed Internet of Things (IoT);few-shot learning;imbalanced data;intrusion detection;out-of-distribution;variational feature representation","Intrusion detection;Data models;Training;Feature extraction;Training data;Distributed databases;Deep learning","","79","","30","CCBY","28 Sep 2021","","","IEEE","IEEE Journals"
"A Cost-Efficient Auto-Scaling Algorithm for Large-Scale Graph Processing in Cloud Environments with Heterogeneous Resources","S. Heidari; R. Buyya","Cloud Computing and Distributed Systems (CLOUDS) Laboratory, School of Computing and Information Systems, University of Melbourne, Parkville, VIC, Australia; Cloud Computing and Distributed Systems (CLOUDS) Laboratory, School of Computing and Information Systems, University of Melbourne, Parkville, VIC, Australia","IEEE Transactions on Software Engineering","12 Aug 2021","2021","47","8","1729","1741","Graph processing model is being adopted extensively in various domains such as online gaming, social media, scientific computing and Internet of Things (IoT). Since general purpose data processing tools such as MapReduce are shown to be inefficient for iterative graph processing, many frameworks have been developed in recent years to facilitate analytics and computing of large-scale graphs. However, regardless of distributed or single machine based architecture of such frameworks, dynamic scalability is always a major concern. It becomes even more important when there is a correlation between scalability and monetary cost - similar to what public clouds provide. The pay-as-you-go model that is used by public cloud providers enables users to pay only for the number of resources they utilize. Nevertheless, processing large-scale graphs in such environments has been less studied and most frameworks are implemented for commodity clusters where they will not be charged for the resources that they consume. In this paper, we have developed algorithms to take advantage of resource heterogeneity in cloud environments. Using these algorithms, the system can automatically adjust the number and types of virtual machines according to the computation requirements for convergent graph applications to improve the performance and reduce the monetary cost of the entire operation. Also, a smart profiling mechanism along with a novel dynamic repartitioning approach helps to distribute graph partitions expeditiously. It is shown that this method outperforms popular frameworks such as Giraph and decreases more than 50 percent of the dollar cost compared to Giraph.","1939-3520","","10.1109/TSE.2019.2934849","ARC Future Fellowship; ARC Discovery; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798698","Cloud computing;large-scale graph processing;auto-scaling;cost saving;heterogeneous resources","Cloud computing;Scalability;Computational modeling;Internet of Things;Heuristic algorithms;Software algorithms;Clustering algorithms","","2","","47","IEEE","14 Aug 2019","","","IEEE","IEEE Journals"
"Media Access Control in Large-Scale Internet of Things: A Review","P. Z. Sotenga; K. Djouani; A. M. Kurien","Department of Electrical Engineering, Tshwane University of Technology, Pretoria, South Africa; LISSI Lab, Université Paris-Est Créteil, Créteil, France; Department of Electrical Engineering, Tshwane University of Technology, Pretoria, South Africa","IEEE Access","30 Mar 2020","2020","8","","55834","55859","The Media Access Control (MAC) serves as an imperative part of wireless communication networks which enables efficient provisioning of communication resources for device interconnectivity and ensures Quality of Service (QoS). The emergence of Large-Scale Internet of Things (LS-IoT) networks is characterised by a multi-domain distributed wireless communication network that provides end-to-end connectivity for a multitude of active heterogeneous Machine-to-Machine (M2M) devices. The nature of LS-IoT networks requires robust and scalable MAC protocols to manage concurrent, dynamic and massive media access and resource allocation. Several reviews have been conducted on MAC protocols with a handful of them focused on LS-IoT networks or massive M2M networks. In this paper, the characterisation of LS-IoT networks and the MAC component are extensively discussed delineating the impact of LS-IoT on the MAC. Emerging research issues on the MAC for LS-IoT networks including high collision probability, high control overheads, spectrum constraints, timing constraints, hardware constraints, energy consumption and hidden terminals are discussed. Some recently proposed solutions in literature for enhancing the MAC in LS-IoT networks are discussed under LS-IoT specific MAC protocol enhancement classifications. The contributions and drawbacks of the recent solutions in literature are discussed and summarised. The Future direction that is oriented towards the use of virtualisation within the framework of Network Function Virtualisation (NFV) and Software-Defined Networking (SDN) approaches is proposed. This is aimed at providing a dynamic distributed multidimensional MAC resource scaling approach for LS-IoT access network devices to ensure a robust and effective MAC for massive M2M devices in LS-IoT networks.","2169-3536","","10.1109/ACCESS.2020.2982357","National Research Foundation (NRF) of South Africa(grant numbers:90604); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9043545","Large-scale Internet of Things (LS-IoT);machine-to-machine (M2M) communication;media access control (MAC);wireless networks","Machine-to-machine communications;Media Access Protocol;Cloud computing;Data centers;Quality of service","","16","","101","CCBY","20 Mar 2020","","","IEEE","IEEE Journals"
"Alleviating Heterogeneity in SDN-IoT Networks to Maintain QoS and Enhance Security","K. Sood; K. K. Karmakar; S. Yu; V. Varadharajan; S. R. Pokhrel; Y. Xiang","School of Information Technology, Deakin University, Geelong, Australia; School of Electrical Engineering and Computing, University of Newcastle, Callaghan, Australia; School of Computer Science, University of Technology Sydney, Ultimo, Australia; School of Electrical Engineering and Computing, University of Newcastle, Callaghan, Australia; School of Information Technology, Deakin University, Geelong, Australia; School of Information Technology, Deakin University, Geelong, Australia","IEEE Internet of Things Journal","10 Jul 2020","2020","7","7","5964","5975","Software-defined networks (SDNs) offer unique and attractive solutions to solve challenging management issues in Internet of Things (IoT)-based large-scale multi-technological networks. SDN-IoT network collaboration is innovative and attractive but expected to be extremely heterogeneous in future generation IoT systems. For example, multi-technology network, network externality, and nodes heterogeneity in SDN-IoT may seriously affect the flow or application-specific quality-of-service (QoS) requirements. Furthermore, it highly influences security adoption in a network of interconnected IoT nodes. We observe that both QoS and security are interdependent and nonnegligible factors, thus we emphasize that in order to alleviate heterogeneity it is inevitable to study both these factors hand to hand (or vice versa). With this aim, first, we discuss significant and reasonable cases to encourage researchers to study QoS and security integrally in order to alleviate heterogeneity at SDN-IoT control plane. Second, we propose a framework which successfully transforms the m heterogeneous controllers to n homogeneous controller groups. The key metric of our observation and analysis is the SDN controller's response time. Following this, to validate our approach, we use the mathematical model and a proof of concept (PoC) in a virtual SDN ecosystem is demonstrated. From performance evaluation, we observe that the proposed framework significantly alleviates heterogeneity which helps to maintain QoS and enhance security. This fundamental analysis will enable network security individuals to deal heterogeneity, QoS, and security, of SDN-IoT, in more successful and promising ways.","2327-4662","","10.1109/JIOT.2019.2959025","NSF China(grant numbers:61728201); Australia ARC(grant numbers:DP180102828,DP200101374); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8931600","Heterogeneous networks;Internet of Things (IoT);quality-of-service (QoS);security;software-defined networking","Quality of service;Security;Internet of Things;Time factors;Heterogeneous networks;Measurement;Communication networks","","32","","38","IEEE","12 Dec 2019","","","IEEE","IEEE Journals"
"Backscatter Sensors Communication for 6G Low-Powered NOMA-Enabled IoT Networks Under Imperfect SIC","M. Ahmed; W. U. Khan; A. Ihsan; X. Li; J. Li; T. A. Tsiftsis","College of Computer Science and Technology, Qingdao University, Qingdao, China; Interdisciplinary Centre for Security, Reliability, and Trust (SnT), University of Luxembourg, Luxembourg City, Luxembourg; School of Computer Science and Electronic Engineering, Bangor University, Bangor, U.K.; School of Physics and Electronic Information Engineering, Henan Polytechnic University, Jiaozuo, China; College of Computer Science and Technology, Qingdao University, Qingdao, China; School of Intelligent Systems Science and Engineering, Jinan University, Zhuhai, China","IEEE Systems Journal","9 Dec 2022","2022","16","4","5883","5893","The combination of nonorthogonal multiple access (NOMA) using power-domain with backscatter communication (BC) is expected to connect large-scale Internet of things (IoT) devices in the future sixth-generation era. This article introduces a BC in a multicell IoT network, where a source in each cell transmits a superimposed signal to its associated IoT devices using NOMA. The backscatter sensor tag (BST) also transmits data to IoT devices by reflecting and modulating the superimposed signal of the source. A new optimization framework is provided that simultaneously optimizes the total power of each source, power allocation coefficient of IoT devices, and RC of BST under imperfect successive interference cancellation decoding. This work aims to maximize the total energy efficiency (EE) of the IoT network subject to the quality of services of each IoT device. The problem is first transformed using the Dinkelbach method and then decoupled into two subproblems. The Karush–Kuhn–Tucker conditions and dual Lagrangian method are employed to obtain efficient solutions. In addition, we also calculate the EE of the conventional NOMA network without BC as a benchmark framework. Simulation results unveil the advantage of our considered NOMA BC network over the conventional NOMA network in terms of system total EE.","1937-9234","","10.1109/JSYST.2022.3194705","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9857750","Backscatter communication (BC);energy effi- ciency;Internet of Things (IoT);nonorthogonal multiple access (NOMA);sixth-generation (6G)","Internet of Things;NOMA;Sensors;Backscatter;Symbiosis;Decoding;Resource management","","19","","37","IEEE","16 Aug 2022","","","IEEE","IEEE Journals"
"The Role of Microservices in the Internet of Things: Applications, Challenges, and Research Opportunities","M. D. Hossain; T. Sultana; G. -W. Lee; E. -N. Huh","Department of Computer Science and Engineering, Kyung Hee University, Yongin-si, South Korea; Department of Computer Science and Engineering, Kyung Hee University, Yongin-si, South Korea; Department of Computer Science and Engineering, Kyung Hee University, Yongin-si, South Korea; Department of Computer Science and Engineering, Kyung Hee University, Yongin-si, South Korea","2023 Fourteenth International Conference on Ubiquitous and Future Networks (ICUFN)","7 Aug 2023","2023","","","901","906","The Internet of Things (IoT) is a rapidly growing field, encompassing various devices and sensors that produce enormous quantities of data. On the other hand, microservices architecture has emerged as a popular solution for developing complex software applications on a large scale. Combining these two technologies has the potential to revolutionize the creation of powerful and scalable IoT applications. By leveraging the benefits of microservices, such as modularity and decoupling, developers can design more flexible, scalable, and resilient IoT systems. In this paper, we present a thorough analysis of the state-of-the-art research regarding the use of microservices in the development of IoT systems. We summarize thirty selected studies and discuss their contributions to the field. Additionally, this paper offers valuable insights into the use of microservices in IoT applications, which can inform the design and development of future IoT systems. Finally, we outline and explain the future research opportunities that the microservices paradigm can offer in the context of the IoT.","2165-8536","979-8-3503-3538-5","10.1109/ICUFN57995.2023.10199497","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10199497","Microservices;Internet of Things (IoT);Monolithic architecture;Edge cloud","Automation;Smart cities;Scalability;Fault tolerant systems;Microservice architectures;Smart homes;Software","","","","34","IEEE","7 Aug 2023","","","IEEE","IEEE Conferences"
"TinyEVM: Off-Chain Smart Contracts on Low-Power IoT Devices","C. Profentzas; M. Almgren; O. Landsiedel","Chalmers University of Technology, Gothenburg, Sweden; Chalmers University of Technology, Gothenburg, Sweden; Chalmers University of Technology, Gothenburg, Sweden","2020 IEEE 40th International Conference on Distributed Computing Systems (ICDCS)","23 Feb 2021","2020","","","507","518","With the rise of the Internet of Things (IoT), billions of devices ranging from simple sensors to smart-phones will participate in billions of micropayments. However, current centralized solutions are unable to handle a massive number of micropayments from untrusted devices. Blockchains are promising technologies suitable for solving some of these challenges. Particularly, permissionless blockchains such as Ethereum and Bitcoin have drawn the attention of the research community. However, the increasingly large-scale deployments of blockchain reveal some of their scalability limitations. Prominent proposals to scale the payment system include off-chain protocols such as payment channels. However, the leading proposals assume powerful nodes with an always-on connection and frequent synchronization. These assumptions require in practice significant communication, memory, and computation capacity, whereas IoT devices face substantial constraints in these areas. Existing approaches also do not capture the logic and process of IoT, where applications need to process locally collected sensor data to allow for full use of IoT micro-payments. In this paper, we present TinyEVM, a novel system to generate and execute off-chain smart contracts based on sensor data. TinyEVM's goal is to enable IoT devices to perform micro-payments and, at the same time, address the device constraints. We investigate the trade-offs of executing smart contracts on low-power IoT devices using TinyEVM. We test our system with 7,000 publicly verified smart contracts, where TinyEVM achieves to deploy 93% of them without any modification. Finally, we evaluate the execution of off-chain smart contracts in terms of run-time performance, energy, and memory requirements on IoT devices. Notably, we find that low-power devices can deploy a smart contract in 215 ms on average, and they can complete an off-chain payment in 584 ms on average.","2575-8411","978-1-7281-7002-2","10.1109/ICDCS47774.2020.00025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9355720","Internet of Things;Blockchain;Smart Contracts;Payment Channels;Off-chain;Ethereum","Performance evaluation;Scalability;Smart contracts;Memory management;Blockchain;Sensor systems and applications;Intelligent sensors","","4","","36","IEEE","23 Feb 2021","","","IEEE","IEEE Conferences"
"An Adaptive Modeling and Performance Evaluation Framework for Edge-Enabled Green IoT Systems","S. Bebortta; D. Senapati; C. R. Panigrahi; B. Pati","Department of Computer Science, Ravenshaw University, Cuttack, India; Department of Computer Science, Ravenshaw University, Cuttack, India; Department of Computer Science, Rama Devi Women’s University, Bhubaneswar, India; Department of Computer Science, Rama Devi Women’s University, Bhubaneswar, India","IEEE Transactions on Green Communications and Networking","23 May 2022","2022","6","2","836","844","The enormous growth in Internet of Things (IoT) has caused large-scale transformation in data acquisition and communication mechanism for conventional IoT systems. The continuously increasing requirements for delay-tolerant delivery of services in IoT applications has led to the emergence of more scalable and energy-efficient computing platforms like edge computing. However, the massive growth in volume of data being offloaded from low-powered IoT devices to the edge has imposed challenges on edge servers in terms of traffic bottlenecks, latency, and wastage of energy. In this view, a Local Data Reduction (LDR) framework is proposed which addresses the latency issues and cost constraints to facilitate energy-efficient processing of IoT data. We exploit the Markovian birth-death process to model edge-based IoT systems and derive performance metrics for the proposed LDR model. We also provide explicit analytical solution for the total expected cost function incurred pertaining to the LDR and without LDR (WLDR) models. Through extensive numerical illustrations we validate our findings and observe that the proposed LDR model outperforms the WLDR model. Hence, the LDR model operates well to meet the Quality of Service (QoS) requirements for real-time IoT systems by favouring green computing paradigms.","2473-2400","","10.1109/TGCN.2021.3127487","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9622744","Internet of Things (IoT);queuing theory;edge computing;green computing;cost optimization","Internet of Things;Servers;Edge computing;Computational modeling;Numerical models;Costs;Cloud computing","","11","","44","IEEE","22 Nov 2021","","","IEEE","IEEE Journals"
"A Reliable IoT Edge Computing Trust Management Mechanism for Smart Cities","B. Wang; M. Li; X. Jin; C. Guo","School of Software Technology, Dalian University of Technology, Dalian, China; School of Software Technology, Dalian University of Technology, Dalian, China; School of Software Technology, Dalian University of Technology, Dalian, China; School of Software Technology, Dalian University of Technology, Dalian, China","IEEE Access","13 Mar 2020","2020","8","","46373","46399","With the development of the Internet of Things (IoT) technology, many end-users participate in the smart city through their own intelligent mobile devices (such as personal wearable devices, smartphones.) or sensors. The main challenge of the device sensing layer in the edge computing system of the IoT in the smart city is to select the trusted participants. Because not all the intelligent devices of the IoT are trustworthy, some intelligent devices of the IoT may maliciously damage the network or services and affect the service quality of the system. On this basis, an intelligent device selective recommendation mechanism based on the dynamic black-and-white list was proposed to solve the problem of selecting trusted participants to improve the service quality of the edge computing system of the IoT in the smart city. We introduced the evolutionary game theory to theoretically qualitatively study the validity and stability of the trust management mechanism proposed in this paper. The Lyapunov theory was used to prove the validity and stability of the trust management mechanism. The effectiveness of the trust management mechanism was verified by the actual scenario of the personal health monitoring management system and the air-quality monitoring and analysis system in the smart city environment. Experiments showed that the trust management mechanism proposed in this paper has a significant role in promoting the cooperation of multi intelligent devices in the IoT edge computing system. It more reliably resists the malicious attacks to service providers and is suitable for the large-scale IoT edge computing system in the smart city.","2169-3536","","10.1109/ACCESS.2020.2979022","National Natural Science Foundation of China(grant numbers:61572095,61877007); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9026905","Edge computing;Internet of Things;malicious attack;smart city;trust management mechanism","Edge computing;Smart cities;Smart devices;Reliability;Sensors","","48","","57","CCBY","6 Mar 2020","","","IEEE","IEEE Journals"
"An Overview of UPnP-based IoT Security: Threats, Vulnerabilities, and Prospective Solutions","G. Kayas; M. Hossain; J. Payton; S. M. R. Islam","Dept. of Computer & Info. Science, Temple University, USA; Dept. of Computer Science, University of Alabama, Birmingham, USA; Dept. of Computer & Info. Science, Temple University, USA; Dept. of Computer Engineering, Sejong University, South Korea","2020 11th IEEE Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON)","22 Dec 2020","2020","","","0452","0460","Advances in the development and increased availability of smart devices ranging from small sensors to complex cloud infrastructures as well as various networking technologies and communication protocols have supported the rapid expansion of Internet of Things deployments. The Universal Plug and Play (UPnP) protocol has been widely accepted and used in the IoT domain to support interactions among heterogeneous IoT devices, in part due to zero configuration implementation which makes it feasible for use in large-scale networks. The popularity and ubiquity of UPnP to support IoT systems necessitate an exploration of security risks associated with the use of the protocol for IoT deployments. In this work, we analyze security vulnerabilities of UPnP-based IoT systems and identify attack opportunities by the adversaries leveraging the vulnerabilities. Finally, we propose prospective solutions to secure UPnP-based IoT systems from adversarial operations.","2644-3163","978-1-7281-8416-6","10.1109/IEMCON51383.2020.9284885","US National Science Foundation (NSF)(grant numbers:CNS-1828363); Sejong University(grant numbers:20192021); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284885","UPnP;IoT;Secure Service Discovery;Secure Service Advertisement;IoT Security","Performance evaluation;Protocols;Mobile communication;Security;Internet of Things;Smart devices;Plugs","","6","","39","IEEE","22 Dec 2020","","","IEEE","IEEE Conferences"
"Towards 6G Networks: Ensemble Deep Learning Empowered VNF Deployment for IoT Services","M. Emu; S. Choudhury","Department of Computer Science, Lakehead University, Thunder Bay, Canada; Department of Computer Science, Lakehead University, Thunder Bay, Canada","2021 IEEE 18th Annual Consumer Communications & Networking Conference (CCNC)","11 Mar 2021","2021","","","1","4","The prospective Internet of Things (IoT) vertical use cases demand latency perception, privacy preservation, and scalability intelligence equipped Virtual Network Function (VNF) orchestration in a dynamic context. With the massive growth of IoT connectivity, smart VNF orchestration with real-time deployment abilities is vital for the ubiquitous digital network environment. Hence, this paper collaboratively considers all the future service orchestration specifications. Moreover, we urge the necessity to go beyond the traditional service deployment framework and introduce VNF allocation at edge cloudlet small scale data-centers. Extensive simulation results manifest the applicability and potential of our proposed deep learning models with the twist of ensemble techniques for automated VNF orchestration. Additionally, our proposed ensemble deep learning aided approach inspires the employment of intelligent orchestrator to address 6G network era challenges for perpetual telecommunication research enigmas.","2331-9860","978-1-7281-9794-4","10.1109/CCNC49032.2021.9369558","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9369558","Internet of Things (IoT);Virtual Network Function;Multi-access edge computing (MEC);Deep Learning;Convolutional Neural Networks;6G","Deep learning;6G mobile communication;Privacy;Adaptation models;Simulation;Scalability;Internet of Things","","3","","11","IEEE","11 Mar 2021","","","IEEE","IEEE Conferences"
"IoT Based Multi-layered Security & Automated Monitoring System","M. K. Syfullah; H. I. Peyal; S. S. Bipro; S. M. Shahriar; M. H. Mondol","Dept. of Electrical & Computer Engineering, Rajshahi University of Engineering & Technology, Rajshahi, Bangladesh; Dept. of Electrical & Computer Engineering, Rajshahi University of Engineering & Technology, Rajshahi, Bangladesh; Dept. of Electrical & Electronic Engineering, Rajshahi University of Engineering & Technology, Rajshahi, Bangladesh; Dept. of Electrical & Computer Engineering, Rajshahi University of Engineering & Technology, Rajshahi, Bangladesh; Dept. of Electronics & Telecommunication Engineering, Rajshahi University of Engineering & Technology, Rajshahi, Bangladesh","2021 International Conference on Computer, Communication, Chemical, Materials and Electronic Engineering (IC4ME2)","10 May 2022","2021","","","1","4","This paper presents a multi-layered security project consisting of laser, ultrasound, heat, fire and gas detection with fault-tolerable monitoring and alarm system, that is fully automated and targeted to achieve minimum cost with maximum effectiveness. It redefines and improves security concepts like automated intruder detection via multiple security layers, such as-Laser and Ultrasonic detection systems. When one security layer fails to provide detection, the other layers remain effective. Also, it provides security monitoring via multiple network layers such as - TCP/IP communication and Blynk server and the monitoring remains active via any of the two layers when the other one fails. Security monitoring has become an essential part of achieving effective security at home and office. But, the cost for popular security solutions like closed-circuit television (CCTV) and internet protocol camera (IPCAM) are very expensive and quite complicated for installation and maintenance. Therefore, the entire project proposed in this paper focuses on developing a sustainable security solution that comes at a minimum cost. In this project, many features of internet of things (IoT) are utilized to design and configure a security system that requires no additional requirements for maintenance once installed. Most importantly, the overall cost of implementing the system is way below any currently available consumer security solutions. Consequently, it becomes easier for the average consumer to afford cost-efficient security systems. The following project is developed in a manner that it can be manufactured on a large scale in future.","","978-1-6654-0637-6","10.1109/IC4ME253898.2021.9768512","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9768512","Control panel;automation;data link layer;NodeMCU;transmission control protocol (TCP)","Wireless communication;Costs;Protocols;Ultrasonic imaging;Computer architecture;Maintenance engineering;Acoustics","","2","","15","IEEE","10 May 2022","","","IEEE","IEEE Conferences"
"IoT-Based Terrace Farming System for Cities","L. J. Ballais; T. N. Sharma; H. W. Thu; S. D. A. P. Sanadeera; A. Taparugssanagorn; M. N. Dailey","Department of Information and Communication Technologies, Asian Institute of Technology, Pathum Thani, Thailand; Department of Information and Communication Technologies, Asian Institute of Technology, Pathum Thani, Thailand; Department of Information and Communication Technologies, Asian Institute of Technology, Pathum Thani, Thailand; Department of Information and Communication Technologies, Asian Institute of Technology, Pathum Thani, Thailand; Department of Information and Communication Technologies, Asian Institute of Technology, Pathum Thani, Thailand; Department of Information and Communication Technologies, Asian Institute of Technology, Pathum Thani, Thailand","2021 25th International Computer Science and Engineering Conference (ICSEC)","27 Jan 2022","2021","","","11","16","Food for cities is traditionally cultivated on a large scale on farmland then transported to the city where it is consumed. The COVID-19 pandemic has in some places disrupted transportation systems, resulting in severe food shortages in some metropolitan areas. Growing plants on a terrace or other sunny areas could provide urban residents with some portion of their food supply and reduce food transportation distance. In this paper, we propose a simple, low-cost, and durable Internet of Things (IoT)-based system for cultivating short-duration vegetables, flowers, and fruits on urban terraces with minimal user attention. The proposed system is capable of monitoring environmental parameters (temperature and humidity) and controlling soil elements such as soil moisture and soil nutrients. The system can be deployed with pre-existing Wi-Fi infrastructure in the farmer's home with or without an internet connection. The proposed terrace farming system is easy to install, scalable, robust in terms of data security, and developed on open-source platforms with cost-effective hardware components.","","978-1-6654-1197-4","10.1109/ICSEC53205.2021.9684609","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9684609","Internet of Things;Food Insecurity;Pandemic;Smart Agriculture;Terrace Farming","Temperature sensors;Temperature measurement;Urban areas;Soil moisture;Transportation;Humidity;Temperature control","","1","","9","IEEE","27 Jan 2022","","","IEEE","IEEE Conferences"
"Functional Programming for the Internet of Things: A LoRa-MQTT Gateway written in Elixir","P. Branch; P. Weinstock","Department of Engineering Technologies, Swinburne University of Technology, Melbourne, Australia; Department of Engineering Technologies, Swinburne University of Technology, Melbourne, Australia","2023 33rd International Telecommunication Networks and Applications Conference","29 Dec 2023","2023","","","214","217","Networks for the Internet of Things typically use a gateway to provide connectivity between a low bit rate, low capability sensor network and the broader Internet. The gateway can be subject to very high traffic loads, many concurrent processes and needs to be highly reliable. Functional programming languages such as Erlang and Elixir have proven to be an effective programming paradigm for such scenarios, notably in large scale telecommunications switches. In this paper we report on our experiences of developing a gateway between a LoRa network and an MQTT broker using the functional programming language Elixir. Our experience suggests that the discipline imposed by functional programming results in a system that is more compact, supports concurrent processes well and is more reliable than similar systems developed using conventional languages. However, we also note that subsystems to support the development of such systems are primitive and that functional programming has a considerably steep learning curve. Nevertheless we conclude that functional programming has considerable potential for the Internet of Things and plan to continue research in this area.","2474-154X","979-8-3503-1713-8","10.1109/ITNAC59571.2023.10368535","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10368535","Internet of Things;Functional Programming;Elixir;LoRa;MQTT","Codes;Protocols;Telecommunication traffic;Logic gates;Libraries;Robustness;Telecommunications","","","","14","IEEE","29 Dec 2023","","","IEEE","IEEE Conferences"
"Design of Laboratory Virtual Environment Monitoring System Based on Digital Internet of Things Technology","Y. Zhu; L. Qin; N. Wu; H. Zhang; B. He; N. He","Qiqihar Medical University, Heilongjiang, China; Qiqihar Medical University, Heilongjiang, China; Qiqihar Medical University, Heilongjiang, China; Qiqihar Medical University, Heilongjiang, China; Qiqihar Medical University, Heilongjiang, China; Qiqihar Medical University, Heilongjiang, China","2023 International Conference on Evolutionary Algorithms and Soft Computing Techniques (EASCT)","22 Jan 2024","2023","","","1","6","In order to meet the requirements of laboratory ventilation and exhaust purification, it is necessary to monitor the laboratory environment in real time. Effective control of all environmental parameters of animal experimental equipment is a key condition to ensure the smooth progress of animal experiments. To address this issue, this paper proposes to construct a virtual laboratory environment monitoring system based on digital Internet of Things (IoT) technology, which can monitor the temperature and humidity, noise level, lighting, air quality and radiation detection in the laboratory in real time, and can be used to ensure that the environment of animal laboratories meets the standards. The system collect real-time data from the laboratory environment using indication sensors and display it on an OLED screen. The system includes threshold setting methods that activate support services such as audible alarms, temperature and humidity monitoring, and fan activation in the event of abnormal conditions. The system take advantages of real-time monitoring from multiple hosts in different locations, unmanned operation and large-scale data storage. The final experimental results show that the sensitivity and specificity of the laboratory environment monitoring system based on this technique are 95% and 93% respectively, which are higher than other algorithms.","","979-8-3503-1341-3","10.1109/EASCT59475.2023.10392673","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10392673","laboratory environmental monitoring system;virtualization of laboratory;digital internet of things technology;sensing technology","Temperature sensors;Temperature measurement;Animals;Laboratories;Humidity;Real-time systems;Security","","","","20","IEEE","22 Jan 2024","","","IEEE","IEEE Conferences"
"Situation-Aware Hybrid Time Synchronization Based on Multi-Source Timestamping Uncertainty Modeling","H. Wang; P. Jia; X. Wang","Department of Electrical and Computer Engineering, Western University, London, Canada; Department of Electrical and Computer Engineering, Western University, London, Canada; Department of Electrical and Computer Engineering, Western University, London, Canada","2022 IEEE 96th Vehicular Technology Conference (VTC2022-Fall)","18 Jan 2023","2022","","","1","5","Timestamping accuracy is of the utmost importance to achieve accurate time synchronization of large-scale connected systems. However, the heterogeneity and complexity inherent to Internet of Things (IoT) systems lead to multi-source timestamping uncertainties and significantly deteriorate performance of traditional inflexible synchronization methods. In this paper, a situation-aware hybrid time synchronization protocol is designed based on multi-source timestamping uncertainty modeling and integrated time information exchange mechanism for heterogeneous IoT systems. More specifically, the multi-source timestamping error inherent to the overall synchronization process are accurately modeled by exploring the impact of the multi-faceted operating conditions. By analyzing the real-time timestamping uncertainties, a hybrid time synchronization scheme is actualized, which can achieve optimal synchronization strategy for clock parameters estimation. In addition, an integrated time information exchange mechanism is designed to reduce timestamping redundancy during time synchronization. Simulation results show that the proposed scheme can enhance the synchronization accuracy for heterogeneous operating scenarios.","2577-2465","978-1-6654-5468-1","10.1109/VTC2022-Fall57202.2022.10012731","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10012731","Time synchronization;Internet of Things;delay modeling;timestamp uncertainty;skew estimation.","Uncertainty;Protocols;Parameter estimation;Simulation;Redundancy;Real-time systems;Synchronization","","1","","13","IEEE","18 Jan 2023","","","IEEE","IEEE Conferences"
"IoT in Healthcare: Reducing EMS Delivery Time Using IoT & Realtime Geospatial Query Engine","A. K. Pandey; S. Mehta; N. Guruprasad","Department of Computer Science and Engineering, Global Academy of Technology, Bengaluru, Karnataka, India; Department of Information Science and Engineering, Global Academy of Technology, Bengaluru, Karnataka, India; Department of Computer Science and Engineering, Global Academy of Technology, Bengaluru, Karnataka, India","2023 International Conference on IoT, Communication and Automation Technology (ICICAT)","2 Oct 2023","2023","","","1","5","The Internet of Things (IoT) represents a network of interconnected digital devices that communicate wirelessly, enabling data collection, transmission, and storage without the need for human interaction. This paper introduces an innovative approach aimed at reducing fatalities resulting from major accidents on Indian roads by minimizing response time. By leveraging IoT devices such as smartphones and smartwatches, their embedded sensors can detect accident events. Utilizing a real-time geospatial search engine, potential nearby support services can be identified based on the accident's location, effectively reducing response time by eliminating idle periods. Furthermore, the paper explores the transformative potential of 5G technology in revolutionizing the system, enabling real-time monitoring of drivers and addressing existing system vulnerabilities. The paper underscores the urgency of implementing this system and thoroughly explores various user scenarios and expected technological behaviors. To enhance scalability and robustness, the integration of AI and machine learning techniques is proposed, facilitating large-scale deployment. Additionally, the paper delves into the constraints associated with implementing this technology and presents potential solutions to overcome them.","","979-8-3503-0282-0","10.1109/ICICAT57735.2023.10263689","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10263689","EMS (Emergency Medical Services);Support;Smartphone;Smartwatch","Roads;Medical services;Real-time systems;Sensors;Geospatial analysis;Internet of Things;Time factors","","","","11","IEEE","2 Oct 2023","","","IEEE","IEEE Conferences"
"Industrial Internet of Things: A Cyber Security Perspective Investigation","F. S. Al-Zahrani; N. Hassan","Computer Science Department, Albaha University, Albaha, Saudi Arabia; Computer Science Department, Albaha University, Albaha, Saudi Arabia","2023 1st International Conference on Advanced Innovations in Smart Cities (ICAISC)","3 Apr 2023","2023","","","1","6","The IIoT arose as a result of the increased automation, dependability, and management that Industry 4.0 introduced to the manufacturing and production sectors. The Internet of Things has the potential to speed up the process of automating several industries, including the automotive, transportation, production, and advertising sectors. Large-scale IIoT systems will have security difficulties when its benefits become clear, leading to repeated large-scale attacks that damage key infrastructure or fraudulent transactions. The system is additionally challenged by the vast quantity of connected devices and the consequent constraints on available resources (such as their battery life, memory, and processing power). Traditional communication and networking flaws are also present in the IIoT, but it takes more work to tailor security solutions to secure critical industrial control systems. These flaws are carried over to the IIoT. While there is some literature on the topics of security, privacy, and trust in IIoT systems, a more thorough examination of the many moving parts that make up an IIoT system is lacking. This study compares IoT security vulnerabilities to solve the problem. We explore several IIoT security difficulties and criteria. We also explore available IIoT designs to rigorously investigate these security threats. We describe viable countermeasures and explain how security weaknesses at any layer of an IIoT architecture affect its functionality. This report proposes future research on trustworthy, large-scale, and secure IIoT systems. The report highlights the multiple IIoT system threats and attacks to improve security awareness.","","978-1-6654-7275-3","10.1109/ICAISC56366.2023.10085080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10085080","Industrial internet of things;security;architecture;threats;attacks;countermeasures","Technological innovation;Transportation;Computer architecture;System integration;Control systems;Fourth Industrial Revolution;Trajectory","","","","44","IEEE","3 Apr 2023","","","IEEE","IEEE Conferences"
"Message Diffusion Using Publish and Subscribe","R. K. Ghosh; H. Ghosh",NA; NA,"Distributed Systems: Theory and Applications","","2023","","","283","307","Many distributed applications, particularly for embedded and Internet of things (IoT) networks, require a message diffusion model, where information collected from many data sources is delivered to millions of clients according to their interests. We know about three information diffusion models, IP multicast, peer‐to‐peer (P2P) overlay, and gossip. However, these models require substantial resources or apply to a small domain. The other possibility is to use the publish–subscribe model together with event‐action semantics. This messaging model with content brokering addresses the issues of targeted distribution of messages from producers to consumers. Content brokers reduce flooding by applying selective forwarding based on message contents. The concept of message filters is a nice theoretical abstraction through which aggregation of notifications for targeted routing is possible. Integration of IoT to IP networks provides a framework for large‐scale futuristic distributed systems. The objects and their locations in a large‐scale heterogeneous distributed system are often unknown to one another. This scenario typically occurs in machine‐to‐machine (M2M) communication. Advanced message queuing protocol (AMQP) with constrained application protocol (CoAP) or message queue telemetry transport (MQTT) can be used as the message dissemination protocol for the same.","","9781119825944","10.1002/9781119825968.ch11","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10045062.pdf&bkn=10044991&pdfType=chapter","","Soft sensors;Peer-to-peer computing;IP networks;Adaptation models;Task analysis;Servers;Semantics","","","","","","15 Feb 2023","","","IEEE","Wiley-IEEE Press eBook Chapters"
"Fuzzy C-Means based Clustering Algorithm in WSNs for IoT Applications","R. Bensaid; M. Ben Said; H. Boujemaa","National Engineering School of Gabes, ENIG; University of Carthage, Higher School of Communications of Tunis SUPCOM, COSIM Research Lab.; University of Carthage, Higher School of Communications of Tunis SUPCOM, COSIM Research Lab.","2020 International Wireless Communications and Mobile Computing (IWCMC)","27 Jul 2020","2020","","","126","130","Energy efficiency in Wireless Sensor Network (WSN)-based Internet of Things (IoT) systems is a very challenging issue since IoT is becoming more complex due to its large scale deployment. Cluster-based hierarchical routing protocols are used as a very effective tool to forward data among nodes in energy constrained networks. In this paper, we propose a new Fuzzy C-Means (FCM) based clustering algorithm for WSN-based IoT applications. The algorithm considers an FCM approach to form the clusters and the minimization of the overall consumed energy in each cluster to select the optimal Cluster Head (CH) in each transmission round. A comparison with Low Energy Adaptive Clustering Hierarchy (LEACH) protocol is presented to analyze the performance and to validate the proposed algorithm. Results show that the proposed FCM method improves the network lifetime by enhancing the residual energy by 50%.","2376-6506","978-1-7281-3129-0","10.1109/IWCMC48107.2020.9148077","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9148077","WSN;IoT;Clustering;FCM;residual energy","Clustering algorithms;Wireless sensor networks;Base stations;Energy consumption;Protocols;Internet of Things;Fuzzy logic","","10","","12","IEEE","27 Jul 2020","","","IEEE","IEEE Conferences"
"Large-Scale Information and Communications Technology (ICT) Management in Smart Cities based on Edge to Cloud Orchestration","A. Sinaeepourfard; J. Krogstie; T. K. Soltvedt; T. Skuggevik","Department of Computer Science, Norwegian University of Science and Technology (NTNU), Trondheim, Norway; Department of Computer Science, Norwegian University of Science and Technology (NTNU), Trondheim, Norway; Department of Computer Science, Norwegian University of Science and Technology (NTNU); Department of Computer Science, Norwegian University of Science and Technology (NTNU), Trondheim, Norway","2020 International Conference on Omni-layer Intelligent Systems (COINS)","10 Sep 2020","2020","","","1","8","A smart city has changed the city landscape with the assistance of ICT, and sensor-enabled internet of things (IoT) devices. The development of a ubiquitous connected source environment is to be complicated and global to improve service performance delivery, cost-effectiveness, and using all capabilities of technology resources. For gaining those benefits in the smart city, it is necessary to design a capable ICT architecture. The ICT architecture in the smart city must provide the facility to organize all technology resources, the produced data, network communication orchestration, and services in the large scale of smart cities. In today’s smart cities, three main different ICT architecture proposals are available, Centralized, Decentralized-to-Centralized, and Distributed-to-Centralized. Centralized ICT architectures are designed based on Cloud technologies. The Decentralized-to-Centralized and Distributed-to-Centralized ICT architectures are using the multiple facilities from the joined benefits of edge to Cloud technologies orchestration. In this paper, we first describe these three ICT architectures in smart cities. Besides, we present our proposed Decentralized-to-Centralized and Distributed-to-Centralized ICT architectures in smart cities. Second, we show how our ICT architecture can be beneficial for Large-Scale ICT management through different use case studies. Finally, we describe the advantages of our ICT architecture and discuss challenges.","","978-1-7281-6371-0","10.1109/COINS49042.2020.9191685","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9191685","Smart City;Large-Scale IoT Management;Large-Scale ICT Management;Decentralized-to-Centralized ICT Architecture;Distributed-to-Centralized ICT Architecture","Performance evaluation;Cloud computing;Smart cities;Information and communication technology;Internet of Things;Proposals;Intelligent systems","","3","","11","IEEE","10 Sep 2020","","","IEEE","IEEE Conferences"
"Performance- and Energy-Aware Gait-Based User Authentication With Intermittent Computation for IoT Devices","P. Zouridakis; S. M. P. Dinakarrao","Department of Electrical and Computer Engineering, George Mason University, Fairfax, VA, USA; Department of Electrical and Computer Engineering, George Mason University, Fairfax, VA, USA","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","19 Jan 2024","2024","43","2","600","612","Internet of Things (IoT) makes it possible to utilize a multitude of small- and medium-scale devices allowing for increased functionality in flexible networks. However, user authentication on IoT devices is as important as it can be challenging. Due to limitations on the available energy, interface, and processing power, IoT devices can be the weakest link in their networks. Multiple authentication techniques have been developed to address these challenges. However, the existing techniques are limited in terms of performance, overheads, and efficiency. In contrast, our proposed authentication method uses a user’s walking gait as an input, because gait is unique to every user and can be collected using low-power inertial sensors found on all handheld devices. Our authentication method uses a lightweight neural network (NN) which is further complimented with early exits to further optimize computational cost(s). We also propose reinforcement learning that considers the energy consumption to dynamically determine which of the exits should be chosen to strike a balance between performance and computational and energy cost. Though effective, one of the challenges with IoT devices is their power supply such as dependence on batteries. Discharge of the battery or any other interruptions can lead to recomputations, which are expensive on already limited battery-operated IoT devices. To address such challenges, especially for user authorization, we introduce intermittent computation to our proposed authentication framework. Intermittent computation can store the state of the NNs at checkpoints. In the case of power disruption, the execution will be resumed from the saved checkpoints instead of performing the whole execution. Most implementations of intermittent computation take place at the compiler level, which makes for a very efficient design, however, that also makes them hardware specific. Our method is implemented on software and is hardware-agnostic, allowing us to create checkpoints to save and retrieve the authentication framework state, in case of power interruption. The proposed authentication framework can authenticate users with up to more than 85% accuracy and can save up to 34% of computations due to the proposed intermittent computing.","1937-4151","","10.1109/TCAD.2023.3313097","Defense Advanced Research Projects Agency (DARPA)(grant numbers:HR001120C0154); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10242378","Early-exit neural networks (EENets);gait-based authentication;intermittent computing;Internet of Things (IoT) networks;reinforcement learning;user authentication","Authentication;Internet of Things;Neural networks;Computational efficiency;Artificial neural networks;Costs;Performance evaluation","","","","58","IEEE","7 Sep 2023","","","IEEE","IEEE Journals"
"Edge-Based Federated Deep Reinforcement Learning for IoT Traffic Management","A. Jarwan; M. Ibnkahla","Data Analytics Department, Lytica Inc., Kanata, ON, Canada; Department of Systems and Computer Engineering, Carleton University, Ottawa, ON, Canada","IEEE Internet of Things Journal","20 Feb 2023","2023","10","5","3799","3813","The wide adoption of large-scale Internet of Things (IoT) systems has led to an unprecedented increase in backhaul (BH) traffic congestion, making it critical to optimize traffic management at the network edge. In IoT systems, the BH network is supported by various backhauling technologies that have different characteristics. Also, the characteristics of the BH links can be sometimes time varying and have an unknown state, due to external factors such as having the resources shared with other systems. It is the responsibility of the edge devices to be able to forward IoT traffic through the unknown-state BH network by selecting the suitable BH link for each collected data flow. To the best of our knowledge, this type of BH selection problem is not addressed in the literature. Therefore, there is a crucial need to develop intelligent approaches enabling edge devices to learn how to deal with unknown-state (partially observable) components of the BH network, which is the primary goal of this article. We propose an edge-based BH selection technique for improving traffic delivery by exploiting multiobjective feedback on delivery performance. The proposed approach relies on the advantage-actor–critic deep reinforcement learning (DRL) methods. Moreover, to improve the DRL training performance in large-scale deployments of distributed IoT systems, federated learning (FL) is applied to enable multiple edge devices to collaborate in training a shared BH selection policy. The proposed federated DRL (F-DRL) approach is able to solve the BH selection problem as verified and demonstrated through extensive simulations.","2327-4662","","10.1109/JIOT.2022.3174469","Cisco Chair on Sensor Technology for the Internet of Things; NSERC/Cisco Industrial Research Chair on Sensor Networks for the Internet of Things; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9772619","Advantage-actor–critic (A2C) methods;backhaul (BH) selection;deep reinforcement learning (DRL);distributed edge learning;federated learning (FL);Internet of Things (IoT);IoT traffic management","Internet of Things;Quality of service;Performance evaluation;Wireless sensor networks;Training;Reinforcement learning;Delays","","7","","35","IEEE","11 May 2022","","","IEEE","IEEE Journals"
"Prototype implementation of downward transfer method by tunneling for a large-scale data collection system using MQTT","F. Aoki; K. Ishibashi; T. Yokotani","Kanazawa Institute of Technology, Japan; Kanazawa Institute of Technology, Japan; Kanazawa Institute of Technology, Japan","2022 27th Asia Pacific Conference on Communications (APCC)","15 Nov 2022","2022","","","439","444","Message queuing telemetry transport (MQTT) has recently attracted attention as an important communication method in the Internet of Things (IoT). Research and development have been conducted over time to realize IoT services using MQTT; however, when the number of connected IoT devices increase or an IoT system is deployed widely, issues such as scalability and interoperability exist. We have previously proposed an efficient communication method for large-scale data collection systems with multiple MQTT brokers such as smart street lighting systems, called the downward transfer method by tunneling, in which connection management is by a server and transfer from a server is by tunneling. In other words, the server manages the information of the broker to which the sensor is connected, called sensor location information; then, when the server notifies data to a sensor, it transfers a message with the sensor location information and original data to a specific broker, called a top broker, using tunneling technology. The top broker forwards the received message to a bottom broker according to the extracted sensor location information via de-tunneling. Because the top broker need not to manage a location information for each sensor, the downward transfer method by tunneling can reduce memory resources required for the connection management of the top broker. In addition, it can prevent an increase of traffic due to memory overflow. In this paper, we implemented a prototype of this downward transfer method by tunneling and evaluated the amount of traffic. As a result, we confirmed that the proposed downward transfer method by tunneling is effective and available for a large-scale data collection system.","2163-0771","978-1-6654-9927-9","10.1109/APCC55198.2022.9943713","Ministry of Economy; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9943713","IoT;Large-scale data collection;Wireless sensor network;Connection management","Scalability;Memory management;Prototypes;Lighting;Tunneling;Data collection;Servers","","","","13","IEEE","15 Nov 2022","","","IEEE","IEEE Conferences"
"Toward Enhanced Attack Detection and Explanation in Intrusion Detection System-Based IoT Environment Data","T. -T. -H. Le; R. W. Wardhani; D. S. C. Putranto; U. Jo; H. Kim","Blockchain Platform Research Center, Pusan National University, Busan, South Korea; School of Computer Science and Engineering, Pusan National University, Busan, South Korea; Blockchain Platform Research Center, Pusan National University, Busan, South Korea; School of Computer Science and Engineering, Pusan National University, Busan, South Korea; School of Computer Science and Engineering, Pusan National University, Busan, South Korea","IEEE Access","30 Nov 2023","2023","11","","131661","131676","Securing the Internet of Things (IoT) against cyber threats is a formidable challenge, and Intrusion Detection Systems (IDS) play a critical role in this effort. However, the lack of transparent explanations for IDS decisions remains a significant concern. In response, we introduce a novel approach that leverages a blending model for attack classification and integrates counterfactual and Local Interpretable Model-Agnostic Explanations (LIME) techniques to enhance explanations. To assess the effectiveness of our approach, we conducted experiments using the recently introduced CICIoT2023 and IoTID20 datasets. These datasets are real-time and large-scale benchmark datasets for IoT environment attacks, offering a realistic and challenging scenario that captures the intricacies of intrusion detection in dynamic IoT environments. Our experimental results demonstrate significant improvements in attack detection accuracy compared to conventional IDS methods. Furthermore, our proposed approach provides clear and interpretable insights into the factors influencing classification decisions, empowering users to make informed security choices. Integrating blending model classification and explanation techniques enhances the security and reliability of IoT systems. Therefore, this work represents a significant advancement in IoT intrusion detection, offering a robust and transparent defense against large-scale cyber-attacks of IoT environment data.","2169-3536","","10.1109/ACCESS.2023.3336678","MSIT (Ministry of Science and ICT), Korea, under the Convergence security core talent training business (Pusan National University) support program(grant numbers:IITP-2023-2022-0-01201); Institute of Information & communications Technology Planning & Evaluation (IITP) grant funded by the Korea government (MSIT)(grant numbers:2022-0-00407); MSIT (Ministry of Science and ICT), Korea, under the Special R&D Zone Development Project (R&D) - Development of R&D Innovation Valley support program(grant numbers:2023-DD-RD-0152); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10328753","Counterfactual;ensemble blending model;IoT;IDS;LIME;XAI","Internet of Things;Security;Intrusion detection;Impurities;Computational modeling;Feature extraction;Ensemble learning","","","","50","CCBYNCND","24 Nov 2023","","","IEEE","IEEE Journals"
"Effective Multitask Deep Learning for IoT Malware Detection and Identification Using Behavioral Traffic Analysis","S. Ali; O. Abusabha; F. Ali; M. Imran; T. Abuhmed","Department of Electrical and Computer Engineering, Sungkyunkwan University, Suwon, South Korea; College of Computing and Informatics, Sungkyunkwan University, Suwon, South Korea; Department of Software, Sejong University, Seoul, South Korea; Institute of Innovation, Science and Sustainability, Federation University Australia, Brisbane, QLD, Australia; College of Computing and Informatics, Sungkyunkwan University, Suwon, South Korea","IEEE Transactions on Network and Service Management","29 Jun 2023","2023","20","2","1199","1209","Despite the benefits of the Internet of Things (IoT), the growing influx of IoT-specific malware coordinating large-scale cyberattacks via infected IoT devices has created a substantial threat to the Internet ecosystem. Assessing IoT systems’ security and developing mitigation measures to prevent the spread of IoT malware is therefore critical. Furthermore, for training and testing the fidelity of cyber security-based Machine Learning (ML) and Deep Learning (DL) approaches, the collection and exploration of information from multiple sources from the IoT are crucial. In this regard, we propose a multitask DL model for detecting IoT malware. Our proposed Long Short-Term Memory (LSTM) based model efficiently performs two tasks: 1) determination of whether the provided traffic is benign or malicious, and 2) determination of the malware type for identifying malicious network traffic. We used large-scale traffic data of 145. pcap files of benign and malicious traffic collected from 18 different IoT devices. We performed a time-series analysis on the packets of traffic flows, which were then used to train the proposed model. The features extracted from the dataset were categorized into three modalities: flow-related, traffic flag-related, and packet payload-related features. A feature selection approach was employed at the feature and modality levels, and the best modalities and features were utilized for performance enhancement. For tasks 1 and 2 and multitask classification, the flow-related and flag-related modalities showed the best testing accuracies of 92.63%, 88.45%, and 95.83%, respectively.","1932-4537","","10.1109/TNSM.2022.3200741","MSIT (Ministry of Science and ICT), South Korea, under the ICT Creative Consilience Program(grant numbers:IITP-2021-2020-0-01821); IITP (Institute for Information & communications Technology Planning & Evaluation), and the National Research Foundation of Korea (NRF) grant; Korea government (MSIT)(grant numbers:2021R1A2C1011198); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9865131","Multitask deep learning;multimodal learning;Cybersecurity;IoT malware detection;malware identification;heterogeneity traffic analysis","Internet of Things;Malware;Feature extraction;Task analysis;Security;Telecommunication traffic;Intrusion detection","","9","","58","IEEE","23 Aug 2022","","","IEEE","IEEE Journals"
"BlockAM: An Adaptive Middleware for Intelligent Data Storage Selection for Internet of Things","S. M. Danish; K. Zhang; H. -A. Jacobsen","Middleware Systems Research Group, École de technologie supérieure; Middleware Systems Research Group, École de technologie supérieure; Middleware Systems Research Group, École de technologie supérieure","2020 IEEE International Conference on Decentralized Applications and Infrastructures (DAPPS)","8 Jul 2020","2020","","","61","71","Current Internet of Things (IoT) infrastructures, with its massive data requirements, rely on cloud storage: however, usage of a single cloud storage can place limitations on the IoT applications in terms of service requirements (performance, availability, security etc.). Multi-cloud storage architecture has been emerged as a promising infrastructure to solve this problem, but this approach has limited impact due to the lack of differentiation between competing cloud solutions. Multiple decentralized storage solutions (e.g., based on blockchains) are entering the market with distinct characteristics in terms of architecture, performance, security and availability and at a lower price compared to cloud storage. In this work, we introduce BlockAM: an adaptive middleware for the intelligent selection of storage technology for IoT applications, which jointly considers the cloud, multi-cloud and decentralized storage technologies to store large-scale IoT data. We model the cost-minimization storage selection problem and propose two heuristic algorithms: Dynamic Programming (DP) based algorithm and Greedy Style (GS) algorithm, for optimizing the choice of data storage based on IoT application's service requirements. We also employ blockchain to store IoT data on-chain in order to provide data integrity, auditability and accountability to the middleware architecture. Comparisons among the heuristic algorithms are conducted through extensive experiments, which demonstrates that DP heuristic and GS heuristic achieve up to 92% and 80% accuracy respectively. Moreover, the price associated with a specific IoT application data storage decrease by up to 31.2% by employing our middleware solution.","","978-1-7281-6978-1","10.1109/DAPPS49028.2020.00007","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9126003","Adaptive middleware;Intelligent storage selection;Internet of Things;Blockchain","Cloud computing;Adaptation models;Heuristic algorithms;Memory;Decentralized applications;Data models;Blockchains","","3","","33","IEEE","8 Jul 2020","","","IEEE","IEEE Conferences"
"Intent-Driven Internet of Things: Architectures, Technology, and Challenges","L. Zhang; R. Dong; F. Li; J. Zhang; J. Zhang; C. Yang","The State Key Laboratory on Integrated Services Networks, Xidian University, Xi’an, China; The State Key Laboratory on Integrated Services Networks, Xidian University, Xi’an, China; 20th Institute, Key Laboratory of Technology on Datalink China Electronics Technology Group Corporation(CETC), Xi’an, China; The State Key Laboratory on Integrated Services Networks, Xidian University, Xi’an, China; The State Key Laboratory on Integrated Services Networks, Xidian University, Xi’an, China; The State Key Laboratory on Integrated Services Networks, Xidian University, Xi’an, China","2023 6th World Conference on Computing and Communication Technologies (WCCCT)","28 Feb 2023","2023","","","112","117","The Internet of Things (IoT) aims to connect everything. However, with the emergence of large-scale heterogeneous devices, the complexity of network configuration and management becomes increasingly prominent, and it becomes more and more urgent for infrastructure to automatically and adaptively update the configuration according to the business requirements. Intent-driven Network (IDN) has the advantages of user friendliness, fine-grained policy mapping and closed-loop verification. IDN can promote the improvement of traditional IoT configuration and management methods, and further achieve the goal of improving user experience. First, we review the development of IoT architecture and propose an intent-driven IoT architecture. We then analyze the key technologies involved in the architecture and provide a list of typical intent-driven IoT platforms from industry and academia. Finally, the future research challenges of intent-driven IoT are briefly discussed.","","978-1-6654-6146-7","10.1109/WCCCT56755.2023.10052382","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10052382","intent-driven networks;internet of things;configuration and management","Industries;Human computer interaction;Configuration management;Computer architecture;User experience;Communications technology;Complexity theory","","","","15","IEEE","28 Feb 2023","","","IEEE","IEEE Conferences"
"A Blockchain-based Fast Authentication and Collaborative Video Data Forwarding Scheme for Vehicular Networks","W. Qiu; X. Yang; M. Wei; W. Ren; T. Zhu","School of Computer Science, China University of Geosciences, Wuhan, P.R. China; Wuhan Institute of Marine Electric Propulsion CSSC, P.R. China; School of Computer Science, China University of Geosciences, Wuhan, P.R. China; School of Computer Science, China University of Geosciences, Wuhan, P.R. China; School of Computer Science, China University of Geosciences, Wuhan, P.R. China","2021 IEEE 19th International Conference on Embedded and Ubiquitous Computing (EUC)","30 Mar 2022","2021","","","56","63","Internet of Things (IoT) current present two trends with respect to ubiquity and mobility. The number of devices increases remarkably and most forthcoming devices are mobile, e.g., Internet of Vehicles (IoV). In large scale mobile IoT, the management of device identification, fast authentication, and certification of public keys experiences upcoming difficulties. Centralized security architecture may not be suitable and in contrast cross-domain security architecture will tackle the ubiquity and mobility better. We note that blockchain is a new decentralized architecture equipped with basic cryptographic settings, which provides new tools such as token and guarantees many security properties such as block integrity. In this paper we design a blockchain-based fast authentication video data forwarding scheme for IoV. Compared with existing protocols, it has the advantages of decentralization, high authentication efficiency, strong trust, and resistance to common attacks. We evaluate our scheme with real experiments over Hyperledger Fabric and the authentication delay is manageable (e.g, 4 seconds in IoV).","","978-1-6654-0036-7","10.1109/EUC53437.2021.00017","National Natural Science Foundation of China(grant numbers:61972366); Major Sci-entific and Technological Special Project of Guizhou Province(grant numbers:20183001); Foundation of Guizhou Provincial Key Laboratory of Public Big Data(grant numbers:2018BDKFJJ009,2019BDKFJJ003,2019BDK-FJJ011); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9742259","Blockchain;authentication;Internet of Vehicles;Internet of Things","Resistance;Protocols;Authentication;Public key;Computer architecture;Near field communication;Ubiquitous computing","","","","17","IEEE","30 Mar 2022","","","IEEE","IEEE Conferences"
"Design and Implementation of IoT System for Aeroponic Chamber Temperature Monitoring","C. A. Jamhari; W. K. Wibowo; A. R. Annisa; T. M. Roffi","Department of Electrical Engineering, Universitas Pertamina, Jakarta, Indonesia; Department of Electrical Engineering, Universitas Pertamina, Jakarta, Indonesia; Department of Electrical Engineering, Universitas Pertamina, Jakarta, Indonesia; Department of Electrical Engineering, Universitas Pertamina, Jakarta, Indonesia","2020 Third International Conference on Vocational Education and Electrical Engineering (ICVEE)","3 Nov 2020","2020","","","1","4","Urban farming lifestyle has gained traction in recent years as society started to pay more attention to the quality of the product being consumed. Aeroponic is one of the urban farming techniques which employs air as the growing medium. Aeroponic allows a significant reduction in water usage with increased productivity as compared to hydroponic or conventional farming. However, optimum aeroponic farming requires precise control of the cultivation environment. This work presents a design and implementation of a lab-scale aeroponic system that employs the Internet of Things (IoT) for online and automated monitoring capability. An aeroponic system that consists of a growth chamber and a root chamber was built for 6 vegetable plants. The root chamber was designed as a closed and dark space resembling that of the soil. The temperature in this chamber was carefully monitored by using the DHT-11 sensor connected to the internet through the Wemos-D1-mini integrated microprocessor and Wifi module. Actuators, i.e. a Peltier cell, fans, and mist makers were placed to control the temperature and to supply nutrients to the roots. Considering the ideal growth environment for the plant, the required temperature was in the range of 25-30°C with a humidity level above 60%. The chamber was placed indoor with a certain exposure to sunlight where the recorded temperature variation was from 29-32.9°C. Application of a simplified temperature control system with 2 set points at 25°C and 29°C successfully decreased the root chamber temperature to an average of 28.8°C, ideal for vegetable plant growth.","","978-1-7281-7434-1","10.1109/ICVEE50212.2020.9243213","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9243213","aeroponic;internet of things;online and automated monitoring;control system","Temperature sensors;Temperature measurement;Humidity;Temperature control;Internet of Things;Monitoring;Wireless fidelity","","13","","11","IEEE","3 Nov 2020","","","IEEE","IEEE Conferences"
"Design and research of Music Internet of things","J. Yanhong","School of Music and Drama, Zhengzhou Sias University, Zhengzhou, China","2021 IEEE 2nd International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE)","2 Apr 2021","2021","","","1050","1053","Music Internet of things is a comprehensive project involving multiple disciplines and specialties. Previous studies are relatively single, lack of a unified research framework, complete research system is not perfect. Therefore, the research focus of this paper is to define music events from the perspective of engineering. Firstly, music events are defined as corresponding engineering links according to their contents, functions and objectives. Then, each link is mapped to the Internet and realized by using Internet technology. Finally, the effect of the design scheme is fed back from the actual effect, and the response is adjusted. The research group builds a small-scale ecosystem of iomust, tests the performance of iomust from the perspective of software, and verifies the effect of the design architecture of iomust on hardware.","","978-1-6654-1540-8","10.1109/ICBAIE52039.2021.9390058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9390058","Internet of things;music things;intelligent control","Operating systems;Linux;Ecosystems;Information processing;Software;Hardware;Internet of Things","","","","13","IEEE","2 Apr 2021","","","IEEE","IEEE Conferences"
"Multi-Attribute Top-k Query Processing Leveraging Caching Mechanism in IoT Sensing Networks","L. Zhang","School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, China","2020 International Conference on Internet of Things and Intelligent Applications (ITIA)","16 Feb 2021","2020","","","1","5","The large-scaled and multifarious smart things generate huge sensory data in the Internet of Things (IoT). The collaboration of cloud computing and edge computing is acquired to support industrial applications to process the continuous real-time monitoring and query, and bring the query results to a centralized entity (e.g., cloud). In the context of edge-cloud collaborative architecture, answering the preference top-k query is a challenging issue. To address this issue, we propose a method to improve the performance of answering continuous preference top-k queries in IoT sensing networks. Specifically, a hierarchical region quadtree is constructed to support efficient query processing by eliminating invalid data at branch nodes. The cloud divides the query into different types according to their preferences, and a responsible edge node caches data records for different types of queries based on popularity. The efficient filter thresholds of top-k queries generate from the cache. To further reduce the transmission of invalid data records, a grid index scheme is developed. Experiments indicate our proposed approach is promising in reducing the energy cost of network transmission.","","978-1-7281-9301-4","10.1109/ITIA50152.2020.9312272","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9312272","multidimensional top-k query;hierarchical region quadtree;edge caching;grid index;IoT sensing networks","Sensors;Indexes;Query processing;Energy consumption;Cloud computing;Prefetching;Filtering","","","","17","IEEE","16 Feb 2021","","","IEEE","IEEE Conferences"
"A Review of 5G Millimeter Waves and Enabling Technologies for IoT","J. Onolemhemhen; S. Thomas; O. Oshiga; T. Karataev; O. Osanaiye; O. Oyeleke","Electrical Electronics Engineering, Nile University of Nigeria, Abuja, Nigeria; Computer Engineering, Nile University of Nigeria, Abuja, Nigeria; Electrical Electronics Engineering, Nile University of Nigeria, Abuja, Nigeria; Electrical Electronics Engineering, Nile University of Nigeria, Abuja, Nigeria; Computer Engineering, Nile University of Nigeria, Abuja; Computer Engineering, Nile University of Nigeria","2021 1st International Conference on Multidisciplinary Engineering and Applied Science (ICMEAS)","8 Feb 2022","2021","","","1","6","One of the most exhilarating developments of fifth-generation (5G) mobile broadband networks is the Internet of Things (IoT).5G wireless networks, which are data-driven, need unparalleled capacity and availability. The future problems with consumer devices under a single 5G network are discussed. Presenting an up-to-date state-of-the-art review focusing on the technological challenges of enabling large-scale IoT applications with millimeter-wave (mm-wave) technology. The review of mmwave 5G architecture problems and solutions focuses on communication requirements in consumer devices, as well as the challenges, advantages, and disadvantages of mmwave.","","978-1-6654-3493-5","10.1109/ICMEAS52683.2021.9692372","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9692372","IOT Internet of Things;5G;Millimeter-waves;Massive MIMO (Multiple Input Multiple Output)","Protocols;5G mobile communication;Wireless networks;Millimeter wave technology;Transforms;Reliability engineering;Propagation losses","","","","15","IEEE","8 Feb 2022","","","IEEE","IEEE Conferences"
"Multimedia IoT Data Compression using Deep Learning Technique","V. Yathavaraj; N. Karthikeyan; A. Kousalya; P. Sindhuja","Department of Computer Science and Engineering, Dr. N.G.P. Institute of Technology, Coimbatore, India; Department of Computer Science and Engineering, SNS College of Technology, Coimbatore, India; Department of Information Technology, Sri Krishna College of Engineering and Technology, Coimbatore, India; Department of Computer Science and Engineering, United Institute of Technology, Coimbatore, India","2023 2nd International Conference on Applied Artificial Intelligence and Computing (ICAAIC)","8 Jun 2023","2023","","","1","7","Due to the considerable complexity of the multimedia data acquired, IoT (Internet of Things) and multimedia will encounter a number of energy and communication overload limits. One well-known solution to the problem of large datasets is to use the lossy compression algorithm. However, the lower transmission rate required by current lossy compression techniques to ensure endurable apparent image/picture quality only results in a minor reduction in the amount of communicated data and, as a result, a minor reduction in power and bandwidth use. An effective firmness technique is required to strike a fair equilibrium flanked by information volume and visual degradation. A deep-learning super-resolution technique is utilized in this study to restore high-resolution photographs from damaged photos with a considerable compression ratio as input. The results of the study clearly show how the suggested approach improves the graphical fidelity of compressed and down scaled images. The suggested method reduces largely the communication transparency and energy consumption of constrained multimedia IoT framework components as a result.","","978-1-6654-5630-2","10.1109/ICAAIC56838.2023.10140936","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10140936","Deep learning;Internet of Things;Multimedia;lossy compression;visual degradation","Degradation;Visualization;Image coding;Superresolution;Noise reduction;Multimedia databases;Propagation losses","","","","21","IEEE","8 Jun 2023","","","IEEE","IEEE Conferences"
"Low-Cost Energy-efficient Voice-Activated Home Automation System – Addressing the United Nations Sustainable Development Goals","O. Alblooshi; A. Alzaabi; S. Alqahtani; A. A. Alnoman; H. Alnuaimi; A. Ghani","Computer Science and Engineering, American University of Ras al Khaimah, Ras al Khaimah, UAE; Computer Science and Engineering, American University of Ras al Khaimah, Ras al Khaimah, UAE; Computer Science and Engineering, American University of Ras al Khaimah, Ras al Khaimah, UAE; Computer Science and Engineering, American University of Ras al Khaimah, Ras al Khaimah, UAE; Computer Science and Engineering, American University of Ras al Khaimah, Ras al Khaimah, UAE; Computer Science and Engineering, American University of Ras al Khaimah, Ras al Khaimah, UAE","2022 International Conference on Electrical and Computing Technologies and Applications (ICECTA)","26 Dec 2022","2022","","","76","79","In the context of the United Nations Sustainable Development Goals (SDG), countries are encouraged to achieve net-zero emissions by 2050. With the rapid technological advancement in the area of home automation and the ever-increasing consumption of energy, it is necessary to adopt smart control systems that help to reduce the cost and emission of greenhouse gases. This work aims to reduce the amount of energy consumption by implementing a customized design of a voice-controlled hardware/software embedded platform. The prototype utilizes an Android mobile application in addition to a software-controlled On/Off switch that controls home appliances. The proposed prototype is cost-effective, power efficient, and user-friendly. An Android-based mobile application also facilitates its usability by controlling home appliances using voice-activated commands. This work demonstrates a fully functional small-scale prototype using Arduino IDE which could easily be scaled up to an industrial scale as an IoT (Internet of Things) device. The energy efficiency of the hardware platform is solely dependent on the Arduino board that acts as a hub between all the electrical appliances and the Firebase mobile application. To optimize the energy consumption of the utilized hardware, different energy-efficient modes are implemented and results are reported.","","978-1-6654-5600-5","10.1109/ICECTA57148.2022.9990313","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9990313","home automation;SDG;Android app;low power;IoT device","Home appliances;Energy consumption;Visualization;Home automation;Operating systems;Prototypes;Hardware","","","","11","IEEE","26 Dec 2022","","","IEEE","IEEE Conferences"
"AMACoT: A Marketplace Architecture for Trading Cloud of Things Resources","A. S. Alrawahi; K. Lee; A. Lotfi","School of Science and Technology, Nottingham Trent University, Nottingham, U.K.; School of Information Technology, Deakin University, Melbourne, Australia; School of Science and Technology, Nottingham Trent University, Nottingham, U.K.","IEEE Internet of Things Journal","12 Mar 2020","2020","7","3","2483","2495","Cloud of Things (CoT) is increasingly viewed as a paradigm that can satisfy the diverse requirements of emerging Internet of Things (IoT) applications. The potential of CoT is not yet realized due to challenges in sharing and reusing IoT physical resources across multiple applications. The existing approaches provide small-scale and hardware-dependent shared access to IoT resources. This article considers using market mechanisms to commoditize CoT resources as the approach to enable shared access to CoT resources and to improve their reusability. In order to achieve this, the requirements for trading CoT resources are discussed to conceptualize the proposed approach. A generic description model for CoT resource is introduced to quantify the value of CoT resources. In this article, a marketplace architecture for trading CoT resources referred to as AMACoT is proposed. By formulating the trading of CoT resources as an optimization problem, the proposed approach is experimentally validated. The evaluation measures the system performance and verifies the optimization problem using three evolutionary algorithms. The evaluation of the optimization algorithms demonstrates the optimality of trading CoT resources solutions in terms of resource cost, resource utilization, provider lock-in, and provider profit.","2327-4662","","10.1109/JIOT.2019.2957441","Ministry of Higher Education, Oman(grant numbers:PGE023347); Nottingham Trent University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8920099","Cloud of Things (CoT);Internet of Things (IoT);marketplace;optimization","Computer architecture;Internet of Things;Cloud computing;Resource management;Computational modeling;Security;Sensors","","4","","36","IEEE","3 Dec 2019","","","IEEE","IEEE Journals"
"Wireless Technology for Autonomous Albanian Farming and Crop Monitoring","B. Tabaku; M. Ali","Department of Computer Engineering, Epoka University, Tirana, Albania; Department of Computer Engineering, Epoka University, Tirana, Albania","2020 International Conference on Computing, Networking, Telecommunications & Engineering Sciences Applications (CoNTESA)","28 Dec 2020","2020","","","100","105","The adoption of Internet of Things (IoT) has made possible remote networking of a diverse and broad spectrum of applications from the microscopic to the industrial scale. Agricultural science is rapidly evolving along with the need to apply more cost-effective techniques and equipment that would make this science more productive and efficient. The deployment of wireless technologies would be an essential factor that will facilitate small farm holders to reach these goals in the farming ecosystem, such as arable land usage, asset tracking and management, natural environment and crop monitoring. This paper surveys the technology and recommends the selected products with their full costing to implement a small-scale wireless monitored autonomous farming system in Albania.","","978-1-7281-8488-3","10.1109/CoNTESA50436.2020.9302860","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9302860","Internet of Things (IoTs);wireless sensors;Wireless Sensor Networks (WSNs);Unmanned Ground Vehicles (UGVs);ad hoc networks;monitoring system","Sensors;Monitoring;Cameras;Ad hoc networks;Wireless sensor networks;Temperature sensors;Internet of Things","","1","","25","IEEE","28 Dec 2020","","","IEEE","IEEE Conferences"
"Modeling of Multiple Cantilevers System for Broadband Vibration Energy Harvester","L. W. Thong; S. L. Kok; R. Ramlan","Faculty of Engineering and Technology, Multimedia University, Melaka, Malaysia; Faculty of Electronic and Computer Engineering, Universiti Teknikal Malaysia Melaka, Melaka, Malaysia; Faculty of Mechanical Engineering, Universiti Teknikal Malaysia Melaka, Melaka, Malaysia","2021 4th International Seminar on Research of Information Technology and Intelligent Systems (ISRITI)","11 Feb 2022","2021","","","407","411","Piezoelectric energy harvester has the capability in powering small scale semiconductor devices particularly in the low power sensors applications in Internet of Things (IoT) environment. It is known that the bandwidth and power of these energy harvesters can be improved by increasing the number of cantilevers in the system. This research presents the electromechanical model of multimode piezoelectric energy harvesters with different polarity connections between the cantilever beams to improve the broadband performance of frequency response in the system. The theoretical model and experimental results of the proposed multi-mode system exhibited a significant escalation of output voltage at the gap between two resonance frequencies when the polarity configuration in the cantilever connection is reversed accordingly. The outcomes designate that by interchanging the polarity of the electrical connection between the cantilever beams, the output voltage between the resonance frequency of the multi-mode system can be increase significantly in comparison with the conventional series interconnection.","","978-1-6654-0151-7","10.1109/ISRITI54043.2021.9702763","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9702763","vibration energy harvesting;broadband energy;lumped-parameter model;polarity configurations;multimode","Vibrations;Seminars;Resonant frequency;Voltage;Bandwidth;Broadband communication;Structural beams","","1","","20","IEEE","11 Feb 2022","","","IEEE","IEEE Conferences"
"Private Data Trading Towards Range Counting Queries in Internet of Things","Z. Cai; X. Zheng; J. Wang; Z. He","Department of Computer Science, Georgia State University, Atlanta, GA, USA; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, Heilongjiang, China; Department of Computer Science, College of Information Science and Technology, Jinan University, Guangzhou, Guangdong, China","IEEE Transactions on Mobile Computing","30 Jun 2023","2023","22","8","4881","4897","The data collected in Internet of Thing (IoT) systems (IoT data) have stimulated dramatic extension to the boundary of commercialized data statistic analysis, owing to the pervasive availability of low-cost wireless network access and off-the-shelf mobile devices. In such cases, many data consumers post their queries for urban statistic analysis in the system, like the scales of traffics, and then data contributors in IoT networks upload their contents, which can be evaluated by data brokers and responded to data consumers. However, huge volumes of devices bring large scales of data, constituting heavy burdens for data exchange. Even worse, contents in IoT systems are also sensitive as they are usually linked to private physical status of data contributors. The previous studies for IoT data trading fail to provide comprehensive estimation and pricing towards these difficulties. Therefore, this paper proposes a novel framework for the range counting trading over IoT networks by jointly considering data utility, bandwidth consumption, and privacy preservation. The range counting accumulates the number of data items falling in a concerned range of value, providing important information on the underlying data distribution. This paper first proposes a novel sampling-based method with histogram sketching for range counting estimation. The estimator is proved to be unbiased and achieves advanced performance on variance. Then the framework adopts a perturbation mechanism that can further preserve the results under differential privacy. The theoretical analysis shows that the mechanism can guarantee the privacy preservation under a given size of samples and the accuracy requirement of results. Finally, two types of pricing strategies for range counting trading are introduced for different circumstances, providing holistic consideration on how the parameters given in the estimator should be used for data trading. The framework is evaluated by estimating the air pollution levels and the traffic levels with different ranges on the 2014 CityPulse Smart City datasets. The evaluation results demonstrate that our framework can provide more accurate and reliable statistical information, with reduced bandwidth consumption and strengthened privacy preservation.","1558-0660","","10.1109/TMC.2022.3164325","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9748012","Mobile wireless networks;IoT;data trading;big data","Pricing;Sensors;Mobile computing;Differential privacy;Distributed databases;Privacy;Internet of Things","","29","","32","IEEE","1 Apr 2022","","","IEEE","IEEE Journals"
"Sensor Compliance Development for Smart Lift Safety Application Based on IEEE 2668","Y. Wei; K. F. Tsang; H. Wang","Department of Electrical Engineering, City University of Hong Kong; Department of Electrical Engineering, City University of Hong Kong; Department of Electrical Engineering, City University of Hong Kong","2023 IEEE International Conference on Industrial Technology (ICIT)","9 Jun 2023","2023","","","1","4","Lift is an indispensable means of transportation in our daily life. Lift safety is a great concern with large-scale deployment and heavy use. To enhance lift safety, Internet of Things (IoT) devices have been applied in lift systems to provide smart services, such as remote control, emergency alarms, etc. However, large amounts of interconnections from different end devices embedded with different sensors cause difficulties in interoperability. To be specific, different end devices from different manufactures have their own hardware and software design, which is difficult to integrate into one lift system. In addition, different sensors (e.g., current sensor for motor, brake, etc.) has different data structure, data precision, etc., which is difficult to verify the data accuracy. To address these interoperability issues, a Sensor Compliance (SC) design based on IEEE 2668 standard is developed for lift safety application. In SC design, standardized interface with Digital Information Specification (DIS) is developed to store essential sensor information, etc. Through standardized SC design, different sensors from different manufacturers can be integrated, which enables sensor-plug-and-play and improve system interoperability. Besides, data accuracy evaluation is performed on the prototype, which verifies the effectiveness and efficiency of the SC design for lift safety. Through standardized evaluation, guidance on blending of lift safety to evolve into better performance.","2643-2978","979-8-3503-3650-4","10.1109/ICIT58465.2023.10143127","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10143127","Sensor compliance;lift safety;IEEE 2668;digital information specification","Software design;Transportation;Prototypes;Sensor systems;Safety;Internet of Things;Interoperability","","","","11","IEEE","9 Jun 2023","","","IEEE","IEEE Conferences"
"Blockchain-Enabled Data-Sharing Scheme for Consumer IoT Applications","B. Hu; Y. Chen; H. Yu; L. Meng; Z. Duan","National University of Defense Technology, China; National University of Defense Technology, China; National University of Defense Technology, China; National University of Defense Technology, China; National University of Defense Technology, China","IEEE Consumer Electronics Magazine","2 Mar 2022","2022","11","2","77","87","A staggering number of consumer Internet-of-Things devices are being deployed in various application scenarios, and massive data will be generated per day. How to achieve a secure and efficient data-sharing scheme for the consumer IoT applications is a huge challenge for us. The traditional cloud-based IoT has the dilemma of prolonged communication delay and privacy leakage. With the application of 5G technology, edge computing can effectively alleviate these problems. However, it cannot meet the higher security requirements for the data sources’ authenticity and information reliability. By combining the blockchain and smart contracts technology, this article proposes a distributed, efficient, and secure data-sharing scheme centered on consumer IoT devices. This architecture consists of four layers: 1) IoT devices layer, 2) edge storage layer, 3) blockchain network layer, and 4) application services layer. We design smart contracts based on the attributed based access control and the searchable encryption algorithm, including device retrieval contract, policy management contract, and authorization verification contract. Through the implementation of simulated experiments, we prove that our proposed architecture can satisfy the large-scale data access requests and bring a tolerable level of communication overhead. The proposed framework is one of the few attempts to leverage the edge computing and blockchain technologies to support IoT data sharing.","2162-2256","","10.1109/MCE.2021.3066793","National Key Research and Development Program of China(grant numbers:2018YFB0204301); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9380940","","Internet of Things;Blockchains;Cloud computing;Security;Edge computing;Servers;Data privacy","","6","","26","IEEE","17 Mar 2021","","","IEEE","IEEE Magazines"
"A Novel ROS2 QoS Policy-Enabled Synchronizing Middleware for Co-Simulation of Heterogeneous Multi-Robot Systems","E. Dey; M. Walczak; M. S. Anwar; N. Roy; J. Freeman; T. Gregory; N. Suri; C. Busart","University of Maryland, Baltimore County, USA; University of Maryland, Baltimore County, USA; University of Maryland, Baltimore County, USA; University of Maryland, Baltimore County, USA; DEVCOM Army Research Lab, USA; DEVCOM Army Research Lab, USA; DEVCOM Army Research Lab, USA; DEVCOM Army Research Lab, USA","2023 32nd International Conference on Computer Communications and Networks (ICCCN)","1 Sep 2023","2023","","","1","10","Recent Internet-of-Things (IoT) networks span across a multitude of stationary and robotic devices, namely unmanned ground vehicles, surface vessels, and aerial drones, to carry out mission-critical services such as search and rescue operations, wildfire monitoring, and flood/hurricane impact assessment. Achieving communication synchrony, reliability, and minimal communication jitter among these devices is a key challenge both at the simulation and system levels of implementation due to the underpinning differences between a physics-based robot operating system (ROS) simulator that is time-based and a network-based wireless simulator that is event-based, in addition to the complex dynamics of mobile and heterogeneous IoT devices deployed in a real environment. Nevertheless, synchronization between physics (robotics) and network simulators is one of the most difficult issues to address in simulating a heterogeneous multi-robot system before transitioning it into practice. The existing TCP/IP communication protocol-based synchronizing middleware mostly relied on Robot Operating System 1 (ROS1), which expends a significant portion of communication bandwidth and time due to its master-based architecture. To address these issues, we design a novel synchronizing middleware between robotics and traditional wireless network simulators, relying on the newly released real-time ROS2 architecture with a masterless packet discovery mechanism. Additionally, we propose a ground and aerial agents' velocity-aware customized QoS policy for Data Distribution Service (DDS) to minimize the packet loss and transmission latency between a diverse set of robotic agents, and we offer the theoretical guarantee of our proposed QoS policy. We performed extensive network performance evaluations both at the simulation and system levels in terms of packet loss probability and average latency with line-of-sight (LOS) and non-line-of-sight (NLOS) and TCP/UDP communication protocols over our proposed ROS2-based synchronization middleware. Moreover, for a comparative study, we presented a detailed ablation study replacing NS-3 with a real-time wireless network simulator, EMANE, and masterless ROS2 with master-based ROS1. Our proposed middleware attests to the promise of building a large-scale IoT infrastructure with a diverse set of stationary and robotic devices that achieve low-latency communications (12% and 11% reduction in simulation and reality, respectively) while satisfying the reliability (10% and 15% packet loss reduction in simulation and reality, respectively) and high-fidelity requirements of mission-critical applications.","2637-9430","979-8-3503-3618-4","10.1109/ICCCN58024.2023.10230109","U.S. Army(grant numbers:W911NF2120076,2233879); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10230109","IoT;Heterogeneous multi-robot systems;Gazebo;NS-3;EMANE;TCP;UDP;Synchronization","Wireless networks;Packet loss;Quality of service;TCPIP;Real-time systems;Windows;Reliability","","","","34","IEEE","1 Sep 2023","","","IEEE","IEEE Conferences"
"Fast and Robust Spectrum Sensing for Cognitive Radio Enabled IoT","Z. Idrees; M. Usman; H. E. Gelani; L. Zheng","School of Information Science and Engineering, Fudan University, Shanghai, China; School of Environmental Science and Engineering, Fudan University, Shanghai, China; Electrical Engineering Department, University of Engineering and Technology Lahore, Lahore, Pakistan; School of Information Science and Engineering, Fudan University, Shanghai, China","IEEE Access","24 Dec 2021","2021","9","","165996","166007","The development of spectral efficient solutions for internet of things (IoT) face challenges primarily due to the large-scale placement of an immense number of sensors and devices. Cognitive radio (CR) technology is considered as a potential solution to resolve the spectrum scarcity problems of IoT. Incorporation of CR in IoT encounters various challenges including fast response and efficient spectrum sensing even in low signal to noise ratio. In this study we integrate the basic functionalities of the both CR and IoT technology and present a five layered framework for CR enabled IoT. In addition to the framework we also proposed and develop a spectrum sensing algorithm for CR-based IoT architecture, meeting the efficiency and time sensitivity requirements. The proposed algorithm is more accurate, robust to noisy environment and four times faster than existing approaches. The developed algorithm is compared with existing blind spectrum sensing techniques in term of detection performance, optimization methods and computational complexity. Experimental evaluations with real wireless microphone signals demonstrate the effectiveness of the proposed scheme and show superiority over existing ones.","2169-3536","","10.1109/ACCESS.2021.3133336","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9638681","Cognitive radios;Internet of Things;principle component analysis;spectrum sensing","Sensors;Internet of Things;Principal component analysis;Cognitive radio;Signal to noise ratio;Machine-to-machine communications;Covariance matrices","","5","","55","CCBY","6 Dec 2021","","","IEEE","IEEE Journals"
"Blockchain-Based Programmable Fog Architecture for Future Internet of Things Applications","S. Nayak; N. Ahmed; S. Misra; K. -K. R. Choo","School of Nano Science & Technology, Indian Institute of Technology, Kharagpur, India; Department of Computer Science & Engineering, Indian Institute of Technology, Kharagpur, India; Department of Computer Science & Engineering, Indian Institute of Technology, Kharagpur, India; Department of Information Systems and Cyber Security, University of Texas at San Antonio, San Antonio, TX, USA","GLOBECOM 2020 - 2020 IEEE Global Communications Conference","12 Feb 2021","2020","","","1","6","In this paper, we propose a secure programmable fog architecture for future Internet of Things (IoT) applications. The programmable feature in the proposed architecture enables us to achieve additional flexibility and support changes over the fog nodes deployed on a large scale network, where individual fog nodes are managed by the centralized fog controller. Specifically, the exchange of programmable content between the controller and the nodes is secured using blockchain. The performance evaluation of the proposed scheme shows significant improvements in reducing downtime and increasing reliability, as compared to conventional fog computing schemes.","2576-6813","978-1-7281-8298-8","10.1109/GLOBECOM42002.2020.9347969","University Grants Commission (UGC); UK India Education Research Initiative (UKIERI)(grant numbers:184-17/2017(IC)); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9347969","IoT;Blockchain;Fog Computing;Programmable Fog;SDN","Performance evaluation;Machine learning algorithms;Computer architecture;Blockchain;Security;Reliability;Industrial Internet of Things","","2","","17","IEEE","12 Feb 2021","","","IEEE","IEEE Conferences"
"Extending Network Programmability to the Things Overlay Using Distributed Industrial IoT Protocols","E. Municio; S. Latré; J. M. Marquez-Barja","University of Antwerp - imec, IDLab, Antwerpen, Belgium; University of Antwerp - imec, IDLab, Antwerpen, Belgium; University of Antwerp - imec, IDLab, Antwerpen, Belgium","IEEE Transactions on Industrial Informatics","29 Oct 2020","2021","17","1","251","259","Current industrial Internet of Things (IoT) demands are calling for more flexible and programmable networks that ensure high reliability in dynamic mission-critical scenarios. Centralized software-defined networking (SDN) offers high levels of flexibility and programmability that traditional distributed IoT protocols cannot offer. However, the use of SDN in IoT is currently not really lifting off due to wireless links unreliability, excessive control overhead, and devices' limited resources. In order to reduce the impact of these issues, Whisper enables SDN-like capabilities in IoT by centrally controlling the distributed routing and scheduling planes in the IoT network (things overlay). To do so, the Whisper controller carefully sends computed messages compatible with the standardized distributed protocols already running in the network that change the default protocols' behavior. However, as many other SDN-on-IoT approaches, Whisper is currently limited to the IoT network scope and remains as yet another independent network management silo. In this article, we argue that IoT network control should be jointly coordinated by the same SDN instance that also manages the wired segments. In order to do so, we present a new fully programmable solution that shifts the Whisper scope from the edge to the core, deploying and testing such architecture in real-world large-scale testbeds. We use 6TiSCH as industrial IoT enabler and the open network operating system platform to orchestrate all network segments. Finally, we report the technical challenges, discussing the lessons learned, and demonstrating the feasibility and suitability of this Whisper-based solution to provide an efficient and programmable end-to-end control over a heterogeneous network domain.","1941-0050","","10.1109/TII.2020.2972613","European Union's Horizon 2020 Fed4FIRE+ Project(grant numbers:723638); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8990019","Flexibility;IIoT;routing protocol for low power and lossy networks (RPL);software-defined networking (SDN);Whisper;6TiSCH","Protocols;Reliability;Job shop scheduling;Informatics;Routing;Industries","","17","","32","IEEE","10 Feb 2020","","","IEEE","IEEE Journals"
"Blockchain Sharding Strategy for Collaborative Computing Internet of Things Combining Dynamic Clustering and Deep Reinforcement Learning","Z. Yang; M. Li; R. Yang; F. R. Yu; Y. Zhang","Faculty of Information Technology, Beijing University of Technology, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China; Department of Systems and Computer Engineering, Carleton University, Ottawa, Canada; Faculty of Information Technology, Beijing University of Technology, Beijing, China","ICC 2022 - IEEE International Conference on Communications","11 Aug 2022","2022","","","2786","2791","Immutability, decentralization, and linear promoted scalability make sharded blockchain a promising solution, which can effectively address the trust issue in the large-scale Internet of Things (IoT). However, currently, the throughput of sharded blockchains is still limited when it comes to high proportions of cross-shard transactions (CST). On the other hand, assemblage characteristics of collaborative computing in IoT have not been received attention. Therefore, in this paper, we present a clustering-based sharded blockchain strategy for collaborative computing in the IoT, where the sharding of the blockchain system is implemented in two steps: k-means clustering-based user grouping and the assignment of consensus nodes. In this framework, how to reasonably group the IoT users while simultaneously guaranteeing the system performance is the key point. Specifically, we describe the data transactions among IoT devices by data transaction flow graph (DTFG) based on a dynamic stochastic block model. Then, formed as a Markov decision process (MDP), the optimization of the cluster number (shard number) and the adjustment of consensus parameters are jointly trained by deep reinforcement learning (DRL). Simulation results show that the proposed scheme improves the scalability of the sharded blockchain in the IoT application.","1938-1883","978-1-5386-8347-7","10.1109/ICC45855.2022.9838570","National Natural Science Foundation of China; Natural Science Foundation of Beijing Municipality; Beijing Municipal Commission of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9838570","Internet of Things (IoT);sharded blockchain;collaborative computing;dynamic graph analysis;k-means clustering;deep reinforcement learning (DRL)","Scalability;System performance;Simulation;Collaboration;Reinforcement learning;Markov processes;Throughput","","1","","25","IEEE","11 Aug 2022","","","IEEE","IEEE Conferences"
"Optimization of Resource Management for NFV-Enabled IoT Systems in Edge Cloud Computing","T. -M. Pham; T. -T. -L. Nguyen","Faculty of Computer Science, Phenikaa University, Hanoi, Vietnam; Faculty of Information Technology, VNU University of Engineering and Technology, Hanoi, Vietnam","IEEE Access","6 Oct 2020","2020","8","","178217","178229","The Internet of Things (IoT) has been envisioned as an enabler of the digital transformation that can enhance different features of people’s daily lives, such as healthcare, home automation, and smart transportation. The vast amount of data generated by a massive number of devices in an IoT system could lead to a severe performance problem. Edge cloud computing and network function virtualization (NFV) technologies are potential approaches to improve the efficiency of resource use and the flexibility of responsive services in an IoT system. In this paper, we consider the joint optimization problem of gateway placement and multihop routing in the IoT layer, the problem of service placement in the edge and cloud layers of an NFV-enabled IoT system in edge cloud computing (NIoT). We propose three optimization models (i.e., GMO, SP1O, SP2O) that allow an IoT service provider to find the optimal deployment of gateways, the optimal resource allocation for service functions, and the optimal routing according to a cost function with a performance constraint in a NIoT system. We then develop three approximation algorithms (i.e., GMA, SP1A, SP2A) for tackling the problems in a large-scale NIoT system. The evaluation results under a set of scenarios with various topologies and parameters show that the approximation algorithms can obtain results close to the optimal solution with a significant reduction in computation time. We also derive new insights into the strategy for an IoT provider to optimize its objectives. Specifically, the results suggest that an IoT provider should select an appropriate service placement strategy with regard to a charging agreement with an NFV infrastructure provider, and only deploy service functions with a strict delay requirement on the edge of networks for optimizing its cost.","2169-3536","","10.1109/ACCESS.2020.3026711","National Foundation for Science and Technology Development (NAFOSTED) affiliated with the Vietnam Ministry of Science and Technology (MOST)(grant numbers:102.02-2020.13); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9206011","NIoT;resource management;optimization;NFV-enabled IoT systems;edge cloud computing","Internet of Things;Cloud computing;Resource management;Optimization;Computational modeling;Logic gates;Routing","","16","","27","CCBY","25 Sep 2020","","","IEEE","IEEE Journals"
"Bio-Inspired Network Security for 5G-Enabled IoT Applications","K. Saleem; G. M. Alabduljabbar; N. Alrowais; J. Al-Muhtadi; M. Imran; J. J. P. C. Rodrigues","Center of Excellence in Information Assurance (CoEIA), King Saud University, Riyadh, Saudi Arabia; College of Computer and Information Sciences (CCIS), King Saud University, Riyadh, Saudi Arabia; College of Computer and Information Sciences (CCIS), King Saud University, Riyadh, Saudi Arabia; Center of Excellence in Information Assurance (CoEIA), King Saud University, Riyadh, Saudi Arabia; College of Applied Computer Science, King Saud University, Riyadh, Saudi Arabia; Center of Excellence in Information Assurance (CoEIA), King Saud University, Riyadh, Saudi Arabia","IEEE Access","30 Dec 2020","2020","8","","229152","229160","Every IPv6-enabled device connected and communicating over the Internet forms the Internet of things (IoT) that is prevalent in society and is used in daily life. This IoT platform will quickly grow to be populated with billions or more objects by making every electrical appliance, car, and even items of furniture smart and connected. The 5th generation (5G) and beyond networks will further boost these IoT systems. The massive utilization of these systems over gigabits per second generates numerous issues. Owing to the huge complexity in large-scale deployment of IoT, data privacy and security are the most prominent challenges, especially for critical applications such as Industry 4.0, e-healthcare, and military. Threat agents persistently strive to find new vulnerabilities and exploit them. Therefore, including promising security measures to support the running systems, not to harm or collapse them, is essential. Nature-inspired algorithms have the capability to provide autonomous and sustainable defense and healing mechanisms. This paper first surveys the 5G network layer security for IoT applications and lists the network layer security vulnerabilities and requirements in wireless sensor networks, IoT, and 5G-enabled IoT. Second, a detailed literature review is conducted with the current network layer security methods and the bio-inspired techniques for IoT applications exchanging data packets over 5G. Finally, the bio-inspired algorithms are analyzed in the context of providing a secure network layer for IoT applications connected over 5G and beyond networks.","2169-3536","","10.1109/ACCESS.2020.3046325","Deputyship for Research and Innovation, “Ministry of Education” in Saudi Arabia for funding this research work through the Project(grant numbers:IFKSURP-109); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9301313","5th generation network;artificial intelligence;biological;the Internet of Things;network layer;security;wireless sensor networks","Security;Internet of Things;5G mobile communication;Routing;Computer network reliability;Authentication;Genetic algorithms","","22","","63","CCBY","21 Dec 2020","","","IEEE","IEEE Journals"
"IoT Threat Detection Testbed Using Generative Adversarial Networks","F. Shaikh; E. Bou-Harb; A. Vehabovic; J. Crichigno; A. Yayimli; N. Ghani",Univ. of South Florida; Univ. of Texas San Antonio; Univ. of South Florida; Univ. of South Carolina; Valparaiso University; Univ. of South Florida,"2022 IEEE International Black Sea Conference on Communications and Networking (BlackSeaCom)","24 Aug 2022","2022","","","77","84","The Internet of Things (IoT) paradigm provides persistent sensing and data collection capabilities and is becoming increasingly prevalent across many market sectors. However, most IoT devices emphasize usability and function over security, making them very vulnerable to malicious exploits. This concern is evidenced by the increased use of compromised IoT devices in large scale bot networks (botnets) to launch distributed denial of service (DDoS) attacks against high value targets. Unsecured IoT systems can also provide entry points to private networks, allowing adversaries relatively easy access to valuable resources and services. Indeed, these evolving IoT threat vectors (ranging from brute force attacks to remote code execution exploits) are posing key challenges. Moreover, many traditional security mechanisms are not amenable for deployment on smaller resource-constrained IoT platforms. As a result, researchers have been developing a range of methods for IoT security, with many strategies using advanced machine learning (ML) techniques. Along these lines, this paper presents a novel generative adversarial network (GAN) solution to detect threats from malicious IoT devices both inside and outside a network. This model is trained using both benign IoT traffic and global darknet data and further evaluated in a testbed with real IoT devices and malware threats.","","978-1-6654-9749-7","10.1109/BlackSeaCom54372.2022.9858239","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9858239","Machine learning;deep learning;IoT security;malware;generative adversarial networks (GAN)","Force;Machine learning;Generative adversarial networks;Denial-of-service attack;Malware;Distance measurement;Sensors","","","","25","IEEE","24 Aug 2022","","","IEEE","IEEE Conferences"
"Smart City Battery Operated IoT Based Indoor Air Quality Monitoring System","S. Esfahani; P. Rollins; J. P. Specht; M. Cole; J. W. Gardner","School of Engineering, University of Warwick, Coventry, UK; School of Engineering, University of Warwick, Coventry, UK; School of Engineering, University of Warwick, Coventry, UK; School of Engineering, University of Warwick, Coventry, UK; School of Engineering, University of Warwick, Coventry, UK","2020 IEEE SENSORS","9 Dec 2020","2020","","","1","4","Indoor and outdoor air pollution is known to cause many health problems. In order to improve air quality it is essential to monitor relevant parameters and identify sources of pollutants. This paper presents the design and development of a low-cost, portable Internet of Things (IoT) Indoor Air Quality (IAQ) monitoring system with 30 hours of battery life. The unit is intended for the monitoring of total VOCs, CO2, PM2.5, PM10, temperature, humidity and illuminance. The system can be used for both real-time measurements as well as hourly and daily averaging, in low power modes, and interfaces with a custom Blynk smartphone app, developed for easy user engagement. The device calculates a qualitative air quality index from measurements taken in-situ, based on United States Environmental Protection Agency (EPA) standards. Environmental data is used by the system to provide recommendations, such as increasing ventilation or reducing activity levels, which can help users improve their air quality. This system can be used as a node to monitor air quality in large scale networks for Smart Cities.","2168-9229","978-1-7281-6801-2","10.1109/SENSORS47125.2020.9278913","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9278913","Air Quality Monitoring;Internet of Things;Indoor air quality;Cloud Computing Component;Smart Cities","Monitoring;Air quality;Temperature measurement;Temperature sensors;Pollution measurement;Atmospheric measurements;Indexes","","28","","12","IEEE","9 Dec 2020","","","IEEE","IEEE Conferences"
"Simulation of Large-Scale 5G Communication Optimization Model Based on Fuzzy Neural Network Optimization Algorithm","X. Zhou; S. Lv; X. Luo; X. Li; C. Huang","Information & Communication Branch of Hubei epc, Wuhan, Hubei, China; Information & Communication Branch of Hubei epc, Wuhan, Hubei, China; Information & Communication Branch of Hubei epc, Wuhan, Hubei, China; Information & Communication Branch of Hubei epc, Wuhan, Hubei, China; Information & Communication Branch of Hubei epc, Wuhan, Hubei, China","2023 International Conference on Power, Electrical Engineering, Electronics and Control (PEEEC)","1 Feb 2024","2023","","","849","853","With the rapid development of Internet of Things (IoT) technology, the demand for machine communication (MTC) is increasing. The traditional cellular mobile communication system designed and built for human communication (HTC) will not meet the communication needs of MTC. At the same time, due to the huge number of users and the expanded network scale, the energy consumption of wireless communication network system is on the rise. The environmental pollution caused by greenhouse gas emissions generated by wireless communication systems and the accompanying huge energy consumption have attracted wide attention of operators and the whole society. This article briefly introduces the development of 5G wireless communication systems, comprehensively summarizes the spectrum allocation of millimeter waves, channel propagation characteristics, channel measurement methods, channel detectors, channel parameter estimation algorithms, channel modeling methods, and standardized channel models. A large number of multi band and multi scene millimeter wave channel measurements have been conducted. Experiments were conducted using UCI datasets and engineering examples, and compared with traditional cloud models, fuzzy neural networks, and BP neural networks to analyze the operational efficiency, accuracy, and number of rules of the algorithm. In addition, computer simulation further verifies that the proposed method can achieve better performance compared to several existing codebook design methods.","","979-8-3503-2912-4","10.1109/PEEEC60561.2023.00167","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10414789","Fuzzy neural network;Large scale 5G communication;Optimization model simulation","Wireless communication;5G mobile communication;Millimeter wave measurements;Channel estimation;Fuzzy neural networks;Pollution measurement;Antenna arrays","","","","10","IEEE","1 Feb 2024","","","IEEE","IEEE Conferences"
"Performance Prospects of Deeply Scaled Spin-Transfer Torque Magnetic Random-Access Memory for In-Memory Computing","Y. Shi; S. Oh; Z. Huang; X. Lu; S. H. Kang; D. Kuzum","Electrical and Computer Engineering Department, University of California at San Diego, San Diego, USA; Electrical and Computer Engineering Department, University of California at San Diego, San Diego, USA; Electrical and Computer Engineering Department, University of California at San Diego, San Diego, USA; Qualcomm Inc, San Diego, USA; Qualcomm Inc, San Diego, USA; Electrical and Computer Engineering Department, University of California at San Diego, San Diego, USA","IEEE Electron Device Letters","29 Jun 2020","2020","41","7","1126","1129","In recent years, Spin-Transfer-Torque Magnetic Random Access Memory (STT-MRAM) has been considered as one of the most promising non-volatile memory candidates for in-memory computing. However, system-level performance gains using STT-MRAM for in-memory computing at deeply scaled nodes have not been assessed with respect to more mature memory technologies. In this letter, we present perpendicular magnetic tunnel junction (pMTJ) STT-MRAM devices at 28nm and 7nm. We evaluate the system-level performance of convolutional neural network (CNN) inference with STT-MRAM arrays in comparison to Static Random Access Memory (SRAM). We benchmark STT-MRAM and SRAM in terms of area, leakage power, energy, and latency from 65nm to 7nm technology nodes. Our results show that STT-MRAM keeps providing ~5× smaller synaptic core area, ~20× less leakage power, and ~7× less energy than SRAM when both devices are scaled from 65nm to 7nm. With the emerging need for low power computation for a broad range of applications such as internet-of-things (IoT) and neural network (NN), STT-MRAM can offer energy-efficient and high-density in-memory computing.","1558-0563","","10.1109/LED.2020.2995819","Qualcomm FMA fellowship(grant numbers:N00014-20-1-2405); Office of Naval Research(grant numbers:N00014-20-1-2405); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9097177","pMTJ;STT-MRAM;SRAM;neural networks;in-memory computing","Random access memory;Artificial neural networks;Magnetic tunneling;Performance evaluation;Performance gain;Computer architecture;Microprocessors","","21","","24","IEEE","20 May 2020","","","IEEE","IEEE Journals"
"Efficient FPGA-Based Accelerator of the L-BFGS Algorithm for IoT Applications","H. Xiong; B. Xiong; W. Wang; J. Tian; H. Zhu; Z. Wang","School of Electronic Science and Engineering, Nanjing University, Nanjing, China; School of Electronic Science and Engineering, Nanjing University, Nanjing, China; School of Electronic Science and Engineering, Nanjing University, Nanjing, China; School of Electronic Science and Engineering, Nanjing University, Nanjing, China; School of Electronic Science and Engineering, Nanjing University, Nanjing, China; School of Electronic Science and Engineering, Nanjing University, Nanjing, China","2023 IEEE International Symposium on Circuits and Systems (ISCAS)","21 Jul 2023","2023","","","1","5","The Internet of Things (IoT)-centric applications, such as augmented reality and self-driven cars, require real-time task processing, large bandwidth, and low data transmission latency. FPGA-based edge computing is considered an effective solution to tackle these challenges. As an excellent tool in these applications, nonlinear optimization methods involve computation-intensive and data-dependency operations leading to limited real-time applications. The limited-memory Broyden-Fletcher-Goldfarb-Shanno (L-BFGS) algorithm ranks among the most efficient algorithms for large-scale optimization problems. In this paper, we propose, for the first time, a high-parallel FPGA-based architecture for the two key parts of the L-BFGS algorithm: the search direction computation and line searching. Compared with the implementation on CPU, the search direction computation and line searching implementation on FPGA achieve $\mathbf{39.73}\times$ and $\mathbf{5.50}\times$ speedups, respectively. Compared with the straightforward implementation on GPU, the search direction computation on FPGA obtains a speedup of $\mathbf{31.03}\times$.","2158-1525","978-1-6654-5109-3","10.1109/ISCAS46773.2023.10181544","National Natural Science Foundation of China(grant numbers:62104097,62001213); Key Research Plan of Jiangsu Province of China(grant numbers:BE2022098); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10181544","IoT;FPGA;nonlinear optimization;L-BFGS;hardware implementation","Circuits and systems;Optimization methods;Graphics processing units;Computer architecture;Real-time systems;Internet of Things;Data communication","","","","13","IEEE","21 Jul 2023","","","IEEE","IEEE Conferences"
"A Novel MIMO IoT Antenna Selection Strategy Assisted by Machine Learning","S. Mishra","Centre for Interdisciplinary Research in Business and Technology, Chitkara University Institute of Engineering and Technology, Chitkara University, Punjab, India","2023 3rd International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE)","24 Jul 2023","2023","","","2532","2536","In this paper, we suggest a transmission antenna selecting (AS) method assisted by a multi-label convolutional neural networks for end-to-end multiple-input multiple-output Internet of Things (IoT) connectivity networks under correlation channels circumstances. In the suggested convolutional neural networks-aided transmission AS multiple-input multiple-output IoT systems, we choose to use the notion of multi-label rather than the traditional single-label multi-class categorization ML schemes, which may significantly shorten the duration of train labeling in the case of multi-antenna choice. Using the multi-label idea may also greatly increase the trained convolutional neural networks model’s prediction performance in related large-scale multiple-input multiple-output channels situations with less train information. According to the relevant simulations outcomes, the suggested convolutional neural networks-aided AS system may be capable to achieve near-optimal capacities efficiency in real time, where the efficiency is somewhat unaffected by the consequences of faulty CSI.","","979-8-3503-9926-4","10.1109/ICACITE57410.2023.10183036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10183036","multiple-input multiple-output;Internet of Things (IoT);multi-label convolution neural network;antenna selection (AS);machine learning","Correlation;Simulation;Transmitting antennas;Predictive models;MIMO;Real-time systems;Convolutional neural networks","","","","33","IEEE","24 Jul 2023","","","IEEE","IEEE Conferences"
"AdaBoost-Based Cyberattack Detection Algorithm for Battery Systems Providing Frequency Regulation","N. Kharlamova; C. Træholt; S. Hashemi","Department of Wind Energy, Technical University of Denmark, Copenhagen, Denmark; Department of Wind Energy, Technical University of Denmark, Copenhagen, Denmark; Department of Wind Energy, Technical University of Denmark, Copenhagen, Denmark","2023 IEEE 3rd International Conference on Industrial Electronics for Sustainable Energy Systems (IESES)","25 Sep 2023","2023","","","1","5","The intermittent nature of renewable energy sources may require the integration of an increasing amount of battery energy storage systems (BESSs) in the electrical grid. A BESS can provide multiple services such as frequency regulation and backup. Simultaneously, internet-of-things (IoT) enabled technologies are increasingly being applied in the BESS domain. IoT integration is not supported by any specific regulations with respect to BESS design and operation, which can increase the vulnerability of utility-scale batteries to cyberattacks. Cyberattacks can compromise the ability of BESSs to provide an adequate and reliable response to the system's demand. This paper presents a machine-learning-based algorithm for cyberattack detection that can decrease the vulnerability of a BESS to cyber threats. It utilizes Adaptive Boosting to forecast the state of charge and detect potentially corrupted data. Moreover, this paper presents mathematical models of cyberattacks than can be applied against a BESS, providing frequency regulation. The benefits of applying the novel cyberattack detection algorithm are demonstrated in the example of the simulated dataset. The dataset is generated based on parameters of the largest grid-connected BESS in Denmark as well as real frequency data of the Nordic Region.","","979-8-3503-2475-4","10.1109/IESES53571.2023.10253743","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10253743","AdaBoost;artificial intelligence;battery energy storage system;battery state estimation","Renewable energy sources;Sensitivity;Detectors;Batteries;Internet of Things;State of charge;Computer crime","","","","19","IEEE","25 Sep 2023","","","IEEE","IEEE Conferences"
"Heterogeneous Wireless Device Management in Edge Computing Systems for IoT Services","M. Vitumbiko; Y. Kim","School of Electronic Engineering, Seoul, Korea; School of Electronic Engineering, Seoul, Korea","2023 14th International Conference on Information and Communication Technology Convergence (ICTC)","23 Jan 2024","2023","","","616","618","In a heterogeneous Internet of Things (IoT) setup, it is impractical and requires human intervention to deploy workloads for every device after enrolment, especially considering the diverse range of wireless technologies involved. Furthermore, it is extremely complex to design and develop a large-scale system that can accommodate and integrate heterogeneous wireless technologies to achieve interoperability between the devices. As the number of devices increases, it is necessary to dynamically adjust workloads to accommodate the growing demand and maintain quality of service. In this paper we employ a state-of-art solution called Project-Flotta, which is utilized for managing edge devices and edge workloads. However, Project-Flotta does not provide a way of automating and managing heterogeneous wireless technologies for an IoT service. Therefore, we propose a system based on Project-Flotta leveraging its kubernetes custom resources by extending its functionality to adapt diverse wireless technologies.","2162-1241","979-8-3503-1327-7","10.1109/ICTC58733.2023.10393081","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10393081","kubernetes;Project-Flotta;horizontal pod auto scaling;automation;edge compuning;heterogenous;wireless sensor","Wireless communication;Wireless sensor networks;Quality of service;Large-scale systems;Information and communication technology;Internet of Things;Interoperability","","","","21","IEEE","23 Jan 2024","","","IEEE","IEEE Conferences"
"An Efficient Workflow Management Model for Fog Computing","C. S; M. S","Department of Computer Science, Amrita School of Arts and Sciences, Mysuru Amrita Vishwa Vidyapeetham, India; Department of Computer Science, Amrita School of Arts and Sciences, Mysuru Amrita Vishwa Vidyapeetham, India","2021 Third International Conference on Inventive Research in Computing Applications (ICIRCA)","1 Oct 2021","2021","","","1323","1328","With the emergence of the Internet of Things, there has been significant growth in the number of smart compatible devices, necessitating the development of more effective data storage systems. So far, cloud storage has shown to be a feasible method for storing and processing enormous amounts of data. Due to bandwidth limits, cloud computing is projected to fail in the future years to manage the massive amounts of data created by IoT devices. Fog Computing is a more advanced technique that aims to address several flaws in large-scale IoT networks. Fog Computing is anticipated to enable mobile users near high-quality Cloud services. With low latency and high bandwidth, the Fog can supply computing power and storage space. The proposed study focuses on a fog-based workflow management system that eliminates cloud-based restrictions such as bandwidth, latency, and data storage.","","978-1-6654-3877-3","10.1109/ICIRCA51532.2021.9544673","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9544673","fog computing;cloud;Interntet of Things;optimised workflow;green ecosystem;hybrid cloud system","Cloud computing;Memory;Bandwidth;Resource management;Internet of Things;Low latency communication;Workflow management software","","","","27","IEEE","1 Oct 2021","","","IEEE","IEEE Conferences"
"Precision Solutions in Livestock Farming – feasibility and applicability of digital data collection","M. Alexy; T. Haidegger","University Research and Innovation Center (EKIK), Óbuda University, Budapest, Hungary; University Research and Innovation Center (EKIK)/John von Neumann Faculty of Informatics (NIK) Óbuda University, Budapest, HU","2022 IEEE 10th Jubilee International Conference on Computational Cybernetics and Cyber-Medical Systems (ICCC)","21 Oct 2022","2022","","","000233","000238","Food production systems face many challenges nowadays. Concerns regarding the environmental impact of increasingly intensive production, the rising cost of inputs needed to achieve adequate yields and the negative impact of the COVID-19 pandemic have put, and continuously put the agricultural sector in a difficult position regarding its sustainability, since even customers became conscious about them. Such external factors have affected both the animal production and the crop farming, inducing fundamental changes in these sectors, leading towards smart agriculture. Technology solutions have been increasingly experimented with and deployed to counterbalance the above. Currently, precision farming, and the use of so-called precision livestock technologies in large-scale livestock systems offer tangible, yet costly implementations to monitor and optimize yields. While pilot studies and prototypes have been widely demonstrated in the past 10 years, standard, scalable Internet of Things (IoT) based implementations are still lacking, mostly due to the complexity of the technology application. Many factors should be considered from communication protocol to protection against weather conditions to ensure that the employed IT solution can really add value to the livestock farmer at the end of the production cycle. This scoping review is focusing on the current good practices and challenges of the domain, and on appropriate data collection. Theoretical and practical factors that determine the quality of data collection and pre-processing are presented in this article, aiming to pave the road for future scalable precision livestock IoT implementation.","","978-1-6654-8177-9","10.1109/ICCC202255925.2022.9922883","Innovation Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9922883","precision farming;digital data collection;Internet of Things;environment;farm animals;farm-to-fork technologies","Smart agriculture;Protocols;Animals;Roads;Prototypes;Data collection;Internet of Things","","","","20","IEEE","21 Oct 2022","","","IEEE","IEEE Conferences"
"Joint Sub-Carriers and Spreading Factors Allocation for LoRaWAN IoT Networks","M. M. Salah; R. S. Saad; B. M. ElHalawany","Faculty of Engineering at Shoubra, Benha University, Egypt; Faculty of Engineering at Shoubra, Benha University, Egypt; Faculty of Engineering at Shoubra, Benha University, Egypt","2022 International Telecommunications Conference (ITC-Egypt)","19 Aug 2022","2022","","","1","5","Low-power wide-area networks (LPWAN) are gaining a lot of interest to support Internet of things (IoT) applications. LPWAN can provide massive connectivity and services for thousands of nodes with low power consumption, which is crucial for battery-based IoT devices. Different technologies have been proposed for (LPWAN), however, long range wide-area network (LoRaWAN) is one of the most promising and widely used types that provide large-scale deployment, high energy efficiency, and low-cost. Resources allocation in LoRaWAN has vital role to enhance the system performance. In this work, we propose a resource allocation technique that aims to minimize the total system transmit power. The proposed technique exploits the Hungarian matching algorithm to assign both the LoRaWAN spreading factors (SFs) and the sub-carriers (SCs) for different end nodes. The results show that the performance of the proposed Hungarian-based resources allocation algorithm reduces the power consumption compared with other conventional algorithms. Additionally, it provides a better energy efficiency.","","978-1-6654-8808-2","10.1109/ITC-Egypt55520.2022.9855747","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9855747","IoT;LPWAN;LoRaWAN;Resource allocation;Spreading Factor;sub-carriers;Hungarian Algorithm","Power demand;System performance;Heuristic algorithms;Machine learning;Energy efficiency;Telecommunications;Resource management","","","","25","IEEE","19 Aug 2022","","","IEEE","IEEE Conferences"
"Design, Resource Management, and Evaluation of Fog Computing Systems: A Survey","I. Martinez; A. S. Hafid; A. Jarray","Department of Computer Science and Operations Research, University of Montreal, Montreal, Canada; Department of Computer Science and Operations Research, University of Montreal, Montreal, Canada; School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, Canada","IEEE Internet of Things Journal","5 Feb 2021","2021","8","4","2494","2516","A steady increase in Internet-of-Things (IoT) applications needing large-scale computation and long-term storage has lead to an overreliance on cloud computing. The resulting network congestion in the cloud, coupled with the distance of cloud data centers from IoT, contributes to unreliable end-to-end response delay. Fog computing has been introduced as an alternative to cloud, providing low-latency service by bringing processing and storage resources to the network edge. In this survey, we sequentially present the phases required in the implementation and realization of practical fog computing systems: 1) design and dimensioning of a fog infrastructure; 2) fog resource provisioning for IoT application use and IoT resource allocation to fog; 3) installation of fog frameworks for fog resource management; and 4) evaluation of fog infrastructure through simulation and emulation. Our focus is on determining the implementation aspects required to build a practical large-scale fog computing infrastructure to support the general IoT landscape.","2327-4662","","10.1109/JIOT.2020.3022699","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9194714","Fog computing;fog design and dimensioning;fog infrastructure evaluation;fog resource management;Internet of Things (IoT);simulation;survey","Cloud computing;Edge computing;Resource management;Servers;Internet of Things;Computational modeling;Tools","","72","","141","IEEE","11 Sep 2020","","","IEEE","IEEE Journals"
"ARBA: Anomaly and Reputation Based Approach for Detecting Infected IoT Devices","G. Rosenthal; O. E. Kdosha; K. Cohen; A. Freund; A. Bartik; A. Ron","School of Electrical and Computer Engineering, Ben-Gurion University of the Negev, Be’er Sheva, Israel; School of Electrical and Computer Engineering, Ben-Gurion University of the Negev, Be’er Sheva, Israel; School of Electrical and Computer Engineering, Ben-Gurion University of the Negev, Be’er Sheva, Israel; IBM Cyber Security Center of Excellence, Be’er Sheva, Israel; IBM Cyber Security Center of Excellence, Be’er Sheva, Israel; IBM Cyber Security Center of Excellence, Be’er Sheva, Israel","IEEE Access","14 Aug 2020","2020","8","","145751","145767","Today, cyber attacks are constantly evolving and changing, which makes them harder to detect. In particular, detecting attacks in large-scale networks is very challenging because they require high detection rates under real-time resource constraints. In this paper, we focus on detecting infected Internet of Things (IoT) hosts from domain name system (DNS) traffic data. IoT hosts, such as streaming cameras, printers, air conditioners, are hard to protect, unlike PCs and servers. Enterprises are often unaware of the devices which are connected to the network, their types, makes, and vulnerabilities. Since IoT hosts make use of the DNS protocol, analyzing DNS data can give a broad view of malicious activities, because they abuse the DNS protocol and leave fingerprints as part of their attack vector. In this collaborative research between Ben-Gurion University, and IBM, we establish a novel algorithm to detect infected IoT hosts in large-scale DNS traffic, named Anomaly and Reputation Based Algorithm (ARBA). Its novelty resides in developing a framework that combines host classification and domain reputation in a real-time production environment. ARBA is highly computational efficient and meets real-time requirements in terms of run time and computational complexity. By contrast to existing algorithms, it does not require a massive traffic volume for training, which is of significant interest in detecting infected hosts in real-time. The research was conducted on real live streaming data from IBM internal network traffic, and confirm the algorithm's strong performance in a real-time production environment.","2169-3536","","10.1109/ACCESS.2020.3014619","IBM Cyber Security Center of Excellence, Gav-Yam Negev; Israeli National Cyber Bureau via the Cyber Security Research Center, Ben-Gurion University of the Negev; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9160931","Cyber security;anomaly detection;domain name system (DNS);detection algorithms;real-time algorithms","Real-time systems;Machine learning algorithms;Botnet;Computer crime;Internet of Things;Anomaly detection","","5","","58","CCBY","6 Aug 2020","","","IEEE","IEEE Journals"
"A Novel Semi-Supervised Learning Framework for Specific Emitter Identification","X. Fu; Y. Wang; Y. Lin; G. Gui; H. Gacanin; F. Adachi","College of Telecommunications and Information Engineering, NJUPT, Nanjing, China; College of Telecommunications and Information Engineering, NJUPT, Nanjing, China; College of Information and Communication Engineering, Harbin Engineering University, Harbin, China; College of Telecommunications and Information Engineering, NJUPT, Nanjing, China; Institute for Communication Technologies and Embedded Systems, RWTH Aachen University, Aachen, Germany; International Research Institute of Disaster Science (IRIDeS), Tohoku University, Sendai, Japan","2022 IEEE 96th Vehicular Technology Conference (VTC2022-Fall)","18 Jan 2023","2022","","","1","5","Specific emitter identification (SEI) is developed as a potential technology against attackers in cognitive radio networks and authenticate devices in Internet of Things (IoT). It refers to a process to discriminate individual emitters from each other by analyzing extracted characteristics from given radio signals. Due to the strong capability of deep learning (DL) in extracting the hidden features of data and making classification decision, deep neural networks (DNNs) have been widely used in the SEI. Considering the insufficiently labeled training dataset and large unlabeled training dataset, we propose a novel SEI method using semi-supervised (SS) learning framework, i.e., metric-adversarial training (MAT). Specifically, two object functions (i.e., cross-entropy (CE) loss combined with deep metric learning (DML) and CE loss combined with virtual adversarial training (VAT)) and an alternating optimization way are designed to extract discriminative and generalized semantic features of radio signals. The proposed MAT-based SS-SEI method is evaluated on an open source large-scale real-world automatic-dependent surveillance-broadcast (ADS-B) dataset. The simulation results show that the proposed method achieves a better identification performance than four latest SS-SEI methods.","2577-2465","978-1-6654-5468-1","10.1109/VTC2022-Fall57202.2022.10012910","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10012910","Specific emitter identification (SEI);semi-supervised learning;deep metric learning;virtual adversarial training;alternating optimization","Training;Measurement;Deep learning;Vehicular and wireless technologies;Simulation;Semantics;Semisupervised learning","","4","","26","IEEE","18 Jan 2023","","","IEEE","IEEE Conferences"
"Real-Time Facial Expression Recognition Based on Edge Computing","J. Yang; T. Qian; F. Zhang; S. U. Khan","Department of Computer Science and Technology, Nanjing Tech University, Nanjing, China; Department of Computer Science and Technology, Nanjing Tech University, Nanjing, China; IBM Massachusetts Laboratory, IBM Watson Group, Littleton, MA, USA; Department of Electrical and Computer Engineering, Mississippi State University, Mississippi State, MS, USA","IEEE Access","27 May 2021","2021","9","","76178","76190","In recent years, many large-scale information systems in the Internet of Things (IoT) can be converted into interdependent sensor networks, such as smart cities, smart medical systems, and industrial Internet systems. The successful application of edge computing in the IoT will make our algorithms faster, more convenient, lower overall costs, providing better business practices, and enhance sustainability. Facial action unit (AU) detection recognizes facial expressions by analyzing cues about the movement of certain atomic muscles in the local facial area. According to the detected facial feature points, we could calculate the values of AU, and then use classification algorithms for emotion recognition. In edge devices, using optimized and custom algorithms to directly process the raw image data from each camera, the detected emotions can be more easily transmitted to the end-user. Due to the tremendous network overhead of transferring the facial action unit feature data, it poses challenges of a real-time facial expression recognition system being deployed in a distributed manner while running in production. Therefore, we designed a lightweight edge computing-based distributed system using Raspberry Pi tailed for this need, and we optimized the data transfer and components deployment. In the vicinity, the front-end and back-end processing modes are separated to reduce round-trip delay, thereby completing complex computing tasks and providing high-reliability, large-scale connection services. For IoT or smart city applications and services, they can be made into smart sensing systems that can be deployed anywhere with network connections.","2169-3536","","10.1109/ACCESS.2021.3082641","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9438728","Edge computing;facial expression recognition;real-time;facial action units;Raspberry Pi","Gold;Feature extraction;Edge computing;Image edge detection;Face recognition;Task analysis;Servers","","17","","49","CCBY","21 May 2021","","","IEEE","IEEE Journals"
"Design of Logistics Information Management System Based On Improved Genetic Algorithm In The Context of Internet of Things","X. Chen; F. Jia","Quanzhou University of Information Engineering, Quanzhou, China; Quanzhou University of Information Engineering, Quanzhou, China","2023 5th International Conference on Decision Science & Management (ICDSM)","14 Nov 2023","2023","","","14","19","The network infrastructure has more selectivity, which leads to high energy consumption of the IoT control platform of the heat collection system and can not effectively improve the heat energy conversion rate of the heat collection system. Therefore, the IoT control platform of heat energy collection system based on genetic algorithm is designed. After the logistics industry enters the information age, it also needs information management. By establishing an efficient and smooth logistics information system, it can carry out scientific management of logistics and complete the whole process information of logistics decision-making, business process and customer service, which is logistics management information. As a large-scale integrated network oriented to the whole manufacturing process, the Internet of Things for Manufacturing includes data collection, transmission, processing, control and service, which realizes the optimal scheduling control and dynamic information service of the whole complex industrial manufacturing process. In the data real-time transmission layer, the IoT in manufacturing has the characteristics of highly heterogeneous network structure, wireless network with large scale and multi hop, dynamic network topology change, various transmission data types, the important role of manufacturing enterprises in China's economic development, and the role of logistics management in manufacturing enterprise management. This paper specifically describes the current situation and practical problems of logistics management within manufacturing enterprises in China, and provides solutions for the existing entities. According to the relationship between the enterprise logistics inside the enterprise and the social logistics outside the enterprise in the enterprise logistics management, the requirements for realizing the enterprise logistics informatization inside the enterprise are proposed. As a rising industry in the national economy, the logistics industry will become an important industrial sector and a new economic growth point in China in this century. Therefore, the development of the logistics industry has attracted the attention of governments at all levels. As many logistics enterprises have transformed from the original transportation industry or warehousing industry, lacking the necessary management information system and business integration and integration scheme, they can no longer meet the requirements of online e-commerce development for logistics distribution, and have become one of the important bottlenecks in the development of e-commerce in China. Computers and the Internet have penetrated into all areas of society, such as politics, economy, culture, and driven the rapid development of these areas. At this stage, communication network has become a powerful force for social development and the lifeblood of national development. Countries all over the world also pay more and more attention to the development of computers and networks, and want to be the master of world information.","","979-8-3503-2501-0","10.1109/ICDSM59373.2023.00014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10314118","component;Internet of Things;Genetic Algorithm;Logistics Information Management","Heating systems;Manufacturing processes;Warehousing;Production;Spatial databases;Manufacturing;Information management","","","","10","IEEE","14 Nov 2023","","","IEEE","IEEE Conferences"
"Path Planning for Large-Scale Data Collection in UAV-Assisted loT System","S. Bai; M. Li; J. Miao","Beijing Laboratory of Advanced Information Networks, Beijing University of Posts and Telecommunications, Beijing, China; Beijing Laboratory of Advanced Information Networks, Beijing University of Posts and Telecommunications, Beijing, China; Beijing Laboratory of Advanced Information Networks, Beijing University of Posts and Telecommunications, Beijing, China","2022 IEEE 8th International Conference on Computer and Communications (ICCC)","20 Mar 2023","2022","","","817","822","Unmanned aerial vehicle (UAV) is deemed the most prospective technique for data collection in the future Internet of Things (IoT), due to its flexible deployment, potential mobility, and low cost. In order to ensure that UAV s can choose the most efficient and reliable flight route in complex environments, we propose a novel path planning scheme for data collection in a large-scale loT system based on Hilbert curve and ge-netic algorithm (HC-GA). We aim to minimize the total path length of the UAV by optimizing the flight path of the UA V. Meanwhile, the simulation time of the proposed algorithm is optimized to ensure real-time. Simulation results demonstrate that the proposed scheme could reduce the path length efficiently compared with benchmark algorithms. The simulation time cost for path planning is limited to a satisfactory volume, especially for scenarios with a large scale of sensor nodes.","","978-1-6654-5051-5","10.1109/ICCC56324.2022.10065725","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10065725","UAV path planning;data collection;genetic algorithm;Hilbert curve","Solid modeling;Costs;Simulation;Data collection;Physical layer security;Autonomous aerial vehicles;Real-time systems","","","","10","IEEE","20 Mar 2023","","","IEEE","IEEE Conferences"
"Scalable Impact Range Detection against Newly Added Rules for Smart Network Verification","Y. Takita; M. Miyabe; H. Tomonaga; N. Oguchi",Fujitsu Laboratories Limited; Fujitsu Laboratories Limited; Fujitsu Laboratories Limited; Fujitsu Laboratories Limited,"2020 IEEE 44th Annual Computers, Software, and Applications Conference (COMPSAC)","22 Sep 2020","2020","","","1471","1476","Technological progress in cloud networking, 5G networks, and the IoT (Internet of Things) are remarkable. In addition, demands for flexible construction of SoEs (Systems on Engagement) for various type of businesses are increasing. In such environments, dynamic changes of network rules, such as access control (AC) or packet forwarding, are required to ensure function and security in networks. On the other hand, it is becoming increasingly difficult to grasp the exact situation in such networks by utilizing current well-known network verification technologies since a huge number of network rules are complexly intertwined. To mitigate these issues, we have proposed a scalable network verification approach utilizing the concept of ""Packet Equivalence Class (PEC),"" which enable precise network function verification by strictly recognizing the impact range of each network rule. However, this approach is still not scalable for very large-scale networks which consist of tens of thousands of routers. In this paper, we enhanced our impact range detection algorithm for practical large-scale networks. Through evaluation in the network with more than 80,000 AC rules, we confirmed that our enhanced algorithm can achieve precise impact range detection in under 600 seconds.","0730-3157","978-1-7281-7303-0","10.1109/COMPSAC48688.2020.00-47","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9202792","network verification, access control, packet forwarding, packet equivalence class, impact range recognition, Hasse diagram","Firewalls (computing);Internet of Things;Access control;Servers;IP networks;Detection algorithms;Cloud computing","","","","12","IEEE","22 Sep 2020","","","IEEE","IEEE Conferences"
"IoT Based Network Model And Sensor Node Prototype For Precision Agriculture Application","J. Spisic; J. Balen; D. Zagar; V. Galić","Faculty of Electrical Engineering, Computer Science and Information Technology, Josip Juraj Strossmayer University of Osijek, Osijek, Croatia; Faculty of Electrical Engineering, Computer Science and Information Technology, Josip Juraj Strossmayer University of Osijek, Osijek, Croatia; Faculty of Electrical Engineering, Computer Science and Information Technology, Josip Juraj Strossmayer University of Osijek, Osijek, Croatia; Agricultural Institute Osijek, Osijek, Croatia","2022 IEEE 8th World Forum on Internet of Things (WF-IoT)","22 Jun 2023","2022","","","1","8","The recent advancement of the Internet of Things (IoT) enabled the development of precision agriculture by using high technology sensors and analysis tools for improving crop yields and assisting management decisions. Due to its highly interoperable, scalable, widespread, and open nature, the IoT approach is an ideal match for precision agriculture. We built our model in response to the above benefits and potentials of IoT in precision agriculture. In this paper we propose a low cost IoT based network model using the developed IoT sensor node for precision agriculture applications consisting of a near-infrared sensor and general purpose microcontroller for gathering data from agricultural fields. Our model architecture is extremely flexible, and it provides a machine learning data analytics solution that enables small size data processing at the edge of the network (sensor nodes) and large-scale data processing on real-time observation streams of data from a number nodes in the cloud. We employ LoRaWAN™, a wide area networking protocol as a transmission protocol in our solution, which has a low power consumption, long-range capability, it's affordable and requires little maintenance, making it perfect for large fields and variable number of sensor nodes. According to the first results of device testing presented in this report, our device might provide affordable means of field-based spatio-temporal sensing.","","978-1-6654-9153-2","10.1109/WF-IoT54382.2022.10152218","European Union; European Regional Development Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10152218","IoT;LPWAN;near-infrared spectroscopy;precision agriculture;sensor","Protocols;Power demand;Microcontrollers;Prototypes;Agriculture;Data models;Real-time systems","","1","","30","IEEE","22 Jun 2023","","","IEEE","IEEE Conferences"
"A Comprehensive Review on Artificial Intelligence/Machine Learning Algorithms for Empowering the Future IoT Toward 6G Era","M. R. Mahmood; M. A. Matin; P. Sarigiannidis; S. K. Goudos","Department of Electrical and Computer Engineering, North South University, Dhaka, Bangladesh; Department of Electrical and Computer Engineering, North South University, Dhaka, Bangladesh; Department of Informatics and Telecommunications Engineering, University of Western Macedonia, Kozani, Greece; Department of Physics, ELEDIA@AUTH, Aristotle University of Thessaloniki, Thessaloniki, Greece","IEEE Access","26 Aug 2022","2022","10","","87535","87562","The evolution of the wireless network systems over decades has been providing new services to the users with the help of innovative network and device technologies. In recent times, the 5G network systems are about to be deployed which creates the opportunity to realize massive connectivity with high throughput, low latency, high energy efficiency and security. It also focuses on providing massive Internet of Things (IoT) network connectivity as well as services for good health, large-scale agricultural and industrial production, intelligent traffic control and electricity generation, transmission and distribution systems. However, the ever-increasing number of user devices is directing the researchers towards beyond 5G systems to allocate these user devices with higher bandwidth. Researches on the 6G wireless network systems have already begun to provide higher bandwidth availability for densely connected larger network devices with QoS surety. Researchers are leveraging artificial intelligence (AI)/machine learning (ML) for enhancing future IoT network operations and services. This paper attempts to discuss AI/ML algorithms that can help in developing energy efficient, secured and effective IoT network operations and services. In particular, our article concentrates on the major issues and factors that influence the design of the communication systems for future IoT with the integration of AI/ML. It also highlights application domains, including smart healthcare, smart agriculture, smart transportation, smart grid and smart industry that can operate efficiently and securely. Finally, this paper ends with the discussion on future research scopes with these algorithms in addressing the open issues of the future IoT network systems.","2169-3536","","10.1109/ACCESS.2022.3199689","European Union's Horizon 2020 research and innovation programme(grant numbers:957406 (TERMINET)); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9861650","Future IoT;future communication systems;B5G/6G;artificial intelligence;machine learning","6G mobile communication;Communication systems;5G mobile communication;Internet of Things;Wireless networks;Network systems;Energy efficiency;Artificial intelligence;Machine learning","","31","","192","CCBY","18 Aug 2022","","","IEEE","IEEE Journals"
"AirSync: Time Synchronization for Large-Scale IoT Networks Using Aircraft Signals","S. Zhu; X. Zheng; L. Liu; H. Ma","School of Computer Science and Beijing Key Lab of Intelligent Telecommunication Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing, China; School of Computer Science and Beijing Key Lab of Intelligent Telecommunication Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing, China; School of Computer Science and Beijing Key Lab of Intelligent Telecommunication Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing, China; School of Computer Science and Beijing Key Lab of Intelligent Telecommunication Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing, China","IEEE Transactions on Mobile Computing","5 Dec 2022","2023","22","1","69","83","The prosperity of Internet of Things (IoT) brings forth the deployment of large-scale sensing systems such as smart cities. To enable the collaboration tasks among distributed devices, time synchronization is crucial. However, due to the long-range and device heterogeneity, accurate time synchronization for a large-scale IoT network is challenging. Existing GPS or NTP solutions either require an outdoor environment or only have low and unstable accuracy. In this paper, we propose AirSync, a novel synchronization method that leverages the widely existed aircraft signals, ADS-B, to synchronize large-scale IoT networks with nodes even in indoor environments. But ADS-B messages have no time stamp and cannot provide a reference time. We leverage the continuity of aircraft movements to estimate the aircraft traveling time. Then devices that observe common aircraft moving segments can calculate their time offset. To obtain the time skew, we propose a combined aircraft linear regression method. We also design a transitive synchronization for devices that cannot observe common aircraft. Besides, we also design a duty-cycled ADS-B message collection method for resource-limited IoT devices. We implement a prototype of AirSync and evaluate its performance in various real-world environments. The results show that AirSync can obtain the sub-ms accuracy.","1558-0660","","10.1109/TMC.2021.3070644","National Key Research and Development Program of China(grant numbers:2018AAA0100500); National Natural Science Foundation of China(grant numbers:61932013,62061146002,61720106007); National Natural Science Foundation of China(grant numbers:61921003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9394785","Time synchronization;large-scale;aircraft signal","Synchronization;Aircraft;Global Positioning System;Servers;Mobile computing;Ions;Location awareness","","1","","36","IEEE","2 Apr 2021","","","IEEE","IEEE Journals"
"An Energy-Efficient Convolution-Based Partitioned Collaborative Perception Algorithm for Large-Scale IoT Services","Z. Yang; J. Zhang; Y. Jiang; Y. Jin","School of Electronic Information, Huzhou College, Huzhou, China; School of Information Engineering, Huzhou University, Huzhou, China; Key Laboratory of Intelligent Education Technology and Application of Zhejiang Province, Zhejiang Normal University, Jinhua, China; School of Engineering, Westlake University, Hangzhou, China","IEEE Transactions on Industrial Informatics","","2024","PP","99","1","10","The perception layer of Internet of Things (IoT) not only needs to perceive service requests rapidly, but also considers reducing energy consumption intelligently. This issue becomes crucial in the scenario of large-scale IoT services. The existing research usually focus on one single aspect only, either energy consumption or perception rate. Inspired from the human visual direction-sensitive system and convolutional neural network, we propose an energy-efficient convolution-based partitioned collaborative perception algorithm (CPCPA) for large-scale IoT services. The perception range of each node is divided into multiple regions. First, by introducing the direction sensitive mechanism, the preferred search orientation can be determined quickly and become directional. Then, a selection operator of the partitioned region is designed to keep the search region updating and prevent CPCPA from getting stuck in local optimums. Meanwhile, a convolutional method is used to filter out unhelpful nodes to adapt the self-adaptive wake-up probability, which precisely controls the state switch of the nodes to reduce energy consumption. Finally, simulation results verify that CPCPA enables IoT to discover large-scale random service requests. The results also indicate that the proposed algorithm achieves better energy maintenance and maintains a higher perception rate than the state-of-the-art algorithms including directional sensitivity-based perception algorithm, sensor node activation method using bat algorithm, coverage aware scheduling for optimal placement, intelligent self-organizing scheme. An overall average perception rate improvement of 2.46% is achieved by CPCPA than the compared algorithms.","1941-0050","","10.1109/TII.2024.3353853","National Natural Science Foundation of China(grant numbers:U22A20102,61903139); Natural Science Foundation of Zhejiang Province(grant numbers:LY24F030012); Pioneer; Leading Goose; R&D Program of Zhejiang Province(grant numbers:2023C01150); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10436383","Direction sensitive mechanism;Internet of Things (IoT);large-scale;service perception","Internet of Things;Energy consumption;Visualization;Collaboration;Switches;Partitioning algorithms;Maintenance engineering","","","","","IEEE","14 Feb 2024","","","IEEE","IEEE Early Access Articles"
"Age of Information in Internet of Things: A Survey","İ. Kahraman; A. Köse; M. Koca; E. Anarım","Department of Electrical and Electronics Engineering, Wireless Communications Laboratory, Boğaziçi University, Istanbul, Turkey; Department of Electrical and Electronics Engineering, Wireless Communications Laboratory, Boğaziçi University, Istanbul, Turkey; Department of Electrical and Electronics Engineering, Wireless Communications Laboratory, Boğaziçi University, Istanbul, Turkey; Department of Electrical and Electronics Engineering, Wireless Communications Laboratory, Boğaziçi University, Istanbul, Turkey","IEEE Internet of Things Journal","","2023","PP","99","1","1","In recent years, the increasing demand to see the status of objects over the internet leads to an increase in the number of Internet of things (IoT) applications. The unique nature of IoT, which involves potentially millions of interconnected devices with different data rate, power, bandwidth and range specifications, require different performance metrics than those conventionally employed in other communication applications. In conventional wireless communication systems such as cellular networks, performance indicators including data rate and spectral efficiency have become decisive, whereas in energy-constrained real-time IoT applications which require low data rate, the freshness of information has become a more prominent characteristic. Age of information (AoI), which is the elapsed time after the last received packet update was created at the source, has emerged as a fundamental metric for determining the freshness of information and has attracted substantial research interest. In this regard, this paper is dedicated to provide an overview of the current state-of-the-art on the use of AoI for the design and optimization of a large variety IoT applications. After a brief introduction of the IoT and AoI fundamentals, this paper presents a survey of the research works on common design issues such as AoI based optimization, scheduling for IoT networks, application of learning methods in large scale IoT systems, real life applications and experimental results together with a synopsis of potential future applications and research challenges.","2327-4662","","10.1109/JIOT.2023.3324879","T?rkiye Bilimsel ve Teknolojik Ara?t?rma Kurumu(grant numbers:119N154); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10286022","Age of Information (AoI);Internet of Things (IoT);scheduling;optimization","Internet of Things;Sensors;Optimization;Surveys;Wireless communication;Satellites;Logic gates","","","","","IEEE","16 Oct 2023","","","IEEE","IEEE Early Access Articles"
"A Review on IoT with Big Data Analytics","A. F. Ahmad; M. S. Sayeed; C. P. Tan; K. G. Tan; M. A. Bari; F. Hossain","Faculty of Information Science and Technology, Multimedia University, Melaka, Malaysia; Faculty of Information Science and Technology, Multimedia University, Melaka, Malaysia; Faculty of Information Science and Technology, Multimedia University, Melaka, Malaysia; Faculty of Engineering and Technology, Multimedia University, Melaka, Malaysia; Faculty of Information Science and Technology, Multimedia University, Melaka, Malaysia; Faculty of Engineering and Technology, Multimedia University, Melaka, Malaysia","2021 9th International Conference on Information and Communication Technology (ICoICT)","6 Sep 2021","2021","","","160","164","The Internet of Things (IoT) is a powerful and transformative force for the convergence of the physical and digital world of technology. The IoT is connecting things, businesses, and people in real-time and on a massive scale. The IoT is the network of interconnected devices that contains actuators, sensors, electronics, software and connectivity which lets these things connect, interact and transfer data. Connected devices and software work in ways that produce massive amounts of data where Big Data comes into the picture. The terminology of Big Data represents diverse sets of information that are both very large and complex in nature. Big data offers a better way of managing and using a large amount of data with the opportunity to conduct deeper and richer analysis. Although the extensive number of big data analytics and IoT studies has been performed, the overlapping of the two fields of study creates various possibilities for thriving data analysis in the IoT environment. This paper presents a thorough review of the recent advancement of IoT with big data and analytics. We also make a review of the relationship between these fields. We present a discussion on the application area of IoT and big data analytics as well as the opportunities created by enabling analytics in an IoT system.","","978-1-6654-0447-1","10.1109/ICoICT52021.2021.9527503","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9527503","IoT;Big Data;Analytics;smart environment;wearables","Data analysis;Terminology;Force;Big Data;Software;Real-time systems;Sensors","","4","","45","IEEE","6 Sep 2021","","","IEEE","IEEE Conferences"
"Distributed Air-Time Reduction In Multi-Hop LoRa Networks With Multiple Spreading Factors","C. Chimma; A. Phonphoem; A. Jansang; W. Tangtrongpairoj; C. Jaikaeo","Department of Computer Engineering, Kasetsart University, Bangkok, Thailand; Department of Computer Engineering, Kasetsart University, Bangkok, Thailand; Department of Computer Engineering, Kasetsart University, Bangkok, Thailand; Department of Computer Engineering, Kasetsart University, Bangkok, Thailand; Department of Computer Engineering, Kasetsart University, Bangkok, Thailand","2023 International Conference On Cyber Management And Engineering (CyMaEn)","28 Feb 2023","2023","","","148","152","LoRa is a physical-layer communication technology usually used for Internet of Things (IoT). LoRa has one specific parameter not found in typical wireless technology, called spreading factors (SF). The lowest SF,SF7, has the highest data transfer rate, so it is common to conFigure all the end devices to use SF7. On the other hand, for a LoRa network that spans a large area, higher SFs can be used to cover larger distances. LoRa’s radio modulation is based on the chirp spread spectrum technique which allows multiple devices using different SFs to transmit data in simultaneously. Even though LoRa supports long-distance data transmission (up to 15 km line-of-sight and 1.5 km in outdoor urban scenarios), single-hop networks do not support the coverage range required by certain scenarios such as smart cities, in which multi-hop networks are more appropriate. However, managing devices in multi-hop networks requires more effort. Centralized, manual configuration of devices become impractical in large-scale deployments. In this paper, we propose a distributed algorithm that improves the capacity of a multi-hop LoRa network. The algorithm arranges the end devices in a tree topology and assigns different SFs to different branches of the tree so that transmissions can be carried out in parallel at much as possible, hence minimizing total time on air. From simulation experiment, the algorithm can reduce time on air of the system up to 41%.","","978-1-6654-9329-1","10.1109/CyMaEn57228.2023.10050943","Kasetsart University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10050943","component;LoRa;Multi-Spreading Factor;Multi-Hop;Air-Time Reduction","Wireless communication;Performance evaluation;Smart cities;Network topology;Simulation;Modulation;Spread spectrum communication","","","","16","IEEE","28 Feb 2023","","","IEEE","IEEE Conferences"
"Towards Zero-Carbon Data Movement at the HPC and Cloud Data Centers","T. Kosar","Department of Computer Science and Engineering, University at Buffalo, Buffalo, New York, USA","2023 IEEE John Vincent Atanasoff International Symposium on Modern Computing (JVA)","15 Jan 2024","2023","","","54","55","The proliferation of scientific applications, the Internet of Things (IoT), social media, and e-commerce has led to an exponential growth in data generation, consequently fueling the demand for large-scale data analytics systems. Consequently, the transfer of data over the Internet has escalated to an unprecedented scale, surpassing the zettabyte mark [37]. As data generation rates continue to surge, the carbon footprint associated with data movement has emerged as a pressing concern, particularly for High-Performance Computing (HPC) and Cloud data centers. Projections indicate that by 2030, information and communication technologies will account for 8%–21% of global electricity usage [6]. HPC and Cloud data centers and communication networks contribute to 69% of the overall power consumption within the IT sector [4]. Within this segment, data transfers alone consume over a hundred terawatt-hours of energy annually, amounting to a staggering $20 billion USD [6]. The environmental implications are equally monumental, with information and communication technologies projected to be responsible for a staggering 14% of carbon emissions by 2040 [6]. These trends have spurred significant efforts to reduce energy consumption in hardware and software systems, as well as networking devices.","","979-8-3503-2889-9","10.1109/JVA60410.2023.00019","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10387561","green computing;sustainability;energy efficient data transfers;application-layer optimization;adaptive tuning","Data centers;Cloud computing;Power demand;Social networking (online);Pressing;Software systems;Information and communication technology","","","","40","IEEE","15 Jan 2024","","","IEEE","IEEE Conferences"
"A Multibranch U-Shaped Tunable Encoding Chipless RFID Strain Sensor for IoT Sensing System","L. Chen; L. Liu; L. Kang; Z. Wan; G. Wan; L. Xie","Department of Electrical and Electronic Engineering, Shanghai Institute of Technology, Shanghai, China; Department of Electrical and Electronic Engineering, Shanghai Institute of Technology, Shanghai, China; Department of Electrical and Electronic Engineering, Shanghai Institute of Technology, Shanghai, China; Department of Electrical and Electronic Engineering, Shanghai Institute of Technology, Shanghai, China; Department of Electronic Science and Technology, Tongji University, Shanghai, China; Department of Disaster Mitigation for Structures, Tongji University, Shanghai, China","IEEE Internet of Things Journal","7 Mar 2023","2023","10","6","5304","5320","Structural health monitoring (SHM) is essential for modern large buildings and infrastructure. Radio frequency identification (RFID) widen a new paradigm for SHM in the Internet of Things (IoT) era. This article introduces a low-cost intelligent RFID monitoring system for future IoT applications. Through adding a multiparameter sensing strategy to the passive RFID tags that can be deployed on a large scale to form a sensor network, which expands the coverage of IoT in key positions health monitoring of buildings. In this work, a novel chipless RFID strain sensing tag is designed to characterize the magnitude and direction of metal surface strain, and a low-cost detection method suitable for large mechanical structures is proposed. The traditional strain antennas focus on identifying the strain characteristics without the function of encoding, and there are limitations, such as the rigid measurement methods and the expensive measurement instruments. The tag designed in this article integrates both strain sensing and encoding functions, and has the advantages of small size, high data capacity, and information reading is not easily affected by environmental noise. This article proposes an economical and flexible tag spectrum extraction method, which realizes the intelligent collection and transmission of tag data by connecting lightweight vector network analyzer (VNA) with microcontroller. Combined with the IoT, this method can be well applied to the security assessment and damage detection of large infrastructure structures, which provides a new approach to modern building health monitoring applications from integrated tag design to intelligent detection and risk assessment schemes.","2327-4662","","10.1109/JIOT.2022.3221938","General Program of National Natural Science Foundation of China, “Research on the Principles of Passive Sensing and Structural Deformation Monitoring Methods Based on Antennas Without Stress Patch”(grant numbers:52078375); Top Discipline Plan of Shanghai Universities-Class I; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9951066","Chipless radio frequency identification (RFID) tag;Internet of Things (IoT);multiparameter on-chip integration;strain sensing;structural health monitoring~(SHM);tunable encoding","Strain;Sensors;Resonant frequency;Internet of Things;Monitoring;RFID tags;Encoding","","4","","38","IEEE","15 Nov 2022","","","IEEE","IEEE Journals"
"Smart Irrigation System using Internet of Things (IoT) and Machine Learning","S. Badotra; L. Gundaboina; A. Trehan; D. Mishra; P. Srivastava; A. K. Dhaiya; S. Anwar","Department of Computer Science Engineering, Lovely Professional University, Phagwara, Punjab, India; Department of Computer Science Engineering, Lovely Professional University, Phagwara, Punjab, India; Department of Computer Science Engineering, Lovely Professional University, Phagwara, Punjab, India; Department of Computer Science Engineering, Lovely Professional University, Phagwara, Punjab, India; Department of Computer Science Engineering, Lovely Professional University, Phagwara, Punjab, India; Department of Computer Science and Engineering, DIT University, Dehradun, India; Department of Computer Science Engineering, Lovely Professional University, Phagwara, Punjab, India","2021 9th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)","15 Nov 2021","2021","","","1","4","Despite the world being in 21st century most of the developing and under-developed nation use traditional method for farming we requires tremendous energy and hectic schedule from a small scale farmer with a very measly return in terms of profit moreover the water wastage and continuous monitoring required to keep check in plants condition is just unjustified but with 58% of population having agriculture as primary income source most of the Indian farmers having extremely low income it seems impossible for them to hop over costly machineries. But now with the cost-effective processors out there in the market can provide a solution to all these issues faced by Indian farmers. With exponential progress of Internet of Things (IoT) devices in the market smart irrigation systems are becoming a new trend. This paper proposes design and theory of one such smart irrigation system using NodeMCU to wirelessly operate a network of irrigation modules by irrigating the field when required by measuring the water content of soil and keep checking condition of plant using a camera this paper also provide insight of how to keep safe integrity of data which travels from NodeMCU to user smartphone using ciphering methods and by keeping proposed system reliable and cost effective.","","978-1-6654-1703-7","10.1109/ICRITO51393.2021.9596139","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9596139","agriculture;internet of things;irrigation system etc","Irrigation;Costs;Crops;Soil;Market research;Sensor systems;Internet of Things","","4","","21","IEEE","15 Nov 2021","","","IEEE","IEEE Conferences"
"Digital-Twin-Aided Product Design Framework For IoT Platforms","C. Wang; Y. Li","Department of Computer Science, Georgia State University, Atlanta, GA, USA; Department of Computer Science, Georgia State University, Atlanta, GA, USA","IEEE Internet of Things Journal","7 Jun 2022","2022","9","12","9290","9300","The increasing number of products is the trend of current industry. However, the product development process is significantly limited by budget and testing risk. Recently, digital twin (DT) has emerged as a promising industrial paradigm that provides an integrated and cohesive view of the product design process. In this article, we propose a product design framework for Internet of Things (IoT) platforms, namely, DT-aided IoT platform design (DTIPD). This framework considers a large number of IoT devices performing different tasks with machine learning (ML) technologies. Each IoT device constructs a particular ML-based model that deals with its task automatically by feeding related data with labels. The challenges of large-scale network management and ground-truth shortage at the initial stage of product iteration are addressed. We propose a two-level hierarchical learning process using the real-time model status stored at DT servers (DTS), aiming to improve product quality while shortening the development lifecycle. The comprehensive experimental results for both the single-DTS and multiple-DTS scenarios demonstrate the applicability of our framework.","2327-4662","","10.1109/JIOT.2021.3100796","National Science Foundation of U.S.(grant numbers:1829674,1741277); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9499110","Digital twin (DT);distributed learning;machine learning (ML);Internet of Things (IoT);product design","Internet of Things;Task analysis;Product design;Data models;Computational modeling;Servers;Digital twin","","7","","40","IEEE","28 Jul 2021","","","IEEE","IEEE Journals"
"Active Monitoring of Energy Utilization in Smart Home Appliances","M. I. Abdullah; D. Roobashini; M. H. Alkawaz","Faculty of Information Sciences & Engineering Management and Science University, Shah Alam, Selangor, Malaysia; Faculty of Information Sciences & Engineering Management and Science University, Shah Alam, Selangor, Malaysia; Faculty of Information Sciences & Engineering Management and Science University, Shah Alam, Selangor, Malaysia","2021 IEEE 11th IEEE Symposium on Computer Applications & Industrial Electronics (ISCAIE)","26 May 2021","2021","","","245","249","In our contemporary world, people are rapidly turning to high-tech as smart and intelligent way to enhance the standard of living. Smart devices capture and exchange data from the network's boundary, which later linked to the Internet to form the Internet of Things (IoT). Smart devices may be small-scale, but they are effective. The prospective of mobile apps seems to integrate them perfectly into all aspects of our applications, from innovations such as a connected car, health monitors, fitness trackers and smart watches. The promise of smart home technology is to offer benefits to modern households and their community. However, it has been scuffling to achieve mass market acceptance since its early growth. The Smart Home is an application of the IoT technologies that used by the households to ensure it easier for humans to use smartphone apps to track and manage all devices at home. Smart home allows users to manage of their energy usage through a variety of smart-home environmentally conscious strategies. This application interprets the energy used to show the users which of their appliances are consuming high energy power. After analyzing other current systems, we have proposed the interface for improved human interaction and more efficient use of energy usage data.","","978-1-6654-0338-2","10.1109/ISCAIE51753.2021.9431776","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9431776","Monitoring;Controlling;Saving Electricity;Smart Home;Internet of Things","Meters;Home appliances;Technological innovation;Smart homes;Turning;Mobile applications;Internet of Things","","7","","24","IEEE","26 May 2021","","","IEEE","IEEE Conferences"
"BDIM: A Blockchain-Based Decentralized Identity Management Scheme for Large Scale Internet of Things","R. Xiong; W. Ren; X. Hao; J. He; K. -K. R. Choo","State Key Laboratory of Public Big Data, Guizhou University, Guiyang, China; Guangxi Key Laboratory of Machine Vision and Intelligent Control, Wuzhou University, Wuzhou, China; Artificial Intelligence Thrust, Information Hub, Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China; Guangxi Key Laboratory of Machine Vision and Intelligent Control, Wuzhou University, Wuzhou, China; Department of Information Systems and Cyber Security, University of Texas at San Antonio, San Antonio, TX, USA","IEEE Internet of Things Journal","11 Dec 2023","2023","10","24","22581","22590","In large-scale Internet of Things (IoT) systems, centralized authentication can be challenging, for example in terms of identity management, authentication overhead, and single point of failure. Distributed identity management has been envisioned as a promising approach for mitigating above all, but the security and performance of the overall solution have not been extensively evaluated. In this article, we proposed a decentralized identity management scheme based on blockchain for tackling large-scale IoT such as VANET. We implement smart contracts to support large-scale user access control, together with design trust management methods for reputation evaluation and credit penalty mechanisms, which can prevent various types of attacks in distributed identification contexts. The experiment results and analysis justified that our scheme is scalable with good performance. Specifically, the system response is on a millisecond scale and all the functions consume within 250 ms. Also, the time consumption of the query maintains a manageable delay within 0.5 ms no matter the remarkable growth of users. Finally, we observe that the throughput of the current blockchain platform could meet the requirement of our scheme with the increasing number of users’ upload request in real-world simulation.","2327-4662","","10.1109/JIOT.2023.3303922","Guangxi Key Laboratory of Machine Vision and Intelligent Control(grant numbers:2022B11); Opening Project of Nanchang Innovation Institute, Peking University(grant numbers:NCII2022A02); Knowledge Innovation Program of Wuhan–Basic Research(grant numbers:2022010801010197); Foundation of State Key Laboratory of Public Big Data(grant numbers:PBD2022-13); Foundation of Beijing Key Laboratory of Urban Spatial Information Engineering(grant numbers:20220107); open Foundation of Anhui Engineering Research Center of Intelligent Perception and Elderly Care, Chuzhou University(grant numbers:2022OPA01); National Natural Science Foundation of China(grant numbers:61961036,62162054); Cloud Technology Endowed Professorship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10214286","Blockchain;distributed identification;Internet of Things (IoT);verifiable credential (VC)","Blockchains;Internet of Things;Smart contracts;Authentication;Delays;Vehicular ad hoc networks;Standards","","2","","27","IEEE","10 Aug 2023","","","IEEE","IEEE Journals"
"A Multiscale Algorithm for Joint Forecasting–Scheduling to Solve the Massive Access Problem of IoT","V. Rodoplu; M. Nakıp; D. T. Eliiyi; C. Güzeliş","Department of Electrical and Electronics Engineering, Yaşar University, İzmir, Turkey; Department of Electrical and Electronics Engineering, Yaşar University, İzmir, Turkey; Department of Industrial Engineering, İzmir Bakırçay University, İzmir, Turkey; Department of Electrical and Electronics Engineering, Yaşar University, İzmir, Turkey","IEEE Internet of Things Journal","15 Sep 2020","2020","7","9","8572","8589","The massive access problem of the Internet of Things (IoT) is the problem of enabling the wireless access of a massive number of IoT devices to the wired infrastructure. In this article, we describe a multiscale algorithm (MSA) for joint forecasting-scheduling at a dedicated IoT gateway to solve the massive access problem at the medium access control (MAC) layer. Our algorithm operates at multiple time scales that are determined by the delay constraints of IoT applications as well as the minimum traffic generation periods of IoT devices. In contrast with the current approaches to the massive access problem that assume random arrivals for IoT data, our algorithm forecasts the upcoming traffic of IoT devices using a multilayer perceptron architecture and preallocates the uplink wireless channel based on these forecasts. The multiscale nature of our algorithm ensures scalable time and space complexity to support up to 6650 IoT devices in our simulations. We compare the throughput and energy consumption of MSA with those of reservation-based access barring (RAB), priority based on average load (PAL), and enhanced predictive version burst-oriented (E-PRV-BO) protocols, and show that MSA significantly outperforms these beyond 3000 devices. Furthermore, we show that the percentage control overhead of MSA remains less than 1.5%. Our results pave the way to building scalable joint forecasting-scheduling engines to handle a massive number of IoT devices at IoT gateways.","2327-4662","","10.1109/JIOT.2020.2992391","Project Support Commission Yasar University Izmir Turkey(grant numbers:BAP060 Scheduling Algorithms for Wireless Communic); TUBITAK The Scientific and Technological Research Council of Turkey(grant numbers:118E277); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9086729","Forecasting;machine learning;machine-to-machine (M2M) communication;massive access;scheduling","Internet of Things;Protocols;Logic gates;Forecasting;Performance evaluation;Wireless communication;Delays","","20","","37","IEEE","5 May 2020","","","IEEE","IEEE Journals"
"Intelligent Live Video Streaming for Object Detection","M. Chen; J. Sun; K. Aida; R. J. Figueiredo; Y. -J. Ku; K. Subratie","Department of Informatics, The Graduate University for Advanced Studies, SOKENDAI, Tokyo, Japan; National Institute of Informatics, Tokyo, Japan; Department of Informatics, National Institute of Informatics, The Graduate University for Advanced Studies, SOKENDAI, Tokyo, Japan; Electrical and Computer Engineering, University of Florida, Florida, USA; Electrical and Computer Engineering, University of Florida, Florida, USA; Electrical and Computer Engineering, University of Florida, Florida, USA","2021 IEEE 23rd Int Conf on High Performance Computing & Communications; 7th Int Conf on Data Science & Systems; 19th Int Conf on Smart City; 7th Int Conf on Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys)","30 May 2022","2021","","","1427","1434","These days, sensors and cameras are being deployed on an increasingly large scale. Furthermore, the rapid development of machine learning models for computer vision now presents novel opportunities for the use of artificial intelligence (AI) and Internet of Things (IoT) combinations in various application scenarios. However, challenges remain in supporting low-latency video streaming from distributed mobile IoT devices under dynamic network environments, and overcoming video data quality degradation that results from weather “noise”, which reduces the accuracy of AI-based data analyses such as object detection. In this paper, we propose a live video stream processing system for supporting intelligent services that integrates the following features. First, to cope with dynamic networks and achieve low latency, our approach employs a peer-to-peer (P2P)-based virtual network at the edge and a multi-tiered architecture composed of IoT cameras, edge, and cloud servers. Second, we construct a flexible messaging system for video analysis built upon SINETStream, which is a messaging system that adopts a topic-based pub/sub model. Third, we implement a framework that can remove weather-related (rain, snow, and fog) noise by applying weather classification and adaptive noise removal models that improve the accuracy of video analysis from data collected outdoors. The latency, throughput, and image quality benchmark experiments conducted to validate the feasibility of our proposed system showed that the process resulted in image quality improvements of approximately 30% (on average).","","978-1-6654-9457-1","10.1109/HPCC-DSS-SmartCity-DependSys53884.2021.00214","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9781127","IoT;Edge Computing;P2P;Video Stream;Object Detection","Image quality;Adaptation models;Image edge detection;Object detection;Streaming media;Throughput;Internet of Things","","","","18","IEEE","30 May 2022","","","IEEE","IEEE Conferences"
"DT-SSIM: A Decentralized Trustworthy Self-Sovereign Identity Management Framework","E. Samir; H. Wu; M. Azab; C. Xin; Q. Zhang","Department of Electrical and Computer Engineering, School of Cybersecurity, Old Dominion University, Norfolk, VA, USA; Department of Electrical and Computer Engineering, School of Cybersecurity, Old Dominion University, Norfolk, VA, USA; Computer and Information Sciences, Virginia Military Institute, Lexington, VA, USA; Department of Electrical and Computer Engineering, School of Cybersecurity, Old Dominion University, Norfolk, VA, USA; Department of Electrical and Computer Engineering, School of Cybersecurity, Old Dominion University, Norfolk, VA, USA","IEEE Internet of Things Journal","23 May 2022","2022","9","11","7972","7988","In a ubiquitous environment enclosing cooperative Internet-of-Things (IoT) devices, individuals, and entities, digital identity management (DIM) becomes critical and challenging. DIM pertains to device identities authentication and verification to enable trustworthy service exchange, data collection, and decision making. DIM is the supporting pillar for all online services and the foundation for security and authentication mechanisms. Due to the extreme heterogeneity, scale, and configuration complexity of such environments, enabling trustworthy DIM is crucial and seriously challenging. In an IoT context, devices use local digital identities stored within a tamper-proof unit and verified by a centralized authority for authentication. The recent attacks on IoT systems showed how vulnerable such a design is. It is also an inherent problem that influences humans. From that, self-sovereign identity (SSI) has emerged as a decentralized DIM approach embracing the concept of portable self-possession identity. SSI was presented to couple the digital identity from the owner to enable large-scale cooperation. However, digital identity storage and verification still occur on the device and in a centralized manner. Utilizing a local single-point-of-failure storage memory for verifiable credentials is one of the considerable drawbacks in contemporary SSI. In this regard, this article introduces decentralized trustworthy-self-sovereign identity management (DT-SSIM), a novel decentralized trustworthy SSI management framework. DT-SSIM integrates the secret share scheme with the blockchain-based smart contracts technologies to provide transparent and trustworthy SSI-based DIM services for IoT. Storing IoT identity credentials outside the devices’ local storage preserves the identity credentials from being tampered with or misused. Evaluations and discussions show the resiliency assessment of the system and the cost and estimated running times for verification processes in DT-SSIM.","2327-4662","","10.1109/JIOT.2021.3112537","National Science Foundation(grant numbers:CNS-2120279,CNS-1828593,OAC-1829771,EEC-1840458,CNS-1950704); Office of Naval Research(grant numbers:N00014-20-1-2065); National Security Agency(grant numbers:H98230-21-1-0165,H98230-21-1-0278); Commonwealth Cyber Initiative(grant numbers:HS-4Q21-005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9536956","Blockchain;secret sharing;self-sovereign identity (SSI);smart contracts;verifiable credentials","Authentication;Blockchains;Internet of Things;Smart contracts;Privacy;Integrated circuit modeling;Computational modeling","","16","","48","IEEE","14 Sep 2021","","","IEEE","IEEE Journals"
"Ground-Level Mapping and Navigating for Agriculture Based on IoT and Computer Vision","W. Zhao; X. Wang; B. Qi; T. Runge","Department of Biological System Engineering, University of Wisconsin–Madison, Madison, WI, USA; Department of Electrical and Computer Engineering, University of Wisconsin–Madison, Madison, WI, USA; Department of Electrical and Computer Engineering, University of Wisconsin–Madison, Madison, WI, USA; Department of Biological System Engineering, University of Wisconsin–Madison, Madison, WI, USA","IEEE Access","17 Dec 2020","2020","8","","221975","221985","Autonomous agricultural systems are a promising solution to bridge the gap between labor shortage for agriculture tasks and the continuing needs for increasing productivity in agriculture. Automated mapping and navigation system will be a cornerstone of most autonomous agricultural system. Accordingly, we propose a ground-level mapping and navigating system based on computer vision technology (Mesh Simultaneous Localization and Mapping algorithm, Mesh-SLAM) and Internet of Things (IoT), to generate a 3D farm map on both the edge side and cloud. The innovation of this system includes three layers as sub-systems that are 1) ground-level robot vehicles’ layer for conducting frames collection only with a monocular camera, 2) edge node layer for image feature data edge computing and communication, and 3) cloud layer for general management and deep computing. High efficiency and speed of mapping stage are enabled by making the robot vehicles directly stream continuous frames to their corresponding edge node. Then each edge node, that coordinate a certain range of robots, applies a new Mesh-SLAM frame by frame, whose core is reconstructing the features map by a mesh-based algorithm with scalable units and reduce the feature data size by a filtering algorithm. Additionally, the cloud-computing allows comprehensive arrangement and heavily deep computing. The system is scalable to larger-scale fields and more complex environment by taking advantage of dynamically distributing the computation power to edges. Our evaluation indicates that: 1) this Mesh-SLAM algorithm outperforms in mapping and localization precision, accuracy, and yield prediction error (resolution at centimeter); and 2) The scalability and flexibility of the IoT architecture make the system modularized, easy adding/removing new functional modules or IoT sensors. We conclude the trade-off between cost and performance widely augments the feasibility and practical implementation of this system in real farms.","2169-3536","","10.1109/ACCESS.2020.3043662","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288741","Mesh-SLAM;IoT;intelligent agriculture;productive agriculture","Cloud computing;Navigation;Image edge detection;Robot kinematics;Agriculture;Servers;Internet of Things","","32","","41","CCBYNCND","9 Dec 2020","","","IEEE","IEEE Journals"
"Federated Transfer–Ordered–Personalized Learning for Driver Monitoring Application","L. Yuan; L. Su; Z. Wang","College of Engineering, Purdue University, West Lafayette, IN, USA; College of Engineering, Purdue University, West Lafayette, IN, USA; College of Engineering, Purdue University, West Lafayette, IN, USA","IEEE Internet of Things Journal","3 Oct 2023","2023","10","20","18292","18301","Federated learning (FL) shines through in the Internet of Things (IoT) with its ability to realize collaborative learning and improve learning efficiency by sharing client model parameters trained on local data. Although FL has been successfully applied to various domains, including driver monitoring applications (DMAs) on the Internet of Vehicles (IoV), its usages still face some open issues, such as data and system heterogeneity, large-scale parallelism communication resources, malicious attacks, and data poisoning. This article proposes a federated transfer–ordered–personalized learning (FedTOP) framework to address the above problems and test on two real-world data sets with and without system heterogeneity. The performance of the three extensions, transfer, ordered, and personalized, is compared by an ablation study and achieves 92.32% and 95.96% accuracy on the test clients of two data sets, respectively. Compared to the baseline, there is a 462% improvement in accuracy and a 37.46% reduction in communication resource consumption. The results demonstrate that the proposed FedTOP can be used as a highly accurate, streamlined, privacy-preserving, cybersecurity-oriented, and personalized framework for DMA.","2327-4662","","10.1109/JIOT.2023.3279273","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10131959","Driver monitoring;federated learning (FL);Internet of Things (IoT);personalization;privacy protection","Vehicles;Internet of Things;Servers;Training;Privacy;Monitoring;Data models","","5","","43","IEEE","23 May 2023","","","IEEE","IEEE Journals"
"Transaction Throughput Optimization for Integrated Blockchain and MEC System in IoT","Y. Xu; H. Zhang; H. Ji; L. Yang; X. Li; V. C. M. Leung","Key Laboratory of Universal Wireless Communications, Ministry of Education, Beijing University of Posts and Telecommunications, Beijing, China; Key Laboratory of Universal Wireless Communications, Ministry of Education, Beijing University of Posts and Telecommunications, Beijing, China; Key Laboratory of Universal Wireless Communications, Ministry of Education, Beijing University of Posts and Telecommunications, Beijing, China; Vanke School of Public Health, Tsinghua University, Beijing, China; Key Laboratory of Universal Wireless Communications, Ministry of Education, Beijing University of Posts and Telecommunications, Beijing, China; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China","IEEE Transactions on Wireless Communications","11 Feb 2022","2022","21","2","1022","1036","The integration of blockchain and mobile edge computing (MEC), as a secure, efficient, and reliable edge computing paradigm, has been widely applied in many applications, such as large-scale Internet of Things (IoT), Internet of Vehicles (IoV), and smart grid. However, due to the restricted transaction throughput of blockchain, the combination of blockchain and MEC in most existing works cannot support applications with frequent transaction requirements. In this paper, we propose an integrated blockchain and MEC (IBM) framework based on a space-structured ledger to meet the transaction demands for IoT applications. In the framework, a collaborative mining process is designed, where we consider the cooperation between mobile devices (MDs) and MEC servers. To promote mining efficiency, we further develop a high-performance consensus mechanism called reputation-based proof of work (Re-PoW), in which differentiated mining targets are assigned according to the reputation of MDs. In the Re-PoW consensus mechanism, heterogeneous capabilities and historical behaviors of MDs are all considered for accurately evaluating their reputation. In addition, we present an alternating optimization algorithm by jointly optimizing bandwidth allocation and computation resource allocation to further enhance the performance of the proposed scheme. Simulation results show that the proposed approach can achieve significant throughput improvement.","1558-2248","","10.1109/TWC.2021.3100985","National Natural Science Foundation of China(grant numbers:61771070); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9508194","Internet of Things;mobile edge computing;blockchain;transaction throughput","Blockchains;Throughput;Wireless communication;Servers;Optimization;Security;Resource management","","13","","41","IEEE","5 Aug 2021","","","IEEE","IEEE Journals"
"Quantile Context-Aware Social IoT Service Big Data Recommendation With D2D Communication","Y. Yang; J. Xu; Z. Xu; P. Zhou; T. Qiu","School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Electrical and Computer Engineering Department, University of Miami, Coral Gables, USA; Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, School of Software, Dalian University of Technology, Dalian, China; Hubei Engineering Research Center on Big Data Security, School of Cyber Science and Engineering, Huazhong University of Science and Technology, Wuhan, China; School of Computer Science and Technology, Tianjin University, Tianjin, China","IEEE Internet of Things Journal","12 Jun 2020","2020","7","6","5533","5548","With the rapid development of the Internet-of-Things (IoT) networks, millions of IoT services provided through wireless networks are waiting for people’s exploration. Such a large number of heterogeneous IoT services produce huge amounts of data in almost real time, known as big data, many of which cannot be measured or quantified. Hence, a recommended system that aims to deal with the unquantifiable big data is urgently needed. To solve the problem, we propose a novel quantile contextual tree-based multiarmed bandits algorithm to support the large-scale recommendation with both quantifiable and unquantifiable data. Furthermore, the high failure rate of communication has a serious influence on the recommendation accuracy of our system with the widely used D2D technology in today’s IoT network. To improve recommendation accuracy under the D2D communication, we take into account the feedback of historical service receivers and the historical successful delivery rate (SDP) of data transmission at the same time for the service recommendation system. We give theoretical analysis to prove a sublinear bound of the regret. Numerical experiments with tremendously large data sets show that we can balance the regret with the system time cost and guarantee a high SDP.","2327-4662","","10.1109/JIOT.2020.2980046","National Natural Science Foundation of China (NSFC)(grant numbers:61972448,61802048); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9032093","Big data;D2D communication;online learning;quantile contextual bandit;recommended system;Social Internet of Things (IoT)","Heuristic algorithms;Device-to-device communication;Internet of Things;Big Data;Receivers;Machine learning algorithms;Image color analysis","","18","","38","IEEE","11 Mar 2020","","","IEEE","IEEE Journals"
"AirSync: Time Synchronization for Large-scale IoT Networks Using Aircraft Signals","S. Zhu; X. Zheng; L. Liu; H. Ma","Beijing Key Laboratory of Intelligent Telecommunication Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing, China; Beijing Key Laboratory of Intelligent Telecommunication Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing, China; Beijing Key Laboratory of Intelligent Telecommunication Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing, China; Beijing Key Laboratory of Intelligent Telecommunication Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing, China","2020 17th Annual IEEE International Conference on Sensing, Communication, and Networking (SECON)","4 Aug 2020","2020","","","1","9","The prosperity of Internet of Things (IoT) brings forth the deployment of large-scale sensing systems such as smart cities. The distributed devices upload their local sensing data to the cloud and collaborate to fulfill the large-area tasks such as pollutant diffusion analysis and target tracking. To accomplish the collaboration, time synchronization is crucial. However, due to the long range and device heterogeneity, accurate time synchronization for a large-scale IoT network is challenging. Existing GPS or NTP solutions either require an outdoor environment or only have low and unstable accuracy. In this paper, we propose AirSync, a novel synchronization method that leverages the widely existed aircraft signals, ADS-B, to synchronize large-scale IoT networks with nodes even in indoor environments. But ADS-B messages have no time stamp and cannot provide a reference time. We leverage the continuity of aircraft movements to estimate the aircraft traveling time. Then devices that observe common aircraft moving segments can calculate their time offset. To obtain the time skew, we propose a combined aircraft linear regression method. We also design a transitive synchronization for devices that cannot observe common aircraft. We implement a prototype of AirSync and evaluate its performance in various real-world environments. The results show that AirSync can obtain the sub-ms accuracy.","2155-5494","978-1-7281-6630-8","10.1109/SECON48991.2020.9158433","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9158433","Time synchronization;large-scale;aircraft signal","Synchronization;Aircraft;Servers;Global Positioning System;Sensors;Windows;Cloud computing","","3","","26","IEEE","4 Aug 2020","","","IEEE","IEEE Conferences"
"A Novel Edge-to-Cloud-as-a-Service (E2CaaS) Model for Building Software Services in Smart Cities","J. Robberechts; A. Sinaeepourfard; T. Goethals; B. Volckaert","Department of Information Technology, Ghent University, Ghent, Belgium; Department of Computer Science, Norwegian University of Science and Technology, Trondheim, Norway; Department of Information Technology, Ghent University, Ghent, Belgium; Department of Information Technology, Ghent University, Ghent, Belgium","2020 21st IEEE International Conference on Mobile Data Management (MDM)","7 Aug 2020","2020","","","365","370","The main goal of a smart city is to enhance the quality of life of its inhabitants by providing services using Information and Communications Technology (ICT) components in a city. ICT components include not only Internet of Things (IoT) data sources spread across the city, but also traditional non-IoT data sources. Managing all ICT components in a smart city can be challenging and results in many complexities. Consequently, there is a need for ICT management architectures. Traditional solutions are often based on a centralized ICT architecture using Cloud technologies. Recently, the number of ICT components, services, and their corresponding complexities are growing, leading to large-scale ICT architectures. Centralized Cloud solutions cannot cope with the ever-expanding demands of this kind of architectures. The limitations of the centralized approaches necessitate the design of a new ICT architecture, using distributed technologies, for every layer and element of the city. Many solutions for management from Edge-to-Cloud (E2C) through distributed technologies are forthcoming, including Decentralized-to-Centralized ICT (DC2C-ICT) and Distributed-to-Centralized ICT (D2C-ICT) architectures. The DC2C-ICT architecture and its components work on their own tasks and are solely communicating with a centralized platform. On the other hand, components of the D2C-ICT architecture can work together to provide the services for the citizens across different layers from E2C. Therefore, the D2CICT architecture is less dependent on the central Cloud-based entity, but harder to design and manage. In this paper, an “Edge-to-Cloud-as-a-Service (E2CaaS) ” model is proposed together with a model on how to build efficient software services in smart cities through different layers of E2C. The most important tasks for building these services are the management of“Data/Database,” “Resources,” and “Network Communication and Cybersecurity issues”.","2375-0324","978-1-7281-4663-8","10.1109/MDM48529.2020.00079","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9162334","Smart City;IoT;Edge-to-Cloud;Distributed-to-Centralized ICT architecture;Edge-to-Cloud-as-a-Service","Conferences;5G mobile communication","","5","","21","IEEE","7 Aug 2020","","","IEEE","IEEE Conferences"
"SFPAG-R: A Reliable Routing Algorithm Based on Sealed First-Price Auction Games for Industrial Internet of Things Networks","W. Zhang; X. Wang; G. Han; Y. Peng; M. Guizani","School of Information Science and Engineering, Shenyang Ligong University, Shenyang, China; School of Information Science and Engineering, Shenyang Ligong University, Shenyang, China; Department of Internet of Things Engineering, Hohai University, Changzhou, China; School of Artificial Intelligence, Shanghai University, Shanghai, China; CSE Department in Qatar University, Qatar, Qatar","IEEE Transactions on Vehicular Technology","9 Jun 2021","2021","70","5","5016","5027","Due to the harsh deployment environment of the Industrial Internet of Things, the reliability of data transmission has always been an important challenge and a hot topic in Industrial Internet of Things (IIoT). Based on a multiple sink node network model, we propose a reliable routing algorithm called SFPAG-R, which is based on sealed first-price auction games. The algorithm offers a route discovery process and data transmission mechanism using the multi-sink network structure. The classic sealed first-price auction game is improved, and we propose a sealed first-price auction game model based on standard normal distribution, in order to ensure that the auction nodes can obtain higher returns. Based on an analysis of the factors affecting reliable data transmission in a large-scale, industrial IoT system, a data forwarding auction game model is established. Finally, to address the issue of selfish nodes, a dynamic revenue control method is proposed to promote cooperation between nodes. The simulation results indicate that the SFPAG-R algorithm proposed in this paper can reliably reduce the average amount of hops that occur during data transmission, ensure a high rate of successful data transmission, balance network energy consumption, and prolong the network's life cycle.","1939-9359","","10.1109/TVT.2021.3074398","National Key Research and Development Program of China(grant numbers:2017YFE0125300); China Academy of Military Sciences Fund; Liaoning innovation team; Liaoning Distinguished Professor Project; Liaoning BaiQianWan Talents Program(grant numbers:2016); Natural Science Foundation of Liaoning Province(grant numbers:20170540793); National Natural Science Foundation of China-Guangdong Joint Fund(grant numbers:U1801264); Jiangsu Key Research and Development Program(grant numbers:BE2019648); Project of Shenzhen science and technology innovation committee(grant numbers:JCYJ20190809145407809); National Science and Technology Major Project(grant numbers:2017-V-0011-0062); Project of Fujian University of Technology(grant numbers:GYZ19066); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9409654","IoT;Routing algorithm;Auction game;Reliable transmission","Reliability;Routing;Games;Peer-to-peer computing;Industrial Internet of Things;Data communication;Wireless sensor networks","","11","","24","IEEE","20 Apr 2021","","","IEEE","IEEE Journals"
"A Genetic Algorithm- and t-Test-based system for DDoS Attack Detection in IoT Networks","M. F. Saiyed; I. Al-Anbagi","Faculty of Engineering and Applied Science, University of Regina, SK, Canada; Faculty of Engineering and Applied Science, University of Regina, SK, Canada","IEEE Access","","2024","PP","99","1","1","Internet and cloud-based technologies have facilitated the implementation of large-scale Internet of Things (IoT) networks. However, these networks are susceptible to emerging attacks. This paper proposes a novel lightweight system for detecting both high- and low-volume Distributed Denial of Service (DDoS) attacks in IoT networks, namely Genetic Algorithm (GA) and t-Test for DDoS Attack Detection (GADAD). The GADAD system employs edge-based technologies and has three phases. In the first phase, it creates and preprocesses an HL-IoT (High- and Low-volume attacks in IoT networks) dataset, which includes both high- and low-volume DDoS attacks. The second phase introduces a novel and lightweight method, called GAStats, for optimal feature selection using the GA and statistical parameters (Stats.). In the third phase, the system trains three tree-based Machine Learning (ML) models: Random Forest (RF), Extra-Tree (ET), and Adaptive Boosting (AdaBoost), along with other ML models, using both the self-generated HL-IoT dataset and the publicly available ToN-IoT dataset. The evaluation includes the assessment of key performance metrics such as accuracy, precision, recall, F1-score, Receiver Operating Characteristic Curve (ROC), computation time, and scalability analysis with overall system performance. The experimental results illustrate the efficacy of the feature selection method in optimizing the system's efficiency in detecting DDoS attacks in IoT networks, along with a reduction in computation time compared to existing state-of-the-art techniques.","2169-3536","","10.1109/ACCESS.2024.3367357","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10440087","DDoS attack;feature engineering;genetic algorithm;IoT;security;t-Test;tree-based machine learning","Internet of Things;Denial-of-service attack;Feature extraction;Computer crime;Support vector machines;Radio frequency;Genetic algorithms;Machine learning","","","","","CCBYNCND","19 Feb 2024","","","IEEE","IEEE Early Access Articles"
"Application of Wearable Sensors in Physical education for biomedical surveillance and human-machine interface","M. J. Alsalhy; I. Ahmed; N. A. Hussien; A. k. Hussain; A. Hussian; T. R. Al-Shaikhli","Department of Medical Devices Engineering Technologies, National University of Science and Technology, Dhi Qar, Nasiriyah, Iraq; Medical instruments engineering techniques, Al-farahidi University, Baghdad, Iraq; Information and Communication Technology Research Group, Scientific Research Center, Al-Ayen University, Thi-Qar, Iraq; Computer Technologies Engineering, Al-Turath University College, Baghdad, Iraq; Technical Computer Engineering Department, Al-Kunooze University College, Basrah, Iraq; Computer Engineering Techniques, Al-Nisour University College, Baghdad, Iraq","2023 Annual International Conference on Emerging Research Areas: International Conference on Intelligent Systems (AICERA/ICIS)","13 Feb 2024","2023","","","1","6","Continuous biological surveillance requires less mechanical aid and affordable wearable technology and sensors. The health industry benefits greatly from the rapid development and expansion of the Internet of Things (IoT). Measuring the accuracy of physical education systems is a major difficulty for fitness and sports trackers, as human dependability is a primary concern for these technologies. This study supports the use of a portable sensor device for monitoring activities in athletes' training. The proposed method is achieved with the help of monitoring physical education using a wearable sensor device(MPE-Wsd)to track their health. With the Service Level Agreement (SLA) method, processing power requirements are estimated with the help of a server. The article opened with a unique and compelling model for health. The article offers a portable sensor for use at the human-machine interface. It's convenient for both the participants and the doctor to have access to the various sources of information. With this new field of study, policymakers may make the most efficient use of hardware and software designed for the Internet of Things. Provides the network with instantaneous access to large-scale resources while reducing operational and capital expenditures. Many mental and physiological diseases are rising as the global population ages because point-of-care (POC) treatment and continuous disease monitoring are important. The results of the tests validate the technique as being both convenient and economical to employ regularly.","","979-8-3503-0345-2","10.1109/AICERA/ICIS59538.2023.10420331","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10420331","Physical Education;Biomedical Sensors;Human Machine Interface HMIs;Continuous Monitoring of Vital Signs","Surveillance;Human-machine systems;Internet of Things;Biomedical monitoring;Wearable sensors;Service level agreements;Diseases","","","","34","IEEE","13 Feb 2024","","","IEEE","IEEE Conferences"
"Phoenix: Transformative Reconfigurability for Edge IoT Devices in Small-Scale IoT Systems","M. Moghaddassian; S. Shafaghi; P. Habibi; A. Leon-Garcia","The Edward S. Rogers Sr. Department of Electrical and Computer Engineering, University of Toronto, Toronto, Canada; The Edward S. Rogers Sr. Department of Electrical and Computer Engineering, University of Toronto, Toronto, Canada; The Edward S. Rogers Sr. Department of Electrical and Computer Engineering, University of Toronto, Toronto, Canada; The Edward S. Rogers Sr. Department of Electrical and Computer Engineering, University of Toronto, Toronto, Canada","IEEE Access","15 Dec 2023","2023","11","","137821","137836","Transformative reconfigurability refers to the ability of changing the current software stack of a configurable device by fully replacing its existing one. In the context of IoT systems, such major device reconfigurations can be used to change the role, adapt new functionality, and keep reconfigurable IoT devices compatible with the IoT systems requirements as the ambient technology around them evolve, thus fostering a thriving and continuously-connected IoT environment. In this paper, we introduce Phoenix, an IoT device configuration management system that is designed to automate transformative reconfigurability for edge IoT devices at small scales. Edge IoT devices are typically computationally capable and configurable devices that have enough processing power to run user programs and control sensors and embedded devices in an IoT environment. Enabling transformative reconfigurability for such devices at small scales can increase IoT systems flexibility, efficiency, and adaptability in small IoT environments, for example, agri-farms, smart homes, micro grids, and the like. Phoenix manages the life cycle of edge IoT devices configuration and uses bare-metal provisioning to provide unattended installation of new software stacks that are defined by user intents that instruct the reconfiguration process. We implemented a Phoenix proof-of-concept system and deployed it on the SAVI testbed where we evaluated its performance in reconfiguring a variety of edge IoT devices under different network conditions. Our results indicate that Phoenix can meet the requirements of small-scale heterogeneous IoT systems in various application environments.","2169-3536","","10.1109/ACCESS.2023.3339154","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10341245","Bare metal provisioning;infrastructure automation;Internet of Things;reconfigurability","Internet of Things;Engines;Operating systems;Microservice architectures;Metals;Full stack;Fires;Reconfigurable architectures;Edge computing","","","","66","CCBY","4 Dec 2023","","","IEEE","IEEE Journals"
"An Intelligent Edge-Cloud Collaborative Framework for Communication Security in Distributed Cyber-Physical Systems","C. Chen; Y. Li; Q. Wang; X. Yang; X. Wang; L. T. Yang","School of Future Technology, South China University of Technology, Guangzhou, Guangdong, P.R. China; School of Computer Science and Engineering, Central South University, No.932 South Lushan Road, Changsha, Hunan, P.R. China; School of Future Technology, South China University of Technology, Guangzhou, Guangdong, P.R. China; Institute for Infocomm Research, A*STAR, Singapore; School of Computer Science and Technology, Hainan University, Hainan, China; School of Computer Science and Technology, Hainan University, Hainan, China","IEEE Network","","2023","PP","99","1","1","The rapid growth of IoT (Internet of Things) and smart services facilitate many CPS (Cyber-Physical Systems) such as smart health, smart grid and so on. Nevertheless, the communication security issues in CPS are becoming more and more important with the growing complexity of the CPS network and the increasing dependency of critical network infrastructure on cyber-based technologies. In recent years, deep learning technology has shown its superiority in detecting communication security attacks, but its high computational complexity and the massive amount of data generated by IoT devices have brought challenges to traditional cloud computing technology in terms of bandwidth and computing resources. In this paper, we have analyzed the characteristics of heterogeneity and hierarchy in attacks on CPS. We have also analyzed the role of edge intelligence in handling the security of large-scale data communication in CPS. Furthermore, we proposed a CPS communication attack detection framework based on edge cloud collaboration, aiming to improve the parallel efficiency of hardware resources when executing detection tasks. We aim to enhance the intelligence of physical devices and the degree of cloud collaboration, satisfying the real-time processing requirements of large-scale, hierarchical CPS attack detection. Furthermore, through simple simulation experiments, we verified the effectiveness of the proposed edge cloud collaboration framework in CPS attack detection.","1558-156X","","10.1109/MNET.2023.3321923","National Outstanding Youth Foundation of China(grant numbers:62262014); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10286283","Cyber Physical System;Communication Security;Big Data;Deep Learning;Edge-cloud Collaboration","Security;Cloud computing;Image edge detection;Deep learning;Collaboration;Big Data;Servers","","","","","IEEE","16 Oct 2023","","","IEEE","IEEE Early Access Articles"
"Internet of Video Things: Next-Generation IoT With Visual Sensors","C. W. Chen","Peng Cheng Laboratory, Shenzhen, China","IEEE Internet of Things Journal","12 Aug 2020","2020","7","8","6676","6685","The worldwide flourishing of the Internet of Things (IoT) in the past decade has enabled numerous new applications through the internetworking of a wide variety of devices and sensors. More recently, visual sensors have seen their considerable booming in IoT systems because they are capable of providing richer and more versatile information. Internetworking of large-scale visual sensors has been named Internet of Video Things (IoVT). IoVT has its own unique characteristics in terms of sensing, transmission, storage, and analysis, which are fundamentally different from the conventional IoT. These new characteristics of IoVT are expected to impose significant challenges to existing technical infrastructures. In this article, an overview of recent advances in various fronts of IoVT will be introduced and a broad range of technological and system challenges will be addressed. Several emerging IoVT applications will be discussed briefly to illustrate the potentials of IoVT in a broad range of practical scenarios.","2327-4662","","10.1109/JIOT.2020.3005727","Key-Area Research and Development Program of Guangdong Province, China(grant numbers:2019B010155002); National Natural Science Foundation of China(grant numbers:91538203); U.S. NSF(grant numbers:1405594); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9129776","Intelligent integration;Internet of Things (IoT);Internet of Video Things (IoVT);IoVT applications;pervasive networking;smart visual signal analysis;visual communication and networking;visual sensors","Internet of Things;Visualization;Cloud computing;Intelligent sensors;Cameras;Sensor phenomena and characterization","","73","","34","IEEE","30 Jun 2020","","","IEEE","IEEE Journals"
"Energy Efficiency Characterization in Heterogeneous IoT System With UAV Swarms Based on Wireless Power Transfer","Y. Yao; Z. Zhu; S. Huang; X. Yue; C. Pan; X. Li","School of Information and Communication Engineering, Beijing Information Science and Technology University, Beijing, China; School of Information Engineering, Zhengzhou University, Zhengzhou, China; Key Laboratory of Universal Wireless Communications, Ministry of Education, Beijing University of Posts and Telecommunications, Beijing, China; School of Information and Communication Engineering, Beijing Information Science and Technology University, Beijing, China; School of Information and Communication Engineering, Beijing Information Science and Technology University, Beijing, China; School of Information and Communication Engineering, Beijing Information Science and Technology University, Beijing, China","IEEE Access","6 Jan 2020","2020","8","","967","979","An unmanned aerial vehicle (UAV) swarm together with a large-scale heterogeneous Internet of Things (IoT) network consisting of macrocells and energy-constrained IoT transmitters (IoT-Ts) is investigated. The UAVs are utilized as flying robot swarms that intelligently transfer energy to the energy-constrained IoT-Ts on the ground. Each IoT-T has an associated IoT device (IoT-D) that is placed at a fixed distance in a random direction. The transmission probability of the energy-constrained IoT-Ts is derived by considering one-slot charging and two-slot charging according to three dimensional (3D) locations, respectively. The coverage probability of each type of IoT-D is investigated. The energy efficiency is derived by considering the transmission power of the active IoT-Ts and the effect of the association biasing factor, and the energy efficiency is also maximized by deploying the optimal density of IoT-Ts. Simulation results are examined to validate the accuracy of our theoretical analysis. Results illustrate the insightful effects of the network parameters, and the helpful guidelines for practical UAV swarms and IoT system design.","2169-3536","","10.1109/ACCESS.2019.2961977","Natural Science Foundation of Beijing Municipality(grant numbers:19L2022,4202046,4204099,KZ201911232046); National Natural Science Foundation of China(grant numbers:61801052,61801434); Beijing Municipal Commission of Education(grant numbers:KM202011232002,KM202011232003); Beijing Information Science and Technology University(grant numbers:5211910926,5211910924); Beijing Information Science and Technology University(grant numbers:5029011103,5111911147); Zhengzhou Municipal Science Technology Innovation Project(grant numbers:2019CXZX0037); China Postdoctoral Science Foundation(grant numbers:2018M642784); Scientific and Technological Key Project of Henan Province(grant numbers:192102310178); Key Laboratory of Dynamic Cognitive System of Electromagnetic Spectrum Space (Nanjing Univ. Aeronaut. Astronaut.), Ministry of Industry and Information Technology(grant numbers:KF20181901); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8941032","Unmanned aerial vehicle swarms;heterogeneous IoT networks;wireless power transfer;stochastic geometry;energy efficiency","Internet of Things;Wireless communication;Unmanned aerial vehicles;Three-dimensional displays;Batteries;Energy efficiency;Wireless power transfer","","17","","37","CCBY","24 Dec 2019","","","IEEE","IEEE Journals"
"Using the Power of Two Choices for Real-Time Task Scheduling in Fog-Cloud Computing","F. Hoseiny; S. Azizi; S. Dabiri","Department of Computer Engineering and IT, University of Kurdistan, Sanandaj, Iran; Department of Computer Engineering and IT, University of Kurdistan, Sanandaj, Iran; Department of Computer Engineering and IT, University of Kurdistan, Sanandaj, Iran","2020 4th International Conference on Smart City, Internet of Things and Applications (SCIOT)","10 Nov 2020","2020","","","18","23","With the rapid development of the Internet of Things (IoT) applications and services, the need for high Quality of Service (QoS) and computation power has been dramatically increased. In order to meet these needs, a promising computing system based on the integration of fog and cloud computing has been recently introduced. However, this system is still in its infancy and it is associated with many challenging issues. Task scheduling problem is one of the most important ones in this context. Motivated by this, in this paper, we propose a real-time randomized algorithm to address this problem in the large-scale fog-cloud computing systems. The proposed algorithm uses the Power of Two Choices (Po2C) approach to maximize QoS while minimizing monetary cost. The efficiency of the proposed Po2C is evaluated using extensive experiments. The results demonstrate that the proposed algorithm significantly outperforms the baseline scheduling strategies. Specifically, our algorithm improves the deadline violation cost by up to 58% in comparison with the Round Robin strategy.","","978-1-7281-9611-4","10.1109/SCIOT50840.2020.9250197","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9250197","Internet of Things (IoT);fog computing;cloud computing;task scheduling;power of two choices;Quality of Service (QoS);cost-efficient","Cloud computing;Smart cities;Quality of service;Real-time systems;Scheduling;Internet of Things;Task analysis","","8","","15","IEEE","10 Nov 2020","","","IEEE","IEEE Conferences"
"IoT Application for Water Quality Monitoring: Nitrates","L. Hernández-Alpizar; A. Carrasquilla-Batista; L. Sancho-Chavarría","Chemistry Department, Instituto Tecnológico de Costa Rica (ITCR); Mechatronic Engineering, ITCR; School of Computing, ITCR","2020 IEEE 11th Latin American Symposium on Circuits & Systems (LASCAS)","16 Apr 2020","2020","","","1","4","The intensive agricultural fertilization used for large scale food production generates an increase in the concentration of nitrates in water systems, contamination of water for human consumption and eutrophication of surface waters. Therefore, nitrates monitoring is a must practice in a basin receiving high agricultural activity. Discrete and sporadic samples analysis might reveal spatial differences in concentration, but continuous samples analysis gives the information about the origin, hydrological dynamics, transport and the bioprocessing of the nitrates. Here we present a design of an autonomous system for nitrates remote monitoring that uses an adjustable but continuous sampling flow, UV spectroscopy and Internet of Things (IoT) to directly perform and control the system calibration and nitrates quantification and, a strategy to optimize data generation and the monitoring resolution: a conductivity sensor used as a sampling frequency trigger.","2473-4667","978-1-7281-3427-7","10.1109/LASCAS45839.2020.9069039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9069039","Frequency triggers;Internet of Things;nitrates continuous monitoring.","Monitoring;Software;Water pollution;Calibration;Cloud computing;Water resources;Underwater vehicles","","5","","27","IEEE","16 Apr 2020","","","IEEE","IEEE Conferences"
"Accountable and Verifiable Secure Aggregation for Federated Learning in IoT Networks","X. Yang; Y. Zhao; Q. Chen; Y. Yu; X. Du; M. Guizani","The Hong Kong Polytechnic University, Hong Kong; Xi'an University of Posts and Telecommunications, China; Xidian University, China; Shaanxi Normal University and Wuyi University, China; Stevens Institute of Technology, USA; Mohamed Bin Zayed University of Artificial Intelligence, UAE","IEEE Network","25 Nov 2022","2022","36","5","173","179","In the Internet of things (IoT) networks, largescale IoT devices are connected to the Internet to collect users' data. As a distributed machine learning paradigm, federated learning (FL) collaboratively trains the global model by utilizing large-scale distributed devices, while protecting the privacy of the local data sets of each participant. Federated learning with secure aggregation employs an aggregation server (aggregator) to compute a multiparty sum of model parameter updates of each participants in a secure manner and further realizes the updates. However, existing schemes are usually based on semi-honest assumptions, which make them vulnerable to malicious clients. In addition, they address the random client dropouts problem by increasing the data size, which brings a large communication overhead. To solve these issues, we propose an accountable and verifiable secure aggregation for federated learning framework. Specifically, we employ an SMC protocol based on homomorphic proxy re-authenticators and homomorphic proxy re-encryption to execute secure aggregation, while integrating the blockchain to realize the function of penalty for malicious behavior. Our framework can guarantee the verifiability of data provenance and is accountable for malicious clients. To demonstrate the usability of our framework, we evaluate the specific cryptography schemes and develop a blockchain-based prototype system by using solidity language to test the performance of the framework.","1558-156X","","10.1109/MNET.001.2200214","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9964025","","Data privacy;Protocols;Federated learning;Computational modeling;Prototypes;Data models;Blockchains","","1","","15","IEEE","25 Nov 2022","","","IEEE","IEEE Magazines"
"State fusion evaluation and fusion compression method of multi-source sensors in power distribution Internet of things","J. Liu; L. Lu; D. Ju; Y. Jia; J. Qin; J. Dai; J. Wu; X. Xiao; C. Xiang","State Grid Electric Power Research Institute, Beijing, China; State Grid Electric Power Research Institute, Beijing, China; State Grid Electric Power Research Institute, Beijing, China; State Grid Electric Power Research Institute, Beijing, China; Electric Power Research Institute of State Grid Jiangsu Electric Power Co., Ltd, Nanjing, China; Electric Power Research Institute of State Grid Jiangsu Electric Power Co., Ltd, Nanjing, China; State Grid Electric Power Research Institute, Beijing, China; Electric Power Research Institute of State Grid Jiangsu Electric Power Co., Ltd, Nanjing, China; State Grid Electric Power Research Institute, Beijing, China","2020 12th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC)","23 Sep 2020","2020","1","","162","166","With the development of distribution Internet of things, the workload of judging and maintaining running state of sensors is quite considerable after large-scale construction of sensing layer. Moreover, promotion of long-distance low-power sensors puts forward the requirements of low energy consumption and bandwidth reduction for communication network between “side” and “end”. This paper proposes a state fusion evaluation method of multi-source sensors and data fusion compression method of low-power wireless sensors under the new inspection mode of distribution Internet of things. Taking the sensor system in Jiangsu power distribution substation as an example, the validity of state fusion evaluation of sensors is verified. The application of fusion compression algorithm can keep waveform characteristics and reduce data flow by 99.3%, which is more suitable for low-power and long-distance wireless transmission.","","978-1-7281-6517-2","10.1109/IHMSC49165.2020.00044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9204296","power distribution Internet of things;sensor;multi-source;fusion;compression","Sensor phenomena and characterization;Sensor fusion;Monitoring;Temperature sensors;Topology;Intelligent sensors","","","","15","IEEE","23 Sep 2020","","","IEEE","IEEE Conferences"
"Blockchain Smart Contract for Scalable Data Sharing in IoT: A Case Study of Smart Agriculture","M. Ur Rahman; F. Baiardi; L. Ricci","Department of Computer Science, University of Pisa, Pisa, Italy; Department of Philology, Literature, Linguistics University of Pisa, Pisa, Italy; Department of Computer Science, University of Pisa, Pisa, Italy","2020 IEEE Global Conference on Artificial Intelligence and Internet of Things (GCAIoT)","9 Feb 2021","2020","","","1","7","The emerging Smart Agriculture based on Internet of Things (IoT) is facing major challenges like data sharing, storage, and monitoring, primarily due to the distributed nature of IoT and massive scale. We performed a review of the literature and found that blockchain performance, scalability, cost, and throughput are the major challenges in adopting blockchain for smart agriculture. To overcome these challenges, this paper proposes a scalable and distributed data sharing system integrating access control for smart agriculture. We demonstrate our approach in a smart agriculture setting, which consists of four tiers that are: smart agriculture, smart contract, Interplanetary File System (IPFS) and agriculture stakeholders (remote users). This paper explains in detail the different components of our proposed architecture. Our approach uses anonymous identities to ensure users' privacy. Our approach is fully scalable because a large number of resource owners can use their data sharing smart contracts to create, update or delete data sharing policies. In addition, our approach does not require transaction fees when the smart contract receives a large number of policy evaluation requests. For the sake of simplicity, we publish and test a single data sharing smart contract. However, in practice, multiple smart contracts need to be deployed to allow each resource owner to securely share agriculture data with stakeholders. Finally, we evaluate the performance of our proposed system on the EOS blockchain to show that the resource consumption (in terms of computing power and network bandwidth) introduced by our framework are insignificant compared to its scalability, cost and security benefits.","","978-1-7281-8420-3","10.1109/GCAIoT51063.2020.9345874","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9345874","Blockchain;Smart Contract;Smart Agriculture;Smart Farming;Data Sharing;Trust;Access Control;Scalability","Scalability;Smart contracts;Distributed databases;Blockchain;Agriculture;Internet of Things;Stakeholders","","24","","19","IEEE","9 Feb 2021","","","IEEE","IEEE Conferences"
"How to Exploit 5G Networks for IoT e-Health Security and Privacy Challenges","B. D. Deebak; F. AL-Turjman","Vellore Institute of Technology, India; Near East University, Cyprus","IEEE Internet of Things Magazine","27 Sep 2021","2021","4","3","6","11","Cutting-edge IoT revolutionizes the delivery of healthcare information services to meet the global demand. The convergence of smart sensors has prioritized the development of eHealth technologies. In a telecommunication system, it is primarily concerned with the development of core technologies that enable electronic applications associated with 5G networks to achieve the confidential connectivity. Of late, it has increasingly been drawing its research interest for big data, IoT, fog, and cloud computing. However, security and privacy are still challenging to eHealth applications including the Internet of Medical Things, Internet of Health Things, and Mobile Internet of Things. Such guaranteed characteristics converge communication, computing, and caching (3C) to inherit large-scale economic and societal benefits. Thus, this work presents the challenges of secure authentication and key agreement (S-AKA) schemes that envision the security efficiencies of intelligent sensing technologies. S-AKA schemes are hard to break in real-time practice and have become the most useful contribution to modern cryptography. Such authentication schemes allow two or more communication parties to establish a secure session key to ensure data authenticity, confidentiality, and non-repudiation.","2576-3199","","10.1109/IOTM.0101.2000048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9548993","","Privacy;Protocols;5G mobile communication;Authentication;Real-time systems;Electronic healthcare;Telecommunication computing;Smart healthcare","","2","","15","IEEE","27 Sep 2021","","","IEEE","IEEE Magazines"
"An Intrusion Detection Method for Cyber Monintoring Using Attention based Hierarchical LSTM","H. Hou; Z. Di; M. Zhang; D. Yuan","College of Science and Information Science, Qingdao Agricultural University, Qingdao, China; School of Information Science and Engineering, Shandong University, Jinan, China; School of Information Science and Engineering, Shandong University, Jinan, China; School of Information Science and Engineering, Shandong University, Jinan, China","2022 IEEE 8th Intl Conference on Big Data Security on Cloud (BigDataSecurity), IEEE Intl Conference on High Performance and Smart Computing, (HPSC) and IEEE Intl Conference on Intelligent Data and Security (IDS)","27 Jun 2022","2022","","","125","130","The large-scale adoption of the Internet of Things (IoT) is accompanied by significant challenges posed by cyber security issues. Therefore, it is crucial to develop intrusion detection system (IDS) that can guarantee the security of IoT networks. In this paper, in view of the problem that the network traffic data has multidimensional features, and different feature units represent different meanings, which have different levels of contribution to the type of traffic data classification, an intrusion detection method based on Hierarchical LSTM and attention mechanism (HLSTM + Attention) is proposed. First, the HLSTM is used to extract sequence features across multiple hierarchical structures on the network record sequence. After that, the attention layer is used to capture the correlation between the features, and redistribute the weights of the features, which adaptively map the different importance of each feature to different network attack categories into the network learning process. The verification experiment results on the intrusion detection benchmark data set NSL-KDD show that the proposed algorithm has a better detection performance on network intrusion detection.","","978-1-6654-8069-7","10.1109/BigDataSecurityHPSCIDS54978.2022.00032","Key Research and Development Plan of Shandong Province(grant numbers:2019JZZY01011); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9799443","IoT;Intrusion Detection System;Hierarchical LSTM;Attention mechanism;NSL-KDD","Correlation;Conferences;Network intrusion detection;Telecommunication traffic;Predictive models;Feature extraction;Security","","4","","20","IEEE","27 Jun 2022","","","IEEE","IEEE Conferences"
"A Low-Cost Defect Segmentation System Based On IoT for Large-Scale Photovoltaic Manufacturing","C. Wang; H. Chen; S. Zhao; Y. Wang; Z. Cao","School of Artificial Intelligence and Data Science, Hebei University of Technology, Tianjin, China; School of Artificial Intelligence and Data Science, Hebei University of Technology, Tianjin, China; School of Artificial Intelligence and Data Science, Hebei University of Technology, Tianjin, China; School of Artificial Intelligence and Data Science, Hebei University of Technology, Tianjin, China; School of Artificial Intelligence and Data Science, Hebei University of Technology, Tianjin, China","IEEE Internet of Things Journal","","2024","PP","99","1","1","The photovoltaic industry is a strategic industry with international competitive advantages and is developing towards a larger scale, higher efficiency, and higher quality. However, current researchers have not built a pixel-level defect inspection system for large-scale photovoltaic production processes. This paper proposes an intelligent defect segmentation system combining the Internet of Things (IoT), artificial intelligence (AI), and edge computing for quality inspection of large-scale photovoltaic production lines. The intelligent factory based on this system is highly intelligent and deeply integrated, which can significantly reduce labor costs and improve factory productivity and product quality. The system’s core uses edge computing to segment cells in real-time by a lightweight defect segmentation model. Specifically, this paper proposes a lightweight yet effective architecture named Low-cost Defect Segmentation Network (LDSN). An Efficient Split (ES) block is designed to support more channels and improve model accuracy without adding much computational complexity. Moreover, the ES block can express multiscale features in a finer granularity and enhance the information interaction between grouping features. In the decoding structure, a Dual Focus Attention (DFA) that efficiently captures long-range spatial and channel information is proposed. Comprehensive experiments have been performed on a low-end PC with an NVIDIA GeForce RTX3060 GPU and an Intel Core i5-10600KF. LDSN-T-Lite achieves 84FPS and the F-measure OIS of 0.827, which only has 166K parameters and 395.6M memory usage on our PSCDE1 dataset. A bigger version of LDSN-B achieves the F-measure OIS of 0.872, significantly outperforming current methods.","2327-4662","","10.1109/JIOT.2024.3366945","Interdisciplinary postgraduate Training Program of Hebei University of Technology(grant numbers:HEBUT-Y-XKJC- 2022101,HEBUT-Y-XKJC- 2023001); Natural Science Foundation of Hebei Province(grant numbers:F2022202064); National Natural Science Foundation of China(grant numbers:62073117,62173124,U21A20482); Central Government Guides Local Science and Technology Development Fund Projects(grant numbers:206Z1701G); National Key Research and Development Program of China(grant numbers:2022YFB3303800); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10439979","IoT;AI;Large-Scale Photovoltaic Manufacturing;Efficient Defect Segmentation Model","Production;Solar power generation;Photovoltaic systems;Image edge detection;Computational modeling;Edge computing;Photovoltaic cells","","","","","IEEE","19 Feb 2024","","","IEEE","IEEE Early Access Articles"
"Information-Centric Massive IoT-Based Ubiquitous Connected VR/AR in 6G: A Proposed Caching Consensus Approach","S. Liao; J. Wu; J. Li; K. Konstantin","Shanghai Key Laboratory of Integrated Administration Technologies for Information Security, School of Cyber Security, Shanghai Jiao Tong University, Shanghai, China; Shanghai Key Laboratory of Integrated Administration Technologies for Information Security, School of Cyber Security, Shanghai Jiao Tong University, Shanghai, China; Shanghai Key Laboratory of Integrated Administration Technologies for Information Security, School of Cyber Security, Shanghai Jiao Tong University, Shanghai, China; Department of Physics of Nanoscale Systems, South Ural State University, Chelyabinsk, Russia","IEEE Internet of Things Journal","24 Mar 2021","2021","8","7","5172","5184","The development of massive IoT has not only brought about a wealth of hardware resources but also brought about the problems of difficult data management, resource running and low efficiency. The emergence of sixth-generation (6G) network will not only provide faster data rates, more device connections but also bring ubiquitous virtual reality/augmented reality (VR/AR) services. In the 6G era, large-scale IoT devices will generate VR/AR service and resource requirements, and the network will also face unprecedented pressure to respond to the ubiquitous VR/AR requirements. To address the above issues, this article proposes the information-centric massive Internet of Things (IC-mIoT) suitable for 6G large-scale VR/AR content distribution to improve the efficiency of IC-mIoT and fully guarantee the Quality of Service (QoS) of users. First, this article introduces the blockchain for IC-mIoT nodes and proposes a new consensus mechanism Proof-of-Cache-Offloading (PoCO). Second, an architecture using blockchain-enabled IC-mIoT for VR/AR is proposed in this article. The massive IoT resources are fully integrated and scheduled to support large-scale VR/AR applications and IC-mIoT. Third, a Stackelberg game model and a cache index selection and calculation algorithm are formulated for blockchain-enabled cache offloading. The analysis and performance simulation results indicate the superiority and effectiveness of the proposed scheme.","2327-4662","","10.1109/JIOT.2020.3030718","National Natural Science Foundation of China(grant numbers:61972255); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222169","6G;blockchain;information-centric network (ICN);massive IoT","6G mobile communication;Blockchain;Computer architecture;Internet of Things;Quality of service;Artificial intelligence;Games","","38","","40","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"Fast Authentication and Progressive Authorization in Large-Scale IoT: How to Leverage AI for Security Enhancement","H. Fang; A. Qi; X. Wang",Western University; The University of British Columbia; Western University,"IEEE Network","2 Jun 2020","2020","34","3","24","29","Security provisioning has become the most important design consideration for large-scale Internet of Things (IoT) systems due to their critical roles in supporting diverse vertical applications by connecting heterogenous devices, machines, and industry processes. Conventional authentication and authorization schemes are insufficient to overcome the emerging IoT security challenges due to their reliance on both static digital mechanisms and computational complexity for improving security levels. Furthermore, the isolated security designs for different layers and link segments while ignoring the overall protection leads to cascaded security risks as well as growing communication latency and overhead. In this article, we envision new artificial intelligence (AI)-enabled security provisioning approaches to overcome these issues while achieving fast authentication and progressive authorization. To be more specific, a lightweight intelligent authentication approach is developed by exploring machine learning at the base station to identify the prearranged access time sequences or frequency bands or codes used in IoT devices. Then we propose a holistic authentication and authorization approach, where online machine learning and trust management are adopted for achieving adaptive access control. These new AI-enabled approaches establish the connections between transceivers quickly and enhance security progressively so that communication latency can be reduced and security risks are well controlled in large-scale IoT systems. Finally, we outline several areas for AI-enabled security provisioning for future research.","1558-156X","","10.1109/MNET.011.1900276","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9105930","","Authentication;Artificial intelligence;Internet of Things;Authorization;Base stations;Feature extraction","","44","","15","IEEE","2 Jun 2020","","","IEEE","IEEE Magazines"
"PoBTx(Proof of Block and Transaction): An Efficient Consensus Algorithm for IoT Business Blockchain","M. C. Jobin Christ; D. Kalaiyarasi; J. G; K. Senthamilselvan; D. Kirubakaran; N. S. Gowri Ganesh","Department of Biomedical Engineering, Rajalakshmi Engineering College, Chennai, Tamil Nadu, India; Department of Electronics and Communication Engineering, Panimalar Engineering College, Chennai, Tamil Nadu; Department of Information Technology, RMD Engineering College, Chennai, Tamil Nadu, India; Department of Electronics and Communication Engineering, Prince Shri Venkateshwara Padmavathy Engineering College, Chennai, Tamil Nadu, India; Department of Computer Science and Engineering, R.M.K Engineering College, Chennai, Tamilnadu, India; Department of Artificial Intelligence and Data Science, Saveetha Engineering College, Chennai, Tamil Nadu, India","2023 Second International Conference on Augmented Intelligence and Sustainable Systems (ICAISS)","22 Sep 2023","2023","","","1343","1348","The rise of Internet of Things (IoT) networks has brought about numerous challenges in Industry 4.0 that can be addressed by blockchain technology. However, conventional business blockchain algorithms are inadequate for large-scale IoT systems and need to be adapted to make them scalable for IoT. This may require simplifying complex consensus-based security measures. This paper proposes a novel Proof of Block and Transaction (PoBTx) consensus algorithm, combining the advantages of Proof of Trade (PoT) and Proof of Block (PoB) approaches. PoBTx is tailored for IoT networks, addressing energy and computational constraints. The comprehensive analysis demonstrates its improvements in security, computation time, memory, and throughput compared to traditional consensus algorithms, making PoBTx a promising solution for large-scale IoT networks.","","979-8-3503-2579-9","10.1109/ICAISS58487.2023.10250612","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10250612","Internet of Things;Blockchain;Consensus algorithms;Proof of Trade;Proof of Block","Industries;Scalability;Consensus algorithm;Bandwidth;Throughput;Blockchains;Fourth Industrial Revolution","","","","15","IEEE","22 Sep 2023","","","IEEE","IEEE Conferences"
"Efficient Detection and Classification of Internet-of-Things Malware Based on Byte Sequences from Executable Files","T. -L. Wan; T. Ban; S. -M. Cheng; Y. -T. Lee; B. Sun; R. Isawa; T. Takahashi; D. Inoue","Department of Computer Science and Information Engineering, National Taiwan University of Science and Technology, Taipei, Taiwan; National Institute of Information and Communications Technology, Koganei, Tokyo, Japan; Department of Computer Science and Information Engineering, National Taiwan University of Science and Technology, Taipei, Taiwan; Department of Computer Science and Information Engineering, National Taiwan University of Science and Technology, Taipei, Taiwan; Saitama Institute of Technology, Saitama, Japan; National Institute of Information and Communications Technology, Koganei, Tokyo, Japan; National Institute of Information and Communications Technology, Koganei, Tokyo, Japan; National Institute of Information and Communications Technology, Koganei, Tokyo, Japan","IEEE Open Journal of the Computer Society","25 Nov 2020","2020","1","","262","275","Simple implementation and autonomous operation features make the Internet-of-Things (IoT) vulnerable to malware attacks. Static analysis of IoT malware executable files is a feasible approach to understanding the behavior of IoT malware for mitigation and prevention. However, current analytic approaches based on opcodes or call graphs typically do not work well with diversity in central processing unit (CPU) architectures and are often resource intensive. In this paper, we propose an efficient method for leveraging machine learning methods to detect and classify IoT malware programs. We show that reliable and efficient detection and classification can be achieved by exploring the essential discriminating information stored in the byte sequences at the entry points of executable programs. We demonstrate the performance of the proposed method using a large-scale dataset consisting of 111K benignware and 111K malware programs from seven CPU architectures. The proposed method achieves near optimal generalization performance for malware detection (99.96% accuracy) and for malware family classification (98.47% accuracy). Moreover, when CPU architecture information is considered in learning, the proposed method combined with support vector machine classifiers can yield even higher generalization performance using fewer bytes from the executable files. The findings in this paper are promising for implementing light-weight malware protection on IoT devices with limited resources.","2644-1268","","10.1109/OJCS.2020.3033974","Ministry of Science and Technology, Taiwan(grant numbers:109-2636-E-009-022,109-2218-E-011-007); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9240051","Computer security;machine learning;binary code;malware analysis;static analysis","Malware;Internet of Things;Feature extraction;Computer architecture;Machine learning;Support vector machines;Botnet","","19","","35","CCBYNCND","26 Oct 2020","","","IEEE","IEEE Journals"
"Efficient Privacy-Preserving Federated Learning for Resource-Constrained Edge Devices","J. Wu; Q. Xia; Q. Li","Department of Computer Science, William & Mary; Department of Computer Science, William & Mary; Department of Computer Science, William & Mary","2021 17th International Conference on Mobility, Sensing and Networking (MSN)","13 Apr 2022","2021","","","191","198","A large volume of data is generated by ubiquitous Internet-of-Things (IoT) devices and utilized to train machine learning models by IoT manufacturers to provide users with better services. Many deep learning systems for IoT data are required to perform all computation locally on small devices, which is not suitable for these resource-constrained devices. The devices can also send all the collected data to a server for costly model training by ignoring privacy concerns. To design an efficient and secure deep learning model training system, in this paper, we propose a federated learning system on the edge using the differential privacy mechanism to protect sensitive information and offload computation work from edge devices to edge servers, with consideration of communication reduction. In our system, a large-scale deep learning model is partitioned onto edge devices and edge servers, and trained in a distributed manner, in which all untrusted components are prevented from retrieving protected information from the training and inference process. We evaluate the proposed approach with respect to computation, communication, and privacy protection. The experiment results show that the proposed approach can preserve users’ privacy while significantly reducing computation and communication costs.","","978-1-6654-0668-0","10.1109/MSN53354.2021.00041","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9751555","Federated Learning;Privacy-Preserving Algorithm;Communication Efficiency","Training;Deep learning;Privacy;Differential privacy;Costs;Computational modeling;Feature extraction","","1","","17","IEEE","13 Apr 2022","","","IEEE","IEEE Conferences"
"Qatar Green Schools Initiative: Energy Management System with Cost-Efficient and Lightweight Networked IoT","U. Hijawi; A. Gastli; R. Hamila; O. Ellabban; D. Unal","Department of Electrical Engineering, Qatar University, Doha, Qatar; Department of Electrical Engineering, Qatar University, Doha, Qatar; Department of Electrical Engineering, Qatar University, Doha, Qatar; Iberdrola Innovation Middel East, Qatar Science & Technology Park, Doha, Qatar; KINDI Center for Computing Research, Qatar University, Doha, Qatar","2020 IEEE International Conference on Informatics, IoT, and Enabling Technologies (ICIoT)","11 May 2020","2020","","","415","421","With the growing need of developing real-time energy management and automation systems, building energy efficiency is of large focus in recent research. In particular, school buildings require special attention to occupants' comfort and behavioral patterns related to the power consumed by heavy functional electrical systems. This paper introduces an Energy Management System (EMS) for schools using cost-efficient Internet of Things (IoT) units. The basis of such a platform is networked IoT sensing units, of which as compared to existing solutions, they are convenient and cost-efficient for large-scale IoT deployments. The proposed school's EMS platform features four main layers (described bottom-up): 1) scalable deployment of the environment-sensing unit, and the smart meter unit. The units compute electric parameters and energy profiles of the connected appliances/switchboard circuits, in addition to the environmental parameters; 2) sensor communication networks in restricted physical zones; 3) live and historical data monitoring and analysis at the cloud; and 4) remote real-time control of the connected circuits/appliances for efficient energy consumption and management. While being highly cost-efficient and energy efficient, the implemented IoT sensing units show measured-data credibility on lightweight and computationally constrained resources, and are designed to be noninvasive for convenient commercialized deployments. The proposed system is planned to be integrated with the external smart grid network as well as renewable energy production systems.","","978-1-7281-4821-2","10.1109/ICIoT48696.2020.9089443","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9089443","sensor networks;energy management;internet of things;constrained resources;energy efficiency","Voltage measurement;Energy management;Buildings;Current measurement;Smart meters;Energy measurement;Servers","","5","","23","IEEE","11 May 2020","","","IEEE","IEEE Conferences"
"Web Service-Based Turkish Automatic Speech Recognition Platform","S. Oyucu; H. Polat; H. Sever","Dept. of computer engineering, University of Gazi, Ankara, Tukey; Dept. of computer engineering, University of Gazi, Ankara, Tukey; Dept. of software engineering, University of Cankaya, Ankara, Tukey","2020 International Congress on Human-Computer Interaction, Optimization and Robotic Applications (HORA)","30 Jul 2020","2020","","","1","5","In response to the similar challenges in building large-scale distributed applications and platforms on the Web, microservice architecture has emerged and gained a lot of popularity in recent years. Therefore, both for the use of microservices and for the provided of the necessary interface for Automatic Speech Recognition (ASR), a web-based platform has been developed. Within firstly the scope of the study, a Turkish ASR system was developed. A web service structure was created to facilitate access to the ASR system. The access of methods and data in the web service structure was provided through Representational State Transfer (REST) web services and service layer. An interface was developed to enable interaction with the web service. The platform was developed using a combination of different technologies such as ASR, web services, microservices, and interface technologies. The developed platform can be used via a standard web browser or an Application Programming Interface (API). In this study, Docker packages were used to improve system performance instead of using different virtual machines on a single server. In the experiments performed, it was shown that the Turkish ASR system had a word error rate of 24.70%. In web service performance tests, it was shown that the platform responded in an average of 9.6 seconds for a 59-second speech recording. The developed user interface was tested in both mobile and desktop web browsers and was shown to function properly. Applications and other services were given access to the platform without the need to use an interface via API support provided by the platform. As a result, a web service-based Turkish ASR platform working seamlessly on the ever-increasing number of mobile devices, the Internet of Things ecosystem, or other access devices was developed.","","978-1-7281-9352-6","10.1109/HORA49412.2020.9152920","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9152920","Automatic speech recognition;ASR;web service;microservices;web-based ASR;Turkish speech recognition","Web services;Hidden Markov models;Maximum likelihood decoding;Testing;Speech recognition;Tools;Browsers","","2","","19","IEEE","30 Jul 2020","","","IEEE","IEEE Conferences"
"Distribution Network Distributed Resources Application Framework and Key Technologies Based on Cloud-Edge-Device Collaboration","J. Zhang; C. Bao; M. Xu; Y. Jin; C. Zhou; J. Xie","Electric Power Research Institute, State Grid Henan Power Company, Zhengzhou, China; College of Energy and Electrical Engineering, Hohai University, Nanjing, China; Electric Power Research Institute, State Grid Henan Power Company, Zhengzhou, China; College of Energy and Electrical Engineering, Hohai University, Nanjing, China; College of Energy and Electrical Engineering, Hohai University, Nanjing, China; College of Energy and Electrical Engineering, Hohai University, Nanjing, China","2022 IEEE 6th Conference on Energy Internet and Energy System Integration (EI2)","10 May 2023","2022","","","1888","1892","Large-scale access of distributed photovoltaic, distributed energy storage and electric vehicle to the distribution network drives the transformation of the ""source-network-load-storage"" regulation mode. Frequent two-way interaction between distribution network and distributed resources puts forward higher requirements for the power Internet of Things. At present, centralized data storage and processing based on cloud computing in the power grid makes massive distributed resource data unable to be effectively applied. In that case, for the challenges in the application of distributed resources in the cloud-edge-device collaborative distribution network, a distributed resource data application framework based on cloud-edge-device collaborative distribution network is proposed to break the interaction barriers between distributed resources and power system caused by limited computing resources. The distributed resource data application framework of distribution network based on cloud-edge-device collaboration provides reference for the hierarchical, distributed storage and processing of massive data in power grid. Finally, based on this framework, the key technology of distribution network distributed resources based on cloud-edge-device collaboration are proposed, which provides a new idea for constructing distributed resource cloud-edge-device collaboration technology with adequate security and economic benefit, as well as lean management and high service quality in distribution network.","","979-8-3503-4715-9","10.1109/EI256261.2022.10116961","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10116961","distribution network;distributed resources;cloud-edge-device collaboration;edge computing;power Internet of Things","Economics;Cloud computing;Collaboration;Distributed databases;Distribution networks;System integration;Big Data applications","","","","10","IEEE","10 May 2023","","","IEEE","IEEE Conferences"
"IoT and Cloud Computing based Smart Water Metering System","A. Ray; S. Goswami","A. K. C. School of Information Technology, University of Calcutta, Kolkata, India; A. K. C. School of Information Technology, University of Calcutta, Kolkata, India","2020 International Conference on Power Electronics & IoT Applications in Renewable Energy and its Control (PARC)","7 May 2020","2020","","","308","313","This paper focuses on the developmental and implementation methodology of smart water meter based on Internet of Things (IoT) and Cloud computing equipped with machine learning algorithms, to differentiate between normal and excessive water usage at industrial, domestic and all other sectors having an abundance of water usage, both for Indian and worldwide context. Recognizing that intelligent metering of water has the potential to alter customer engagement of water usage in urban and rural water supplies, this paper fosters for sustainable water management, a need of the present. With shrinking reserves of clean water resources worldwide, it is becoming cumbersome to cater for this resource to masses in the coming years on a consistent basis. Using our smart water meter, water resources can be managed efficiently and an optimum use could save water for the future generations. Sensors will provide for real time monitoring of hydraulic data, automated control and alarming from Cloud platform in case of events such as water leakages, excessive usage, etc. Analysis of the same will help in taking meaningful actions. Thus we do propose for a smart water metering technology that can be utilized by Indian citizens, and worldwide, to curb wastage of water. With an ease of monitoring and visualization of the data through the Cloud platform combined with machine learning based tools to detect excess water consumption, the server-less architecture we propose can be easily adopted and implemented in a large scale.","","978-1-7281-6575-2","10.1109/PARC49193.2020.236616","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9087024","Cloud computing;IoT;Machine learning;Server-less architecture;Revenue generation","","","17","","18","IEEE","7 May 2020","","","IEEE","IEEE Conferences"
"Scheduling Optimization of real-time IOT system based on RNN","S. Liu; C. Zhang; Y. Chen","Graduate School, National University of Defence Technology, ChangSha, HuNan, China; School of Computer, National University of Defence Technology, ChangSha, HuNan, China; School of Computer, National University of Defence Technology, ChangSha, HuNan, China","2020 International Conference on Intelligent Computing and Human-Computer Interaction (ICHCI)","10 May 2021","2020","","","249","253","Ubiquitous computation, which promoted by Rapid development of Wireless Sensor Network (WSN) technologies cuts across many areas of modern day living, Internet of Things has been identified as one of Network Infrastructure in the next generation of application domains. An architecture based on cloud computing at the center, which contribute to highly flexibility and scalablity, is an extensively used scheme to construct IOT applications. With growing number of intelligent terminals and third part application accessing on the platform, the Qos problem caused by the large-scale concurrent access rise to the surface. To address this question, a self-adaption Multi-level Feedback Queue Scheduling policy, used to reduce mean turnaround time and complexity of scheduling, based on Recurrent Neural Network (RNN) is presented in this paper. Feature parameters of queues and tasks are used as input of network, the calculated parameters are exported to optimize queue parameters continuously. This research implement a prototype of this scheme. According To demonstrate the efficiency, this thesis give performance results from our prototype and other scheduling policy.","","978-1-6654-2316-8","10.1109/ICHCI51889.2020.00061","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9424792","IOT platform;Scheduling optimization;RNN;Self-adaption;Multi-level Feedback Queue","Wireless sensor networks;Recurrent neural networks;Processor scheduling;Prototypes;Quality of service;Computer architecture;Ubiquitous computing","","","","23","IEEE","10 May 2021","","","IEEE","IEEE Conferences"
"A Simulation-Based Optimization Approach for Reliability-Aware Service Composition in Edge Computing","J. Huang; J. Liang; S. Ali","Department of Computer Science and Technology, China University of Petroleum, Beijing, China; Department of Computer Science and Technology, China University of Petroleum, Beijing, China; Department of Computer Science and Technology, China University of Petroleum, Beijing, China","IEEE Access","18 Mar 2020","2020","8","","50355","50366","With the prevalence of Internet of Things (IoT), edge computing has emerged as a novel computing model for optimizing traditional cloud computing systems by moving part of the computational tasks to the edge of the network for better performance and security. With the technique of services computing, edge computing systems can accommodate the application requirements with more agility and flexibility. In large-scale edge computing systems, service composition as one of the most important problems in services computing suffers from several new challenges, i.e., complex layered architecture, failures and recoveries always in the lifecycle, and search space explosion. In this paper, we make an attempt at addressing these challenges by designing a simulation-based optimization approach for reliability-aware service composition. Composite stochastic Petri net models are proposed for formulating the dynamics of multi-layered edge computing systems, and their corresponding quantitative analysis is conducted. To solve the state explosion problem in large-scale systems or complex service processes, time scale decomposition technique is applied to improving the efficiency of model solving. Additionally, simulation schemes are designed for performance evaluation and optimization, and ordinal optimization technique is introduced to significantly reduce the size of the search space. Finally, we conduct experiments based on real-life data, and the empirical results validate the efficacy of the approach.","2169-3536","","10.1109/ACCESS.2020.2979970","National Natural Science Foundation of China(grant numbers:61972414); Natural Science Foundation of Beijing Municipality(grant numbers:4202066); Fundamental Research Funds for the Central Universities(grant numbers:2462018YJRC040,2462020YJRC001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9032180","Edge computing;reliability;service composition;stochastic Petri net;simulation-based optimization","Computational modeling;Edge computing;Optimization;Petri nets;Performance evaluation;Reliability;Stochastic processes","","21","","45","CCBY","11 Mar 2020","","","IEEE","IEEE Journals"
"HSFL: Efficient and Privacy-Preserving Offloading for Split and Federated Learning in IoT Services","R. Deng; X. Du; Z. Lu; Q. Duan; S. -C. Huang; J. Wu","School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; Information Sciences & Technology Department, Pennsylvania State University, Abington, PA, USA; Department of Electronic Engineering, National Taipei University of Technology, Taiwan; School of Computer Science, Fudan University, Shanghai, China","2023 IEEE International Conference on Web Services (ICWS)","19 Sep 2023","2023","","","658","668","Distributed machine learning methods like Federated Learning (FL) and Split Learning (SL) meet the growing demands of processing large-scale datasets under privacy restrictions. Recently, FL and SL are combined in hybrid SLFL (SFL) frameworks to exploit both methods’ advantages to facilitate ubiquitous intelligence in the Internet of Things (IoT), for example, smart finance. Despite its significant impact on the performance and costs of SFL, model decomposition that splits an ML model into the client-server pair has not been sufficiently studied, especially for SFL in a large-scale dynamic IoT environment. In this paper, we propose a new SFL framework HSFL with a lightweight model decomposition method to offload a part of model training to the edge server. Specifically, we develop a method for estimating the training latency of HSFL and designed a metric for measuring privacy leakage in HSFL, based on which we formulate model decomposition in HSFL as an optimization problem with privacy protection as a constraint. Then, we transform the formulated problem into a contextual bandit problem and design an efficient algorithm to solve it. We have conducted thorough evaluations of the proposed HSFL framework through extensive experiments on a prototype testbed and a simulation platform. The experimental results validate the superiority of HSFL over the state-of-the-art benchmarks in terms of training latency, efficiency, scalability, and privacy protection.","2836-3868","979-8-3503-0485-5","10.1109/ICWS60048.2023.00084","Research and Development; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10248280","Federated Learning;Split Learning;Model Decomposition;Privacy Leakage Analysis;Internet of Things;Financial Technology","Training;Measurement;Privacy;Adaptation models;Federated learning;Scalability;Benchmark testing","","1","","36","IEEE","19 Sep 2023","","","IEEE","IEEE Conferences"
"Flexible Semantic-based Data Networking for IoT Domains","M. Al-Naday; I. Macaluso","School of Computer Science and Electronic Engineering, University of Essex; CONNECT Centre, Trinity College Dublin","2021 IEEE 22nd International Conference on High Performance Switching and Routing (HPSR)","15 Jul 2021","2021","","","1","6","The rapid adoption of the Internet of Things (IoT) as a means for digital transformation is sketching a new landscape of heterogeneous data and distributed, machine learning-based, applications. The intertwine of the two combined with the varying availability of data, generated in different parts of the domain, raises the need to exchange bulks of relevant data on demand across application(s) points. Data relevance escalates the role of semantics in identifying and locating suitable data; particularly at the network layer, to provide efficient mapping of data supply and demand. This paper proposes a semantic-based data networking framework, for managed IoT domains, embracing principles of information-centric networking without restrictions on the routing function. Managed semantics are used to provide flexible (label-based) data addressing scheme and a scalable semantic locator function, designed as an overlay network of distributed instances that can be realized on top of any routing or forwarding solution. Nonetheless, we outline different routing solutions and their suitability to such scenarios, to then draw a recommendation of the most suitable underlying routing fabric. We evaluate our framework over an example IoT domain of the Pervasive Nation (PN), Ireland national IoT network. Through our example, we show that the number of managed semantics in such a domain can be vastly smaller than that expected on an Internet scale. We analyze our semantic aggregation scheme over the example PN network, and show the high flexibility in mapping data while maintaining a small state in the semantic locator function.","2325-5609","978-1-6654-4005-9","10.1109/HPSR52026.2021.9481800","Science Foundation Ireland; Irish Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9481800","semantic-based addressing;information-centric networking;Internet of Things (IoT);machine learning;Artificial Intelligence (AI) applications","Supply and demand;Overlay networks;Semantics;Information-centric networking;Distributed databases;Switches;Logic gates","","4","","24","IEEE","15 Jul 2021","","","IEEE","IEEE Conferences"
"Energy Management System with IoT Connectivity for Portable Solar Power Plant","D. D. Putra; B. Syihabuddin; M. A. M. Jabbar; A. Irsal; A. Purwadi; A. Munir","School of Electrical Eng. & Informatics, Institut Teknologi Bandung, Bandung, Indonesia; School of Electrical Engineering, Telkom University, Bandung, Indonesia; School of Electrical Eng. & Informatics, Institut Teknologi Bandung, Bandung, Indonesia; School of Electrical Eng. & Informatics, Institut Teknologi Bandung, Bandung, Indonesia; Electrical Energy Conversion Lab. School of Electrical Eng. & Informatics, Institut Teknologi Bandung, Bandung, Indonesia; Radio Telecomm. and Microwave Lab. School of Electrical Eng. & Informatics, Institut Teknologi Bandung, Bandung, Indonesia","2020 IEEE International Conference on Internet of Things and Intelligence System (IoTaIS)","23 Feb 2021","2021","","","56","59","Indonesia has a potentiality in solar energy quite high since it is located on the equator area. The potency of solar energy in Indonesia, based on the national energy council, spans around 4.8 kilowatt-hours per square meter per day (kWh/m2/day). This is very advantage for establishing small scale solar power plants as source of electricity in remote areas especially which has portability aspect. However, the energy management generated by a portable solar power plant has rarely received attention and often conducted manually. Therefore, in this paper, the development of energy management system is proposed for portable solar power plant, in which the system has the connection to Internet of Things (IoT) network. So the controlling of power usage as well as the monitoring process of battery capacity can be conducted easily through smartphones, tablets, or computers.","","978-1-7281-9448-6","10.1109/IoTaIS50849.2021.9359705","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9359705","Energy management system;IoT connectivity;monitoring system;solar power plant","Process control;Solar energy;Internet of Things;Energy management systems;Power generation;Monitoring;Smart phones","","4","","14","IEEE","23 Feb 2021","","","IEEE","IEEE Conferences"
"A Novel Cyber-Physical System for the Optimal Heating-Cooling of Buildings","M. Barzegar; A. Farhadi","Department of Electrical Engineering, Sharif University of Technology, Tehran, Iran; Department of Electrical Engineering, Sharif University of Technology, Tehran, Iran","IEEE Transactions on Automation Science and Engineering","","2023","PP","99","1","12","This paper presents a novel Cyber-Physical System (CPS) equipped with an advanced Distributed Model Predictive Control (DMPC) method with reduced order computational complexity, zero steady-state error, reduced start-up energy consumption and improved transient response for the optimal heating-cooling of buildings. The satisfactory application of this method for the optimal heating-cooling of a large-scale (6-story) building with 40 rooms is illustrated. Smart Industrial Internet of Things (IIoT) -based thermostats, a gateway and a general Quadratic Programming (QP) solver are developed. Using this hardware set-up, the simulation results for the 6-story building are verified in a small scale by practical implementation. Note to Practitioners—This paper proposes a novel cyber-physical system for the optimal heating-cooling of large-scale buildings. The proposed system is practical, in particular, for large-scale buildings because for its realization, we do not need mighty and therefore expensive computer servers to execute required optimization problems in real-time. It also has high reliability and resilience due to its distributed computation nature and can be realized using available and cost-effective On-Off electric valves. To implement this system, a general QP solver, smart IIoT-based thermostats and a gateway are designed, developed and implemented in a building for the optimal heating and cooling. The satisfactory performance and superiority of the proposed system in terms of zero steady-state error, transient response, applicability for both heating and cooling systems and limited start-up energy consumption over the traditional as well as more advanced systems are illustrated by simulation and practical implementation.","1558-3783","","10.1109/TASE.2023.3335090","Iran’s National Elites Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10329334","Distributed model predictive control;cyber-physical system;building automation and control","Buildings;Heating systems;Steady-state;Industrial Internet of Things;Energy consumption;Weather forecasting;HVAC","","","","","IEEE","27 Nov 2023","","","IEEE","IEEE Early Access Articles"
"Machine Learning based Occupant Behavior Prediction in Smart Building to Improve Energy Efficiency","N. Fatehi; A. Politis; L. Lin; M. Stobby; M. H. Nazari","Department of Electrical and Computer Engineering, Wayne State University, Detroit, MI, USA; Department of Electrical and Computer Engineering, Wayne State University, Detroit, MI, USA; Department of Electrical and Computer Engineering, Wayne State University, Detroit, MI, USA; Department of Electrical and Computer Engineering, Wayne State University, Detroit, MI, USA; Department of Electrical and Computer Engineering, Wayne State University, Detroit, MI, USA","2023 IEEE Power & Energy Society Innovative Smart Grid Technologies Conference (ISGT)","22 Mar 2023","2023","","","1","5","The demand for quick and precise occupancy prediction in building management system is rapidly growing as a result of more complex Internet of Things (IoT) devices and their widespread implementation in smart building automation. This is done to save electricity while maintaining occupant's comfort. In this paper, we propose a one-layer Gated Recurrent Unit (GRU) neural network for smart building occupancy prediction. We compare its performance with that of Long Short-Term Memory (LSTM) network which is widely used in the literature. We use a data-set collected from hundreds of digital passive infrared (PIR) occupancy sensors in a large academic building in California. The experimental findings reveal that GRU outperforms the LSTM network by obtaining lower error by 1.21% and requiring less parameters of 13.57% for training. As a result, GRU can be trained 10% faster and thus is better suited for large-scale occupancy prediction tasks in emerging smart buildings.","2472-8152","978-1-6654-5355-4","10.1109/ISGT51731.2023.10066411","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10066411","Deep neural network;Energy consumption;Internet of things;GRU;LSTM;Occupancy prediction;Smart building","Training;Performance evaluation;Energy consumption;Smart buildings;Neural networks;Predictive models;Windows","","4","","22","IEEE","22 Mar 2023","","","IEEE","IEEE Conferences"
"Early Detection and Prevention of Red Palm Weevil Along with Irrigation Management System","O. M. Haraz; W. Saad; M. M. M. Ali; T. A. Denidni","Electrical Engineering Dept., Assiut University, Assiut, 71516, Egypt; Electronic and Electrical Comm. Dep., Menoufia University, Menoufia, Egypt; Institut National de la Recherche Scientifique, Universite du Quebec, Montreal, Quebec, Canada; Institut National de la Recherche Scientifique, Universite du Quebec, Montreal, Quebec, Canada","2021 IEEE USNC-URSI Radio Science Meeting (Joint with AP-S Symposium)","10 Feb 2022","2021","","","56","57","Middle East and North Africa (MENA) region has large numbers of palm tree farms. Monitoring trees requires early detection technology that can be sustained at a large scale and at minimal cost. This paper proposes innovative solutions using modern techniques for early detection & control of red palm weevil. Through this proposed system, Internet of things (IoT) technology can be used for water leak detection and irrigation management as well as intelligent solutions to increase water efficiency.","","978-1-946815-10-1","10.23919/USNC-URSI51813.2021.9703522","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9703522","Date palm;Red palm weevil;IOT;Sensors;Weevil early detection and irrigation management","Irrigation;Costs;Meetings;Africa;Sensor systems;Internet of Things;Leak detection","","1","","11","","10 Feb 2022","","","IEEE","IEEE Conferences"
"Analysis of IoT-Based Load Altering Attacks Against Power Grids Using the Theory of Second-Order Dynamical Systems","S. Lakshminarayana; S. Adhikari; C. Maple","School of Engineering, University of Warwick, Coventry, U.K.; College of Engineering, Swansea University, Swansea, U.K.; Warwick Manufacturing Group, University of Warwick, Coventry, U.K.","IEEE Transactions on Smart Grid","20 Aug 2021","2021","12","5","4415","4425","Recent research has shown that large-scale Internet of Things (IoT)-based load altering attacks can have a serious impact on power grid operations such as causing unsafe frequency excursions and destabilizing the grid's control loops. In this work, we present an analytical framework to investigate the impact of IoT-based static/dynamic load altering attacks (S/DLAAs) on the power grid's dynamic response. Existing work on this topic has mainly relied on numerical simulations and, to date, there is no analytical framework to identify the victim nodes from which that attacker can launch the most impactful attacks. To address these shortcomings, we use results from second-order dynamical systems to analyze the power grid frequency control loop under S/DLAAs. We use parametric sensitivity of the system's eigensolutions to identify victim nodes that correspond to the least-effort destabilizing DLAAs. Further, to analyze the SLAAs, we present closed-form expression for the system's frequency response in terms of the attacker's inputs, helping us characterize the minimum load change required to cause unsafe frequency excursions. Using these results, we formulate the defense against S/DLAAs as a linear programming problem in which we determine the minimum amount of load that needs to be secured at the victim nodes to ensure system safety/stability. Extensive simulations conducted using benchmark IEEE-bus systems validate the accuracy and efficacy of our approach.","1949-3061","","10.1109/TSG.2021.3070313","Startup Grant from the University of Warwick; Alan Turing Institute and PETRAS, UK’s National Centre of Excellence for IoT Systems Cyber Security; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9393479","IoT-based load altering attacks;second-order dynamical systems;eigenvalue sensitivity;attack impact","Power grids;Sensitivity;Eigenvalues and eigenfunctions;Generators;Computational modeling;Load modeling;Safety","","22","","34","IEEE","1 Apr 2021","","","IEEE","IEEE Journals"
"Safeguarding the IoT From Malware Epidemics: A Percolation Theory Approach","A. Zhaikhan; M. A. Kishk; H. ElSawy; M. -S. Alouini","Computer, Electrical, and Mathematical Sciences and Engineering Division, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; Computer, Electrical, and Mathematical Sciences and Engineering Division, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; Electrical Engineering Department, King Fahd University of Petroleum and Minerals, Dhahran, Saudi Arabia; Computer, Electrical, and Mathematical Sciences and Engineering Division, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia","IEEE Internet of Things Journal","24 Mar 2021","2021","8","7","6039","6052","The upcoming Internet of Things (IoT) is foreseen to encompass massive numbers of connected devices, smart objects, and cyber-physical systems. Due to the large scale and massive deployment of devices, it is deemed infeasible to safeguard 100% of the devices with state-of-the-art security countermeasures. Hence, large-scale IoT has inevitable loopholes for network intrusion and malware infiltration. Even worse, exploiting the high density of devices and direct wireless connectivity, malware infection can stealthily propagate through susceptible (i.e., unsecured) devices and form an epidemic outbreak without being noticed to security administration. A malware outbreak enables adversaries to compromise a large population of devices, which can be exploited to launch versatile cyber and physical malicious attacks. In this context, we utilize spatial firewalls, to safeguard the IoT from malware outbreak. In particular, spatial firewalls are computationally capable devices equipped with state-of-the-art security and anti-malware programs that are spatially deployed across the network to filter the wireless traffic in order to detect and thwart malware propagation. Using tools from percolation theory, we prove that there exists a critical density of spatial firewalls beyond which malware outbreak is impossible. This, in turn, safeguards the IoT from malware epidemics regardless of the infection/treatment rates. To this end, a tractable upper bound for the critical density of spatial firewalls is obtained. Furthermore, we characterize the relative communications ranges of the spatial firewalls and IoT devices to ensure secure network connectivity. The percentage of devices secured by the firewalls is also characterized.","2327-4662","","10.1109/JIOT.2020.3034111","Deanship of Scientific Research (DSR) at King Fahd University of Petroleum and Minerals (KFUPM)(grant numbers:DF191052); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9240972","Boolean model;network epidemics;percolation theory;random geometric graphs (RGGs)","Malware;Wireless communication;Epidemics;Security;Wireless sensor networks;Communication system security;Internet of Things","","13","","49","IEEE","27 Oct 2020","","","IEEE","IEEE Journals"
"Soft Actor Critic Framework for Resource Allocation in Backscatter-NOMA Networks","A. Alajmi; M. Fayaz; W. Ahsan; A. Nallanathan","Queen Mary University of London, London, UK; Queen Mary University of London, London, UK; Queen Mary University of London, London, UK; Queen Mary University of London, London, UK","2022 IEEE Latin-American Conference on Communications (LATINCOM)","2 Jan 2023","2022","","","1","6","With the use of power domain non-orthogonal multiple access (NOMA) and backscatter communication (BAC), future sixth-generation ultra massive machine type communications networks are expected to connect large-scale Internet of things (IoT) devices. However, due to NOMA co-channel interference, the power allocation to large-scale IoT devices becomes critical. The existing convex optimization-based solutions are highly complex hence, it is difficult to find the optimal solution to the resource allocation problem in a highly dynamic environment. Therefore, this work develops an efficient model-free BACNOMA system to assist the base station for complex resource scheduling tasks in a dynamic BAC-NOMA IoT network. More specifically, we jointly optimize the transmit power of downlink IoT users and the reflection coefficient of uplink backscatter devices using a reinforcement learning algorithm, namely, softactor critic. Numerical results show that the proposed algorithm obtained a higher reward and converges to an optimal solution with respect to a large number of iterations. The proposed algorithm increases the sum rate by 57.6% as compared to the conventional optimization (benchmark) approach. Moreover, we show that the proposed algorithm outperforms the conventional BAC-NOMA scheme and BAC with orthogonal multiple access in terms of average sum rate with the increasing number of backscatter devices.","2330-989X","978-1-6654-8225-7","10.1109/LATINCOM56090.2022.10000455","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10000455","Backscatter communications;non-orthogonal multiple access;resource allocation;reinforcement learning","NOMA;Heuristic algorithms;Reinforcement learning;Benchmark testing;Dynamic scheduling;Internet of Things;Resource management","","","","11","IEEE","2 Jan 2023","","","IEEE","IEEE Conferences"
"A Service-Oriented Permissioned Blockchain for the Internet of Things","C. Qiu; H. Yao; F. R. Yu; C. Jiang; S. Guo","College of Intelligence and Computing, School of Computer Science and Technology, Tianjin University, Tianjin, China; Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; Systems and Computer Engineering, Carleton University, Ottawa, Canada; Space Center, Tsinghua University, Beijing, China; Department of Computing, The Hong Kong Polytechnic University, Hong Kong","IEEE Transactions on Services Computing","8 Apr 2020","2020","13","2","203","215","Recently, the emergence of blockchain has stirred great interests in the field of Internet of Things (IoT). However, numerous non-trivial problems in the current blockchain system prevent it from being used as a generic platform for large-scale services and applications in IoT. One notable drawback is the scalability problem. Lots of projects and researches have been done to solve this problem. Nevertheless, they do not consider different users' conditions, only using a single consensus protocol as the best fit one, as well as the IoT system is heavily constrained by computing and networking resources. In this article, we study a permissioned blockchain-based IoT architecture. In order to improve the scalability of the blockchain system and meet the needs of different users, we propose a service-oriented permissioned blockchain, where different consensus protocols are launched according to users' quality of service (QoS) requirements. Specially, we quantify a few popular consensus protocols. Additionally, we select block producers, which need a great number of computation resources, as well as dynamically allocate network bandwidth to the blockchain system. We formulate consensus protocols selection, block producers selection, and network bandwidth allocation as a joint optimization problem. We then use a dueling deep reinforcement learning approach to solve the problem. Simulation results demonstrate the effectiveness of our proposed scheme.","1939-1374","","10.1109/TSC.2019.2948870","National Engineering Laboratory for Public Safety Risk Perception and Control by Big Data; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880544","Internet of things (IoT);permissioned blockchain;service-oriented;Byzantine fault tolerance;deep reinforcement learning","Quality of service;Internet of Things;Computational modeling;Scalability","","31","","27","IEEE","23 Oct 2019","","","IEEE","IEEE Journals"
"Joint Activity and Blind Information Detection for UAV-Assisted Massive IoT Access","L. Qiao; J. Zhang; Z. Gao; D. Zheng; M. J. Hossain; Y. Gao; D. W. K. Ng; M. Di Renzo","School of Information and Electronics and Advanced Research Institute of Multidisciplinary Science, Beijing Institute of Technology, Beijing, China; School of Information and Electronics and Advanced Research Institute of Multidisciplinary Science, Beijing Institute of Technology, Beijing, China; School of Information and Electronics and Advanced Research Institute of Multidisciplinary Science, Beijing Institute of Technology, Beijing, China; School of Information and Electronics and Advanced Research Institute of Multidisciplinary Science, Beijing Institute of Technology, Beijing, China; School of Engineering, The University of British Columbia, Kelowna, Canada; School of Computer Science, Fudan University, Shanghai, China; School of Electrical Engineering and Telecommunications, University of New South Wales, Sydney, NSW, Australia; Laboratoire des Signaux et Systèmes, French National Center for Scientific Research (CNRS), CentraleSupélec, Université Paris-Saclay, Gif-sur-Yvette, France","IEEE Journal on Selected Areas in Communications","15 Apr 2022","2022","40","5","1489","1508","Grant-free non-coherent index-modulation (NC-IM) has been recently considered as an efficient massive access scheme for enabling cost- and energy-limited Internet-of-Things (IoT) devices that transmit small data packets. This paper investigates the grant-free NC-IM scheme combined with orthogonal frequency division multiplexing for applicant to unmanned aerial vehicle (UAV)-based massive IoT access. Specifically, each device is assigned a unique non-orthogonal signature sequence codebook. Each active device transmits one of its signature sequences in the given time-frequency resources, by modulating the information in the index of the transmitted signature sequence. For small-scale multiple-input multiple-output (MIMO) deployed at the UAV-based aerial base station (BS), by jointly exploiting the space-time-frequency domain device activity, we propose a computationally efficient space-time-frequency joint activity and blind information detection (JABID) algorithm with significantly improved detection performance. Furthermore, for large-scale MIMO deployed at the aerial BS, by leveraging the sparsity of the virtual angular-domain channels, we propose an angular-domain based JABID algorithm for improving the system performance with reduced access latency. In addition, for the case of high mobility IoT devices and/or UAVs, we introduce a time-frequency spread transmission (TFST) strategy for the proposed JABID algorithms to combat doubly-selective fading channels. Finally, extensive simulation results are illustrated to verify the superiority of the proposed algorithms and the TFST strategy over known state-of-the-art algorithms.","1558-0008","","10.1109/JSAC.2022.3143255","Natural Science Foundation of China (NSFC)(grant numbers:62088101,62071044,61827901); UNSW Digital Grid Futures Institute, UNSW, Sydney, under a Cross-Disciplinary Fund Scheme; Australian Research Council’s Discovery Project(grant numbers:DP210102169); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9726781","Internet-of-Things (IoT);massive machine-type communications;massive IoT access;unmanned aerial vehicle (UAV);non-coherent index modulation;compressed sensing","Performance evaluation;Modulation;Media;MIMO communication;Autonomous aerial vehicles;OFDM;Indexes","","10","","46","IEEE","3 Mar 2022","","","IEEE","IEEE Journals"
"Anomaly Detection in IoT Sensor Networks using Machine Learning","K. Mithran; C. Gopi","Department of Electronics and Communication Engineering, Government Engineering College, Thrissur, Kerala, India; Department of Electronics and Communication Engineering, Government Engineering College, Thrissur, Kerala, India","2022 International Conference on Computing, Communication, Security and Intelligent Systems (IC3SIS)","15 Sep 2022","2022","","","1","7","Anomaly Detection is a promising new approach for quality control in wireless networks and telecommunication networks. New modern network architecture enables intensive computing and communication at the edge of the network. It can thus support large scale IoT applications. The proper and timely detection of attacks in the Internet of Things (IoT) infrastructure is very important. With the rise in IoT technologies in various application areas these days, the attacks and threats are also on the verge of exploiting this. Denial of Service, Data Type Probing, Malicious Control, Malicious Operation, Scanning, Spying and Wrong Setup are the different attacks and anomalies which can cause a communication system failure. In the past decades an enormous rise in the internet applications was seen, which has led to concreting the need of security of the information networks by many folds. As the network operations continuously changes in different time frames, an anomaly detection system should be capable of adapting dynamically to the situations. The objective of this paper is to identify various attacks on IoT sensor networks and the development of a generalized anomaly detection model using machine learning techniques to check if an IoT sensor network is anomalous or not. Kaggle and NSL-KDD datasets are used for this study. Model is trained based on the Levenberg – Marquardt optimization using TRAINLM training function and LEARNGDM adaptation learning function. High performance was exhibited by the model. Menu based environment is also created in Jupyter in this paper.","","978-1-6654-6883-1","10.1109/IC3SIS54991.2022.9885575","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9885575","Internet of Things;Anomaly detection;Kaggle dataset","Training;Adaptation models;Wireless sensor networks;Wireless networks;Machine learning;Quality control;Internet of Things","","","","13","IEEE","15 Sep 2022","","","IEEE","IEEE Conferences"
"Backscatter Wireless Communications and Sensing in Green Internet of Things","U. S. Toro; K. Wu; V. C. M. Leung","College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China","IEEE Transactions on Green Communications and Networking","16 Feb 2022","2022","6","1","37","55","Internet of Things (IoT) is a key technology for enabling ubiquitous applications that interconnect with cyber-physical systems in various environments. However, its large scale adoption is strongly impeded by the limited energy available for most IoT devices that are battery-powered, and further challenged by the growing demands to pack increasing functionalities into IoT devices while shrinking their sizes. To address these problems, researchers have developed techniques for energy harvesting, wireless power transfer, and minimizing power consumption in the sensing, communication and computation components of IoT nodes, as found in many surveys. In contrast, this paper surveys Backscatter Communication (BackCom), a recently emerged technique that enables green IoT through joint wireless communication and sensing and potentially allows IoT devices to operate without batteries. The operating principle of BackCom-based green IoT, its architecture and evolution are presented. Also state-of-the-art applications such as healthcare, agriculture, human activity recognition, transportation and mobile IoT are reviewed together with the operational and security challenges faced by these applications and potential solution techniques to address these challenges while ensuring a high energy efficiency. Lastly, some future applications of BackCom-based green IoT are discussed.","2473-2400","","10.1109/TGCN.2021.3095792","China NSFC(grant numbers:U2001207,61872248); Guangdong NSF(grant numbers:2017A030312008); Shenzhen Science and Technology Foundation(grant numbers:ZDSYS20190902092853047); Project of DEGP(grant numbers:2019KCXTD005,R2020A045); Guangdong “Pearl River Talent Recruitment Program”(grant numbers:2019ZT08X603); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9482542","Green Internet of Things;wireless communications;sensing;backscatter communications","Green products;Sensors;Backscatter;Internet of Things;Receivers;Radiofrequency identification;Energy efficiency","","34","","156","IEEE","13 Jul 2021","","","IEEE","IEEE Journals"
"Explainable Intrusion Detection for Cyber Defences in the Internet of Things: Opportunities and Solutions","N. Moustafa; N. Koroniotis; M. Keshk; A. Y. Zomaya; Z. Tari","University of New South Wales at Canberra, Canberra, ACT, Australia; University of New South Wales at Canberra, Canberra, ACT, Australia; University of New South Wales at Canberra, Canberra, ACT, Australia; Centre for Distributed and High Performance Computing, School of Information Technologies, The University of Sydney, Sydney, NSW, Australia; Centre of Cyber Security Research and Innovation, School of Computing Technologies, RMIT University, Melbourne, VIC, Australia","IEEE Communications Surveys & Tutorials","22 Aug 2023","2023","25","3","1775","1807","The field of Explainable Artificial Intelligence (XAI) has garnered considerable research attention in recent years, aiming to provide interpretability and confidence to the inner workings of state-of-the-art deep learning models. However, XAI-enhanced cybersecurity measures in the Internet of Things (IoT) and its sub-domains, require further investigation to provide effective discovery of attack surfaces, their corresponding vectors, and interpretable justification of model outputs. Cyber defence involves operations conducted in the cybersecurity field supporting mission objectives to identify and prevent cyberattacks using various tools and techniques, including intrusion detection systems (IDS), threat intelligence and hunting, and intrusion prevention. In cyber defence, especially anomaly-based IDS, the emerging applications of deep learning models require the interpretation of the models’ architecture and the explanation of models’ prediction to examine how cyberattacks would occur. This paper presents a comprehensive review of XAI techniques for anomaly-based intrusion detection in IoT networks. Firstly, we review IDSs focusing on anomaly-based detection techniques in IoT and how XAI models can augment them to provide trust and confidence in their detections. Secondly, we review AI models, including machine learning (ML) and deep learning (DL), for anomaly detection applications and IoT ecosystems. Moreover, we discuss DL’s ability to effectively learn from large-scale IoT datasets, accomplishing high performances in discovering and interpreting security events. Thirdly, we demonstrate recent research on the intersection of XAI, anomaly-based IDS and IoT. Finally, we discuss the current challenges and solutions of XAI for security applications in the cyber defence perspective of IoT networks, revealing future research directions. By analysing our findings, new cybersecurity applications that require XAI models emerge, assisting decision-makers in understanding and explaining security events in compromised IoT networks.","1553-877X","","10.1109/COMST.2023.3280465","Australian Research Council’s Discovery Early Career Researcher Award (DECRA)(grant numbers:DE230100116); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10136827","Cyber defence;intrusion detection system (IDS);artificial intelligence (AI);explainable AI (XAI);Internet of Things (IoT)","Internet of Things;Computer crime;Artificial intelligence;Soft sensors;Biological system modeling;Surveys;Computer security","","11","","215","IEEE","26 May 2023","","","IEEE","IEEE Journals"
"A Self-Adaptive Load Balancing Approach for Software-Defined Networks in IoT","Z. Min; H. Sun; S. Bao; A. S. Gokhale; S. S. Gokhale","Dept. of EECS, Vanderbilt University, Nashville, TN, USA; Dept. of EECS, Vanderbilt University, Nashville, TN, USA; Dept. of EECS, Vanderbilt University, Nashville, TN, USA; Dept. of EECS, Vanderbilt University, Nashville, TN, USA; Dept. of CSE, University of Connecticut, Storrs, CT, USA","2021 IEEE International Conference on Autonomic Computing and Self-Organizing Systems (ACSOS)","5 Jan 2022","2021","","","11","20","The Internet of Things (IoT) is gaining popularity as it offers to connect billions of devices and exchange data over the internet. However, the large-scale and heterogeneous IoT network environment brings serious challenges to assuring the quality of service of IoT-based services. In this context, Software-Defined Networking (SDN) shows promise in improving the performance of IoT services by decoupling the control plane from the data plane. However, existing SDN-based distributed architectures are able to address the scalability and management issues in static IoT scenarios only. In this paper, we utilize multiple M/M/1 queues to model and optimize the service-level and system-level objectives in dynamic IoT scenarios, where the network switches and/or their request rates could change dynamically over time. We propose several heuristic-based solutions including a genetic algorithm, a simulated annealing algorithm and a modified greedy algorithm with the goal of minimizing the queuing and processing times of the requests from switches at the controllers and balancing the controller loads while also incorporating the switch migration costs. Empirical studies using Mininet-based simulations show that our algorithms offer effective self-adaptation and self-healing in dynamic network conditions.","","978-1-6654-1261-2","10.1109/ACSOS52086.2021.00034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9659533","Switch Migration Problem (SMP);Software-Defined Networking (SDN);Internet of Things (IoT);Queuing Model;Load Balancing;Resource management","Performance evaluation;Heuristic algorithms;Computational modeling;Scalability;Process control;Simulated annealing;Quality of service","","4","","40","IEEE","5 Jan 2022","","","IEEE","IEEE Conferences"
"Sharded Blockchain for Collaborative Computing in the Internet of Things: Combined of Dynamic Clustering and Deep Reinforcement Learning Approach","Z. Yang; R. Yang; F. R. Yu; M. Li; Y. Zhang; Y. Teng","Faculty of Information Technology, Beijing University of Technology, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China; Department of Systems and Computer Engineering, Carleton University, Ottawa, ON, Canada; Faculty of Information Technology, Beijing University of Technology, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China; Beijing Key Laboratory of Space-Ground Interconnection and Convergence, School of Electronic Engineering, Beijing University of Posts and Telecommunications, Beijing, China","IEEE Internet of Things Journal","24 Aug 2022","2022","9","17","16494","16509","Immutability, decentralization, and linear promoted scalability make the sharded blockchain a promising solution, which can effectively address the trust issue in the large-scale Internet of Things (IoT). However, currently, the throughput of sharded blockchains is still limited when it comes to high proportion of cross-shard transactions (CSTs). On the other hand, the assemblage characteristic of the collaborative computing in IoT has not been received attention. Therefore, in this article, we present a clustering-based sharded blockchain strategy for collaborative computing in the IoT, where the sharding of the blockchain system is implemented in two steps: K-means-clustering-based user grouping and the assignment of consensus nodes. In this framework, how to reasonably group the IoT users while simultaneously guaranteeing the system performance is the key point. Specifically, we describe the data transactions among IoT devices by data transaction flow graph (DTFG) based on a dynamic stochastic block model. Then, formed as a Markov decision process (MDP), the optimization of the cluster number (shard number) and the adjustment of consensus parameters are jointly trained by deep reinforcement learning (DRL). Simulation results show that the proposed scheme improves the scalability of the sharded blockchain in the IoT application.","2327-4662","","10.1109/JIOT.2022.3152188","National Natural Science Foundation of China(grant numbers:62171062,61901011); Foundation of Beijing Municipal Commission of Education(grant numbers:KM202010005017,KM202110005021); Beijing Natural Science Foundation(grant numbers:L211002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9716041","Collaborative computing;deep reinforcement learning (DRL);dynamic graph analysis;Internet of Things (IoT);K-means clustering;sharded blockchain","Blockchains;Internet of Things;Collaboration;Throughput;Security;Task analysis;Reinforcement learning","","21","","43","IEEE","17 Feb 2022","","","IEEE","IEEE Journals"
"Secure and Cost Effective IoT Authentication and Data Storage Framework using Blockchain NFT","N. E. Majd; M. Sharko","Department of Computer Science and Information Systems, California State University San Marcos, United States; Department of Computer Science and Information Systems, California State University San Marcos, United States","2023 32nd International Conference on Computer Communications and Networks (ICCCN)","1 Sep 2023","2023","","","1","7","The scale and scope of using IoT has had a rapid growth over the past few years. This growth has raised security and cost challenges of using IoT smart devices in large scale. In this research, we propose a comprehensive framework that addresses these challenges using cryptographic systems and blockchain NFTs. We analyze the credibility and scalability of our framework. In our proposed framework, we securely authenticate IoT devices and bind them to blockchain Non-Fungible Tokens (NFTs). To uniquely bind each IoT device to an NFT, we use the device's physical unclonable function (PUF). The link between the NFT and the device is difficult to break and can be traced anytime. Our framework also authenticates the device's acquired data using the device's PUF and securely stores the authenticated data on the blockchain. We use an approach that significantly reduces the blockchain costs and analyze it in large scale. Our analysis show that our framework is a secure and cost-effective solution for large-scale IoT authentication and data storage.","2637-9430","979-8-3503-3618-4","10.1109/ICCCN58024.2023.10230124","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10230124","IoT Security;Blockchain;Secure Authentication;Secure Data Storage;Scalable IoT Infrastructure","Costs;Scalability;Smart contracts;Physical unclonable function;Decentralized applications;Registers;Internet of Things","","","","13","IEEE","1 Sep 2023","","","IEEE","IEEE Conferences"
"Optimizing Logging and Monitoring in Heterogeneous Cloud Environments for IoT and Edge Applications","C. Kim; S. Kim","Department of Computer Science and Engineering, Seoul National University of Science and Technology, Seoul, Republic of Korea; Department of Computer Science and Engineering, Seoul National University of Science and Technology, Seoul, Republic of Korea","IEEE Internet of Things Journal","11 Dec 2023","2023","10","24","22611","22622","As data is becoming more and more important, Internet of Things (IoT) devices are widely used to collect information and process data from various industries, such as finance, autonomous driving, and smart factories. To address the limited computational power of IoT devices in processing real-time data, both edge computing, which utilizes nearby computers with greater computation capabilities, and cloud computing with even more processing power, are widely adopted solutions. As these systems have heterogeneous software and hardware configurations, it can be challenging to understand the behavior of the application from the perspective of different resources. In this article, we propose an efficient logging and monitoring system in large-scale, heterogeneous environments for IoT and edge applications. To do this, our scheme first collects system resource usage data from each compute node using the operating system’s native system analysis tool. Then, it consolidates the system resource usage information from multiple nodes into an integrated database which creates a comprehensive view of the system. Finally, our scheme provides global system resource information in terms of specific jobs and nodes, providing a comprehensive understanding of complex heterogeneous hardware/software stacks. Our evaluation, using IoT and edge workloads in heterogeneous systems, demonstrates the efficiency of logging and monitoring schemes. The average network usage for Windows and Linux is 0.12 and 1.29 kB/s, respectively, resulting in minimal network overhead. In addition, the proposed scheme shows negligible overhead in terms of both runtime (up to 0.73%) and storage (0.0474%).","2327-4662","","10.1109/JIOT.2023.3304373","Seoul National University of Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10214550","Cloud computing;Internet of Things (IoT);resource management","Internet of Things;Monitoring;Cloud computing;Hardware;Software engineering;Real-time systems;Interference;Resource management;Edge computing;Heterogeneous networks","","1","","52","IEEE","11 Aug 2023","","","IEEE","IEEE Journals"
"LEMDA: A Novel Feature Engineering Method for Intrusion Detection in IoT Systems","A. Ghubaish; Z. Yang; A. Erbad; R. Jain","Washington University in Saint Louis, St. Louis, MO, USA; Washington University in Saint Louis, St. Louis, MO, USA; College of Science and Engineering, Hamad Bin Khalifa University, Qatar; Washington University in Saint Louis, St. Louis, MO, USA","IEEE Internet of Things Journal","","2023","PP","99","1","1","Intrusion detection systems (IDS) for the Internet of Things (IoT) systems can use AI-based models to ensure secure communications. IoT systems tend to have many connected devices producing massive amounts of data with high dimensionality, which requires complex models. Complex models have notorious problems such as overfitting, low interpretability, and high computational complexity. Adding model complexity penalty (i.e., regularization) can ease overfitting, but it barely helps interpretability and computational efficiency. Feature engineering can solve these issues; hence, it has become critical for IDS in large-scale IoT systems to reduce the size and dimensionality of data, resulting in less complex models with excellent performance, smaller data storage, and fast detection. This paper proposes a new feature engineering method called LEMDA (Light feature Engineering based on the Mean Decrease in Accuracy). LEMDA applies exponential decay and an optional sensitivity factor to select and create the most informative features. The proposed method has been evaluated and compared to other feature engineering methods using three IoT datasets and four AI/ML models. The results show that LEMDA improves the F1 score performance of all the IDS models by an average of 34% and reduces the average training and detection times in most cases.","2327-4662","","10.1109/JIOT.2023.3328795","NSF(grant numbers:CNS-1718929); Prince Sattam bin Abdulaziz University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10335901","Feature engineering;Feature reduction;Feature selection;Internet of Things;IoT;Intrusion Detection Systems;IDS;Mean Decrease in Accuracy;MDA;Permutation feature importance","Feature extraction;Internet of Things;Computational modeling;Data models;Training;Impurities;Electronic mail","","","","","IEEE","30 Nov 2023","","","IEEE","IEEE Early Access Articles"
"ADIperf: A Framework for Application-driven IoT Network Performance Evaluation","S. Si-Mohammed; T. Begin; I. G. Lassous; P. Vicat-Blanc","ENSL, UCBL, CNRS, Inria, LIP, Univ Lyon, France; ENSL, UCBL, CNRS, Inria, LIP, Univ Lyon, France; ENSL, UCBL, CNRS, Inria, LIP, Univ Lyon, France; Stackeo, Lyon, France","2022 International Conference on Computer Communications and Networks (ICCCN)","5 Sep 2022","2022","","","1","8","The Internet of Things (IoT) is the convergence of the physical and the digital worlds. It enables a large spectrum of applications such as smart building, smart tracking, smart metering, predictive maintenance, remote control, augmented reality or video surveillance. The diversity of these applications has caused a profusion of the IoT communication technologies offerings for exchanging data between IoT devices and applications. The latter technologies come with different features in terms of range, throughput, latency, scalability, energy, etc. Each technology can fit several use cases and a use case can leverage several technologies. It is complex, yet critical, for an IoT architect to evaluate the adequacy and the limits of a network technology for a targeted application and to continuously optimize its configuration as the deployment evolves. This paper introduces ADIperf, a framework to simplify and systematize the evaluation of the performance of an IoT communication technology for a given IoT use case and context. The ADIperf approach pays special attention to the energy efficiency as well as to the ability of an IoT communication technology to properly scale up with the number of end-devices, with the ultimate goal of giving guidelines and tools for IoT architects to select the technology and configure the network that fulfill their application's needs over time.","2637-9430","978-1-6654-9726-8","10.1109/ICCCN54977.2022.9868888","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9868888","Internet of Things;Applications;Framework;Performance Evaluation;Simulation","Performance evaluation;Smart buildings;Scalability;Video surveillance;Throughput;Communications technology;Energy efficiency","","2","","28","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Permissioned Blockchain and Deep Reinforcement Learning Enabled Security and Energy Efficient Healthcare Internet of Things","L. Liu; Z. Li","School of Political Science and Public Administration, East China University of Political Science and Law, Shanghai, China; School of International and Public Affairs, Shanghai Jiao Tong University, Shanghai, China","IEEE Access","24 May 2022","2022","10","","53640","53651","Recently, the Healthcare Internet of Things (H-IoT) has been widely applied to alleviate the global challenge of the coronavirus disease 2019 (COVID-19) pandemic. However, security and limited energy capacity issues remain the two main factors that prevent the large-scale application of the H-IoT. Therefore, a permissioned blockchain and deep reinforcement learning (DRL)-empowered H-IoT system is presented in this research to address these two issues. The proposed H-IoT system can provide real-time security and energy-efficient healthcare services to control the propagation of the COVID-19 pandemic. To address the security issue, a permissioned blockchain method is adopted to guarantee the security of the proposed H-IoT system. As for handling the limited energy constraint, we employ the mobile edge computing (MEC) method to offload the computing tasks to alleviate the computational burden and energy consumption of the proposed H-IoT system. We also adopt an energy harvesting method to improve performance. In addition, a DRL method is employed to jointly optimize both the security and energy efficiency performance of the proposed system. The simulation results demonstrate that the proposed solution can balance the requirements of security and energy efficiency issues and hence can better respond to the COVID-19 pandemic.","2169-3536","","10.1109/ACCESS.2022.3176444","National Natural Science Foundation of China(grant numbers:71974057,72071031); Ministry of Education through the Humanities and Social Science Project(grant numbers:19YJC630104); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9777961","Blockchain;deep reinforcement learning;mobile edge computing;energy harvesting;healthcare Internet of Things;COVID-19","COVID-19;Blockchains;Security;Pandemics;Medical services;Internet of Things;Industries","","14","","56","CCBY","18 May 2022","","","IEEE","IEEE Journals"
"Botnet Detection Using Label Propagation and Batch K-means Clustering for Securing IoT Networks","M. Almiani; A. AbuGhazleh; A. Mughaid; Y. Jararweh","Gulf University of Science and Technology, Kuwait; Jordan University of Science and Technology, Irbid, Jordan; The Hashemite University, Zarqa, Jordan; Jordan University of Science and Technology, Irbid, Jordan","2023 Eighth International Conference on Fog and Mobile Edge Computing (FMEC)","8 Nov 2023","2023","","","167","174","A profound devastation is experienced when privacy is violated, and personal information is compromised or lost. Now, consider the situation where all these penetrations occur simultaneously and remain oblivious until a considerable time has passed. This scenario described the Internet of Things (IoT) network when attacked by a Botnet. Existing machine-learning Botnet detection methods tend to increase the number of incorporated features along with increasing the complexity of the detection algorithms, which can impede timely Botnet detection and hinder optimal defense, especially in large-scale environments. This work introduces an intelligent Botnet detection system constructed based on batch k-means and label propagation algorithms. Despite its simplicity, the system exhibits noticeable efficacy in identifying Botnet traffic. Moreover, the system is highly able to learn the underlying behavioral patterns of Botnet flows despite being constructed with a narrow zone of flow-based features solely relying on packet-length distribution. The proposed system can serve the dual purpose of clustering and classifying Botnet traffic where it is designed to detect HTTP-based Botnet attacks belonging specifically to the Virut Botnet family. Using the ISCX-Botnet dataset, the system has achieved accuracy and F1-score of 98.25% and 93.23% respectively. These findings are on par with (or superior) to those of state-of-the-art complex techniques, demonstrating the proposed system's capability to be deployed in timely, large-scale botnet defense architectures.","","979-8-3503-1697-1","10.1109/FMEC59375.2023.10305882","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10305882","Botnet;IoT network;Intrusion detection;Label propagation;k-means clustering;Elbow point;Davies-Bouldin index","Training;Privacy;Multi-access edge computing;Botnet;Training data;Statistical distributions;Computer architecture","","","","19","IEEE","8 Nov 2023","","","IEEE","IEEE Conferences"
"Design and Implementation of IoT DDoS Attacks Detection System based on Machine Learning","Y. -W. Chen; J. -P. Sheu; Y. -C. Kuo; N. Van Cuong","Institute of Communication Engineering, National Tsing Hua University, Hsinchu, Taiwan; Institute of Communication Engineering, National Tsing Hua University, Hsinchu, Taiwan; Institute of Communication Engineering, National Tsing Hua University, Hsinchu, Taiwan; Institute of Communication Engineering, National Tsing Hua University, Hsinchu, Taiwan","2020 European Conference on Networks and Communications (EuCNC)","21 Sep 2020","2020","","","122","127","DDoS attacks often happen in cloud servers and cause a devastating problem. However, an increasing number of Internet of Things (IoT) devices makes us not ignore the influence of large-scale DDoS attacks from IoT devices. In this paper, we propose a machine learning-based on a multi-layer IoT DDoS attack detection system, including IoT devices, IoT gateways, SDN switches, and cloud servers. Firstly, we build eight smart poles with various sensors on our campus and collect sensor data as our datasets through wireless networks or wired networks. Next, we extract the features based on DDoS attack types. The feature selection can result in high accuracy DDoS attack detection in the real IoT environment. The experimental results show that our multi-layer DDoS detection system can accurately detect DDoS attacks. And the SDN controller can block venomous devices effectively according to blacklists from the results of our IoT DDoS attacks detection system.","2575-4912","978-1-7281-4355-2","10.1109/EuCNC48522.2020.9200909","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9200909","Distributed Denial of Service;Internet of Things;Machine Learning;Software Defined Networking","Computer crime;Sensors;Feature extraction;Logic gates;Authentication;Internet of Things;Machine learning","","35","","18","IEEE","21 Sep 2020","","","IEEE","IEEE Conferences"
"IQ-Impaired Wireless-Powered Modify-and-Forward Relaying for IoT Networks: An In-Depth Physical-Layer Security Analysis","X. Li; H. Qi; D. -T. Do; Z. Hui; Y. Ding; M. Zhu; H. Peng","School of Physics and Electronic Information Engineering, Henan Polytechnic University, Jiaozuo, China; School of Physics and Electronic Information Engineering, Henan Polytechnic University, Jiaozuo, China; School of Engineering, University of Mount Union, Alliance, OH, USA; Institute of Mining Engineering, Guizhou Institute of Technology, Guiyang, China; School of Engineering and Physical Sciences, Heriot-Watt University, Edinburgh, U.K; School of Computer Science and Technology, Henan Polytechnic University, Jiaozuo, China; School of Physics and Electronic Information Engineering, Henan Polytechnic University, Jiaozuo, China","IEEE Internet of Things Journal","23 Aug 2023","2023","10","17","14912","14924","With the large-scale commercialization of 5G networks, the era of Internet of Things (IoT), which is oriented toward the Internet of Everything (IoE), is coming. Under the circumstance, reliable and secure communication are the great challenges for future wireless network because of the broadcasting characteristics of electromagnetic wave. Physical-layer security (PLS) is an effective way to ensure secure communication by exploiting random nature of fading channels. Motivated by this, we investigate PLS of the wireless-powered cooperative multirelaying for IoT networks in the presence of eavesdropper with the estimation errors of channel (EEC) and imbalance between in-phase and quadrature-phase (IIQ). Specifically, the relays can be charged by the source with the aid of energy harvesters, and a novel more secure modify-and-forward (MF) relay protocol is proposed. For further improving energy efficiency and reducing extra interference, the  $K$ th superior relay selection scheme is proposed since some best ones are not available due to some scheduling or failure. Based on the system under study, we derive the analytical expressions for the outage probability (OP), intercept probability (IP), and secrecy OP (SOP) to evaluate the reliable and secure performance of this consideration system. Particularly, we then analyze the asymptotic behaviors of the OP, IP, and SOP, respectively. Through computer simulation, we show that: 1) with EEC, the error floors of the OP and SOP are of presence; 2) multiple relays lead to better OP and SOP performance; and 3) IIQ improves the security and is detrimental to the system reliability.","2327-4662","","10.1109/JIOT.2023.3249964","National Natural Science Foundation of China(grant numbers:52164007); Key Project of Guizhou Science and Technology Support Program; Guizhou Key Science and Support [2021]-001; Open Foundation of Key Laboratory of Cognitive Radio and Information Processing, Ministry of Education (Guilin University of Electronic Technology)(grant numbers:CRKL220203); Key Scientific Research Projects of Higher Education Institutions in Henan Province(grant numbers:23B510001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10054398","Channel estimation errors;in-phase/quadrature-phase imbalance;modify-and-forward (MF);power splitting;the Kth superior relay selection","Relays;Security;Protocols;IP networks;Cooperative systems;Power system reliability;NOMA","","2","","47","IEEE","27 Feb 2023","","","IEEE","IEEE Journals"
"An 111pW Voltage Reference with a Diode-Leakage-Decoupling Replica for High-Temperature Miniature IoT Systems","Y. Li; I. Lee","University of Pittsburgh, Pittsburgh, PA, USA; University of Pittsburgh, Pittsburgh, PA, USA","2021 IEEE Custom Integrated Circuits Conference (CICC)","17 May 2021","2021","","","1","2","A miniature Internet-of-Thing (IoT) system has been an attractive solution for a variety of applications such as biomedical, infrastructure, and energy resource monitoring. The small wireless device enables to continuously monitor important parameters in a limited space with minimally disturbing characteristics of a target object. They demonstrate a potential use of the miniature IoT system in high-temperature environment including automotive, aerospace, and geothermal. However, to implement a robust small system for the high-temperature application, there are two significant challenges in designing its necessary building blocks and their required circuits. First, the small system form factor limits physical size of a battery and thus battery capacity. Thus, circuits of the system should consume low power for reasonable system lifetime. A 3.8mm2 thin film battery only has a battery capacity of 5{mu}Ahr. An advanced millimeter-scale system using this type of batteries consumes only 8nW in standby mode. Second, circuits in the system should operate over a wide range of temperature including a typical minimum outdoor condition (-20°C [1]) and the maximum target temperature (e.g., >125°C).","2152-3630","978-1-7281-7581-2","10.1109/CICC51472.2021.9431577","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9431577","","Wireless communication;Temperature sensors;Temperature measurement;Temperature distribution;Energy resources;Conferences;Batteries","","4","","6","IEEE","17 May 2021","","","IEEE","IEEE Conferences"
"Communication-Based Train Control Simulator to Optimize Train Headway","F. S. Suwita; R. Rin Nurmalasari; R. J. Hakim","Department of Information System, Universitas Komputer Indonesia, Bandung, Indonesia; Department of Electrical Engineering, UIN Sunan Gunung Djati Bandung, Bandung, Indonesia; Department of Electrical Engineering, UIN Sunan Gunung Djati Bandung, Bandung, Indonesia","2023 International Conference on Informatics Engineering, Science & Technology (INCITEST)","24 Jan 2024","2023","","","1","7","The development of public transportation, especially for large urban areas, is mandatory, where the need for time efficiency and integrated mass transportation to provide optimal services to customers. Trains in Indonesia generally use traditional signaling systems while currently, some countries have developed the use of modern communication-based train control (CBTC) Internet of Things (IoT) technology. The use of CBTC can be a solution to optimize train headway in Indonesia with the concept of communication carried out between trains and control stations to determine the position of the train so that the train can determine the optimal speed to reach the destination and create comfort as well as accidental safety. This study analyzes the use of the concept of communication-based train control to optimize the railroad track. The research was conducted by simulating using a miniature model train scale HO or 1:87. This research will be elaborated on the literature review, design and implementation, testing and analysis, conclusions from the train system simulator specifically the results of the use of MQTT in the railroad scheduling subsystem. The results of the study indicate that in the simulation the train headway had an average distance of 12.83cm.","","979-8-3503-1786-2","10.1109/INCITEST59455.2023.10395923","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10395923","CBTC;MQTT;TRAIN;HEADWAY","Communication system signaling;Bibliographies;Urban areas;Safety;Internet of Things;Public transportation;Testing","","","","11","IEEE","24 Jan 2024","","","IEEE","IEEE Conferences"
"Enhancing Real-Time License Plate Recognition Through Edge-Cloud Computing","C. F. G. Panganiban; C. F. L. Sandoval; C. A. M. Festin; W. M. Tan","Department of Computer Science, University of the Philippines Diliman, Quezon City, Philippines; Department of Computer Science, University of the Philippines Diliman, Quezon City, Philippines; Department of Computer Science, University of the Philippines Diliman, Quezon City, Philippines; Department of Computer Science, University of the Philippines Diliman, Quezon City, Philippines","TENCON 2022 - 2022 IEEE Region 10 Conference (TENCON)","20 Dec 2022","2022","","","1","6","Video makes up a significant portion of data gathered from the edge [1]. A notable source of video data is the dashboard camera, and modern models can now be connected to the Internet of Things (IoT). With this video data, automatic license plate recognition (ALPR) algorithms can be performed to locate vehicles, which can be used in investigations such as child abductions and vehicle theft. However, this volume of video data only increases with the rising number of connected devices, putting a large strain on the network. Edge computing can help alleviate this strain on the bandwidth. We propose an edge computing-based ALPR system that locates a target vehicle given a video feed and GPS data. Specifically, we implement this system on a cloud server and a Raspberry Pi 4 as its edge. Comparisons between edge-heavy, cloud-heavy, and hybridized setups are done to evaluate its performance. We also evaluated their scalability and their performance in low-bandwidth conditions. Experimental findings show that edge-heavy and hybridized setups can scale up easily and can perform effectively in low bandwidth conditions (10 Kbps). Meanwhile, the cloud-heavy setup performs the best with a single edge, but performance suffers in low-bandwidth conditions and has poor scalability.","2159-3450","978-1-6654-5095-9","10.1109/TENCON55691.2022.9978152","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9978152","Automatic license plate recognition (ALPR);edge computing;internet of things (IoT)","Cloud computing;Image edge detection;Scalability;Pipelines;Bandwidth;Hardware;Task analysis","","","","15","IEEE","20 Dec 2022","","","IEEE","IEEE Conferences"
"Research on Client Side Terminal Security Detection Technology for Smart Grid","Y. Liu; H. Wang; X. Fang; J. Wang","Intelligent Power Sub Center XJ Group Corporation, Xuchang City, China; Metrology Center, State Grid Shanxi Marketing Service Center, Taiyuan City, China; Intelligent Power Sub Center XJ Group Corporation, Xuchang City, China; Intelligent Power Sub Center XJ Group Corporation, Xuchang City, China","2021 International Conference on Wireless Communications and Smart Grid (ICWCSG)","26 Nov 2021","2021","","","468","472","The customer side terminal network in the power environment has the characteristics of high interconnection, huge network scale and higher risk than the traditional Internet of things (IOT). A complete client side terminal network system has a large number of terminals. Once a terminal is broken, the damage may spread through the terminal network at a high speed, which will have a huge impact on the whole system. This paper analyzes the current situation of client terminal and terminal network security, and analyzes its security threats. First of all, the key data indicators of online security monitoring of client side terminal equipment are analyzed and studied, and the standardized data acquisition technology of data indicators is studied. Then, based on the network security monitoring indicators, using the standardized data collected by the client side terminal equipment, the illegal attack detection technology is studied to realize the fast and accurate judgment of attack mode. Finally, the network attack detection is carried out based on neural network, and the experimental results are analyzed.","","978-1-6654-2598-8","10.1109/ICWCSG53609.2021.00099","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9616560","NQI;customer side terminal;security threats;attack detection","Wireless communication;Correlation;Neural networks;Data acquisition;Network security;Smart grids;Internet of Things","","","","16","IEEE","26 Nov 2021","","","IEEE","IEEE Conferences"
"Multi-Topology Based QoS-Differentiation in RPL for Internet of Things Applications","K. S. Bhandari; I. -H. Ra; G. Cho","Division of Computer Science and Engineering, Jeonbuk National University, Jeonju, South Korea; School of Computer, Information and Communication Engineering, Kunsan National University, Gunsan, South Korea; Division of Computer Science and Engineering, Jeonbuk National University, Jeonju, South Korea","IEEE Access","2 Jun 2020","2020","8","","96686","96705","The rapid development of the Internet of Things (IoT) concept has promoted the presence of routing protocol for low power and lossy network (RPL). Unlike traditional applications, many applications envisioned for IoT networks may have different and sometimes conflicting requirements. In this context, the underlying routing protocol requires to provide quality of service (QoS) for multipurpose IoT and is inevitable. However, the routing approach in RPL is not efficient because default objective functions (OFs) rely on a single metric, which can result in a tradeoff in routing performance, particularly for multipurpose IoT that enchant different QoS requirements in the same network. Although RPL specification allows the use of multiple metrics for parent selection, however, no specific guideline is defined for metric combinations. Besides, many studies have revealed that RPL encounters severe problems in large scale networks as it was mainly designed for low data traffic network. To address these problems, in this paper, we primarily focus on QoS differentiation by exploiting the multi-topology routing feature of the RPL standard. For this, we propose different OFs, which ensures the QoS differentiation at the network level by splitting the physical network virtually into multiple RPL Instances. Each Instance can incorporate different traffic by associating with differing OFs, and routed it through the corresponding virtual network topology. We also present a new parent selection framework based on a multi-attribute decision-making approach that addresses the single routing metric problem in RPL. The extensive simulation results verify that our multi-topology routing approach can support the QoS provisioning and is suitable for large scale networks as compared with standard RPL.","2169-3536","","10.1109/ACCESS.2020.2995794","Institute for Information and Communication Technology Promotion (IITP); Korea Government Ministry of Science and ICT (MSIT)(grant numbers:2018-0-00508); Research Funds of Jeonbuk National University, in 2020; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9097219","Internet of Things;quality of service;low power and lossy networks;routing metrics;objective function;6LoWPAN;border router","Routing;Quality of service;Measurement;Network topology;Internet of Things;Routing protocols;Topology","","24","","77","CCBY","20 May 2020","","","IEEE","IEEE Journals"
"Fed-DDM: A Federated Ledgers based Framework for Hierarchical Decentralized Data Marketplaces","R. Xu; Y. Chen","Department of Electrical and Computer Engineering, Binghamton University, Binghamton, NY, USA; Department of Electrical and Computer Engineering, Binghamton University, Binghamton, NY, USA","2021 International Conference on Computer Communications and Networks (ICCCN)","31 Aug 2021","2021","","","1","8","Data marketplaces (DMs) promote the benefits of the Internet of Things (IoT) in smart cities. To facilitate the easy exchanges of real-time IoT data streams between device owners and third-party applications, it is required to provide scalable, interoperable, and secured services for large numbers of distributed IoT devices operated by different application vendors. Thanks to decentralization, immutability, and auditability, Blockchain is promising to enable a tamper-proof and trust-free framework to enhance performance and security issues in centralized DMs. However, directly integrating blockchains into large-scale IoT-based DMs still faces many limitations, such as high resource and energy demands, low transaction throughput, poor scalability, and challenges in privacy preservation. This paper introduces a novel Federated Ledgers-based Framework for Hierarchical Decentralized Data Marketplaces (Fed-DDM). In Fed-DDM, participants are divided into multiple permissioned domains given their registrations. Each domain leverages an efficient Byzantine Fault Tolerance (BFT) consensus protocol to commit transactions of a domain on a private intra-ledger. A public inter-ledger network adopts a scalable Proof-of-Work (PoW) consensus protocol to federate multiple private intra-ledger networks. We design a smart contract-enabled inter-ledger protocol to guarantee the security of the cross-domain operations on a public federated ledger without exposing sensitive privacy information from private ledgers. A proof-of-concept prototype is implemented, and the experimental results verify the feasibility of the proposed Fed-DDM solution with performance and security guarantees.","2637-9430","978-1-6654-1278-0","10.1109/ICCCN52240.2021.9522359","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9522359","IoT-based Data Marketplaces;Federated Ledger;Blockchain;Smart Contract;Security;Privacy","Privacy;Smart cities;Scalability;Prototypes;Throughput;Stability analysis;Real-time systems","","4","","32","IEEE","31 Aug 2021","","","IEEE","IEEE Conferences"
"Internet Financial Fraud Detection Based on a Distributed Big Data Approach With Node2vec","H. Zhou; G. Sun; S. Fu; L. Wang; J. Hu; Y. Gao","Department of Information Technology and Management, Hunan University of Finance and Economics, Changsha, China; Department of Information Technology and Management, Hunan University of Finance and Economics, Changsha, China; Department of Information Technology and Management, Hunan University of Finance and Economics, Changsha, China; Department of Information Technology and Management, Hunan University of Finance and Economics, Changsha, China; Department of Information Technology and Management, Hunan University of Finance and Economics, Changsha, China; Department of Information Technology and Management, Hunan University of Finance and Economics, Changsha, China","IEEE Access","19 Mar 2021","2021","9","","43378","43386","The rapid development of information technologies like Internet of Things, Big Data, Artificial Intelligence, Blockchain, etc., has profoundly affected people’s consumption behaviors and changed the development model of the financial industry. The financial services on Internet and IoT with new technologies has provided convenience and efficiency for consumers, but new hidden fraud risks are generated also. Fraud, arbitrage, vicious collection, etc., have caused bad effects and huge losses to the development of finance on Internet and IoT. However, as the scale of financial data continues to increase dramatically, it is more and more difficult for existing rule-based expert systems and traditional machine learning model systems to detect financial frauds from large-scale historical data. In the meantime, as the degree of specialization of financial fraud continues to increase, fraudsters can evade fraud detection by frequently changing their fraud methods. In this article, an intelligent and distributed Big Data approach for Internet financial fraud detections is proposed to implement graph embedding algorithm Node2Vec to learn and represent the topological features in the financial network graph into low-dimensional dense vectors, so as to intelligently and efficiently classify and predict the data samples of the large-scale dataset with the deep neural network. The approach is distributedly performed on the clusters of Apache Spark GraphX and Hadoop to process the large dataset in parallel. The groups of experimental results demonstrate that the proposed approach can improve the efficiency of Internet financial fraud detections with better precision rate, recall rate, F1-Score and F2-Score.","2169-3536","","10.1109/ACCESS.2021.3062467","Scientific Research Project of Education Department of Hunan Province(grant numbers:20K021,20A080); Hunan Provincial Higher Education Teaching Reform Research Project(grant numbers:HNJG-2020-1124); Social Science Foundation of Hunan Province(grant numbers:17YBA049); 2011 Collaborative Innovation Center of Big Data for Financial and Economical Asset Development and Utility in Universities of Hunan Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9363921","Internet of Things (IoT);Internet finance;fraud detection;graph embedding algorithm;Node2Vec","Credit cards;Finance;Data models;Internet of Things;Expert systems;Clustering algorithms;Big Data","","14","","35","CCBY","26 Feb 2021","","","IEEE","IEEE Journals"
"Cost-aware & Fault-tolerant Geo-distributed Edge Computing for Low-latency Stream Processing","J. Xu; B. Palanisamy","School of Computing and Information, University of Pittsburgh, Pittsburgh, PA, USA; School of Computing and Information, University of Pittsburgh, Pittsburgh, PA, USA","2021 IEEE 7th International Conference on Collaboration and Internet Computing (CIC)","14 Feb 2022","2021","","","117","124","The number of Internet-of-Things (IoT) devices is rapidly increasing with the growth of IoT applications in various domains. As IoT applications have a strong demand for low latency and high throughput computing, stream processing using edge computing resources is a promising approach to support low latency processing of large-scale data. Edge-based stream processing extends the capability of cloud-based stream processing by processing the data streams near the edge of the network. In this vision paper, we discuss a distributed stream processing framework that optimizes the performance of stream processing applications through a careful allocation of geo-distributed computing and network resources available in edge computing environments. The framework includes key optimizations in both the platform layer and the infrastructure layer. While the platform layer is responsible for converting the user program into a stream processing physical plan and optimizing the physical plan and operator placement, the infrastructure layer is responsible for provisioning geo-distributed resources to the platform layer. The framework optimizes the performance of stream query processing at the platform layer through its careful consideration of data locality and resource constraints during physical plan generation and operator placement and by incorporating resilience to deal with failures. The framework also includes techniques to dynamically determine the level of parallelism to adapt to changing workload conditions. At the infrastructure layer, the framework includes a novel model for allocating computing resources in edge and geo-distributed cloud computing environments by carefully considering latency and cost. End users benefit from the platform through reduced cost and improved user experience in terms of response time and latency.","","978-1-6654-1625-2","10.1109/CIC52973.2021.00026","IBM Faculty award; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9707172","","Cloud computing;Costs;Throughput;User experience;Internet of Things;Time factors;Resource management","","","","42","IEEE","14 Feb 2022","","","IEEE","IEEE Conferences"
"Wireless IoT Monitoring System in Hong Kong–Zhuhai–Macao Bridge and Edge Computing for Anomaly Detection","X. Wang; W. Wu; Y. Du; J. Cao; Q. Chen; Y. Xia","Department of Civil and Environmental Engineering and the Research Institute for Artificial Intelligence of Things, The Hong Kong Polytechnic University, Kowloon, Hong Kong; Department of Civil and Environmental Engineering, The Hong Kong Polytechnic University, Kowloon, Hong Kong; Department of Civil and Environmental Engineering, The Hong Kong Polytechnic University, Kowloon, Hong Kong; Department of Computing and the Research Institute for Artificial Intelligence of Things, The Hong Kong Polytechnic University, Kowloon, Hong Kong; Department of Computing and the Research Institute for Artificial Intelligence of Things, The Hong Kong Polytechnic University, Kowloon, Hong Kong; Department of Civil and Environmental Engineering and the Research Institute for Artificial Intelligence of Things, The Hong Kong Polytechnic University, Kowloon, Hong Kong","IEEE Internet of Things Journal","24 Jan 2024","2024","11","3","4763","4774","The emergence of the Internet of Things (IoT) has facilitated the development and usage of low-computational microcontrollers at the edge of the network, which process data in the proximity of data sources and thereby offload the pressure of data transmission. Recently, IoT is becoming a key technology for structural health monitoring (SHM) systems. This study designs a novel wireless IoT monitoring system for the Hong Kong–Zhuhai–Macao Bridge, the world longest sea-crossing bridge. The 5G technology and edge computing are integrated to improve the system performance in sensor serviceability, data transmission, time synchronization, and data quality control. The artificial intelligent (AI) algorithm is embedded into the NVIDIA Xavier NX edge computing boards to preliminarily detect data anomalies caused by sensor faults, before uploading the massive data to the cloud platform. As training AI models requires a large amount of labeled data and is always time consuming, a novel data anomaly detection method is developed by transferring the model trained from the other bridge to the target bridge. Given that prestoring source data in edge devices consumes expensive storage resources, the source-free domain adaptation is developed by integrating the robust self-training mechanism and self-knowledge distillation strategy. Thus, the model transfer is achieved cross bridges in the absence of source data. This study provides a valuable and practical reference for developing a wireless IoT SHM system for large-scale infrastructure and enabling edge computing for data anomaly detection with high efficiency and accuracy.","2327-4662","","10.1109/JIOT.2023.3300073","Key-Area Research and Development Program of Guangdong Province(grant numbers:2019B111106001); RGC-GRF(grant numbers:15217522); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10197602","Anomaly detection;edge computing;Internet of Things (IoT);source-free domain adaptation;structural health monitoring (SHM)","Bridges;Sensors;Wireless sensor networks;Wireless communication;Edge computing;Sensor systems;Cloud computing","","1","","43","IEEE","31 Jul 2023","","","IEEE","IEEE Journals"
"Artificial Neural Networks-Based Intrusion Detection System for Internet of Things Fog Nodes","J. Pacheco; V. H. Benitez; L. C. Félix-Herrán; P. Satam","Department of Industrial Engineering, Universidad de Sonora, Hermosillo, Mexico; Department of Industrial Engineering, Universidad de Sonora, Hermosillo, Mexico; School of Engineering and Sciences, Tecnológico de Monterrey, Hermosillo, Mexico; Department of Electrical and Computer Engineering, The University of Arizona, Tucson, USA","IEEE Access","28 Apr 2020","2020","8","","73907","73918","The Internet of Things (IoT) represents a mean to share resources (memory, storage computational power, data, etc.) between computers and mobile devices, as well as buildings, wearable devices, electrical grids, and automobiles, just to name few. The IoT is leading to the development of advanced information services that will require large storage and computational power, as well as real-time processing capabilities. The integration of IoT with emerging technologies such as Fog Computing can complement these requirements with pervasive and cost-effective services capable of processing large-scale geo-distributed information. In any IoT application, communication availability is essential to deliver accurate and useful information, for instance, to take actions during dangerous situations, or to manage critical infrastructures. IoT components like gateways, also called Fog Nodes, face outstanding security challenges as the attack surface grows with the number of connected devices requesting communication services. These Fog nodes can be targeted by an attacker, preventing the nodes from delivering important information to the final users or to perform accurate automated actions. This paper introduces an Anomaly Behavior Analysis Methodology based on Artificial Neural Networks, to implement an adaptive Intrusion Detection System (IDS) capable of detecting when a Fog node has been compromised, and then take the required actions to ensure communication availability. The experimental results reveal that the proposed approach has the capability for characterizing the normal behavior of Fog Nodes despite its complexity due to the adaptive scheme, and also has the capability of detecting anomalies due to any kind of sources such as misuses, cyber-attacks or system glitches, with high detection rate and low false alarms.","2169-3536","","10.1109/ACCESS.2020.2988055","Consejo Nacional de Ciencia y Tecnología (CONACYT) through the Fondo de Cooperación Internacional en Ciencia y Tecnología del Conacyt (FONCICYT) Project entitled Cloud and Autonomic Computing Center, Universidad de Sonora(grant numbers:296323); Tecnologico de Monterrey, Vicerrectory of Research and Technology Transfer for funding the publication cost of this research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9068218","Anomaly behavior;cyber security;fog computing;IoT;neural networks","Edge computing;Internet of Things;Intrusion detection;Cloud computing;Computer security;Artificial neural networks","","41","","42","CCBY","15 Apr 2020","","","IEEE","IEEE Journals"
"Landing Reinforcement Learning onto Smart Scanning of The Internet of Things","J. Qu; X. Ma; W. Liu; H. Sang; J. Li; L. Xue; X. Luo; Z. Li; L. Feng; X. Guan","MOE Key Lab for Intelligent Networks and Network Security, Xi’an Jiaotong University, Xi’an, China; MOE Key Lab for Intelligent Networks and Network Security, Xi’an Jiaotong University, Xi’an, China; NSFOCUS Inc., China; NSFOCUS Inc., China; Department of Computing, The Hong Kong Polytechnic University, Hong Kong, China; Department of Computing, The Hong Kong Polytechnic University, Hong Kong, China; Department of Computing, The Hong Kong Polytechnic University, Hong Kong, China; School of Software, Tsinghua University, Beijing, China; Center of Dependable and Secure Computing (CDSC) of Wuhan Digital Engineering Institute (WDEI), Wuhan, China; MOE Key Lab for Intelligent Networks and Network Security, Xi’an Jiaotong University, Xi’an, China","IEEE INFOCOM 2022 - IEEE Conference on Computer Communications","20 Jun 2022","2022","","","2088","2097","Cyber search engines, such as Shodan and Censys, have gained popularity due to their strong capability of indexing the Internet of Things (IoT). They actively scan and fingerprint IoT devices for unearthing IP-device mapping. Because of the large address space of the Internet and the mapping’s mutative nature, efficiently tracking the evolution of IP-device mapping with a limited budget of scans is essential for building timely cyber search engines. An intuitive solution is to use reinforcement learning to schedule more scans to networks with high churn rates of IP-device mapping. However, such an intuitive solution has never been systematically studied. In this paper, we take the first step toward demystifying this problem based on our experiences in maintaining a global IoT scanning platform. Inspired by the measurement study of large-scale real-world IoT scan records, we land reinforcement learning onto a system capable of smartly scanning IoT devices in a principled way. We disclose key parameters affecting the effectiveness of different scanning strategies, and find that our system would achieve growing advantages with the proliferation of IoT devices.","2641-9874","978-1-6654-5822-1","10.1109/INFOCOM48880.2022.9796737","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796737","","Performance evaluation;Schedules;Conferences;Decision making;Reinforcement learning;Search engines;Fingerprint recognition","","1","","32","IEEE","20 Jun 2022","","","IEEE","IEEE Conferences"
"Visualization of Front-End Data Logger Internet of Things Technology using Vue.Js Framework","T. Maulida; A. Nur Afa Zumaroh; H. Akbar Awal Rozaq; A. Yahya Syafa'at; R. Sepri Ananda; I. Tahyudin; B. Pilu Hartato; Berlilana","Department of Informatics, Faculty of Computer Science, Universitas Amikom Purwokerto, Purwokerto, Indonesia; Department of Informatics, Faculty of Computer Science, Universitas Amikom Purwokerto, Purwokerto, Indonesia; Department of Computer Science, Graduate School of Informatics Gazi Üniversitesi, Ankara, Türkiye; Department of Informatics, Faculty of Computer Science, Universitas Amikom Purwokerto, Purwokerto, Indonesia; Department of Informatics, Faculty of Computer Science, Universitas Amikom Purwokerto, Purwokerto, Indonesia; Department of Information Systems, Faculty of Computer Science, Universitas Amikom Purwokerto, Purwokertos, Indonesia; Department of Information Technology, Faculty of Computer Science, Universitas Amikom Purwokerto, Purwokertos, Indonesia; Department of Information Systems, Faculty of Computer Science, Universitas Amikom Purwokerto, Purwokertos, Indonesia","2022 6th International Conference on Information Technology, Information Systems and Electrical Engineering (ICITISEE)","10 Mar 2023","2022","","","693","698","The danger of spreading the new variant of Coronavirus Disease (COVID-19) still exists. It takes a new habit to prevent it. The World Health Organization (WHO)urges to minimize the spread of the COVID-19 variant, including by getting used to washing hands regularly. To support this call, the researchers carried out various innovations. One of them is through the application of Internet of Things (IoT) technology for routine hand washing. This research innovates by using an IoT tool that we named Amikom Purwokerto Hand Sanitizer (AMPUH). In addition to functioning as an automatic hand-washing device, this tool is also capable of recording temperature data, and the number of users, controlling hand sanitizer liquid and measuring saturation automatically. The recordings are stored through a data logger and processed through an IoT platform called ThingSpeak. ThingSpeak has the disadvantage of data visualization which is less attractive and informative. A website dashboard is needed to visualize the data contained on the ThingSpeak platform so that the display is more attractive and easier to understand. Therefore, this study aims to create a website dashboard that can provide information from the data stored on the ThingSpeak platform. The author focuses on the front-end by using the Vue.js framework. This framework has advantages such as being flexible (can be used in large-and small-scale websites), reducing repetitive code, and making the page display more dynamic. In building this front end, we apply the Extreme Programming development method. Based on the results of the study, showed that the implementation of the Vue.js framework on the AMPUH data logger front-end resulted in performance in accordance with expectations. Websites that are built to produce attractive and informative visualizations.","","979-8-3503-9961-5","10.1109/ICITISEE57756.2022.10057919","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10057919","Coronavirus Disease (COVID-19);Extreme Programming;Front-End Development;Internet of Things (IoT);Vue.Js","COVID-19;Temperature measurement;Temperature distribution;Technological innovation;Buildings;Data visualization;Temperature control","","","","17","IEEE","10 Mar 2023","","","IEEE","IEEE Conferences"
"Mixture distribution modelling of the sensitivities of a digital 3-axis MEMS accelerometers large batch","A. Prato; F. R. Pennecchi; G. Genta; A. Schiavi","Division of Applied Metrology and Engineering, INRiM - National Institute of Metrological Research, Turin, Italy; Division of Applied Metrology and Engineering, INRiM - National Institute of Metrological Research, Turin, Italy; Department of Management and Production Engineering, Politecnico di Torino, Turin, Italy; Division of Applied Metrology and Engineering, INRiM - National Institute of Metrological Research, Turin, Italy","2022 IEEE International Workshop on Metrology for Industry 4.0 & IoT (MetroInd4.0&IoT)","22 Jul 2022","2022","","","223","228","Huge quantities of low-cost analogue or digital MEMS sensors, in the order of millions per week, are produced by manufacturers. Their use is broad, from consumer electronic devices to Industry 4.0, Internet of Things and Smart Cities. In many cases, such sensors have to be calibrated by accredited laboratories to provide traceable measurements. However, at present, such a massive number of sensors cannot be calibrated and large-scale calibration systems and procedures are still missing. A first step to implementing these methods can be based on the distribution of the sensitivities of the large batches produced. Such distribution is also useful for sensor network end-users who need a single sensitivity, with the associated uncertainty, to be attributed to the whole network. Recently, a large batch of 100 digital 3-axis MEMS accelerometers was calibrated with a primary calibration system developed at INRiM and suitable for 3-axis accelerometers. Distributions of their sensitivities as a function of axis and frequency were analyzed and their non-normal behaviour was shown. However, in the preliminary phase of the study, the calibration uncertainties were not considered in these distributions. Therefore, in this paper, a mixture distribution modelling, based on Monte Carlo simulations and aimed at including the calibration uncertainties in the sensitivity distributions, is implemented and the resulting distributions are compared to the previous ones in histogram form. These distributions are also fitted with Johnson's unbounded and bimodal functions to get continuous distributions. This paper represents a further step towards the development of large-scale statistical calibration methods.","","978-1-6654-1093-9","10.1109/MetroInd4.0IoT54413.2022.9831583","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9831583","Digital MEMS accelerometers;large-scale;sensitivity;mixture distribution","Micromechanical devices;Accelerometers;Sensitivity;Uncertainty;Correlation;Smart cities;Sensor phenomena and characterization","","","","22","IEEE","22 Jul 2022","","","IEEE","IEEE Conferences"
"Dynamic Oversampling in 1-Bit Quantized Asynchronous Large-Scale Multiple-Antenna Systems for Sustainable Iot Networks","Z. Shao; L. T. N. Landau; R. C. de Lamare","Centre for Telecommunications Studies, Pontifical Catholic University of Rio de Janeiro, Brazil; Centre for Telecommunications Studies, Pontifical Catholic University of Rio de Janeiro, Brazil; Centre for Telecommunications Studies, Pontifical Catholic University of Rio de Janeiro, Brazil","ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","9031","9035","In this paper, we propose a dynamic oversampling technique for asynchronous large-scale multiple-antenna systems with 1-bit analog-to-digital converters at the base station that is suitable for sustainable internet of things and cellular networks. To the best of our knowledge, this is the first paper to introduce a dynamic oversampling technique for such systems. The main idea is to sample the received signal at a higher rate and only few weighted samples are chosen for further signal processing. We apply the generalized eigenvalue decomposition algorithm for linearly combining the samples and performing dimension reduction. We investigate the proposed technique in terms of the Bussgang theorem based sum rate capacity. Numerical results show that with the proposed dynamic oversampling technique the system can use small number of processing samples to achieve the same sum rates as the standard uniform oversampling technique while maintaining the same power consumption.","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9054015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9054015","Asynchronous large-scale MIMO;1-bit ADCs;dynamic oversampling;sum rate capacity","Power demand;Simulation;Signal processing algorithms;Receivers;Speech processing;Standards;System analysis and design","","1","","20","IEEE","9 Apr 2020","","","IEEE","IEEE Conferences"
"Study on a Novel Network Nod Monitoring System based on the Spherical Multi-robot","S. Guo; R. Wang; J. Guo; J. Xu","Tianjin Key Laboratory for Control Theory&Applications In Complicated systems and Intelligent Robot Laboratory, Tianjin University of Technology, Tianjin, China; Tianjin Key Laboratory for Control Theory&Applications In Complicated systems and Intelligent Robot Laboratory, Tianjin University of Technology, Tianjin, China; Tianjin Key Laboratory for Control Theory&Applications In Complicated systems and Intelligent Robot Laboratory, Tianjin University of Technology, Tianjin, China; Unit68709 Qinghai Haidong, China","2021 IEEE International Conference on Mechatronics and Automation (ICMA)","27 Aug 2021","2021","","","1207","1212","The spherical multi-robot system is mainly used for water quality monitoring in large-scale aquaculture. The main research content of this article is how to realize the multi-robot system effectiveness of data transmission. Or, when the detection range is too large, the multi-robot system adopts the centralized control mode, once the instability of the central robot network occurs. If the data can not be fed back to the user, how to ensure the control ability of the entire multi-robot system. Novel network nod monitoring system has the advantages of Ad Hoc network, self - repair and not limited by the distance of router. It has been widely used in various fields. At the same time, cloud platform communication technology has also been widely used in the field of the Internet of Things. Its advantages are multi-purpose function, long transmission distance, strong safety performance, etc. By adopting self - owned cloud platform structure and the novel network nod monitoring system. It improves the flexibility and reliability of the multi-robot system and ensures the efficiency of large-scale data acquisition. In this paper, a Mesh network architecture and a network system based on cloud platform for spherical multi-robot systems are proposed. The experimental results show that it is feasible to construct the whole node monitoring system based on Mesh. With this system, the multi-robot system can accomplish more complex tasks.","2152-744X","978-1-6654-4101-8","10.1109/ICMA52036.2021.9512728","National Natural Science Foundation of China(grant numbers:61703305); Natural Science Foundation of Tianjin(grant numbers:18JCZDJC38500); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9512728","Meshnetworking;Data management;Multi-robot self-organizing team;Cloud server","Cloud computing;Mesh networks;Water quality;Safety;Multi-robot systems;Servers;Reliability","","1","","23","IEEE","27 Aug 2021","","","IEEE","IEEE Conferences"
"An AI-Enabled Three-Party Game Framework for Guaranteed Data Privacy in Mobile Edge Crowdsensing of IoT","J. Xiong; M. Zhao; M. Z. A. Bhuiyan; L. Chen; Y. Tian","Fujian Provincial Key Laboratory of Network Security and Cryptology, College of Mathematics and Informatics, Fujian Normal University, Fuzhou, China; Fujian Provincial Key Laboratory of Network Security and Cryptology, College of Mathematics and Informatics, Fujian Normal University, Fuzhou, China; Department of Computer and Information Sciences, Fordham University, New York, NY, USA; College of Engineering and Computing, Georgia Southern University, Statesboro, NY, USA; State Key Laboratory of Public Big Data, College of Computer Science and Technology, Guizhou University, Guiyang, China","IEEE Transactions on Industrial Informatics","19 Nov 2020","2021","17","2","922","933","The mobile crowdsensing (MCS) technology with a large number of Internet of Things (IoT) devices provides an economic and efficient solution to participation in coordinated large-scale sensing tasks. Edge computing powers MCS to form the mobile edge crowdsensing (MECS) framework. Privacy disclosure of sensing data in multiple stages is a significant challenge in the MECS. To tackle this issue, combining machine learning with game theory, in this article, we propose an artificial intelligence (AI)-enabled three-party game (ATG) framework for guaranteed data privacy in the MECS of IoT. Specifically, based on the random forest classifier and the k-anonymity algorithm, we propose a classification-anonymity model that effectively guarantees the privacy of sensitive data. Moreover, we construct a three-party game model for analyzing the data privacy leakage in different phases in the MECS. Finally, we conduct numerical and theoretical analyses and ample simulations. The results indicate that the ATG framework is effective and efficient, and better suited to the MECS of IoT.","1941-0050","","10.1109/TII.2019.2957130","National Natural Science Foundation of China(grant numbers:61872088,61872090,U1905211,61772008,61662009); Key Lab of Information Network Security; Ministry of Public Security of the People's Republic of China(grant numbers:C18602); Major Scientific and Technological Special Project of Guizhou Province(grant numbers:20183001); Natural Science Foundation of Fujian Province(grant numbers:2019J01276); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8918437","Machine learning;mobile edge crowdsensing (MECS);Nash equilibrium (NE);privacy protection;three-party game (TG) model","Sensors;Data privacy;Games;Data models;Task analysis;Analytical models;Informatics","","98","","40","IEEE","2 Dec 2019","","","IEEE","IEEE Journals"
"Internet of Things based User Identification and Hand Sanitization System with Non-Contact Temperature Measurement","H. Dandekar; S. Deo; S. Deo; S. Date; Y. Chougule","Department of Instrumentation, Vishwakarma Institute of Technology, Pune, India; Department of Instrumentation, Vishwakarma Institute of Technology, Pune, India; Department of Instrumentation, Vishwakarma Institute of Technology, Pune, India; Department of Instrumentation, Vishwakarma Institute of Technology, Pune, India; Department of Instrumentation, Vishwakarma Institute of Technology, Pune, India","2021 Fifth International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)","20 Dec 2021","2021","","","70","77","With the spread of SARS-CoV-2, the demand for students’ and employees’ health monitoring and non-contact methods of sanitization has escalated. This paper details the design and implementation of an economic, non-contact sanitization and user data recording system using the Internet of Things (IoT). The design includes a non-invasive temperature measurement technique, user identification using Radio Frequency Identification (RFID), data recording over Wi-Fi using ESP8266, and a contactless hand sanitizer dispenser. The prototype is targeted at educational institutes and small-scale commercial entities.","2768-0673","978-1-6654-2642-8","10.1109/I-SMAC52330.2021.9640816","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9640816","Non-contact;IOT;RFID;ESP8266;Sanitization;Automation;Temperature Monitoring","Temperature measurement;Temperature sensors;Economics;Prototypes;Organizations;Coronaviruses;Internet of Things","","3","","30","IEEE","20 Dec 2021","","","IEEE","IEEE Conferences"
"Implementation of Micro Hydro Power Plant Monitoring System Based on Internet of Things","Z. F. Sumarna; N. Sartika; L. Kamelia; A. E. Setiawan; Nurhayati; T. Yusuf","Department of Electrical Engineering, UIN Sunan Gunung Djati Bandung, Bandung, Indonesia; Department of Electrical Engineering, UIN Sunan Gunung Djati Bandung, Bandung, Indonesia; Department of Electrical Engineering, UIN Sunan Gunung Djati Bandung, Bandung, Indonesia; Department of Electrical Engineering, UIN Sunan Gunung Djati Bandung, Bandung, Indonesia; Faculty of Education and Teacher Training, UIN Sunan Gunung Djati Bandung, Bandung, Indonesia; Department of Electrical Engineering, UIN Sunan Gunung Djati Bandung, Bandung, Indonesia","2023 9th International Conference on Wireless and Telematics (ICWT)","11 Dec 2023","2023","","","1","5","The utilization of renewable energy sources (RES) in the surrounding environment provides an alternative solution for environmentally friendly electricity generation. A micro-hydro power plant is a small-scale power plant (100 kW) that utilizes water resources (irrigation channels, rivers, or waterfalls) as the driving force, taking advantage of the head and water flow. The Internet of Things (IoT) technology is employed as a monitoring system for voltage, current, and power generated by the Archimedes screw turbine generator, utilizing the Ubidots platform. The results obtained by varying the inclination angle of the turbine head at 0° and 34° show that the Archimedes screw turbine generator produces the highest output power of 0.281 watts with an efficiency of 7.5% at the 0° angle and 2.6 watts with an efficiency of 9.3% at the 34° angle. The inclination angle of the turbine head affects the voltage, current, input power, output power, and efficiency generated by the Archimedes screw turbine generator.","2769-8289","979-8-3503-0502-9","10.1109/ICWT58823.2023.10335467","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10335467","micro-hydro power plant;monitoring system;internet of things;ubidots","Wireless communication;Microhydro power;Hydraulic turbines;Wireless sensor networks;Voltage;Fasteners;Generators","","","","13","IEEE","11 Dec 2023","","","IEEE","IEEE Conferences"
"Controlling Resource Allocation using Blockchain-Based Delegation","S. Pal; A. Hill; T. Rabehaja; M. Hitchens","School of Computer Science, Queensland University of Technology, Brisbane, QLD, Australia; School of Computer Science and Engineering, University of New South Wales, Sydney, NSW, Australia; School of Computer Science and Engineering, University of New South Wales, Sydney, NSW, Australia; Department of Computing, Macquarie University, Sydney, NSW, Australia","2021 IEEE Globecom Workshops (GC Wkshps)","24 Jan 2022","2021","","","1","7","Allocation of resources and their control over multiple organisations is challenging. This is especially true for a large-scale and dynamic system like the Internet of Things (IoT). One of the core issues in such a system is the provision of secure access control. In particular, transfer of access rights from one entity to another in a secure, flexible and fine-grained manner. In this paper, we present a multi-organisational delegation framework using blockchain. Our framework takes advantage of blockchain smart contracts to define the interactions and resource allocation between the consortium of organisations. We show the feasibility of our solution in a real-world scenario using the allocation of transportation credits in a multi-level organisational setting as a use-case. We provide proof of implementation of the proposed framework using the Hyperledger Fabric blockchain platform. Our results indicate that the proposed framework is efficient and can be used for city-wide transport, potentially even scale country-wide with a shared blockchain with complex access control rules. It also bestows better transparency to the delegation of access rights and control over the employees’ transportation access for the organisations.","","978-1-6654-2390-8","10.1109/GCWkshps52748.2021.9682089","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9682089","","Access control;Distributed ledger;Smart contracts;Transportation;Permission;Fabrics;Blockchains","","","","30","IEEE","24 Jan 2022","","","IEEE","IEEE Conferences"
"High Quality-Factor Planar Inductors Compatible with Flexible Large-Area Electronics for Integrated IoT and 5G/6G Applications","Y. Ma; S. Wagner; N. Verma; J. C. Sturm","Department of Electrical and Computer Engineering, Princeton University, Princeton, NJ, USA; Department of Electrical and Computer Engineering, Princeton University, Princeton, NJ, USA; Department of Electrical and Computer Engineering, Princeton University, Princeton, NJ, USA; Department of Electrical and Computer Engineering, Princeton University, Princeton, NJ, USA","2023 IEEE International Flexible Electronics Technology Conference (IFETC)","25 Sep 2023","2023","","","01","03","Resonant operation, exploiting high quality-factor planar inductors, has recently enabled giga-Hertz applications in large-area electronics, opening up a new technology platform for large-scale and flexible wireless systems. This work presents the design, analysis, and characterization methodology of flex-compatible large-area planar inductors with a record-high quality factor of up to 65 in the 2.4-GHz frequency band. The inductor design and analysis address a key frequency limiter to recently demonstrated large-area and conformal wireless systems for integrated Internet of Things and 5G/6G applications.","","979-8-3503-3209-4","10.1109/IFETC57334.2023.10254834","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10254834","Internet of Things;5G/6G;planar inductor;monolithic integration;flex-compatible","Wireless communication;Q-factor;Internet of Things;Inductors;Flexible electronics","","","","15","IEEE","25 Sep 2023","","","IEEE","IEEE Conferences"
"UAV-Assisted IoT Communication Network Using STLC Technique","T. Yilmaz; H. İlhan","Havacılık Elektrik Elektroniği Bölümü, Kartepe-KOCAELİ, Kocaeli Üniversitesi; Elektronik ve Haberleşme Müh. Bölümü, Davutpaşa-İSTANBUL, Yıldız Teknik Üniversitesi","2022 30th Signal Processing and Communications Applications Conference (SIU)","29 Aug 2022","2022","","","1","4","In this study, an Internet of Things (IoT) communication network is considered, where mobile users in a dense urban environment communicate via a stationary Unmanned Aerial Vehicle (UAV) that acts as a base station. It is thought that the users in the network are designed with a single antenna and the UAV with a double antenna. Users estimate the channel gain parameters according to the pilot symbols they receive from the UAV and send their symbols to the UAV by encoding them with the Space-Time Line Coding (STLC) technique according to these channel gain parameters. In the UAV, on the other hand, symbols are retrieved intensively without the need for channel gain information that may come from users. Monte Carlo simulations were created under various assumptions and the error performance of a fixed user on the network was examined. It is assumed that the envelopes of the communication channels in the system follow the Ricean fading channel in small-scale fading.","2165-0608","978-1-6654-5092-8","10.1109/SIU55565.2022.9864974","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9864974","Unmanned Aerial Vehicle (UAV);Space-Time Line Coding (STLC);Internet of Things (IoT);Ricean Fading Channels","Fading channels;Monte Carlo methods;Urban areas;Symbols;Channel estimation;Autonomous aerial vehicles;Encoding","","","","0","IEEE","29 Aug 2022","","","IEEE","IEEE Conferences"
"S-Rum Inductors: 30-Fold Enhancement of Inductance by Controlled Electroplating Post Rolling","Z. Yang; A. Khandelwal; A. Wang; K. Nguyen; S. Wicker; Y. V. Shao; X. Li","The Department of Electrical and Computer Engineering, Microelectronics Research Center, The University of Texas at Austin, Austin, TX, United States; Department of Electrical and Computer Engineering, Holonyak Micro and Nanotechnology Laboratory, University of Illinois Urbana-Champaign, Urbana, IL, United States; The Department of Electrical and Computer Engineering, Microelectronics Research Center, The University of Texas at Austin, Austin, TX, United States; The Department of Electrical and Computer Engineering, Microelectronics Research Center, The University of Texas at Austin, Austin, TX, United States; The Department of Electrical and Computer Engineering, Microelectronics Research Center, The University of Texas at Austin, Austin, TX, United States; Department of Electrical and Computer Engineering, Holonyak Micro and Nanotechnology Laboratory, University of Illinois Urbana-Champaign, Urbana, IL, United States; The Department of Electrical and Computer Engineering, Microelectronics Research Center, The University of Texas at Austin, Austin, TX, United States","2024 IEEE 37th International Conference on Micro Electro Mechanical Systems (MEMS)","22 Feb 2024","2024","","","691","692","The demand on power inductors with high inductances (micro-Henries) and high current-carrying capacities to have small footprints for Internet-of-Things (IOT) and Cyber-Physical-System (CPS) applications poses design and fabrication challenges. 3D air-core microtube inductors fabricated with self-rolled-up membranes (S-RuM) can provide higher inductance densities than planar inductors, but are restricted by both high resistive losses, dependent on metal film thickness, and air-core limited magnetic core integration. This study proposes a post-rolling electroplating process for increased metal conductivity and core permeability for S-RuM inductors. S-RuM inductors with parallel-processed Au-shell and partial-plated permalloy core resulted in improvements of over 10x DC resistance (DCR) decrease and over 30x inductance boost. Such improvements are predicted to increase in magnitudes upon optimized shell and core-filling, offering the potential for scaling this technology for use in power electronics applications such as converters and filters with minimal power losses.","2160-1968","979-8-3503-5792-9","10.1109/MEMS58180.2024.10439516","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10439516","Micro-inductors;magnetic cores;electroplating;self-rolled membranes;miniaturization;on-chip;MEMS","Electrochemical deposition;Fabrication;Inductance;Three-dimensional displays;Magnetic cores;Metals;Inductors","","","","4","IEEE","22 Feb 2024","","","IEEE","IEEE Conferences"
"TransCAB: Transferable Clean-Annotation Backdoor to Object Detection with Natural Trigger in Real-World","H. Ma; Y. Li; Y. Gao; Z. Zhang; A. Abuadbba; A. Fu; S. F. Al-Sarawi; S. Nepal; D. Abbott","The University of Adelaide, Australia; Nanjing University of Science and Technology, China; Data61, CSIRO, Syndey, Australia; The University of Western Australia, Australia; Data61, CSIRO, Syndey, Australia; Nanjing University of Science and Technology, China; The University of Adelaide, Australia; Data61, CSIRO, Syndey, Australia; The University of Adelaide, Australia","2023 42nd International Symposium on Reliable Distributed Systems (SRDS)","9 Feb 2024","2023","","","82","92","Object detection is the foundation of various critical computer-vision tasks such as segmentation, object tracking, and event detection, which can be deployed on pervasive Internet of Things (IoT) and edge devices. A large amount of data is often required to train an object detector with satisfactory accuracy. However, due to the intensive workforce involved with collecting and annotating large datasets, data curation task is often outsourced to a third party (e.g., Amazon Mechanical Turk) or volunteers. This work reveals severe vulnerabilities in this data curation pipeline. We propose TransCAB, the first work to craft clean-annotated images to stealthily implant the backdoor into the object detectors later trained on them by the data curator/user even when the data curator can manually audit the images and fully controls the training process. Existing clean-label poisoned images are only shown in classification tasks but not non-classification tasks, in particular, object detection due to unique challenges faced, generally owing to the complexity of having multiple objects within each frame (image), including the victim and non-victim objects. Furthermore, we demonstrate that the backdoor effect of both cloaking and misclassification are robustly achieved in the wild when the backdoor is activated with inconspicuously natural physical object as trigger (i.e., T-shirt). The efficacy of our TransCAB is ensured by constructively i) applying the image-camouflage attack that abuses the image-scaling function widely used by the deep learning framework (i.e., PyTorch), ii) incorporating the devised clean image replica technique, and iii) combining identified poison data selection criteria given constrained attacking budget. Extensive experi-ments on YOLOv3, YOLOv4, CenterNet, and Faster R-CNN affirm that TransCAB exhibits more than 90% attack success rate under various real-world scenes even when a very small (i.e., 0.14%) dataset fraction is poisoned. In addition, the small set of poisoned images crafted on one detector (i.e., YOLOv3) can be effectively transferred to insert a backdoor on another detector (i.e., CenterNet). A comprehensive video demo is at https://youtu.be/MA7L_LpXkp4, where a poison rate of merely 0.14% is set for YOLOv4 cloaking backdoor and Faster R-CNN misclassification backdoor. Our collected dataset with T-shirt as a natural trigger (about 11,350 frames in total) is open to the public at https://github.com/inconstance/T-shirt-natural-backdoor-dataset, which is the first relatively large-scale natural trigger backdoor dataset.","2575-8462","979-8-3503-2910-0","10.1109/SRDS60354.2023.00018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10419265","Object detection;Backdoor attack;Natural trigger;Clean-label backdoor;Physical world","YOLO;Training;Toxicology;Detectors;Implants;Internet of Things;Task analysis","","1","","42","IEEE","9 Feb 2024","","","IEEE","IEEE Conferences"
"SoC Reconfigurable Architecture for Implementing Software Trained Recurrent Neural Networks on FPGA","M. Wasef; N. Rafla","Electrical and Computer Engineering Department, Boise State University, Boise, ID, USA; Electrical and Computer Engineering Department, Boise State University, Boise, ID, USA","IEEE Transactions on Circuits and Systems I: Regular Papers","26 May 2023","2023","70","6","2497","2510","Recurrent neural networks (RNNs) are used extensively in time series data applications. Modern RNNs consist of three layer types: recurrent, Fully-Connected (FC), and attention. This paper introduces the design, acceleration, implementation, and verification of a complete reconfigurable RNN using a system-on-chip approach on an FPGA. This design is suitable for small-scale projects and Internet of Things (IoT) end devices as the design utilizes a small number of hardware resources compared to previous configurable architectures. The proposed reconfigurable architecture consists of three layers. The first layer is a Python software layer that contains a function serving as the architecture’s user interface. The output of the python function is three binary files containing the RNN architecture description and trained parameters. The embedded software layer implemented on an on-chip ARM microcontroller is the second layer of that architecture. This layer reads the first layer output files and configures the hardware layer with the required configuration and parameters to execute each layer in the RNN. The hardware layer consists of two Intellectual Properties (IPs) with different configurations. The Recurrent Layer Hardware IP implements the recurrent layer using either Long Short Term Memory (LSTM) or Gated Recurrent Unit (GRU) as basic building blocks, while the ATTENTION/FC IP implements the attention layer and the FC layer. The proposed design allows the implementation of a recurrent layer on an FPGA with variable input and a hidden vector length of up to 100 elements for each vector. It also supports implementing an attention layer with up to 64 input vectors and a maximum vector length of 100 items. The FC layers can be configured to support a maximum value of 256 for the input vector length and the number of neurons in each layer. The hardware design of the recurrent layer achieves a maximum performance of 1.958 and 2.479 GOPS for the GRU and LSTM models, respectively. The maximum performance of the attention and FC layers is 2.641 GOPS and 634.3 MOPS, respectively. The hardware design works at a maximum frequency of 100 MHz.","1558-0806","","10.1109/TCSI.2023.3262479","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10097519","FPGA;RNN;LSTM;GRU;system-on-chip;attention layer","Computer architecture;Hardware;Field programmable gate arrays;Logic gates;Software;Recurrent neural networks;Python","","","","28","IEEE","7 Apr 2023","","","IEEE","IEEE Journals"
"Lightweight Authenticated-Encryption Scheme for Internet of Things Based on Publish-Subscribe Communication","A. Diro; H. Reda; N. Chilamkurti; A. Mahmood; N. Zaman; Y. Nam","Department of Computer Science and IT, La Trobe University, Bundoora, Australia; Department of Computer Science and IT, La Trobe University, Bundoora, Australia; Department of Computer Science and IT, La Trobe University, Bundoora, Australia; Department of Computer Science and IT, La Trobe University, Bundoora, Australia; School of Computer Science and Engineering (SCE), Taylor’s University, Selangor, Malaysia; Department of Computer Science and Engineering, Soonchunhyang University, Asan, South Korea","IEEE Access","7 Apr 2020","2020","8","","60539","60551","The resource-constrained nature and large-scale adoption of Internet of Things (IoT) have a significant challenge for securing IoT applications. This necessitates a robust and lightweight security architecture and schemes as the existing traditional Internet security architecture and protocols require huge resources and lack of end-to-end security mechanism. In this research, a resource efficient end-to-end security scheme has been proposed by offloading computations and storage of security parameters to fog nodes in the vicinity. In addition, a symmetric-key payload encryption has been used to minimize the overhead of message communication in the resource-contested IoT environment. The analysis shows that the proposed scheme outperforms Transport Layer Security (TLS) in resource usage while it maintains equivalent authenticated end-to-end communication between communicating IoT nodes. The proposed end-to-end security scheme saves more communication bandwidth and incurs less overhead as compared to existing TLS-based security schemes. In particular, the proposed system uses less number of handshakes and achieves a decrease in the number of transmitted messages (approximately 184 bytes as compared to compared TSL message size of 332 bytes) for every handshake. Further, it has been demonstrated through experiments that the proposed security method incurs less overheads as compared to the TLS bandwidth consumption considering a single connection session during message subscription.","2169-3536","","10.1109/ACCESS.2020.2983117","Korea Institute for Advancement of Technology (KIAT); Korea Government (MOTIE: Ministry of Trade Industry and Energy)(grant numbers:N0001791); HRD Program for ICT Convergence Smart Rehabilitation Industrial Education Program; Soonchunhyang University Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9045934","Encryption;authentication;cybersecurity;end-end security;Internet of Things;publish-subscribe systems","Internet of Things;Protocols;Publish-subscribe;Computer architecture;Cloud computing;Authentication","","66","","35","CCBY","24 Mar 2020","","","IEEE","IEEE Journals"
"Automated Configuration of Heterogeneous Graph Neural Networks With a Semantic Math Parser for IoT Systems","A. Ba; K. Lynch; J. Ploennigs; B. Schaper; C. Lohse; F. Lorenzi","AI and Quantum, IBM Research Europe (IBM Dublin Technology Campus), Dublin 15, Ireland; AI and Quantum, IBM Research Europe (IBM Dublin Technology Campus), Dublin 15, Ireland; AI and Quantum, IBM Research Europe (IBM Dublin Technology Campus), Dublin 15, Ireland; AI and Quantum, IBM Research Europe (IBM Dublin Technology Campus), Dublin 15, Ireland; AI and Quantum, IBM Research Europe (IBM Dublin Technology Campus), Dublin 15, Ireland; AI and Quantum, IBM Research Europe (IBM Dublin Technology Campus), Dublin 15, Ireland","IEEE Internet of Things Journal","5 Jan 2023","2023","10","2","1042","1052","Efficient training of deep learning models from time series data for Internet of Things (IoT) systems requires a good understanding of the domain, particularly if the training is automated for large-scale applications. Heterogeneous graph neural networks (HGNNs) are a promising approach for incorporating domain knowledge into the modeling framework and consequently improving model performance. However, encoding domain knowledge into HGNNs is nontrivial for IoT systems and requires substantial manual effort. This complicates the adoption of HGNNs in practical settings. To overcome this drawback, we propose a framework for the automatic derivation of HGNN features by semantically parsing equations present in scientific and dedicated publications. We encode the derived features considering physical causation from these equations into an HGNN using an underlying Transformer for prediction and anomaly detection. We validate our approach using two IoT use cases, namely, the prediction of the remaining energy in the battery of an electric race car and the anomaly detection during pick and place operations in a robot workcell. We demonstrate that our approach significantly outperforms other competitive techniques.","2327-4662","","10.1109/JIOT.2022.3204889","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9878268","Anomaly detection;AutoML;heterogeneous graph neural networks (HGNNs);Internet of Things (IoT);monitoring;semantics;time series;transformer","Semantics;Internet of Things;Transformers;Mathematical models;Time series analysis;Feature extraction;Task analysis","","4","","45","IEEE","6 Sep 2022","","","IEEE","IEEE Journals"
"BS-IoT: Blockchain Based Software Defined Network Framework for Internet of Things","L. Liu; W. Feng; C. Chen; Y. Zhang; D. Lan; X. Yuan; S. Vashisht","State Key Laboratory of Integrated Services Networks, Xidian University, Xi'an, China; School of Cyber Engineering, Xidian University, Xi'an, China; State Key Laboratory of Integrated Services Networks, Xidian University, Xi'an, China; State Key Laboratory of Integrated Services Networks, Xidian University, Xi'an, China; Department for Informatics, University of Oslo, Oslo, Norway; Qinhuangdao Branch Campus, Northeastern University, Qinhuangdao, China; Computer Science and Engineering, CGC College of Engineering, Mohali, Punjab, India","IEEE INFOCOM 2020 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)","10 Aug 2020","2020","","","496","501","Software Defined Networking (SDN) is a promising platform to secure and manage large-scale Internet of Things (IoT) due to its separated control and data plane functionality as well as programmability in the network. The original design of SDN faces single point of failure, and therefore several decentralized SDN architectures for IoT were proposed. However, practical SDN may be deployed by various networking operators, which incurs the conflict between data security of different networking operators and cooperative network management among them. Existing schemes cannot well support the cooperative network management among multiple controllers and meanwhile guarantee data security. To tackle this problem, we propose a blockchain based SDN framework for IoT called BS-IoT. BS-IoT introduces blockchain into SDN to support secure and cooperative network management. Besides, we leverage blockchain sharding for better efficiency and improve it with secure multi-party computation (SMPC) to make it suitable for decentralized SDN management with data security. The security analysis illustrate the security and effectiveness of our scheme.","","978-1-7281-8695-5","10.1109/INFOCOMWKSHPS50562.2020.9163070","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9163070","SDN;Blockchain;IoT;Data Security;Sharding","Data security;Smart devices;Cooperative systems;Internet of Things;Computer architecture","","4","","32","IEEE","10 Aug 2020","","","IEEE","IEEE Conferences"
"EIS: Edge Information-Aware Scheduler for Containerized IoT Applications","Z. Wang; X. Zhang; L. Yang","School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Software Engineering, South China University of Technology, Guangzhou, China","2023 IEEE International Conference on Edge Computing and Communications (EDGE)","1 Sep 2023","2023","","","280","289","Edge computing has emerged as a powerful paradigm for Internet of Things (IoT) applications as it can provide computing and network services in close proximity to end devices. In an edge environment, leveraging container technology to package IoT applications offers significant benefits of flexibility and agility, while the incorporation of Kubernetes can effectively orchestrate large-scale containerized applications. However, the existing Kubernetes scheduling solutions mostly cannot satisfy IoT applications with stringent and diverse network, computing, and storage requirements, and they also lack the scalability to customize scheduling strategies. To address these, we develop an edge information-aware scheduler (EIS) based on the novel Kubernetes scheduling framework. EIS schedules containerized IoT applications by sensing the network topology and performance information of edge clusters. Moreover, EIS can make scheduling decisions according to application characteristics and resource requirements. By adopting a plug-in architecture, EIS not only provides an extensible programming interface, but is also compatible with Kubernetes’ default scheduler. We evaluate EIS in a real-world experimental environment, and the results show that EIS can reduce network latency by 18%, improve computing performance up to 140% and improve I/O performance up to 130%. These improvements are critical for IoT applications to provide high quality of service.","2767-9918","979-8-3503-0483-1","10.1109/EDGE60047.2023.00050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10234296","Kubernetes;edge computing;containerized application scheduling;scheduling framework;Internet of Things","Schedules;Processor scheduling;Network topology;Scalability;Image processing;Quality of service;Programming","","","","34","IEEE","1 Sep 2023","","","IEEE","IEEE Conferences"
"IoT Implementation in Slaughterhouses Supply Chain: A Case Study of the Adahi Experiment in the Kingdom of Saudi Arabia","M. Alkahtani; B. Aljabri; A. Alsaleh; H. Alghamdi; O. AlJuraiyed","Department of Industrial Engineering, College of Engineering, King Saud University, P.O. Box-800, Riyadh, Saudi Arabia; Department of Industrial Engineering, College of Engineering, King Saud University, P.O. Box-800, Riyadh, Saudi Arabia; Department of Industrial Engineering, College of Engineering, King Saud University, P.O. Box-800, Riyadh, Saudi Arabia; Department of Industrial Engineering, College of Engineering, King Saud University, P.O. Box-800, Riyadh, Saudi Arabia; Department of Industrial Engineering, College of Engineering, King Saud University, P.O. Box-800, Riyadh, Saudi Arabia","IEEE Access","","2024","PP","99","1","1","The Hajj season holds immense significance for Muslims globally, attracting millions of pilgrims annually to engage in sacred rituals. The Kingdom of Saudi Arabia, as the host of this pilgrimage, extends a range of services to facilitate and enhance the pilgrims’ experience. Among these services, the provision of sacrificial animals for Udhiyah and Hadi, integral components of Hajj rituals, is crucial and managed by organizations like the Kingdom of Saudi Arabian Project for the Benefit of Udhiyah and Sacrifices (Adahi). Adahi’s primary mission is to execute sacrificial rituals on behalf of Hajj pilgrims, ensuring the seamless progression of religious practices. Embracing technological advancements, particularly the Internet of Things (IoT), has become pivotal in enhancing various sectors, including the food supply chain. In Saudi Arabia, Adahi conducts a noteworthy experiment during Hajj, utilizing IoT to count slaughtered cattle in the supply chain. This study seeks to elucidate and assess the role and impact of IoT in Adahi’s experiment, proposing a conceptual framework to enhance monitoring, counting, and tracking of slaughtered cattle during Hajj within Adahi slaughterhouses. The study adopts a descriptive methodology, thoroughly reviewing contemporary literature to identify technological gaps in automatically measuring and inspecting post-harvest meat safety during the slaughtering process. The authors recognize the challenge of implementing IoT, specifically Radio-Frequency Identification (RFID), on a large scale, such as Adahi, due to associated infrastructure and chip costs. This study aims to propose a conceptual framework for an IoT-based meat monitoring system within Adahi’s slaughterhouses, contributing to technological advancements and ensuring the safety and efficiency of the Hajj sacrificial rituals.","2169-3536","","10.1109/ACCESS.2024.3365628","King Saud University(grant numbers:RSP2023R274); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10433486","Food supply chain;Meat safety in slaughterhouses;Sensors;IoT;Smart devices;Machine learning;Hajj","Internet of Things;Safety;Cows;Industrial engineering;Temperature sensors;Supply chain management;Food security;Smart agriculture;Machine learning;Smart devices;Cultural aspects","","","","","CCBYNCND","13 Feb 2024","","","IEEE","IEEE Early Access Articles"
"Recognition and Integration of AI with IoT for Innovative Decision Making Techniques in Cyber Physical Systems","S. Nethani; L. Sivaranjani; M. A. Kumar; B. Lal; M. Tiwari","Department of Computer Science and Engineering, Hyderabad Institute of Technology and Management, Hyderabad, Telangana, India; School of Computing, Mohan Babu University Rangampet, Tirupati, Andhra Pradesh, India; Department of Computer Science and Engineering, Centurion University of Technology and Management, Vizianagaram, Andhra Pradesh, India; Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation (KLEF), KL University, Guntur, Andhra Pradesh, India; Department of Computer Science and Engineering, Bharati Vidyapeeth’s College of Engineering, Delhi, India","2023 Second International Conference on Augmented Intelligence and Sustainable Systems (ICAISS)","22 Sep 2023","2023","","","190","195","With the integration of Internet of Things (IoT) devices and the demand for effective decision-making methods, cyber-physical systems (CPS) are getting more complicated. In CPS, machine learning (ML) has become a potent technique for processing and analyzing massive volumes of data. The problem remains in optimizing ML algorithms to accomplish quick and accurate decision-making. To overcome this difficulty, we provide a novel strategy in this paper that integrates ML with Particle Swarm Optimisation (PSO) and IoT. The suggested framework optimizes ML algorithms for CPS using PSO, an optimization technique inspired by nature. To find the optimum solution in a multidimensional space, PSO imitates the behavior of a swarm of particles. Our goal is to improve the precision and effectiveness of decision-making processes in CPS by combining PSO with ML techniques. Additionally, by integrating IoT devices into CPS, a wealth of real-time data is made available, enabling the collection of diverse and dynamic data from numerous sources. Our method uses this data to analyze patterns, trends, and anomalies using ML algorithms, enabling wise decision-making in real time. The advantages of our suggested strategy are dual. First, PSO optimization increases the efficiency of ML algorithms and lessens the computational complexity related to large-scale datasets. Second, the framework's inclusion of IoT devices makes it possible to employ real-time data, leading to more precise and rapid decision-making.","","979-8-3503-2579-9","10.1109/ICAISS58487.2023.10250493","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10250493","Cyber-physical system;machine learning;particle swarm optimization;real time data;decision making","Machine learning algorithms;Heuristic algorithms;Decision making;Transportation;Machine learning;Cyber-physical systems;Real-time systems","","","","28","IEEE","22 Sep 2023","","","IEEE","IEEE Conferences"
"Blockchain-based Volunteer Edge Cloud for IoT Applications","M. -T. Zhou; F. -G. Shen; T. -F. Ren; X. -Y. Feng","Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences Shanghai, China; Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences Shanghai, China; Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences Shanghai, China; Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences Shanghai, China","2021 IEEE 93rd Vehicular Technology Conference (VTC2021-Spring)","15 Jun 2021","2021","","","1","6","Cloud computing has been widely used in the field of information services. However, large-scale Internet of things (IoT) applications are raising new challenges to cloud computing architecture. Edge computing, which complements cloud computing, is considered to be the way to address these challenges. Volunteer computing, which harvests idle resources in the network can improve the hardware utilization rate and support tens of billions of IoT devices. In view of the limitations of traditional volunteer computing that cannot provide realtime services and has no mechanism to reward services in existing volunteer clouds, this paper presents blockchain-based volunteer edge cloud. A common runtime environment is provided by container technology, and blockchain smart contract is used for critical business steps and computing service payment. Volunteer edge cloud systems based on blockchain is introduced from a top-level perspective, and a prototype system build on Ethereum and KubeEdge is described in detail. On top of the prototype system, we deployed an example IoT application of robot formation control. It demonstrates the benefits of volunteer edge cloud in reducing the complexity of IoT devices, improving the flexibility of software development, and paying the computing service.","2577-2465","978-1-7281-8964-2","10.1109/VTC2021-Spring51267.2021.9449041","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9449041","blockchain;edge cloud;volunteer computing","Cloud computing;Vehicular and wireless technologies;Prototypes;Blockchain;Computer architecture;Hardware;Internet of Things","","6","","15","IEEE","15 Jun 2021","","","IEEE","IEEE Conferences"
"Simulation of Pick and Place Factory Automation Process using Application Programming Interface","B. P; G. Ahil; K. K; D. S. Ganesh; R. M. P E","Department of EEE, National Engineering College, Kovilpatti, Tamilnadu; Department of EEE, National Engineering College, Kovilpatti, Tamilnadu; Department of EEE, National Engineering College, Kovilpatti, Tamilnadu; Department of EEE, National Engineering College, Kovilpatti, Tamilnadu; Department of EEE, National Engineering College, Kovilpatti, Tamilnadu","2022 6th International Conference on Trends in Electronics and Informatics (ICOEI)","24 May 2022","2022","","","311","316","Industry 4.0 or I4.0 is an advanced technology which can upgrade the facilities in small to large scale industries. It is possible to monitor and access date from any machine or a process from a remote place through internet. The smart industrial sensors used in various process can send the data from a server to the client via modern machine to machine communication protocol like Modbus, Message queuing telemetry transport (MQTT) and Open platform communication - unified architecture (OPC-UA). The controllers installed and commissioned in industries several years before might not able to utilize these communication protocols. It needs an IIoT (Industrial Internet of Things) device to overcome the technical glitch. In this project, a new approach is proposed to implement opc-ua communication protocol to communicate between an industrial controller and an application programming interface.","","978-1-6654-8328-5","10.1109/ICOEI53556.2022.9777202","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9777202","Automation;Controllers;Sensors;Industry4.0;Message queuing telemetry transport;Open platform communication - unified architecture","Industries;Protocols;Process control;Market research;Production facilities;Fourth Industrial Revolution;Telemetry","","1","","15","IEEE","24 May 2022","","","IEEE","IEEE Conferences"
"GPU-Accelerated Compression and Visualization of Large-Scale Vessel Trajectories in Maritime IoT Industries","Y. Huang; Y. Li; Z. Zhang; R. W. Liu","Chinese Academy of Sciences, Shanghai Advanced Research Institute, Shanghai, China; Hubei Key Laboratory of Inland Shipping Technology, School of Navigation, Wuhan University of Technology, Wuhan, China; Chinese Academy of Sciences, Shanghai Advanced Research Institute, Shanghai, China; Hubei Key Laboratory of Inland Shipping Technology, School of Navigation, Wuhan University of Technology, Wuhan, China","IEEE Internet of Things Journal","12 Nov 2020","2020","7","11","10794","10812","The automatic identification system (AIS), an automatic vessel-tracking system, has been widely adopted to perform intelligent traffic management and collision avoidance services in maritime Internet-of-Things (IoT) industries. With the rapid development of maritime transportation, tremendous numbers of AIS-based vessel trajectory data have been collected, which make trajectory data compression imperative and challenging. This article mainly focuses on the compression and visualization of large-scale vessel trajectories and their graphics processing unit (GPU)-accelerated implementations. The visualization was implemented to investigate the influence of compression on vessel trajectory data quality. In particular, the Douglas-Peucker (DP) and kernel density estimation (KDE) algorithms, respectively, utilized for trajectory compression and visualization, were significantly accelerated through the massively parallel computation capabilities of the GPU architecture. Comprehensive experiments on trajectory compression and visualization have been conducted on large-scale AIS data of recording ship movements collected from three different water areas, i.e., the South Channel of Yangtze River Estuary, the Chengshan Jiao Promontory, and the Zhoushan Islands. Experimental results illustrated that: 1) the proposed GPU-based parallel implementation frameworks could significantly reduce the computational time for both trajectory compression and visualization; 2) the influence of compressed vessel trajectories on trajectory visualization could be negligible if the compression threshold was selected suitably; and 3) the Gaussian kernel was capable of generating more appropriate KDE-based visualization performance by comparing with other seven kernel functions.","2327-4662","","10.1109/JIOT.2020.2989398","National Natural Science Foundation of China(grant numbers:51609195); Excellent Dissertation Cultivation Funds of Wuhan University of Technology(grant numbers:2018-YS-068); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9075295","Data visualization;graphics processing unit (GPU);parallel computing;trajectory compression;vessel trajectory","Trajectory;Data visualization;Graphics processing units;Internet of Things;Artificial intelligence;Industries;Acceleration","","78","","75","IEEE","21 Apr 2020","","","IEEE","IEEE Journals"
"IoT-Based Big Data Secure Management in the Fog Over a 6G Wireless Network","C. L. Stergiou; K. E. Psannis; B. B. Gupta","Department of Applied Informatics, University of Macedonia, Thessaloniki, Greece; Department of Applied Informatics, University of Macedonia, Thessaloniki, Greece; Department of Computer Engineering, National Institute of Technology Kurukshetra, Haryana, India","IEEE Internet of Things Journal","24 Mar 2021","2021","8","7","5164","5171","This work proposes an innovative infrastructure of secure scenario which operates in a wireless-mobile 6G network for managing big data (BD) on smart buildings (SBs). Count on the rapid growth of telecommunication field new challenges arise. Furthermore, a new type of wireless network infrastructure, the sixth generation (6G), provides all the benefits of its past versions and also improves some issues which its predecessors had. In addition, relative technologies to the telecommunications filed, such as Internet of Things, cloud computing (CC) and edge computing (EC), can operate through a 6G wireless network. Take into account all these, we propose a scenario that try to combine the functions of the Internet of Things with CC, EC and BD in order to achieve a Smart and Secure environment. The major purpose of this work is to create a novel and secure cache decision system (CDS) in a wireless network that operates over an SB, which will offer the users safer and efficient environment for browsing the Internet, sharing and managing large-scale data in the fog. This CDS consisted of two types of servers, one cloud server and one edge server. In order to come up with our proposal, we study related cache scenarios systems which are listed, presented, and compared in this work.","2327-4662","","10.1109/JIOT.2020.3033131","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9239366","Big data (BD);cloud computing (CC);edge computing (EC);Internet of Things (IoT);management;security;sixth generation (6G);smart building (SB);wireless network","Cloud computing;6G mobile communication;Wireless networks;Servers;Internet of Things;Big Data","","198","","29","IEEE","26 Oct 2020","","","IEEE","IEEE Journals"
"Differential Contour Stellar-Based Radio Frequency Fingerprint Identification for Internet of Things","J. Li; Y. Ying; C. Ji; B. Zhang","School of Electronic and Information, Shanghai Dianji University, Shanghai, China; School of Energy and Mechanical Engineering, Shanghai University of Electric Power, Shanghai, China; School of Electronic and Information, Shanghai Dianji University, Shanghai, China; Department of Mechanical Engineering, Kanagawa University, Yokohama, Japan","IEEE Access","12 Apr 2021","2021","9","","53745","53753","Data attacks from illegal access devices of the Internet of Things will cause serious interference and threats to the entire network. It is difficult to ensure the security of the communication system only by relying on traditional application layer password authentication methods. Therefore, it is of great significance to design an effective physical layer authentication system based on radio frequency fingerprints. Regarding the issue above, this paper proposes a novel physical layer authentication method for Internet of Things based on differential contour stellar. Through the test of identification and authentication of 20 WiFi network card devices from same manufacturer, same type and same batch, the recognition accuracy rate can reach 98.6% by the proposed method. The proposed method can improve the effect of radio frequency fingerprint identification from three aspects: i. The differential processing can effectively reduce the negative influence of phase rotation caused by carrier frequency offset and Doppler effects; ii. The color processing can effectively reduce the negative influence of random noise caused by channel noise; iii. It is suitable for processing large-scale networks and the massive data they bring.","2169-3536","","10.1109/ACCESS.2021.3071352","National Natural Science Foundation of China(grant numbers:62076160,51806135,61603239); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9395614","Differential contour stellar;radio frequency fingerprint;physical layer authentication;fine portrait;deep convolutional neural network","Fingerprint recognition;Feature extraction;Authentication;Radiofrequency identification;Object recognition;Radio frequency;Physical layer","","7","","28","CCBY","6 Apr 2021","","","IEEE","IEEE Journals"
"CL-ME: Efficient Certificateless Matchmaking Encryption for Internet of Things","B. Chen; T. Xiang; M. Ma; D. He; X. Liao","College of Computer Science, Chongqing University, Chongqing, China; College of Computer Science, Chongqing University, Chongqing, China; Key Laboratory of Grain Information Processing and Control, College of Information Science and Engineering, Henan University of Technology, Zhengzhou, China; School of Cyber Science and Engineering, Wuhan University, Wuhan, China; College of Computer Science, Chongqing University, Chongqing, China","IEEE Internet of Things Journal","22 Sep 2021","2021","8","19","15010","15023","The Internet of Things (IoT) is gradually stepping out of its infancy into maturity. Its widespread applications cover from tiny wearable devices to large industrial systems. Although many security solutions have been introduced to address data security and privacy problems caused by the unique characteristics of IoT, how to simultaneously achieve data confidentiality, protect the privacy of access control policy, and provide reasonable data source identification has been a challenging problem. Moreover, lacking one of the above properties may result in serious issues (e.g., leakage information and forging identity), and the situation grows steadily worse with the expansion of “things” scale. To address the above issues, we propose a new cryptographic primitive named certificateless matchmaking encryption (CL-ME), which inherits the security properties of certificateless cryptosystem and matchmaking encryption. Meanwhile, we also present two effective concrete constructions with formal security proofs based on the standard hard assumptions. The basic construction is the first instance of CL-ME based on bilinear pairing, and the enhanced construction is a pairing-free lightweight solution. Finally, we implement our proposed schemes using popular cryptography library and compare their performance with existing works. Theoretical analysis and experimental evaluations demonstrate that our proposed schemes are more suitable for IoT environment.","2327-4662","","10.1109/JIOT.2021.3073008","National Natural Science Foundation of China(grant numbers:U20A20176,62072062,61972294,61932016,61902111); Special Project on Science and Technology Program of Hubei Province(grant numbers:2020AEA013); Natural Science Foundation of Hubei Province(grant numbers:2020CFA052); Guangxi Key Laboratory of Trusted Software(grant numbers:KX202043); Wuhan Municipal Science and Technology Project(grant numbers:2020010601012187); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9403372","Certificateless;Internet of Things (IoT);lightweight;matchmaking encryption (ME);privacy preserving","Encryption;Cryptography;Access control;Security;Receivers;Data privacy;Authentication","","14","","29","IEEE","13 Apr 2021","","","IEEE","IEEE Journals"
"$f_{MAX}$ Exceeding 3 GHz in Self-Aligned Zinc-Oxide Thin-Film Transistors with Micron-Scale Gate Length","Y. Ma; S. Wagner; N. Verma; J. C. Sturm","Department of Electrical and Computer Engineering, Princeton University, Princeton, New Jersey, USA; Department of Electrical and Computer Engineering, Princeton University, Princeton, New Jersey, USA; Department of Electrical and Computer Engineering, Princeton University, Princeton, New Jersey, USA; Department of Electrical and Computer Engineering, Princeton University, Princeton, New Jersey, USA","2023 Device Research Conference (DRC)","24 Jul 2023","2023","","","1","2","Large-area electronic (LAE) metal-oxide thin-film transistors (TFTs) with $f_{T}$ and/or $f_{MAX}$ beyond 1 GHz demonstrated over recent years [1]–[3] enable critical circuits and systems towards wireless applications in Internet of Things and 5G/6G (e.g., a 1-GHz phased array for far-field radiation beam steering [4]). Since most existing approaches towards GHz TFTs rely on improved charge-carrier mobility through high-temperature deposition of semiconductors and/or submicron TFT feature size achieved by electron-beam lithography, they are incompatible with low-cost, large-area, and flex-substrate fabrication of TFTs. By additional dependence on gate resistance $R_{G}, f_{MAX}$ opens broader device engineering space to maintain large-area and flex-compatibility, and motivates $f_{MAX}$-limited circuit/system topologies [4]. Here, we show that with optimal TFT bias voltages and reduced $R_{G}$ through TFT width scaling, a record-high $f_{MAX}$ exceeding 3 GHz is achieved in self-aligned zinc-oxide (ZnO) TFTs with gate length of $\sim 1\ \mu m$, patterned by photolithography, with a maximum process temperature of ∼200 °C. A high-frequency non-quasi-static TFT model [5] is used to guide the device engineering efforts towards this result.","2640-6853","979-8-3503-2310-8","10.1109/DRC58590.2023.10186903","DARPA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10186903","","Wireless communication;II-VI semiconductor materials;Lithography;Logic gates;Zinc oxide;Mathematical models;Thin film transistors","","","","6","IEEE","24 Jul 2023","","","IEEE","IEEE Conferences"
"Measurement-based Analysis and Modeling of Channel Characteristics in an Industrial Scenario at 28 GHz","Y. Wang; T. Jiang; P. Tang; Q. Song; X. Zhao; L. Tian; J. Zhang; B. Liu","State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China","2021 IEEE 94th Vehicular Technology Conference (VTC2021-Fall)","10 Dec 2021","2021","","","1","5","Millimeter-wave technology is the key technology to support the connection and throughput of the Industrial Internet of Things (IIoT). And the channel model is the basis for the evaluation, optimization, and deployment of the wireless communication system. To model the millimeter-wave channel characteristics in the IIoT scenario, we conduct measurements in a factory-like scenario at 28 GHz. In measurements, antenna heights are set to be higher or lower than most of the metal machines, separately. Based on the collected data, we analyze the large-scale fading and small-scale fading characteristics, including path loss, delay spread (DS), and angular spread (AS). These channel characteristics are statistically modeled. The effects of antenna heights on these channel characteristics are also investigated. Furthermore, we study the distance dependence of the DS and AS.","2577-2465","978-1-6654-1368-8","10.1109/VTC2021-Fall52928.2021.9625331","National Natural Science Foundation of China(grant numbers:62031019); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9625331","IIoT;millimeter wave;28 GHz;path loss;delay spread;angular spread","Antenna measurements;Fading channels;Wireless communication;Analytical models;Vehicular and wireless technologies;Millimeter wave technology;Metals","","9","","13","IEEE","10 Dec 2021","","","IEEE","IEEE Conferences"
"Enhancement of Data Transfer Rate by Blockchain based Transmission for Internet of Things","M. K. Yadav; B. Deshpande","College of Law, IIMT University, Meerut, Uttar Pradesh, India; ISDI - School of Design & Innovation, ATLAS Skill Tech University, Mumbai, Maharashtra, India","2023 IEEE 4th Annual Flagship India Council International Subsections Conference (INDISCON)","10 Oct 2023","2023","","","1","8","The emergence of the Internet of Things (IoT) brings great opportunities to both society and the economy. Among various emerging technologies, blockchain has great potential in ensuring the reliability and security of the transmission of IoT data. The distributed ledger technology on which blockchain is founded can protect against data prone to tampering, counterfeiting, and manipulation, ultimately increasing customer confidence and trust in the information they rely upon. Blockchain based transmission systems can enable secure, near-real-time, and distributed data exchange between different types of nodes. This will allow for a safer exchange of coins and tokens, enable decentralized access control, improve traceability and transparency, enable the monetization of data and services, and create a single source of truth for IoT devices. By deploying a blockchain to discern itself from other devices and initiate trust relationships, bring the blockchain to IoT devices and specific use cases will enable a seamless end-to-end experience to the user. Additionally, the scalability of blockchain technology for the large-scale deployment of devices and services, like automated parking systems and smart cities, is another advantage that can help create a decentralized alternative to commonly used centralized systems. In this way, blockchain-enabled IoT systems are able to offer enhanced security and trust measures, improve transaction latency, ensure privacy, and reduce costs.","","979-8-3503-3355-8","10.1109/INDISCON58499.2023.10270044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10270044","IoT;Blockchain;reliability;security;data","Access control;Privacy;Distributed ledger;Smart cities;Law;Scalability;Smart homes","","","","19","IEEE","10 Oct 2023","","","IEEE","IEEE Conferences"
"Novel Cyber Incident Management System for 5G-based Critical Infrastructures","A. Polozhentsev; S. Gnatyuk; R. Berdibayev; V. Sydorenko; O. Zhyharevych","National Aviation University, Kyiv, Ukraine; National Aviation University, Kyiv, Ukraine; Almaty University of Power Energy and Telecommunication, Almaty, Kazakhstan; National Aviation University, Kyiv, Ukraine; Lesya Ukrainka Volyn National University, Lutsk, Ukraine","2023 IEEE 12th International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS)","21 Dec 2023","2023","1","","1037","1041","Modern critical infrastructure with diverse systems requires a security information and event management (SIEM) system for unified monitoring against cyber threats. This system collects log data, performs real-time analysis, flags threats, triggers alerts, and advises response strategies. Enhanced by AI, Internet of Things, and cloud technologies, modern SIEM systems have significantly improved and optimized threat detection. This research examines the functionality, basic operation, and comparative capabilities of current SIEM systems. In addition, a universal event correlation and cybersecurity incident management system was designed and studied specifically for 5G networks. Hybrid security data storage models were also developed to ensure fast search, scale with data volume, and interface with external storage. The research also formulated models for distributed data bus operation, which enables fast processing of large data streams with minimal latency and high resilience. The proposed system addresses key cybersecurity challenges and meets global standards for establishing cyber incident management systems in 5G-based critical infrastructure.","2770-4254","979-8-3503-5805-6","10.1109/IDAACS58523.2023.10348645","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10348645","SIEM;5G-based critical infrastrucute;cyber security;cyber threats","Solid modeling;Distributed databases;Data models;Threat assessment;Real-time systems;Critical infrastructure;Computer security","","","","14","IEEE","21 Dec 2023","","","IEEE","IEEE Conferences"
"Generative Adversarial Network and Auto Encoder based Anomaly Detection in Distributed IoT Networks","T. Zixu; K. S. K. Liyanage; M. Gurusamy","University of Singapore, Singapore; University of Singapore, Singapore; University of Singapore, Singapore","GLOBECOM 2020 - 2020 IEEE Global Communications Conference","15 Feb 2021","2020","","","1","7","With the advances in modern communication technologies, the application scale of Internet of Things (IoT) has evolved at an unprecedented level, which on the other hand poses threats to the IoT ecosystem. As the intrusions and malicious actions are becoming more complex and unpredictable, developing an effective anomaly detection system, considering the distributed nature of IoT networks, remains a challenge. Moreover, the lack of sufficiently large amount of data samples of IoT traffic and data privacy pose further challenges in developing a behavior-based anomaly detection system. To address these issues, we present an unsupervised hierarchical approach for anomaly detection through cooperation between generative adversarial network (GAN) and auto-encoder (AE). The problems of data aggregation and privacy preservation are addressed by reconstructing a sampling pool at a centralized controller using a collection of generators from the individual IoT networks. Then, a centralized global AE is trained and passed to individual local networks for anomaly detection after a final adaptation with the local raw data from the IoT nodes. The performance is evaluated using the UNSW Bot-IoT dataset and the results demonstrate the effectiveness of our proposed approach which outperforms other approaches.","2576-6813","978-1-7281-8298-8","10.1109/GLOBECOM42002.2020.9348244","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9348244","Anomaly Detection;Auto-Encoder;Generative Adversarial Networks;Internet of Things;Network Security","Data privacy;Generative adversarial networks;Generators;Internet of Things;Security;Global communication;Anomaly detection","","15","","21","IEEE","15 Feb 2021","","","IEEE","IEEE Conferences"
"Towards IoT Rejuvenation: a Study on HY-SRF05 Ultrasonic Sensor Ageing for Intelligent Street Pole Lamp Control in a Smart City","V. Lukaj; F. Martella; A. Quattrocchi; M. Fazio; R. Montanini; M. Villari; A. Celesti","Department of Engineering, University of Messina, Messina, Italy; Department of Engineering, University of Messina, Messina, Italy; Department of Engineering, University of Messina, Messina, Italy; Department of Mathematics, Computer, Physics and Hearth Sciences, University of Messina, Messina, Italy; Department of Engineering, University of Messina, Messina, Italy; Department of Mathematics, Computer, Physics and Hearth Sciences, University of Messina, Messina, Italy; Department of Mathematics, Computer, Physics and Hearth Sciences, University of Messina, Messina, Italy","2022 IEEE Symposium on Computers and Communications (ISCC)","19 Oct 2022","2022","","","1","8","Nowadays, the Internet of Things (IoT) is widely adopted. To push-down costs, a possible solution can be represented by the large-scale adoption of low-cost sensors that, unfortunately, present several issues including sensor ageing that may cause, over time, failures in IoT systems due to erroneous collected data. In our opinion, a possible solution is IoT rejuvenation, a proactive cost-effective technique that can contrast the inevitable ageing of IoT systems guaranteeing the accuracy of collected data over time. Specifically, the purpose of this paper is to experimentally demonstrate the seriousness of the IoT ageing issue. To achieve such a goal, we consider a smart city scenario including intelligent street pole lamps equipped with low-cost ultrasonic sensors able to switch on lights when a vehicle is detected. Moreover, we pave the way toward IoT rejuvenation by discussing the perspectives of a Function as a Service (FaaS) based approach acting at the Edge.","2642-7389","978-1-6654-9792-3","10.1109/ISCC55528.2022.9912765","AIM(grant numbers:1852923); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9912765","IoT rejuvenation;Edge computing;sensor ageing;low-cost sensor;HY-SRF05;smart lamp;smart city","Systematics;Smart cities;Transfer functions;Aging;Sensor phenomena and characterization;Acoustics;Sensor systems","","4","","18","IEEE","19 Oct 2022","","","IEEE","IEEE Conferences"
"A Blockchain-Assisted Authentication for SDN-IoT Network Using Smart Contract","B. Bargayary; N. Medhi","Computer Science and Engineering, Tezpur University, Tezpur, Assam, India; Computer Science and Engineering, Tezpur University, Tezpur, Assam, India","2023 4th International Conference on Computing and Communication Systems (I3CS)","22 May 2023","2023","","","1","6","The Internet of Things (IoT) is a rapidly growing technology due to the demand for automation in various industries, such as healthcare, manufacturing, and home automation etc. As IoT devices continue to proliferate, authentication and access control remain a major challenge. By verifying the identity of the device and the user, authentication helps prevent fraudulent activities and ensure that the IoT data is not tampered with. The existing works are dependent on a centralized server which can become overwhelmed by large users, making them difficult to scale. In this work, we greatly utilize the characteristics of Blockchain to authenticate the user in the Software-Defined Network based IoT (SDN-IoT) network. The SDN provides centralized management of growing IoT devices. Blockchain is a decentralised and tamper-proof method for storing and sharing authentication information making it suitable for the system. We generate a digital token for each device access request through Smart Contract. The token manager on the Smart Contract validates the token for each user before giving access to it. The Smart Contract can revoke the token on unsuccessful authentication from the user to avoid an attack on the system. We conduct an experiment on the potency of the proposed work by testing the Smart Contract based on authentication delay, transaction cost and ability to resist the attack. The experiment result shows that the proposed work is a promising solution for authentication in SDN-IoT networks.","","979-8-3503-2377-1","10.1109/I3CS58314.2023.10127386","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10127386","Authentication;Blockchain;Internet-of-Thing;Smart Contract;Software-Defined Networking;Token","Access control;Scalability;Smart contracts;Authentication;Resists;Blockchains;Internet of Things","","1","","16","IEEE","22 May 2023","","","IEEE","IEEE Conferences"
"Distributed Manufacturing in Knitting Industry","L. Li; P. Sun; J. Lu","School of Automation, Southeast University, Nanjing, China; Institute of Knitting Ningbo Cixing Co., Ltd., Ningbo, China; College of Science and Technology, Ningbo University, Ningbo, China","2021 IEEE 1st International Conference on Digital Twins and Parallel Intelligence (DTPI)","22 Sep 2021","2021","","","1","4","Knitwear is the second largest product category in the traditional clothing industry. The traditional clothing product supply chain is difficult to meet consumer's demand of fast fashion. AI and industrial Internet technology, together with intelligent knitting equipments make C2M flexible supply chain possible through digitization. Distributed cloud factory is built as regional node of production supported by digital twin and parallel intelligence. Personalized needs of end consumers can be quickly responded, and the cost is close to traditional large-scale assembly line. Parallel manufacturing applies industrial robots, Internet of things, cloud computing, AR and AI technologies comprehensively to build virtual factory in Cloud that carries out decision-making and management simultaneously, with highly automated production equipments in workshop. Meanwhile, it combines with smart knitting factories to build a global distributed collaborative production management platform based on parallel manufacturing architecture system through virtual reality interaction, distributed manufacturing, managed and controlled through Cloud. Intelligent upgrading of traditional knitting industry can effectively improve labor productivity, reduce production cost and number of employees.","","978-1-6654-3337-2","10.1109/DTPI52967.2021.9540079","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9540079","Distributed manufacturing;knitting industry;parallel intelligence;large-scale flexible production","Productivity;Cloud computing;Costs;Digital twin;Conferences;Supply chains;Collaboration","","","","22","IEEE","22 Sep 2021","","","IEEE","IEEE Conferences"
"On-Demand Sensing and Wireless Power Transfer for Self-Sustainable Industrial Internet of Things Networks","W. Ejaz; M. Naeem; S. Zeadally","Department of Electrical Engineering, Lakehead University, Barrie, ON, Canada; COMSATS University Islamabad, Wah Campus,, Rawalpindi, Pakistan; College of Communication and Information, University of Kentucky, Lexington, KY, USA","IEEE Transactions on Industrial Informatics","12 Jul 2021","2021","17","10","7075","7084","On-demand data sensing and wireless power transfer (WPT) can provide sustainability and robust operations in large-scale industrial Internet of Things (IoT) networks. The efficiency of on-demand data collection and WPT can be increased by efficient scheduling of IoT nodes and dedicated energy transmitters respectively. In this article, we propose an energy-aware mode switching strategy to enable IoT nodes to perform either on-demand sensing or dedicated WPT. For on-demand sensing, we propose an IoT node scheduling scheme to maximize the utility of the IoT nodes comprising residual energy and energy required for sensing operation while considering the reliability of sensing tasks. For WPT, we propose an energy transmitter scheduling scheme for IoT nodes to minimize the cost of charging while keeping IoT nodes sufficiently charged. The simulation results for IoT node scheduling demonstrate that less than 50% IoT nodes need to be activated in all scenarios to complete the tasks. The proposed energy transmitter scheduling scheme shows that less than 60% energy transmitters should be scheduled in all the scenarios which results in significant energy reduction in the overall system.","1941-0050","","10.1109/TII.2020.3025510","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9204414","Internet of Things (IoT);mobile edge computing (MEC);on-demand sensing;wireless power transfer (WPT)","Transmitters;Sensors;Job shop scheduling;Optimization;Reliability;Internet of Things;Wireless sensor networks","","20","","25","IEEE","22 Sep 2020","","","IEEE","IEEE Journals"
"FastIoTBot: Identifying IoT Bots by Fast Detecting Anomalous Domain Queries with Long Short-Term Memory Networks","R. Li; L. Yin; Y. Zhang; K. Qian; X. Luo","School of Cyberspace Security, Guangzhou University, Guangzhou, China; School of Cyberspace Security, Guangzhou University, Guangzhou, China; School of Cyberspace Security, Guangzhou University, Guangzhou, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Cyberspace Security, Guangzhou University, Guangzhou, China","2023 3rd International Conference on Consumer Electronics and Computer Engineering (ICCECE)","2 Jun 2023","2023","","","329","335","Along with the progression in technology, Internet of Things (IoT) has been dramatically developed in recent ten years. It connects physical world and digital world, which makes people's life more convenient. However, IoT devices have bring great vulnerability to Internet security since they usually under weak protection, which makes them easy to be exploited by criminals to launch multiple attacks. In fact, IoT devices have been a crucial part of botnets that launch horrible Distributed Denial of Service (DDoS) with explosive traffic. Unfortunately, traditional detection works have limited effectiveness face IoT botnets because of the restricted resources of IoT devices and unprecedented huge scale of IoT botnets. To mitigate the threat of IoT botnets, in this paper, we propose a lightweight system, named FastIoTBot, to discover compromised IoT devices in a fast way. FastIoTBot can distinguish compromised IoT devices instantly and prevent potential malicious behaviors by examining domain query activities. Specifically, FastIoTBot monitors the DNS query for a device and generates its NXDOMAIN query sequence. Then, for each domain in the sequence, FastIoTBot takes the domain name string as input and calculates its malicious score using long short-term memory (LSTM) model. Finally, FastIoTBot identifies compromised IoT devices through analyzing NXDOMAIN sequences with internal domains' malicious score leveraging threshold random walk (TRW) algorithm. The effectiveness of FastIoTBot is evaluate with real world DNS data of two large ISP networks. The results show that FastIoTBot perform well with over 99% accuracy.","","979-8-3503-3157-8","10.1109/ICCECE58074.2023.10135366","National Key R&D Program of China(grant numbers:2022YFB3104100); National Science Foundation of China(grant numbers:62102109); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10135366","component;botnet;domain generation algorithm;NXDomain queries;LSTM;threshold random walk","Performance evaluation;Botnet;Prototypes;Real-time systems;Internet of Things;Computer crime;Monitoring","","","","23","IEEE","2 Jun 2023","","","IEEE","IEEE Conferences"
"Service Function Chain Deployment Using Deep Q Learning and Tidal Mechanism","J. Xu; X. Cao; Q. Duan; S. Li","College of Computer Science and Technology, China University of Petroleum (East China), Qingdao, China; College of Computer Science and Technology, China University of Petroleum (East China), Qingdao, China; Information Sciences and Technology Department, The Pennsylvania State University, Abington, PA, USA; College of Oceanography and Space Informatics, China University of Petroleum (East China), Qingdao, China","IEEE Internet of Things Journal","24 Jan 2024","2024","11","3","5401","5416","With the rapid development of software-defined networking/network function virtualization (NFV) technologies, service function chaining (SFC) has become a key enabler for end-to-end service provisioning in future networks. In the Internet of Things (IoT), the highly dynamic nature of the network environment demands flexible and adaptive mechanisms for dynamic SFC deployment to fully utilize network resources while meeting the service requirements. Although reinforcement learning (RL) techniques offer a promising approach to dynamic SFC deployment, the learning delay of RL may limit its prompt response to sudden changes in network state and/or service demand. To address this challenge in this article, we propose to employ a deep  $Q$ -learning network (DQN) method for dynamic SFC deployment combined with a tidal virtual machine (TVM) control mechanism for adaptive virtual machine (VM) auto-scaling. We present a tidal DQN framework (TDQNF) that integrates the DQN method and TVM control in the ETSI NFV architecture and develop the algorithms for implementing DQN-based decisions for SFC deployment and TVM control for VM scaling. The performance of the TDQNF framework with the proposed algorithms has been evaluated through extensive simulation experiments. The obtained experimental results verify the effectiveness of the proposed scheme and indicate better performance in terms of system delay, packet loss, and load balancing in large-scale networks compared to existing methods.","2327-4662","","10.1109/JIOT.2023.3306737","National Natural Science Foundation of China(grant numbers:61972417); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10225044","Deep reinforcement learning (DRL);network function virtualization (NFV);service function chain;virtual network function (VNF) deployment;virtualized network function","Service function chaining;Heuristic algorithms;Internet of Things;Dynamic scheduling;Costs;Q-learning;Delays","","","","49","IEEE","21 Aug 2023","","","IEEE","IEEE Journals"
"Cooperative Computation Offloading for Multi-Access Edge Computing in 6G Mobile Networks via Soft Actor Critic","C. Sun; X. Wu; X. Li; Q. Fan; J. Wen; V. C. M. Leung","Big Data & Software Engineering, Chongqing University, 47913 Chongqing, Chongqing, China, (e-mail: c.sun@cqu.edu.cn); Electronic Engineering, The Chinese University of Hong Kong, 26451 Hong Kong, Hong Kong, Hong Kong, (e-mail: xwwu@ee.cuhk.edu.hk); Big Data & Software Engineering, Chongqing University, 47913 Chongqing, Chongqing, China, 401331 (e-mail: lixiuhua@cqu.edu.cn); Big Data & Software Engineering, Chongqing University, 47913 Chongqing, Sichuan, China, (e-mail: fanqilin@cqu.edu.cn); Big Data & Software Engineering, Chongqing University, 47913 Chongqing, Sichuan, China, (e-mail: jhwen@cqu.edu.cn); Electrical and Computer Engineering, University British Columbia, Vancouver, British Columbia, Canada, V6T 1Z4 (e-mail: vleung@ece.ubc.ca)","IEEE Transactions on Network Science and Engineering","","2021","PP","99","1","1","Driven by numerous emerging services and applications of mobile devices, multi-access edge computing (MEC) is regarded as a promising technique for massive Internet of Things (IoT) with 6G mobile networks to alleviate core network congestion and reduce service latency. However, the conventional MEC suffers from the infrastructure without the cloud server (CS) and cooperation of multiple edge servers (ESs), which cannot deal with the large-scale computation tasks in the ultra-dense smart environments. This paper investigates the issue of the cooperative computation offloading for MEC in the 6G era. The proposed MEC system allows the cooperation of edge-cloud and the cooperation of edge-edge to address the limitation of single ES and the nonuniform distribution of computation task arrival among multiple ESs. To support low-latency services, we model the cooperative computation offloading problem as a Markov decision process, and propose two intelligent computation offloading algorithms based on Soft Actor Critic (SAC), i.e., centralized SAC offloading and decentralized SAC offloading. Evaluation results show that the proposed algorithms outperform the existing computation offloading algorithms in terms of service latency.","2327-4697","","10.1109/TNSE.2021.3076795","Chongqing Research Program of Basic Research and Frontier Technology(grant numbers:cstc2019jcyj-msxmX0589); National Key Research and Development Program of China(grant numbers:2018YFB2100100,2018YFF0214700); Fundamental Research Funds for the Central Universities(grant numbers:2020CDJQY-A022); National NSFC(grant numbers:61672117,61902044,62072060); Key Research Program of Chongqing Science Technology Commission(grant numbers:CSTC2017jcyjBX0025,CSTC2019jscx-zdztzxX0031); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9420264","Multi-access edge computing;6G;cooperative computation offloading;service latency;Soft Actor Critic","Task analysis;6G mobile communication;Edge computing;Cloud computing;Computer architecture;Servers;Resource management","","40","","","IEEE","30 Apr 2021","","","IEEE","IEEE Early Access Articles"
"Calibration of digital 3-axis MEMS accelerometers: A double-blind «multi-bilateral» comparison","A. Schiavi; A. Prato; F. Mazzoleni; G. D'Emilia; A. Gaspari; E. Natale","Division of Applied Metrology and Engineering, INRiM - National Institute of Metrological Research, Turin, Italy; Division of Applied Metrology and Engineering, INRiM - National Institute of Metrological Research, Turin, Italy; Division of Applied Metrology and Engineering, INRiM - National Institute of Metrological Research, Turin, Italy; Department of Industrial and Information Engineering and of Economics, University of L'Aquila, L'Aquila, Italy; Department of Industrial and Information Engineering and of Economics, University of L'Aquila, L'Aquila, Italy; Department of Industrial and Information Engineering and of Economics, University of L'Aquila, L'Aquila, Italy","2020 IEEE International Workshop on Metrology for Industry 4.0 & IoT","10 Jul 2020","2020","","","542","547","Nowadays, digital sensors based on MEMS/NEMS technology, are produced in very huge quantities by manufacturers. Beyond typical applications, e.g., in the predominant market of smartphones, these sensors began to be largely used in a wide range of monitoring systems and survey, in applied engineering and in advanced application, such as Internet of Things (IoT) and Industry 4.0. In these technological applications, accuracy and reliability of digital MEMS sensors, are emerging quality attributes of interest, allowing to improve, in general terms, the management of processes under investigation, on the basis of high data quality. On the other hand, quality of measurements data depends on a specific metrological characterization, in terms of traceability and accuracy. Although some methods and procedures for the digital MEMS sensors calibration, as well as proper sensitivity parameters for digital output, are nowadays available, it is not possible to calibrate every single device, but it is necessary to define suitable protocols of sampling, in order to deliver statistically acceptable levels of performance and reliability while reducing manufacturing costs. In this paper a double-blind «multi-bilateral» comparison on large-sample scale of 25 digital MEMS accelerometers calibration data, is carried out and results are discussed.","","978-1-7281-4892-2","10.1109/MetroInd4.0IoT48571.2020.9138215","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138215","calibration;digital sensors;MEMS accelerometer;inter-laboratory comparison","Micromechanical devices;Accelerometers;Sensitivity;Transducers;Systematics;Sensor phenomena and characterization;Calibration","","11","","18","IEEE","10 Jul 2020","","","IEEE","IEEE Conferences"
"Novel Elastomer Vibration Sensor for Machine Health-Monitoring Applications","S. Asutkar; M. Korrapati; D. Gupta; S. Tallur","Department of Electrical Engineering, Indian Institute of Technology (IIT) Bombay, Mumbai, India; IITB-Monash Research Academy, Indian Institute of Technology Bombay, Mumbai, India; Department of Metallurgical Engineering & Materials Science, Indian Institute of Technology (IIT) Bombay, Mumbai, India; Department of Electrical Engineering, Indian Institute of Technology (IIT) Bombay, Mumbai, India","IEEE Sensors Letters","22 Oct 2020","2020","4","11","1","4","Condition-based maintenance strategies for monitoring the state of health of machinery utilize vibration sensors as early indicators of anomalous operation. Large-scale deployment of commercially available vibration sensors for such Internet of Things (IoT) applications is cost-prohibitive. We present an elastomer-based vibration sensor prepared using a low-cost sensor synthesis process with performance suitable for machine health-monitoring applications. A water-soluble polyvinyl alcohol mold manufactured using 3D printer is used to cast a polydimethylsiloxane matrix that is subsequently coated with conductive elastomeric ink to impart piezoresistivity to the sensor. The 3D printing process used for manufacturing the mold allows control over its pore size and could be used to tune the stiffness and sensitivity of the sensor. Through electro-mechanical characterization experiments baselined with a reference micro-electromechanical systems accelerometer (ADXL335), we demonstrate the capability of this elastomer sensor to discern change in vibration spectrum of a motor due to fault introduced in inner race of the motor bearing.","2475-1472","","10.1109/LSENS.2020.3030804","Indian Institute of Technology Bombay(grant numbers:RD/0517-IRCCSH0-014); Indian Space Research Organisation(grant numbers:RD/0119-ISROC00-018); Department of Science and Technology Government of India(grant numbers:IMP/2019/000237); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222521","Mechanical sensors;elastomer vibration sensor;machine health monitoring;PDMS;Internet of Things (IoT)","Vibrations;Ink;Sensor phenomena and characterization;Accelerometers;Monitoring;Sensitivity","","8","","31","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"A Novel Approach for Predicting wide range of traffic congestion using deep learning Technique","A. N. Gnana Jeevan; K. Keerthika; S. Rao Terli; S. T. Naitik; K. G. S. Venkatesan; G. Manikandan","Lecturer, Department of Computer Engineering, Seshasayee Institute of Technology, Tiruchirappalli, Tamil Nadu, India; Assistant Professor, Department of Computer Science and Engineering, Karpagam College of Engineering, Coimbatore, Tamilnadu, India; Department of Computer Science and Engineering, Gitam Institute of Technology, Visakhapatnam, Andhra Pradesh, India; Assistant Professor, Department of Computer Science and Engineering, KLS Gogte Institute of Technology, Karnataka, India; Professor, Department of Computer Science and Engineering, MEGHA Institute of Engg& Tech for Women, Hyderabad, Telengana, India; Assistant Professor, Department of Electronics and Communication Engineering, Saveetha School of Engineering, Saveetha Institute of Medical and Technical Sciences, Chennai","2022 International Conference on Innovative Computing, Intelligent Communication and Smart Electrical Systems (ICSES)","14 Oct 2022","2022","","","1","6","Identifying traffic bottlenecks and devising solutions to the problem requires researchers and practitioners in transportation to understand how congestion in one place impacts the rest of the network. The dynamics of traffic congestion are often modelled using mathematical equations or simulation approaches. Most methods have flaws, such as unreliable assumptions and a time-consuming parameter calibration procedure. For example, ITS and the Internet of Things (IoT) have facilitated the collection of transportation data. This sets off a chain reaction of data-driven investigations into transportation anomalies.Deep learning theory is a potential technique for dealing with big, multidimensional datasets. For this research, deep learning theory will be used to analyze large-scale transportation networks. Recurrent Neural Networks and Restricted Boltzmann Machines are used to model and forecast the evolution of traffic congestion based on the GPS data from a cab. Numerical research was carried out in Delhi, India, to verify the method's efficacy and efficiency. Using a GPU-based parallel computing system, the forecast's accuracy might reach 88% in as little as six minutes. Congestion evolution trends are displayed using a map-based platform to identify weak links for proactive congestion reduction.","","978-1-6654-7413-9","10.1109/ICSES55317.2022.9914313","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9914313","","Deep learning;Training;Transportation;Telecommunication traffic;Predictive models;Prediction algorithms;Mathematical models","","6","","19","IEEE","14 Oct 2022","","","IEEE","IEEE Conferences"
"Multi-Level Distributed Caching on the Blockchain for Storage Optimisation","J. W. Heo; A. Dorri; R. Jurdak","School of Computer Science Queensland University of Technology, Brisbane, Australia; School of Computer Science Queensland University of Technology, Brisbane, Australia; School of Computer Science Queensland University of Technology, Brisbane, Australia","2022 IEEE International Conference on Blockchain and Cryptocurrency (ICBC)","29 Jun 2022","2022","","","1","5","Blockchain has attracted considerable attention as a solution to the challenges of privacy, security and decentralisation for many applications. However, these characteristics of the blockchain result in ever growing ledger size, which is one of the major barriers to blockchain adoption in large-scale networks such as the Internet of Things (IoT). In this paper, we propose Multi-Level Distributed Caching (MLDC) for blockchain storage optimisation which reduces data replication based on data access pattern. MLDC divides nodes into storage classes (SCs) by their node availability, and assigns each SC a different Access Frequency (AF) to remove data from the local storage. Over time, each node only stores frequently accessed data, so MLDC can reduce the total storage cost by 83% compared to conventional blockchain systems, while maintaining blockchain consistency and data availability with a slight increase in network overhead and data query delay.","","978-1-6654-9538-7","10.1109/ICBC54727.2022.9805518","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9805518","Blockchain;Internet of Things (IoT);Storage optimisation;Distributed caching","Privacy;Costs;Conferences;Frequency conversion;Blockchains;Delays;Cryptocurrency","","4","","17","IEEE","29 Jun 2022","","","IEEE","IEEE Conferences"
"On the Effects of Channel Aging in D2D Two-Way Relaying with Space-Constrained Massive MIMO","J. Qian; C. Masouros","The Department of Electronic and Electrical Engineering, University College London, London; The Department of Electronic and Electrical Engineering, University College London, London","2020 IEEE Globecom Workshops (GC Wkshps","5 Mar 2021","2020","","","1","6","This paper studies the spectral efficiency (SE) of a space-constrained multi-pair two-way massive multiple-input multiple-output (MIMO) decode-and-forward (DF) relay system with channel aging for device-to-device (D2D) communications in the Internet of Things (IoT) environments. Maximum ratio combining-Maximum ratio transmission (MRC/MRT) processing is employed at the relay and imperfect channel estimation is assumed. With the consideration of the spatial correlation due to insufficiently spaced antennas, and the time correlation due to channel aging, we study the closed-form large-scale approximations of the SE performance. Our analytical studies and performance results demonstrate that a degree of both spatial correlation due to antenna proximity, and time correlation due to channel aging can be tolerated in the massive MIMO regime without significant performance degradation.","","978-1-7281-7307-8","10.1109/GCWkshps50303.2020.9367524","Engineering and Physical Sciences Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9367524","Channel aging;Decode-and-forward relaying;D2D communications;maximum ratio combining/transmission;spatial correlation;spectral efficiency","Correlation;Spectral efficiency;System performance;Channel estimation;Massive MIMO;Aging;Device-to-device communication","","1","","19","IEEE","5 Mar 2021","","","IEEE","IEEE Conferences"
"A smart-and-connected low-cost sensor system for measuring air and soil properties in the Central U.S.: first results","Z. Ru; J. Wang; S. Kuhl; L. C. Garcia; X. Qiao; D. Reed","Iowa Technology Institute (ITI), The University of Iowa, Iowa City, IA, USA; ITI & Chemical & Biochemical Eng, The University of Iowa, Iowa City, IA, USA; Protostudios, The University of Iowa, Iowa City, IA, USA; Iowa Technology Institute (ITI), The University of Iowa, Iowa City, IA, USA; Biological Systems Engineering Department, University of Nebraska-Lincoln, Scottsbluff, NE, USA; Elect & Computer Engineering Department, University of Utah Salt, Lake City, UT, USA","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","5720","5723","This article describes the design and development of a smart-and-connected low-cost Iowan-designed canopy (I-Canopy) sensor system that is enabled by the Internet of Things (IoT) devices capabilities, empowered by solar-based rechargeable batteries, and developed for community science applications. The I-Canopy sensor, is designed for real-time monitoring of near-surface air properties (temperature, relative humidity, pressure) and soil properties (temperature and moisture) for a wide range of weather and canopy conditions. The sensor is well suited for rural areas where the real-time data of air and soil is lacking in part due to the lack of broadband internet connection, and in part due to the limited (if any) ground-based weather stations in the current federal and state observation network. The canopy sensor has been tested in rural communities in western Nebraska to provide information for farmer's decision-making of irrigation and agricultural water use in the crop growing season. The sensor is capable to transmit data through both WiFi and LoRaWAN in real-time to a cloud data server and the local data server. Presented here are the first results of the sensor design and sensor data evaluation in various out-door environments, which illustrates the high-level readiness of the sensor for large-scale deployment for either routine or scientific applications for rural areas.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884823","USDA National Institute of Food and Agriculture(grant numbers:2019-67021-29227); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884823","IoT;sensor network;Citizen Science;Earth and atmospheric science","Temperature sensors;Temperature distribution;Irrigation;Soil properties;Rural areas;Humidity;Real-time systems","","1","","11","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"A Survey on Physical Layer Security Schemes in Satellite Networks","G. Jang; B. You; H. Jung","Department of Electronics and Information Convergence Engineering, Kyung Hee University, Yongin-si, South Korea; Department of Electronics and Information Convergence Engineering, Kyung Hee University, Yongin-si, South Korea; Department of Electronics and Information Convergence Engineering, Kyung Hee University, Yongin-si, South Korea","2022 13th International Conference on Information and Communication Technology Convergence (ICTC)","25 Nov 2022","2022","","","1213","1215","The terrestrial and the non-terrestrial networks have been envisaged to be amalgamated to form the next generation networks. Further development in wireless communications may enable Internet of Things (IoT) to be extended to the large-scale wireless networks including satellites, which are vulnerable to both eavesdropping and malicious attacks by illegal users. In this context, physical layer security (PLS) has been attracting increasing attention on the ground of its potential to overcome those vulnerabilities with the randomness of the wireless channels. In this paper, we review the existing works on PLS in satellite communications and present the background of the satellite systems and the current challenges that need to be solved in the future.","2162-1241","978-1-6654-9939-2","10.1109/ICTC55196.2022.9952733","National Research Foundation of Korea (NRF)(grant numbers:NRF-2022R1F1A1065367,NRF-2022R1A4A3033401); IITP (Institute for Information & Communications Technology Planning & Evaluation); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9952733","IoT network;satellite communication;physical layer security","Satellites;Protocols;Array signal processing;Network topology;Wireless networks;Physical layer security;Topology","","1","","32","IEEE","25 Nov 2022","","","IEEE","IEEE Conferences"
"Multi-Dimensional Data Communication Protocols for the Physical Level of the Internet of Things Based on 5G Communication","Y. Mao","College of science, ShaoYang University, ShaoYang, China","2020 International Conference on Inventive Computation Technologies (ICICT)","9 Jun 2020","2020","","","471","474","Multi-dimensional data communication protocols for the physical level of the Internet of Things based on the 5G communication is designed in this research. 5G, B5G and future 6G communications will use large-scale antennas. The high-band wide detection technology can greatly improve the spatial resolution of the channel and increase the amount of channel information hundreds of times, and the channel difference of absolute distance is more intense as the frequency band increases and the wavelength decreases. Hence, this paper starts from the physical layer of the IoT to obtain the comprehensive analysis. The system is designed and combined with cloud computing, green communications and end-to-end low latency design. The simulations have proven the efficiency.","","978-1-7281-4685-0","10.1109/ICICT48043.2020.9112399","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9112399","5G Communication;Data Communication;Physical Level;Internet of Things;Multi-Dimensional Data","Cloud computing;Time-frequency analysis;Protocols;5G mobile communication;Computational modeling;Logic gates;Data models","","1","","20","IEEE","9 Jun 2020","","","IEEE","IEEE Conferences"
"Statistical Modeling of the Battery Recharging Time in RF Energy Harvesting for IoT Applications","A. Mouapi; N. Hakem; N. Kandil","Laboratoire de Recherche Télébec en Communications Souterraines (LRTCS), Université du Québec en Abitibi-Témiscamingue (UQAT), Val-d'Or, Canada; Laboratoire de Recherche Télébec en Communications Souterraines (LRTCS), Université du Québec en Abitibi-Témiscamingue (UQAT), Val-d'Or, Canada; Laboratoire de Recherche Télébec en Communications Souterraines (LRTCS), Université du Québec en Abitibi-Témiscamingue (UQAT), Val-d'Or, Canada","2020 IEEE International Symposium on Antennas and Propagation and North American Radio Science Meeting","17 Feb 2021","2020","","","1183","1184","Radiofrequency waves are increasingly seen as a promising solution for powering Wireless Sensor Nodes (WSN) dedicated to the Internet of Things (IoT) applications. However, by considering the RF source as a WSN power solution, Battery Recharging Time (BRT) becomes a critical performance metric, especially when the Quality of Service (QoS) is a requirement. In the literature, very few works propose an analysis of BRT based on an RF Energy Harvesting system. In this paper, the characterization of the BRT as a function of the harvestable power is analyzed, and modeling of the BRT is then proposed. The results are based on the ambient power density level measured in a building. It is obtained that the BRT undergoes as the received ambient power, a large scale fading effect shadowing more specifically the lognormal Shadowing.","1947-1491","978-1-7281-6670-4","10.1109/IEEECONF35879.2020.9330240","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9330240","IoT;BRT;lognormal Shadowing;Smart buildings","Radio frequency;Fading channels;Wireless sensor networks;Density measurement;Batteries;Internet of Things;Shadow mapping","","","","5","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"An Open Source Virtual Prototyping Platform for Electric Drive Systems","B. Ge","University of Florida, Gainesville, FL, USA","2022 IEEE Energy Conversion Congress and Exposition (ECCE)","30 Nov 2022","2022","","","1","7","Simulation of electric drive systems is usually done with commercial software nowadays. Open-source simulation platforms can be more cost-effective, especially for early-stage startups and/or in internet-of-things (IoT) scenes, where large-scale simulation capability is craved. This paper presents one such platform based on the NgSpice environment and C language. NgSpice is used for modeling power electronics and electric machines hardware, represented in electric circuits and magnetic circuits respectively. C language, interfacing with NgSpice, is used to build control algorithms at the software-in-the-loop (SIL) level and glue magnetic circuits together. Experimental results are shown to validate the effectiveness of the platform and future work is laid out to further enrich the capability of the platform.","2329-3748","978-1-7281-9387-8","10.1109/ECCE50734.2022.9947519","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9947519","electric machines;magnetic circuit;NgSpice;power electronics;simulation","Electric machines;C languages;Energy conversion;Software;Power electronics;Hardware;Virtual prototyping","","","","8","IEEE","30 Nov 2022","","","IEEE","IEEE Conferences"
"LoRaWAN Gateway Architecture for Aquaculture Monitoring in Rural Area","D. Singh; G. Sharma; I. Minhas; G. Singh; P. Mahajan; P. Verma; G. C. Manocha","Electronics and Communication Engineering department, Thapar Institute of Engineering and technology, Patiala, Punjab, India; Electronics and Communication Engineering department, Thapar Institute of Engineering and technology, Patiala, Punjab, India; Electronics and Communication Engineering department, Thapar Institute of Engineering and technology, Patiala, Punjab, India; Electronics and Communication Engineering department, Thapar Institute of Engineering and technology, Patiala, Punjab, India; Electronics and Communication Engineering department, Thapar Institute of Engineering and technology, Patiala, Punjab, India; Electronics and Communication Engineering department, Thapar Institute of Engineering and technology, Patiala, Punjab, India; Electronics and Communication Engineering department, Thapar Institute of Engineering and technology, Patiala, Punjab, India","2023 6th International Conference on Information Systems and Computer Networks (ISCON)","4 May 2023","2023","","","1","4","In fish farming, it is imperative to have detailed data about water quality, dissolved oxygen and nutrients etc., not only in large scale classic farming applications but also for urban aquaculture. To ensure the survival of the fish, the water should be monitoring at regular intervals. This periodic monitoring is cumbersome and prone to human error if done manually. Live and automated monitoring will not only save human effort but also increase the productivity of the fishing farming. This automated monitoring requires robust network connectivity to ensure live data collection using sensors and storage in cloud/server. However, for rural area the network connectivity may or may not be available. LoRaWAN is very popular Internet of Things (IoT) access network technology. In this paper, we carry out experiment to extend the network range using LoRaWAN (Long Range Wide Area Network) for live and automated aquaculture monitoring. The monitoring is done with the various sensors that collect data related to quality of water at different time and sending the data to the nearest LoRaWAN Sensor Node, which further forwards the aggregated data to LoRaWAN gateway. The LoRaWAN radio module that allows long-range wireless data transmission and low-power battery operation for several months at reasonable module costs The proposed system is evaluated in terms of transmission range, battery runtime and sensor data accuracy.","2832-143X","979-8-3503-4696-1","10.1109/ISCON57294.2023.10111936","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10111936","LoRaWAN;Gateway;Aquaculture;IoT","Cloud computing;Rural areas;Logic gates;Directive antennas;Fish;Sensors;Internet of Things","","","","17","IEEE","4 May 2023","","","IEEE","IEEE Conferences"
"Spike and Slab Prior Based Joint Sparse Channel Estimation and Multiuser Detection in MTC Communications","X. Zhang; L. Hao; J. Liu","Southwest Jiaotong University, Chengdu, China; Southwest Jiaotong University, Chengdu, China; National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China, Chengdu, China","2020 International Conference on Wireless Communications and Signal Processing (WCSP)","28 Dec 2020","2020","","","412","417","Machine-type communications (MTC) has become one of the key requirements to support Internet-of-Things (IoT) for wireless communications. Due to the fact of large-scale connectivity and low activity factor, we exploit Low-Activity Code Division Multiple Access (LA-CDMA) as the multiple access technology. In MTC communications, effective multiuser detection (MUD) algorithms are required. In previous work, a variety of MUD approaches have been designed with known channel state information (CSI). In this paper, we address the joint channel estimation (CE) and MUD problems for LA-CDMA uplink systems with unknown CSI in MTC communications. We introduce a novel spike and slab prior based Gibbs sampling (SS-GS) approach to reconstruct the signal. It is shown that the introduced spike and slab prior is more effective in promoting sparsity and sparse signal reconstruction, and the proposed SSGS scheme outperforms the conventional schemes for CE and MUD in MTC communications.","2472-7628","978-1-7281-7236-1","10.1109/WCSP49889.2020.9299766","Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9299766","","Multiuser detection;Slabs;Uplink;Gaussian distribution;Bayes methods;Machine learning algorithms;Long Term Evolution","","","","15","IEEE","28 Dec 2020","","","IEEE","IEEE Conferences"
"PM2.5 Hotspot Identification in Dakar area: An Innovative IoT and Mapping-Based Approach for Effective Air Quality Management","A. Gueye; M. S. Drame; M. Diallo; B. Ngom; D. Ndao Niang; A. Faye; S. Pusede","Department of Physics, Cheikh Anta Diop University of Dakar, Dakar, Senegal; Department of Physics, Cheikh Anta Diop University of Dakar, Dakar, Senegal; Higher Polytechnic School, Cheikh Anta Diop University of Dakar, Dakar, Senegal; Higher Polytechnic School, Cheikh Anta Diop University of Dakar, Dakar, Senegal; Higher Polytechnic School, Cheikh Anta Diop University of Dakar, Dakar, Senegal; Department of Environmental Sciences, University of Virginia, Charlottesville, USA; Department of Environmental Sciences, University of Virginia, Charlottesville, USA","2023 IEEE 9th International Conference on Smart Instrumentation, Measurement and Applications (ICSIMA)","3 Jan 2024","2023","","","302","307","Air pollution has become a major public health concern in large cities in Africa, often exceeding the recommended thresholds set by the WHO. This article introduces an innovative approach leveraging the Internet of Things (IoT) and the use of cost-effective sensors to detect areas with high concentrations of fine particles, particularly PM2.5, in Dakar, Senegal. In the context of this research, an experimental device equipped with a GPS module was deployed on a vehicle for spatiotemporal monitoring of fine particle concentrations. Through an intensive measurement campaign spanning nearly two months and covering approximately 30 routes in the Dakar region, five hotspots were clearly identified as the primary anthropogenic sources of particle pollution, such as traffic, industry, and the public landfill. The combination of this innovative approach with the use of a community-scale geographic information system will provide an even deeper understanding of the spatial distribution of pollution. This toolkit will serve as a powerful instrument for local authorities in decision-making, enabling them to implement targeted measures effectively to improve air quality at the local level.","2640-6535","979-8-3503-4338-0","10.1109/ICSIMA59853.2023.10373491","University of Virginia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10373491","Air quality;fine particles;Internet of Things (IoT);hotspots;anthropogenic sources;Geographic Information System (GIS)","Atmospheric measurements;Particle measurements;Pollution measurement;Sensors;Internet of Things;Monitoring;Geographic information systems","","","","15","IEEE","3 Jan 2024","","","IEEE","IEEE Conferences"
"Van der Waals Integrated Silicon Broadband Imagers","Y. Xu; F. Tian; S. C. Bodepudi; Z. Li; Y. Dong; X. Wang; Y. Chen; Y. Ma; J. Chai; B. Yu","School of Micro-Nano Electronics, Zhejiang University, ZJU-Hangzhou Global Scientific and Technological Innovation Center, State Key Laboratory of Silicon Materials, Zhejiang University, Hangzhou, China; School of Micro-Nano Electronics, Zhejiang University, ZJU-Hangzhou Global Scientific and Technological Innovation Center, State Key Laboratory of Silicon Materials, Zhejiang University, Hangzhou, China; School of Micro-Nano Electronics, Zhejiang University, ZJU-Hangzhou Global Scientific and Technological Innovation Center, State Key Laboratory of Silicon Materials, Zhejiang University, Hangzhou, China; School of Micro-Nano Electronics, Zhejiang University, ZJU-Hangzhou Global Scientific and Technological Innovation Center, State Key Laboratory of Silicon Materials, Zhejiang University, Hangzhou, China; School of Micro-Nano Electronics, Zhejiang University, ZJU-Hangzhou Global Scientific and Technological Innovation Center, State Key Laboratory of Silicon Materials, Zhejiang University, Hangzhou, China; School of Micro-Nano Electronics, Zhejiang University, ZJU-Hangzhou Global Scientific and Technological Innovation Center, State Key Laboratory of Silicon Materials, Zhejiang University, Hangzhou, China; School of Micro-Nano Electronics, Zhejiang University, ZJU-Hangzhou Global Scientific and Technological Innovation Center, State Key Laboratory of Silicon Materials, Zhejiang University, Hangzhou, China; School of Micro-Nano Electronics, Zhejiang University, ZJU-Hangzhou Global Scientific and Technological Innovation Center, State Key Laboratory of Silicon Materials, Zhejiang University, Hangzhou, China; School of Micro-Nano Electronics, Zhejiang University, ZJU-Hangzhou Global Scientific and Technological Innovation Center, State Key Laboratory of Silicon Materials, Zhejiang University, Hangzhou, China; School of Micro-Nano Electronics, Zhejiang University, ZJU-Hangzhou Global Scientific and Technological Innovation Center, State Key Laboratory of Silicon Materials, Zhejiang University, Hangzhou, China","2023 IEEE Nanotechnology Materials and Devices Conference (NMDC)","12 Dec 2023","2023","","","21","24","Van der Waals (vdWs) heterostructures with their extended cross-dimensional integration freedom, emerged as most appropriate choice for next-generation electronics and optoelectronics. In the post Moore era, the electronics industry is on the verge of shifting from covalent or ionic bond-dominated homo- and hetero-interfaces to vdWs integrated systems, hailed by clean interfaces free of dangling bonds and Fermi-level pinning while lodging rich device physics from confinement and gating effects. Hence, it is essential to develop devices exploiting cross-dimensional benefits, bringing the best of materials in different dimensions. One such strategy is to integrate two-dimensional (2D) materials with bulk semiconductors in the most widely used large-scale device schemes like charge-coupled devices (CCD) and complementary-metal-oxide-semiconductor (CMOS) using a flip-chip method. Taking this into consideration, we demonstrate 2D-silicon hybrid imagers with the benefits of both CCD and CMOS, showing potential for broadband, ultrafast photoresponse, viable for the period of Internet of Things (IoTs), artificial intelligence (AI), and compute-in-memory.","2473-0718","979-8-3503-3546-0","10.1109/NMDC57951.2023.10343980","Fundamental Research Funds for the Central Universities; China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10343980","","Charge coupled devices;Two dimensional displays;Silicon;Broadband communication;Internet of Things;Flip-chip devices;Artificial intelligence","","","","14","IEEE","12 Dec 2023","","","IEEE","IEEE Conferences"
"Implementation of Pump Condition Monitoring Function Based on Handheld Devices","Y. Chai; L. Yao; X. Liu","School of Electronic Engineering/School of Intelligent Manufacturing, Anhui Xinhua University, Hefei, China; School of Electronic Engineering/School of Intelligent Manufacturing, Anhui Xinhua University, Hefei, China; School of Electronic Engineering/School of Intelligent Manufacturing, Anhui Xinhua University, Hefei, China","2023 IEEE 15th International Conference on Advanced Infocomm Technology (ICAIT)","29 Dec 2023","2023","","","252","256","As a large-scale device, pump equipment is usually stored in the industrial site, with the characteristics of complex site environment and concentrated equipment location, and requires on-site inspection personnel to regularly inspect to eliminate faults. The traditional central control room uses the PC to monitor the industrial site, and there is a common problem of untimely fault feedback, so it is necessary to use handheld explosion-proof equipment to obtain the equipment status immediately. Narrowband Internet of Things (NB IoT) and Bluetooth (BT) protocols are both wireless communication protocol technologies. Due to the widespread use of Bluetooth technology in mobile devices such as smartphones, it is necessary to design command formats and implement programs based on Bluetooth technology. As a more cutting-edge technology than BT, NB technology can serve as a supplement to system data transmission due to its low power consumption and low-frequency characteristics. Therefore, the work of this article mainly revolves around these two technologies. This article first explores the similarities and differences between NB and BT protocols in pump status monitoring, and then expands on how to develop command formats for specific pump equipment status monitoring tasks. Finally, based on the format of parameter setting commands and data packet transmission commands, the writing process of mobile terminal programs was explained, and the final implementation results were provided.","2770-1603","979-8-3503-1412-0","10.1109/ICAIT59485.2023.10367300","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10367300","Bluetooth protocol;packet format;mobile implementation","Wireless communication;Protocols;Power demand;Writing;Internet of Things;Personnel;Time-domain analysis","","","","15","IEEE","29 Dec 2023","","","IEEE","IEEE Conferences"
"BOTA: Explainable IoT Malware Detection in Large Networks","D. Uhříček; K. Hynek; T. Čejka; D. Kolář","Network Security Lab, Avast Software s.r.o., Prague, Czech Republic; Security and Administration Department, CESNET z.s.p.o., Prague, Czech Republic; Security and Administration Department, CESNET z.s.p.o., Prague, Czech Republic; Department of Information Systems, FIT, Brno University of Technology, Brno, Czech Republic","IEEE Internet of Things Journal","5 May 2023","2023","10","10","8416","8431","Explainability and alert reasoning are essential but often neglected properties of intrusion detection systems. The lack of explainability reduces security personnel’s trust, limiting the overall impact of alerts. This article proposes the botnet analysis (BOTA) system, which uses the concepts of weak indicators and heterogeneous meta-classifiers to maintain accuracy compared with state-of-the-art systems while also providing explainable results that are easy to understand. To evaluate the proposed system, we have implemented a demonstration of intrusion weak-indication detectors, each working on a different principle to ensure robustness. We tested the architecture with various real-world and lab-created data sets, and it correctly identified 94.3% of infected Internet of Things (IoT) devices without false positives. Furthermore, the implementation is designed to work on top of extended bidirectional flow data, making it deployable on large 100-Gb/s large-scale networks at the level of Internet Service Providers. Thus, a single instance of BOTA can protect millions of devices connected to end-users’ local networks and significantly reduce the threat arising from powerful IoT botnets.","2327-4662","","10.1109/JIOT.2022.3228816","Ministry of Interior of the Czech Republic through Flow-Based Encrypted Traffic Analysis(grant numbers:VJ02010024); Agency of the CTU in Prague; MEYS of the Czech Republic(grant numbers:SGS20/210/OHK3/3T/18); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9983820","Detection;explainability;Internet of Things (IoT);malware;network monitoring;network security;weak indicators","Internet of Things;Botnet;Detectors;Malware;Cognition;Intrusion detection;Deep learning","","3","","74","IEEE","13 Dec 2022","","","IEEE","IEEE Journals"
"A Survey on IoT Positioning Leveraging LPWAN, GNSS, and LEO-PNT","T. Janssen; A. Koppert; R. Berkvens; M. Weyn","IDLab-imec Research Group, Faculty of Applied Engineering, University of Antwerp, Antwerp, Belgium; Engineering Research and Development, OHB Digital Solutions GmbH, Graz, Austria; IDLab-imec Research Group, Faculty of Applied Engineering, University of Antwerp, Antwerp, Belgium; IDLab-imec Research Group, Faculty of Applied Engineering, University of Antwerp, Antwerp, Belgium","IEEE Internet of Things Journal","22 Jun 2023","2023","10","13","11135","11159","Location data is an important piece of information in many Internet of Things (IoT) applications. Global navigation satellite systems (GNSSs) have been established as the standard for large-scale localization. However, the rapidly increasing need to locate IoT devices in recent years has exposed several shortcomings of traditional GNSS approaches. These limitations include the weak signal propagation in indoor and dense environments, the inability to calculate or obtain a location remotely, and a high energy consumption. Therefore, several industries have shown an increasing demand for alternative and innovative positioning solutions that are more suited in an IoT context. Hence, we conduct a survey on state-of-the-art, large-scale, and energy-efficient positioning techniques for IoT applications. More specifically, we analyze the performance of terrestrial-based low power wide area network (LPWAN) techniques, novel GNSS solutions, and innovative positioning techniques leveraging low Earth orbit (LEO) satellite constellations. A comparison is made in terms of 16 dimensions, including energy consumption, positioning accuracy, coverage, and scalability. The analysis shows that interoperability between technologies is key to enable energy-efficient communication and positioning applications in the emerging market of satellite IoT.","2327-4662","","10.1109/JIOT.2023.3243207","Fund for Scientific Research (FWO) Flanders(grant numbers:1S03821N); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10040628","Global navigation satellite system (GNSS);LEO-PNT;low power wide area network (LPWAN);satellite Internet of Things (IoT)","Internet of Things;Global navigation satellite system;Satellites;Low-power wide area networks;Low earth orbit satellites;Satellite broadcasting;Logic gates","","13","","93","CCBY","7 Feb 2023","","","IEEE","IEEE Journals"
"Distributed Computation Offloading and Trajectory Optimization in Multi-UAV-Enabled Edge Computing","X. Chen; Y. Bi; G. Han; D. Zhang; M. Liu; H. Shi; H. Zhao; F. Li","School of Computer Science and Engineering, Northeastern University, Shenyang, China; School of Computer Science and Engineering, Northeastern University, Shenyang, China; Department of Information and Communication Systems, Hohai University, Changzhou, China; School of Computer Science and Engineering, Northeastern University, Shenyang, China; School of Computer Science and Engineering, Northeastern University, Shenyang, China; School of Computer Science and Engineering, Northeastern University, Shenyang, China; School of Computer Science and Engineering, Northeastern University, Shenyang, China; School of Computer Science and Engineering, Northeastern University, Shenyang, China","IEEE Internet of Things Journal","6 Oct 2022","2022","9","20","20096","20110","The Internet of Things (IoT) technology has expanded network space by interconnected devices, which has been widely used in various fields, such as environmental monitoring, object tracking, risk warning, etc. Due to insufficient computing capacity, limited battery life, and unreliable communication environment in IoT, unmanned aerial vehicle (UAV)-enabled edge computing has been recently utilized to provide enhanced coverage and efficient computational support in the scenarios with sparse or unreliable ground infrastructure, such as disaster rescue, emergency response, military fields, etc. However, UAV-enabled edge computing faces many challenges, such as low offloading efficiency, high energy consumption, high complexity, etc. In this article, a distributed computation offloading scheme is proposed to provide computational support to large-scale IoT nodes and optimize the energy efficiency of multiple UAVs. First, to provide accurate and efficient computational support, a real-time intelligent positioning algorithm is designed to obtain the precise location information of IoT nodes. Then, a distributed computation offloading and path planning algorithm is presented, which jointly optimizes the computation offloading of large-scale IoT nodes and trajectory planning of multiple UAVs to reduce the energy consumption of UAVs. Furthermore, we develop a closed-form theoretical analysis model to demonstrate that the algorithm enables a performance guarantee related to energy efficiency. Finally, extensive simulations have been conducted and show that the proposed scheme can greatly improve the system utility and energy efficiency.","2327-4662","","10.1109/JIOT.2022.3175050","National Key Research and Development Program of China(grant numbers:2017YFE0125300,2019JSJ12ZDYF01); National Natural Science Foundation of China(grant numbers:U1808207,62171113); Fundamental Research Funds for the Central Universities of China(grant numbers:N2116002,2020GFZD014,N2124006-1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9775036","Computation offloading;edge computing;Internet of Things (IoT);trajectory optimization","Internet of Things;Task analysis;Optimization;Servers;Edge computing;Computational modeling;Energy consumption","","7","","51","IEEE","13 May 2022","","","IEEE","IEEE Journals"
"Energy Efficient Optimized Routing Technique With Distributed SDN-AI to Large Scale I-IoT Networks","P. K. Udayaprasad; J. Shreyas; N. N. Srinidhi; S. M. D. Kumar; P. Dayananda; S. S. Askar; M. Abouhawwash","Department of Artificial Intelligence and Machine Learning, Global Academy of Technology, Bengaluru, India; Department of Information Technology, Manipal Institute of Technology Bengaluru, Manipal Academy of Higher Education, Manipal, Karnataka, India; Department of Computer Science and Engineering, Manipal Institute of Technology Bengaluru, Manipal Academy of Higher Education, Manipal, Karnataka, India; Department of Computer Science and Engineering, University Visvesvaraya College of Engineering, Bengaluru, India; Department of Information Technology, Manipal Institute of Technology Bengaluru, Manipal Academy of Higher Education, Manipal, Karnataka, India; Department of Statistics and Operations Research, College of Science, King Saud University, Riyadh, Saudi Arabia; Department of Computational Mathematics, Science and Engineering (CMSE), College of Engineering, Michigan State University, East Lansing, MI, USA","IEEE Access","8 Jan 2024","2024","12","","2742","2759","Effective research has been aimed at increasing the distributed compute dependent Software Define Network (SDN) with high-level Intelligent - Internet of Things (I-IoT). Wireless sensor networks come with a set of resource restrictions. Still, only a few functions are often configured such as energy restraint and the concerted demands that are vital for IoT application routing performance. A major technique for solving the expansion of network scalability by applying Mobile Sink (MS). The construction of data transmission optimal path, the detection of an optimal set data-gathering points  $O_{DG} $  and MS scheduled with dynamic networks for energy-efficient techniques, that the network’s lifetime in enormous complications, principally in large-scale IoT networks. The research work proposes an Research Objective: i) Develop an energy-efficient routing technique for large-scale I-IoT networks within a cloud-based SDN system. ii) Optimize network scalability, lower-level routing, and load balancing using Genetic Algorithm (GA), Particle Swarm Optimization (PSO), and Artificial Bee Colony (ABC). The prime aim of cloud-based SDN with AI is to determine: a lower level routing in the perception layer, a load-balanced Cluster Table (CT), an optimal  $O_{DG} $  points, and MS optimal paths  $O_{MSpath} $ . The main contribution of proposed routing is i) Energy Minimization (EM): The proposed routing minimizes energy dissemination by the Cluster Head (CH) in critical conditions (EM-CH). ii) Enhanced Energy Balance (EEB): The EC-based SDN, considering both Optimal Data-Gathering ( $O_{DG}$ ) and Mobile Sink (MS) advancements, achieves enhanced energy balance during network routing (EEB-SDN). Research results validate the proposed model stability that improves the network lifetime up to 63%, the energy usage in the network is reduced up to 78%, the high volume data loaded to the MS up to 95%, and the delay of the  $O_{MSpath} $  by 69% when compared with various model.","2169-3536","","10.1109/ACCESS.2023.3346679","King Saud University, Riyadh, Saudi Arabia; Researchers Supporting Project number(grant numbers:RSP2024R167); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10379454","Artificial intelligence;cloud-computing;intelligent-Internet of Things;mobile sink;software defined network","Internet of Things;Routing;Artificial intelligence;Energy efficiency;Cloud computing;Robot sensing systems;Wireless sensor networks","","","","34","CCBYNCND","1 Jan 2024","","","IEEE","IEEE Journals"
"A Comparative Study of Software Architectures in Constrained Device IoT Deployments","S. du Plessis; N. Correia","CEOT, University of Algarve, Faro, Portugal; Faculty of Science and Technology, CEOT, University of Algarve, Faro, Portugal","2021 IEEE International Conference on Internet of Things and Intelligence Systems (IoTaIS)","7 Dec 2021","2021","","","35","41","The Internet of Things (IoT) is an area that has consistently seen growth and development and will no doubt continue to do so. One group of IoT devices - constrained devices - has seen significant developments in recent years. With the advent of constrained devices in almost every area of life, e.g. industrial, leisure and medical, this group of devices is well worth studying. Clearly, resource management is a critical aspect to ensure optimal use of such devices. A number of factors can have a significant impact on resource management, such as the operating system and the software architecture.This study aimed to compare the power consumption, runtime performance and memory consumption of two software architectures: microservices and monolithic. The study was conducted using a constrained device, and to ensure that the results are not language-specific, three different programming languages were used: Go, Python and C++. It was found that, for smallscale applications, the monolithic architecture performed better across most metrics. These results may provide valuable insights to engineers for the design and implementation of constrained-device IoT applications. It was recommended that additional research be conducted on larger-scale applications.","","978-1-6654-2035-8","10.1109/IoTaIS53735.2021.9628703","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9628703","Internet of Things;resource-constrained devices;software architecture;microservices;monolithic","Performance evaluation;Power demand;Runtime;Software architecture;Memory management;Microservice architectures;C++ languages","","","","18","IEEE","7 Dec 2021","","","IEEE","IEEE Conferences"
"Stochastic Analysis of Double Blockchain Architecture in IoT Communication Networks","X. Hao; P. L. Yeoh; Z. Ji; Y. Yu; B. Vucetic; Y. Li","School of Electrical and Information Engineering, The University of Sydney, Sydney, NSW, Australia; School of Electrical and Information Engineering, The University of Sydney, Sydney, NSW, Australia; School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Computer Science and Engineering, Northeastern University, Shenyang, China; School of Electrical and Information Engineering, The University of Sydney, Sydney, NSW, Australia; School of Electrical and Information Engineering, The University of Sydney, Sydney, NSW, Australia","IEEE Internet of Things Journal","7 Jun 2022","2022","9","12","9700","9711","In this article, we present practical stochastic modeling and detailed performance analysis of our double blockchain (DBC) from Hao et al. (2021) for secure information and reputation data management in large-scale wireless Internet of Things (IoT) networks. Specifically, the DBC is a private blockchain deployed on a cloud-fog communication network which is composed of an information blockchain (IBC) storing large amounts of IoT data in the cloud layer and a reputation blockchain (RBC) storing reputation data of the IoT devices in the near-terminal fog layer. The locations of the fog layer nodes are modeled according to a random Poisson point process (PPP) over a given 2-D area to approximate the stochastic property of real-world wireless node deployments. Furthermore, we assume that the number of IoT devices transmitting to the fog nodes also follow a random Poisson distribution. Based on these models, we derive novel closed-form expressions for the storage size, transmission latency, and tampering time of the IoT fog nodes in our DBC architecture. Numerical simulations highlight high storage scalability, low latency, and superior security of the DBC design, and provide insights into the performance gains for different fog node and IoT device densities.","2327-4662","","10.1109/JIOT.2022.3142761","Australian Research Council (ARC)(grant numbers:DP190100770); National Natural Science Foundation of China(grant numbers:62171113); ARC Laureate Fellowship(grant numbers:FL160100032); ARC(grant numbers:DP190101988,DP210103410); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9680687","Double blockchain (DBC);Poisson point process (PPP);trusted and secure Internet of Things (IoT) networks;wireless communications","Blockchains;Internet of Things;Interference;Stochastic processes;Smart contracts;Scalability;Security","","9","","34","IEEE","13 Jan 2022","","","IEEE","IEEE Journals"
"High-performance Machine Learning in Enabling Large-scale Load Analysis Considering Class Imbalance and Frequency Domain Characteristics","X. Wang; Q. Tang; H. Wang; R. Ma; Z. Tang","State Grid Sichuan Economic Research Institute, Chengdu, China; State Grid Sichuan Economic Research Institute, Chengdu, China; State Grid Sichuan Economic Research Institute, Chengdu, China; State Grid Sichuan Economic Research Institute, Chengdu, China; College of electrical engineering, Sichuan University, Chengdu, China","2020 IEEE Sustainable Power and Energy Conference (iSPEC)","18 Feb 2021","2020","","","2411","2416","Exploring the power consumption characteristics of user load is an urgent demand for the development of the internet of things technology in power system. This paper presents a high-performance machine learning approach in enabling large-scale load analysis considering class imbalance and frequency domain characteristics, which aims at serving the classification task for the large-scale class imbalanced load data. In order to handle the time series load data, this paper firstly employs Long Short-Term Memory (LSTM) neural network as the basic classification algorithm. Secondly, frequency domain decomposition is incorporated into the classification model to highlight the features of the input data. Thirdly, in order to solve the potential class imbalance issue which may significantly impact the network training, boundary-based data synthesis algorithm (Borderline-SMOTE) is adopted to preprocess the training data. At last, ensemble learning is employed to implement the parallelization of the presented approach using Spark to improve the efficiency of processing large-scale load data. The experimental results indicate the effectiveness of the approach in terms of classification accuracy and efficiency.","","978-1-7281-9164-5","10.1109/iSPEC50848.2020.9350922","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9350922","class imbalance;maximum overlapping discrete wavelet transform(MODWT);load classification;long-term and short-term memory network (LSTM);Spark;ensemble learning","Training;Frequency-domain analysis;Neural networks;Training data;Machine learning;Classification algorithms;Sparks","","","","20","IEEE","18 Feb 2021","","","IEEE","IEEE Conferences"
"On the Statistical Delay Performance of Large-Scale IoT Networks","M. Mei; M. Yao; Q. Yang; M. Qin; Z. Jing; K. S. Kwak; R. R. Rao","State Key Laboratory of Integrated Services Networks, School of the Telecommunication Engineering and Guangzhou Institute, Xidian University, Xi’an, China; State Key Laboratory of Integrated Services Networks, School of the Telecommunication Engineering and Guangzhou Institute, Xidian University, Xi’an, China; State Key Laboratory of Integrated Services Networks, School of the Telecommunication Engineering and Guangzhou Institute, Xidian University, Xi’an, China; School of Electronics and Computer Engineering, Peking University, and Shenzhen Pengcheng Laboratory, Shenzhen, Guangdong, China; State Key Laboratory of Integrated Services Networks, School of the Telecommunication Engineering and Guangzhou Institute, Xidian University, Xi’an, China; Graduate School of Information Technology and Telecommunications, Inha University, Nam-gu, Incheon, South Korea; Department of Electrical and Computer Engineering, San Diego State University, San Diego, CA, USA","IEEE Transactions on Vehicular Technology","16 Aug 2022","2022","71","8","8967","8979","Large-scale Internet of things (IoT) networks have shown great advantages and attracted much attention in 5G networks due to its high-speed Internet connectivity, high data rate, ultra reliability and low latency. However, the diversity of ubiquitous IoT devices and complex transmission environment lead to the difficulty of theoretical analysis of delay performance. In order to capture the characteristics of large IoT networks, a novel integrated analysis framework is developed to build the performance model and analyze the statistical delay performance in this paper. Specifically, we model the spatial distribution of IoT devices with heterogeneous Poisson point processes. With the Laplace transform of signal-to-interference-plus-noise ratio, the service capability of the wireless channel with multiple interferes is determined with a mathematical stochastic-network-calculus aided approach in the exponential domain for Poisson bipolar and cellular networks. Then, the upper bound of delay is achieved by the Mellin transform of the service incremental process. We extend our work to a $k$-tier heterogeneous network and apply the analysis results to a practical two-tier cognitive radio IoT network. Simulation results validate the theoretical analysis of delay performance with various network parameters.","1939-9359","","10.1109/TVT.2022.3175019","National Key Research and Development Program of China(grant numbers:2020YFB1807700); National Natural Science Foundation of China(grant numbers:6180011410,61801365,61671353,61971327,61901319); Natural Science Basic Research Program of Shaanxi Province of China(grant numbers:2020JQ-328); Fundamental Research Funds for the Central Universities(grant numbers:XJS210113); Shaanxi Key Project(grant numbers:2020ZDLGY05-03); Ningbo Science and Technology Bureau through Technological Innovation 2025 Major Project(grant numbers:2019B10081); China Postdoctoral Science Foundation(grant numbers:2019TQ0210,2019M663015); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9774941","Delay;Internet of Things (IoT);large-scale networks;poisson point process (PPP);stochastic network calculus (SNC)","Delays;Internet of Things;Signal to noise ratio;Queueing analysis;Performance evaluation;Analytical models;Radio transmitters","","2","","41","IEEE","13 May 2022","","","IEEE","IEEE Journals"
"Space-Time- and Frequency- Spreading for Interference Minimization in Dense IoT","I. Dey; N. Marchetti","Walton Institute for Information and Communication Sciences, Waterford, Ireland; Trinity College Dublin, Dublin, Ireland","IEEE Internet of Things Magazine","14 Mar 2023","2023","6","1","148","153","In this article, we propose a space spreading-assisted framework that leverages either {time or frequency diversity or both to reduce interference and signal loss} owing to channel impairments and facilitate the efficient operation of large-scale dense Internet-of-Things (IoT). Our approach employs dispersion of data-streams transmitted from individual IoT devices over indexed space-time (ST), space-frequency (SF) or space-time-frequency (STF) blocks. As a result, no two devices transmit on the same block; only one is activated while the rest of the devices in the network is silent, thereby minimizing possibility of interference on the transmit side. On the receive side, multiple-antenna array ameliorates performance in presence of channel impairments while exploiting array-processing gain. As interference due to superposition of multiple data-streams is killed at its root, no extra energy is wasted in fighting interference and other impairments, thereby enabling energy-efficient transmission from multiple devices over multiple access channel (MAC). To validate the proposed concept, we simulate the performance of the framework against dense IoT networks deployed in generalized indoor and outdoor scenarios in terms of probability of signal outage. Results demonstrate that our conceptualized framework benefits from interference-free transmission as well as enhancement in overall system performance.","2576-3199","","10.1109/IOTM.001.2200174","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10070405","","Performance evaluation;System performance;Interference;Minimization;Frequency diversity;Energy efficiency;Internet of Things","","1","","15","IEEE","14 Mar 2023","","","IEEE","IEEE Magazines"
"Multi-Resolution Wavelet Fractal Analysis and Subtask Training for Enhancing Few-Shot Noisy Brainwave Recognition","D. Zhang; M. Shafiq; K. Tang; U. Naseem","Cyberspace Institute of Advanced Technology, Guangzhou University, China; Cyberspace Institute of Advanced Technology, Guangzhou University, China; Cyberspace Institute of Advanced Technology, Guangzhou University, China; College of Science and Engineering, James Cook University, Australia","IEEE Journal of Biomedical and Health Informatics","","2023","PP","99","1","11","The integration of healthcare monitoring with Internet of Things (IoT) networks radically transforms the management and monitoring of human well-being. Portable and lightweight electroencephalography (EEG) systems with fewer electrodes have improved convenience and flexibility while retaining adequate accuracy. However, challenges emerge when dealing with real-time EEG data from IoT devices due to the presence of noisy samples, which impedes improvements in brainwave detection accuracy. Moreover, high inter-subject variability and substantial variability in EEG signals present difficulties for conventional data augmentation and subtask learning techniques, leading to poor generalizability. To address these issues, we present a novel framework for enhancing EEG-based recognition through multi-resolution data analysis, capturing features at different scales using wavelet fractals. The original data can be expanded many times after continuous wavelet transform (CWT) and recombination, alleviating insufficient training samples. In the transfer stage of deep learning (DL) models, we adopt a subtask learning approach to train the recognition model to generalize efficiently. This incorporates wavelets at various scales instead of exclusively considering average prediction performance across scales and paradigms. Through extensive experiments, we demonstrate that our proposed DL-based method excels at extracting features from small-scale and noisy EEG data. This significantly improves healthcare monitoring performance by mitigating the impact of noise introduced by the external environment.","2168-2208","","10.1109/JBHI.2023.3318419","National Natural Science Foundation of China(grant numbers:62250410365); Guangdong Basic and Applied Basic Research Foundation of China(grant numbers:2022A1515011542); Guangzhou Science and Technology Program of China(grant numbers:202201010606); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10261171","Healthcare monitoring;EEG;Subtask Learning;Data Augmentation","Electroencephalography;Feature extraction;Brain modeling;Wavelet transforms;Monitoring;Task analysis;Internet of Things","","","","","IEEE","22 Sep 2023","","","IEEE","IEEE Early Access Articles"
"Plant Health Monitoring System and Smart Gardening using IoT","R. N. D; A. R; D. G; G. P. S","Department of Electronics and Communication Engineering, KPR Institute of Engineering and Technology, Arasur, India; Department of Electronics and Communication Engineering, KPR Institute of Engineering and Technology, Arasur, India; Department of Electronics and Communication Engineering, KPR Institute of Engineering and Technology, Arasur, India; Department of Electronics and Communication Engineering, KPR Institute of Engineering and Technology, Arasur, India","2022 IEEE International Conference on Data Science and Information System (ICDSIS)","14 Oct 2022","2022","","","1","5","Plant heath is the scientific framework associated with controlling pest infection and pathogen intervention. This in large scale could be helpful in managing effectiveness of field or forest. The food we eat in and the cattle we grow all have close correlation with plant health. The plant health monitoring system includes chlorophyll analysis, crop density or growth analysis and nutrient analysis using image processing technique. The proposed method monitors the plant health by Chlorophyll meter is used for identifying nutrient deficiency in plants. The existing chlorophyll meter is expensive and has many disadvantages. A low-cost chlorophyll meter is implemented and it has combined assistance of internet of things. The results are compared with that of spectrophotometer and all its enhancements are highlighted. The objective is satisfied there by introduction of low cost and less complexity. The ultrasonic sensors transmit and receives waves from the target it hits. This is mounted at the top of the crop or field there by continuously monitoring the growth and indicating the periodical growth updation. The nutrition of the plant is monitored by the image processing technique, using plant image acquired from the camera. The raspberry pi board is the heart of the entire system where it controls the entire experimentation.","","978-1-6654-9801-2","10.1109/ICDSIS55133.2022.9915830","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9915830","Raspberry pi. Plant Health Monitoring;Nutrition and Chlorophyll.","Temperature sensors;Meters;Temperature measurement;Costs;Image processing;Crops;Cameras","","","","15","IEEE","14 Oct 2022","","","IEEE","IEEE Conferences"
"Priority-based Access Strategy for Multi-transmitter Multi-receiver Ambient Backscatter Communication System","Q. Chen; X. Zhang; J. Li; J. Zhou","Wireless Signal Processing and Network Laboratory, Beijing University of Posts and Telecommunications, Beijing, China; Wireless Signal Processing and Network Laboratory, Beijing University of Posts and Telecommunications, Beijing, China; Wireless Signal Processing and Network Laboratory, Beijing University of Posts and Telecommunications, Beijing, China; Wireless Signal Processing and Network Laboratory, Beijing University of Posts and Telecommunications, Beijing, China","2020 IEEE 91st Vehicular Technology Conference (VTC2020-Spring)","30 Jun 2020","2020","","","1","5","In large-scale Internet of Thing (IoT), ambient backscatter communication has become a new green technology of concern. At present, the research scenario on ambient backscatter communication mainly focuses on single-transmitter and single-receiver, and a few studies have multiple receivers. And backscatter system is always only allowing one transmitter-receiver pair active. However, the condition multiple transmitters communicate with multiple receivers is essential to achieve giant connection in Internet of Everything. Besides, the system with active multipair can transmit more byte and use energy more effectively. So there is an urgent need of research on multi-transmitter multi-receiver system. We propose an ambient back scatter communication system which allows multi-transmitter and multi-receiver active. This paper is devoted to studying the user association problem in such system. When studying the ambient backscatter communication system, we pay attention to the power limitation. Because the energy collected by the device is relatively small and limit communication performance. In the case of limited link budget, this paper maximized system communication capacity. A priority-based access strategy is proposed in this paper. It arranges priority to the receiver according to the power threshold and link budgets. Then, the strategy handles association problem according to receiver's priority from high to low. Simulation results show that the proposed access strategy has better convergence than the random access strategy. It achieves maximum communication capacity and suboptimal bit rate. What's more, it has low complexity.","2577-2465","978-1-7281-5207-3","10.1109/VTC2020-Spring48590.2020.9128895","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9128895","ambient backscatter communication;multiple transmitters;multiple receivers;priority;power limitation;system capacity","Lead;Radio frequency;Manganese;Voltage control","","3","","8","IEEE","30 Jun 2020","","","IEEE","IEEE Conferences"
"Hardware/Software Cooperative Design Against Power Side-Channel Attacks on IoT Devices","M. Yang; T. Ahmed; S. Inagaki; K. Sakiyama; Y. Li; Y. Hara-Azumi","School of Engineering, Tokyo Institute of Technology, Tokyo, Japan; School of Engineering, Tokyo Institute of Technology, Tokyo, Japan; School of Engineering, Tokyo Institute of Technology, Tokyo, Japan; Graduate School of Informatics and Engineering, The University of Electro-Communications, Tokyo, Japan; Graduate School of Informatics and Engineering, The University of Electro-Communications, Tokyo, Japan; School of Engineering, Tokyo Institute of Technology, Tokyo, Japan","IEEE Internet of Things Journal","","2024","PP","99","1","1","With the growth of Internet of Things (IoT) era, the protection of secret information on IoT devices is becoming increasingly important. For IoT devices, attacks that target information leakage through physical side-channels (e.g., a power side-channel) are a major threat in many use cases because IoT devices can be accessed easily by a hostile third party. However, securing resource-constrained IoT devices against side-channel attacks is a challenging issue. Generally, it is difficult to satisfy the requirements on side-channel protection while maintaining the low-power and real-time constrains of IoT devices. In this paper, we propose a hardware/software cooperative design for cryptosystems that is suitable for resource-constrained IoT devices. Combining a security-oriented processor design (i.e., an instruction set architecture definition and its architectural structure) and careful implementations of masked software implementation for cipher algorithms can effectively improve the power-performance-area (PPA) while suppressing power side-channel leakage. In our evaluation, for three ciphers (Chaskey, Simon, and AES), we demonstrate that our work is superior to state-of-the-art works (two RISC-V processors and a small-scale low-power processor) in terms of both PPA and power side-channel protection.","2327-4662","","10.1109/JIOT.2024.3355417","Japan Society for the Promotion of Science(grant numbers:KAKENHI JP20H00590); Japan Science and Technology Agency(grant numbers:AIP Acceleration Research JPMJCR20U2,FOREST Program JPMJFR216P); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10404032","Internet of Things (IoT);Hardware Security;Embedded Processor;Side-channel Attack;Constrained Devices","Ciphers;Internet of Things;Software;Side-channel attacks;Hardware;Software algorithms;Microprocessors","","","","","CCBY","18 Jan 2024","","","IEEE","IEEE Early Access Articles"
"A Methodology and Simulation-Based Toolchain for Estimating Deployment Performance of Smart Collective Services at the Edge","R. Casadei; G. Fortino; D. Pianini; A. Placuzzi; C. Savaglio; M. Viroli","Department of Computer Science and Engineering (DISI), Alma Mater Studiorum–Università di Bologna, Cesena, Italy; Department of Informatics, Modeling, Electronics and Systems, Università della Calabria, Rende, Italy; Department of Computer Science and Engineering (DISI), Alma Mater Studiorum–Università di Bologna, Cesena, Italy; Department of Computer Science and Engineering (DISI), Alma Mater Studiorum–Università di Bologna, Cesena, Italy; Institute for High Performance Computing and Networking (ICAR), National Research Council, Rende, Italy; Department of Computer Science and Engineering (DISI), Alma Mater Studiorum–Università di Bologna, Cesena, Italy","IEEE Internet of Things Journal","6 Oct 2022","2022","9","20","20136","20148","Research trends are pushing artificial intelligence (AI) across the Internet of Things (IoT)–edge–fog–cloud continuum to enable effective data analytics, decision making, as well as the efficient use of resources for QoS targets. Approaches for collective adaptive systems (CASs) engineering, such as aggregate computing, provide declarative programming models and tools for dealing with the uncertainty and the complexity that may arise from scale, heterogeneity, and dynamicity. Crucially, aggregate computing architecture allows for “pulverization”: applications can be decomposed into many deployable micromodules that can be spread across the ICT infrastructure, thus allowing multiple potential deployment configurations for the same application logic. This article studies the deployment architecture of aggregate-based edge services and its implications in terms of performance and cost. The goal is to provide methodological guidelines and a model-based toolchain for the generation and simulation-based evaluation of potential deployments. First, we address this subject methodologically by proposing an approach based on deployment code generators and a simulation phase whose obtained solutions are assessed with respect to their performance and costs. We then tailor this approach to aggregate computing applications deployed onto an IoT–edge–fog–cloud infrastructure, and we develop a corresponding toolchain based on Protelis and EdgeCloudSim. Finally, we evaluate the approach and tools through a case study of edge multimedia streaming, where the edge ecosystem exhibits intelligence by self-organizing into clusters to promote load balancing in large-scale dynamic settings.","2327-4662","","10.1109/JIOT.2022.3172470","Italian Ministero dell’Istruzione, dell’Università e della Ricerca (MIUR) PRIN 2017 Project “Fluidware”(grant numbers:2017KRC7KT); EU/MUR FSE REACT-EU PON R&I 2014–2022(grant numbers:CCI2014IT16M2OP005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9768117","Cloud services;collective services;cyber--physical systems;deployment methodology;edge intelligence;mobile and ubiquitous systems;pulverizable architectures;service middleware and platform;simulation","Aggregates;Computational modeling;Costs;Internet of Things;Programming;Computer architecture;Adaptive systems","","11","","61","CCBY","4 May 2022","","","IEEE","IEEE Journals"
"FedXPro: Bayesian Inference for Mitigating Poisoning Attacks in IoT Federated Learning","P. L. Indrasiri; D. C. Nguyen; B. Kashyap; P. N. Pathirana; Y. C. Eldar","School of Engineering, Deakin University, Waurn Ponds, VIC, Australia; Department of Electrical and Computer Engineering, The University of Alabama in Huntsville, USA; School of Engineering, Deakin University, Waurn Ponds, VIC, Australia; School of Engineering, Deakin University, Waurn Ponds, VIC, Australia; Wiezmann–Israel Institute of Technology, Haifa, Israel","IEEE Internet of Things Journal","","2023","PP","99","1","1","Federated learning (FL) has been envisioned to enable many Internet of Things (IoT) devices to perform large-scale machine learning without sharing raw data, resulting in significant privacy improvements. In a wireless IoT system, FL helps clients to secure their confidential information and achieve improved learning performance. However, the conventional FL architecture is vulnerable to Byzantine workers, possessing the potential to send malicious updates that compromise the accuracy of the global model. Previous studies have proposed various secure aggregation rules and attacker detection techniques to address this issue. However, these techniques exhibit limited effectiveness and may lead to a decrease in accuracy. To overcome these limitations, we propose a Byzantine client detection algorithm called FedXPro by combining the PC/BC-DIM neural network and Geometric Median (GM). Predictive coding (PC) is the core of the PC/BC-DIM architecture, which can perform Bayesian inference by fusing priors and likelihoods to determine posterior distributions. The GM is employed to determine the prior knowledge of legitimate clients to execute the PC/BC-DIM algorithm. During training, the framework calculates the probability distribution for a set of valid clients chosen from the GM. In testing, it attempts to reconstruct the same distribution from other clients concerning prior knowledge, and ultimately, the reconstruction power is utilized to filter the malicious clients. Our extensive simulations demonstrate the superiority of our FedXPro approach over other state-of-the-art methods in terms of accuracy, a guaranteed faster convergence rate, and attack detection under different network settings.","2327-4662","","10.1109/JIOT.2023.3334298","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10323108","Federated Learning;IoT;Byzantine;Bayesian Inference;Predictive Coding;Geometric Median","Internet of Things;Servers;Federated learning;Training;Data models;Artificial intelligence;Behavioral sciences","","","","","IEEE","20 Nov 2023","","","IEEE","IEEE Early Access Articles"
"Secure and Efficient Federated Learning Through Layering and Sharding Blockchain","S. Yuan; B. Cao; Y. Sun; Z. Wan; M. Peng","State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; James Watt School of Engineering, University of Glasgow, Glasgow, Scotland, U.K.; Zhejiang Lab, Hangzhou, Zhejiang, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China","IEEE Transactions on Network Science and Engineering","","2024","PP","99","1","15","Introducing blockchain into Federated Learning (FL) to build a trusted edge computing environment for transmission and learning has attracted widespread attention as a new decentralized learning pattern. However, traditional consensus mechanisms and architectures of blockchain systems face significant challenges in handling large-scale FL tasks, especially on Internet of Things (IoT) devices, due to their substantial resource consumption, limited transaction throughput, and complex communication requirements. To address these challenges, this paper proposes ChainFL, a novel two-layer blockchain-driven FL system. It splits the IoT network into multiple shards within the subchain layer, effectively reducing the scale of information exchange, and employs a Direct Acyclic Graph (DAG)-based mainchain as the mainchain layer, enabling parallel and asynchronous cross-shard validation. Furthermore, the FL procedure is customized to integrate deeply with blockchain technology, and a modified DAG consensus mechanism is designed to mitigate distortion caused by abnormal models. To provide a proof-of-concept implementation and evaluation, multiple subchains based on Hyperledger Fabric and a self-developed DAG-based mainchain are deployed. Extensive experiments demonstrate that ChainFL significantly surpasses conventional FL systems, showing up to a 14","2327-4697","","10.1109/TNSE.2024.3361458","National Key R&D Program of China(grant numbers:2021YFB1714100); National Natural Science Foundation of China(grant numbers:U22B2006); BUPT Excellent Ph.D. Students Foundation(grant numbers:CX2020106); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10419032","Federated learning;blockchain;direct acyclic graph;sharding;layering","Blockchains;Training;Internet of Things;Computational modeling;Computer architecture;Security;Throughput","","","","","IEEE","2 Feb 2024","","","IEEE","IEEE Early Access Articles"
"Uplink Interference and Performance Analysis for Megasatellite Constellation","H. Jia; Z. Ni; C. Jiang; L. Kuang; J. Lu","Department of Electronic Engineering and the Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, China; Tsinghua Space Center and the Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, China; Tsinghua Space Center and the Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, China; Tsinghua Space Center and the Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, China; Department of Electronic Engineering and the Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, China","IEEE Internet of Things Journal","8 Mar 2022","2022","9","6","4318","4329","Satellite communications play an important role in future Internet of Things (IoT) networks, and megasatellite constellations can further provide global coverage and high-quality services for IoT communications. In the megaconstellation, large-scale satellites are launched to enhance the capacity. However, the dense distribution of satellites brings intraconstellation interference, limiting the performance. In order to evaluate the restriction of interference caused by system parameters, such as the scale of constellation or the frequency reuse factor, we investigate uplink intraconstellation interference and performance of the megasatellite constellation. First, a multibeam polar constellation with uplink spatial frequency reuse is assumed. Then, the interference model is constructed considering the antenna gain of interfering user terminals and multibeam satellites, where the details of the satellite-fixed frequency reuse scheme and coordinates of co-frequency cells are provided. To evaluate the performance, expressions of outage probability, ergodic capacity, and sum ergodic capacity are driven. The analytical results disclose the impact of system design on the performance, and the accuracy of analysis results is obtained through extensive simulation evaluation. The results show that sum ergodic capacity achieves highest in the case of full frequency reuse for the frequency-limited constellation system, and it gets a linear growth at first but then keeps flat with a trend of fluctuating downward as the scale increases; therefore, the impact of the scale should be considered when constructing megaconstellations.","2327-4662","","10.1109/JIOT.2021.3104095","Shanghai Municipal Science and Technology Major Project(grant numbers:2018SHZDZX04); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9511625","Ergodic capacity;frequency reuse;intraconstellation interference;megaconstellation","Satellites;Interference;Internet of Things;Uplink;Analytical models;Satellite constellations;Satellite antennas","","10","","35","IEEE","11 Aug 2021","","","IEEE","IEEE Journals"
"Wrapping a NoSQL Datastore for Stream Analytics","K. Mahmood; K. Orsborn; T. Risch","Department of Information Technology, Uppsala University, Uppsala, Sweden; Department of Information Technology, Uppsala University, Uppsala, Sweden; Department of Information Technology, Uppsala University, Uppsala, Sweden","2020 IEEE 21st International Conference on Information Reuse and Integration for Data Science (IRI)","10 Sep 2020","2020","","","301","305","With the advent of the Industrial Internet of Things (IIoT) and Industrial Analytics, numerous application scenarios emerge, where business and mission-critical decisions depend upon large scale analytics of sensor streams. However, very large volumes of data from data streams generated at a high rate pose substantial challenges in providing scalable analytics from existing Database Management Systems (DBMS). While scalability can be provided by high-performance distributed datastores, due to the simple query operations, access to high-level query-based data analytics is usually limited. This work combines high-level query-based data analytics capabilities with high-performance distributed scalability by applying a wrapper-mediator approach. The Amos II extensible main-memory DBMS provides online query processing data analytics engine in front of the MongoDB distributed NoSQL datastore to support large-scale distributed data analytics over persisted data streams. Thus, the implemented system enables query-based online data stream analytics over persisted data streams stored/logged in distributed NoSQL datastores.","","978-1-7281-1054-7","10.1109/IRI49571.2020.00050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9191644","NoSQL Datastores;MongoDB;IIoT;Data Streams","Data analysis;Temperature measurement;Distributed databases;Hydraulic systems;Hydraulic drives;Control systems","","4","","30","IEEE","10 Sep 2020","","","IEEE","IEEE Conferences"
"Data statistics acceleration calculation method based on massive measuring point scene in industrial field","D. Jiang; J. Wang; X. Yang","R&D Department, Beijing NARI Digital Technology Co., Ltd., Beijing, People's Republic of China; R&D Department, Beijing NARI Digital Technology Co., Ltd., Beijing, People's Republic of China; R&D Department, Beijing NARI Digital Technology Co., Ltd., Beijing, People's Republic of China","5th International Conference on Artificial Intelligence and Advanced Manufacturing (AIAM 2023)","16 Jan 2024","2023","2023","","20","24","Energy measurement in the industrial field requires hierarchical measurement and statistics of all links in the energy use process, which is not only large in data scale, but also requires high real time performance. Based on the actual background of the above massive measurement points in the industrial Internet of Things field, a hierarchical accelerated calculation method based on statistical data is proposed, which solves the problems of traditional calculation methods such as long time consumption, large system resources occupation, and inability to meet large scale scene applications. Through the practical application in an industrial system in Hunan, it is found that the accelerated statistical calculation method reduces the statistical calculation time by more than three times, and improves the statistical calculation efficiency. In addition, the computational speed of the algorithm can increase linearly with the number of computing centers allocated.","","978-1-83953-983-1","10.1049/icp.2023.2909","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10400668","","","","","","","","16 Jan 2024","","","IET","IET Conferences"
"Multi-Channel Joint Forecasting-Scheduling for the Internet of Things","V. Rodoplu; M. Nakip; R. Qorbanian; D. T. Eliiyi","Department of Electrical and Electronics Engineering, Yaşar University, İzmir, Turkey; Polish Academy of Sciences (PAN), Institute of Theoretical and Applied Informatics, Gliwice, Poland; Luxembourg Centre for Logistics and Supply Chain Management, University of Luxembourg, Luxembourg City, Luxembourg; Department of Industrial Engineering, Izmir Bakırçay University, İzmir, Turkey","IEEE Access","11 Dec 2020","2020","8","","217324","217354","We develop a methodology for Multi-Channel Joint Forecasting-Scheduling (MC-JFS) targeted at solving the Medium Access Control (MAC) layer Massive Access Problem of Machine-to-Machine (M2M) communication in the presence of multiple channels, as found in Orthogonal Frequency Division Multiple Access (OFDMA) systems. In contrast with the existing schemes that merely react to current traffic demand, Joint Forecasting-Scheduling (JFS) forecasts the traffic generation pattern of each Internet of Things (IoT) device in the coverage area of an IoT Gateway and schedules the uplink transmissions of the IoT devices over multiple channels in advance, thus obviating contention, collision and handshaking, which are found in reactive protocols. In this paper, we present the general form of a deterministic scheduling optimization program for MC-JFS that maximizes the total number of bits that are delivered over multiple channels by the delay deadlines of the IoT applications. In order to enable real-time operation of the MC-JFS system, first, we design a heuristic, called Multi-Channel Look Ahead Priority based on Average Load (MC-LAPAL), that solves the general form of the scheduling problem. Second, for the special case of identical channels, we develop a reduction technique by virtue of which an optimal solution of the scheduling problem is computed in real time. We compare the network performance of our MC-JFS scheme against Multi-Channel Reservation-based Access Barring (MC-RAB) and Multi-Channel Enhanced Reservation-based Access Barring (MC-ERAB), both of which serve as benchmark reactive protocols. Our results show that MC-JFS outperforms both MC-RAB and MC-ERAB with respect to uplink cross-layer throughput and transmit energy consumption, and that MC-LAPAL provides high performance as an MC-JFS heuristic. Furthermore, we show that the computation time of MC-LAPAL scales approximately linearly with the number of IoT devices. This work serves as a foundation for building scalable JFS schemes at IoT Gateways in the near future.","2169-3536","","10.1109/ACCESS.2020.3038358","Project Support Commission of Yaşar University within the scope of the Scientific Research Project “Scheduling Algorithms for Wireless Communication”(grant numbers:BAP060); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9260218","Forecasting;scheduling;massive access;IoT;M2M communication","Performance evaluation;Protocols;Processor scheduling;Optimal scheduling;Logic gates;Internet of Things;Uplink","","12","","60","CCBY","16 Nov 2020","","","IEEE","IEEE Journals"
"Intelligent Network Selection Algorithm for Multiservice Users in 5G Heterogeneous Network System: Nash Q-Learning Method","M. Ma; A. Zhu; S. Guo; Y. Yang","Key Laboratory of Dependable Service Computing in Cyber-Physical-Society (Ministry of Education) and the College of Computer Science, Chongqing University, Chongqing, China; Robotics Research Center, College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China; Key Laboratory of Dependable Service Computing in Cyber-Physical-Society (Ministry of Education) and the College of Computer Science, Chongqing University, Chongqing, China; Department of Electrical and Computer Engineering, Stony Brook University, Stony Brook, NY, USA","IEEE Internet of Things Journal","26 Jul 2021","2021","8","15","11877","11890","The 5G heterogeneous network architecture integrates different radio access technologies (RATs), which will support the large-scale communication connection of massive Internet-of-Things (IoT) devices. However, as the rapid growth of IoT connections, personalized requirements of services requested and heterogeneity deepening of the network system, how to design an intelligent network selection scheme for user devices (UDs) is becoming a crucial challenge in the 5G heterogeneous network system. Most of the existing network selection methods only optimize the selection strategies from the user side or network side, which results in heavy network congestion, poor user experience, and system performance degradation. Accordingly, we propose a multiagent  $Q$ -learning network selection (MAQNS) algorithm based on Nash  $Q$ -learning, which can learn a joint optimal selection strategy to improve system throughput and reduce user blocking on the premise of ensuring the requirements of IoT services. In particular, we apply the discrete-time Markov chains to model the network selection, and the analytic hierarchy process (AHP) and gray relation analysis (GRA) are jointly utilized to obtain user preferences for each network. Finally, performance evaluation demonstrates that comparing to the existing schemes, MAQNS proposed cannot only improve system throughput and reduce user blocking but also promote user experience on average energy efficiency and delay.","2327-4662","","10.1109/JIOT.2021.3073027","National Natural Science Foundation of China(grant numbers:61772432,61772433); Natural Science Key Foundation of Chongqing(grant numbers:cstc2020jcyj-zdxmX0026); Fundamental Research Funds for the Central Universities(grant numbers:2020CDCGJSJ071,2020CDCGJSJ038,2019CDYGZD004); Zhejiang Lab(grant numbers:2021LC0AB01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9403383","Analytic hierarchy process (AHP);grey relation analysis (GRA);heterogeneous wireless networks;Nash equilibrium;Nash Q-learning;network selection","Internet of Things;5G mobile communication;Heterogeneous networks;Throughput;Delays;Wireless networks;User experience","","20","","45","IEEE","13 Apr 2021","","","IEEE","IEEE Journals"
"Millimeter-Scale Node-to-Node Radio Using a Carrier Frequency-Interlocking IF Receiver for a Fully Integrated 4 $\times$ 4 $\times$ 4 mm3 Wireless Sensor Node","L. -X. Chuo; Z. Feng; Y. Kim; N. Chiotellis; M. Yasuda; S. Miyoshi; M. Kawaminami; A. Grbic; D. Wentzloff; D. Blaauw; H. -S. Kim","Department of Electrical and Computer Engineering, University of Michigan, Ann Arbor, USA; Department of Electrical and Computer Engineering, University of Michigan, Ann Arbor, USA; Department of Electrical and Computer Engineering, University of Michigan, Ann Arbor, USA; Department of Electrical and Computer Engineering, University of Michigan, Ann Arbor, USA; Mie Fujitsu Semiconductor Ltd., Yokohama, Japan; Mie Fujitsu Semiconductor Ltd., Yokohama, Japan; Mie Fujitsu Semiconductor Ltd., Yokohama, Japan; Department of Electrical and Computer Engineering, University of Michigan, Ann Arbor, USA; Department of Electrical and Computer Engineering, University of Michigan, Ann Arbor, USA; Department of Electrical and Computer Engineering, University of Michigan, Ann Arbor, USA; Department of Electrical and Computer Engineering, University of Michigan, Ann Arbor, USA","IEEE Journal of Solid-State Circuits","23 Apr 2020","2020","55","5","1128","1138","Ultralow-power (ULP) mm-scale Internet-of-Things (IoT) platforms enable newly emerging applications such as pervasive agricultural monitoring and biosensing. Although there is an increasing interest in node-to-node communication as defined in Bluetooth v5.0, prior research in mm-scale wireless systems is mostly limited to asymmetric node-to-gateway communications. We present a 2.4-GHz node-to-node communication system for an ultra-small wireless sensor node fully integrated within a 4 × 4 × 4 mm3 form factor. The system integrates multiple stacked layers including an RF transceiver, a ULP processor, a photovoltaic (PV) cell, a 32-kHz crystal, and a 3-D magnetic dipole antenna. The transceiver front-end circuit is co-designed with a printed 3-D magnetic dipole antenna to form a power oscillator for the transmitter (TX) as well as a Q-enhanced amplifier (QEA) for the receiver (RX). A new carrier frequency-interlocking IF architecture successfully mitigates the TX-RX carrier frequency synchronization challenge that is critical to the mm-scale radio systems. The complete system achieves -94-dBm sensitivity with 97-μW power consumption and -12.6-dBm equivalent isotropically radiated power (EIRP). Standalone operation of a sensor node is demonstrated through bi-directional wireless communication to another sensor node over 1-m distance in real, uncontrolled wireless channels.","1558-173X","","10.1109/JSSC.2019.2959505","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8944070","Internet-of-Things (IoT);mesh wireless sensor networks;millimeter-scale sensor node;printed loop antenna;Q-enhanced amplifier (QEA);ultra-low power (ULP) RF transceiver","Dipole antennas;Wireless sensor networks;Wireless communication;Radio frequency;Logic gates;Receiving antennas","","11","","23","IEEE","27 Dec 2019","","","IEEE","IEEE Journals"
"A Real-Time IoT and Cloud System for Carbon Dioxide Monitoring in Dhaka City's Buildings with Rooftop Garden and without Rooftop Garden","M. H. I. Bijoy; A. Siddika; M. M. Rahman; M. R. Mia; F. Ahmed; F. Faisal","Department of Computer Science and Engieering, Daffodil International University, Dhaka, Bangladesh; Department of Computer Science and Engieering, Daffodil International University, Dhaka, Bangladesh; Department of Computer Science and Engieering, Daffodil International University, Dhaka, Bangladesh; Department of Electrical & Electronics, Engineering American International University - Bangladesh, Dhaka, Bangladesh; Department of Computer Science and Engieering, Daffodil International University, Dhaka, Bangladesh; Department of Computer Science and Engieering, Daffodil International University, Dhaka, Bangladesh","2022 IEEE International Conference on Signal Processing, Informatics, Communication and Energy Systems (SPICES)","16 May 2022","2022","1","","577","583","Carbon dioxide produced by fossil fuel burning, cement manufacture, and deforestation contributes greatly to the greenhouse effect, which is one of the most important consequences of industrialization. The Internet of Things (IoT), wireless communication networks and sensor devices, enables real-time tasks and data interchange in a central server with high-performance and cost-effective components. We design and develop an IoT and cloud-based system to monitor CO2 levels in the environment in two separate places in Dhaka city buildings: Rooftop Garden Area (RGA) and Normal Regular Rooftop (NRR) without a garden. The difference in carbon dioxide levels between the two sites varies throughout a number of days. The data is collected in four dayparts: Early Morning (EM), Morning (M), Noon (N), and Afternoon (AN) at three-hour intervals. The MQ-135 gas sensor monitors long-term and large-scale carbon dioxide levels, and the collected data is sent to the Firebase cloud storage using the NodeMCU ESP 8266 12E Wi-Fi module. To ensure that the internet connection is always available and that dummy values are avoided, the system in the network was continuously monitored. Data is collected at 5-minute intervals from the beginning of the morning (6:00 AM) until the end of the afternoon (6:00 PM) to obtain the most accurate value. We took 432 data row points and visualized them using a variety of comparison themes. According to the statistics, the maximum amount of CO2 in a regular rooftop was 568 PPM, whereas the maximum level of CO2 in a rooftop garden area was 443 PPM. That paper developed a very dependable real-time carbon dioxide concentration monitoring system using smart applications. The importance of rooftop gardening in buildings is also discussed in this paper. Veranda gardening on a small scale does not immediately impact the environment, but it does improve air quality and supply adequate oxygen for many people to survive. A typical rooftop's CO2 level is always higher than a rooftop with a garden area, according to our findings.","","978-1-6654-4940-3","10.1109/SPICES52834.2022.9774269","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9774269","Air Quality;CO2 Monitoring;Rooftop Garden;Internet of Things (IoT);MQ-135;NodeMCU","Wireless communication;Cloud computing;Urban areas;Buildings;Carbon dioxide;Air quality;Real-time systems","","2","","12","IEEE","16 May 2022","","","IEEE","IEEE Conferences"
"SDN-NFV-Aided Edge-Cloud Interplay for 5G-Envisioned Energy Internet Ecosystem","S. Garg; K. Kaur; G. Kaddoum; S. Guo",École De Technologie Supéneare; École De Technologie Supéneare; École De Technologie Supéneare; The Hong Kong Polytechnic University,"IEEE Network","16 Feb 2021","2021","35","1","356","364","Energy Internet (also referred to as Smart Grid 2.0) is another promising application of the Industrial Internet of Things (IIoT), for example, in the way energy is being produced, traded, distributed, and consumed. This is partly due to the lowering of barriers (e.g., costs and Internet connectivity) and advances in the underlying technologies, such as smart meters, electric vehicles, and actuators. This has also resulted in significant growth in the volume, velocity, variety, veracity, and value of data (i.e., the 5 Vs of big data). However, efficiently and effectively handling such big data remains challenging. One solution currently being explored in the literature (including industry) to cope with the increasing network traffic is to use conventional cloud infrastructure, but the key limitations of such an approach include long response time and high bandwidth consumption. Therefore, there have been attempts to introduce next-generation Internet of Things networks to satisfy (real-time) network service demands and guarantee quality of service, for example, by pushing computing capabilities closer to the users (e.g., edge of the network). However, computation-intensive energy analytics can be challenging to perform at the network edge by edge or fog computing devices. Hence, there have also been attempts to utilize software defined networking (SDN) and network function virtualization (NFV) in order to improve network functionality while adding programmability and flexibility features to the network infrastructure. Specifically, NFV facilitates virtual network function (VNF) deployment and orchestration, while SDN controls them for specific use cases. However, with the rise of next-generation mobile networks (i.e., 5G), applications and services require fast and smooth operations with greater flexibility, efficiency, and scalability. In order to align with 5G and leverage potential benefits of edge computing, VNFs should possess critical processing requirements (e.g., high throughput, low latency, and minimal computation overheads). In other words, virtualization plays an important role. To date, several techniques have been introduced in order to achieve the desired objective using virtual machines (VMs) and containers in isolation. However, a hybrid approach using VMs and containers is likely to bring potential benefits for the large-scale deployment of VNFs across the heterogeneous edge and cloud platform. Thus, in this article, a novel architecture for SDN integrated with NFV, specifically for the Energy Internet ecosystem, is presented by leveraging the advantagesof edge computing. In the considered setup, the deployment of VNFs is achieved using a mix of both virtualization and containerization. Findings from our evaluation demonstrate the potential for VNF placement across a hybrid execution setup powered by VMs, as well as the benefits of using containers.","1558-156X","","10.1109/MNET.011.1900602","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9355050","","Ecosystems;Containers;Big Data;Internet;Virtualization;Software defined networking;Edge computing","","8","","15","IEEE","16 Feb 2021","","","IEEE","IEEE Magazines"
"Internet of Things-Based Online Condition Monitor and Improved Adaptive Fuzzy Control for a Medium-Low-Speed Maglev Train System","Y. Sun; H. Qiang; J. Xu; G. Lin","College of Transportation Engineering, National Maglev Transportation Engineering R&D Center, Tongji University, Shanghai, China; Logistics Engineering College, Shanghai Maritime University, Shanghai, China; National Maglev Transportation Engineering R&D Center, Tongji University, Shanghai, China; National Maglev Transportation Engineering R&D Center, Tongji University, Shanghai, China","IEEE Transactions on Industrial Informatics","22 Jan 2020","2020","16","4","2629","2639","The maglev rail transit has entered a rapid development stage. In order to prevent potential safety hazards in the operation of maglev train, the related monitoring technology needs to be studied urgently. In this article, in view of the wide application of the Internet of Things (IoT) in intelligent transportation, a new method for realizing suspension control for medium-low-speed maglev trains using the IoT and an adaptive fuzzy controller is proposed. First, a mathematical model of the suspension system of medium-low-speed maglev trains is established. Then, the basic composition of the IoT and the circuit design of the key components of maglev trains are introduced. On this basis, an improved Apriori algorithm is used to extract the stored historical database and establish a trusted database. Then, according to the data of the trusted database, the suspension airgap control law is extracted, and the adaptive fuzzy rules of the maglev train suspension system are determined. An improved adaptive suspension controller is designed. Finally, the effectiveness of the method is verified by experiments utilizing a full-scale maglev train.","1941-0050","","10.1109/TII.2019.2938145","National Natural Science Foundation of China(grant numbers:51905380); China Postdoctoral Science Foundation(grant numbers:2019M651582); National Key Research and Development Program of China Stem Cell and Translational Research(grant numbers:2016YFB1200600); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8818315","Adaptive fuzzy control;Internet of Things (IoT);maglev train;online condition monitoring","Monitoring;Rails;Data acquisition;Informatics;Control systems;Adaptive systems","","85","","25","IEEE","28 Aug 2019","","","IEEE","IEEE Journals"
"Enabling Computational Intelligence for Green Internet of Things: Data-Driven Adaptation in LPWA Networking","C. Zhang; M. Dong; K. Ota","Advanced Institute of Industrial Technology, Tokyo Metropolitan University Public University Corporation, Tokyo, Japan; Department of Information and Electronic Engineering, Muroran Institute of Technology, Muroran, Japan; Department of Information and Electronic Engineering, Muroran Institute of Technology, Muroran, Japan","IEEE Computational Intelligence Magazine","10 Jan 2020","2020","15","1","32","43","With the exponential expansion of the number of Internet of Things (IoT) devices, many state-of-the-art communication technologies are being developed to use the lowerpower but extensively deployed devices. Due to the limits of pure channel characteristics, most protocols cannot allow an IoT network to be simultaneously large-scale and energy-efficient, especially in hybrid architectures. However, different from the original intention to pursue faster and broader connectivity, the daily operation of IoT devices only requires stable and low-cost links. Thus, our design goal is to develop a comprehensive solution for intelligent green IoT networking to satisfy the modern requirements through a data-driven mechanism, so that the IoT networks use computational intelligence to realize self-regulation of composition, size minimization, and throughput optimization. To the best of our knowledge, this study is the first to use the green protocols of LoRa and ZigBee to establish an ad hoc network and solve the problem of energy efficiency. First, we propose a unique initialization mechanism that automatically schedules node clustering and throughput optimization. Then, each device executes a procedure to manage its own energy consumption to optimize switching in and out of sleep mode, which relies on AI-controlled service usage habit prediction to learn the future usage trend. Finally, our new theory is corroborated through real-world deployment and numerical comparisons. We believe that our new type of network organization and control system could improve the performance of all green-oriented IoT services and even change human lifestyle habits.","1556-6048","","10.1109/MCI.2019.2954642","JSPS KAKENHI(grant numbers:JP16K00117); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8956107","","Internet of Things;Energy efficiency;Throughput;Optimization;Intelligent networks","","28","","39","IEEE","10 Jan 2020","","","IEEE","IEEE Magazines"
"Building an Interoperable IoT Ecosystem for Data-Driven Agriculture","K. Tržec; M. Kušek; I. P. Žarko","Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia","2022 International Conference on Smart Systems and Technologies (SST)","28 Nov 2022","2022","","","341","347","Climate change with its extreme weather conditions and the shift to organic farming pose new challenges for crop production in Europe. Continuous and dense monitoring of crop condition and environmental parameters in the fields using various Internet of Things (IoT) devices creates Big Data for data-driven agriculture and provides the opportunity to address the above challenges. However, it is extremely complex to develop a large-scale system that integrates a variety of heterogeneous data sources to provide farmers and agronomists with simple and usable tools, such as assessing current field conditions, estimating crop stress levels, or determining the best time to apply certain cultivation practice. One of the solutions of this problem is to design and implement an interoperable IoT ecosystem for data-driven agriculture that turns the data from multiple sources into knowledge, giving rise to valuable insights and appropriate decisions based on the analysis of sensor measurements delivered from IoT devices. The paper presents the architecture and design of an ecosystem for data-driven agriculture which includes a cloud-native and microservice-based IoT platform. The novel contribution of our proposed approach is the IoT platform with effective interoperability solutions for integrating different types of edge devices used in agricultural practices for continuous monitoring of agrometeorological and crop conditions, as well as with flexible means for integrating different analytical and data visualization services ensured by strict access control mechanisms.","","978-1-6654-8215-8","10.1109/SST55530.2022.9954641","European Union; European Regional Development Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9954641","smart agriculture;IoT platform;interoperability;cloud-native architecture;microservices","Soft sensors;Ecosystems;Crops;Microservice architectures;Production;Agriculture;Internet of Things","","","","33","IEEE","28 Nov 2022","","","IEEE","IEEE Conferences"
"Neural Networks for DDoS Attack Detection using an Enhanced Urban IoT Dataset","A. Hekmati; E. Grippo; B. Krishnamachari","Dept. of Computer Science, University of Southern California, Los Angeles, California, USA; Dept. of Electrical and Computer Engineering, University of Southern California, Los Angeles, California, USA; Dept. of Computer Science, University of Southern California, Los Angeles, California, USA","2022 International Conference on Computer Communications and Networks (ICCCN)","5 Sep 2022","2022","","","1","8","We investigate the application of artificial intelligence to cybersecurity, to contribute to the safe and secure growth of the internet of things (IoT). Specifically, we train and evaluate different neural networks models to detect distributed denial of service (DDoS) attacks in a large-scale IoT system. We consider futuristic attacks launched by sophisticated malicious entities that take over multiple distributed IoT nodes and are able to disguise their intrusion by closely mimicking the benign traffic of the network. Using data from prior work, we find that a truncated Cauchy distribution is a suitable fit for benign traffic volume from IoT devices, and we model the attack traffic volume as following the same distribution but with different parameters for location and scale. We emulate both benign and attack traffic by overlaying these traffic volume distributions on top of an activity status data trace from a real urban IoT deployment consisting of about 4000 nodes. Using our enhanced dataset, we compare four neural network models: multi-layer perceptron (MLP), convolutional neural network (CNN), long short-term memory (LSTM), and autoencoder (AEN), analyzing their performance as a function of a parameter that measures the deviation of the attacks from the benign data. We observe that all four models are sensitive to the distance between benign and attack traffic. We further observe that LSTM gives the best overall performance in terms of both high accuracy and high recall.","2637-9430","978-1-6654-9726-8","10.1109/ICCCN54977.2022.9868942","Defense Advanced Research Projects Agency(grant numbers:HR001120C0160); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9868942","IoT DDoS Attacks;datasets;neural networks;machine learning;botnet;Cauchy distribution","Training;Neural networks;Urban areas;Predictive models;Denial-of-service attack;Data models;Internet of Things","","3","","31","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"A Multi-Dimensional Deep Learning Framework for IoT Malware Classification and Family Attribution","M. Dib; S. Torabi; E. Bou-Harb; C. Assi","Cyber Security Research Centre, Concordia Institute for Information Systems Engineering, Montreal, QC, Canada; Cyber Security Research Centre, Concordia Institute for Information Systems Engineering, Montreal, QC, Canada; Cyber Center for Security and Analytics, University of Texas at San Antonio, San Antonio, TX, USA; Cyber Security Research Centre, Concordia Institute for Information Systems Engineering, Montreal, QC, Canada","IEEE Transactions on Network and Service Management","10 Jun 2021","2021","18","2","1165","1177","The emergence of Internet of Things malware, which leverages exploited IoT devices to perform large-scale cyber attacks (e.g., Mirai botnet), is considered as a major threat to the Internet ecosystem. To mitigate such threat, there is an utmost need for effective IoT malware classification and family attribution, which provide essential steps towards initiating attack mitigation/prevention countermeasures. In this paper, motivated by the lack of sophisticated malware obfuscation in the implementation of IoT malware, we utilize features extracted from strings- and image-based representations of the executable binaries to propose a novel multi-dimensional classification approach using Deep Learning (DL) architectures. To this end, we analyze more than 70,000 recently detected IoT malware samples. Our in-depth experiments with four prominent IoT malware families highlight the significant accuracy of the approach (99.78%), which outperforms conventional single-level classifiers. Additionally, we utilize our IoT-tailored approach for labeling newly detected “unknown” malware samples, which were mainly attributed to a few predominant families. Finally, this work contributes to the security of future networks (e.g., 5G) through the implementation of effective tools/techniques for timely IoT malware classification, and attack mitigation.","1932-4537","","10.1109/TNSM.2021.3075315","Natural Sciences and Engineering Research Council of Canada (NSERC) and Concordia University; U.S. National Science Foundation (NSF), Office of Advanced Cyberinfrastructure (OAC)(grant numbers:#1907821); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9411822","IoT malware classification;deep learning;multimodal learning;feature fusion;static malware analysis","Malware;Feature extraction;Internet of Things;Deep learning;Labeling;Security;Tsunami","","35","","45","IEEE","23 Apr 2021","","","IEEE","IEEE Journals"
"Space-Terrestrial Integrated Internet of Things: Challenges and Opportunities","J. A. Fraire; O. Iova; F. Valois","Inria, France; INSA, France; INSA, France","IEEE Communications Magazine","12 Dec 2022","2022","60","12","64","70","Large geographical regions of our planet remain uncovered by terrestrial network connections. Sparse and dense constellations of near Earth orbit satellites can bridge this gap by providing Internet of Things (IoT) connectivity on a worldwide scale in a flexible and cost-effective manner. This article presents STEREO: a novel space-terrestrial integrated IoT architecture spanning direct- and indirect-to-satellite access from IoT assets on the surface. Framed on the identified requirements, we analyze NB-IoT and LoRa/LoRaWAN features to put these technologies forward as appealing candidates for future satellite IoT deployments. Finally, we list and discuss the key open research challenges to be addressed in order to achieve successful space-terrestrial IoT integration.","1558-1896","","10.1109/MCOM.008.2200215","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9887919","","Internet of Things;Satellites;Satellite broadcasting;Low earth orbit satellites;Logic gates;Space vehicles;Protocols","","10","","15","IEEE","12 Sep 2022","","","IEEE","IEEE Magazines"
"EdgeLoc: A Robust and Real-Time Localization System Toward Heterogeneous IoT Devices","Q. Ye; H. Bie; K. -C. Li; X. Fan; L. Gong; X. He; G. Fang","Department of Intelligent Science and Technology, Beijing University of Posts and Telecommunications, Beijing, China; Department of Intelligent Science and Technology, Beijing University of Posts and Telecommunications, Beijing, China; Department of Computer Science and Information Engineering, Providence University, Taichung, Taiwan; Centre for Assessment and Demonstration Research, AMS, Beijing, China; School of Software and BNRist, Tsinghua University, Beijing, China; Faculty of Engineering and Information Technology, University of Technology Sydney, Ultimo, NSW, Australia; Faculty of Engineering and Information Technology, University of Technology Sydney, Ultimo, NSW, Australia","IEEE Internet of Things Journal","21 Feb 2022","2022","9","5","3865","3876","Indoor localization has become an essential demand driven by indoor location-based services (ILBSs) for mobile users. With the rising of Internet of Things (IoT), heterogeneous smartphones and wearables have become ubiquitous. However, the ILBSs for heterogeneous IoT devices confront significant challenges, such as received signal strength (RSS) variances caused by hardware heterogeneity, multipath reflections from complex environments, and localization time restricted by computation resources. This article proposes EdgeLoc, a robust and real-time indoor localization system toward heterogeneous IoT devices to solve the above challenges. In particular, the RSS fingerprinting data of Wi-Fi is employed for localization and tackling the heterogeneity of IoT devices in twofold. First, feature-level and signal-level solutions are presented to address the random RSS variances. At the feature level, this work proposes a novel capsule neural network model to efficiently extract incremental features from RSS fingerprinting data. At the signal level, a multistep dataflow is further devised to process RSS fingerprints into image-like data, which utilizes the feature matrix to reduce absolute sensing errors introduced by hardware heterogeneity. Second, an edge-IoT framework is designed to utilize the edge server to train the deep learning model and further supports real-time localization for heterogeneous IoT devices. Extensive field experiments with over 33 600 data points are conducted to validate the effectiveness of EdgeLoc with a large-scale Wi-Fi fingerprint data set. The results show that EdgeLoc outperforms the state-of-the-art SAE-CNN method in localization accuracy by up to 14.4%, with an average error of 0.68 m and an average positioning time of 2.05 ms.","2327-4662","","10.1109/JIOT.2021.3101368","National Natural Science Foundation of China (NSFC) Project(grant numbers:41174158,61902211); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9502156","Capsule neural network (CapsNet);deep learning;edge computing;indoor localization;Internet of Things (IoT)","Location awareness;Wireless fidelity;Real-time systems;Computational modeling;Feature extraction;Internet of Things;Data models","","12","","43","IEEE","30 Jul 2021","","","IEEE","IEEE Journals"
"BlockAIM: A Neural Network-Based Intelligent Middleware For Large-Scale IoT Data Placement Decisions","S. M. Danish; K. Zhang; H. -A. Jacobsen","FUSÉE Laboratory, École de technologie supérieure, Montreal, Quebec, Canada; FUSÉE Laboratory, École de technologie supérieure, Montreal, Quebec, Canada; Middleware Systems Research Group, University of Toronto, Toronto, ON, Canada","IEEE Transactions on Mobile Computing","5 Dec 2022","2023","22","1","84","99","Current Internet of Things (IoT) infrastructures rely on cloud storage however, relying on a single cloud provider puts limitations on the IoT applications and Service Level Agreement (SLA) requirements. Recently, multiple decentralized storage solutions (e.g., based on blockchains) have entered the market with distinct architecture, Quality of Service (QoS) parameters and at lower price compared to the cloud storage. In this work, we introduce BAM: a neural network-based middleware designed for intelligent selection of storage technology for IoT applications. We first propose a blockchain-based data placement protocol and theoretically model a decision optimization problem, which jointly considers cloud, multi-cloud and decentralized storage technologies to select the appropriate medium to store large-scale IoT data, while ensuring data integrity, traceability, auditability and decision verifiability. We then propose a neural network-based maintenance reconfiguration, which aims to optimize the computational complexity of the middleware design along with the blockchain transaction and storage overhead by learning and predicting the applications parameters. We also propose the aggregation rate feedback functionality in our design and model it as a linear optimization problem to improve data quality and precision. Finally, we provide a reference implementation and perform extensive experiments, which demonstrate the effectiveness of the proposed design.","1558-0660","","10.1109/TMC.2021.3071576","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9398554","Middleware;data storage;Internet of Things;blockchain;neural networks","Internet of Things;Middleware;Cloud computing;Blockchain;Computer architecture;Memory;Optimization","","8","","49","IEEE","7 Apr 2021","","","IEEE","IEEE Journals"
"Mixed Logic Dynamic modeling used for Cloud Services Optimization in Smart City","J. Liu; H. Wu; Y. Wu; B. Chen; W. Xu","Key Laboratory of Ministry of Education for Geomechanics and Embankment Engineering, Hohai University, Nanjing, China; Key Laboratory of Ministry of Education for Geomechanics and Embankment Engineering, Hohai University, Nanjing, China; Key Laboratory of Ministry of Education for Geomechanics and Embankment Engineering, Hohai University, Nanjing, China; Off-Season Breeding Management Station of Jiangsu Province, Nanjing, China; Key Laboratory of Ministry of Education for Geomechanics and Embankment Engineering, Hohai University, Nanjing, China","2021 33rd Chinese Control and Decision Conference (CCDC)","30 Nov 2021","2021","","","6334","6341","The Internet of Things (IoT) technology for cloud services has made some progress. However, there are still many limitations in largescale information flow perception modeling and performance optimization. In this paper, the Mixed Logic Dynamic modeling method of IoT information flow perception is studied. The IoT sensor nodes, controlled nodes and coordination nodes are used to describe the system application scenarios, whereas the automaton is used to carry out internal information transmission, This lays an important foundation for the coordination and optimization of the system. Then, an open queuing method based on large-scale information flow perception modeling and network delay analysis method is proposed. By analyzing the end-to-end delay of the node path and the average delay analysis of the whole queuing network, the open queuing is obtained, So as to maximize the performance of the perceived network in the IoT. Aiming at the characteristics of distributed data of information flow perception in the IoT, a priority-based queuing network is proposed to model and analyze the aggregation nodes based on embedded multi-core System on Chip (SoC), which greatly improves the performance of embedded multicore SoC.","1948-9447","978-1-6654-4089-9","10.1109/CCDC52312.2021.9601804","Fundamental Research Funds for the Central Universities(grant numbers:B210202034,B200204036); State Grid Fujian Electric Power Co., Ltd(grant numbers:52130419002H); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9601804","Mixed Logic Dynamic(MLD);information flow perception;open queuing;modeling","Cloud computing;Multicore processing;Distributed databases;Load management;Delays;Internet of Things;Queueing analysis","","","","19","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Massive Wireless Energy Transfer without Channel State Information via Imperfect Intelligent Reflecting Surfaces","C. Luo; J. Hu; L. Xiang; K. Yang; K. -K. Wong","School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; Yangtze Delta Region Institute (Quzhou), University of Electronic Science and Technology of China, Quzhou, China; Department of Electronic and Electrical Engineering, University College London, London, U.K","IEEE Transactions on Vehicular Technology","","2024","PP","99","1","13","Intelligent Reflecting Surface (IRS) utilizes low-cost, passive reflecting elements to enhance the passive beam gain, improve Wireless Energy Transfer (WET) efficiency, and enable its deployment for numerous Internet of Things (IoT) devices. However, the increasing number of IRS elements presents considerable channel estimation challenges. This is due to the lack of active Radio Frequency (RF) chains in an IRS, while pilot overhead becomes intolerable. To address this issue, we propose a Channel State Information (CSI)-free scheme that maximizes received energy in a specific direction and covers the entire space through phased beam rotation. Furthermore, we take into account the impact of an imperfect IRS and meticulously design the active precoder and IRS reflecting phase shift to mitigate its effects. Our proposed technique does not alter the existing IRS hardware architecture, allowing for easy implementation in the current system, and enabling access or removal of any Energy Receivers (ERs) without additional cost. Numerical results illustrate the efficacy of our CSI-free scheme in facilitating large-scale IRS without compromising performance due to excessive pilot overhead. Furthermore, our scheme outperforms the CSI-based counterpart in scenarios involving large-scale ERs, making it a promising solution in the era of IoT.","1939-9359","","10.1109/TVT.2024.3361210","Key Research and Development Program of Zhejiang Province(grant numbers:2022C01093); Natural Science Foundation of China(grant numbers:62132004,62301122); UESTC Yangtze Delta Region Research Institute-Quzhou(grant numbers:2022D031,2023D005); Stable Supporting Fund of National Key Laboratory of Underwater Acoustic Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10422762","Intelligent reflecting surface;wireless energy transfer;channel state information-free;massive energy receivers;imperfect hardware","Wireless communication;Internet of Things;Hardware;Channel estimation;Communication system security;Receivers;6G mobile communication","","","","","IEEE","5 Feb 2024","","","IEEE","IEEE Early Access Articles"
"Channel Estimation Performance Analysis of Massive MIMO IoT Systems With Ricean Fading","P. Liu; T. Jiang","School of Information Engineering, Wuhan University of Technology, Wuhan, China; Wuhan National Laboratory for Optoelectronics and the School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China","IEEE Internet of Things Journal","24 Mar 2021","2021","8","7","6114","6126","This article analyzes the channel estimation performance of massive multiple-input-multiple-output (MIMO) Internet-of-Things (IoT) systems with Ricean fading. First, by utilizing the least squares (LSs) and minimum mean squared error (MMSE) estimation methods, we consider the relative channel estimation error (RCEE) between the IoT device and base-station, and provide the approximations of the expectation of RCEE ( Exprcee). Then, it is found that when the number of antennas M becomes infinite, pilot contamination (PC) exists in both cases. However, for MMSE case, Exprcee scales down by the inverse of Ricean K-factor, and hence PC phenomenon disappears with a large Ricean K-factor. Moreover, as M→ ∞, the power scaling laws show that the pilot sequence power can be scaled down proportionally to 1/Mα ( α > 0) with the MMSE case, where the performance is determined only by the Ricean K-factor. Next, the channel hardening and favorable propagation effects are examined via analyzing the approximations of the variance of RCEE ( Varrcee). Analysis implies that Varrcee decreases by 1/M when M→ ∞. For a large Ricean K-factor, Varrcee approaches a nonzero constant for the LS case and scales down by the inverse of the square of Ricean K-factor for the MMSE case. Finally, all results are verified via Monte Carlo simulations.","2327-4662","","10.1109/JIOT.2020.3033667","National Natural Science Foundation of China(grant numbers:61831013,62001336); Fundamental Research Funds for the Central Universities(grant numbers:WUT: 2020IVA024); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9239381","Internet of Things (IoT);massive multiple-input–multiple-output (MIMO);relative channel estimation error (RCEE);Ricean fading","Massive MIMO;Channel estimation;Internet of Things;Rayleigh channels;Estimation;Measurement","","20","","52","IEEE","26 Oct 2020","","","IEEE","IEEE Journals"
"Federated Deep Reinforcement Learning for Online Task Offloading and Resource Allocation in WPC-MEC Networks","L. Zang; X. Zhang; B. Guo","School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China","IEEE Access","27 Jan 2022","2022","10","","9856","9867","Mobile edge computing (MEC) is considered a more effective technological solution for developing the Internet of Things (IoT) by providing cloud-like capabilities for mobile users. This article combines wireless powered communication (WPC) technology with an MEC network, where a base station (BS) can transfer wireless energy to edge users (EUs) and execute computation-intensive tasks through task offloading. Traditional numerical optimization methods are time-consuming approaches for solving this problem in time-varying wireless channels, and centralized deep reinforcement learning (DRL) is not stable in large-scale dynamic IoT networks. Therefore, we propose a federated DRL-based online task offloading and resource allocation (FDOR) algorithm. In this algorithm, DRL is executed in EUs, and federated learning (FL) uses the distributed architecture of MEC to aggregate and update the parameters. To further solve the problem of the non-IID data of mobile EUs, we devise an adaptive method that automatically adjusts the FDOR algorithm’s learning rate. Simulation results demonstrate that the proposed FDOR algorithm is superior to the traditional numerical optimization method and the existing DRL algorithm in four aspects: convergence speed, execution delay, overall calculation rate and stability in large-scale and dynamic IoT.","2169-3536","","10.1109/ACCESS.2022.3144415","Beijing University of Posts and Telecommunications-China Mobile Research Institute Joint Innovation Center; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9684853","Mobile edge computing;federated learning;deep reinforcement learning;online computing offload;wireless powered communication","Task analysis;Heuristic algorithms;Wireless communication;Resource management;Computational modeling;Servers;Fading channels","","11","","32","CCBY","18 Jan 2022","","","IEEE","IEEE Journals"
"Real-time Optimal Multibeam and Power Allocation in 5G Satellite–Terrestrial IoT Networks","T. Q. Duong; L. D. Nguyen; T. T. Bui; K. D. Pham","Queen's University Belfast, Belfast, U.K.; Dong Nai University, Bien Hoa, Dong Nai, Vietnam; Ho Chi Minh City University of Technology, Ho Chi Minh City, Vietnam; Air Force Research Laboratory/Space Vehicles Directorate, AFRL/RV, US","GLOBECOM 2022 - 2022 IEEE Global Communications Conference","11 Jan 2023","2022","","","5619","5624","In this paper, we propose a joint large-scale resource allocation and optimal multibeam design for satellite-enabled Internet-of-Things (IoT) networks. To overcome the long latency issue in satellite communications, a new gaming optimisation framework is proposed, which is solved in real-time scenario. Firstly, IoT devices are clustered using coalition game that is designed for considering simultaneously transmission time minimisation and channel gain maximisation. Then, bisection search which is very low-complexity procedure is used for maximising the network energy efficiency in closed-form power allocation. The numerical results prove that our method outperforms conventional approaches and is applicable to large-scale networks with real-time IoT scenario.","","978-1-6654-3540-6","10.1109/GLOBECOM48099.2022.10001491","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10001491","","Wireless communication;Minimization;Real-time systems;Numerical models;Internet of Things;Resource management;Reliability","","","","17","IEEE","11 Jan 2023","","","IEEE","IEEE Conferences"
"Low Cost System for Fall Detection in the Elderly","T. P. Filgueiras; C. R. P. Torres; P. B. Filho","Electrical Engineering Graduate Program — EEGP, Universidade do Estado de Santa Catarina, Joinville, Brazil; Electrical Engineering Graduate Program — EEGP, Universidade do Estado de Santa Catarina, Joinville, Brazil; Electrical Engineering Graduate Program — EEGP, Universidade do Estado de Santa Catarina, Joinville, Brazil","2020 IEEE 20th International Conference on Bioinformatics and Bioengineering (BIBE)","16 Dec 2020","2020","","","697","700","Over the recent years, Internet of Things have been used to monitor biosignals in a large scale. Large scale demands the use of many biosensors and a complex control system, which may results in high cost technology. This article proposes a simple fall detection system targeting the elderly population at low cost. A prototype based on the Arduino Uno, accelerator and gyroscope was implemented and fixed in a individual's torso. Five types of movement were analyzed (walking, sitting, running, and falling). Data were transferred to a mobile phone using the HC-06 Bluetooth transmission module. The final proposed prototype was about $18.00 and have the advantage of detecting falls automatically. Measurements showed that a fall can be detected by either using the gyroscope or the accelerometer. The findings from this article mighty be useful when working on a multi-parameter device which uses intelligent algorithms to control health and fall among the elderly. With these, algorithms, it is expected to improve the fall detection system so that it also provides the individual's location and history of movements that precede a possible fall.","2471-7819","978-1-7281-9574-2","10.1109/BIBE50027.2020.00117","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288094","Internet of Things;Fall Detection;Monitoring of the Elderly. Reduced Cost","Torso;Senior citizens;Sociology;Prototypes;Gyroscopes;Statistics;Monitoring","","2","","27","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"A Partition-Based Mobile-Crowdsensing-Enabled Task Allocation for Solar Insecticidal Lamp Internet of Things Maintenance","Y. Sun; E. Nurellari; W. Ding; L. Shu; Z. Huo","College of Engineering, Nanjing Agricultural University, Nanjing, China; School of Engineering, University of Lincoln, Lincoln, U.K.; College of Engineering, Nanjing Agricultural University, Nanjing, China; School of Engineering, University of Lincoln, Lincoln, U.K.; Institutional Research Information System, University College London, London, U.K.","IEEE Internet of Things Journal","6 Oct 2022","2022","9","20","20547","20560","Solar insecticidal lamps Internet of Things (SIL-IoT) is a new green prevention and control technology for pest management. In the implementation of SIL-IoT to large-scale regions, two practical issues remain to be solved, that is: 1) scheduling the cleaning tasks of SILs periodically and 2) minimizing the insecticidal efficiency reduction over time. As smartphones are widely available among farmers across the globe, mobile crowdsensing (MCS) for agricultural data collection becomes a cost-effective and efficient solution by integrating participatory sensing based on a large group of individuals. This article proposes an MCS-enabled framework to address the SIL maintenance problem (SILMP) and perform system analysis by considering both the partition structure of farmland and the insecticidal efficiency of SILs. In addition, considering the farmland’s practical natural geographical features, we propose dividing the regions of interest into numerous subareas, where each subarea can be considered a separate partition. Finally, we formulate the SILMP framework as two subproblems, i.e., path planning and task selection, and propose two different methods to tackle each problem based on the concept of greedy algorithm. Simulation results show that our proposed methods have improved performance in the tradeoff between task cost and insecticidal efficiency and outperform the three selected baseline algorithms.","2327-4662","","10.1109/JIOT.2022.3175732","National Natural Science Foundation of China(grant numbers:62072248); China Scholarship Council (CSC)(grant numbers:202006850075); Jiangsu Agricultural Science and Technology Innovation Fund(grant numbers:CX(21)3060); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9776495","Combinatorial optimization;mobile crowdsensing (MCS);path planning;smart agriculture;solar insecticidal lamps maintenance problem;task allocation","Task analysis;Resource management;Maintenance engineering;Urban areas;Sensors;Costs;Internet of Things","","3","","31","IEEE","17 May 2022","","","IEEE","IEEE Journals"
"YONO: Modeling Multiple Heterogeneous Neural Networks on Microcontrollers","Y. D. Kwon; J. Chauhan; C. Mascolo","University of Cambridge, United Kingdom; University of Cambridge, United Kingdom; University of Southampton, United Kingdom","2022 21st ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)","18 Jul 2022","2022","","","285","297","Internet of Things (IoT) systems provide large amounts of data on all aspects of human behavior. Machine learning techniques, especially deep neural networks (DNN), have shown promise in making sense of this data at a large scale. Also, the research community has worked to reduce the computational and resource demands of DNN to compute on low-resourced micro controllers (MCUs). However, most of the current work in embedded deep learning focuses on solving a single task efficiently, while the multi-tasking nature and applications of IoT devices demand systems that can handle a diverse range of tasks (such as activity, gesture, voice, and context recognition) with input from a variety of sensors, simultaneously. In this paper, we propose YONO, a product quantization (PQ) based approach that compresses multiple heterogeneous models and enables in-memory model execution and model switching for dissimilar multi-task learning on MCUs. We first adopt PQ to learn codebooks that store weights of different models. Also, we propose a novel network optimization and heuristics to maximize the com-pression rate and minimize the accuracy loss. Then, we develop an online component of YONO for efficient model execution and switching between multiple tasks on an MCU at run time without relying on an external storage device. YONO shows remarkable performance as it can compress multiple heterogeneous models with negligible or no loss of accuracy up to 12.37x. Furthermore, YONO's online component enables an efficient execution (latency of 16–159 ms and energy consumption of 3.8-37.9 mJ per operation) and reduces modelloading/switching la-tency and energy consumption by 93.3-94.5% and 93.9-95.0%, respectively, compared to external storage access. Interestingly, YONO can compress various architectures trained with datasets that were not shown during YONO's offline codebook learning phase showing the generalizability of our method. To summarize, YONO shows great potential and opens further doors to enable multi-task learning systems on extremely resource-constrained devices.","","978-1-6654-9624-7","10.1109/IPSN54338.2022.00030","University of Cambridge; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9826043","Multi Task Learning;Product Quantization;Microcontrollers","Deep learning;Energy consumption;Neural networks;Switches;Multitasking;Internet of Things;Task analysis","","3","","88","IEEE","18 Jul 2022","","","IEEE","IEEE Conferences"
"Decentralized Adaptive Optimal Tracking Control for Massive Autonomous Vehicle Systems With Heterogeneous Dynamics: A Stackelberg Game","Z. Zhou; H. Xu","Department of Electrical and Biomedical Engineering, University of Nevada, Reno, NV, USA; Department of Electrical and Biomedical Engineering, University of Nevada, Reno, NV, USA","IEEE Transactions on Neural Networks and Learning Systems","30 Nov 2021","2021","32","12","5654","5663","In this article, a decentralized optimal tracking control problem has been studied for a large-scale autonomous vehicle system with heterogeneous system dynamics. Due to the ultralarge number of agents, the notorious “curse of dimension” problem as well as the unrealistic assumption of the existence of reliable very large-scale communication links in uncertain environments have challenged the traditional multiagent system (MAS) algorithms for decades. The emerging mean-field game (MFG) theory has recently been widely adopted to generate a decentralized control method that deals with those challenges by encoding the large scale MASs’ information into a novel time-varying probability density functions (PDF) which can be obtained locally. However, the traditional MFG methods assume all agents are homogeneous, which is unrealistic in practical industrial applications, e.g., Internet of Things (IoTs), and so on. Therefore, a novel mean-field Stackelberg game (MFSG) is formulated based on the Stackelberg game, where all the agents have been classified as two different categories where one major leader’s decision dominates the other minor agents. Moreover, a hierarchical structure that treats all minor agents as a mean-field group is developed to tackle the assumption of homogeneous agents. Then, the actor-actor–critic–critic-mass ( $A^{2}C^{2}M$ ) algorithm with five neural networks is designed to learn the optimal policies by solving the MFSG. The Lyapunov theory is utilized to prove the convergence of  $A^{2}C^{2}M$  neural networks and the closed-loop system’s stability. Finally, a series of numerical simulations are conducted to demonstrate the effectiveness of the developed method.","2162-2388","","10.1109/TNNLS.2021.3100417","U.S. Office of the Under Secretary of Defense for Research and Engineering (OUSD(R&E))(grant numbers:FA8750-15-2-0119); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9509348","Approximate dynamic programming (ADP);mean-field games (MFGs);reinforcement learning;Stackelberg game","Games;Probability density function;Neural networks;Autonomous vehicles;Trajectory;Optimal control;Cost function","","7","","32","IEEE","9 Aug 2021","","","IEEE","IEEE Journals"
"Semi-Deterministic Dynamic Millimeter-Wave Channel Modeling Based on an Optimal Neural Network Approach","X. Zhao; Z. Fu; W. Fan; Y. Zhang; S. Geng; F. Du; P. Qin; Z. Zhou; L. Zhang","State Key Laboratory of Alternate Electrical Power System With Renewable Energy Sources, School of Electrical and Electronic Engineering, North China Electric Power University, Beijing, China; State Key Laboratory of Alternate Electrical Power System With Renewable Energy Sources, School of Electrical and Electronic Engineering, North China Electric Power University, Beijing, China; Department of Electronic Systems, Aalborg University, Aalborg, Denmark; State Key Laboratory of Alternate Electrical Power System With Renewable Energy Sources, School of Electrical and Electronic Engineering, North China Electric Power University, Beijing, China; State Key Laboratory of Alternate Electrical Power System With Renewable Energy Sources, School of Electrical and Electronic Engineering, North China Electric Power University, Beijing, China; State Key Laboratory of Alternate Electrical Power System With Renewable Energy Sources, School of Electrical and Electronic Engineering, North China Electric Power University, Beijing, China; State Key Laboratory of Alternate Electrical Power System With Renewable Energy Sources, School of Electrical and Electronic Engineering, North China Electric Power University, Beijing, China; State Key Laboratory of Alternate Electrical Power System With Renewable Energy Sources, School of Electrical and Electronic Engineering, North China Electric Power University, Beijing, China; Shandong Electric Power Research Institute, State Grid Corporation of China, Jinan, China","IEEE Transactions on Antennas and Propagation","13 Jun 2022","2022","70","6","4082","4095","Billions of mobile terminals will be deployed in various Internet of Things (IoT), in which millimeter-wave (mmWave) technology will be gradually applied. Accurate modeling and simulation of wireless channel is the base for efficient design and performance evaluation. This becomes more important for industrial scenarios, which might be highly dynamic and potentially different from well-investigated cellular deployment scenarios. In this work, a novel semi-deterministic mmWave dynamic channel modeling approach based on optimal neural network (ONN) principle is proposed. The ONNs are radial basis function (RBF) neural networks (NNs) trained with optimal variance parameters and are applied to predict large-scale channel parameters (LSCPs) [e.g., path loss (PL), delay spread (DS), and angle spread (AS)]. Based on the ONNs’ predicted large-scale parameters and simplified propagation environment including the layout of transmitter (TX), receiver (RX), and major scatterers, the proposed channel modeling approach can generate accurate dynamic channel parameters. The proposed approach is validated by the channel data measured at a high-voltage substation. Large-scale parameters, multipath component (MPC) distributions, and power delay profiles (PDPs) are validated. The proposed approach is demonstrated to be an accurate, fast, and robust channel modeling method, which can be used for both link-level and system-level channel simulation for future design and optimization of industrial IoT.","1558-2221","","10.1109/TAP.2022.3145438","National Natural Science Foundation of China (NSFC)(grant numbers:61931001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9695951","Dynamic channel modeling;map-based channel modeling;millimeter wave (mmWave);multipath component (MPC);optimal neural network (ONN)","Computational modeling;Data models;Vehicle dynamics;Wireless communication;Predictive models;Stochastic processes;Delays","","6","","43","IEEE","28 Jan 2022","","","IEEE","IEEE Journals"
"Collective Remote Attestation at the Internet of Things Scale: State-of-the-Art and Future Challenges","M. Ambrosin; M. Conti; R. Lazzeretti; M. M. Rabbani; S. Ranise","University of Padova, Padova, Italy; Department of Mathematics, University of Padua, Padua, Italy; Department of Computer, Control, and Management Engineering “Antonio Ruberti,”, Sapienza University of Rome, Rome, Italy; University of Padova, Padova, Italy; Security and Trust Research Unit, Fondazione Bruno Kessler, Povo, Italy","IEEE Communications Surveys & Tutorials","20 Nov 2020","2020","22","4","2447","2461","In recent years, the booming of Internet of Things (IoT) has populated the world with billions of smart devices that implement novel services and applications. The potential for cyberattacks on IoT systems have called for new solutions from the research community. Remote attestation is a widely used technique that allows a verifier to identify software compromise on a remote platform (called prover). Traditional challenge-response remote attestation protocols between the verifier and a single prover face a severe scalability challenge when they are applied to large scale IoT systems. To tackle this issue, recently researchers have started developing attestation schemes, which we refer to as Collective Remote Attestation (CRA) schemes, that are capable of remotely performing attestation of large networks of IoT devices. In this paper, after providing the reader with a background on remote attestation, we survey and analyze existing CRA schemes. We present an analysis of their advantages and disadvantages, as well as of their effectiveness against a reference attacker model. We focus our attention on CRA schemes' characteristics and adversarial mitigation capabilities. We finally highlight open research issues and give possible directions for mitigating both the limitations of existing schemes, and new emerging challenges. We believe this work can help guiding the design of current and future proposals for CRA.","1553-877X","","10.1109/COMST.2020.3008879","EU LOCARD Project(grant numbers:H2020-SU-SEC-2018-832735); Sapienza University of Rome within the Project SPoB-MA(grant numbers:RM11715C7878B045); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9139454","Internet of Things;remote attestation;collective remote attestation;software-based attestation;hardware-based attestation;network security and privacy","Protocols;Smart devices;Security;Internet of Things;Performance evaluation;Computer crime","","30","","61","IEEE","13 Jul 2020","","","IEEE","IEEE Journals"
"On Smartly Scanning of the Internet of Things","J. Qu; X. Ma; W. Liu; H. Sang; J. Li; L. Xue; X. Luo; Z. Li; L. Feng; X. Guan","MOE Key Laboratory for Intelligent Networks and Network Security and the Faculty of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China; MOE Key Laboratory for Intelligent Networks and Network Security and the Faculty of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China; NSFOCUS Inc, Beijing, China; NSFOCUS Inc, Beijing, China; MOE Key Laboratory for Intelligent Networks and Network Security and the Faculty of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China; School of Cyber Science and Technology, Sun Yat-sen University, Guangzhou, China; Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong; School of Software and BNRist, Tsinghua University, Beijing, China; School of Computing and Artificial Intelligence, Southwest Jiaotong University, Chengdu, China; MOE Key Laboratory for Intelligent Networks and Network Security and the Faculty of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China","IEEE/ACM Transactions on Networking","","2023","PP","99","1","16","Cyber search engines, such as Shodan and Censys, have gained popularity due to their strong capability of indexing the Internet of Things (IoT). They actively scan and fingerprint IoT devices for unearthing IP-device mapping. Because of the large address space of the Internet and the mapping’s mutative nature, efficiently tracking the evolution of IP-device mapping with a limited budget of scans is essential for building timely cyber search engines. An intuitive solution is to use reinforcement learning to schedule more scans to networks with high churn rates of IP-device mapping. However, such an intuitive solution has never been systematically studied. In this paper, we take the first step toward demystifying this problem based on our experiences in maintaining a global IoT scanning platform. Inspired by the measurement study of large-scale real-world IoT scan records, we land reinforcement learning onto a system capable of smartly scanning IoT devices in a principled way. We disclose key parameters affecting the effectiveness of different scanning strategies, and real-world experiments demonstrate that our system can scan up to around 40 times as many IP-device mapping mutations as random/sequential scanning.","1558-2566","","10.1109/TNET.2023.3312162","National Natural Science Foundation of China(grant numbers:61972313,62272381,62002306,62202405,T2341003); Natural Science Basic Research Program of Shaanxi Province(grant numbers:2023-JC-JQ-50); Fundamental Research Funds for the Central Universities, Postdoctoral Science Foundation(grant numbers:2019M663725,2021T140543,2023M732791); Hong Kong Research Grants Council (RGC) Project(grant numbers:PolyU15223918); CCF-NSFOCUS Kunpeng Research Fund of China; Cyrus Tang Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10250418","Internet of Things (IoT);Adaptive algorithms;IP networks;Cyberspace","Internet of Things;Search engines;IP networks;Fingerprint recognition;Cameras;Schedules;Reinforcement learning","","","","","IEEE","13 Sep 2023","","","IEEE","IEEE Early Access Articles"
"A New Block-Based Reinforcement Learning Approach for Distributed Resource Allocation in Clustered IoT Networks","F. Hussain; R. Hussain; A. Anpalagan; A. Benslimane","Royal Bank of Canada, Toronto, Canada; Institute of Information Security and Cyber-Physical Systems, Innopolis University, Innopolis, Russia; WINCORE Lab, Department of Computer Science, Ryerson University, Toronto, Canada; University of Avigon, Avignon, France","IEEE Transactions on Vehicular Technology","13 Mar 2020","2020","69","3","2891","2904","Resource allocation and spectrum management are two major challenges in the massive scale deployment of Internet of Things (IoT) and Machine-to-Machine (M2M) communication. Furthermore, the large number of devices per unit area in IoT networks also leads to congestion, network overload, and deterioration of the Signal to Noise Ratio (SNR). To address these problems, efficient resource allocation play a pivotal role in optimizing the throughput, delay, and power management of IoT networks. To this end, most of the existing resource allocation mechanisms are centralized and do not gracefully support the heterogeneous and dynamic IoT networks. Therefore, distributed and Machine Learning (ML)-based approaches are essential. However, distributed resource allocation techniques also have scalability problem with large number of devices whereas the ML-based approaches are currently scarce in the literature. In this paper, we propose a new distributed block-based Q-learning algorithm for slot scheduling in the smart devices and Machine Type Communication Devices (MTCDs) participating in clustered IoT networks. We furthermore, propose various reward schemes for the evolution of Q-values in the proposed scheme and, discuss and evaluate their effect on the distributed model. Our goal is to avoid inter- and intra-cluster interference, and to improve the Signal to Interference Ratio (SIR) by employing frequency diversity in a multi-channel system. Through extensive simulations, we analyze the effects of the distributed slot-assignment (with respect to varying SIR) on the convergence rate and the convergence probability. Our theoretical analysis and simulations validate the effectiveness of our proposed method where, (i) a suitable slot with acceptable SIR levels is allocated to each MTCD, and (ii) IoT network can efficiently converge to a collision-free transmission causing minimum intra-cluster interference. The network convergence is achieved through each MTCD's learning ability during the distributed slot allocation.","1939-9359","","10.1109/TVT.2020.2965796","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8955961","MTCDs;clustered IoT network;machine learning;block Q-learning;resource allocation","Resource management;Internet of Things;Machine-to-machine communications;Interference;Quality of service;Reinforcement learning;Throughput","","21","","42","IEEE","10 Jan 2020","","","IEEE","IEEE Journals"
"Research on the Optimization Algorithm of Big Data Computing System","M. Wu; J. Jiang; L. Wang","School of China Agriculture University, Beijing, China; School of Digital Technology, Dalian University of Science and Technology, Dalian, China; School of Digital Technology, Dalian University of Science and Technology, Dalian, China","2021 International Wireless Communications and Mobile Computing (IWCMC)","9 Aug 2021","2021","","","1783","1787","With the social progress and development, the scale of data continues to expand, in order to realize the processing and analysis of large-scale data, graph computing system came into being. At present, with the continuous maturity of graph computing system, graph computing has been widely used in various fields, such as social field, Internet of things field and neural network field. In recent years, different graph computing models have emerged, and some typical distributed graph computing models show good expansibility in the formulation of graph data for big data processing. However, in order to further expand the expansibility, many graph calculation models are studied by algorithms. At present, the SFA algorithm is mostly used in the graph calculation system. However, with the continuous development of graph calculation, many inadaptability of the SFA algorithm appear which restricts the further development of graph calculation. Therefore, it is an urgent problem to optimize the algorithm of graph computing system. On the basis of scholars' research, this paper firstly gives a simple overview of graph calculation and graph calculation model. On this basis, it analyzes the specific formula and significance of SFA algorithm, puts forward the specific scheme of algorithm optimization, and carries out experimental detection of optimization algorithm.","2376-6506","978-1-7281-8616-0","10.1109/IWCMC51323.2021.9498813","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9498813","big data;graph calculation system;optimization algorithm;SFA algorithm","Wireless communication;Computational modeling;Neural networks;Distributed databases;Big Data;Data processing;Data models","","1","","23","IEEE","9 Aug 2021","","","IEEE","IEEE Conferences"
"Energy Efficient UAV-Enabled Mobile Edge Computing for IoT Devices: A Review","M. Abrar; U. Ajmal; Z. M. Almohaimeed; X. Gui; R. Akram; R. Masroor","Department of Electrical Engineering, Bahauddin Zakariya University, Multan, Pakistan; Department of Electrical Engineering, Bahauddin Zakariya University, Multan, Pakistan; Department of Electrical Engineering, College of Engineering, Qassim University, Buraydah, Al-Qassim, Saudi Arabia; School of Food and Advanced Technology, Massey University, Manawatu, Palmerston North, New Zealand; Department of Electrical Engineering, College of Engineering, Qassim University, Buraydah, Al-Qassim, Saudi Arabia; Department of Electrical and Computer Engineering, COMSATS University Islamabad, Wah Campus, Wah Cantt, Pakistan","IEEE Access","20 Sep 2021","2021","9","","127779","127798","With the emergence of computation-intensive and delay-sensitive applications, such as face recognition, virtual reality, augmented reality, and Internet of Things (IoT) devices; Mobile Edge Computing (MEC) allows the IoT devices to offload their heavy computation tasks to nearby edge cloud network rather than to compute the tasks locally. Therefore, it helps to reduce the energy consumption and execution delay in the ground mobile users. Flying Unmanned Aerial Vehicles (UAVs) integrated with the MEC server play a key role in 5G and future wireless communication networks to provide spatial coverage and further computational services to the small, battery-powered and energy-constrained devices. The UAV-enabled MEC (U-MEC) system has flexible mobility and more computational capability compared to the terrestrial MEC network. They support line-of-sight (LoS) links with the users offloading their tasks to the UAVs. Hence, users can transmit more data without interference by mitigating small-scale fading and shadowing effects. UAVs resources and flight time are very limited due to size, weight, and power (SWaP) constraints. Therefore, energy-aware communication and computation resources are allocated in order to minimize energy consumption.In this paper, a brief survey on U-MEC networks is presented. It includes the brief introduction regarding UAVs and MEC technology. The basic terminologies and architectures used in U-MEC networks are also defined. Moreover, mobile edge computation offloading working, different access schemes used during computation offloading technique are explained. Resources that are needed to be optimized in U-MEC systems are depicted with different optimization problem, and solution types. Furthermore, to guide future work in this area of research, future research directions are outlined. At the end, challenges and open issues in this domain are also summarized.","2169-3536","","10.1109/ACCESS.2021.3112104","Deanship of Scientific Research, Qassim University for funding the publication of this project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9535463","Computation;energy efficiency;Internet of Things;mobile edge computing;offloading;resource allocation;UAVs","Task analysis;Edge computing;Servers;Wireless communication;Mobile handsets;Internet of Things;5G mobile communication","","39","","73","CCBY","10 Sep 2021","","","IEEE","IEEE Journals"
"Research on Power Quality Monitoring Method of Distribution Network based on Intelligent Fusion Terminal","Y. Du; Z. Liu; L. Huang; L. Wang; J. Fang; S. Zhang","State Grid Information & Telecommunication Group Co., Ltd., The State Grid Corp. of China, Beijing, China; State Grid Information & Telecommunication Group Co., Ltd., The State Grid Corp. of China, Beijing, China; State Grid Information & Telecommunication Group Co., Ltd., The State Grid Corp. of China, Beijing, China; State Grid Information & Telecommunication Group Co., Ltd., The State Grid Corp. of China, Beijing, China; State Grid Information & Telecommunication Group Co., Ltd., The State Grid Corp. of China, Beijing, China; State Grid Information & Telecommunication Group Co., Ltd., The State Grid Corp. of China, Beijing, China","2021 IEEE International Conference on Energy Internet (ICEI)","8 Feb 2022","2021","","","56","61","At present, distributed generation, microgrid, energy storage and electric vehicles are widely connected to the power grid, which makes the power grid show obvious imbalance in space and time. The power quality problem of distribution network is more and more prominent. It is necessary to realize the large-scale power quality monitoring of distribution network. In order to solve the lack of large-scale power quality monitoring of distribution network economically, this paper studies a power quality monitoring method of distribution network based on Intelligent Fusion terminal under the framework of Internet of things. The terminal and method realize the monitoring of voltage and current harmonics, three-phase imbalance and other power quality indexes, and meet the economic requirements of power quality monitoring of distribution network. The test results show that the method achieves 2–50th harmonic monitoring, the accuracy error is less than 2%, and the basic monitoring time window meets the requirements of gapless and non-overlapping 10 cycles; The accuracy error of three-phase unbalance monitoring is less than 0.065%. The test results verify the accuracy of the monitoring method, which can be applied to power quality monitoring of distribution network.","","978-1-6654-0734-2","10.1109/ICEI52466.2021.00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9701024","Distribution network;Power quality;Monitoring method;Intelligent fusion terminal;Internet of things","Space vehicles;Power quality;Distribution networks;Voltage;Microgrids;Power system harmonics;Harmonic analysis","","","","18","IEEE","8 Feb 2022","","","IEEE","IEEE Conferences"
"Development of Large-Scale Precision Farming Monitoring System based on REST API and SignalR","I. M. Adhiarta Wikantyasa; R. Sarno; S. Triajo","Informatic Engineering, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Informatic Engineering, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Informatic Engineering, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia","2023 International Conference on Computer Science, Information Technology and Engineering (ICCoSITE)","23 May 2023","2023","","","832","837","Farming is one of the primary resources to provide human food therefore, it takes a large amount of cultivated land to meet food needs. Currently, technologies such as IoT have significant role in advancing agriculture in this digitalize era by improving conventional agriculture methods by not only making it optimal but also making it cost efficient for farmer to produce quality of crops. The aims of this paper to develop system in the form of REST API service by using .net 6 as framework to efficiently manage the growth of IoT devices from the ground up in medium scale to large scale cultivated land with easy to scale up based on the SignalR library and crops health monitoring. The system will assist institute farmer and technician by visualizing data from each deployed IoT device (Temperature, humidity, soil moisture, Ph) from each section of cultivated land and management of each new IoT device such as sensor, actuator and microcontroller that will be deployed and by using SignalR library as an interconnection between device to API. To ensure the quality of the system author measured using the JMeter application by conducting simulation with high peak of user access and transmitted data of IoT device to give a validation of load testing that the system will run smoothly without any problem. The research concludes based on the testing that been done has successfully delivered and shown no latency or error with performance result on each test 21ms functional and 0.50ms on SignalR testing.","","979-8-3503-2095-4","10.1109/ICCoSITE57641.2023.10127746","Institut Teknologi Sepuluh Nopember; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10127746","Internet of Thing;REST API;Precision Farming;SignalR;System Development","Temperature measurement;Temperature sensors;Temperature distribution;Crops;Libraries;Agriculture;Internet of Things","","","","21","IEEE","23 May 2023","","","IEEE","IEEE Conferences"
"A 72-Channel Resistive-and-Capacitive Sensor Interface Achieving 0.74 μ W/ Channel and 0.038 mm2/ Channel by Noise-Orthogonalizing and Pad-Sharing Techniques","X. Feng; Y. Luo; T. Cai; Y. Xuan; Y. Zhang; Y. Shen; C. Yang; Q. Xiao; Y. Chen; B. Zhao","Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; University of Macau, Macao, China; Zhejiang University, Hangzhou, China","2023 IEEE Custom Integrated Circuits Conference (CICC)","11 May 2023","2023","","","1","2","The recent surge in the internet-of-things envisions the integration of trillions of sensors in various applications such as environmental monitoring. A myriad of parameters such as temperature, pressure, humidity, and proximity are required to be collected simultaneously by resistive (R) or capacitive (C) transducers [1–4]. The traditional sinusoidal-stimulated sensor system exhibits high precision [5] and scales for multiple channels through multiplexing and demultiplexing as shown in Fig. 1, top. However, these systems are not suitable for emerging energy-limited systems and cost-sensitive applications in massive-channel sensing due to: 1) The signal-to-noise ratio (SNR) of the signal chain is directly traded with power consumption and core area, leading to high power and large die area. 2) The multiplexing methods in conventional sensor interface take 2 additional I/O pads to support 1 more sensor, and the large pad frame significantly increases the total chip area.","2152-3630","979-8-3503-9948-6","10.1109/CICC57935.2023.10121283","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10121283","","Temperature sensors;Application specific integrated circuits;Demultiplexing;Transducers;Power demand;Humidity;Sensor systems","","","","5","IEEE","11 May 2023","","","IEEE","IEEE Conferences"
"NanoLambda: Implementing Functions as a Service at All Resource Scales for the Internet of Things","G. George; F. Bakir; R. Wolski; C. Krintz","Computer Science Department, Univ. of California, Santa Barbara; Computer Science Department, Univ. of California, Santa Barbara; Computer Science Department, Univ. of California, Santa Barbara; Computer Science Department, Univ. of California, Santa Barbara","2020 IEEE/ACM Symposium on Edge Computing (SEC)","22 Feb 2021","2020","","","220","231","Internet of Things (IoT) devices are becoming increasingly prevalent in our environment, yet the process of programming these devices and processing the data they produce remains difficult. Typically, data is processed on device, involving arduous work in low level languages, or data is moved to the cloud, where abundant resources are available for Functions as a Service (FaaS) or other handlers. FaaS is an emerging category of flexible computing services, where developers deploy self-contained functions to be run in portable and secure containerized environments; however, at the moment, these functions are limited to running in the cloud or in some cases at the “edge” of the network using resource rich, Linux-based systems.In this paper, we present NanoLambda, a portable platform that brings FaaS, high-level language programming, and familiar cloud service APIs to non-Linux and microcontroller-based IoT devices. To enable this, NanoLambda couples a new, minimal Python runtime system that we have designed for the least capable end of the IoT device spectrum, with API compatibility for AWS Lambda and S3. NanoLambda transfers functions between IoT devices (sensors, edge, cloud), providing power and latency savings while retaining the programmer productivity benefits of high-level languages and FaaS. A key feature of NanoLambda is a scheduler that intelligently places function executions across multi-scale IoT deployments according to resource availability and power constraints. We evaluate a range of applications that use NanoLambda to run on devices as small as the ESP8266 with 64KB of ram and 512KB flash storage.","","978-1-7281-5943-0","10.1109/SEC50012.2020.00035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9355717","IoT;serverless;cloud functions;edge computing;microcontrollers;portability","Cloud computing;Runtime;FAA;Programming;Nanoscale devices;Internet of Things;Python","","10","","36","IEEE","22 Feb 2021","","","IEEE","IEEE Conferences"
"Implementation of a Self-hosted Internet of Things Solution on Personal Computer","S. Matuska; P. Brida; I. Bridova","Department of Multimedia and Information-Communication Technologies, University of Zilina, Zilina, Slovakia; Department of Multimedia and Information-Communication Technologies, University of Zilina, Zilina, Slovakia; Department of Information Networks, University of Zilina, Zilina, Slovakia","2023 27th International Conference Electronics","13 Jul 2023","2023","","","1","6","This article presents the implementation of a self-hosted Internet of Things solution on a personal computer. The proposed solution utilizes open-source software components to create a low-cost and customizable alternative to cloud-based IoT solutions. The IoT system is implemented using the Docker platform. The system is designed to collect, process, and visualize sensor data in real-time, and includes a dashboard-type user interface for remote monitoring and control. Other core modules are the Node-RED, the MQTT broker, and the Mongo DB. The solution is easily managed and starts with a single command with few dependencies. We demonstrated the usage of our solutions in creating a single complex IoT project. The results show that the self-hosted IoT solution is a viable option for small-scale IoT projects and can be easily adapted to different types of sensors and applications.","","979-8-3503-2255-2","10.1109/IEEECONF58372.2023.10177497","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10177497","IoT;Self-hosted solution;Docker;Node-RED","Uniform resource locators;Data visualization;Process control;Microcomputers;Routing;Real-time systems;Internet of Things","","","","24","IEEE","13 Jul 2023","","","IEEE","IEEE Conferences"
"In-Network Compression for Accelerating IoT Analytics at Scale","R. Oliveira; A. Gavrilovska",Georgia Institute of Technology; Georgia Institute of Technology,"2023 IEEE Symposium on High-Performance Interconnects (HOTI)","20 Oct 2023","2023","","","15","24","To enable the Internet of Things (IoT) to scale at the level of next generation smart cities and grids, there is a need for cost-effective infrastructure for hosting IoT analytics applications. Offload and acceleration via SmartNICs have been shown to provide benefits to these workloads. However, even with offload, long-term analysis on IoT data still needs to operate on massive number of device updates, often in the form of small messages. Despite offloading, the ingestion of these updates continues to present server bottlenecks. In this paper, we present domain-specific compression and batching engines, that leverage the unique properties of IoT messages to reduce the load on analytics servers and improve their scalability. Using a prototype system based on the InnovaFlex programmable SmartNICs, and several representative IoT benchmarks, we demonstrate that the combination of these techniques achieves up to 14.5× improvement in sustained throughput rates compared to a system without SmartNIC offload, and up to 7× improvement over existing offload approaches.","2332-5569","979-8-3503-0475-6","10.1109/HOTI59126.2023.00017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10287299","In network acceleration;Compression;IoT;Accelerator;SmartNIC","Smart cities;Scalability;Prototypes;Benchmark testing;Throughput;Internet of Things;Servers","","","","53","IEEE","20 Oct 2023","","","IEEE","IEEE Conferences"
"A Blockchain Node Organizing and Auto-Scaling Architecture for the Internet of Things","R. Elsaadany; G. Bégin","Computer Science Dept., Université du Québec à Montréal (UQAM); Computer Science Dept., Université du Québec à Montréal (UQAM)","2023 Fifth International Conference on Blockchain Computing and Applications (BCCA)","11 Dec 2023","2023","","","36","43","Blockchain has recently received great attention in non-monetary fields such as Internet of Things (IoT) due to its noticeable peculiarities including decentralization, security and immutability. Most conventional blockchain designs have limited throughput and large transaction delays. The majority of the proposed IoT-based blockchain models lack the neces-sary scalability to handle the massive amount of transactions produced by IoT devices, as well as the mechanisms that take control decentralization and managing node overhead capacity into account. In this paper, we propose: i) a multi-tiered self-scalable dynamic (SSD) architecture that limits the number of nodes participating in consensus and the number of hops needed through clustering all nodes, ii) a logical positioning mechanism for locating nodes in O (1), iii) a high efficiency dynamic cyclic application-agnostic scaling algorithm, SSD algorithm, that helps SSD structure to shrink and/or expand automatically, conserving scalability and security by maintaining a load balance between control decentralization and node overhead capacity and iv) a colocality mechanism that can be leveraged. The architecture along with the proposed algorithm and mechanisms help reduce consensus time: in O(1) plus twice O(maximum propagation delay towards topmost nodes), whose number is a recursive logarithmic reduction of the number of nodes directly managing IoT devices, worst case. As a proof of concept, we have created simulations in Python3 for SSD model and SSD algorithm and the results rank SSD model to exceed traditional as well as two-tiered models.","","979-8-3503-3923-9","10.1109/BCCA58897.2023.10338882","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10338882","Blockchain;Internet of Things (IoT);Consen-sus Time;Scalability;Load balancing;Control decentralization;Security;Node management Overhead","Heuristic algorithms;Scalability;Clustering algorithms;Computer architecture;Throughput;Blockchains;Internet of Things","","","","25","IEEE","11 Dec 2023","","","IEEE","IEEE Conferences"
"Real-Time DDoS Defense in 5G-Enabled IoT: A Multidomain Collaboration Perspective","X. Chen; Y. Chen; W. Feng; L. Xiao; X. Li; J. Zhang; N. Ge","Department of Electronic Engineering, Tsinghua University, Beijing, China; School of Engineering, University of Warwick, Coventry, U.K; Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Communication Engineering, Xiamen University, Xiamen, China; Department of Information Engineering, Beijing University of Chemical Technology, Beijing, China; Department of Electronic and Electrical Engineering, The University of Sheffield, Sheffield, U.K; Department of Electronic Engineering, Tsinghua University, Beijing, China","IEEE Internet of Things Journal","20 Feb 2023","2023","10","5","4490","4505","While 5G networks have accelerated the development of the Internet of Things (IoT), they have also introduced a large number of vulnerable IoT devices into the network, which would lead to severe Distributed Denial-of-Service (DDoS) attacks. The newly emerging DDoS attack methods generally have a shorter duration, which imposes higher requirements for the response time of DDoS mitigation technologies. Existing DDoS defense methods cannot achieve real-time detection due to the difficulty of reducing the delay of feature extraction and large-scale data processing. In this article, we focus on the timeliness of DDoS detection and mitigation. We hope that deploying effective defense countermeasures at the source side will block the majority of DDoS attack traffic in real time before it enters the data network (DN). To this end, we propose a real-time DDoS defense framework based on multidomain collaboration that combines multisource information to detect attack sessions with high accuracy in 5G networks. To operate the framework at line rate, we propose an optimal packet sampling strategy based on the accurate session size estimation, which can greatly reduce the detection overhead while ensuring good accuracy. In a typical scenario with an attack session size larger than 10, this method can achieve a 99% detection rate while reducing the packet inspection rate (PIR) to less than 37%.","2327-4662","","10.1109/JIOT.2022.3218728","National Key Research and Development Program of China(grant numbers:2018YFA0701601); National Natural Science Foundation of China(grant numbers:61922049,62201605,61941104,U21A20444); Fundamental Research Funds for the Central Universities(grant numbers:buctrc202124); Tsinghua University- China Mobile Communications Group Company Ltd., Joint Institute; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9933825","5G networks;Distributed Denial of Service (DDoS);multidomain collaboration;real time","Computer crime;Denial-of-service attack;Internet of Things;Real-time systems;5G mobile communication;Feature extraction;Delays","","1","","60","IEEE","1 Nov 2022","","","IEEE","IEEE Journals"
"Federated Learning Over Wireless IoT Networks With Optimized Communication and Resources","H. Chen; S. Huang; D. Zhang; M. Xiao; M. Skoglund; H. V. Poor","School of Electrical Engineering and Computer Science, Royal Institute of Technology, Stockholm, Sweden; School of Electrical Engineering and Computer Science, Royal Institute of Technology, Stockholm, Sweden; School of Electrical Engineering and Computer Science, Royal Institute of Technology, Stockholm, Sweden; School of Electrical Engineering and Computer Science, Royal Institute of Technology, Stockholm, Sweden; School of Electrical Engineering and Computer Science, Royal Institute of Technology, Stockholm, Sweden; Department of Electrical and Computer Engineering, Princeton University, Princeton, NJ, USA","IEEE Internet of Things Journal","24 Aug 2022","2022","9","17","16592","16605","To leverage massive distributed data and computation resources, machine learning in the network edge is considered to be a promising technique, especially for large-scale model training. Federated learning (FL), as a paradigm of collaborative learning techniques, has obtained increasing research attention with the benefits of communication efficiency and improved data privacy. Due to the lossy communication channels and limited communication resources (e.g., bandwidth and power), it is of interest to investigate fast responding and accurate FL schemes over wireless systems. Hence, we investigate the problem of jointly optimized communication efficiency and resources for FL over wireless Internet of Things (IoT) networks. To reduce complexity, we divide the overall optimization problem into two subproblems, i.e., the client scheduling problem and the resource allocation problem. To reduce the communication costs for FL in wireless IoT networks, a new client scheduling policy is proposed by reusing stale local model parameters. To maximize successful information exchange over networks, a Lagrange multiplier method is first leveraged by decoupling variables, including power variables, bandwidth variables, and transmission indicators. Then, a linear-search-based power and bandwidth allocation method is developed. Given appropriate hyperparameters, we show that the proposed communication-efficient FL (CEFL) framework converges at a strong linear rate. Through extensive experiments, it is revealed that the proposed CEFL framework substantially boosts both the communication efficiency and learning performance of both training loss and test accuracy for FL over wireless IoT networks compared to a basic FL approach with uniform resource allocation.","2327-4662","","10.1109/JIOT.2022.3151193","ERA-NET Smart Energy Systems SG+ 2017 Program through “SMART-MLA” Project(grant numbers:89029,42811-2); FORMAS Project titled “Intelligent Energy Management in Smart Community with Distributed Machine Learning”(grant numbers:2021-00306); Swedish Research Council Project titled “Coding for Large-Scale Distributed Machine Learning”(grant numbers:2021-04772); Digital Futures Postdoc Fellowships; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9712615","Communication efficiency;federated learning (FL);resource allocation;wireless Internet of Things (IoT) networks","Wireless communication;Training;Internet of Things;Resource management;Data models;Collaborative work;Bandwidth","","32","","53","IEEE","14 Feb 2022","","","IEEE","IEEE Journals"
"Content Object Security in the Internet of Things: Challenges, Prospects, and Emerging Solutions","C. Gündoğan; C. Amsüss; T. C. Schmidt; M. Wählisch","Internet Technologies Group, Hamburg University of Applied Sciences (HAW), Hamburg, Germany; NA; Internet Technologies Group, Hamburg University of Applied Sciences (HAW), Hamburg, Germany; Department of Computer Science, Freie Universität Berlin, Berlin, Germany","IEEE Transactions on Network and Service Management","10 Mar 2022","2022","19","1","538","553","Content objects are confined data elements that carry meaningful information. Massive amounts of content objects are published and exchanged every day on the Internet. The emerging Internet of Things (IoT) augments the network edge with reading sensors and controlling actuators that comprise machine-to-machine communication using small data objects. IoT content objects are often messages that fit into single IPv6 datagram. These IoT messages frequently traverse protocol translators at gateways, which break end-to-end transport and security of Internet protocols. To preserve content security from end to end via gateways and proxies, the IETF recently developed Object Security for Constrained RESTful Environments (OSCORE), which extends the Constrained Application Protocol (CoAP) with content object security features commonly known from Information Centric Networking (ICN). This paper revisits the current IoT protocol architectures and presents a comparative analysis of protocol stacks that protect request-response transactions. We discuss features and limitations of the different protocols and analyze emerging functional extensions. We measure the protocol performances of CoAP over Datagram Transport Layer Security (DTLS), OSCORE, and the information-centric Named Data Networking (NDN) protocol on a large-scale IoT testbed in single- and multi-hop scenarios. Our findings indicate that (a) OSCORE improves on CoAP over DTLS in error-prone wireless regimes due to omitting the overhead of maintaining security sessions at endpoints, (b) NDN attains superior robustness and reliability due to its intrinsic network caches and hop-wise retransmissions, and (c) OSCORE/CoAP offers room for improvement and optimization in multiple directions.","1932-4537","","10.1109/TNSM.2021.3099902","German Federal Ministry for Education and Research (BMBF) within the project PIVOT – Privacy-Integrated design and Validation in the constrained IoT, and the Hamburg ahoi.digital initiative; Ericsson AB; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9495929","IoT protocol architecture;CoAP;OSCORE;DTLS;ICN;secure networking;protocol evaluation;network experimentation","Protocols;Logic gates;Cryptography;Internet of Things;Sensors;Internet;Wireless sensor networks","","10","","62","IEEE","26 Jul 2021","","","IEEE","IEEE Journals"
"Nexus of Deep Reinforcement Learning and Leader–Follower Approach for AIoT Enabled Aerial Networks","G. Raja; S. Essaky; A. Ganapathisubramaniyan; Y. Baskar","NGNLab, Department of Computer Technology, Anna University, MIT Campus, Chennai, India; NGNLab, Department of Computer Technology, Anna University, MIT Campus, Chennai, India; Foreign Exchange and Local Markets Group, Citicorp Services India Private Ltd., Chennai, India; NGNLab, Department of Computer Technology, Anna University, MIT Campus, Chennai, India","IEEE Transactions on Industrial Informatics","13 Jul 2023","2023","19","8","9165","9172","The Industrial Internet of Things (IIoT) is a new industrial 4.0 paradigm that combines IoT, robotics, cyber-physical systems, and other future industrial advancements. Unmanned aerial vehicles (UAVs), part of the IIoT infrastructure, have a significant potential for civil and military purposes. Through the artificial intelligence of things (AIoT), a well-organized group of UAVs outperforms a single large UAV in terms of device scalability, maintenance, and expense. Therefore, the UAV swarm with industry 4.0 intelligence can be used for a wide range of 24/7 security and remote monitoring applications. Though multi-UAV systems are beneficial, their application has many challenges. There is a high risk of collision in the multi-UAV system without coordination. This article proposes an AIoT-based navigation and formation control (AIoT-NFC) mechanism to scale down the collision risk by combining deep reinforcement learning (DRL) with the leader–follower approach. In AIoT-NFC, a deep deterministic policy gradient (DDPG) based algorithm is proposed to navigate UAVs in remote surveillance without colliding with obstacles and other UAVs. Furthermore, the AIoT-NFC system incorporates a fault tolerance mechanism that can handle the scenario of a leader's failure due to actuator malfunction. Experimental results show that the AIoT-NFC achieves faster convergence with a lower collision rate. AIoT-NFC reduced the collision rate by 14.99% compared to existing navigation methods in successful formation without colliding with the other UAVs.","1941-0050","","10.1109/TII.2022.3226529","NGNLab, Department of Computer Technology, Anna University, Chennai, India; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9969936","Artificial Intelligence of Things (AIoT);deep reinforcement learning (DRL);industrial internet of things (IIoT);navigation and formation control (NFC);remote surveillance;unmanned aerial vehicles (UAV)","Navigation;Autonomous aerial vehicles;Surveillance;Industrial Internet of Things;Monitoring;Mathematical models;Collision avoidance","","","","33","IEEE","5 Dec 2022","","","IEEE","IEEE Journals"
"An Energy-Efficient Time-Domain Binary Neural Network Accelerator with Error-Detection in 28nm CMOS","Y. Du; X. Shang; W. Shan","School of Electronic Science and Engineering, Southeast University, Nanjing, P. R. China; School of Electronic Science and Engineering, Southeast University, Nanjing, P. R. China; School of Electronic Science and Engineering, Southeast University, Nanjing, P. R. China","2020 IEEE Asia Pacific Conference on Circuits and Systems (APCCAS)","29 Dec 2020","2020","","","70","73","Due to the increasing demand of high energy-efficient processor for deep neural networks, traditional neural network accelerators with high-precision weights and activations that usually occupies huge on/off-chip resources with large power consumption is no longer suitable for internet-of-things applications. Binary neural networks (BNNs) reduce memory size and computation complexity, achieving drastically increased energy efficiency. In this paper, an energy-efficient time-domain binary neural network accelerator is optimized for image recognition, with time-domain accumulation (TD-MAC), timing error detection based adaptive voltage scaling design and the related approximate computing. The proposed key features are: 1) an error-tolerant adaptive voltage scaling system with TD-MAC chain truncation for aggressive power reduction, working from near-threshold to normal voltage; 2) architectural parallelism and data reuse with 100% TD-MAC utilization; 3) low power TD-MAC based on analog delay lines. Fabricated in a 28nm CMOS process, our timing error detection based adaptive voltage scaling design enables the whole system achieves a maximum 51.5TOPS/W energy efficiency at 0.42V and 25MHz, with 99.6% accuracy on MNIST dataset.","","978-1-7281-9396-0","10.1109/APCCAS50809.2020.9301692","National Natural Science Foundation of China; Aeronautical Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9301692","time domain;binary neural network;analog delay line;adaptive voltage scaling;error resilience","Timing;Energy efficiency;Neural networks;Time-domain analysis;Random access memory;Biological neural networks;Arrays","","5","","9","IEEE","29 Dec 2020","","","IEEE","IEEE Conferences"
"An Online Model to Minimize Energy Consumption of IoT Sensors in Smart Cities","M. Al-Hawawreh; I. Elgendi; K. Munasinghe","School of Information Technology, Deakin University, Geelong, VIC, Australia; University of Canberra, Bruce, ACT, Australia; University of Canberra, Bruce, ACT, Australia","IEEE Sensors Journal","17 Oct 2022","2022","22","20","19524","19532","The Internet of Things (IoT), which allows systems of billions or trillions of “things,” such as sensors, to communicate with each other over the Internet, is encountering several technical and application challenges. One of these challenges is that IoT sensors send redundant and self-similar data to the edge gateways consuming a large amount of energy and making it extremely difficult to obtain an appropriate network lifetime, which has become a bottleneck in scaling such applications. To address these issues, we propose a new solution based on powering sensors using artificial intelligence to make smart decisions about transmitting collected readings. We take advantage of autocorrelation (AC) to detect self-similarity and propose updating mechanism that employs deep reinforcement learning (RL). Our proposed model is a real-time model that can determine the redundant data and self-similarity and then make the smart decision about transmitting data. We evaluate our proposed solution using measurements obtained from Queanbeyan smart city, Australia, and available-public dataset and show that our proposed model can reduce the amount of transmitted data and minimize the power consumption of sensors.","1558-1748","","10.1109/JSEN.2022.3199590","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9866004","Autocorrelation (AC);energy consumption;Internet of Things (IoT);reinforcement learning (RL);smart city","Sensors;Intelligent sensors;Data models;Internet of Things;Temperature sensors;Logic gates;Predictive models","","4","","28","IEEE","23 Aug 2022","","","IEEE","IEEE Journals"
"AutoFlex: Unified Evaluation and Design Framework for Flexible Hybrid Electronics","T. Ma; Z. Deng; L. Shao","Shanghai Jiao Tong University, Minhang, Shanghai, China; Shanghai Jiao Tong University, Minhang, Shanghai, China; Shanghai Jiao Tong University, Minhang, Shanghai, China","2023 28th Asia and South Pacific Design Automation Conference (ASP-DAC)","23 Feb 2023","2023","","","757","762","Flexible hybrid electronics (FHE), integrating high performance silicon chips with multi-functional sensors and actuators on flexi-ble substrates, can be intimately attached onto irregular surfaces without compromising their functionalities, thus enabling more innovations in healthcare, internet of things (IoTs) and various human-machine interfaces (HMIs). Recent developments on com-pact models and process design kits (PDKs) of flexible electronics have made designs of small to medium flexible circuits feasible. However, the absence of a unified model and comprehensive eval-uation benchmarks for flexible electronics makes it infeasible for a designer to fairly compare different flexible technologies and to explore potential design options for a heterogeneous FHE design. In this paper, we present AutoFlex, a unified evaluation and design framework for flexible hybrid electronics, where device parameters can be extracted automatically and performance can be evaluated comprehensively from device levels, digital blocks to large-scale digital circuits. Moreover, a ubiquitous FHE sensor acquisition system, including a flexible multi-functional sensor array, scan drivers, amplifiers and a silicon based analog-to-digital converter (ADC), is developed to reveal the design challenges of a representative FHE system.","2153-697X","978-1-4503-9783-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10044846","Flexible hybrid electronics;design automation;flexible electronics;heterogeneous system design;hardware/software co-design","Technological innovation;System performance;Benchmark testing;Silicon;Sensor systems;Sensors;Internet of Things","","","","25","","23 Feb 2023","","","IEEE","IEEE Conferences"
"Efficient Data Access Control With Fine-Grained Data Protection in Cloud-Assisted IIoT","S. Qi; Y. Lu; W. Wei; X. Chen","State Key Laboratory of Integrated Service Networks, Xidian University, Xi’an, China; School of Computer Science and Technology, Xi’an Jiaotong University, Xi’an, China; School of Computer and Engineering, Xi’an University of Technology, Xi’an, China; State Key Laboratory of Integrated Service Networks, Xidian University, Xi’an, China","IEEE Internet of Things Journal","5 Feb 2021","2021","8","4","2886","2899","The Industrial Internet of Things (IIoT) has provided a promising opportunity to build digitalized industrial systems. A fundamental technology of IIoT is the radio-frequency identification (RFID) technique, which allows industrial participants to identify items and anchor time-series IoT data for them. They can further share the IoT data through the cloud service to enable information exchange and support critical decisions in production operations. Storing IoT data in the cloud, however, requires a data access control mechanism to protect sensitive business issues. Unfortunately, using traditional cryptographic access control schemes for time-series IoT data face severe efficiency and key leakage problems. In this article, we design a secure industrial data access control scheme for cloud-assisted IIoT. Our scheme enables participants to enforce fine-grained access control policies for their IoT data via ciphertext policy-attribute-based encryption (CP-ABE) scheme. Our scheme adopts a hybrid cloud infrastructure for participants to outsource expensive CP-ABE tasks to the cloud service with strong privacy guarantees. Importantly, our scheme guarantees a new privacy notion named item-level data protection for IoT data to prevent key leakage problem. We achieve these goals via several encryption and optimization techniques. Our performance assessments combine system implementation with large-scale emulations and confirm the security and efficiency of our design.","2327-4662","","10.1109/JIOT.2020.3020979","National Nature Science Foundation of China(grant numbers:61960206014,61602363); Fundamental Research Funds for the Central Universities(grant numbers:XJS191502); National Key Research and Development Program of China(grant numbers:2018YFB1402700); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9184078","Access control;cloud;Industrial Internet of Things (IIoT);radio-frequency identification (RFID);time-series IoT data","Cloud computing;Time series analysis;Task analysis;Access control;Production;Data protection;Encryption","","60","","56","IEEE","1 Sep 2020","","","IEEE","IEEE Journals"
"Fuzzing the Internet of Things: A Review on the Techniques and Challenges for Efficient Vulnerability Discovery in Embedded Systems","M. Eceiza; J. L. Flores; M. Iturbe","Department of Industrial Cybersecurity, IKERLAN Technology Research Center, Basque Research and Technology Alliance, Arrasate-Mondragón, Spain; Department of Industrial Cybersecurity, IKERLAN Technology Research Center, Basque Research and Technology Alliance, Arrasate-Mondragón, Spain; Department of Computing and Electronics, Faculty of Engineering, Mondragon Unibertsitatea, Arrasate-Mondragón, Spain","IEEE Internet of Things Journal","22 Jun 2021","2021","8","13","10390","10411","With a growing number of embedded devices that create, transform, and send data autonomously at its core, the Internet of Things (IoT) is a reality in different sectors, such as manufacturing, healthcare, or transportation. With this expansion, the IoT is becoming more present in critical environments, where security is paramount. Infamous attacks, such as Mirai, have shown the insecurity of the devices that power the IoT, as well as the potential of such large-scale attacks. Therefore, it is important to secure these embedded systems that form the backbone of the IoT. However, the particular nature of these devices and their resource constraints mean that the most cost-effective manner of securing these devices is to secure them before they are deployed, by minimizing the number of vulnerabilities they ship. To this end, fuzzing has proved itself as a valuable technique for automated vulnerability finding, where specially crafted inputs are fed to programs in order to trigger vulnerabilities and crash the system. In this survey, we link the world of embedded IoT devices and fuzzing. For this end, we list the particularities of the embedded world as far as security is concerned, we perform a literature review on fuzzing techniques and proposals, studying their applicability to embedded IoT devices and, finally, we present future research directions by pointing out the gaps identified in the review.","2327-4662","","10.1109/JIOT.2021.3056179","Ayudas Cervera para Centros Tecnológicos Grant of the Spanish Centre for the Development of Industrial Technology (CDTI)(grant numbers:EGIDA CER-20191012); Intelligent Systems for Industrial Systems, financed by the Department of Education, Linguistic Policy and Culture of the Basque Government; Department of Economic Development, Sustainability and Environment of the Basque Government through the Bikaintek program(grant numbers:20-AF-W2-2019-00006); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9344712","Embedded system;fuzzing;internet of Things (IoT);software testing;vulnerabilities","Fuzzing;Embedded systems;Security;Internet of Things;Task analysis;Software;Hardware","","12","","156","CCBY","2 Feb 2021","","","IEEE","IEEE Journals"
"Intelligent Intrusion Detection for Internet of Things Security: A Deep Convolutional Generative Adversarial Network-Enabled Approach","Y. Wu; L. Nie; S. Wang; Z. Ning; S. Li","School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; Chinese Academy of Sciences, Institute of Information Engineering, Beijing, China; School of Software, Dalian University of Technology, Dalian, China; School of Information Science and Engineering, Shandong Normal University, Jinan, China","IEEE Internet of Things Journal","6 Feb 2023","2023","10","4","3094","3106","With the rapid advance of Internet of Things (IoT), it is difficult for cloud-centric computing to meet the requirements of low latency and ease of use. As an open and distributed system, edge computing integrates computing, networking, storage, and applications. It provides intelligent services on the edge of an IoT. The edge network is composed of various wireless and wired networks, and the computing and storage resources of edge nodes are limited. These conditions make the edge network expose to a variety of cyber attacks. Additionally, it is difficult for an IoT edge node to support large-scale network data collection and detection for IoT security. Although big data-enabled intrusion detection algorithms can ensure the high accuracy of intrusion detection systems, it is stressful for resource-limited edge nodes to implement those algorithms in IoT. Motivated by these challenges, we propose an intelligent intrusion detection algorithm implemented by big data mining based on a fuzzy rough set, generative adversarial network (GAN), and convolutional neural network (CNN). In our method, we first propose a fuzzy rough set-based algorithm to perform feature selection for big data via IoT. Then, we take advantage of the efficient feature extraction capabilities of CNN for implementing intrusion detection based on selected features. Furthermore, after combining CNN and GAN, we propose an intelligent algorithm to realize intrusion detection in a variety of scenarios. Finally, the proposed method is compared with existing methods for evaluation. Simulation results show that our method has up to 4% higher accuracy than existing methods.","2327-4662","","10.1109/JIOT.2021.3112159","National Natural Science Foundation of China(grant numbers:61931019,61971084,62001073,62171378,61803238); Dalian Young Science and Technology Star(grant numbers:2020RQ002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9536565","Convolutional neural network (CNN);edge computing;generative adversarial network (GAN);intrusion detection","Image edge detection;Intrusion detection;Feature extraction;Convolutional neural networks;Computational modeling;Internet of Things;Generative adversarial networks","","12","","48","IEEE","13 Sep 2021","","","IEEE","IEEE Journals"
"Witness-based Approach for Scaling Distributed Ledgers to Massive IoT Scenarios","D. -L. Nguyen; I. Leyva-Mayorga; P. Popovski","Connectivity Section, Department of Electronic Systems, Aalborg University, Aalborg, Denmark; Connectivity Section, Department of Electronic Systems, Aalborg University, Aalborg, Denmark; Connectivity Section, Department of Electronic Systems, Aalborg University, Aalborg, Denmark","2020 IEEE 6th World Forum on Internet of Things (WF-IoT)","13 Oct 2020","2020","","","1","6","Distributed Ledger Technologies (DLTs) are playing a major role in building security and trust in Internet of Things (IoT) systems. However, IoT deployments with a large number of devices, such as in environment monitoring applications, generate and send massive amounts of data. This would generate vast number of transactions that must be processed within the distributed ledger. In this work, we first demonstrate that the Proof of Work (PoW) blockchain fails to scale in a sizable IoT connectivity infrastructure. To solve this problem, we present a lightweight distributed ledger scheme to integrate PoW blockchain into IoT. In our scheme, we classify transactions into two types: 1) global transactions, which must be processed by global blockchain nodes and 2) local transactions, which can be processed locally by entities called witnesses. Performance evaluation demonstrates that our proposed scheme improves the scalability of integrated blockchain and IoT monitoring systems by processing a fraction of the transactions, inversely proportional to the number of witnesses, locally. Hence, reducing the number of global transactions.","","978-1-7281-5503-6","10.1109/WF-IoT48130.2020.9221269","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9221269","Distributed Ledgers;Blockchain;IoT;Witness;Environment Monitoring;scalability","Performance evaluation;Distributed ledger;Scalability;Buildings;Proof of Work;Blockchains;Internet of Things","","3","","11","IEEE","13 Oct 2020","","","IEEE","IEEE Conferences"
"Physical-Level Parallel Inclusive Communication for Heterogeneous IoT Devices","S. Yu; X. Zhang; P. Huang; L. Guo","Clemson University, Clemson, SC, USA; Florida State University, Tallahassee, FL, USA; Clemson University, Clemson, SC, USA; Clemson University, Clemson, SC, USA","IEEE INFOCOM 2022 - IEEE Conference on Computer Communications","20 Jun 2022","2022","","","380","389","The proliferation of Internet of Things (IoT) has transformed the way people interact with the world. Various kinds of wireless protocols have been developed to support diverse types of IoT communications. Unfortunately, the lack of spectrum resources puts a hard limit on managing the large-scale heterogeneous IoT system. Although previous works alleviate this strain by coordinating transmission power, time slots, and sub-channels, they may not be feasible in future IoT applications with dense deployments. In this paper, we explore a physical-level parallel inclusive communication paradigm for the coexistence of Wi-Fi and ZigBee, which leverages novel bits embedding approaches on the OQPSK protocol to enable both Wi-Fi and ZigBee IoT devices to decode the same inclusive signals at the same time but with each one’s different data. By carefully crafting the inclusive signals using legacy Wi-Fi protocol, the overlapping spectrum can be simultaneously re-used by both protocols, expecting a maximum data rate (250kbps) for ZigBee devices and up to 3.75Mbps for a Wi-Fi pair over only a 2MHz bandwidth. The achieved spectrum efficiency outperforms a majority of CTC schemes and parallel communication designs. Compared with existing works on parallel communication, our proposed system is the first one that achieves an entire software-level design, which can be readily implemented on Commercial Off-The-Shelf (COTS) devices without any hardware modification. Based on extensive real-world experiments on both USRP and COTS device platforms, we demonstrate the feasibility, generality, and efficiency of the proposed new paradigm.","2641-9874","978-1-6654-5822-1","10.1109/INFOCOM48880.2022.9796876","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796876","Parallel Inclusive Communication;Cross-Technology Communication;Wireless Coexistence;Spectrum Efficiency","Wireless communication;Performance evaluation;Protocols;Zigbee;Receivers;Throughput;Decoding","","1","","39","IEEE","20 Jun 2022","","","IEEE","IEEE Conferences"
"Modeling and Analysis of Data Trading on Blockchain-Based Market in IoT Networks","L. D. Nguyen; I. Leyva-Mayorga; A. N. Lewis; P. Popovski","Department of Electronic System, Connectivity Section, Aalborg University, Aalborg, Denmark; Department of Electronic System, Connectivity Section, Aalborg University, Aalborg, Denmark; Donald Bren School of Information and Computer Sciences, University of California at Irvine, Irvine, CA, USA; Department of Electronic System, Connectivity Section, Aalborg University, Aalborg, Denmark","IEEE Internet of Things Journal","7 Apr 2021","2021","8","8","6487","6497","Mobile devices with embedded sensors for data collection and environmental sensing create a basis for a cost-effective approach for data trading. For example, these data can be related to pollution and gas emissions, which can be used to check the compliance with national and international regulations. The current approach for IoT data trading relies on a centralized third-party entity to negotiate between data consumers and data providers, which is inefficient and insecure on a large scale. In comparison, a decentralized approach based on distributed ledger technologies (DLT) enables data trading while ensuring trust, security, and privacy. However, due to the lack of understanding of the communication efficiency between sellers and buyers, there is still a significant gap in benchmarking the data trading protocols in IoT environments. Motivated by this knowledge gap, we introduce a model for DLT-based IoT data trading over the narrowband Internet-of-Things (NB-IoT) system, intended to support massive environmental sensing. We characterize the communication efficiency of three basic DLT-based IoT data trading protocols via NB-IoT connectivity in terms of latency and energy consumption. The model and analyses of these protocols provide a benchmark for IoT data trading applications.","2327-4662","","10.1109/JIOT.2021.3051923","European Research Council (Horizon 2020 ERC Consolidator)(grant numbers:648382 WILLOW); European Union’s Horizon 2020 Program(grant numbers:957218 IntellIoT); Independent Research Fund Denmark (DFF)(grant numbers:8022-00284B (SEMIOTIC),9165-00001B (GROW)); National Science Foundation Graduate Research Fellowship(grant numbers:DGE-1839285); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9324804","Blockchain;data trading;distributed ledger technology (DLT);Internet of Things (IoT);narrowband IoT (NB-IoT);smart contract;smart city","Distributed databases;Internet of Things;Distributed ledger;Sensors;Downlink;Data models;Blockchain","","40","","23","CCBY","14 Jan 2021","","","IEEE","IEEE Journals"
"PCBChain: Lightweight Reconfigurable Blockchain Primitives for Secure IoT Applications","W. Yan; N. Zhang; L. L. Njilla; X. Zhang","Department of Electrical and System Engineering, Washington University in St. Louis, St. Louis, USA; Department of Computer and System Engineering, Washington University in St. Louis, St. Louis, USA; U.S. Air Force Research Laboratory, Rome, USA; Department of Electrical and System Engineering, Washington University in St. Louis, St. Louis, USA","IEEE Transactions on Very Large Scale Integration (VLSI) Systems","25 Sep 2020","2020","28","10","2196","2209","In the era of ubiquitous intelligence, the Internet of Things (IoT) holds the promise as a breakthrough technology to enable diverse applications that benefit societal problems. Yet interconnecting myriad heterogeneous IoT devices across various application domains remain a security challenge. Decentralized technology has recently emerged as a powerful primitive in building distributed applications to facilitate secure transactions between mutually distrustful parties in a trustworthy manner. Unfortunately, these decentralized protocols demand computing resources and power far beyond the reach of resource-constrained IoT devices, preventing the full adoption of distributed consensus platform in the IoT setting. In this article, we address the key bottleneck to enable blockchain in resource-constrained IoT devices. We propose a lightweight implementation of proof-of-work (PoW) mining with reconfigurable hardware primitives. By replacing the hash and cryptographic functions in classic blockchain protocol with secure and efficient hardware implementations, our proposed solution can significantly reduce hardware resources and power overheads of PoW mining, while improving the transaction speed of large-scale IoT systems. Finally, we demonstrate the algorithm by proposing an antispoofing solution for GPS navigation among lightweight IoT devices. As a replacement for position computation, a mining process generates the expected coordinates with the correct initial value and function configuration.","1557-9999","","10.1109/TVLSI.2020.3014155","U.S. Air Force Material Command(grant numbers:ICA2018-UP-LN); U.S. National Science Foundation(grant numbers:CNS-1657562,CNS-1916926); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9165861","Blockchain;configurable nonlinear feedback shift register (CNLFSR);Internet of Things (IoT) security;lightweight hardware primitives;physical unclonable function (PUF)","Protocols;Hardware;Cryptography;Internet of Things;Network topology","","17","","53","IEEE","12 Aug 2020","","","IEEE","IEEE Journals"
"A Large-Scale Empirical Study on the Vulnerability of Deployed IoT Devices","B. Zhao; S. Ji; W. -H. Lee; C. Lin; H. Weng; J. Wu; P. Zhou; L. Fang; R. Beyah","College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China; IBM T.J. Watson Research Center, Armonk, NY, USA; Zhejiang Gongshang University, Hangzhou, Zhejiang, China; Ant Group, Hangzhou, Zhejiang, China; Institute of Software, Chinese Academy of Sciences, Beijing, China; Hubei Engineering Research Center on Big Data Security, School of Cyber Science and Engineering, Huazhong University of Science and Technology, Wuhan, Hubei, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, Jiangsu, China; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA","IEEE Transactions on Dependable and Secure Computing","12 May 2022","2022","19","3","1826","1840","The Internet of Things (IoT) has become ubiquitous and greatly affected peoples’ daily lives. With the increasing development of IoT devices, the corresponding security issues are becoming more and more challenging. Such a severe security situation raises the following questions that need urgent attention: What are the primary security threats that IoT devices face currently? How do vendors and users deal with these threats? In this article, we aim to answer these critical questions through a large-scale systematic study. Specifically, we perform a ten-month-long empirical study on the vulnerability of 1,362,906 IoT devices varying from six types. The results show sufficient evidence that N-days vulnerability is seriously endangering the IoT devices: 385,060 (28.25 percent) devices suffer from at least one N-days vulnerability. Moreover, 2669 of these vulnerable devices may have been compromised by botnets. We further reveal the massive differences among five popular IoT search engines: Shodan [1], Censys [2], [3], Zoomeye [4], Fofa [5], and NTI [6]. To study whether vendors and users adopt defenses against the threats, we measure the security of MQTT [7] servers, and identify that 12740 (88 percent) MQTT servers have no password protection. Our analysis can serve as an important guideline for investigating the security of IoT devices, as well as advancing the development of a more secure environment for IoT systems.","1941-0018","","10.1109/TDSC.2020.3037908","National Key Research and Development Program of China(grant numbers:2018YFB0804102); National Natural Science Foundation of China(grant numbers:61772466,U1936215,U1836202); Zhejiang Provincial Natural Science Foundation for Distinguished Young Scholars(grant numbers:LR19F020003); Zhejiang Provincial Key R&D Program(grant numbers:2019C01055); Fundamental Research Funds for the Central Universities; Army Research Laboratory; Ministry of Defence(grant numbers:W911NF-16-3-0001); State Key Laboratory of Information Security(grant numbers:2020-MS-12); Natural Science Foundation of Zhejiang Province(grant numbers:LQ21F020010); National Natural Science Foundation of China(grant numbers:61772507,61972448,61872181); Zhejiang University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9259111","IoT search engine;vulnerable device assessment","Security;Search engines;Internet of Things;Internet;Servers;Engines;Password","","16","","61","IEEE","13 Nov 2020","","","IEEE","IEEE Journals"
"Characterizing Heterogeneous Internet of Things Devices at Internet Scale Using Semantic Extraction","K. Yang; Y. Zhang; X. Lin; Z. Li; L. Sun","Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Search R&D Department, Baidu Tech, Beijing, China; School of Computer Science, University of Guelph, Guelph, ON, Canada; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China","IEEE Internet of Things Journal","24 Mar 2022","2022","9","7","5434","5446","Along with the rapid-growth number of Internet of Things (IoT) devices, significant security concerns are raised due to the hidden vulnerabilities among them. Illuminating the characteristics of online devices would shed a light on protecting these potential vulnerable devices. State-of-arts methodologies enumerate devices characteristics as keywords and rules and match them with IoT network data. However, the heterogeneous implementations of IoT devices introduce intricate characteristics features, which impede the large-scale identification. In this work, we close this gap and present a semantic extraction-based approach that can automatically and effectively characterize online devices. We leverage the observation that IoT devices can be identified by analyzing the semantic information of the network packets. Specifically, we first collect the network data of IoT devices and utilize a co-training algorithm to annotate the data. We propose a residual dilate gated convolutional neural network (RDGCNN)-based encoder to extract semantic features from the annotated data. Then, we put forward an entity relationship-based decoder to generate the characteristic triplet (type, brand, and model) of IoT devices by decoding extracted features. We have implemented the prototype of the system and conducted real-world experiments to evaluate the performance. Results show that our approach achieves 92.16% precision and 86.79% recall. In addition, we apply our proposed method to characterize 15 millions IoT devices on the Internet.","2327-4662","","10.1109/JIOT.2021.3110757","Key Program of National Natural Science Foundation of China(grant numbers:U1766215); National Key Research and Development Program of China(grant numbers:Y810021104,Y950201104); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9530590","Fingerprinting;Internet measurement;Internet of Things","Semantics;Feature extraction;Data mining;Internet of Things;Object recognition;Decoding;Data models","","5","","51","IEEE","7 Sep 2021","","","IEEE","IEEE Journals"
"Developing Energy Monitoring Application For Monitoring Power Consumption In Production Machines","M. Tarigan; A. Pambudi; H. Sutopo; H. Hendra; D. Handayani","Faculty of Computer Science, Universitas Esa Unggul, Jakarta, Indonesia; School Economic and Management, North China Electric Power University, Beijing, China; Kalbis Institute, Jakarta, Indonesia; Faculty of Computer Science, Universitas Esa Unggul, Jakarta, Indonesia; Faculty of Computer Science, Universitas Esa Unggul, Jakarta, Indonesia","2021 3rd International Conference on Advances in Computer Technology, Information Science and Communication (CTISC)","6 Sep 2021","2021","","","42","46","The manufacturing sector in Indonesia is included in the category of countries with large-scale industries. Every day, of course, activities in the industrial sector need a production process and require electric power as a support for ongoing productivity. The power consumption used in the production process needs monitoring and control as needed. Monitoring the power consumption of machines in the PT. Modern Gravure Indonesia has not been well monitored. To make efforts in calculating the amount of electrical power used, a system that can monitor the amount of power consumption on production machines in real-time is needed for carrying out better electricity management. Then an Internet of Things-based system is made which is integrated into the Android-based Energy Monitoring application for monitoring power consumption and cost calculations, this monitoring system for monitoring power consumption uses the STC013 Current sensor as a flow detector and uses the Arduino Pro Mini as a microcontroller in developing a power consumption monitoring system. This research uses System Development Life Cycle that consists of planning, analysis, design, implementation, testing and integration, and maintenance. stakeholders. This Energy Monitoring application is expected to help get real-time power consumption data.","","978-1-6654-1868-3","10.1109/CTISC52352.2021.00015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9527722","EMon;power consumption monitoring;SCT013 Sensor;production machine;internet of things","Productivity;Power demand;Process control;Real-time systems;Power systems;Planning;Stakeholders","","1","","20","IEEE","6 Sep 2021","","","IEEE","IEEE Conferences"
"Preventing IoT DDoS Attacks using Blockchain and IP Address Obfuscation","G. He; Y. Si; X. Xiao; Q. Wei; H. Zhu; B. Xu","School of Internet of Things, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Internet of Things, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Internet of Things, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Internet of Things, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Internet of Things, Nanjing University of Posts and Telecommunications, Nanjing, China; College of Information Science and Technology, Nanjing Forestry University, Nanjing, China","2021 13th International Conference on Wireless Communications and Signal Processing (WCSP)","1 Dec 2021","2021","","","1","5","With the widespread deployment of Internet of Things (IoT) devices, hackers can use IoT devices to launch large-scale distributed denial of service (DDoS) attacks, which bring great harm to the Internet. However, how to defend against these attacks remains to be an open challenge. In this paper, we propose a novel prevention method for IoT DDoS attacks based on blockchain and obfuscation of IP addresses. Our observation is that IoT devices are usually resource-constrained and cannot support complicated cryptographic algorithms such as RSA. Based on the observation, we employ a novel authentication then communication mechanism for IoT DDoS attack prevention. In this mechanism, the attack targets' IP addresses are encrypted by a random security parameter. Clients need to be authenticated to obtain the random security parameter and decrypt the IP addresses. In particular, we propose to authenticate clients with public-key cryptography and a blockchain system. The complex authentication and IP address decryption operations disable IoT devices and thus block IoT DDoS attacks. The effectiveness of the proposed method is analyzed and validated by theoretical analysis and simulation experiments.","2472-7628","978-1-6654-0785-4","10.1109/WCSP52459.2021.9613370","National Natural Science Foundation of China(grant numbers:61802192,61802206,61702282); Fundamental Research Funds for the Central Universities(grant numbers:NJ2020022); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9613370","Internet of things;Distributed denial of service;Blockchain;Identity authentication;IP address obfuscation","Wireless communication;Computer hacking;Authentication;Signal processing algorithms;Signal processing;Denial-of-service attack;Blockchains","","1","","16","IEEE","1 Dec 2021","","","IEEE","IEEE Conferences"
"Research on Panoramic Monitoring of Distributed Photovoltaic Power Station Based on Power Iot Platform","L. Ming; C. Hang; D. Xiaoling; Y. Dongbo","Information &TeleCommuniccation Branch, State Grid Anhui Electric Power Co., Ltd, Hefei, China; Information &TeleCommuniccation Branch, State Grid Anhui Electric Power Co., Ltd, Hefei, China; Information &TeleCommuniccation Branch, State Grid Anhui Electric Power Co., Ltd, Hefei, China; Information &TeleCommuniccation Branch, State Grid Anhui Electric Power Co., Ltd, Hefei, China","2023 IEEE International Conference on Sensors, Electronics and Computer Engineering (ICSECE)","29 Sep 2023","2023","","","1206","1210","In this paper, distributed monitoring structure is used to configure various types of acquisition units and monitoring units based on the power Internet of Things. The purpose is to realize the real-time monitoring of the photovoltaic controller and the equipment in various stations. The system hardware design data detection module, data monitoring module, processor and data processing module. The system establishes a monitoring strategy covering resource information statistics, power generation capacity prediction, power station operation monitoring and operation characteristics analysis from four aspects: power generation space control, power generation process control, operation and maintenance implementation control and post-evaluation. The software design of the system is completed by processing the monitoring data of distributed photovoltaic power station and designing the monitoring process of distributed photovoltaic power station. The operation results show that the monitoring system designed and implemented according to this method runs stably and reliably, and fully meets the requirements of large-scale photovoltaic power generation monitoring.","","979-8-3503-1373-4","10.1109/ICSECE58870.2023.10263461","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10263461","electric Internet of Things;photovoltaic power station;distributed power supply;panoramic monitoring system","Photovoltaic systems;Wireless communication;Wireless sensor networks;Software design;Space power stations;Maintenance engineering;Aerospace electronics","","","","8","IEEE","29 Sep 2023","","","IEEE","IEEE Conferences"
"Research on the Method of Intelligent Vehicle Management Analysis and System Design","C. Dong; W. Guowei; H. Kai","Department of Automotive Engineering, Weifang Engineering Vocational College, Weifang, Shandong, China; Department of Automotive Engineering, Weifang Engineering Vocational College, Weifang, Shandong, China; Department of Automotive Engineering, Weifang Engineering Vocational College, Weifang, Shandong, China","2020 12th International Conference on Measuring Technology and Mechatronics Automation (ICMTMA)","30 Mar 2020","2020","","","118","121","In order to improve the intelligence of automobile management system and improve the efficiency of modern automobile management, this paper puts forward a novel intelligent automobile management system based on a variety of cutting-edge science and technology. The system is mainly based on the Internet platform and integrates a variety of advanced science and technology, such as automation technology, artificial intelligence technology and Internet of things technology. The research results show that the intelligent vehicle management system can improve the intelligence and safety of the vehicle management system, and can realize large-scale batch vehicle management.","2157-1481","978-1-7281-7081-7","10.1109/ICMTMA50254.2020.00034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9050407","Artificial intelligence technology;Internet of things technology;Automobile management system","Computers;Automation;Mechatronics;Intelligent vehicles;Time measurement;Safety;Automobiles","","","","10","IEEE","30 Mar 2020","","","IEEE","IEEE Conferences"
"Positioning by fingerprinting with multiple cells in NB-IoT networks","L. De Nardis; G. Caso; Ö. Alay; U. Ali; M. Neri; A. Brunstrom; M. -G. Di Benedetto","Sapienza University of Rome, Rome, Italy; Ericsson Research, Kista, Sweden; University of Oslo, Oslo, Norway; Sapienza University of Rome, Rome, Italy; Rohde&Schwarz, Rome, Italy; Karlstad University, Karlstad, Sweden; Sapienza University of Rome, Rome, Italy","2022 International Conference on Localization and GNSS (ICL-GNSS)","21 Jun 2022","2022","","","01","07","Narrowband Internet of Things (NB-IoT) has quickly become a leading technology in the deployment of IoT systems and services, thanks to its appealing features in terms of coverage and energy efficiency, as well as compatibility with existing mobile networks. Increasingly, IoT services and applications require location information to be paired with data collected by devices; NB-IoT still lacks, however, reliable positioning methods. Time-based techniques inherited from Long Term Evolution (LTE) are not yet widely available in existing networks, and are expected to perform poorly on NB-IoT signals due to their narrow bandwidth. This investigation proposes a set of strategies for NB-IoT positioning, based on fingerprinting, that use coverage and radio information from multiple cells. The proposed strategies are evaluated on a large-scale dataset that includes experimental data from two NB-IoT operators. Results show that the proposed strategies, using a combination of coverage and radio information from multiple cells, outperform current state-of-the-art approaches based on single cell finger-printing, with a minimum average positioning error of about 20 meters, consistent across different network scenarios, vs. about 70 meters for current state-of-the-art.","2325-0771","978-1-6654-0575-1","10.1109/ICL-GNSS54081.2022.9797029","Sapienza University of Rome(grant numbers:RP11816433F508D1,RP11916B88A04AE6,RP11816426A9F174,RP12117A8483B1C1); EU H2020 research and innovation programme(grant numbers:815178); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9797029","NB-IoT;Positioning;Fingerprinting","Meters;Radio frequency;Performance evaluation;Location awareness;Fingerprint recognition;Modems;Internet of Things","","","","29","IEEE","21 Jun 2022","","","IEEE","IEEE Conferences"
"Named Data Networking (NDN) for Data Collection of Digital Twins-based IoT Systems","H. Liang; C. Qian; C. Lu; L. Burgess; J. Mulo; W. Yu","Department of Computer and Information Sciences, Towson University, Towson, MD; Department of Computer and Information Sciences, Towson University, Towson, MD; Department of Computer and Information Sciences, Towson University, Towson, MD; Department of Computer and Information Sciences, Towson University, Towson, MD; Department of Computer and Information Sciences, Towson University, Towson, MD; Department of Computer and Information Sciences, Towson University, Towson, MD","2023 IEEE/ACIS 21st International Conference on Software Engineering Research, Management and Applications (SERA)","3 Aug 2023","2023","","","122","127","With the rise and growing attention on Digital Twins (DT) as a way to provide integration between the Internet of Things (IoT) and data analytics, so does the need to consider how to address its challenges. To deal with these challenges, Named Data Networking (NDN) can be a possible solution. NDN has been rising in popularity due to its advancements over the traditional TCP/IP Internet architecture. In this paper, our approach begins with the framework that leverages an NDN-based DT architecture for data management. We then design two scenarios that focus on the performance of data querying in a small and large-scale simulated NDN-based DT architecture. Based on the designed scenarios, we conduct the performance evaluation of data query and DT performance to investigate the performance gap and determine whether an action needs to be taken.","2770-8209","979-8-3503-4588-9","10.1109/SERA57763.2023.10197693","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10197693","Named Data Networking (NDN);Digital Twins (DT);and Internet of Things (IoT)","Performance evaluation;Data analysis;Computer architecture;TCPIP;Data collection;Digital twins;Internet of Things","","","","44","IEEE","3 Aug 2023","","","IEEE","IEEE Conferences"
"Toward an Effective Locality-Sensitive Hashing Search for WMSNs Based on the Neighborhood Rough Set Approach","R. Xiao; S. Liu; Y. Li; Y. Ni; X. Du","College of Mathematics and Informatics and Digit Fujian Internet-of-Things Laboratory of Environmental Monitoring, Fujian Normal University, Fuzhou, China; College of Mathematics and Informatics and Digit Fujian Internet-of-Things Laboratory of Environmental Monitoring, Fujian Normal University, Fuzhou, China; College of Mathematics and Informatics and Digit Fujian Internet-of-Things Laboratory of Environmental Monitoring, Fujian Normal University, Fuzhou, China; College of Mathematics and Informatics and Digit Fujian Internet-of-Things Laboratory of Environmental Monitoring, Fujian Normal University, Fuzhou, China; College of Mathematics and Informatics and Digit Fujian Internet-of-Things Laboratory of Environmental Monitoring, Fujian Normal University, Fuzhou, China","IEEE Internet of Things Journal","12 Nov 2020","2020","7","11","10985","10995","With the advent of the 5G era, wireless multimedia sensor networks (WMSNs) will be more widely used in security monitoring, environmental monitoring, intelligent transportation, and other applications of the Internet of Things (IoT). Data collected by WMSNs, part of IoT systems, are high-dimensional, multilevel, unstructured, and large-scale complex data. Effective nearest neighbor searching faces the “dimension curse” problem. To this end, by incorporating the neighborhood rough set (NRS) approach, this article proposes a novel and effective locality-sensitive hashing (LSH) method for high-dimensional WMSN data based on the neighborhood (NLSH). This method innovatively combines the neighborhood knowledge representation method with the LSH mechanism and extends the indexing ability of LSH. Moreover, this method does not require any prior knowledge and has good universality. The indexing method of neighborhood bucket building can reduce the number of searches and improve the response speed of the WMSN system. Extensive experiments have been carried out on several real-world multimedia data sets. The results show that a large-scale high-dimensional NLSH search based on the NRS approach can efficiently query the target point and produce very accurate results. The NLSH algorithm based on the NRS approach outperforms other advanced mainstream LSH algorithms.","2327-4662","","10.1109/JIOT.2020.2992035","National Natural Science Foundation of China(grant numbers:U1805263,61672157,61772004); Great Project of Fujian Province Science and Technology Plan(grant numbers:2016H6007); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9085931","Approximate nearest neighbor;high-dimensional wireless multimedia sensor network (WMSN) search;locality-sensitive hashing (LSH);neighborhood rough set (NRS)","Internet of Things;Rough sets;Hash functions;Partitioning algorithms;Environmental monitoring;Search problems","","1","","38","IEEE","4 May 2020","","","IEEE","IEEE Journals"
"NOMA-Based Hybrid Satellite-UAV-Terrestrial Networks for 6G Maritime Coverage","X. Fang; W. Feng; Y. Wang; Y. Chen; N. Ge; Z. Ding; H. Zhu","Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, China; Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, China; School of Information Engineering, Minzu University of China, Beijing, China; School of Engineering, University of Warwick, Coventry, U.K; Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, China; School of Electrical and Electronic Engineering, The University of Manchester, Manchester, U.K; Coordination Innovative Center of IoT Technology and Application (Jiangsu), Nanjing University of Posts and Telecommunications, Nanjing, China","IEEE Transactions on Wireless Communications","6 Jan 2023","2023","22","1","138","152","Current fifth-generation (5G) networks do not cover maritime areas, causing difficulties in developing maritime Internet of Things (IoT). To tackle this problem, we establish a nearshore network by collaboratively using on-shore terrestrial base stations (TBSs) and tethered unmanned aerial vehicles (UAVs). These TBSs and UAVs form virtual clusters in a user-centric manner. Within each virtual cluster, non-orthogonal multiple access (NOMA) is adopted for agilely including various maritime IoT devices, which are sparsely distributed over the vast ocean. The nearshore network also shares the spectrum with marine satellites. In such a NOMA-based hybrid satellite-UAV-terrestrial network, interference among different network segments, different clusters, and different users occurs. We thereby formulate a joint power allocation problem to maximize the sum rate of the network. Different from existing studies, we use large-scale channel state information (CSI) only for optimization to reduce system overhead. The large-scale CSI is obtained by using the position information of maritime IoT devices. The problem is non-convex with intractable non-linear constraints. We tackle these difficulties by adopting max-min optimization, the auxiliary function method, and the successive convex approximation technique. An iterative power allocation algorithm is accordingly proposed, which is shown to be effective for coverage enhancement by simulations. This shows the potential of NOMA-based hybrid satellite-UAV-terrestrial networks for maritime on-demand coverage.","1558-2248","","10.1109/TWC.2022.3191719","National Key Research and Development Program of China(grant numbers:2020YFA0711301); National Natural Science Foundation of China(grant numbers:61941104,61922049); King Abdullah University of Science and Technology Research Funding (KRF)(grant numbers:ORA-2021-CRG10-4696); Tsinghua University–China Mobile Communications Group Company Ltd., Joint Institute; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9839554","Hybrid satellite-UAV-terrestrial network;interference;maritime Internet of Things;non-orthogonal multiple access (NOMA);power allocation","NOMA;Resource management;Interference;Satellites;Internet of Things;Marine vehicles;Precoding","","29","","47","IEEE","25 Jul 2022","","","IEEE","IEEE Journals"
"A Survey on Behavioral Pattern Mining From Sensor Data in Internet of Things","M. M. Rashid; J. Kamruzzaman; M. M. Hassan; S. Shahriar Shafin; M. Z. A. Bhuiyan","School of Engineering and Technology, CQUniversity Melbourne, Melbourne, Australia; School of Science and Information Technology, Federation University Australia, Ballarat, Australia; College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia; Department of Electrical and Electronic Engineering, Islamic University of Technology, Gazipur, Bangladesh; Department of Computer and Information Science, Fordham University, New York City, USA","IEEE Access","24 Feb 2020","2020","8","","33318","33341","The deployment of large-scale wireless sensor networks (WSNs) for the Internet of Things (IoT) applications is increasing day-by-day, especially with the emergence of smart city services. The sensor data streams generated from these applications are largely dynamic, heterogeneous, and often geographically distributed over large areas. For high-value use in business, industry and services, these data streams must be mined to extract insightful knowledge, such as about monitoring (e.g., discovering certain behaviors over a deployed area) or network diagnostics (e.g., predicting faulty sensor nodes). However, due to the inherent constraints of sensor networks and application requirements, traditional data mining techniques cannot be directly used to mine IoT data streams efficiently and accurately in real-time. In the last decade, a number of works have been reported in the literature proposing behavioral pattern mining algorithms for sensor networks. This paper presents the technical challenges that need to be considered for mining sensor data. It then provides a thorough review of the mining techniques proposed in the recent literature to mine behavioral patterns from sensor data in IoT, and their characteristics and differences are highlighted and compared. We also propose a behavioral pattern mining framework for IoT and discuss possible future research directions in this area.","2169-3536","","10.1109/ACCESS.2020.2974035","King Saud University(grant numbers:RSP-2019/18); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8999541","Association rules;behavioral patterns;data mining;frequent pattern;Internet of Things;knowledge discovery;wireless sensor networks","Data mining;Wireless sensor networks;Internet of Things;Knowledge discovery;Distributed databases;Monitoring","","14","","135","CCBY","14 Feb 2020","","","IEEE","IEEE Journals"
"Identifying Security and Privacy Vulnerabilities in 4G LTE and IoT Communications Networks","S. Wu; P. L. Yeoh; W. Hardjawana; B. Vucetic","School of Electrical and Information Engineering, The University of Sydney, Australia; School of Electrical and Information Engineering, The University of Sydney, Australia; School of Electrical and Information Engineering, The University of Sydney, Australia; School of Electrical and Information Engineering, The University of Sydney, Australia","2021 IEEE 7th World Forum on Internet of Things (WF-IoT)","9 Nov 2021","2021","","","512","517","The fourth-generation (4G) Long Term Evolution (LTE) wireless system has supported tremendous growth in the number of mobile users accessing high speed data communications. Due to the large numbers of users in large-scale Internet of Things (IoT) application relying on LTE, it is increasingly important to consider the level of data privacy and security in wireless systems. Furthermore, IoT devices are typically more vulnerable to security attacks due to their limited hardware functionalities. The most common wireless communication attacks include intercepting, spoofing and Denial of Service (DoS). This paper investigates the design and implementation of DoS attacks on 4G and IoT user equipment (UE) using open-source software-defined radio (SDR) equipment. During the DoS security attack, we also identify a UE International Mobile Subscriber Identity (IMSI) disclosure attack, which is a significant privacy risk. Finally, we present detailed LTE security analysis and discuss potential solutions to prevent attacks in 4G and future 5G wireless communication systems.","","978-1-6654-4431-6","10.1109/WF-IoT51360.2021.9595689","University of Sydney; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9595689","","Wireless communication;Privacy;Data privacy;Hardware;Internet of Things;Security;Data communication","","1","","22","IEEE","9 Nov 2021","","","IEEE","IEEE Conferences"
"OBLoc: Online Batch Localization for Large-Scale Indoor Environments","A. T. Abraha; B. Wang; Z. Yu; J. He","School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Shenzhen Polytechnic, Shenzhen, China","IEEE Systems Journal","12 Dec 2023","2023","17","4","6552","6563","The demand for indoor localization is increasing with ubiquitous computing and the Internet of Things (IoT) emergence. Location awareness is crucial to intelligent systems in large-scale indoor environments, such as smart airports, train stations, hospitals, malls, and smart cities. Hence, indoor localization has been researched for the last decades. However, most site survey based WiFi fingerprint based indoor localization methods involve independent or one by one online localization methods, that are costly, and inefficient regarding computation time, memory, and energy consumption to implement in large-scale indoor environments. We propose an Online Batch Localization (OBLoc) for large-scale indoor environments scheme to address these challenges. The basic idea of OBLoc is that the indoor localization users close to each other have similar WiFi fingerprinting and can be clustered to form batches. Every batch's search space could be reduced using a batch representative. We propose a search space-slicing algorithm that slices part of the large-scale database using the appointed representative to minimize searching overhead. Furthermore, we designed a neighborhood consistency algorithm to identify erroneous location annotations in the sliced search space. We conduct experiments on three field-measured datasets to evaluate the performance of the proposed method. The experiment results show the improvement over the peer schemes of 21.34%, 17.38%, and 27.24% localization accuracy in the three datasets.","1937-9234","","10.1109/JSYST.2023.3307561","Hubei Province International Science and Technology Cooperation; Shenzhen Key Technology Research and Development(grant numbers:2019N048); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10262239","Batch indoor localization;large-scale users;representative nomination;search space;WiFi fingerprint","Location awareness;Wireless fidelity;Indoor environment;Estimation;Training;Memory management;Distortion","","","","56","IEEE","25 Sep 2023","","","IEEE","IEEE Journals"
"DDPG-Edge-Cloud: A Deep-Deterministic Policy Gradient based Multi-Resource Allocation in Edge-Cloud System","A. Qadeer; M. J. Lee","Department of Electrical Engineering, The City College of New York of CUNY, New York, USA; Department of Electrical Engineering, The City College of New York of CUNY, New York, USA","2022 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)","1 Mar 2022","2022","","","339","344","5G and beyond is the key enabler for extreme mobile-broadband (xMBB), Massive and Ultra-reliable machine-type communication (mMTC, uMTC). To handle such large-scale and real-time traffics, Edge Cloud (EC) plays a critical role to minimize the latency and provide compute power at the edge of the network for Internet of Things (IoTs). However, an EC endures limited compute capacity in contrast with the back-end cloud (BC). Intelligent resource management techniques become imperative in such resource constrained environment. This paper studies the problem of compute and wireless resource allocation in an integrated EC and BC environment. Machine learning-based techniques are emerging to solve such optimization problems. However, it is challenging to adopt traditional discrete action space-based methods since they do not scale well in large-scale environments. To this end, to overcome the bottlenecks of wireless bandwidth and compute capacity in resource constrained EC and BC, we propose continuous action space-based DDPG-Edge-Cloud, a deep deterministic policy gradient-based multi-resource allocation (MRA) framework with a pruning principle. The proposed agent is equipped with a Conv1D residual block, gated recurrent unit (GRU) layer and an attention layer for local and long-term temporal feature extraction. We validate the proposed framework by comparing with two alternative agents. Experimental results demonstrate that our proposed agent converges fast and achieves up to 55% and 86.5% reduction in operational cost and rejection rate, and achieves up to 115% gain in the quality of experience on average.","","978-1-6654-5818-4","10.1109/ICAIIC54071.2022.9722676","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9722676","Edge cloud computing;deep deterministic policy gradient;resource allocation;smart city;IoT","Wireless communication;Cloud computing;Costs;Logic gates;Feature extraction;Real-time systems;Resource management","","2","","20","IEEE","1 Mar 2022","","","IEEE","IEEE Conferences"
"A wideband zinc oxide energy harvester for IoT based sensor","P. Asthana; G. Khanna","DoE&CE National Institute of Technology, Hamirpur, H.P; DoE&CE National Institute of Technology, Hamirpur, H.P","2020 Zooming Innovation in Consumer Technologies Conference (ZINC)","7 Aug 2020","2020","","","251","252","The features of microelectromechanical systems have been improved by advancements in manufacturing technology and growing rates of integration. The development of small structures or micro systems has created the” Internet of Things” revolution, thereby providing a significant portion of a digitized automated and interconnected environment around smart manufacturing, infrastructure, health and other areas of society. Frequent maintenance and battery refurbishment are not desirable in micro-systems, which require very low power $( \mu W mW )$ to operate. Therefore, the most challenging field of micro-scale harvesting research is battery-less activity. Low-frequency ambient vibrations are abundantly available sources of energy that can be used in electrical power conversion. In this study, a low-frequency wideband energy harvester is proposed and simulated.","","978-1-7281-8259-9","10.1109/ZINC50678.2020.9161806","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9161806","Piezoelectric Energy Harvesting;MEMS;ambient energy;IOT;structural health monitoring","Resonant frequency;Energy harvesting;Wireless sensor networks;Vibrations;Wireless communication;Batteries;Wideband","","1","","5","IEEE","7 Aug 2020","","","IEEE","IEEE Conferences"
"MSN: Battery-Less Multiple Subcarrier Multiple Access Sensor Node with Full-Duplex Backscatter Concurrent Data Streaming","Y. Zhao; H. Wang; Y. Xu; Z. Ying; Y. Lu; J. Liu; T. Hu; J. Mitsugi; H. Min","Fudan University, Shanghai, China; Fudan University, Shanghai, China; Fudan University, Shanghai, China; Fudan University, Shanghai, China; Fudan University, Shanghai, China; Quanray Electronics, Shanghai, China; Fudan University, Shanghai, China; Keio University, Fujisawa, Japan; Fudan University, Shanghai, China","2023 IEEE Asian Solid-State Circuits Conference (A-SSCC)","18 Dec 2023","2023","","","1","3","To scale to trillions of Internet-of-Things (loT) nodes, devices must be battery-less by achieving energy autonomy, having a µW power floor, few off-chip components, and a small form factor. These features are beneficial for short-range high-density loT applications such as structural health monitoring (SHM) for wings and gears, human motion capture (HMC), and air conditioning system monitoring. This work focuses on the synchronous transmission of sensor data streams, called concurrent data streaming, from multiple sensor nodes for multi-points sensing. Traditional wireless communication protocols need construct wireless networks for time synchronization, increasing system complexity [1]. However, the recent development of Multiple Subcarrier Multiple Access (MSMA), enables concurrent backscatter communication by assigning multiple uplink subcarrier (USC) channels to sensor nodes [2]–[4]. To expand the deployment in the mentioned loT applications, MSMA should be compatible with existing communication protocols and achieve real-time control of starting and stopping of concurrent data streaming without wasting extra sensing system energy. To avoid channel interference among multiple nodes and catastrophic failure of concurrent data transmission, the USC frequency must always keep stable from the influence of PVT.","","979-8-3503-3003-8","10.1109/A-SSCC58667.2023.10347996","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10347996","","Protocols;Wireless networks;Real-time systems;Sensors;Solid state circuits;Synchronization;Uplink","","","","8","IEEE","18 Dec 2023","","","IEEE","IEEE Conferences"
"Distributed Resource Scheduling for Large-Scale MEC Systems: A Multiagent Ensemble Deep Reinforcement Learning With Imitation Acceleration","F. Jiang; L. Dong; K. Wang; K. Yang; C. Pan","Hunan Provincial Key Laboratory of Intelligent Computing and Language Information Processing, Hunan Normal University, Changsha, China; Key Laboratory of Hunan Province for New Retail Virtual Reality Technology, Hunan University of Technology and Business, Changsha, China; Department of Computer and Information Sciences, Northumbria University, Newcastle upon Tyne, U.K.; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Electronic Engineering and Computer Science, Queen Mary University of London, London, U.K.","IEEE Internet of Things Journal","25 Apr 2022","2022","9","9","6597","6610","In large-scale mobile edge computing (MEC) systems, the task latency, and energy consumption are important for massive resource-consuming and delay-sensitive Internet of Things Devices (IoTDs). Against this background, we propose a distributed intelligent resource scheduling (DIRS) framework to minimize the sum of task latency and energy consumption for all IoTDs, which can be formulated as a mixed-integer nonlinear programming. The DIRS framework includes centralized training relying on the global information and distributed decision making by each agent deployed in each MEC server. Specifically, we first introduce a novel multiagent ensemble-assisted distributed deep reinforcement learning (DRL) architecture, which can simplify the overall neural network structure of each agent by partitioning the state space and also improve the performance of a single agent by combining decisions of all the agents. Second, we apply action refinement to enhance the exploration ability of the proposed DIRS framework, where the near-optimal state-action pairs are obtained by a novel Levy flight search. Finally, an imitation acceleration scheme is presented to pretrain all the agents, which can significantly accelerate the learning process of the proposed framework through learning the professional experience from a small amount of demonstration data. The simulation results in three typical scenarios demonstrate that the proposed DIRS framework is efficient and outperforms the existing benchmark schemes.","2327-4662","","10.1109/JIOT.2021.3113872","National Natural Science Foundation of China (NSFC)(grant numbers:41604117,41904127,61620106011,U1705263); Hunan Provincial Natural Science Foundation of China(grant numbers:2020JJ4428,2020JJ5105,2021JJ30455); Hunan Provincial Science Technology Project Foundation(grant numbers:2018TP1018,2018RS3065); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9540904","Distributed deep reinforcement learning (DRL);imitation learning;Lévy flight;multiagent reinforcement learning;resource scheduling","Task analysis;Training;Servers;Resource management;Reinforcement learning;Internet of Things;Processor scheduling","","30","","45","IEEE","20 Sep 2021","","","IEEE","IEEE Journals"
"iEdge: An IoT-assisted Edge Computing Framework","H. Lee; S. Lee; Y. C. Lee; H. Han; S. Kang","Dept. of Computer Science, Hanyang University, Korea; Dept. of Computer Science, Hanyang University, Korea; Dept. of Computing, Macquarie University, Australia; Dept. of Computer Science, Dongduk Women’s University, Korea; Dept. of Computer Science, Hanyang University, Korea","2021 IEEE International Conference on Pervasive Computing and Communications (PerCom)","25 May 2021","2021","","","1","8","Edge computing has emerged as a viable solution to bridge the gap between distributed Internet of Things (IoT) devices and centralized distant clouds. In particular, small-scale servers are deployed at the edge of network (i.e., edge servers) to `help' cloud servers process data IoT devices constantly generate. However, these edge servers often struggle to deal with emerging applications that require real-time data processing in situ, such as real-time facial recognition. In this paper, we present iEdge as an IoT-assisted edge computing framework that enables the seamless execution of applications across an edge server and nearby IoT devices. The seamless execution in essence has been realized by transforming platform-dependent monolithic applications to cross-platform composite applications and offloading some tasks/functions of these composite applications to IoT devices considering device context. We have evaluated iEdge using a prototype implementation with a real-time facial recognition application. Experimental results show that iEdge effectively harnesses smart IoT devices as a consolidated edge computing execution environment and enables such an application to process more video streams than typical `edge-only' computing.","2474-249X","978-1-6654-0418-1","10.1109/PERCOM50583.2021.9439122","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9439122","Edge computing;Internet of Things;Fog computing;IoT-assisted edge computing;In-site data analytics","Pervasive computing;Cloud computing;Face recognition;Prototypes;Streaming media;Real-time systems;Servers","","4","","25","IEEE","25 May 2021","","","IEEE","IEEE Conferences"
"A Novel Layered Architecture and Modular Design Framework for Next-gen Cyber Physical System","A. Mishra; A. K. Ray","School of Electronics Engineering, Kalinga Institute of Industrial Technology, Bhubaneswar, India; School of Electronics Engineering, Kalinga Institute of Industrial Technology, Bhubaneswar, India","2022 International Conference on Computer Communication and Informatics (ICCCI)","31 Mar 2022","2022","","","1","8","Cyber Physical System (CPS) is a complex interdisciplinary engineering system with amalgamation of physical-realm entities like machines, sensors, actuators and embedded devices with the cyber-realm system constituting of communication networks, Internet, and network-centric heterogeneous computing platforms like cloud and Fog/Edge computing. Further, with the recent advancements in the field of Internet of Things (IoT) and Machine-to-Machine (M2M) communication as enabling technologies; it is possible to design large scale CPS and deployment of application-specific sensordata acquisition and control systems. This has unfolded another technological dimension of huge data-centric subsystems: Big-Data and Artificial Intelligence (AI) and Machine Learning (ML) based application specific data analytics requirement for future-ready intelligent CPS also popularly referred as Cognitive CPS (CCPS). In this paper, we have proposed a novel four-layer architecture and their design framework with the vision of Next-generation Cyber Physical System (NG-CPS). Some major design attributes of each layer have been considered to formulate eight NG-CPS design goals with a modelling approach and suggested some major design aspects including modularity, scalability.","2329-7190","978-1-6654-8035-2","10.1109/ICCCI54379.2022.9740757","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9740757","Next-generation;Cyber Physical System (CPS);Internet of Things (IoT);Layered Architecture;Design Framework;Modelling CPS","Machine-to-machine communications;Cloud computing;System performance;Scalability;Computer architecture;Cyber-physical systems;Sensor systems","","3","","13","IEEE","31 Mar 2022","","","IEEE","IEEE Conferences"
"Large-scale Firmware Vulnerability Analysis Based on Code Similarity","S. Haonan; X. Jiangtao; L. Bo; Y. Xi","Information Engineering University, Zhengzhou, China; Information Engineering University, Zhengzhou, China; Information Engineering University, Zhengzhou, China; Information Engineering University, Zhengzhou, China","2021 IEEE International Conference on Power, Intelligent Computing and Systems (ICPICS)","2 Sep 2021","2021","","","184","189","In recent years, the popularity of the Internet of Things has led to a sharp increase in the number of IoT devices. However, device vendors develop firmware using a large number of open source libraries that contain many known and unknown vulnerabilities. What’s more, users rarely update firmware version actively, which leads to the firmware bugs existence persistently. Because of the particularity of hardware architecture and the weak of performance, it’s difficult to implement strong security protection measures. Traditional vulnerability analysis methods rely on manual analysis and are not suitable for large-scale vulnerability analysis. In this paper, we analyze the raw feature of firmware functions and graph embedding network, and calculate the similarity among functions by using features’ embedded vector. We design and implement an effective large-scale firmware vulnerability analysis technology, which can realize large-scale security analysis of device firmware. The test results show that the technology can effectively extract function features and find the known vulnerabilities in the firmware.","","978-1-6654-4130-8","10.1109/ICPICS52425.2021.9524216","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9524216","IoT;Firmware security;Similarity analysis;Graph embedding;Neural network","Performance evaluation;Codes;Static analysis;Manuals;Feature extraction;Particle measurements;Security","","","","19","IEEE","2 Sep 2021","","","IEEE","IEEE Conferences"
"A Comprehensive Study of Present Data Deduplication","Z. Xue; H. Qian; L. Shen; X. Wu","School of Computer and Electronic Information, Nanjing Normal University, Nanjing, P.R. China; School of Computer and Electronic Information, Nanjing Normal University, Nanjing, P.R. China; School of Computer and Electronic Information, Nanjing Normal University, Nanjing, P.R. China; School of Computer and Electronic Information, Nanjing Normal University, Nanjing, P.R. China","2021 IEEE 23rd Int Conf on High Performance Computing & Communications; 7th Int Conf on Data Science & Systems; 19th Int Conf on Smart City; 7th Int Conf on Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys)","30 May 2022","2021","","","1748","1754","With the proliferation of the Internet of Things (IoT), various computing paradigms have been proposed and are developing rapidly these years, which led to the explosive increase of the data amount. However, the significant increase in data imposed a significant burden on contemporary server storage. Many approaches have been designed to tackle the challenge. Among them, deduplication is a quite effective data reduction technique, which received considerable attention from both academia and industry in the large-scale storage systems field. Data deduplication identifies redundant data at chunk level by using secure fingerprints, which not only removes replicated data, decreases the bandwidth, but also minimizes the storage usage and cost. This paper aims at describing the general framework of deduplication compression systems with duplicate and resemblance detection in detail. First, we use a flow chart to present the overall framework and process of the deduplication compression system. Then we summarize the existing algorithm applied to duplicate detection and resemblance detection. Additionally, we make a detailed evaluation of different resemblance detection algorithms. Finally, we make a conclusion of delta compressed prototype system, outline the open problems and shed a light on the future research directions in data deduplication systems.","","978-1-6654-9457-1","10.1109/HPCC-DSS-SmartCity-DependSys53884.2021.00257","Natural Science Research of Jiangsu Higher Education Institutions of China(grant numbers:21KJB520036); Nanjing University(grant numbers:KFKT2021B35); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9781103","Data deduplication;resemblance detection;delta compression","Industries;Costs;Smart cities;Prototypes;Bandwidth;Fingerprint recognition;Explosives","","1","","39","IEEE","30 May 2022","","","IEEE","IEEE Conferences"
"A Process Mining Approach for Supporting IoT Predictive Security","A. Hemmer; R. Badonnel; I. Chrisment","Inria Nancy Grand Est - LORIA, Villers-les-Nancy, France; Inria Nancy Grand Est - LORIA, Villers-les-Nancy, France; Inria Nancy Grand Est - LORIA, Villers-les-Nancy, France","NOMS 2020 - 2020 IEEE/IFIP Network Operations and Management Symposium","8 Jun 2020","2020","","","1","9","The growing interest for the Internet-of-Things (IoT) is supported by the large-scale deployment of sensors and connected objects. These ones are integrated with other Internet resources in order to elaborate more complex and value-added systems and applications. While important efforts have been done for their protection, security management is a major challenge for these systems, due to their complexity, their heterogeneity and the limited resources of their devices. In this paper we introduce a process mining approach for detecting misbehaviors in such systems. It permits to characterize the behavioral models of IoT-based systems and to detect potential attacks, even in the case of heterogenous protocols and platforms. We then describe and formalize its underlying architecture and components, and detail a proof-of-concept prototype. Finally, we evaluate the performance of this solution through extensive experiments based on real industrial datasets.","2374-9709","978-1-7281-4973-8","10.1109/NOMS47738.2020.9110411","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9110411","Security Management;Internet-of-Things;Process Mining;Data Mining;Anomaly Detection","Performance evaluation;Protocols;Runtime;Security management;Buildings;Prototypes;Predictive models","","12","","26","IEEE","8 Jun 2020","","","IEEE","IEEE Conferences"
"Integrating Artificial Intelligence Internet of Things and 5G for Next-Generation Smartgrid: A Survey of Trends Challenges and Prospect","E. Esenogho; K. Djouani; A. M. Kurien","Department of Electrical Engineering, French South African Institute of Technology (F’SATI), Tshwane University of Technology, Pretoria West, Pretoria, South Africa; Department of Electrical Engineering, French South African Institute of Technology (F’SATI), Tshwane University of Technology, Pretoria West, Pretoria, South Africa; Department of Electrical Engineering, French South African Institute of Technology (F’SATI), Tshwane University of Technology, Pretoria West, Pretoria, South Africa","IEEE Access","17 Jan 2022","2022","10","","4794","4831","Smartgrid is a paradigm that was introduced into the conventional electricity network to enhance the way generation, transmission, and distribution networks interrelate. It involves the use of Information and Communication Technology (ICT) and other solution in fault and intrusion detection, mere monitoring of energy generation, transmission, and distribution. However, on one hand, the actual and earlier smartgrid, do not integrate more advanced features such as automatic decision making, security, scalability, self-healing and awareness, real-time monitoring, cross-layer compatibility, etc. On the other hand, the emergence of the digitalization of the communication infrastructure to support the economic sector which among them are energy generation and distribution grid with Artificial Intelligence (AI) and large-scale Machine to Machine (M2M) communication. With the future Massive Internet of Things (MIoT) as one of the pillars of 5G/6G network factory, it is the enabler to support the next generation smart grid by providing the needed platform that integrates, in addition to the communication infrastructure, the AI and IoT support, providing a multitenant system. This paper aim at presenting a comprehensive review of next smart grid research trends and technological background, discuss a futuristic next-generation smart grid driven by artificial intelligence (AI) and leverage by IoT and 5G. In addition, it discusses the challenges of next-generation smart-grids as it relate to the integration of AI, IoT and 5G for better smart grid architecture. Also, proffers possible solutions to some of the challenges and standards to support this novel trend. A corresponding future work will dwell on the implementation of the discussed integration of AI, IoT and 5G for next-generation smart grid, using Matlab, NS2/NS3, Open-daylight and Mininet as soft tools and compare with related literature.","2169-3536","","10.1109/ACCESS.2022.3140595","National Research Foundation (NRF) of South Africa(grant numbers:90604); French South Africa Institute of Technology (F’SAIT), Tshwane University of Technology, South Africa; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9672084","5G;artificial intelligence (AI);Internet of Things (IoT);next-generation smartgrid;network slicing","Smart grids;Artificial intelligence;Next generation networking;5G mobile communication;Internet of Things;Distribution networks;Market research","","58","","216","CCBY","6 Jan 2022","","","IEEE","IEEE Journals"
"Arm PSA-Certified IoT Chip Security: A Case Study","F. Chen; D. Luo; J. Li; V. C. M. Leung; S. Li; J. Fan","College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; Open Security Research, Inc., Shenzhen, China; Open Security Research, Inc., Shenzhen, China","Tsinghua Science and Technology","29 Sep 2022","2023","28","2","244","257","With the large scale adoption of Internet of Things (IoT) applications in people's lives and industrial manufacturing processes, IoT security has become an important problem today. IoT security significantly relies on the security of the underlying hardware chip, which often contains critical information, such as encryption key. To understand existing IoT chip security, this study analyzes the security of an IoT security chip that has obtained an Arm Platform Security Architecture (PSA) Level 2 certification. Our analysis shows that the chip leaks part of the encryption key and presents a considerable security risk. Specifically, we use commodity equipment to collect electromagnetic traces of the chip. Using a statistical T-test, we find that the target chip has physical leakage during the AES encryption process. We further use correlation analysis to locate the detailed encryption interval in the collected electromagnetic trace for the Advanced Encryption Standard (AES) encryption operation. On the basis of the intermediate value correlation analysis, we recover half of the 16-byte AES encryption key. We repeat the process for three different tests; in all the tests, we obtain the same result, and we recover around 8 bytes of the 16-byte AES encryption key. Therefore, experimental results indicate that despite the Arm PSA Level 2 certification, the target security chip still suffers from physical leakage. Upper layer application developers should impose strong security mechanisms in addition to those of the chip itself to ensure IoT application security.","1007-0214","","10.26599/TST.2021.9010094","National Natural Science Foundation of China(grant numbers:61872243,U1713212); Shenzhen Science and Technology Innovation Commission(grant numbers:R2020A045); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9906050","Internet of Things (IoT) security chip;Arm Platform Security Architecture (PSA) certification;electromagnetic side-channel attack;Advanced Encryption Standard (AES) encryption;key leakage","Correlation;Manufacturing processes;Hardware;Encryption;Security;Internet of Things;Electromagnetics","","3","","49","","29 Sep 2022","","","TUP","TUP Journals"
"A Deep-Learning Based Approach to Resource Allocation in NOMA Based Cognitive Radio Network with Heterogeneous IoT Users","S. Devipriya; J. M. Leo Manickam; K. Jasmine Mystica","Department of ECE, St. Joseph's College of Engineering, Chennai, India; Department of ECE, St. Joseph's College of Engineering, Chennai, India; Department of ECE, St. Joseph's College of Engineering, Chennai, India","2022 IEEE International Conference on Distributed Computing and Electrical Circuits and Electronics (ICDCECE)","13 Jun 2022","2022","","","1","6","In 5G mobile technology, the expansion of Internet of Things (IoT) has created a huge need for a wide variety of latency, dependability, and energy efficiency requirements, etc… Spectrum efficiency (SE) of such large scale network needs to be improved with an economical power consumption. The non-orthogonal multiple access (NOMA) technique is utilized to enhance system efficiency (SE) by merging several users in the same frequency. An energy efficient (EE) resource allocation (RA) problem has been formulated for NOMA based heterogeneous IoT networks. Using the examining technique of Cognitive Radio (CR) Network, a stepwise RA scheme is assigned for IoT Users (IoTUs) and Mobile Users (MUs) with the mutual interference management. Later, to find a solution quickly and flawlessly, a deep recurrent neural network (RNN) based mechanism has been proposed. Furthermore, to systemize the approach of heterogeneous users, a rate and precedence demands based scheduling method has been implemented. Extensive results demonstrate that the deep learning based framework performs better than traditional RA methods in terms of computational complexity. On comparing with the prevailing OFDMA technique, the NOMA system with the imperfect SIC provides an acceptable performance on the EE at the cost of low EE and high power consumption.","","978-1-6654-8316-2","10.1109/ICDCECE53908.2022.9793269","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793269","Power Consumption;NOMA;Heterogeneous IoT;Resource Allocation;Imperfect SIC;Cognitive Radio Network;Deep Learning","Deep learning;NOMA;Recurrent neural networks;Power demand;Processor scheduling;Energy efficiency;Resource management","","2","","26","IEEE","13 Jun 2022","","","IEEE","IEEE Conferences"
"MapChain-D: A Distributed Blockchain for IIoT Data Storage and Communications","T. Wu; G. Jourjon; K. Thilakarathna; P. L. Yeoh","The University of Sydney, Sydney, NSW, Australia; CSIRO, Sydney, NSW, Australia; The University of Sydney, Sydney, NSW, Australia; The University of Sydney, Sydney, NSW, Australia","IEEE Transactions on Industrial Informatics","24 Jul 2023","2023","19","9","9766","9776","With the rapid growth of Industrial Internet of Things (IIoT) devices, managing an extensive volume of IIoT data becomes a significant challenge. While the conventional cloud storage approaches with centralized data centers suffer from high latency for large-scale IIoT data storage due to increased communication and latency overheads, distributed storage frameworks, such as blockchains, have become promising solutions. In this article, we design and analyze a dual-blockchain framework for secure and scalable distributed data management in large-scale IIoT networks. The proposed framework, named MapChain-D, consists of a data chain that is mapped to an index chain to provide efficient data storage and lookup. MapChain-D is designed for practical IIoT applications with storage, latency, and communication constraints. Detailed data exchange protocols are presented for data insertion and retrieval operations in MapChain-D. Based on these, theoretical analyses are provided on the space, time, and communication complexities of MapChain-D compared with conventional single-chain frameworks with local and distributed data storage. We implement our MapChain-D prototype using open-source LoRaWAN communications with multiple Raspberry Pi and Arduino devices, Kademlia-based distributed hash table, and Ethereum-based blockchain with proof-of-authority consensus. Experimental results from our prototype show that MapChain-D is more suitable to be deployed on resource-constrained IIoT devices. We also highlight the scalability and flexibility of MapChain-D with different number of edge nodes in the system.","1941-0050","","10.1109/TII.2023.3234631","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10008091","Distributed hash table (DHT) blockchain;low-latency data insertion and retrieval;secure and scalable data storage","Blockchains;Industrial Internet of Things;Memory;Peer-to-peer computing;Base stations;Scalability;Data models","","5","","34","IEEE","6 Jan 2023","","","IEEE","IEEE Journals"
"Energy-Efficient and QoS-Aware Data Transfer in Q-Learning-Based Small-World LPWANs","N. S. Chilamkurthy; N. Karna; V. Vuddagiri; S. K. Tiwari; A. Ghosh; L. R. Cenkeramaddi; O. J. Pandey","Department of Electronics and Communication Engineering, SRM University AP, Amaravati, India; Department of Electronics and Communication Engineering, SRM University AP, Amaravati, India; Department of Electronics and Communication Engineering, SRM University AP, Amaravati, India; Department of Electronics and Communication Engineering, SRM University AP, Amaravati, India; Department of Electronics and Communication Engineering, SRM University AP, Amaravati, India; Department of Information and Communication Technology, University of Agder, Grimstad, Norway; Department of Electronics Engineering, Indian Institute of Technology (BHU) Varanasi, Varanasi, India","IEEE Internet of Things Journal","11 Dec 2023","2023","10","24","22636","22649","The widespread use of the Internet of Things (IoT) necessitates large-scale communication among smart IoT devices (IoDs) across a wide geographical area. However, due to the limited radio range and scalability issues of traditional wireless sensor networks, wide-area communication among IoDs is not feasible. As a solution, a low-power wide-area network (LPWAN) is emerging as one of the techniques that can provide long-range communication with minimal power consumption. Nevertheless, the direct data transmission approach will no longer be viable due to its short network lifetime. As such, multihop data routing strategies for LPWANs are proposed in the literature. However, multihop data transmission has several challenges, including increased data latency, energy imbalance, poor bandwidth utilization, and low data throughput. To address these challenges, we propose a novel method that uses the machine learning technique for an energy-efficient and Quality-of-Service (QoS)-aware data transfer based on a recent breakthrough in social networks known as small-world characteristics (SWC). The network having SWC (i.e., low average path length and high average clustering coefficient) uses long-range links to reduce the number of intermediate hops for data transmission. In particular, a  $Q$ -learning framework is utilized for introducing optimal long-range links between the selected IoDs, resulting in the development of a small-world LPWAN (SW-LPWAN). Furthermore, the performance of the proposed method is computed in terms of energy efficiency and QoS. Moreover, the results are compared with existing data routing techniques, such as low-energy adaptive clustering hierarchy (LEACH), modified LEACH, conventional multihop, and direct data transmission. Specifically, the proposed method maintains 29% more alive nodes, 18% higher residual energy, and 22% higher data throughput compared to the second-best-performing method. As such, the obtained experimental results validate that the proposed method outperforms other existing methods in the context of energy consumption and QoS.","2327-4662","","10.1109/JIOT.2023.3304337","Project “Design and Development of Cognitive Small-World LPWANs for Internet of Things Toward Health Monitoring,”(grant numbers:SRG/2021/000137); Science and Engineering Research Board (SERB), Government of India; Indo-Norwegian Collaboration in Autonomous Cyber-Physical Systems (INCAPS) Project of the International Partnerships for Excellent Education, Research(grant numbers:287918); Innovation (INTPART) Program and the Low-Altitude UAV Communication and Tracking (LUCAT) Project of the IKTPLUSS Program from the Research Council of Norway(grant numbers:280835); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10214496","Energy-efficiency;Internet of Things (IoT);low-power wide-area networks (LPWANs);Q-learning;Quality of Service (QoS);small-world networks (SWNs)","Low-power wide area networks;Quality of service;Energy efficiency;Internet of Things;Throughput;Routing;Bandwidth;Energy efficiency;Wide area networks;Q-learning","","","","47","IEEE","11 Aug 2023","","","IEEE","IEEE Journals"
"DaaS: Dew Computing as a Service for Intelligent Intrusion Detection in Edge-of-Things Ecosystem","P. Singh; A. Kaur; G. S. Aujla; R. S. Batth; S. Kanhere","School of Computer Science and Engineering, Lovely Professional University, Phagwara, India; School of Computer Science and Engineering, Lovely Professional University, Phagwara, India; Department of Computer Science, Durham University, Durham, U.K.; School of Computer Science and Engineering, Lovely Professional University, Phagwara, India; Department of Computer Science and Engineering, University of New South Wales, Sydney, NSW, Australia","IEEE Internet of Things Journal","5 Aug 2021","2021","8","16","12569","12577","Edge of Things (EoT) enables the seamless transfer of services, storage, and data processing from the cloud layer to edge devices in a large-scale distributed Internet of Things (IoT) ecosystems (e.g., Industrial systems). This transition raises the privacy and security concerns in the EoT paradigm distributed at different layers. Intrusion detection systems (IDSs) are implemented in EoT ecosystems to protect the underlying resources from attackers. However, the current IDSs are not intelligent enough to control the false alarms, which significantly lower the reliability and add to the analysis burden on the IDSs. In this article, we present a Dew Computing as a Service (DaaS) for intelligent intrusion detection in EoT ecosystems. In DaaS, a deep learning-based classifier is used to design an intelligent alarm filtration mechanism. In this mechanism, the filtration accuracy is improved (or sustained) by using deep belief networks. In the past, the cloud-based techniques have been applied for offloading the EoT tasks, which increases the middle layer burden and raises the communication delay. Here, we introduce the dew computing features that are used to design the smart false alarm reduction system. DaaS, when experimented in a simulated environment, reflects lower response time to process the data in the EoT ecosystem. The revamped DBN model achieved the classification accuracy up to 95%. Moreover, it depicts a 60% improvement in the latency and 35% workload reduction of the cloud servers as compared to edge IDS.","2327-4662","","10.1109/JIOT.2020.3029248","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9216004","Deep belief networks (DBNs);dew computing;Edge of Things (EoT);intrusion detection;smart false alarm filter","Cloud computing;Intrusion detection;Computational modeling;Peer-to-peer computing;Internet of Things;Ecosystems","","44","","32","IEEE","7 Oct 2020","","","IEEE","IEEE Journals"
"Low-Overhead Wireless Uplink Scheduling for Large-Scale Internet-of-Things","B. Li; J. Liu; B. Ji","Department of Electrical, Computer and Biomedical Engineering, University of Rhode Island, Kingston, RI, USA; Department of Computer Science, Iowa State University, Ames, IA, USA; Department of Computer and Information Sciences, Temple University, Philadelphia, PA, USA","IEEE Transactions on Mobile Computing","11 Jan 2021","2021","20","2","577","587","With the rapid growth of Internet-of-Things (IoT) applications in recent years, there is a strong need for wireless uplink scheduling algorithms that determine when and which subset of a large number of users should transmit to the central controller. Different from the downlink case, the central controller in the uplink scenario typically has very limited information about the users. On the other hand, periodically collecting all such information from a large number of users typically incurs a prohibitively high communication overhead. This motivates us to investigate the development of an efficient and low-overhead uplink scheduling algorithm that is suitable for large-scale IoT applications. Specifically, we first characterize a capacity outer bound subject to the sampling constraint where only a small subset of users are allowed to use control channels for system state reporting at each time. Next, we relax the sampling constraint and propose a joint sampling and transmission algorithm, which utilizes full knowledge of channel state distributions and instantaneous queue lengths to achieve the capacity outer bound. The insights obtained from this capacity-achieving algorithm allow us to develop a low-overhead scheduling algorithm that can strictly satisfy the sampling constraint with asymptotically diminishing throughput loss.","1558-0660","","10.1109/TMC.2019.2949291","National Science Foundation(grant numbers:CNS-1717108,CNS-1815563,ECCS1818791,CCF-1758736,CNS-1758757,CNS-1446582,CNS-1651947,CCF-1657162); ONR(grant numbers:N00014-17-1-2417); Air Force Research Laboratory(grant numbers:FA8750-18-1-0107); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8883088","Internet-of-Things;uplink scheduling;low-complexity algorithm;throughput performance","Uplink;Internet of Things;Wireless communication;Scheduling;Scheduling algorithms;Wireless sensor networks;Schedules","","4","","34","IEEE","25 Oct 2019","","","IEEE","IEEE Journals"
"SMART-IMPALA: Efficient Querying of hyper Massive Spatiotemporal Trajectory Data","L. Zhou; W. Tu; Q. Li","School of civil engineering, Chongqing Jiaotong University, Chongqing, China; Shenzhen Key Laboratory of Spatial Information Smart Sensing and Services and Research Institute of Smart Cities, School of Architecture and Urban Planning, Shenzhen University, Shenzhen, China; Shenzhen Key Laboratory of Spatial Information Smart Sensing and Services and Research Institute of Smart Cities, School of Architecture and Urban Planning, Shenzhen University, Shenzhen, China","2021 28th International Conference on Geoinformatics","31 Jan 2022","2021","","","1","5","Efficient sharing of hyper massive spatiotemporal trajectory data (HMSTD) is the foundation for establishing large-scale perception infrastructure, such as vehicle monitoring network in a smart city containing New York, Tokyo, Beijing, and Shanghai these megacities. Consequently, the daily trajectory data scale of vehicle monitoring networks in the smart city is growing rapidly, reaching daily volumes of 1 billion. Accessing HMSTD in transport, the Internet of Things, or other fields is hard and limited under the present spatiotemporal data indexing methods. Therefore, we propose a path-divided Hadoop Distributed File System (HDFS) data blocking (SMART) based on the Apache Impala (SMART -Impala) method to optimize the efficient access method of HMSTD to improve the efficiency of hyperdata sharing. Apache Impala, as a practical and powerful distributed data access means for massive data stored in memory, is widely applied in massive data sharing. In Smart-Impala, the spatiotemporal trajectory data retrieve capability of Impala is extended. Besides, a self-adaption parquet data partitioning strategy or pattern is proposed. In experiments, the Shenzhen BeiDou (BD) bus network is selected as the experimental scenario, consisting of 35809 buses equipped with BD positioning sensors, creating 1.03 billion data records each day. The buses distribution in Shenzhen city is achieved from 7:00 a.m. to 9:00 a.m. and 11:00 a.m. to 01:00 p.m. Moreover, SMART-Impala achieves approximately 8 times, 9 times, 29 times, 110 times higher performance than that in MongoDB or HBase in data scales of 10 million, 100 million, 500 million, 1 billion, whose results outperform that of the average division in Impala, MongoDB, and HBase methods.","2161-0258","978-1-6654-2074-7","10.1109/IEEECONF54055.2021.9687505","NSFC(grant numbers:61802265); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9687505","Apache Impala;hyper massive trajectory data;indexing;HDFS","Smart cities;Scalability;Distributed databases;Relational databases;Trajectory;Spatiotemporal phenomena;Sensors","","2","","15","IEEE","31 Jan 2022","","","IEEE","IEEE Conferences"
"DNN Migration in IoTs: Emerging Technologies, Current Challenges, and Open Research Directions","M. Xue; H. Wu; R. Li","Tianjin University, China; Tianjin University, China; Kanazawa University, Japan","IEEE Consumer Electronics Magazine","17 Apr 2023","2023","12","3","28","38","With the rapid development of the Internet of Things (IoT) and communication technology, deep neural network (DNN) applications, such as medical imaging, speech transcription, handwritten text recognition, have been widely used in IoT devices. However, due to resource constraints on these devices, e.g., limited memory capacity, weak computing capacity, and low battery capacity, IoT devices cannot support complicated DNN operation effectively and, thus, fail to fulfill the requirements of Quality of Service of mobile users. One promising approach is to migrate the DNN model to a remote cloud server to reduce the computing burden on IoT devices. Unfortunately, it still suffers from high delay and low bandwidth when communicating with cloud servers. Although the transmission delay of the edge server is low, its computing capacity lacks scalability and elasticity.To make matters worse, in the real world, the wireless connection between IoT devices and the cloud is intermittent, which can cause offloading failures during large-scale DNN data transmission. In this article, we describe a DNN model migration framework to overcome the abovementioned challenges, which consists of three parts: DNN model preprocessing, partition-offloading plan, and partition-uploading plan. Accordingly, we introduce the operation of the DNN migration and the available methods for each part. In addition, we improve the DNN partition-uploading plan in a multiuser edge-cloud collaborative computing environment. Finally, we highlight the important challenges of achieving more efficient DNN migration and point out the unresolved issues of DNN migration, which may shed light on future research directions.","2162-2256","","10.1109/MCE.2022.3159348","National Natural Science Foundation of China(grant numbers:62071327); JSPS KAKENHI(grant numbers:19H04105); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9735334","DNN Partition;Computation Offloading;DNN Inference;Edge-Cloud Collaborative Computing;Intelligent Applications","Servers;Computational modeling;Cloud computing;Delays;Collaboration;Partitioning algorithms;Task analysis","","6","","15","IEEE","15 Mar 2022","","","IEEE","IEEE Magazines"
"Hybrid Machine Learning Approach for Evapotranspiration Estimation of Fruit Tree in Agricultural Cyber–Physical Systems","T. Wang; X. Wang; Y. Jiang; Z. Sun; Y. Liang; X. Hu; H. Li; Y. Shi; J. Xu; J. Ruan","Department of Information Systems, City University of Hong Kong, Hong Kong; Institute of Systems Engineering, Dalian University of Technology, Dalian, China; College of Engineering, Nanjing Agricultural University, Nanjing, China; College of Economics and Management, Northwest A&F University, Yangling, China; College of Economics and Management, Northwest A&F University, Yangling, China; School of Management, Zhejiang University, Hangzhou, China; General Manager Office, CHINTY Electric Technology Company Ltd., Yangling, China; General Education Center, Tokai University, Kumamoto, Japan; Department of Information Systems, City University of Hong Kong, Hong Kong; College of Economics and Management, Northwest A&F University, Yangling, China","IEEE Transactions on Cybernetics","17 Aug 2023","2023","53","9","5677","5691","The flourish of the Internet of Things (IoT) and data-driven techniques provide new ideas for enhancing agricultural production, where evapotranspiration estimation is a crucial issue in crop irrigation systems. However, tremendous and unsynchronized data from agricultural cyber–physical systems bring large computational costs as well as complicate performing conventional machine learning methods. To precisely estimate evapotranspiration with acceptable computational costs under the background of IoT, we combine time granulation computing techniques and gradient boosting decision tree (GBDT) with Bayesian optimization (BO) to propose a hybrid machine learning approach. In the combination, a fuzzy granulation method and a time calibration technique are introduced to break voluminous and unsynchronized data into small-scale and synchronized granules with high representativeness. Subsequently, GBDT is implemented to predict evapotranspiration, and BO is utilized to find the optimal hyperparameter values from the reduced granules. IoT data from Xi’an Fruit Technology Promotion Center in Shaanxi Province, China, verify that the proposed granular-GBDT-BO is effective for cherry tree evapotranspiration estimation with reduced computational time, and acceptable and robust predictive accuracy. Consequently, the precise estimation of crop evapotranspiration could provide operational guidance for plant irrigation, plant conservations, and pest control in the agricultural greenhouse.","2168-2275","","10.1109/TCYB.2022.3164542","National Natural Science Foundation of China(grant numbers:71973106,72071028,71933005); Strategic Research Grant at the City University of Hong Kong(grant numbers:7005473); Shaanxi Science Fund for Distinguished Young Scholars(grant numbers:2021JC-21); Natural Science Basic Research Program of Shaanxi Province(grant numbers:2020JQ- 281); 2021 Key Scientific Research Project of Shaanxi Education Department(grant numbers:21JT043); Tang Scholars Program of Northwest A&F University.; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9768183","Agricultural cyber-physical systems;agricultural greenhouse;fuzzy system;machine learning","Estimation;Green products;Agriculture;Crops;Production;Temperature sensors;Mathematical models","","4","","38","IEEE","4 May 2022","","","IEEE","IEEE Journals"
"Energy-Efficient Offloading for DNN-Based Smart IoT Systems in Cloud-Edge Environments","X. Chen; J. Zhang; B. Lin; Z. Chen; K. Wolter; G. Min","College of Mathematics and Computer Science, Fuzhou University, Fuzhou, China; College of Mathematics and Computer Science, Fuzhou University, Fuzhou, China; College of Physics and Energy, Fujian Provincial Key Laboratory of Quantum Manipulation and New Energy Materials, Fujian Normal University, Fuzhou, China; Department of Computer Science, College of Engineering, Mathematics and Physical Sciences, University of Exeter, Exeter, U.K.; Institut für Informatik, Freie Universität Berlin, Berlin, Germany; Department of Computer Science, College of Engineering, Mathematics and Physical Sciences, University of Exeter, Exeter, U.K.","IEEE Transactions on Parallel and Distributed Systems","12 Aug 2021","2022","33","3","683","697","Deep Neural Networks (DNNs) have become an essential and important supporting technology for smart Internet-of-Things (IoT) systems. Due to the high computational costs of large-scale DNNs, it might be infeasible to directly deploy them in energy-constrained IoT devices. Through offloading computation-intensive tasks to the cloud or edges, the computation offloading technology offers a feasible solution to execute DNNs. However, energy-efficient offloading for DNN based smart IoT systems with deadline constraints in the cloud-edge environments is still an open challenge. To address this challenge, we first design a new system energy consumption model, which takes into account the runtime, switching, and computing energy consumption of all participating servers (from both the cloud and edge) and IoT devices. Next, a novel energy-efficient offloading strategy based on a Self-adaptive Particle Swarm Optimization algorithm using the Genetic Algorithm operators (SPSO-GA) is proposed. This new strategy can efficiently make offloading decisions for DNN layers with layer partition operations, which can lessen the encoding dimension and improve the execution time of SPSO-GA. Simulation results demonstrate that the proposed strategy can significantly reduce energy consumption compared to other classic methods.","1558-2183","","10.1109/TPDS.2021.3100298","National Natural Science Foundation of China(grant numbers:62072108); Natural Science Foundation of Fujian Province(grant numbers:2020J06014); Natural Science Foundation of Fujian Province(grant numbers:2019J01286); Young and Middle-aged Teacher Education Foundation of Fujian Province(grant numbers:JT180098); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9497712","Cloud-edge computing;IoT systems;energy-efficient offloading;deep neural networks;particle swarm optimization","Energy consumption;Internet of Things;Cloud computing;Servers;Data communication;Quality of service;Task analysis","","95","","38","IEEE","27 Jul 2021","","","IEEE","IEEE Journals"
"A Scalable and Energy-Efficient IoT System Supported by Cell-Free Massive MIMO","H. Yan; A. Ashikhmin; H. Yang","Department of Electrical and Computer Engineering, NYU Wireless, New York University, Brooklyn, NY, USA; Mathematics of Communications Research Department, Nokia Bell Labs, Murray Hill, NJ, USA; Mathematics of Communications Research Department, Nokia Bell Labs, Murray Hill, NJ, USA","IEEE Internet of Things Journal","22 Sep 2021","2021","8","19","14705","14718","An Internet-of-Things (IoT) system supports a massive number of IoT devices wirelessly. We show how to use cell-free (CF) massive multiple input and multiple output (MIMO) to provide a scalable and energy-efficient IoT system. We employ optimal linear estimation with random pilots to acquire channel state information (CSI) for MIMO precoding and decoding. In the uplink (UL), we employ optimal linear decoder and utilize random matrix (RM) theory to obtain two accurate signal-to-interference plus noise ratio (SINR) approximations involving only large-scale fading coefficients. We derive several max–min type power control algorithms based on both exact SINR expression and RM approximations. Next we consider the power control problem for downlink (DL) transmission. To avoid solving a time-consuming quasiconcave problem that requires repeat tests for the feasibility of a second-order cone programming (SOCP) problem, we develop a neural network (NN) aided power control algorithm that results in 30 times reduction in computation time. This power control algorithm leads to scalable CF Massive MIMO networks in which the amount of computations conducted by each access point (AP) does not depend on the number of network APs. Both UL and DL power control algorithms allow visibly improve the system spectral efficiency (SE) and, more importantly, lead to multifold improvements in energy efficiency (EE), which is crucial for IoT networks.","2327-4662","","10.1109/JIOT.2021.3071781","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9399102","Cell-free (CF);energy efficiency (EE);Internet of Things (IoT);massive MIMO (mMIMO);scalable","Internet of Things;Power control;Signal to noise ratio;Interference;Channel estimation;Receivers;Fading channels","","29","","27","IEEE","8 Apr 2021","","","IEEE","IEEE Journals"
"Stabilizing Frame Slotted Aloha-Based IoT Systems: A Geometric Ergodicity Perspective","J. Yu; P. Zhang; L. Chen; J. Liu; R. Zhang; K. Wang; J. An","School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Computing Science, Simon Fraser University, Burnaby, BC, Canada; Information Engineering College, Capital Normal University, Beijing, China; Department of Information Engineering, Wuhan University of Technology, Wuhan, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China","IEEE Journal on Selected Areas in Communications","18 Feb 2021","2021","39","3","714","725","The explosive deployment of the Internet of Things (IoT) brings a massive number of light-weight and energy-limited IoT devices, challenging stable wireless access. Energy-efficient, Frame Slotted Aloha (FSA) recently emerged as a promising MAC protocol for large-scale IoT systems such as Machine to Machine (M2M) and Radio Frequency Identification (RFID). Yet the stability of FSA and how to stabilize it, despite of its fundamental importance on the effective operation in practical systems, have not been systematically addressed. In order to bridge this gap, we devote this paper to designing stable FSA-based access protocol (SFP) to stabilize IoT systems. We first design an additive active node population estimation scheme and use the estimate to set frame size and participation probability for throughput optimization. We then carry out theoretical analysis demonstrating the stability of SFP in the sense of geometric ergodicity of Markov chain derived from dynamics of the active node population and its estimate. Our central theoretical result is a set of closed-form conditions on the stability of SFP. We further conduct extensive simulations whose results confirm our theoretical analysis and demonstrate the effectiveness of SFP.","1558-0008","","10.1109/JSAC.2020.3018795","NSF of China(grant numbers:61901035,61801064); Beijing Institute of Technology Research Fund Program for Young Scholars and Young Elite Scientist Sponsorship Program by CAST and Chongqing Key Laboratory of Mobile Communications Technology; Science and Technology Project of Beijing Municipal Education Commission(grant numbers:KM202010028005); NSF of China(grant numbers:61672395); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9174915","IoT;massive access;frame slotted aloha","Stability analysis;Sociology;Statistics;Protocols;Throughput;Markov processes;Estimation","","21","","21","IEEE","24 Aug 2020","","","IEEE","IEEE Journals"
"MapChain: A DHT-Based Dual-Blockchain Data Structure for Large-Scale IoT Systems","T. Wu; P. L. Yeoh; G. Jourjon; K. Thilakarathna","The University of Sydney, Australia; The University of Sydney, Australia; Data61, CSIRO, Sydney, Australia; The University of Sydney, Australia","2021 IEEE 7th World Forum on Internet of Things (WF-IoT)","9 Nov 2021","2021","","","177","182","The rapid growth of Internet of Things (IoT) devices is creating enormous amounts of data in large-scale IoT systems. In such systems, the efficiency, trustworthiness, confidentiality, and integrity of data storage and retrieval are significant challenges. In this paper, we propose a dual-blockchain distributed data structure as a highly scalable solution for resource-constrained IoT systems. Our proposed model is based on a distributed hash table (DHT) which is implemented and benchmarked in an experimental IoT network environment. Performance analysis and experimental results highlight that our dual-chain model provides better scalability in terms of space consumption, latency and computational complexity compared to baseline single-chain models. Security analyses are provided to discuss the feasibility of distributed trust management, fault tolerance, as well as confidentiality of data stored in our model and conflict avoidance mechanisms.","","978-1-6654-4431-6","10.1109/WF-IoT51360.2021.9595910","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9595910","blockchain;internet-of-things;scalability","Resistance;Analytical models;Computational modeling;Scalability;Memory;Data structures;Data models","","4","","18","IEEE","9 Nov 2021","","","IEEE","IEEE Conferences"
"Be United in Actions: Taking Live Snapshots of Heterogeneous Edge–Cloud Collaborative Cluster With Low Overhead","B. Shi; B. Dong; Q. Zheng","School of Computer Science and Technology, Xi’an Jiaotong University, Xi’an, China; School of Distance Education, Xi’an Jiaotong University, Xi’an, China; School of Computer Science and Technology, Xi’an Jiaotong University, Xi’an, China","IEEE Internet of Things Journal","6 May 2022","2022","9","10","7311","7324","Failure recovery is one of the most essential problems in the Internet of Things (IoT) systems, especially in crucial scenarios, such as traffic control and healthcare. Meanwhile, with the ever-increasing demand of IoT applications and for latency and security considerations, more and more IoT applications are migrated to large clusters that consist of both cloud and edge servers. However, with the scale of edge–cloud collaborative clusters continue to expand, the risk of system errors and failures is also increasing. The conventional snapshot/rollback method is a powerful way for solving this problem and it is widely used in cloud computing scenarios. But when transplanting to edge–cloud collaborative clusters with the nature of distribution and heterogeneity, it will introduce serious network interruption and guest performance impact. Therefore, in this article, to address the above problems, we propose a duration-aware cluster snapshot system, named Phalanx, which can take live snapshots of edge–cloud collaborative clusters with low performance overhead. In Phalanx, we use the low-overhead precopy model and first propose a virtual machine (VM) snapshot duration prediction method that can accurately predict the snapshot duration of each single VM. Then, based on the prediction results, we coordinate the snapshot process to ensure the whole cluster has a consistency-friendly schedule, thereby solving the network interruption problems and finally, minimizing the adverse performance impact to the guest IoT applications. We implement the prototype of Phalanx on QEMU/KVM platform and conduct several experiments. The experimental results show that Phalanx offers negligible network interruption while incurring 10.68%–20.9% less performance impact over existing solutions.","2327-4662","","10.1109/JIOT.2021.3111023","National Science Foundation of China(grant numbers:62002282,62050194,62037001); China Postdoctoral Science Foundation(grant numbers:2020M683492); MOE Innovation Research Team(grant numbers:IRT_17R86); Research Project of XJTU Undergraduate Teaching Reform(grant numbers:20JX04Y); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9530726","Availability;edge–cloud collaborative cluster;network interruption;precopy;snapshot;virtual machine (VM)","Internet of Things;Collaboration;Cloud computing;Virtual machining;Servers;Medical services;Costs","","","","42","IEEE","8 Sep 2021","","","IEEE","IEEE Journals"
"Latency Aware VNF Deployment at Edge Devices for IoT Services: An Artificial Neural Network Based Approach","M. Emu; P. Yan; S. Choudhury","Department of Computer Science, Lakehead University, Thunder Bay, Canada; Department of Computer Science, Lakehead University, Thunder Bay, Canada; Department of Computer Science, Lakehead University, Thunder Bay, Canada","2020 IEEE International Conference on Communications Workshops (ICC Workshops)","21 Jul 2020","2020","","","1","6","Virtual Network Functions (VNFs) placed at the edge devices in the vicinity of users improve response time, avoid redundant utilization of core network, and reduce user-to-VNF end to end latency to a great extent, while leveraging the Internet of Things (IoT) services in Network functions virtualization (NFV) context. Different approaches for VNF placement have been proposed, however, the main concern has been to minimize resource utilization as much as possible by reducing the required number of servers to run a chain of VNFs to provide a specific service, without considering network conditions, for example, latency. In this paper, we implement the optimal edge VNF placement problem as an Integer Linear Programming model that guarantees the minimum end to end latency, while ensuring Quality of Service by not overstepping beyond an acceptable limit of latency violation. Latency beyond such limits can be the cause of disruption and degradation of performance for time-sensitive IoT services. The time complexity of the existing optimal edge VNF placement algorithm being NP-hard, we further propose a VNF placement strategy using Artificial Neural Network (ANN) trained by the assignment solutions generated from the Integer Linear Programming (ILP) model of the optimal edge VNF placement method for smaller instances of VNFs. This approach solves the VNF assignment problem at edge devices for a larger number of VNFs, while reducing the time complexity to be linear and providing similar results as the ILP model in terms of latency. This research work can be considered as a pioneering mark for IoT virtual service orchestration systems by embedding intelligence that can scale down the massive fabrication costs of IoT endpoints (e.g., sensors, actuators) required to be equipped with high processing power to enable ultra-low response time for users.","2474-9133","978-1-7281-7440-2","10.1109/ICCWorkshops49005.2020.9145242","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9145242","Network Function Virtualization;IoT Services;Artificial Neural Network;Latency;Edge Devices","Hardware;Time complexity;Neural networks;Internet of Things;Network function virtualization;Integer linear programming","","9","","25","IEEE","21 Jul 2020","","","IEEE","IEEE Conferences"
"Large-scale Organizational and Technical Systems Sustainable Development Concept","I. A. Stepanovskaya","Laboratory of Management of Large-Scale System Development, V.A. Trapeznikov Institute of Control Sciences of RAS, Moscow, Russia","2021 14th International Conference Management of large-scale system development (MLSD)","22 Nov 2021","2021","","","1","4","This article's subject is socio-cyber-physical self-organization based on the Internet of things, mobile systems, cognitive technologies, and wireless switching of new generations 4G, 5G, and higher. The purpose of the research is to use the socio-cyber-physical self-organization strategy for methodological and instrumental support of network technologies for remote interdisciplinary controlling the functioning and development of large-scale organizational and technical systems. The study's relevance is due to the increased requirements for indicators of fault tolerance, survivability, information security, and warranty periods for the operation of digital organizational and technical systems.","","978-1-6654-1230-8","10.1109/MLSD52249.2021.9600176","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9600176","digital systems;economic systems;socio-cyber-physical self-organization;controlling;gibrid intelligence;cybernetics","Wireless communication;Warranties;Urban areas;Switches;Seaports;Supercomputers;Macroeconomics","","1","","10","IEEE","22 Nov 2021","","","IEEE","IEEE Conferences"
"EC²Detect: Real-Time Online Video Object Detection in Edge-Cloud Collaborative IoT","S. Guo; C. Zhao; G. Wang; J. Yang; S. Yang","National Engineering Laboratory for Big Data Analytics and the School of Mathematics and Statistics, Xi’an Jiaotong University, Xi’an, China; Department of Computing, Imperial College London, London, U.K.; National Engineering Laboratory for Big Data Analytics and the School of Computer Science and Technology, Xi’an Jiaotong University, Xi’an, China; School of Mathematics and Statistics, Xi’an Jiaotong University, Xi’an, China; National Engineering Laboratory for Big Data Analytics and Ministry of Education Key Laboratory for Intelligent Networks and Network Security, Xi’an Jiaotong University, Xi’an, China","IEEE Internet of Things Journal","6 Oct 2022","2022","9","20","20382","20392","Video object detection is a fundamental technology of intelligent video analytics for Internet of Things (IoT) applications. However, even with extraordinary detection accuracy, predominating solutions based on deep convolutional neural networks (DCNNs) cannot achieve real-time online object detection on video streams with a low end-to-end (E2E) response latency and therefore cannot be applied to proliferating latency-sensitive IoT applications like autonomous driving requiring large-scale intelligent video analytics. To address this issue, we present EC2Detect, an edge-cloud collaborative real-time online video object detection method. Specifically, we propose a tracking-assisted object detection architecture based on edge-cloud collaboration with keyframe selection, where the accurate but heavy object detection is conducted by the Cloud on sparse keyframes adaptively selected according to their semantic variation, and the lightweight object tracking is used to localize and identify objects in other frames at edge devices. Extensive experiments of our real-world prototype demonstrate that, EC2Detect significantly outperforms state-of-the-art methods in terms of processing speed (up to  $4.77\times $  faster), E2E latency (up to  $8.12 \times $  lower), and edge-cloud bandwidth occupation ( $17 \times $  lower) with an acceptable mAP, which can effectively support large-scale intelligent video analytics in practice. Source code of EC2Detect is available at https://github.com/ECCDetect/ECCDetect.","2327-4662","","10.1109/JIOT.2022.3173685","National Key Research and Development Program of China(grant numbers:2020YFA0713900); National Natural Science Foundation of China(grant numbers:61772410,61802298,62172329,U1811461,U21A6005,11690011); China Postdoctoral Science Foundation(grant numbers:2020T130513,2019M663726); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9771217","Deep learning;edge-cloud collaboration;online object detection;real-time video analytics","Object detection;Image edge detection;Streaming media;Internet of Things;Collaboration;Visual analytics;Feature extraction","","8","","44","IEEE","9 May 2022","","","IEEE","IEEE Journals"
"A Dimension Reduction-Based Joint Activity Detection and Channel Estimation Algorithm for Massive Access","X. Shao; X. Chen; R. Jia","College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China","IEEE Transactions on Signal Processing","14 Jan 2020","2020","68","","420","435","Grant-free random access is a promising protocol to support massive access in beyond fifth-generation (B5G) cellular Internet-of-Things (IoT) with sporadic traffic. Specifically, in each coherence interval, the base station (BS) performs joint activity detection and channel estimation (JADCE) before data transmission. Due to the deployment of a large-scale antennas array and the existence of a huge number of IoT devices, JADCE usually has high computational complexity and needs long pilot sequences. To solve these challenges, this paper proposes a dimension reduction method, which projects the original device state matrix to a low-dimensional space by exploiting its sparse and low-rank structure. Then, we develop an optimized design framework with a coupled full column rank constraint for JADCE to reduce the size of the search space. However, the resulting problem is non-convex and highly intractable, for which the conventional convex relaxation approaches are inapplicable. To this end, we propose a logarithmic smoothing method for the non-smoothed objective function and transform the interested matrix to a positive semidefinite matrix, followed by giving a Riemannian trust-region algorithm to solve the problem in complex field. Simulation results show that the proposed algorithm is efficient to a large-scale JADCE problem and requires shorter pilot sequences than the state-of-art algorithms which only exploit the sparsity of device state matrix.","1941-0476","","10.1109/TSP.2019.2961299","National Natural Science Foundation of China(grant numbers:61871344); Zhejiang Provincial Natural Science Foundation of China(grant numbers:LR20F010002); National Science and Technology Major Project of China(grant numbers:2018ZX03001017-002); National Key R&D Program of China(grant numbers:2018YFB1801104); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8937497","B5G;grant-free;activity detection;channel estimation;massive connectivity;Riemannian optimization","Internet of Things;Channel estimation;Sparse matrices;Signal processing algorithms;Coherence;Computational complexity;Matching pursuit algorithms","","50","","46","IEEE","20 Dec 2019","","","IEEE","IEEE Journals"
"Knowledge-Defined Edge Computing Networks Assisted Long-term Optimization of Computation Offloading and Resource Allocation Strategy","K. Yang; X. Wang; Q. He; L. Zhao; Y. Liu; D. Tarchi","Colledge of Computer Science and Engineering, Northeastern University, Shenyang, China; Colledge of Computer Science and Engineering, Northeastern University, Shenyang, China; College of Medicine and Biological Information Engineering, Northeastern University, Shenyang, China; School of Computer Science, Shenyang Aerospace University, Shenyang, China; Colledge of Computer Science and Engineering, Northeastern University, Shenyang, China; College of Electronic and Information Engineering, University of Bologna, Bologna, Italy","IEEE Transactions on Wireless Communications","","2023","PP","99","1","1","With the proliferation of devices connected to the Internet of Things (IoT), the complexity of network management has increased. To intelligently manage large-scale networks, we propose a Knowledge-Defined Edge Computing Networks (KDECN) architecture. Edge Nodes (ENs) deployed in the KDECN architecture are responsible for collecting and preprocessing the relevant information uploaded by User Devices (UDs), and provide computation resources for UDs. Futhermore, since multiple UDs share system computation resources, one computing decision will affect the subsequent decision-making of other UDs. Thus, accurately predicting the demands for UD task requests is a key challenge to maximize long-term execution utility. To this end, we deploy the LSTM-based Task Request Demand Prediction (TRDP) method on the management plane of KDECN architecture to predict the task request quantity of UDs in each future time slot. In order to maximize long-term execution utility of the system, we propose a Deep Reinforcement Learning (DRL)-based Long-term Computation Offloading and computation Resource Allocation (L-CORA) algorithm. Specifically, the proposed L-CORA algorithm makes computing decisions based on the prediction of the offloading task quantity and the personalized demands of UDs to ensure the long-term quality of computing service. Extensive experiments with Shanghai real-world datasets to prove that the KDECN-based L-CORA algorithm effectively improves the average utility of the system.","1558-2248","","10.1109/TWC.2023.3325654","National Natural Science Foundation of China(grant numbers:61872073,62032013,62202089,92267206,U22A2004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10304616","Computation offloading;knowledge-defined networking;mobile edge computing;deep reinforcement learning","Task analysis;Computer architecture;Resource management;Optimization;Decision making;Distributed databases;Delays","","","","","IEEE","1 Nov 2023","","","IEEE","IEEE Early Access Articles"
"ShellCore: Automating Malicious IoT Software Detection Using Shell Commands Representation","H. Alasmary; A. Anwar; A. Abusnaina; A. Alabduljabbar; M. Abuhamad; A. Wang; D. Nyang; A. Awad; D. Mohaisen","Department of Computer Science, King Khalid University, Abha, Saudi Arabia; Department of Computer Science, University of Central Florida, Orlando, FL, USA; Department of Computer Science, University of Central Florida, Orlando, FL, USA; Department of Computer Science, University of Central Florida, Orlando, FL, USA; Department of Computer Science, University of Central Florida, Orlando, FL, USA; Department of Computer and Data Science, Case Western Reserve University, Cleveland, OH, USA; Cyber Security Major, Division of Software and Engineering, Ewha Womans University, Seoul, South Korea; Department Electrical and Computer Engineering, North Carolina State University, Raleigh, NC, USA; Department of Computer Science, University of Central Florida, Orlando, FL, USA","IEEE Internet of Things Journal","4 Feb 2022","2022","9","4","2485","2496","The Linux shell is a command-line interpreter that provides users with a command interface to the operating system, allowing them to perform various functions. Although very useful in building capabilities at the edge, the Linux shell can be exploited, giving adversaries a prime opportunity to use them for malicious activities. With access to Internet of Things (IoT) devices, malware authors can abuse the Linux shell of those devices to propagate infections and launch large-scale attacks, e.g., Distributed Denial of Service. In this work, we provide a first look at the tasks managed by shell commands in Linux-based IoT malware toward detection. We analyze malicious shell commands found in IoT malware and build a neural network-based model, ShellCore, to detect malicious shell commands. Namely, we collected a large data set of shell commands, including malicious commands extracted from 2891 IoT malware samples and benign commands collected from real-world network traffic analysis and volunteered data from Linux users. Using conventional machine and deep learning-based approaches trained with a term- and character-level features, ShellCore is shown to achieve an accuracy of more than 99% in detecting malicious shell commands and files (i.e., binaries).","2327-4662","","10.1109/JIOT.2021.3086398","Global Research Laboratory (GRL) Program of the National Research Foundation (NRF) funded by the Ministry of Science, Information, and Communication Technologies (ICT) and Future Planning(grant numbers:NRF-2016K1A1A2912757); Air Force Research Laboratory (AFRL) Summer Program; NSF(grant numbers:CNS-1809000,CNS-1814417); Cyber Florida Seed Grant; Institute for Smart, Secure and Connected Systems at Case Western Reserve University through a grant provided by the Cleveland Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9446490","Internet of Things (IoT) security;Linux shell commands;machine learning;malware detection","Malware;Feature extraction;Internet of Things;Linux;Task analysis;Password;Data mining","","3","","54","IEEE","3 Jun 2021","","","IEEE","IEEE Journals"
"Privacy-Enhanced Data Fusion for COVID-19 Applications in Intelligent Internet of Medical Things","H. Lin; S. Garg; J. Hu; X. Wang; M. Jalil Piran; M. S. Hossain","College of Mathematics and Informatics, Fujian Normal University, Fuzhou, China; Department of Electrical Engineering, École de technologie supérieure, Montreal, Canada; School of Mathematics and Computer Science, University of Exeter, Exeter, U.K.; College of Mathematics and Informatics, Fujian Normal University, Fuzhou, China; Department of Computer Science and Engineering, Sejong University, Seoul, South Korea; Chair of Pervasive and Mobile Computing and the Department of Software Engineering, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia","IEEE Internet of Things Journal","25 Oct 2021","2021","8","21","15683","15693","With the worldwide large-scale outbreak of COVID-19, the Internet of Medical Things (IoMT), as a new type of Internet of Things (IoT)-based intelligent medical system, is being used for COVID-19 prevention and detection. However, since the widespread use of IoMT will generate a large amount of sensitive information related to patients, it is becoming more and more important yet challenging to ensure data security and privacy of COVID-19 applications in IoMT. The leakage of private information during IoMT data fusion process will cause serious problems and affect people’s willingness to contribute data in IoMT. To address these challenges, this article proposes a new privacy-enhanced data fusion strategy (PDFS). The proposed PDFS consists of four important components, i.e., sensitive task classification, task completion assessment, incentive mechanism-based task contract design, and homomorphic encryption-based data fusion. The extensive simulation experiments demonstrate that PDFS can achieve high task classification accuracy, task completion rate, task data reliability and task participation rate, and low average error rate, while improving the privacy protection for data fusion under COVID-19 application environments based on IoMT.","2327-4662","","10.1109/JIOT.2020.3033129","Deanship of Scientific Research at King Saud University, Riyadh, Saudi Arabia, through the Vice Deanship of Scientific Research Chairs: Chair of Pervasive and Mobile Computing; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9235575","COVID-19;data fusion;deep reinforcement learning;Internet of Medical Things (IoMT);privacy protection","Task analysis;Data integration;COVID-19;Data privacy;Internet of Things;Servers","","51","","25","IEEE","22 Oct 2020","","","IEEE","IEEE Journals"
"Split-and-Shuffle Detector for Real-Time Traffic Object Detection in Aerial Image","G. Mao; H. Liang; Y. Yao; L. Wang; H. Zhang","School of Transportation and Logistics, National United Engineering Laboratory of Integrated and Intelligent Transportation, and National Engineering Laboratory of Integrated Transportation Big Data Application Technology, Southwest Jiaotong University, Chengdu, China; School of Transportation and Logistics, National United Engineering Laboratory of Integrated and Intelligent Transportation, and National Engineering Laboratory of Integrated Transportation Big Data Application Technology, Southwest Jiaotong University, Chengdu, China; School of Transportation and Logistics, National United Engineering Laboratory of Integrated and Intelligent Transportation, and National Engineering Laboratory of Integrated Transportation Big Data Application Technology, Southwest Jiaotong University, Chengdu, China; School of Transportation and Logistics, National United Engineering Laboratory of Integrated and Intelligent Transportation, and National Engineering Laboratory of Integrated Transportation Big Data Application Technology, Southwest Jiaotong University, Chengdu, China; School of Transportation and Logistics, National United Engineering Laboratory of Integrated and Intelligent Transportation, and National Engineering Laboratory of Integrated Transportation Big Data Application Technology, Southwest Jiaotong University, Chengdu, China","IEEE Internet of Things Journal","","2023","PP","99","1","1","Real-time object detection is an essential part of various Internet of Things (IoT) applications. Unmanned aerial vehicles (UAVs) employ visual sensors to capture high-definition images to detect objects of interest. However, current research on UAV detectors mainly focuses on developing more sophisticated network architectures, with little attention paid to the limitations of UAV computing resources. In this work, we present an end-to-end split-and-shuffle detector, named SCSDet. Unlike the mainstream detector designs that heavily rely on bottleneck structures, our method is based on inexpensive split-and-shuffle operations. It encourages the detector to avoid unnecessary transformation layers for channel down-sampling, thereby minimizing memory and computation cost. This is rarely studied in detector architecture design. Specifically, we first design a lightweight backbone structure (SCSNet) based on split-and-shuffle, which allows frequent interaction between different gradient information to capture more useful non-linear features for small-scale objects at a low cost. Next, we construct an efficient receptive field module (ERFM) to generate richer multi-receptive field expressions for the initial feature space. It significantly alleviates the adverse effects of single receptive field size on the capability of the detectors to detect small-scale objects. Finally, we propose a grouped local attention convolution (GLAConv), which utilizes local sliding windows with different coverage rates to adaptively learn channel and spatial attention. This makes the detector to focus on the foreground. Experimental results show that our method achieves high accuracy with low complexity in UAV object detection.","2327-4662","","10.1109/JIOT.2023.3334742","National Natural Science Foundation of China(grant numbers:62071398); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10330582","Traffic scene perception;deep learning;UAV image;real-time object detection","Detectors;Autonomous aerial vehicles;Object detection;Real-time systems;Feature extraction;Internet of Things;Task analysis","","","","","IEEE","28 Nov 2023","","","IEEE","IEEE Early Access Articles"
"Multiple Access in Large-Scale LoRaWAN: Challenges, Solutions, and Future Perspectives","C. Shao; O. Muta; Q. Du; K. R. Dandekar; X. Wang","Kyushu University, Fukuoka, Japan; Kyushu University, Fukuoka, Japan; Xi’an Jiaotong University, Xi’an, Shaanxi, China; Drexel University, Philadelphia, PA, USA; Hainan University, Haikou, Hainan, China","IEEE Consumer Electronics Magazine","","2022","PP","99","1","9","Enabling energy-efficient and long-distance wireless networking is expected by various Internet-of-Things systems and consumer electronics applications. Low Power Wide Area Networks can commendably satisfy this requirement because of their combination of low-power and long-range features. Thereinto, open-standard Long Range Wide Area Network (LoRaWAN) is the representative player with hundreds of deployment cases worldwide. Unfortunately, current multiple access (MA) strategy for LoRaWAN has been proved to incur severe wireless signal interference under large-scale deployment. This is the inherent hindrance for current LoRaWAN to support large-scale wireless networking. In this context, this article aims to provide a detailed tutorial of MA issues in large-scale LoRaWAN for the first time. We start with several practical use cases of large-scale LoRaWAN. We then explain the detailed challenges of large-scale LoRaWAN networking. Representative MA solutions for better LoRaWAN networking are then described and compared. Future research directions for enhanced MA protocol design are also discussed.","2162-2256","","10.1109/MCE.2022.3182518","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9795666","","Logic gates;Wireless communication;Consumer electronics;Chirp;Interference;Discrete Fourier transforms;Wireless sensor networks","","4","","","IEEE","14 Jun 2022","","","IEEE","IEEE Early Access Articles"
"A Time-Domain Binary CNN Engine With Error-Detection-Based Resilience in 28nm CMOS","Z. Cai; B. Cheng; Y. Du; X. Shang; W. Shan","National and Local Joint Engineering Laboratory, RF Integration and Micro-Assembly Technology, College of Electronic and Optical Engineering & College of Microelectronics, Nanjing University of Posts and Telecommunications, Nanjing, China; National ASIC System Engineering Research Center, School of Electronic Science & Engineering, Southeast University, Nanjing, China; National ASIC System Engineering Research Center, School of Electronic Science & Engineering, Southeast University, Nanjing, China; National ASIC System Engineering Research Center, School of Electronic Science & Engineering, Southeast University, Nanjing, China; National ASIC System Engineering Research Center, School of Electronic Science & Engineering, Southeast University, Nanjing, China","IEEE Transactions on Circuits and Systems II: Express Briefs","30 Aug 2021","2021","68","9","3177","3181","Due to the increasing demand of high energy-efficient processor for deep neural networks, traditional neural network engines with high-precision weights and activations that usually occupies huge on/off-chip resources with large power consumption are no longer suitable for Internet-of-Things applications. Binary neural networks (BNNs) reduce memory size and computation complexity, achieving drastically increased energy efficiency. In this brief, an energy-efficient time-domain binary neural network engine is optimized for image recognition, with time-domain accumulation (TD-MAC), timing error detection based adaptive voltage scaling design and the related approximate computing. The proposed key features are: 1) an error-tolerant adaptive voltage scaling system with TD-MAC chain truncation for aggressive power reduction, working from near-threshold to normal voltage; 2) architectural parallelism and data reuse with 100% TD-MAC utilization; 3) low power TD-MAC based on analog delay lines. Fabricated in a 28nm CMOS process, the whole system achieves a maximum 51.5TOPS/W energy efficiency at 0.42V and 25MHz, with 99.6% accuracy on MNIST dataset. When the length of the TD-MAC chain is truncated by configuration, with a 90% accuracy on MNIST and a 150MHz, the proposed BNN achieves a power-saving of 13.2% and a further energy efficiency increasing of 67.6%.","1558-3791","","10.1109/TCSII.2021.3088857","Natural Science Foundation of Jiangsu Province(grant numbers:BK20200002); National Natural Science Foundation of China(grant numbers:62074035,61774038); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9453709","Adaptive voltage scaling;analog delay line;binary neural network;error resilience;time domain","Engines;Neural networks;Energy efficiency;Convolution;Delays;Hardware;Time-domain analysis","","4","","10","IEEE","14 Jun 2021","","","IEEE","IEEE Journals"
"Distributed Optical Fiber Sensing System for Large Infrastructure Temperature Monitoring","Y. Wang; H. Yao; J. Wang; X. Xin","School of Electronic Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; School of Electronic Engineering, Beijing University of Posts and Telecommunications, Beijing, China","IEEE Internet of Things Journal","21 Feb 2022","2022","9","5","3333","3345","In this article, a distributed optical fiber sensing system for large infrastructure temperature monitoring is proposed. To meet the requirements of monitoring networks in terms of measurement accuracy, spatial resolution, and real-time or quasireal-time performance, a quaternion wavelet transform (QWT) image denoising algorithm is proposed to address the original edge node data for the structural monitoring networks of large infrastructures. A distributed Brillouin optical time-domain analysis (BOTDA) sensing system with a 40-km sensing fiber is established. The raw Brillouin gain spectrum (BGS) image is decomposed into one magnitude image and three phase images by QWT. The phase images of the OWT are distributed randomly and disorderly with respect to the noise, while the magnitude image of the quaternion wavelet is greatly affected by the noise. The useful message energy of the magnitude image is concentrated on a small number of coefficients with large amplitude, while the noise mainly corresponds to the coefficients with smaller amplitude. Then, the Bayes shrink threshold method is introduced to filter out noise in the magnitude image. The results indicate that the signal-to-noise ratio (SNR) and the frequency uncertainty have been improved significantly. The accuracy of the retrieved Brillouin frequency shift from denoised BGS images reaches 0.2 MHz, which corresponds to a temperature error of ±0.1 °C. Less than 4 s are required to process a BGS image with 50  $\times $  40 000 pixels by the QWT denoising technique. The uploaded data obtained from 40 M bytes of raw data are reduced to 0.08 M bytes for each measurement. We hope that with technological progress and algorithm optimization, the distributed optical fiber sensing system based on the QWT image denoising algorithm will have an important role in the real-time application of large-scale infrastructure structural health monitoring for the Internet of Things.","2327-4662","","10.1109/JIOT.2021.3098021","National Key Research and Development Program of China(grant numbers:2018YFB1801200); National Natural Science Foundation of China(grant numbers:62075014,61675030); Young Elite Scientist Sponsorship Program by CAST(grant numbers:2020QNRC001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9490339","Brillouin optical time-domain analysis;distributed optical fiber sensing network;quaternion wavelet transform (QWT);structural monitoring for large infrastructure","Monitoring;Noise reduction;Spatial resolution;Sensors;Optical imaging;Image denoising;Temperature sensors","","6","","21","IEEE","19 Jul 2021","","","IEEE","IEEE Journals"
"Spatial Positioning Token (SPToken) for Smart Mobility","R. Overko; R. Ordóñez-Hurtado; S. Zhuk; P. Ferraro; A. Cullen; R. Shorten","Engineering and Materials Science Centre, School of Electrical and Electronic Engineering, University College Dublin, Dublin 4, Ireland; IBM Research, Dublin 15, Ireland; IBM Research, Dublin 15, Ireland; Dyson School of Design Engineering, Imperial College London at South Kensington, London, U.K.; Dyson School of Design Engineering, Imperial College London at South Kensington, London, U.K.; Dyson School of Design Engineering, Imperial College London at South Kensington, London, U.K.","IEEE Transactions on Intelligent Transportation Systems","2 Feb 2022","2022","23","2","1529","1542","We introduce a permissioned distributed ledger technology (DLT) design for crowdsourced smart mobility applications. This architecture is based on a directed acyclic graph architecture (similar to the IOTA tangle) and uses both Proof-of-Work and Proof-of-Position mechanisms to provide protection against spam attacks and malevolent actors. In addition to enabling individuals to retain ownership of their data and to monetize it, the architecture is also suitable for distributed privacy-preserving machine learning algorithms, is lightweight, and can be implemented in simple internet-of-things (IoT) devices. To demonstrate its efficacy, we apply this framework to reinforcement learning settings where a third party is interested in acquiring information from agents. In particular, one may be interested in sampling an unknown vehicular traffic flow in a city, using a DLT-type architecture and without perturbing the density, with the idea of realizing a set of virtual tokens as surrogates of real vehicles to explore geographical areas of interest. These tokens, whose authenticated position determines write access to the ledger, are thus used to emulate the probing actions of commanded (real) vehicles on a given planned route by “jumping” from a passing-by vehicle to another to complete the planned trajectory. Consequently, the environment stays unaffected (i.e., the autonomy of participating vehicles is not influenced by the algorithm), regardless of the number of emitted tokens. The design of such a DLT architecture is presented, and numerical results from large-scale simulations are provided to validate the proposed approach.","1558-0016","","10.1109/TITS.2020.3029537","Science Foundation Ireland (SFI)(grant numbers:16/IA/4610); IOTA Foundation, and it has been carried out using the Research IT Sonic Cluster which was funded by UCD IT Services and the Research Office; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9238413","Smart mobility;distributed ledger technology;reinforcement learning;multi-agent learning;data management;recommender systems","Distributed ledger;Distributed databases;Computer architecture;Recommender systems;Reinforcement learning;Smart cities","","1","","59","IEEE","23 Oct 2020","","","IEEE","IEEE Journals"
"Rapid Detection of Multi-QR Codes Based on Multistage Stepwise Discrimination and a Compressed MobileNet","R. Chen; H. Huang; Y. Yu; J. Ren; P. Wang; H. Zhao; X. Lu","School of Computer Science, Guangdong Polytechnic Normal University, Guangzhou, China; School of Computer Science, Guangdong Polytechnic Normal University, Guangzhou, China; School of Computer Science, Guangdong Polytechnic Normal University, Guangzhou, China; School of Computer Science, Guangdong Polytechnic Normal University, Guangzhou, China; School of Computer Science, Guangdong Polytechnic Normal University, Guangzhou, China; School of Computer Science, Guangdong Polytechnic Normal University, Guangzhou, China; School of Computer Science, Guangdong Polytechnic Normal University, Guangzhou, China","IEEE Internet of Things Journal","6 Sep 2023","2023","10","18","15966","15979","Poor real-time performance in multi-QR codes detection has been a bottleneck in QR code decoding-based Internet of Things (IoT) systems. To tackle this issue, we propose in this article a rapid detection approach, which consists of multistage stepwise discrimination (MSD) and a Compressed MobileNet. Inspired by the object category determination analysis, the preprocessed QR codes are extracted accurately on a small scale using the MSD. Guided by the small scale of the image and the end-to-end detection model, we obtain a lightweight Compressed MobileNet in a deep weight compression manner to realize rapid inference of multi-QR codes. The average detection precision (ADP), multiple box rate (MBR) and running time are used for quantitative evaluation of the efficacy and efficiency. Compared with a few state-of-the-art methods, our approach has higher detection performance in rapid and accurate extraction of all the QR codes. The approach is conducive to embedded implementation in edge devices along with a bit of overhead computation to further benefit a wide range of real-time IoT applications.","2327-4662","","10.1109/JIOT.2023.3268636","National Natural Science Foundation of China(grant numbers:62072122,62176067); Special Projects in Key Fields of Ordinary Universities of Guangdong Province(grant numbers:2021ZDZX1087); Guangzhou Science and Technology Plan Project(grant numbers:2023B03J1327,202102020857); Research Projects of Guangdong Polytechnic Normal University (GPNU)(grant numbers:22GPNUZDJS17); Special Project Enterprise Sci-Tech Commissioner of Guangdong Province(grant numbers:GDKTP2021033100); Key Discipline Improvement Project of Guangdong Province(grant numbers:2022ZDJS015); GPNU Dazhi Scholarship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10106117","Embedded edge devices;Internet of Things (IoT);MobileNet;multi-QR codes;rapid detection","QR codes;Codes;Internet of Things;Image edge detection;Task analysis;Image coding;Terminology","","13","","53","IEEE","20 Apr 2023","","","IEEE","IEEE Journals"
"Development of a Wi-Fi based car gate remote control and supervision system","E. Alihodzic; E. Sokic","Faculty of Electrical engineering, University of Sarajevo, Sarajevo, Bosnia and Herzegovina; Faculty of Electrical engineering, University of Sarajevo, Sarajevo, Bosnia and Herzegovina","2020 28th Telecommunications Forum (TELFOR)","11 Jan 2021","2020","","","1","4","Car gates can be found in many private and business facilities. Typically, gates are controlled by commercially available electronic systems that allow users to remotely operate them. Most of those systems are based on robust RF 315/433MHz transmitters for remote control. These communication modules suffer from limited range and allow the user to establish only simplex communication. Today, with the rapid growth of the Internet of Things, not only that every driver has an Internet-enabled smartphone, but most modern cars are equipped with such systems as well. This paper proposes a prototype of an electronic gate control structure that allows users, in addition to the common gate-panel and an RF-based remote, to control and supervise the gate using an Internet connection (e.g. with a smartphone). Both hardware and software parts that are required to operate the gate are designed, developed, and presented in this paper. Experimental tests on the small-scale model are conducted to point out the device's advantages and disadvantages and propose guidelines for future work and development.","","978-1-6654-0499-0","10.1109/TELFOR51502.2020.9306607","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9306607","Gate control;Internet of Things;ESP32;electronics","Logic gates;Sensors;Radio frequency;DC motors;Control systems;Protocols;Prototypes","","1","","8","IEEE","11 Jan 2021","","","IEEE","IEEE Conferences"
"AgriTech: Data Acquisition in Agriculture","N. Sharma; N. Sharma; P. Verma; R. Sharma","Dept. of ECE, MAIT) GGSIPU, Delhi, India; Dept. of ECE, MAIT MAIT (GGSIPU), Delhi, India; Dept. of ECE, MAIT MAIT (GGSIPU), Delhi, India; Dept. of MAIT) MAIT (GGSIPU), Delhi, India","2021 International Conference on Industrial Electronics Research and Applications (ICIERA)","10 Mar 2022","2021","","","1","6","Internet of Things enabled embedded system have revolutionised the agriculture sector in the past few decades. Agriculture and technology have converged to connect numerous small-scale devices via various communication protocols. By 2025, the size of the smart agriculture market is predicted to quadruple. The main challenge in the horticulture/agriculture sector is the manual collection of sensory data. This human data gathering is replaced in this study by an automatic data collecting system, which then sends the raw data to a cloud-based mobile app. The research utilizes the Blynk mobile application for fast and seamless data acquisition, and reduces the complexities involved in developing and programming a personalised webserver. This research is successful in developing a portable embedded system that is extremely efficient as it can transmit raw sensory data in real-time. As part of the research, a technological case study with a potted plant was carried out, which was used to obtain real-time data points.","","978-1-6654-3542-0","10.1109/ICIERA53202.2021.9726754","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9726754","Internet of Things;Arduino;Blynk;UART","Cloud computing;Embedded systems;Protocols;Data acquisition;Manuals;Real-time systems;Web servers","","","","17","IEEE","10 Mar 2022","","","IEEE","IEEE Conferences"
"Comprex: In-Network Compression for Accelerating IoT Analytics at Scale","R. Oliveira; A. Gavrilovska","Georgia Institute of Technology, US; Georgia Institute of Technology, US","IEEE Micro","","2023","PP","99","1","10","To enable the Internet of Things (IoT) to scale at the level of next-generation smart cities and grids, there is a need for a cost-effective infrastructure for hosting IoT analytics applications. Offload and acceleration via smartNICs have been shown to provide benefits to these workloads. However, even with offload, long-term analysis on IoT data still needs to operate on a massive number of device updates, often in the form of small messages. Despite offloading, the ingestion of these updates continues to present server bottlenecks. In this paper, we present domain-specific compression and batching engines that leverage the unique properties of IoT messages to reduce the load on analytics servers and improve their scalability. Using a prototype system based on InnovaFlex programmable smartNICs and several representative IoT benchmarks, we demonstrate that these techniques achieve up to 7× improvement over existing offload approaches.","1937-4143","","10.1109/MM.2023.3343498","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10360868","","Internet of Things;Kernel;Engines;Servers;Throughput;Scalability;Runtime","","","","","IEEE","15 Dec 2023","","","IEEE","IEEE Early Access Articles"
"Optimization of Application Deployment Delay with Efficient Task Scheduling in Cloud-Based Smart Home Platform","J. Rajkumar; C. Pham; K. K. Nguyen; M. Cheriet","Synchromedia - École de Technologie Supérieure, University of Québec, Canada; Synchromedia - École de Technologie Supérieure, University of Québec, Canada; Synchromedia - École de Technologie Supérieure, University of Québec, Canada; Synchromedia - École de Technologie Supérieure, University of Québec, Canada","2020 Zooming Innovation in Consumer Technologies Conference (ZINC)","7 Aug 2020","2020","","","67","72","Smart home platform is an incarnation of Internet of Things (IoT) system. In such a platform, home applications are deployed using Software as a Service (SaaS) deployment model, a new way of software service provisioning for quick application deployment. However, this deployment model still has deployment performance issues due to the high degree of coordination and mutual dependencies of distributed services built on heterogeneous technologies. In a large scale deployment setup with more number of services, inter and intra-communication links between the coordinated services increase thereby introducing execution delays at service computation, and inter-service communications. Therefore, in this paper, we propose a smart home platform architecture based on Platform as a Service (PaaS) model supporting the SaaS deployment model. Based on the designed architecture, we model an optimization problem named as optimized IoT Application Deployment (OIAD) to minimize application deployment time (total execution time). To solve the OIAD problem, this paper proposes a heuristic algorithm to find a near-optimal deployment time. The results of our simulation show an improvement in comparison with FCFS (First Come First Serve) and Random execution algorithm under various deployment scenarios and strategies.","","978-1-7281-8259-9","10.1109/ZINC50678.2020.9161796","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9161796","","Task analysis;Cloud computing;Smart homes;Computational modeling;Delays;Software as a service;Computer architecture","","1","","12","IEEE","7 Aug 2020","","","IEEE","IEEE Conferences"
"An Incremental Boolean Tensor Factorization for Knowledge Reasoning in Artificial Intelligence of Things","J. Yang; L. T. Yang; Y. Gao; H. Liu; X. Xie","Huazhong University of Science and Technology, Wuhan, China; Huazhong University of Science and Technology, Wuhan, China; Huazhong University of Science and Technology, Wuhan, China; Hainan University, Haikou, China; Hainan University, Haikou, China","IEEE Transactions on Industrial Informatics","3 Feb 2022","2022","18","5","3367","3376","Human-oriented and machine-generated data in cyber-physical-social systems are often complicated graph-structured. Graph-powered learning methods are conducive to discovering valuable knowledge from large-scale graph data and improving decision-making processes. However, due to the neglect of diverse relations among things, most existing knowledge reasoning studies are inherently flawed and inefficient in processing the heterogeneous graphs with high-order connectivity. Tensor, as a powerful and effective tool to model high-level semantic interactions between various things, can provide high-order Internet of things graph with new perspectives and possibilities. Therefore, this article innovatively proposes a collaborative artificial intelligence of things data analysis and application framework based on Boolean tensors, which supports the expression and fusion of heterogeneous graph and ultimately promotes the AI processing. In this context, we focus on developing an incremental Boolean tensor factorization (IBTF) approach for efficient knowledge reasoning to meet the requirements of real-time and high-level quality demands for intelligent services. To the best of our knowledge, we are the first to do this work. More concretely, we present factors update and binary features merge algorithms for the integrated graph tensors to avoid numerous repeated calculations of historical data. Experimental results on general synthetic datasets demonstrate that the IBTF approach proposed in this article guarantees nearly equal approximate accuracy while reducing execution time by dozens and even more of times. Furthermore, experimental evaluations and interpretability analysis on real-world datasets verify the practicality of the proposed framework and approach.","1941-0050","","10.1109/TII.2021.3100978","National Key Research and Development Program of China(grant numbers:2019YFB1705903); National Natural Science Foundation of China(grant numbers:61932010,61867002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9507085","Artificial intelligence of things (AIoT);Boolean tensor factorization;cyber-physical-social systems (CPSS);knowledge reasoning and discovery;tensor","Tensors;Cognition;Informatics;Artificial intelligence;Task analysis;Matrix decomposition;Indexes","","6","","34","IEEE","4 Aug 2021","","","IEEE","IEEE Journals"
"Cell-Free Satellite-UAV Networks for 6G Wide-Area Internet of Things","C. Liu; W. Feng; Y. Chen; C. -X. Wang; N. Ge","Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, China; Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, China; School of Engineering, University of Warwick, Coventry, U.K.; National Mobile Communications Research Laboratory, School of Information Science and Engineering, Southeast University, Nanjing, China; Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, China","IEEE Journal on Selected Areas in Communications","16 Mar 2021","2021","39","4","1116","1131","In fifth generation (5G) and beyond Internet of Things (IoT), it becomes increasingly important to serve a massive number of IoT devices outside the coverage of terrestrial cellular networks. Due to their own limitations, unmanned aerial vehicles (UAVs) and satellites need to coordinate with each other in the coverage holes of 5G, leading to a cognitive satellite-UAV network (CSUN). In this paper, we investigate multi-domain resource allocation for CSUNs consisting of a satellite and a swarm of UAVs, so as to improve the efficiency of massive access in wide areas. Particularly, the cell-free on-demand coverage is established to overcome the cost-ineffectiveness of conventional cellular architecture. Opportunistic spectrum sharing is also implemented to cope with the spectrum scarcity problem. To this end, a process-oriented optimization framework is proposed for jointly allocating subchannels, transmit power and hovering times, which considers the whole flight process of UAVs and uses only the slowly-varying large-scale channel state information (CSI). Under the on-board energy constraints of UAVs and interference temperature constraints from UAV swarm to satellite users, we present iterative multi-domain resource allocation algorithms to improve network efficiency with guaranteed user fairness. Simulation results demonstrate the superiority of the proposed algorithms. Moreover, the adaptive cell-free coverage pattern is observed, which implies a promising way to efficiently serve wide-area IoT devices in the upcoming sixth generation (6G) era.","1558-0008","","10.1109/JSAC.2020.3018837","National Key Research and Development Program of China(grant numbers:2018YFA0701601); National Natural Science Foundation of China(grant numbers:61922049,61771286,61941104,61960206006,61701457,91638205); Frontiers Science Center for Mobile Information Communication and Security; High Level Innovation and Entrepreneurial Research Team Program in Jiangsu; High Level Innovation and Entrepreneurial Talent Introduction Program in Jiangsu; Research Fund of National Mobile Communications Research Laboratory, Southeast University(grant numbers:2020B01); Fundamental Research Funds for the Central Universities(grant numbers:2242020R30001); Huawei Cooperation Project; EU H2020 RISE TESTBED2 project(grant numbers:872172); Nantong Technology Program(grant numbers:JC2019115); Beijing Innovation Center for Future Chip; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9174846","Cell free;cognitive satellite-UAV network;multi-domain resource allocation;wide-area Internet of Things","Satellites;Interference;Optimization;Resource management;Internet of Things;5G mobile communication;Satellite broadcasting","","108","","42","IEEE","24 Aug 2020","","","IEEE","IEEE Journals"
"COSMOS: An Orchestration Framework for Smart Computation Offloading in Edge Clouds","G. Papathanail; I. Fotoglou; C. Demertzis; A. Pentelas; K. Sgouromitis; P. Papadimitriou; D. Spatharakis; I. Dimolitsas; D. Dechouniotis; S. Papavassiliou","University of Macedonia, Greece; University of Macedonia, Greece; University of Macedonia, Greece; University of Macedonia, Greece; University of Macedonia, Greece; University of Macedonia, Greece; National Technical University of Athens, Greece; National Technical University of Athens, Greece; National Technical University of Athens, Greece; National Technical University of Athens, Greece","NOMS 2020 - 2020 IEEE/IFIP Network Operations and Management Symposium","8 Jun 2020","2020","","","1","6","The evolution of Internet of Things (IoT) has sparked significant research interest in edge computing. Within this scope and given the ever-increasing number of IoT and mobile devices, computation offloading is emerging as a cutting-edge and significant research area with enormous potential and practical applications.In this respect, we present the architecture design and experimental evaluation of an orchestration framework for smart computation offloading from IoT or mobile devices to edge cloud servers. The proposed orchestration platform, namely COSMOS, includes control-plane components for workload prediction, load balancing, and admission control. COSMOS is particularly tailored to the needs of an object identification service that receives images from a multitude of Points of Interest (PoIs), performs object identification using a trained model (based on Tensorflow), calculates the prediction accuracy, and finally returns to the end-users the identification outcome and accuracy along with useful information about the identified object. COSMOS has been deployed and evaluated in a large-scale experimental facility that employs OpenStack and OpenSourceMANO (OSM) for Network Function Virtualization (NFV) orchestration. Our experimental results indicate the feasibility of computation offloading for this object identification service and further uncover useful insights in terms of performance and scalability.","2374-9709","978-1-7281-4973-8","10.1109/NOMS47738.2020.9110294","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9110294","","Performance evaluation;Cloud computing;Scalability;Predictive models;Mobile handsets;Network function virtualization;Object recognition","","7","","25","IEEE","8 Jun 2020","","","IEEE","IEEE Conferences"
"Cloud and Edge","H. Raad",NA,"Fundamentals of IoT and Wearable Technology Design","","2021","","","139","155","By minimizing the need for on‐premises infrastructure, the cloud has enabled businesses to go beyond the conventional applications of Internet of Things (IoT) and wearable devices and accelerated the large‐scale deployment of these technologies. This chapter provides an overview of cloud topologies and platforms, and an architectural synopsis of OpenStack cloud. Next, it presents Edge topologies and computing technologies. The chapter shows that the maximum value from an IoT or wearable technology project can only be gained from an optimal combination of cloud and edge computing, and not by a cloud‐only architecture. Selecting the cloud service models and frameworks, fog topology, and analytics modules is an important task where much literature dives deep into the minute details of creating and deploying them. The most useful feature of machine learning in IoT and wearable technology is that it can detect outliers and abnormal activities and trigger necessary actions accordingly.","","9781119617549","10.1002/9781119617570.ch7","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9296515.pdf&bkn=9296419&pdfType=chapter","","Cloud computing;Software;Organizations;Computational modeling;Wearable computers;Security;Servers","","","","","","16 Dec 2020","","","IEEE","Wiley-IEEE Press eBook Chapters"
"A Cloud-edge Cooperative Dispatching Method for Distribution Networks Considering Photovoltaic Generation Uncertainty","L. Shen; X. Dou; H. Long; C. Li; J. Zhou; K. Chen","School of Electrical Engineering, Southeast University, Nanjing, China; School of Electrical Engineering, Southeast University, Nanjing, China; School of Electrical Engineering, Southeast University, Nanjing, China; State Grid National Electric Power Dispatching and Communication Center, Nanjing, China; State Grid National Electric Power Dispatching and Communication Center, Nanjing, China; State Grid Suzhou Power Supply Company, Suzhou, China","Journal of Modern Power Systems and Clean Energy","24 Sep 2021","2021","9","5","1111","1120","With the increasing penetration of renewable energy generation, uncertainty and randomness pose great challenges for optimal dispatching in distribution networks. We propose a cloud-edge cooperative dispatching (CECD) method to exploit the new opportunities offered by Internet of Things (IoT) technology. To alleviate the huge pressure on the modeling and computing of large-scale distribution system, the method deploys edge nodes in small-scale transformer areas in which robust optimization subproblem models are introduced to address the photovoltaic (PV) uncertainty. Considering the limited communication and computing capabilities of the edge nodes, the cloud center in the distribution automation system (DAS) establishes a utility grid master problem model that enforces the consistency between the solution at each edge node with the utility grid based on the alternating direction method of multipliers (AD-MM). Furthermore, the voltage constraint derived from the linear power flow equations is adopted for enhancing the operation security of the distribution network. We perform a cloud-edge system simulation of the proposed CECD method and demonstrate a dispatching application. The case study is carried out on a modified 33-node system to verify the remarkable performance of the proposed model and method.","2196-5420","","10.35833/MPCE.2019.000582","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9290330","Cloud-edge cooperative dispatching method;transformer areas;uncertainty;alternating direction method of multipliers (ADMM)","Mathematical model;Dispatching;Uncertainty;Computational modeling;Security;Distribution networks;Optimization","","8","","45","","10 Dec 2020","","","SGEPRI","SGEPRI Journals"
"Massive MIMO Two-Way Relaying Systems With SWIPT in IoT Networks","J. Wang; G. Wang; B. Li; H. Yang; Y. Hu; A. Schmeink","Communication Research Center, Harbin Institute of Technology, Harbin, China; Communication Research Center, Harbin Institute of Technology, Harbin, China; Communication Research Center, Harbin Institute of Technology, Harbin, China; Communication Research Center, Harbin Institute of Technology, Harbin, China; School of Electronic Information, Wuhan University, Wuhan, China; ISEK Research Group, RWTH Aachen University, Aachen, Germany","IEEE Internet of Things Journal","6 Oct 2021","2021","8","20","15126","15139","In sixth-generation (6G) communication networks, ultrahigh-data rate and reliability are greatly vital for massive user connections and network sensors, such as Internet of Things (IoT) devices. Simultaneous wireless information and power transfer (SWIPT) has been evolved as an efficient strategy to enhance the reliability of wireless communication systems through prolonging the battery lifetime by harvesting energy from the received radio-frequency (RF) signals. Furthermore, cooperative relay sensors in IoT networks can extend the network coverage. In this article, we consider a massive multiple-input–multiple-output (MIMO) two-way relaying system, where the relay node splits the received RF signals into two power streams, one for information decoding (ID) and the other for energy harvesting (EH). Two classical and linear relay precodings, i.e., zero-forcing reception/zero-forcing transmission (ZFR/ZFT) and maximum-ratio combining/maximum-ratio transmission (MRC/MRT), are adopted to satisfy the requirements of high rate in this relay system. Different from prior work, the SWIPT technique and large-scale fading effects of MIMO channels are taken into account for deriving the asymptotic sum-rates of four prevalent power scaling cases when the number of relay antennas grows to infinity. Finally, the analytical results are evaluated by the presented simulation and numerical results.","2327-4662","","10.1109/JIOT.2020.3032446","National Natural Science Funding of China(grant numbers:61671184,61901137); Deutsche Forschungsgemeinschaft(grant numbers:SCHM 2643/16); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9233408","Massive multiple-input–multiple-output (MIMO);maximum-ratio combining/maximum-ratio transmission (MRC/MRT);Simultaneous wireless information and power transfer (SWIPT);two-way relaying;zero-forcing reception/zero-forcing transmission (ZFR/ZFT)","Relays;Massive MIMO;Internet of Things;Antennas;Wireless communication;Fading channels","","23","","37","IEEE","20 Oct 2020","","","IEEE","IEEE Journals"
"SMPC-Based Federated Learning for 6G-Enabled Internet of Medical Things","A. P. Kalapaaking; V. Stephanie; I. Khalil; M. Atiquzzaman; X. Yi; M. Almashor","RMIT University, Australia; RMIT University, Australia; RMIT University, Australia; University of Oklahoma, USA; RMIT University, Australia; CSIRO's Data61 and Cyber Security Cooperative Research Centre","IEEE Network","14 Oct 2022","2022","36","4","182","189","Rapidly developing intelligent healthcare systems are underpinned by sixth generation (6G) connectivity, the ubiquitous Internet of Things, and deep learning (DL) techniques. This portends a future where 6G powers the Internet of Medical Things (loMT) with seamless, large-scale, and real-time connectivity among entities. This article proposes a convolutional neural network (CNN)-based federated learning framework that combines secure multi-party computation (SMPC) based aggregation and Encrypted Inference methods, all within the context of 6G and 1oMT. We consider multiple hospitals with clusters of mixed 1oMT and edge devices that encrypt locally trained models. Subsequently, each hospital sends the encrypted local models for SMPC-based encrypted aggregation in the cloud, which generates the encrypted global model. Ultimately, the encrypted global model is returned to each edge server for more localized training, further improving model accuracy. Moreover, hospitals can perform encrypted inference on their edge servers or the cloud while maintaining data and model privacy. Multiple experiments were conducted with varying CNN models and datasets to evaluate the proposed framework's performance.","1558-156X","","10.1109/MNET.007.2100717","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9919758","","6G mobile communication;Performance evaluation;Cloud computing;Hospitals;Federated learning;Computational modeling;Internet of Medical Things;Telecommunication network performance;Telecommunication network reliability;Quality of service","","5","","15","IEEE","14 Oct 2022","","","IEEE","IEEE Magazines"
"A Machine Learning Framework for Sleeping Cell Detection in a Smart-City IoT Telecommunications Infrastructure","O. G. Manzanilla-Salazar; F. Malandra; H. Mellah; C. Wetté; B. Sansò","Polytechnique Montréal, Montreal, Canada; Department of Electrical Engineering, University at Buffalo, Buffalo, USA; Polytechnique Montréal, Montreal, Canada; Ericsson, Stockholm, Sweden; Polytechnique Montréal, Montreal, Canada","IEEE Access","8 Apr 2020","2020","8","","61213","61225","The smooth operation of largely deployed Internet of Things (IoT) applications will depend on, among other things, effective infrastructure failure detection. Access failures in wireless network Base Stations (BSs) produce a phenomenon called “sleeping cells”, which can render a cell catatonic without triggering any alarms or provoking immediate effects on cell performance, making them difficult to discover. To detect this kind of failure, we propose a Machine Learning (ML) framework based on the use of Key Performance Indicators (KPIs) statistics from the BS under study, as well as those of the neighboring BSs with propensity to have their performance affected by the failure. A simple way to define neighbors is to use adjacency in Voronoi diagrams. In this paper, we propose a much more realistic approach based on the nature of radio-propagation and the way devices choose the BS to which they send access requests. We gather data from large-scale simulators that use real location data for BSs and IoT devices and pose the detection problem as a supervised binary classification problem. We measure the effects on the detection performance by the size of time aggregations of the data, the level of traffic and the parameters of the neighborhood definition. The Extra Trees and Naive Bayes classifiers achieve Receiver Operating Characteristic (ROC) Area Under the Curve (AUC) scores of 0.996 and 0.993, respectively, with False Positive Rates (FPRs) under 5%. The proposed framework holds potential for other pattern recognition tasks in smart-city wireless infrastructures, that would enable the monitoring, prediction and improvement of the Quality of Service (QoS) experienced by IoT applications.","2169-3536","","10.1109/ACCESS.2020.2983383","NSERC and Ericsson(grant numbers:CRDPJ 520642); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9046847","Failure detection;IoT;M2M communications;machine learning;sleeping cells;smart cities;wireless networks","Internet of Things;Telecommunications;Computer architecture;Microprocessors;Smart cities;Cellular networks","","8","","33","CCBY","25 Mar 2020","","","IEEE","IEEE Journals"
"Secure Distributed Data Management for Fog Computing in Large-Scale IoT Application: A Blockchain-Based Solution","Z. Chen; H. Cui; E. Wu; Y. Li; Y. Xi","State Key Lab. of Networking and Switching Technology, Beijing University of Posts and Telecommunications, China; State Key Lab. of Networking and Switching Technology, Beijing University of Posts and Telecommunications, China; State Key Lab. of Networking and Switching Technology, Beijing University of Posts and Telecommunications, China; State Key Lab. of Networking and Switching Technology, Beijing University of Posts and Telecommunications, China; State Key Lab. of Networking and Switching Technology, Beijing University of Posts and Telecommunications, China","2020 IEEE International Conference on Communications Workshops (ICC Workshops)","21 Jul 2020","2020","","","1","6","Fog computing, a novel computing paradigm, migrates cloud computing to the edge of network and consequently decrease the overhead of process and movement of the large-scale big data. Fog computing is promising to lower communication delay and offload network traffic with the scale of big data increasing in large-scale IoT application, which brings micro-data centers to the network edge, enabling the network edge to perceive, process, storage and calculate the massive data, reducing the amount of transferred data. However, numerous fog nodes at the network edge face an external attack resulting in serious security threats arising from the trusting relationship vulnerability because of the lack of the consideration of the properties of the fog computing system. This paper addresses the design for developing secure distributed data management platform for fog computing in large-scale IoT application, along with a blockchain-based data management implementation of the platform, which approaches the major challenges: how to realize the integration of data security and storage management for fog computing in large-scale IoT application and enrich rational interoperability for interconnected things. Experimental results show that the system works well to empower data provenance and transparency and defend against unauthorized access effectively in fog computing, scales well with loss of the performance of communication and computing maintaining in acceptable range, verifying the efficiency and feasibility of our design to provide privacy, integrity and fine-grained data management for fog computing in large-scale IoT application by introducing the data management platform based upon the blockchain network and smart contracts therein.","2474-9133","978-1-7281-7440-2","10.1109/ICCWorkshops49005.2020.9145381","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9145381","Secure Data Management;Blockchain;IoT Application;Fog Computing","Distributed databases;Edge computing;Authorization;Authentication","","5","","15","IEEE","21 Jul 2020","","","IEEE","IEEE Conferences"
"Flying IRS: QoE-Driven Trajectory Optimization and Resource Allocation Based on Adaptive Deployment for WPCNs in 6G IoT","Y. Zhou; Z. Jin; H. Shi; L. Shi; N. Lu","School of Artificial Intelligence, Henan University, Zhengzhou, China; School of Artificial Intelligence, Henan University, Zhengzhou, China; School of Artificial Intelligence and the Henan Engineering Research Center for Industrial Internet of Things, Henan University, Zhengzhou, China; School of Artificial Intelligence, Henan University, Zhengzhou, China; Department of Electrical and Computer Engineering, Queen’s University, Kingston, Canada","IEEE Internet of Things Journal","21 Feb 2024","2024","11","5","9031","9046","6G Internet of Things (IoT) is envisioned to provide large-scale network connections and high data transmission rates to satisfy the diverse needs of IoT nodes. The wireless powered communication network (WPCN) is the essential part of the future 6G IoT, which can provide nodes with reliable and efficient data and energy transmission. In complex environments, wireless power transmissions are inefficient due to transmission distance and obstacles. To address these concerns, we propose a novel quality of experience (QoE)-driven framework for aerial intelligent reflective surface (IRS)-assisted WPCN, which exploits the maneuverability of unmanned aerial vehicle (UAV) to improve the network performance. In the framework, we construct a nonlinear satisfaction function to quantify the QoE and design an adaptive reflective units configuration scheme based on the QoE to reduce resource consumption (e.g., energy) while satisfying the QoE requirements. The optimization problem of maximizing average throughput is formulated by jointly optimizing the aerial IRS flight trajectory, node association variable, time slot allocation ratio, and IRS phase. The existence of coupling between optimization variables and the nonconvexity lead to the difficulty of solving the optimization problem directly. To effectively solve the above optimization problem, the block coordinate descent (BCD) algorithm is utilized to decompose the optimization problem into four subproblems to be solved separately. Simulation results demonstrate that the proposed scheme can significantly enhance the throughput compared with other schemes.","2327-4662","","10.1109/JIOT.2023.3322266","National Natural Science Foundation of China(grant numbers:62176088,62303159); Young Elite Scientist Sponsorship Program by Henan Association for Science and Technology(grant numbers:2022HYTP013); Program for Science and Technology Development of Henan Province(grant numbers:222102210022); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10272692","Intelligent reflective surface (IRS);resource allocation;trajectory optimization;unmanned aerial vehicle (UAV);wireless powered communication network (WPCN)","Quality of experience;Throughput;Resource management;Autonomous aerial vehicles;Wireless communication;Relays;Internet of Things","","","","57","IEEE","5 Oct 2023","","","IEEE","IEEE Journals"
"A Hybrid Service Selection and Composition Model for Cloud-Edge Computing in the Internet of Things","M. Hosseinzadeh; Q. T. Tho; S. Ali; A. M. Rahmani; A. Souri; M. Norouzi; B. Huynh","Institute of Research and Development, Duy Tan University, Da Nang, Vietnam; Ho Chi Minh City University of Technology, Vietnam National University, Ho Chi Minh, Vietnam; Department of Information Systems, College of Economics and Political Science, Sultan Qaboos University, Muscat, Oman; Department of Computer Science, Khazar University, Baku, Azerbaijan; Department of Computer Engineering, Islamshahr Branch, Islamic Azad University, Islamshahr, Iran; Young Researchers and Elite Club, Islamshahr Branch, Islamic Azad University, Islamshahr, Iran; Faculty of Information Technology, Ho Chi Minh City University of Technology (HUTECH), Ho Chi Minh, Vietnam","IEEE Access","18 May 2020","2020","8","","85939","85949","Cloud-edge computing is a hybrid model of computing where resources and services provided via the Internet of Things (IoT) between large-scale and long-term data informs of the cloud layer and small-scale and short-term data as edge layer. The main challenge of the cloud service providers is to select the optimal candidate services that are doing the same work but offer different Quality of Service (QoS) values in IoT applications. Service composition in cloud-edge computing is an NP-hard problem; therefore, many meta-heuristic methods introduced to solve this issue. Also, the correctness of meta-heuristic and machine learning algorithms for evaluating service composition problem should be proven using formal methods to guarantee functional and non-functional specifications. In this paper, a hybrid Artificial Neural Network-based Particle Swarm Optimization (ANN-PSO) Algorithm presented to enhance the QoS factors in cloud-edge computing. To illustrate the correctness and improve the reachability rate of candidate composited services and QoS factors for the proposed hybrid algorithm, we present a formal verification method based on a labeled transition system to check some critical Linear Temporal Logics (LTL) formulas. The experimental results illustrated the high performance of the proposed model in terms of minimum verification time, memory consumption, and guaranteeing critical specifications rules as the Linear Temporal Logic (LTL) formulas. Also, we observed that the proposed model has optimal response time, availability, and price with maximum fitness function value than other service composition algorithms.","2169-3536","","10.1109/ACCESS.2020.2992262","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9085994","Cloud-edge computing;Internet of Things;service composition;formal verification;quality of service;artificial neural network;particle swarm optimization","Quality of service;Cloud computing;Computational modeling;Measurement;Internet of Things;Unified modeling language;Web services","","39","","41","CCBY","4 May 2020","","","IEEE","IEEE Journals"
"Wafer to wafer bonding to increase memory density","D. B. L. Yolanda","System Plus Consulting, Nantes, France","2022 China Semiconductor Technology International Conference (CSTIC)","23 Aug 2022","2022","","","1","4","Fulfilling huge memory chip demand in strong growth applications like Internet of Things, mobile telephones and datacenters requires memory manufacturers to constantly evolve the manufacturing process of 3D NAND flash memories. Wafer to wafer hybrid bonding has been introduced in new generation memories to overcome scaling limit and eliminating several 3D NAND manufacturing challenges. Wafer to wafer bonding in memories involves joining a NAND array wafer to the logic wafer. The wafer-to-wafer hybrid memory design was introduced to continue Moore's law in the third dimension. Copper metals from the two wafers are joined together to form one component. This hybrid bond between two individual wafers permits the manufacturer to produce denser and smaller dies with high-speed data transfer rate. Benefits of wafer-to-wafer bonding could attract manufacturers to adopt this design to continue miniaturization of NAND memory components. Wafer to wafer hybrid bonded NAND chips is compared to conventional 3D NAND memories to reveal density and cost benefits of the novel design. Relentless advancements in 3D NAND designs, together with the emergence of hybrid architectures have enabled continuous NAND memory bit cost reduction while improving the memory characteristics.","","978-1-6654-9758-9","10.1109/CSTIC55103.2022.9856846","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9856846","NAND;Flash;Non-Volatile Memories (NVM);Wafer;Bonding;Hybrid bonding;Xtacking","Wafer bonding;Semiconductor device modeling;Three-dimensional displays;Costs;Manufacturing processes;Nonvolatile memory;Moore's Law","","1","","6","IEEE","23 Aug 2022","","","IEEE","IEEE Conferences"
"Modeling of IIoT Traffic Processing by Intra-Chip NoC Routers of 5G/6G Networks","D. Kutuzov; A. Osovsky; O. Stukach; D. Starov","Telecommunication Department, Astrakhan State Technical University, Russia; Telecommunication Department, Astrakhan State Technical University, Russia; Higher School of Economics, National Research University, Moscow, Russia; Department of Electrical Engineering, Electronics and Automation, Astrakhan State University, Russia","2021 International Siberian Conference on Control and Communications (SIBCON)","25 May 2021","2021","","","1","5","The concept of 5G/6G networks is widely used to design networks of Internet of Things (IoT) and Industrial IoT (IIoT) devices. The characteristics of IIoT traffic can differ significantly from the characteristics of voice traffic, so models are required to analyze IIoT traffic. In this paper, we examined the features of IIoT traffic: the Gaussian model of WSN networks, ON/OFF, which is used for target tracking sensors, models with heavy tails (Pareto, Weibull, lognormal distribution, etc.), self-similar (fractal) models - based on normalized Fractal Brownian Motion (fBM) and Fractal Gaussian Noise (fGN), as well as the IIoT traffic model. The models are obtained empirically and approximated by known models of probability distributions. We investigated an exponential distribution IIoT traffic model. In addition, we considered the prospects of using switch fabric of NoC technology and came to the conclusion that decentralization of the process of establishing connections in switch fabric has significant advantages: it allows you to flexibly distribute incoming traffic; perform distributed arbitration; flexibly scale the communication system, with a large traffic flow from one of the system inputs, to split it by assigning many different routes for its transmission; improves system reliability by allowing reconfiguration of the switch fabric. We model the processing of traffic from such systems as OBS, 1C web systems, OWM, OSM by parallel switch fabric of NoC technology. We used the previously created simulation model of the NoC 5×5 switching system and simulated the processing of traffic having an exponential distribution with different parameter values and different packet processing times.","2380-6516","978-1-7281-8504-0","10.1109/SIBCON50419.2021.9438874","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9438874","NoC;switching element;parallel switching;switch fabric;IoT;IIoT;5G;6G;traffic modeling","Wireless sensor networks;Target tracking;Switching systems;Exponential distribution;Switches;Sensor phenomena and characterization;Routing","","2","","24","IEEE","25 May 2021","","","IEEE","IEEE Conferences"
"Development of an Electromagnetic Energy Harvesting System Based on a Current Transformer for Use in Industrial Electric Motors","L. Oliveira; P. Chaves; A. Mozena; O. Branquinho; F. Morais; L. Manera","University of Campinas (Unicamp), Campinas, Sao Paulo, Brazil, BR; University of Campinas (Unicamp), Campinas, Sao Paulo, Brazil, BR; Faculty of Science and Engineering, Sao Paulo State University (UNESP), BR; PoB-Tec and the Extension Program School (EXTECAMP) from the University of Campinas, BR; Faculty of Science and Engineering, Sao Paulo State University (UNESP), BR; University of Campinas (Unicamp), Campinas, Sao Paulo, Brazil, BR","IEEE Latin America Transactions","14 Sep 2023","2023","21","9","976","983","Predictive maintenance systems for industrial electric motors are being developed using electronic sensors and wireless communication systems incorporated into ultra-low consumption electronic circuits. If the electronic circuit is ultra-low consumption, a simple low-capacity rechargeable battery can power the system for years. However, the use of batteries on a large scale contributes to environmental pollution. To eliminate the use of batteries, several energy harvesting techniques are being used to make the electronic sensors self-sustaining. In this sense, this paper presents the development of an electromagnetic energy harvesting system based on an off-the-shelf Current Transformer (CT), with the energy management done via Integrated Circuit (IC), for use in an Internet of Things (IoT) vibration monitoring system for industrial electric motors. A process was carried out to maximize energy generation through the design of a resonant frequency tuning capacitor, optimization of the electronic circuit for energy harvesting by adjusting a shunt resistor, and energy management based on the LTC3108 IC. The resulting energy harvesting system could generate a maximum output power of 1.657 mW, representing a percentage difference of +590.42 % of the system load power consumption, it is equivalent to about 6.90 times more than the necessary to make the IoT device energetically autonomous.","1548-0992","","10.1109/TLA.2023.10251803","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10251803","Energy Harvesting;Current Transformer;EMF;Ultra Low-Power","Monitoring;Current transformers;Energy harvesting;Integrated circuits;Vibrations;Internet of Things;Electric motors","","1","","","IEEE","14 Sep 2023","","","IEEE","IEEE Journals"
"LCANet: Lightweight Context-Aware Attention Networks for Earthquake Detection and Phase-Picking on IoT Edge Devices","Y. Zhao; P. Deng; J. Liu; M. Wang; J. Wan","State Key Laboratory of Software Development Environment, School of Computer Science and Engineering, Beihang University, Beijing, China; Research Institute for Frontier Science and State Key Laboratory of Software Development Environment, Beihang University, Beijing, China; State Key Laboratory of Software Development Environment, School of Computer Science and Engineering, Beihang University, Beijing, China; State Key Laboratory of Software Development Environment, School of Computer Science and Engineering, Beihang University, Beijing, China; South China University of Technology, Guangzhou, China","IEEE Systems Journal","25 Aug 2022","2022","16","3","4024","4035","Aftershocks monitoring system is a large-scale Internet of Things (IoT) system. Earthquake signal detection and phase-picking, as the core of aftershocks monitoring system, is time-sensitive. Generally, the data generated by seismic stations are transmitted to the cloud for integration, storage, and processing through the network, contributing to network congestion and affecting the real time of earthquake warning as well as the supported applications. Edge computing, a new paradigm for real-time IoT tasks, has emerged as a trend to address concerns of response time, requirement, saving bandwidth costs, as well as data safety and privacy. Therefore, a neglected problem was tackled in this article. First, to meet the real-time requirement, we proposed a novel lightweight deep learning model called lightweight context-aware attention networks for earthquake signal detection and phase-picking. We optimized the deep learning model and reduced the computation requirements to deal with edge devices that have lower computation power than cloud servers. Second, we deployed the model to the Jetson Nano, a small edge device, to offload computation tasks from cloud servers to edge devices. In this way, seismic stations do not need to send raw data to a centralized server. Third, experiments show that our method is robust and easily generalized to other databases. The entire model is only 3.7 MB and achieves the accuracy-latency trade-off.","1937-9234","","10.1109/JSYST.2021.3114689","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9580753","Arrival time picking;earthquake signal detection;edge computing;lightweight deep learning model;Jetson Nano","Convolution;Earthquakes;Image edge detection;Signal detection;Edge computing;Computational modeling;Task analysis","","3","","36","IEEE","19 Oct 2021","","","IEEE","IEEE Journals"
"Collaborative Learning-Based Industrial IoT API Recommendation for Software-Defined Devices: The Implicit Knowledge Discovery Perspective","H. Gao; X. Qin; R. J. D. Barroso; W. Hussain; Y. Xu; Y. Yin","School of Computer Engineering and Science, Shanghai University, Shanghai, China; School of Computer Science and Technology, Xidian University, Xi’an, China; Faculty of Telecommunication Engineering, University of Valladolid, Valladolid, Spain; Faculty of Engineering and IT, University of Technology Sydney, Sydney, Australia; School of Computer Science and Technology, Xidian University, Xi’an, China; School of Computer Science, Hangzhou Dianzi University, Hangzhou, China","IEEE Transactions on Emerging Topics in Computational Intelligence","21 Jan 2022","2022","6","1","66","76","The industrial Internet of things (IIoT), a new computing mode in Industry 4.0, is deployed to connect IoT devices and use communication technology to respond to control commands and handle industrial data. IIoT is typically employed to improve the efficiency of computing and sensing and can be used in many scenarios, such as intelligent manufacturing and video surveillance. To build an IIoT system, we need a collection of software to manage and monitor each system component when there are large-scale devices. Application programming interface (API) is an effective way to invoke public services provided by different platforms. Developers can invoke different APIs to operate IoT devices without knowing the implementation process. We can design a workflow to configure how and when to invoke target APIs. Thus, APIs are a powerful tool for rapidly developing industrial systems. However, the increasing number of APIs exacerbates the problem of finding suitable APIs. Current related recommendation methods have defects. For example, most existing methods focus on the relation between users and APIs but neglect the valuable relations among the users or APIs themselves. To address these problems, this article studies implicit knowledge in IIoT by using collaborative learning techniques. Considering the increased dimensions and dynamics of IoT devices, we explore the possible relationships between users and between APIs. We enhance the matrix factorization (MF) model with the mined implicit knowledge that are implicit relationships on both sides. We build an ensemble model by using all implicit knowledge. We conduct experiments on a collected real-world dataset and simulate industrial system scenarios. The experimental results verify the effectiveness and superiority of the proposed models.","2471-285X","","10.1109/TETCI.2020.3023155","National Natural Science Foundation of China(grant numbers:61902236); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9208715","API recommendation;collaborative learning;implicit relationship mining;industrial internet of things;matrix factorization","Computational modeling;Mashups;Prediction algorithms;Internet of Things;Collaboration;Collaborative work","","87","","38","IEEE","29 Sep 2020","","","IEEE","IEEE Journals"
"Monetization using Blockchains for IoT Data Marketplace","W. Badreddine; K. Zhang; C. Talhi","École de Technologie Supérieure, Montreal, Quebec, Canada; École de Technologie Supérieure, Montreal, Quebec, Canada; École de Technologie Supérieure, Montreal, Quebec, Canada","2020 IEEE International Conference on Blockchain and Cryptocurrency (ICBC)","17 Aug 2020","2020","","","1","9","The number of Internet of Things devices is growing dramatically, generating a huge amount of data which is becoming a valuable asset for data analysts. This trend culminates towards the creation of an IoT data marketplace, where streams of data from heterogeneous sources are sent in real time to various data consumers and are metered for monetization purposes. Publish/subscribe systems, such as Message Queuing Telemetry Transport (MQTT), are a promising solution to act as a transport layer for real-time data streams in a decoupled and large scale manner. However, pub/sub systems lack two key properties for an IoT data marketplace: (1) it does not provide any monetization logic; (2) it assumes that the pub/sub brokers are trusted entities, which is not the case in a decentralized or federated marketplace setting. In this paper, we address these issues using a reliable and transparent monetization system based on Distributed Ledger Technology (DLT) and smart contracts. We propose three monetization solutions and demonstrate the trade-off between the overhead of tracking IoT data on a blockchain vs. the accuracy of the monetization for data producers and consumers. In particular, we provide a Bloom filter-based solution for efficient verification of data exchange. We implement our system using Ethereum and Solidity and evaluate with respect to contract gas cost.","","978-1-7281-6680-3","10.1109/ICBC48266.2020.9169424","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9169424","","Contracts;Real-time systems;Data models;Quality of service;Internet of Things","","11","","30","IEEE","17 Aug 2020","","","IEEE","IEEE Conferences"
"Energy Harvesting Techniques for Internet of Things (IoT)","T. Sanislav; G. D. Mois; S. Zeadally; S. C. Folea","Automation Department, Technical University of Cluj-Napoca, Cluj-Napoca, Romania; Automation Department, Technical University of Cluj-Napoca, Cluj-Napoca, Romania; College of Communication and Information, University of Kentucky, Lexington, KY, USA; Automation Department, Technical University of Cluj-Napoca, Cluj-Napoca, Romania","IEEE Access","15 Mar 2021","2021","9","","39530","39549","The rapid growth of the Internet of Things (IoT) has accelerated strong interests in the development of low-power wireless sensors. Today, wireless sensors are integrated within IoT systems to gather information in a reliable and practical manner to monitor processes and control activities in areas such as transportation, energy, civil infrastructure, smart buildings, environment monitoring, healthcare, defense, manufacturing, and production. The long-term and self-sustainable operation of these IoT devices must be considered early on when they are designed and implemented. Traditionally, wireless sensors have often been powered by batteries, which, despite allowing low overall system costs, can negatively impact the lifespan and the performance of the entire network they are used in. Energy Harvesting (EH) technology is a promising environment-friendly solution that extends the lifetime of these sensors, and, in some cases completely replaces the use of battery power. In addition, energy harvesting offers economic and practical advantages through the optimal use of energy, and the provisioning of lower network maintenance costs. We review recent advances in energy harvesting techniques for IoT. We demonstrate two energy harvesting techniques using case studies. Finally, we discuss some future research challenges that must be addressed to enable the large-scale deployment of energy harvesting solutions for IoT environments.","2169-3536","","10.1109/ACCESS.2021.3064066","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9370135","Energy efficiency;energy harvesting;Internet of Things;IoT device;wireless sensor networks","Wireless sensor networks;Energy harvesting;Wireless communication;Sensors;Batteries;Internet of Things;Communication system security","","106","","162","CCBY","4 Mar 2021","","","IEEE","IEEE Journals"
"Immune-Endocrine System Inspired Hierarchical Coevolutionary Multiobjective Optimization Algorithm for IoT Service","Z. Yang; Y. Ding; Y. Jin; K. Hao","Engineering Research Center of Digitized Textile and Apparel Technology, Shanghai, China; Engineering Research Center of Digitized Textile and Apparel Technology, Shanghai, China; Engineering Research Center of Digitized Textile and Apparel Technology, Shanghai, China; Engineering Research Center of Digitized Textile and Apparel Technology, Shanghai, China","IEEE Transactions on Cybernetics","22 Oct 2019","2020","50","1","164","177","The intelligent devices in Internet of Things (IoT) not only provide services but also consider how to allocate heterogeneous resources and reduce resource consumption and service time as far as possible. This issue becomes crucial in the case of large-scale IoT environments. In order for the IoT service system to respond to multiple requests simultaneously and provide Pareto optimal decisions, we propose an immune-endocrine system inspired hierarchical coevolutionary multiobjective optimization algorithm (IE-HCMOA) in this paper. In IE-HCMOA, a multiobjective immune algorithm based on global ranking with vaccine is designed to choose superior antibodies. Meanwhile, we adopt clustering in top population to make the operations more directional and purposeful and realize self-adaptive searching. And we use the human forgetting memory mechanism to design two-level memory storage for the choice problem of solutions to achieve promising performance. In order to validate the practicability and effectiveness of IE-HCMOA, we apply it to the field of agricultural IoT service. The simulation results demonstrate that the proposed algorithm can obtain the best Pareto, the strongest exploration ability, and excellent performance than nondominated neighbor immune algorithms and NSGA-II.","2168-2275","","10.1109/TCYB.2018.2866527","International Collaborative Project of the Shanghai Committee of Science and Technology(grant numbers:16510711100); National Natural Science Foundation of China(grant numbers:61473077,61473078,61503075,61603090); Shanghai Science and Technology Promotion Project from Shanghai Municipal Agriculture Commission(grant numbers:2016-1-5-12); Northwestern Polytechnical University(grant numbers:2232017D-13); Program for Changjiang Scholars from the Ministry of Education(grant numbers:2015-2019); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8467544","Coevolutionary optimization;hierarchical multipopulation;immune-endocrine system;Internet of Things (IoT);multiobjective optimization;services selection","Optimization;Immune system;Sociology;Statistics;Sensors;Quality of service;Heuristic algorithms","Algorithms;Cluster Analysis;Decision Support Techniques;Endocrine System;Humans;Immune System;Internet of Things;Models, Immunological;Vaccines","22","","60","IEEE","18 Sep 2018","","","IEEE","IEEE Journals"
"Energy-Efficiency Optimization for IoT-Distributed Antenna Systems With SWIPT Over Composite Fading Channels","X. Yu; J. Chu; K. Yu; T. Teng; N. Li","College of Electronic and Information Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Electronic and Information Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Electronic and Information Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Electronic and Information Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Electronic and Information Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, China","IEEE Internet of Things Journal","10 Jan 2020","2020","7","1","197","207","Due to the requirement of low-power network devices for the proliferation of high data communication, enabling technologies for energy sustainable Internet of Things (IoT) are of great significance. In this article, we investigate the energy-efficiency (EE) optimization of IoT-distributed antenna (DA) system with simultaneous wireless information and power transfer (SWIPT) technique over fading channels, where the IoT device is equipped with power splitter to integrate the energy harvesting and information decoding processes via adjusting the transmit power of each DA port and power splitting (PS) ratio of IoT device. According to the analysis of EE, an optimization problem with the aim of maximizing the system EE is formulated under the constraints of maximum transmit power of each DA port as well as minimum harvested energy. Through analyzing the structure of the objective problem, it is found that the EE optimization problem, which combines transmit power allocation (PA) with PS problem, can be predigested to a PA problem. Then, the amount of valid DA ports and the corresponding PA are achieved by utilizing the Karush-Kuhn-Tucker conditions and Lambert function. Based on this, we propose an optimal resource allocation scheme without iteration to obtain the optimal PA and PS ratio, and the resulting closed-form expressions are provided. Considering that perfect channel state information (CSI) is hard to achieve, we also study the resource allocation scheme based on the imperfect CSI (i.e., statistical CSI with large-scale fading information), two suboptimal schemes are proposed. These two schemes have better robustness and lower complexity than the optimal scheme with perfect CSI because they only need partial channel information, but the performances are worse than the latter, as expected. Computer simulation indicates that proposed schemes are valid and can obtain superior EE performance with lower complexity.","2327-4662","","10.1109/JIOT.2019.2946581","National Natural Science Foundation of China(grant numbers:61571225,61571224,61971220); Chinese Academy of Sciences(grant numbers:2017006); Natural Science Foundation of Jiangsu Province(grant numbers:BK20181289); Six Talent Peaks Project in Jiangsu Province(grant numbers:2015-DZXX-007); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8863972","Distributed antenna system (DAS);energy efficiency (EE);imperfect channel state information (CSI);Internet of Things (IoT);power allocation (PA);power splitting (PS);simultaneous wireless information and power transfer (SWIPT)","Resource management;Internet of Things;Wireless communication;Optimization;Complexity theory;Rayleigh channels","","18","","37","IEEE","11 Oct 2019","","","IEEE","IEEE Journals"
"Interoperability and Scalability Trade-offs in Open IoT Platforms","D. Ottolini; I. Zyrianoff; C. Kamienski","Department of Computer Science and Engineering, University of Bologna, Italy; CMCC, Federal University of the ABC, Santo André, Brazil; Department of Computer Science and Engineering, University of Bologna, Italy","2022 IEEE 19th Annual Consumer Communications & Networking Conference (CCNC)","10 Feb 2022","2022","","","1","6","The Internet of Things is getting momentum and generating new demands over infrastructure, systems, and platforms. One of the main aspects that hamper the large-scale development of IoT-based systems is the lack of interoperability. IoT Platforms aim to solve this issue by providing a uniform interface to access data from heterogeneous sources. However, integrating new protocols and applications can impose additional overhead, hindering the platform’s overall performance and scalability. This study provides an insight into the trade-off between interoperability and performance of IoT platforms. First, we present a qualitative analysis of three open-source platforms - FIWARE, ThingsBoard, and Konker - analyzing their interoperability features. Second, we conduct a performance evaluation emulating two IoT-based environments – smart cities and smart health – to understand each platform’s scalability, response time, and computer resource usage. Finally, we analyze the possible trade-offs between interoperability features and scalability based on the qualitative and quantitative analysis. The results show that interoperability features do not have a direct impact on the performance of the platform.","2331-9860","978-1-6654-3161-3","10.1109/CCNC49033.2022.9700622","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9700622","IoT;IoT Platforms;Interoperability;Performance Evaluation","Performance evaluation;Protocols;Statistical analysis;Smart cities;Scalability;Smart healthcare;Time factors","","4","","19","IEEE","10 Feb 2022","","","IEEE","IEEE Conferences"
"Timeliness and Secrecy-Aware Uplink Data Aggregation for Large-Scale UAV-IoT Networks","Y. Ma; K. Liu; Y. Liu; L. Zhu","School of Electronics and Information Engineering, Beihang University, Beijing, China; School of Electronics and Information Engineering, Beihang University, Beijing, China; School of Electronics and Information Engineering, Beihang University, Beijing, China; Department of Electrical and Computer Engineering, National University of Singapore, Singapore","IEEE Internet of Things Journal","","2024","PP","99","1","1","Due to the inherent characteristics of system extensibility and implementation flexibility, unmanned aerial vehicle (UAV)-assisted data aggregations will play an essential role in Internet of Things (IoT) networks, where both communication security and timeliness are of high priority. In this paper, we study uplink data aggregation in cooperative jamming-aided large-scale UAV-IoT networks under the threat of eavesdroppers. By employing stochastic geometry, we derive performance metrics related to the age of information (AoI) and secrecy outage probability (SOP) in a system-level manner, and formulate the combat between legitimate entities (i.e., IoT devices and cooperative jammers) and eavesdroppers as a two-stage Stackelberg game. To solve the formulated game, the backward induction method is utilized to obtain the Stackelberg equilibrium (SE) iteratively. Specifically, we first obtain the minimum detection error probability for the eavesdropper by optimizing its detection threshold using the successive convex approximation (SCA) technique. Subsequently, the minimization of AoI violation probability and SOP for the legitimate entity is achieved using the proposed tighter α branch and bound (T-αBB) method by jointly optimizing the transmit powers of the typical IoT device and cooperative jammers as well as the deployment altitude of the typical UAV. Extensive numerical results demonstrate that the proposed solution converges rapidly, with the timeliness and secrecy metrics decreasing by 25.1%, 33.1%, 35.9%, and 37.6% compared to the benchmark scheme in suburban, urban, dense urban, and high-rise urban environments, respectively.","2327-4662","","10.1109/JIOT.2024.3357123","National Natural Science Foundation of China(grant numbers:U2033215,U2233216); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10411997","Large-scale UAV-IoT network;data aggregation;secrecy;timeliness;cooperative jamming;stochastic geometry;Stackelberg game","Internet of Things;Jamming;Autonomous aerial vehicles;Games;Security;Stochastic processes;Interference","","","","","IEEE","22 Jan 2024","","","IEEE","IEEE Early Access Articles"
"Access Control for Ambient Backscatter Enabled Internet of Things","L. Zhang; G. Feng; S. Qin; J. Wang; L. Cheng","National Key Laboratory of Science and Technology on Communications, and Yangtze Delta Region Institute (Huzhou), University of Electronic Science and Technology of China, Chengdu, China; National Key Laboratory of Science and Technology on Communications, and Yangtze Delta Region Institute (Huzhou), University of Electronic Science and Technology of China, Chengdu, China; National Key Laboratory of Science and Technology on Communications, and Yangtze Delta Region Institute (Huzhou), University of Electronic Science and Technology of China, Chengdu, China; National Key Laboratory of Science and Technology on Communications, and Yangtze Delta Region Institute (Huzhou), University of Electronic Science and Technology of China, Chengdu, China; National Key Laboratory of Science and Technology on Communications, and Yangtze Delta Region Institute (Huzhou), University of Electronic Science and Technology of China, Chengdu, China","ICC 2021 - IEEE International Conference on Communications","6 Aug 2021","2021","","","1","6","The beyond fifth-generation (B5G) and future wireless networks face the challenges of spectral, energy and cost efficiency for large scale machine-type communications. Recently, emerging ambient backscatter communication (AmBC) technology provides a promising paradigm for the development of green Internet of Things (IoT) networks in beyond B5G era. In this paper, we consider a multi-nodes scenario where a backscatter network is symbiotic with primary network consisting of multiple ambient radio frequency (RF) sources, thereby allowing the system to use the appropriate RF to support high throughput and wide coverage for IoT devices. Unlike existing work on AmBC, which focuses on physical layer with relatively ideal model, i.e., classic three-nodes model composed of RF, backscatter device (BD) and IoT device, this paper studies the access control strategy, including coefficient design and device association of BDs and IoT devices, for multi-RF backscatter network from the perspective of maximizing device transmission rate. Under the guarantee of quality of service (QoS), we develop an access control strategy with aim of maximizing the weighted sum of primary and backscatter transmission rates, and design a distributed access control strategy called DCA-S, by using the difference of two convex functions approximation (DCA) and dual decomposition to transform the non-concave optimization problem into the solvable concave subproblems. Numerical results show that the proposed DCA-S can achieve significantly performance improvement of the system compared with benchmark schemes.","1938-1883","978-1-7281-7122-7","10.1109/ICC42927.2021.9500438","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9500438","","Access control;Radio frequency;Symbiosis;Wireless networks;Quality of service;Transforms;Throughput","","","","17","IEEE","6 Aug 2021","","","IEEE","IEEE Conferences"
"Energy-Efficient Activation and Uplink Transmission for Cellular IoT","C. -H. Liu; Y. -H. Shen; C. -H. Lee","Department of Electrical and Computer Engineering, Mississippi State University, Starkville, USA; Institute of Communications Engineering, National Chiao Tung University, Hsinchu, Taiwan; Institute of Communications Engineering, National Chiao Tung University, Hsinchu, Taiwan","IEEE Internet of Things Journal","11 Feb 2020","2020","7","2","906","921","Consider a large-scale cellular network in which base stations (BSs) serve massive Internet of Things (IoT) devices. Since IoT devices are powered by a capacity-limited battery, how to prolong their working lifetime is a paramount problem for the success of cellular IoT systems. This article proposes how to use BSs to manage the active and dormant operating modes of the IoT devices via downlink signaling in an energy-efficient fashion and how the IoT devices perform energy-efficient uplink power control to improve their uplink coverage. We first investigate the fundamental statistical properties of an activation signaling process induced by BSs that would like to activate the devices in their cells, which helps to derive the neat expressions of the true, false, and total activation probabilities that reveal joint downlink power control and BS coordination is an effective means to significantly improve the activation performance. We then propose an energy-efficient uplink power control for IoT devices which is shown to save power and ameliorate the uplink coverage probability at the same time. We also propose an energy-efficient downlink power control and BS coordination scheme, which is shown to remarkably improve the activation and uplink coverage performances at the same time.","2327-4662","","10.1109/JIOT.2019.2946331","Mississippi State University(grant numbers:ORED 253551-060702); Ministry of Science and Technology, Taiwan(grant numbers:MOST 107-2221-E-009-035-MY2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8862872","Activation;cellular network;coverage probability;energy-efficient communications;Internet of Things (IoT);power control;stochastic geometry","Uplink;Internet of Things;Cellular networks;Downlink;Power control;Performance evaluation;Fading channels","","14","","27","IEEE","8 Oct 2019","","","IEEE","IEEE Journals"
"DynaSens: Dynamic Scheduling for IoT Devices Sustainability","N. Maleki; A. Musaddiq; D. Toll; F. Palma; T. Olsson; D. Mozart; M. Omareen; F. Ahlgren","Department of Computer Science and Media Technology, Applied IoT Lab, Linnaeus University, Sweden; Department of Computer Science and Media Technology, Applied IoT Lab, Linnaeus University, Sweden; Department of Computer Science and Media Technology, Applied IoT Lab, Linnaeus University, Sweden; Department of Computer Science and Media Technology, Applied IoT Lab, Linnaeus University, Sweden; Department of Computer Science and Media Technology, Applied IoT Lab, Linnaeus University, Sweden; Department of Computer Science and Media Technology, Applied IoT Lab, Linnaeus University, Sweden; Department of Computer Science and Media Technology, Applied IoT Lab, Linnaeus University, Sweden; Department of Computer Science and Media Technology, Applied IoT Lab, Linnaeus University, Sweden","2022 International Conference on Broadband Communications for Next Generation Networks and Multimedia Applications (CoBCom)","14 Sep 2022","2022","","","1","7","The Internet of Things (IoT) have shown numerous potential applications that can enhance our quality of life. IoT is becoming a core technology to bring smart homes, smart cities, and smart industries into reality. However, with potential benefits comes a challenge of sustainability, and one major concern is to minimize energy consumption. In a citywide area, managing the operation of such large-scale IoT networking is one of the complex tasks. One of the ways is to utilize dynamic sensing scheduling where the IoT device goes to the sleep mode and prevents unnecessary data transmission. In this paper, we propose a dynamic sensing (DynaSens) algorithm for an IoT-based waste management system. This algorithm helps to reduce the waste bin overflowing, thus, provides better sanitation, and it is also helpful in reducing the fuel cost of waste collection vehicles. Our work utilizes measured values such as current consumption, LiDAR measurement time, and LoRa transmission time as the input data for the simulation experiment to evaluate energy consumption. We also assessed DynaSens using a real dataset obtained from a recycling house. We use Pycom LoPy4 micro-controller as a development board. For a number of garbage-thrown scenarios, DynaSens enables longer battery longevity by reducing the repeated execution of the same tasks.","","978-1-6654-8598-2","10.1109/CoBCom55489.2022.9880629","Linnaeus University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9880629","IoT;Dynamic Sensing;Scheduling;Energy Efficiency","Energy consumption;Heuristic algorithms;Energy measurement;Dynamic scheduling;Time measurement;Sensors;Internet of Things","","6","","21","IEEE","14 Sep 2022","","","IEEE","IEEE Conferences"
"IOTs Traffics Detection and Analysis Using Machine Learning for Cybersecurity Application","A. Altrad","School of Digital Technologies, American University of Phnom Penh, Phnom Penh, Cambodia","2023 IEEE 5th Eurasia Conference on IOT, Communication and Engineering (ECICE)","12 Jan 2024","2023","","","78","83","The data generation and transmission over the internet daily by users’ applications are increasing tremendously. Also, the amounts of traffic data transmission produced by IoTs over different networks are massive. The normal networks of companies, campuses, and others connect standard devices such as servers, routers, and switches. However, smart networking and the Internet of Things (IoTs) communication connect devices such as cameras, smart lighting systems, Alexa, and outlets. These devices communicate over networks via protocols. However, they are not robust in their software development due to security reasons, digital vulnerabilities and threats exist and open doors for hackers. Thus, the feature extract technique was applied to detect and analyze IoT’s benign and attack traffic features from a recent and large-scale dataset called CICIoT2023. The dataset contains a diversity of traffic data types generated by the IoT lab-connected 105 smart devices. Finally, the selected features were applied to machine learning algorithms to understand the IoT’s traffic behaviors for security applications and analytics. The applied algorithms showed high performance. The highest F score results were 0.979 for the decision tree, 0.973 for KNN, 0.704 for Naive Bayes, 0.939 for Random Forest, and 0.902 for MLP.","","979-8-3503-1469-4","10.1109/ECICE59523.2023.10383018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10383018","IoT network security;traffic features analysis;machine learning;CICIOT2023;dataset","Machine learning algorithms;Virtual assistants;Feature extraction;Software;Routing protocols;Internet of Things;Servers","","","","33","IEEE","12 Jan 2024","","","IEEE","IEEE Conferences"
"Index","A. J. Anand; P. Tanwar; H. Raza",NA; NA; NA,"Advanced Technologies for Smart Agriculture","","2023","","","383","386","This book brings new smart farming methodologies to the forefront, sparked by pervasive applications with automated farming technology. New indigenous expertise on smart agricultural technologies is presented along with conceptual prototypes showing how the Internet of Things, cloud computing, machine learning, deep learning, precision farming, crop management systems, etc., will be used in large-scale production in the future. The necessity of available welfare systems for farmers’ well-being is also discussed in the book. It draws the conclusion that there is a greater need and demand today for smart farming methodologies driven by technology than ever before.","","9788770228831","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10286352.pdf&bkn=10286317&pdfType=chapter","","","","","","","","16 Oct 2023","","","River Publishers","River eBook Chapters"
"About the Editors","A. J. Anand; P. Tanwar; H. Raza",NA; NA; NA,"Advanced Technologies for Smart Agriculture","","2023","","","387","388","This book brings new smart farming methodologies to the forefront, sparked by pervasive applications with automated farming technology. New indigenous expertise on smart agricultural technologies is presented along with conceptual prototypes showing how the Internet of Things, cloud computing, machine learning, deep learning, precision farming, crop management systems, etc., will be used in large-scale production in the future. The necessity of available welfare systems for farmers’ well-being is also discussed in the book. It draws the conclusion that there is a greater need and demand today for smart farming methodologies driven by technology than ever before.","","9788770228831","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10286354.pdf&bkn=10286317&pdfType=chapter","","","","","","","","16 Oct 2023","","","River Publishers","River eBook Chapters"
"Research on design and implementation of the IOT intelligent transportation virtual simulation experiment system","L. Yang; Y. Liu; L. Ma; D. Zhang; P. He","Xi'an Eurasia University, Xi'an, China; Xi'an Eurasia University, Xi'an, China; Xi'an Eurasia University, Xi'an, China; Xi'an Eurasia University, Xi'an, China; Xi'an Eurasia University, Xi'an, China","9th International Symposium on Test Automation & Instrumentation (ISTAI 2022)","27 Jan 2023","2022","2022","","501","506","In order to solve the rapid verification of the function of the traffic control system and reproduce the complex large-scale experimental scene, this paper realizes the 3D modeling of vehicles, traffic infrastructure, network construction and main scenes based on virtual simulation technology, and simulates ETC charging, intelligent bus station, intelligent parking, and wireless charging working modes. The experimental test results show that the system simulates the intelligent transportation environment truly and effectively, which integrates the theoretical knowledge of Internet of Things communication technology into the experimental operation. With the characteristics of immersion, interactivity and innovation, the system improves the trainees' ability to integrate theory with practice and solve complex engineering problems.","","978-1-83953-839-1","10.1049/icp.2022.3274","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10026757","","","","","","","","27 Jan 2023","","","IET","IET Conferences"
"Research on Temperature and Light Control System of Vertical Farm Based on PLC","S. Li; X. Li; Z. Yang","Kunming University of Science and Technology Oxbridge College, Kunming, China; Kunming University of Science and Technology Oxbridge College, Kunming, China; Kunming University of Science and Technology Oxbridge College, Kunming, China","2023 International Conference on Networking, Informatics and Computing (ICNETIC)","6 Sep 2023","2023","","","320","324","Vertical agriculture has a distinctive feature of agricultural industrialization consortium. Because of its highly intensive, large-scale and industrialized operation, it has become a new agricultural planting mode. The normal operation of vertical farms cannot be supported by a single technology. It needs to integrate many factors such as buildings, facility agriculture, ecological restoration, agricultural Internet of Things and intelligent agricultural machinery. Then, the first thing to be solved is the problem of temperature and light. All of them adopt artificial light mode, which is difficult to realize in production due to the restriction of electric power. Therefore, it is necessary to develop an automatic temperature, humidity and illumination control system for vertical farms in order to detect temperature, humidity and illumination in real time. Therefore, this paper studies the temperature and light control system based on Programmable Logic Controller (PLC). By controlling the environmental factors affecting crop growth, such as temperature, light, humidity and CO2, the crops can obtain the best growth conditions, improve and optimize the crop quality and yield, and obtain the maximum ecological, social and economic benefits. The experimental results show that the temperature monitoring system can control the indoor temperature of the farm within the temperature range required for plant growth, and the maximum relative error of control is 3.17%.","","979-8-3503-1331-4","10.1109/ICNETIC59568.2023.00073","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10236790","Programmable logic controller;Vertical farms;Temperature;Light;Control system","Temperature sensors;Temperature measurement;Temperature distribution;Green products;Crops;Humidity;Control systems","","","","13","IEEE","6 Sep 2023","","","IEEE","IEEE Conferences"
"Integration of Cloud Computing with Internet of Things for Network Management and Performance Monitoring","K. Namee; C. Vantaneeyakul; J. Polpinij; G. M. Albadrani; S. Namee","Faculty of Industrial Technology and Management, King Mongkut's University of Technology North Bangkok, Prachinburi, Thailand; Faculty of Industrial Technology and Management, King Mongkut's University of Technology North Bangkok, Prachinburi, Thailand; Department of Computer Science, Faculty of Informatics, Mahasarakham University, Mahasarakham, Thailand; School of Science, Princess Nourah Bint Abdulrahman University, Riyadh, Saudi Arabia; Department of Disaster Prevention and Mitigation, Ministry of Interior, Bangkok, Thailand","2020 18th International Conference on ICT and Knowledge Engineering (ICT&KE)","25 Dec 2020","2020","","","1","7","The past decade has seen the rapid development of the Internet in many areas. Nowadays, the internet is used widely in every organization. People also have internet usage 24 hours a day. Hence, it is important to monitor the working situation of network equipment all day long. This research is applied Internet of Things and Cloud Computing technology to monitor the operation of computer network devices by monitoring the network condition to be stable, secure, check the operation of the network, record working status and send alerting the administrator. In large scale networks, various problems are often encountered, such as when the server is unavailable due to too many users or when there are network users too much will cause the network to be slow or may not work. For example, which the device may be overused or some error occurs. This proposed platform can analyze problems that may occur in the future, will help reduce costs and damage that will occur when damaged or unusable. Also, it can also analyze the data to reduce the risk that may affect the network. It will be able to use various information to improve network performance, allows administrators to check managing network systems at the same time, multiple machines, and all over. In this testbed experiment, there are a total of 8 network equipment involved. Each device has approximately 48 interfaces, with each interface having an average 5 value. Therefore, the amount of traffic on the network shown is enormous. Researcher studies how to be sure that all data displayed in the system is accurate and reliable. In the process of retrieving the value, the OIDs (Object Identifier) in the MIB (Management Information Base). Hierarchy of each device have different values depending on the model, model type and brand of the device. How to be sure that the value retrieved is displayed as the correct value? Because if the OID value is incorrect, the value received will also be incorrect. The interpretation of the system administrator is also wrong. Another issue is that the values stored in the MIB Database are stored in raw ASCII format. When sending values to a machine that acts as an SNMP manager, the file is in binary format which is an unreadable value. Therefore, in this research, the interpretation of the value obtained must be correctly interpreted is a readable value and is in the unit of the correct value display. In this experiment, using the Raspberry Pi 3 board.","2157-099X","978-1-7281-8251-3","10.1109/ICTKE50349.2020.9289876","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9289876","Internet of Things;Network Monitoring;Cloud Computing;Edge Computing","Cloud computing;Management information base;Organizations;Telecommunication traffic;Servers;Internet of Things;Monitoring","","","","19","IEEE","25 Dec 2020","","","IEEE","IEEE Conferences"
"Time Synchronized Node Localization Using Optimal H-Node Allocation in a Small World WSN","O. J. Pandey; V. Gautam; S. Jha; M. K. Shukla; R. M. Hegde","Department of Electronics and Communication Engineering, School of Engineering and Applied Sciences, SRM University AP, Amaravati, India; Urvija AI Private Limited, Bengaluru, India; Department of Electrical Engineering, Indian Institute of Technology Kanpur, Kanpur, India; Department of Electrical and Computer Engineering, University of Saskatchewan, Saskatoon, SK, Canada; Department of Electrical Engineering, Indian Institute of Technology Kanpur, Kanpur, India","IEEE Communications Letters","10 Nov 2020","2020","24","11","2579","2583","Time synchronization and node localization over a wireless sensor network (WSN) is a vital problem in applications such as Internet of Things (IoT) and context-aware pervasive systems. Addressing this problem leads to an efficient data fusion, power scheduling, bandwidth utilization, geographic routing, time-based channel sharing, and clustering among sensor nodes. In a WSN, sensor nodes utilize multi-hop data transmission model towards the data transfer. Utilization of large number of hops for the data transfer leads to poor time synchronization resulting in erroneous node location estimates. In this letter, we make use of a recent development in social networks termed as small world characteristics and propose a novel method of time synchronized node localization over a small world WSN (SW-WSN). The results are obtained via simulations over a medium scale WSN. The performance of the proposed method is evaluated by conducting detailed analysis of time synchronization and node localization errors over the SW-WSN. The results obtained illustrate that the proposed small world model yields improved localization results when compared to results obtained over a regular WSN.","1558-2558","","10.1109/LCOMM.2020.3008086","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9136781","Small world wireless sensor networks (SW-WSNs);time synchronization;node localization","Wireless sensor networks;Synchronization;Data transfer;Clocks;Resource management;Internet of Things","","19","","31","IEEE","8 Jul 2020","","","IEEE","IEEE Journals"
"XFeed PUF: A Secure and Efficient Delay-based Strong PUF Using Cross-Feed Connections","T. Idriss; A. Gavin; A. Gabales; H. Idriss; M. Bayoumi","Department of Computer Science, Western Washington University, USA; Department of Computer Science, Western Washington University, USA; Department of Computer Science, Western Washington University, USA; Center for Advanced Computer Studies, University of Louisiana at Lafayette, USA; Center for Advanced Computer Studies, University of Louisiana at Lafayette, USA","2022 IEEE International Symposium on Circuits and Systems (ISCAS)","11 Nov 2022","2022","","","461","465","Physical unclonable functions (PUFs) are hardware security primitives that offer a lightweight security solution for constrained devices in the Internet of Things. The challenges facing PUFs security scaling have so far hindered their wide-scale deployment beyond simple key generation primitives. Although physically unclonable, PUFs are vulnerable to soft modeling attacks. Many PUF security enhancements impose significant implementation overhead, which could be problematic for devices operating in a constrained environment. This work introduces the Cross-Feed (XFeed) PUF, a highly efficient PUF circuit resilient against machine learning attacks while requiring a small circuit implementation area. In the XFeed PUF, arbiters feed intermediate race conditions to adjacent PUF rows to increase the non-linearity of the PUF system. A systematic categorization and benchmarking of the possible interconnection strategies are performed to determine the near-optimal connection schemes for the introduced XFeed PUF. The results showed that the XFeed PUF has superior security efficiency and scalability compared to other arbiter PUF-based enhancements.","2158-1525","978-1-6654-8485-5","10.1109/ISCAS48785.2022.9937815","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9937815","Physically Unclonable Functions;Hardware Security;Authentication","Support vector machines;Systematics;Scalability;Integrated circuit interconnections;Machine learning;Physical unclonable function;Security","","1","","27","IEEE","11 Nov 2022","","","IEEE","IEEE Conferences"
"Achieving Energy-Efficient Massive URLLC Over Cell-Free Massive MIMO","J. Zeng; T. Wu; Y. Song; Y. Zhong; T. Lv; S. Zhou","School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China","IEEE Internet of Things Journal","8 Jan 2024","2024","11","2","2198","2210","Achieving energy-efficient massive ultrareliable and low-latency communications (E2-mURLLC) is a promising application prospect for sixth-generation (6G) mobile communication networks. However, there are some insurmountable obstacles, such as a large number of potential users, complex and diverse small-scale and shadow fading, and stringent energy efficiency (EE), reliability, and latency requirements. Considering the above obstacles, we propose a cell-free massive multiple-input–multiple-output (MIMO) architecture based on the  $\kappa $ - $\mu $  shadowed fading model, and maximum-ratio combining (MRC) multiuser detection with simple path-loss decoding (S-PLD) to achieve the simultaneous optimization of EE, latency, and reliability. Furthermore, the finite blocklength information theory is used to uncover the relationship among EE, reliability, latency, and achievable data rate when the packet size is small. Simulation results show that compared with the massive MIMO architecture, using our architecture with MRC multiuser detection and S-PLD can support a threefold increase in the number of access users, reduce transmit power by 90%, achieve a nearly 100 times reliability enhancement, and shorten transmission latency by 23.3%. Consequently, a cell-free massive MIMO system with MRC multiuser detection and S-PLD, as a considerable significant potential to facilitate the advancement from URLLC to E2-mURLLC, is promising to support some time-sensitive applications with massive access, such as unmanned aerial vehicles, the Industrial Internet of Things and vehicle-to-vehicle communications.","2327-4662","","10.1109/JIOT.2023.3293008","National Natural Science Foundation of China(grant numbers:62001264,62271068); Natural Science Foundation of Beijing(grant numbers:L222046); Beijing Institute of Technology Research Fund Program for Young Scholars; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10175166","κ-μ shadowed fading;cell-free massive multiple-input multiple-output (MIMO);energy-efficient massive ultrareliable and low-latency communications (E2-mURLLC);finite blocklength (FBL);simple path-loss decoding (S-PLD)","Fading channels;Reliability;Ultra reliable low latency communication;Massive MIMO;Reliability theory;Internet of Things;Signal processing","","","","43","IEEE","7 Jul 2023","","","IEEE","IEEE Journals"
"Towards Fine-Grained Access Control in Enterprise-Scale Internet-of-Things","Q. Zhou; M. Elbadry; F. Ye; Y. Yang","Electrical and Computer Engineering, Stony Brook University, Stony Brook, NY, USA; Electrical and Computer Engineering, Stony Brook University, Stony Brook, NY, USA; Electrical and Computer Engineering, Stony Brook University, Stony Brook, NY, USA; Electrical and Computer Engineering, Stony Brook University, Stony Brook, NY, USA","IEEE Transactions on Mobile Computing","2 Jul 2021","2021","20","8","2701","2714","Scalable, fine-grained access control for Internet-of-Things is needed in enterprise environments, where tens of thousands of users need to access smart objects which have a similar or larger order of magnitude. Existing solutions offer all-or-nothing access, or require all access to go through a cloud backend, greatly impeding access granularity, robustness and scale. In this paper, we propose Heracles, an IoT access control system which achieves robust, fine-grained access control and responsive execution at enterprise scale. Heracles adopts a capability-based approach using secure, unforgeable tokens that describe the authorizations of users, to either individuals or collections of objects in single or bulk operations. It has a 3-tier architecture to provide centralized policy and distributed execution desired in enterprise environments. Extensive analysis and performance evaluation on a testbed prove that Heracles achieves fine-grained access control and responsive execution at enterprise scale. Compared with systems using access control list, Heracles eliminates or reduces by 10x-100x the updating overhead under frequent changes of subject memberships and policies. Besides, Heracles achieves responsive execution: it takes 0.57 second to access 18 objects which are scattered 1-9 hops away, and execution on a 1-hop or 2-hop object needs only 0.07 or 0.13 second respectively.","1558-0660","","10.1109/TMC.2020.2984700","National Science Foundation(grant numbers:CCF 1652276,CNS 1513719,CNS 1730291); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9055160","Internet of Things;security;access control","Access control;Permission;Mobile computing;Computer architecture;Public key;Robustness","","10","","28","IEEE","2 Apr 2020","","","IEEE","IEEE Journals"
"DFOPS: Deep-Learning-Based Fingerprinting Outdoor Positioning Scheme in Hybrid Networks","G. B. Tarekegn; R. -T. Juang; H. -P. Lin; A. B. Adege; Y. Y. Munaye","Department of Electrical Engineering and Computer Science, National Taipei University of Technology, Taipei, Taiwan; Department of Electronic Engineering, Feng Chia University, Taichung, Taiwan; Department of Electronic Engineering, National Taipei University of Technology, Taipei, Taiwan; Department of Electrical Engineering and Computer Science, National Taipei University of Technology, Taipei, Taiwan; Department of Electrical Engineering and Computer Science, National Taipei University of Technology, Taipei, Taiwan","IEEE Internet of Things Journal","18 Feb 2021","2021","8","5","3717","3729","Many Internet-of-Things (IoT) services rely on location information. This article proposes a deep learning-based fingerprinting outdoor positioning scheme (DFOPS) for use in scalable environments. The proposed scheme is a hierarchical combination of the support vector machine (SVM) and long short-term memory (LSTM) algorithms. It was applied in a large-scale wireless environment with multiple wireless local area networks (WLANs) and cellular base stations. The results show that the positioning error of the proposed scheme is 42 cm, and the computation time is reduced by 63% compared with conventional methods. Thus, the proposed system can provide promising and reasonable support location-aware services for IoT devices in large-scale wireless environments.","2327-4662","","10.1109/JIOT.2020.3024845","Ministry of Science and Technology, Taiwan(grant numbers:109-2222-E-035-003-MY2,109-2634-F-009-018,108-2221-E-027-020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9200463","Affinity propagation clustering (APC);Internet of Things (IoT);linear discriminant analysis (LDA);long short-term memory (LSTM);positioning;received signal strength (RSS);support vector machine (SVM)","Wireless LAN;Fingerprint recognition;Long Term Evolution;Internet of Things;Wireless communication;Support vector machines;Sensors","","10","","44","IEEE","18 Sep 2020","","","IEEE","IEEE Journals"
"Scaling-Up Distributed Processing of Data Streams for Machine Learning","M. Nokleby; H. Raja; W. U. Bajwa","Target AI, Minneapolis, MN, USA; Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA; Department of Electrical and Computer Engineering and the Department of Statistics, Rutgers University, New Brunswick, NJ, USA","Proceedings of the IEEE","27 Oct 2020","2020","108","11","1984","2012","Emerging applications of machine learning in numerous areas-including online social networks, remote sensing, Internet-of-Things (IoT) systems, smart grids, and more-involve continuous gathering of and learning from streams of data samples. Real-time incorporation of streaming data into the learned machine learning models is essential for improved inference in these applications. Furthermore, these applications often involve data that are either inherently gathered at geographically distributed entities due to physical reasons, for example, IoT systems and smart grids, or that are intentionally distributed across multiple computing machines for memory, storage, computational, and/or privacy reasons. Training of machine learning models in this distributed, streaming setting requires solving stochastic optimization (SO) problems in a collaborative manner over communication links between the physical entities. When the streaming data rate is high compared with the processing capabilities of individual computing entities and/or the rate of the communications links, this poses a challenging question: How can one best leverage the incoming data for distributed training of machine learning models under constraints on computing capabilities and/or communications rate? A large body of research in distributed online optimization has emerged in recent decades to tackle this and related problems. This article reviews recently developed methods that focus on large-scale distributed SO in the compute- and bandwidth-limited regimes, with an emphasis on convergence analysis that explicitly accounts for the mismatch between computation, communication, and streaming rates and provides sufficient conditions for order-optimum convergence. In particular, it focuses on methods that solve: 1) distributed stochastic convex problems and 2) distributed principal component analysis, which is a nonconvex problem with the geometric structure that permits global convergence. For such methods, this article discusses recent advances in terms of distributed algorithmic designs when faced with high-rate streaming data. Furthermore, it reviews theoretical guarantees underlying these methods that show that there exist regimes in which systems can learn from distributed processing of streaming data at order-optimal rates-nearly as fast as if all the data were processed at a single superpowerful machine.","1558-2256","","10.1109/JPROC.2020.3021381","National Science Foundation(grant numbers:CCF-1845076,IIS-1838179); Army Research Office(grant numbers:W911NF-19-1-0027); National Science Foundation(grant numbers:CCF-1453073,CCF-1907658,OAC-1940074); Army Research Office(grant numbers:W911NF-17-1-0546); DARPA Lagrange Program under ONR/NIWC(grant numbers:N660011824020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9206551","Convex optimization;distributed training;empirical risk minimization (ERM);federated learning;machine learning;minibatching;principal component analysis (PCA);stochastic gradient descent (SGD);stochastic optimization (SO);streaming data","Machine learning;Training data;Distributed databases;Computational modeling;Data models;Optimization;Stochastic processes","","11","","125","IEEE","28 Sep 2020","","","IEEE","IEEE Journals"
"Research on Data Sharing Architecture for Ecological Monitoring Using Iot Streaming Data","A. Wu; J. Guo; P. Yang","Key Laboratory of Remote Sensing of Gansu Province, Heihe Remote Sensing Experimental Research Station, Northwest Institute of Eco-Environment and Resources, Chinese Academy of Sciences, Lanzhou, China; Key Laboratory of Remote Sensing of Gansu Province, Heihe Remote Sensing Experimental Research Station, Northwest Institute of Eco-Environment and Resources, Chinese Academy of Sciences, Lanzhou, China; Key Laboratory of Remote Sensing of Gansu Province, Heihe Remote Sensing Experimental Research Station, Northwest Institute of Eco-Environment and Resources, Chinese Academy of Sciences, Lanzhou, China","IEEE Access","4 Nov 2020","2020","8","","195385","195397","The rapid development of Internet of Things (IoT) technology and the widespread deployment of various sensors around the world have produced a large number of data streams. Thus, current computing systems face the challenge of quickly receiving and managing these large-scale streaming data. This study builds an efficient distributed database based on Greenplum (GP) and focuses on solving the problem of the low efficiency of structured data queries for observed ecological data collected from fragile areas in Northwest China's desert oasis. First, a distributed database is designed and deployed at the physical storage structure level. A database table structure is then established based on the characteristics of the streaming data. On this basis, the data storage strategy is optimized at the data table level. Additionally, the query efficiency of the distributed database is compared with the query efficiency of traditional standalone databases. The results show that the distributed database significantly improves the data query efficiency. The greater the amount of data stored, the better the improvement in efficiency. Finally, based on the optimized distributed database, we develop a data sharing system for streaming data from ecologically fragile areas in the desert oasis in Northwest China, which provides a new approach for the efficient sharing of massive amounts of IoT streaming data for ecological monitoring. Our storage system is still currently working normally, which is highly important to both data managers and users.","2169-3536","","10.1109/ACCESS.2020.3034466","National Key Research and Development Program of China(grant numbers:2016YFC0500105); National Natural Science Foundation of China(grant numbers:41801270); Foundation for Excellent Youth Scholars of the Northwest Institute of Eco-Environment and Resources, Chinese Academy of Sciences(grant numbers:Y851D41); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9241702","Ecological monitoring;IoT;greenplum;performance optimization;data sharing","Distributed databases;Monitoring;Internet of Things;Optimization;Big Data;Ecosystems","","4","","55","CCBY","28 Oct 2020","","","IEEE","IEEE Journals"
"Optimizing Age of Information in Random-Access Poisson Networks","X. Sun; F. Zhao; H. H. Yang; W. Zhan; X. Wang; T. Q. S. Quek","School of Electronics and Communication Engineering, Shenzhen Campus of Sun Yat-sen University, Shenzhen, China; School of Electronics and Communication Engineering, Shenzhen Campus of Sun Yat-sen University, Shenzhen, China; Zhejiang University/University of Illinois at Urbana–Champaign Institute, Zhejiang University, Haining, China; School of Electronics and Communication Engineering, Shenzhen Campus of Sun Yat-sen University, Shenzhen, China; School of Electronics and Information Technology, Sun Yat-sen University, Guangzhou, China; Information System Technology and Design Pillar, Singapore University of Technology and Design, Singapore","IEEE Internet of Things Journal","25 Apr 2022","2022","9","9","6816","6829","Timeliness is an emerging requirement for many Internet of Things (IoT) applications. In IoT networks with a large number of nodes, severe interference may incur that leads to Age-of-Information (AoI) degradation. It is, therefore, important to study how to optimize the AoI performance. This article focuses on the AoI minimization in random-access Poisson networks. By considering the spatiotemporal interactions amongst the transmitters, an expression of the peak AoI is derived, based on which the optimal peak AoI and the corresponding optimal packet arrival rate and channel access probability are further characterized. The analysis shows that when the channel access probability (resp., the packet arrival rate) is given, the optimal packet arrival rate (resp., the optimal channel access probability) is equal to one when nodes are sparsely deployed, and decreases as the node deployment density increases. With a joint tuning of these two system parameters, the optimal channel access probability always equals one. Moreover, with the sole tuning of the channel access probability, the optimal peak AoI is improved with a smaller packet arrival rate only when the node deployment density is high. In contrast, a higher channel access probability always improves peak AoI performance when the packet arrival rate is solely tuned. The analysis in this article sheds important light on freshness-aware design for large-scale networks.","2327-4662","","10.1109/JIOT.2021.3115780","Key-Area Research and Development Program of Guangdong Province(grant numbers:2020B0101120003); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2019A1515011906); National Natural Science Foundation of China(grant numbers:62001524); Science, Technology, and Innovation Commission of Shenzhen Municipality(grant numbers:2021A04); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2021A1515012631); National Research Foundation, Singapore; Infocomm Media Development Authority under its Future Communications Research and Development Programme; MOE ARF Tier 2(grant numbers:T2EP20120-0006); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9548963","Age of Information (AoI);queuing theory;random access;stochastic geometry","Radio transmitters;Internet of Things;Interference;Tuning;Signal to noise ratio;Geometry;Sun","","3","","31","IEEE","27 Sep 2021","","","IEEE","IEEE Journals"
"Machine-Learning-Based White-Hat Worm Launcher Adaptable to Large-Scale IoT Network","X. Pan; S. Yamaguchi; T. Kageyama","Graduate School of Sciences and Technology for Innovation, Yamaguchi University, Ube, Japan; Graduate School of Sciences and Technology for Innovation, Yamaguchi University, Ube, Japan; Graduate School of Sciences and Technology for Innovation, Yamaguchi University, Ube, Japan","2021 IEEE 10th Global Conference on Consumer Electronics (GCCE)","1 Dec 2021","2021","","","283","286","This paper proposes a white-hat worm launcher based on machine learning (ML) adaptable to large-scale IoT network for Botnet Defense System (BDS). BDS is a kind of cyber-security systems that uses white-hat botnets to exterminate malicious botnets. White-hat bots defend an IoT system against malicious bots, but there is no discussion on the white-hat worms’ deployment in a large-scale IoT network. Therefore, We propose a divide and conquer algorithm, which allows us to apply the white-hat worm launcher to large-scale IoT networks. We introduced the proposed algorithm into the white-hat worm launcher. We modeled BDS and the launcher with agent-oriented Petri net PN2 and confirmed the effect through the simulation of the PN2 model.","2378-8143","978-1-6654-3676-2","10.1109/GCCE53005.2021.9621895","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9621895","worm launcher;divide and conquer algorithm;machine learning (ML);botnet defense system (BDS)","Adaptation models;Botnet;Simulation;Conferences;Petri nets;Machine learning;Delays","","3","","11","IEEE","1 Dec 2021","","","IEEE","IEEE Conferences"
"IoT platforms and services configuration through parameter sweep: a simulation-based approach","A. Barbieri; F. Marozzo; C. Savaglio","Department of Computer Science, Modeling, Electronics and Systems Engineering (DIMES), University of Calabria, Italy; Department of Computer Science, Modeling, Electronics and Systems Engineering (DIMES), University of Calabria, Italy; Institute for High Performance Computing and Networking (ICAR) of National Research Council (CNR) of Italy","2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","6 Jan 2022","2021","","","1803","1808","Due to their inherent cyber-physical features and high interactivity, IoT services exhibit performances which are simultaneously impacted by different orthogonal factors. Indeed, deployment settings (e.g., Cloud- or Edge-based scenarios, network bandwidth, hardware resource availability), algorithmic aspects (e.g., the specific algorithm used to solve a problem) and data features (e.g., packet size and rate) deeply affect the overall functioning of an IoT service and its compliance with specific requirements such as reactivity, reliability and efficiency. An accurate parameter sweep based on realistic IoT simulations is a viable, yet still unexplored, solution to obtain a full-fledged overview and specific evaluations about the performance of an IoT system under development. In such a direction, in this paper we present an approach for assessing Edge analytic in complex IoT scenarios through a parameter sweep analysis conducted through a simulation-based process, enabling a fine-grained modeling of hybrid IoT systems (both Cloud and Edge) of different scales (small, medium and large). Four typical IoT use cases (autonomous vehicles, smart healthcare, gaming, and industrial IoT) are presented to show the benefits of our approach in finding the right settings for configuring and running them. Indeed, the obtained results show that our approach concretely helps IoT developers in the challenging task of tuning the parameters’ set so as to meet the given requirements, even in the case of large solution spaces and before the actual deployment phase.","2577-1655","978-1-6654-4207-7","10.1109/SMC52423.2021.9658613","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9658613","Parameter sweep;IoT platforms;IoT services;Simulation;Edge Analytic","Analytical models;Scalability;Thumb;Medical services;Internet of Things;Reliability;Task analysis","","5","","21","IEEE","6 Jan 2022","","","IEEE","IEEE Conferences"
"DQN-Based Collaborative Computation Offloading for Edge Load Balancing","Z. Li; K. Yu; H. Zhou; X. Wu","School of Artificial Intelligence, Beijing University of Posts and Telecommunications, Beijing, China; School of Artificial Intelligence, Beijing University of Posts and Telecommunications, Beijing, China; School of Artificial Intelligence, Beijing University of Posts and Telecommunications, Beijing, China; School of Artificial Intelligence, Beijing University of Posts and Telecommunications, Beijing, China","2023 8th IEEE International Conference on Network Intelligence and Digital Content (IC-NIDC)","23 Jan 2024","2023","","","01","06","The emergence of mobile edge computing (MEC) supports large-scale computing demand in the Internet of Things era by moving computing pressure from cloud center to the edge. However, computing resources of edge servers are scattered and restricted. A carefully designed computation offloading mechanism is the key to MEC. Besides, it is necessary for cloud centers and edge servers to participate in computation together. Most of the existing researches focus only on a single computation architecture to offload computing tasks and neglect the impact of load balancing on offloading efficiency. In this paper, we consider a cloud-edge-device collaborative computing scenario, leveraging the advantages of different computing levels. In order to direct computing task to service node with sufficient computing resources and avoid edge servers overloading or being idle all the time, we introduce an occupancy table to dynamically track the edge load status. Then we propose a deep Q-network (DQN) based collaborative computation offloading (DQNCCO) method for edge load balancing, jointly minimizing delay, energy consumption and edge load balancing. Experimental results show that the proposed method can balance the use of the whole edge computing resources while realizing suitable fine-grained offloading decisions.","2575-4955","979-8-3503-1792-3","10.1109/IC-NIDC59918.2023.10390728","National Natural Science Foundation of China(grant numbers:62371057,61601046); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10390728","Computation Offloading;Collaborative Computing;Edge Load Balancing;Deep Reinforcement Learning","Performance evaluation;Cloud computing;Multi-access edge computing;Collaboration;Reinforcement learning;Computer architecture;Load management","","","","11","IEEE","23 Jan 2024","","","IEEE","IEEE Conferences"
"OCD: Online Crowdsourced Delivery for On-Demand Food","W. Tu; T. Zhao; B. Zhou; J. Jiang; J. Xia; Q. Li","Department of Urban Informatics, Guangdong Key Laboratory of Urban Informatics, Shenzhen Key Laboratory of Spatial Smart Sensing and Services, the Research Institute of Smart Cities, School of Architecture and Urban Planning, Shenzhen University, Shenzhen, China; Department of Urban Informatics, Guangdong Key Laboratory of Urban Informatics, Shenzhen Key Laboratory of Spatial Smart Sensing and Services, the Research Institute of Smart Cities, School of Architecture and Urban Planning, Shenzhen University, Shenzhen, China; Department of Urban Informatics, Guangdong Key Laboratory of Urban Informatics, Shenzhen Key Laboratory of Spatial Smart Sensing and Services, the Research Institute of Smart Cities, School of Architecture and Urban Planning, Shenzhen University, Shenzhen, China; Department of Urban Informatics, Guangdong Key Laboratory of Urban Informatics, Shenzhen Key Laboratory of Spatial Smart Sensing and Services, the Research Institute of Smart Cities, School of Architecture and Urban Planning, Shenzhen University, Shenzhen, China; Department of Urban Informatics, Guangdong Key Laboratory of Urban Informatics, Shenzhen Key Laboratory of Spatial Smart Sensing and Services, the Research Institute of Smart Cities, School of Architecture and Urban Planning, Shenzhen University, Shenzhen, China; Department of Urban Informatics, Guangdong Key Laboratory of Urban Informatics, Shenzhen Key Laboratory of Spatial Smart Sensing and Services, the Research Institute of Smart Cities, School of Architecture and Urban Planning, Shenzhen University, Shenzhen, China","IEEE Internet of Things Journal","12 Aug 2020","2020","7","8","6842","6854","Online-to-offline (O2O) commerce connecting service providers and individuals to address daily human needs is quickly expanding. In particular, on-demand food, whereby food orders are placed online by customers and delivered by couriers, is becoming popular. This novel urban food application requires highly efficient and scalable real-time delivery services. However, it is difficult to recruit enough couriers and route them to facilitate such food ordering systems. This paper presents an online crowdsourced delivery (OCD) approach for on-demand food. Facilitated by Internet-of-Things and 3G/4G/5G technologies, public riders can be attracted to act as crowdsourced workers delivering food by means of shared bicycles or electric motorbikes. An online dynamic optimization framework comprising order collection, solution generation, and sequential delivery processes is presented. A hybrid metaheuristic solution process integrating the adaptive large neighborhood search and tabu search approaches is developed to assign food delivery tasks and generate high-quality delivery routes in a real-time manner. The crowdsourced riders are dynamically shared among different food providers. Simulated small-scale and real-world large-scale on-demand food delivery instances are used to evaluate the performance of the proposed approach. The results indicate that the presented crowdsourced food delivery approach outperforms traditional urban logistics. The developed hybrid optimization mechanism is able to produce high-quality crowdsourced delivery routes in less than 120 s. The results demonstrate that the presented OCD approach can facilitate city-scale on-demand food delivery.","2327-4662","","10.1109/JIOT.2019.2930984","Basic Research Program of the Shenzhen Science and Technology Innovation Commission(grant numbers:JCJY201803053125113883,JCYJ20170412105839839); National Natural Science Foundation of China(grant numbers:71961137003,41401444); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8822960","Crowdsourcing;heuristics;hybrid optimization;on-demand food delivery;smart cities;urban logistics","Task analysis;Logistics;Crowdsourcing;Optimization;Internet of Things;Real-time systems","","31","","52","IEEE","3 Sep 2019","","","IEEE","IEEE Journals"
"Energy-Efficient Data Aggregation in Low-Power Wireless Networks With Sensors of Discrete Transmission Ranges: A Mathematical Framework for Network Design","E. M. Manuel; V. Pankajakshan; M. T. Mohan","Department of Electronics & Communication Engineering, Indian Institute of Technology Roorkee, Roorkee, India; Department of Electronics & Communication Engineering, Indian Institute of Technology Roorkee, Roorkee, India; Department of Mathematics, Indian Institute of Technology Roorkee, Roorkee, India","IEEE Transactions on Network Science and Engineering","24 Oct 2023","2023","10","6","3858","3870","The advancements in sensor technology and the evolution of new generation technologies such as the Internet of Things have led to extensive deployment of low-power wireless sensor networks for various surveillance and monitoring applications. The volume and velocity of the data generated by a large number of sensors and monitors used in such applications are huge. The harnessing of such Big Data is critical to the real-time control of underlying real-world processes. Future generation networks favor the deployment of sensors with different discrete transmission ranges. Such multiple transmission ranges introduce different connectivity constraints in the network. Advanced strategies are under investigation for designing energy-efficient data aggregation schemes in such connectivity-constrained networks. To aid such works, we introduce a mathematical framework that captures the salient features of low-power networks with sensors of multiple transmission ranges. The proposed framework can serve as a baseline platform to investigate different networking problems in such systems. Further, we consider a cluster-based multihop network with fixed intra-cluster and inter-cluster transmission ranges and address the problem of designing an optimal network configuration for minimizing the data transmission in the network. We model the problem as an integer linear program, which can be applied only to networks of small sizes because of the hardness of the problem. To address the problem in large-scale networks, we design a polynomial-time approximation method using the proposed mathematical framework. The performance of the proposed methods is evaluated under compression schemes based on compressive sensing.","2327-4697","","10.1109/TNSE.2023.3274693","Department of Technical Education, Government of Kerala(grant numbers:1274/2018/H.EDN); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10122132","Approximate method;data aggregation;discrete transmission ranges;low-power networks;mathematical programming","Wireless sensor networks;Sensor phenomena and characterization;Data aggregation;Monitoring;Data communication;Symbols;Energy efficiency;Approximation methods;Low-power electronics;Mathematical programming","","","","32","IEEE","9 May 2023","","","IEEE","IEEE Journals"
"A Novel Strategy to Achieve Bandwidth Cost Reduction and Load Balancing in a Cooperative Three-Layer Fog-Cloud Computing Environment","M. M. Shahriar Maswood; M. R. Rahman; A. G. Alharbi; D. Medhi","Department of Electronics and Communication Engineering, Khulna University of Engineering & Technology, Khulna, Bangladesh; Department of Electronics and Communication Engineering, Khulna University of Engineering & Technology, Khulna, Bangladesh; Department of Electrical Engineering, Faculty of Engineering, Jouf University, Sakaka, Saudi Arabia; Department of Computer Science Electrical Engineering, University of Missouri–Kansas City, Kansas City, USA","IEEE Access","26 Jun 2020","2020","8","","113737","113750","Recently, IoT (Internet of Things) has been an attractive area of research to develop smart home, smart city environment. IoT sensors generate data stream continuously and majority of the IoT based applications are highly delay sensitive. The initially used cloud based IoT services suffers from higher delay and lack of efficient resources utilization. Fog computing is introduced to improve these problems by bringing cloud services near to edge in small scale and distributed nature. This work considers an integrated fog-cloud environment to minimize resource cost and reduce delay to support real-time applications at a lower operational cost. We first present a cooperative three-layer fog-cloud computing environment, and propose a novel optimization model in this environment. This model has a composite objective function to minimize the bandwidth cost and provide load balancing. We consider balancing load in both links' bandwidth and servers' CPU processing capacity level. Simulation results show that our framework can minimize the bandwidth cost and balance the load by utilizing the cooperative environment effectively. We assign weight factors to each objective of the composite objective function to set the level of priority. When minimizing bandwidth cost gets higher priority, at first, the demand generated from the traffic generator sensors continues to be satisfied by the regional capacity of layer-1 fog. If the demand of a region goes beyond the capacity of that region, remaining demand is served by other regions layer-1 fog, then by layer-2 fog, and finally by the cloud. However, when load balancing is the priority, the demand is distributed among these resources to reduce delay. Link level load balancing can reduce the queueing delay of links while server level load balancing can decrease processing delay of servers in an overloaded situation. We further analyzed how the unit bandwidth cost, the average and maximum link utilization, the servers' resources utilization, and the average number of servers used vary with different levels of priority on different objectives. As a result, our optimization formulation allows tradeoff analysis in the cooperative three-layer fog-cloud computing environment.","2169-3536","","10.1109/ACCESS.2020.3003263","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9120013","Fog computing;IoT;optimal resource management;load balancing;task offloading","Servers;Load management;Edge computing;Delays;Bandwidth;Internet of Things;Cloud computing","","41","","32","CCBY","18 Jun 2020","","","IEEE","IEEE Journals"
"Intelligent and Low Overhead Network Synchronization for Large-Scale Industrial IoT Systems in the 6G Era","X. Wang; P. Jia; X. Shen; H. V. Poor","Western University, Canada; Western University, Canada; University of Waterloo, Canada; Princeton University, USA","IEEE Network","6 Sep 2023","2023","37","3","76","84","Holistic temporal coherence among distributed industrial infrastructures enabled by accurate network synchronization is essential for achieving tight orchestration of large-scale Industrial Internet of Things (IIoT) systems. However, the low efficiency and situation agnosticism of conventional synchronization techniques using an inflexible “observing-and-calibrating” approach for clock offset correction are inevitably hindering the performance of many IIoT applications with increasing scale and heterogeneity. In this article, we provide an in-depth analysis of the challenges associated with conventional synchronization schemes over large-scale IIoT systems and then present three promising research directions for achieving intelligent and low overhead IIoT synchronization. Particularly, we first propose a new model-based network synchronization scheme that can proactively enable low overhead clock calibration by leveraging the inherent characteristics of heterogeneous clocks to avoid frequent timestamp exchange. We then design an intelligent device clustering mechanism with a specifically designed synchronization strategy for each group of IIoT devices by jointly exploiting their distinctive synchronization requirements and multi-dimensional device attributes. To leverage the unique characteristics of each oscillator, we analyze historical timestamps to reject unreliable timestamps and identify unreliable devices. Finally, we envision an edge-cloud collaborative network synchronization paradigm to implement the proposed schemes and demonstrate their efficacy in large-scale IIoT systems.","1558-156X","","10.1109/MNET.107.2100631","NSERC(grant numbers:RGPIN2018-06254,I2IPJ 538563-19); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9952198","","Synchronization;Industrial Internet of Things;Clocks;Calibration;Collaboration;Task analysis;Internet","","1","","15","IEEE","15 Nov 2022","","","IEEE","IEEE Magazines"
"Deep RF Device Fingerprinting by Semi-Supervised Learning with Meta Pseudo Time-Frequency Labels","Z. Ren; P. Ren; T. Zhang","School of Information and Communications Engineering, Xi’an Jiaotong University, Xi’an, China; School of Information and Communications Engineering, Xi’an Jiaotong University, Xi’an, China; School of Information and Communications Engineering, Xi’an Jiaotong University, Xi’an, China","2022 IEEE Wireless Communications and Networking Conference (WCNC)","16 May 2022","2022","","","2369","2374","With the ever-increasing growth of wireless communication technologies and the proliferation of the Internet of Things (IoT), intelligent authentication systems to distinguish legitimate devices are of vital importance. These years, deep learning based authentication algorithms have achieved considerable precision by leveraging radio frequency (RF) fingerprints. However, these methods depending on massive labeled data are difficult to apply on large-scale devices identification. In this paper, we propose a novel method using semi-supervised deep learning employing RF fingerprinting with meta pseudo time-frequency labels to improve identification performance in small-scale labeled datasets. We demonstrate how the scale of datasets and the proportion of labeled data influence the accuracy of identification by analyzing a dataset of 40 GB real Long-Term-Evolution (LTE) mobile phone’s raw signals. Experimental results show that compared with the non-convergence of traditional supervised learning with 100 labeled data, our method can achieve the authentication accuracy of 99.86% with the same labeled data. Moreover, when using the same scale of training datasets and labeled half, our approach could obtain authentication accuracy higher than traditional supervised learning. And even 1% labeled data of 900 training data, this method can still obtain the accuracy of 91.25%.","1558-2612","978-1-6654-4266-4","10.1109/WCNC51071.2022.9771750","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9771750","RF fingerprinting;semi-supervised deep learning;short-time Fourier transform;time-frequency image","Radio frequency;Training;Performance evaluation;Time-frequency analysis;Supervised learning;Authentication;Fingerprint recognition","","7","","21","IEEE","16 May 2022","","","IEEE","IEEE Conferences"
"RES: Real-Time Video Stream Analytics Using Edge Enhanced Clouds","M. Ali; A. Anjum; O. Rana; A. R. Zamani; D. Balouek-Thomert; M. Parashar","College of Engineering and Technology, University of Derby, Derby, U.K.; Department of Computer Science, University of Leicester, Leicester, U.K.; Department of Computer Science and Informatics, Cardiff University, Cardiff, U.K.; Rutgers Discovery Informatics Institute (RDI2), Rutgers University, New Brunswick, NJ, USA; Rutgers Discovery Informatics Institute (RDI2), Rutgers University, New Brunswick, NJ, USA; Rutgers Discovery Informatics Institute (RDI2), Rutgers University, New Brunswick, NJ, USA","IEEE Transactions on Cloud Computing","7 Jun 2022","2022","10","2","792","804","With increasing availability and use of Internet of Things (IoT) devices such as sensors and video cameras, large amounts of streaming data is now being produced at high velocity. Applications which require low latency response such as video surveillance, augmented reality and autonomous vehicles demand a swift and efficient analysis of this data. Existing approaches employ cloud infrastructure to store and perform machine learning-based analytics on this data. This centralized approach has limited ability to support real-time analysis of large-scale streaming data due to network bandwidth and latency constraints between data source and cloud. We propose RealEdgeStream (RES) an edge enhanced stream analytics system for large-scale, high performance data analytics. The proposed approach investigates the problem of video stream analytics by proposing (i) filtration and (ii) identification phases. The filtration phase reduces the amount of data by filtering low-value stream objects using configurable rules. The identification phase uses deep learning inference to perform analytics on the streams of interest. The phases consist of stages which are mapped onto available in-transit and cloud resources using a placement algorithm to satisfy the Quality of Service (QoS) constraints identified by a user. We demonstrate that for a 10K element data streams, with a frame rate of 15–100 per second, the job completion in the proposed system takes 49 percent less time and saves 99 percent bandwidth compared to a centralized cloud-only based approach.","2168-7161","","10.1109/TCC.2020.2991748","National Science Foundation(grant numbers:OAC 1640834,OAC 1835661,OAC 1835692,OCE 1745246); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9084281","IoT;edge computing;video stream analytics;real-time analytics;deep learning;software defined networks;big data;cloud computing","Cloud computing;Streaming media;Real-time systems;Bandwidth;Pipelines;Edge computing;Deep learning","","28","","35","IEEE","1 May 2020","","","IEEE","IEEE Journals"
"Greenhouse Monitoring System and Tomato Leaf Disease Classification Using Convolutional Neural Network","K. J.; G. K. C. K.; S. Kailash A.; K. R.; V. S.","Department of Electronics and Communication Engineering, Amrita School of Engineering, Coimbatore Amrita Vishwa Vidyapeetham, India; Department of Electronics and Communication Engineering, Amrita School of Engineering, Coimbatore Amrita Vishwa Vidyapeetham, India; Department of Electronics and Communication Engineering, Amrita School of Engineering, Coimbatore Amrita Vishwa Vidyapeetham, India; Department of Electronics and Communication Engineering, Amrita School of Engineering, Coimbatore Amrita Vishwa Vidyapeetham, India; Department of Electronics and Communication Engineering, Amrita School of Engineering, Coimbatore Amrita Vishwa Vidyapeetham, India","2023 IEEE 3rd Mysore Sub Section International Conference (MysuruCon)","24 Jan 2024","2023","","","1","8","The greenhouse automation system helps the workers to maintain and monitor the greenhouse instead of doing manually which leads to human errors, human fatigue, and high expense due to the large-scale variety of plants grown in the greenhouse and labour expenses. Plants in greenhouses can be affected by diseases which reduces income as well as yield. These diseases can be detected using automated systems. In this paper, automation, alert, and monitoring system is designed. The automation system includes sensing of temperature, humidity, soil moisture, and water level. The alert system includes fire alerts and water alerts. When the water level in the tank falls below a threshold point, or in case of an emergency like a fire outburst, the user will be indicated immediately through a text message in his/her mobile phone which is the function of the alert system. The monitoring system includes taking images and uploading them periodically to the cloud as well as identifying and classifying the diseases in leaves. This is done by using sensors and actuators in the Internet of Things (IoT) like Raspberry Pi, DHT22, soil moisture, and water level sensors. Raspberry Pi is programmed to control the actuators accordingly which include fans, heating bulbs, humidifiers and the water pump. Identification and classification of diseases are done by using convolutional neural networks (CNN) architectures like VGG 19, MobileNet V2, ResNet 152 V2, DenseNet 201, and Inception V3 evaluated on the plant village dataset. As a result, this model has achieved a maximum accuracy of 96.53% for DenseNet 201 Therefore, without direct supervision, the workers can monitor and manage the greenhouse by using this automated technology.","","979-8-3503-4035-8","10.1109/MysuruCon59703.2023.10396989","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10396989","Greenhouse;Internet of Things (IoT);DHT22;Sensor;Actuator;Raspberry Pi;Convolutional Neural Network (CNN)","Temperature sensors;Temperature measurement;Automation;Sensors;Convolutional neural networks;Monitoring;Diseases","","","","18","IEEE","24 Jan 2024","","","IEEE","IEEE Conferences"
"Denoising Signals on the Graph for Distributed Systems by Secure Outsourced Computation","Z. Wang; J. Guo","Department of Electrical and Computer Engineering, California State University, Chico, Chico, CA; Department of Mathematics and Statistics, California State University, Chico, Chico, CA","2021 IEEE 7th World Forum on Internet of Things (WF-IoT)","9 Nov 2021","2021","","","524","529","The burgeoning networked computing devices create many distributed systems and generate new signals on a large scale. Many Internet of Things (IoT) applications, such as peer-to-peer streaming of multimedia data, crowdsourcing, and measurement by sensor networks, can be modeled as a form of big data. Processing massive data calls for new data structures and algorithms different from traditional ones designed for small-scale problems. For measurement from networked distributed systems, we consider an essential data format: signals on graphs. Due to limited computing resources, the sensor nodes in the distributed systems may outsource the computing tasks to third parties, such as cloud platforms, arising a severe concern on data privacy. A de-facto solution is to have third parties only process encrypted data. We propose a novel and efficient privacy-preserving secure outsourced computation protocol for denoising signals on the graph based on the information-theoretic secure multi-party computation (ITS-MPC). Denoising the data makes paths for further meaningful data processing. From experimenting with our algorithms in a testbed, the results indicate a better efficiency of our approach than a counterpart approach with computational security.","","978-1-6654-4431-6","10.1109/WF-IoT51360.2021.9595245","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9595245","","Cloud computing;Protocols;Noise reduction;Distributed databases;Streaming media;Data structures;Computational efficiency","","1","","36","IEEE","9 Nov 2021","","","IEEE","IEEE Conferences"
"Mitigating Load-Altering Attacks Against Power Grids Using Cyber-Resilient Economic Dispatch","Z. Chu; S. Lakshminarayana; B. Chaudhuri; F. Teng","Department of Electrical and Electronic Engineering, Imperial College London, London, U.K; School of Engineering, University of Warwick, Coventry, U.K; Department of Electrical and Electronic Engineering, Imperial College London, London, U.K; Department of Electrical and Electronic Engineering, Imperial College London, London, U.K","IEEE Transactions on Smart Grid","21 Jun 2023","2023","14","4","3164","3175","Large-scale Load-Altering Attacks (LAAs) against Internet-of-Things (IoT) enabled high-wattage electrical appliances pose a serious threat to power system security and stability. This paper investigates, for the first time, the optimal mitigation strategy from a system perspective against such attacks. In particular, a Cyber-Resilient Economic Dispatch (CRED) concept is proposed and seamlessly integrated with attack detection and identification to form a cyber resiliency enhancement framework. Instead of only relying on local resources, CRED coordinates the frequency droop control gains of Inverter-Based Resources (IBRs) in the system to mitigate the destabilizing effect of LAAs while minimizing the overall operational cost. To achieve this, the LAA-inclusive system frequency dynamics is formulated and the corresponding system stability constraints are explicitly derived based on parametric sensitivities, which are further incorporated into the system scheduling model with minimum error through a novel recursive linearization method. In addition, a distributionally robust approach is proposed to account for the uncertainty associated with system dynamics driven by the LAA detection/parameter estimation errors. The overall performance of the proposed CRED model is demonstrated through extensive simulations in a modified IEEE reliability test system.","1949-3061","","10.1109/TSG.2022.3231563","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9997100","Economic dispatch;cyber-resilience;load altering attacks;system stability;sensitivity analysis","Power system stability;Power system dynamics;Power grids;Security;Load modeling;Frequency control;Fluctuations","","3","","32","IEEE","22 Dec 2022","","","IEEE","IEEE Journals"
"A Blockchain-Based Interoperable Architecture for IoT with Selective Disclosure of Information","R. Mukta; S. Pal; S. Mishra; H. -Y. Paik; S. S. Kanhere; M. Hitchens","School of Computer Science and Engineering, University of New South Wales, Sydney, Australia; School of Information Technology, Deakin University, Melbourne, Australia; School of Computer and Communication Sciences, École Polytechnique Fédérale de Lausanne (EPFL), Switzerland; School of Computer Science and Engineering, University of New South Wales, Sydney, Australia; School of Computer Science and Engineering, University of New South Wales, Sydney, Australia; School of Computing, Macquarie University, Sydney, Australia","2023 IEEE 28th Pacific Rim International Symposium on Dependable Computing (PRDC)","21 Dec 2023","2023","","","53","63","With the improvement of Internet of Things (IoT) technologies, services, and applications, there is a proliferation of access to smart devices in everyday life. However, granting access and controlling access rights for each resource is challenging in highly dynamic and large-scale IoT deployments. In particular, multiple access information may need to be provided to an entity when granting access rights to several resources. The situation becomes more complex when an entity is required to share its identity attribute to receive the access information. These raise the question of what identity information an entity needs to provide to obtain the required access to a particular resource and, subsequently, what access information needs to be provided when accessing that resource. That said, there is a need for a flexible approach where an entity can share a distinct identity and access attributes for accessing a resource without revealing additional information. Such flexibility in sharing information is significant given the privacy risk of an entity’s identity. This paper presents an architecture that delivers access rights to an entity with selective disclosure of information. Our approach ensures the minimum exchange of information (identity and access attribute) to enhance an entity’s privacy when granting access rights to an entity. We use blockchain to provide data authenticity (i.e., tamper-proof), transparency and automatic execution of access rights based on shared attributes using smart contracts. We implement a proof of concept of the proposed system using Hyperledger fabric as a permissioned blockchain network. Our results demonstrate the feasibility of the proposed system showing efficiency in granting access rights.","2473-3105","979-8-3503-5876-6","10.1109/PRDC59308.2023.00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10356491","Internet of Things;Access Control;Selective Disclosure of Information;Identity;Capability;Blockchain","Privacy;Distributed ledger;Smart contracts;Computer architecture;Permission;Dynamic scheduling;Fabrics","","","","35","IEEE","21 Dec 2023","","","IEEE","IEEE Conferences"
"A Response-Aware Traffic Offloading Scheme Using Regression Machine Learning for User-Centric Large-Scale Internet of Things","G. Manogaran; G. Srivastava; B. A. Muthu; S. Baskar; P. Mohamed Shakeel; C. -H. Hsu; A. K. Bashir; P. M. Kumar","Computer and Information Science, Gannon University, Erie, PA, USA; Department of Math and CSC, Brandon University, Brandon, Canada; Department of Computer Science and Engineering, VRS College of Engineering and Technology, Arasur, India; Department of Electronics and Communication Engineering, Karpagam Academy of Higher Education, Coimbatore, India; Faculty of Information and Communication Technology, University of Technical Malaysia, Malacca, Malaysia; Department of Computer Science and Information Engineering, Asia University, Taichung, Taiwan; Department of Computing and Mathematics, Manchester Metropolitan University, Manchester, U.K.; Department of Computer Science and Engineering, Kyung Hee University, Seoul, South Korea","IEEE Internet of Things Journal","18 Feb 2021","2021","8","5","3360","3368","Resource allocation and management in an Internet-of-Things (IoT) paradigm requires precise request and response processing irrespective of its scalability support. Unpredictable traffic patterns and user density demands reliable offloading for handling user request traffic and service response. Considering the need for large-scale IoT in an account of its interoperability and heterogeneous support, this manuscript introduces a response-aware traffic offloading scheme (RTOS) for delay-sensitive user requests. This offloading scheme is supported by a multivariate spline regression machine learning model for classifying traffic for reducing the failure rate. The splines are adaptive based on the classified traffic for performing independent and shared offloading. The computation process for determining the offloading model is inherited from the cyber-physical system (CPS) coupled with the IoT-Cloud architecture. The information from the knowledge base and event logs are exploited for decision making in employing the offloading method for the classified traffic. The simulation analysis of this scheme shows that it is effective in improving the request processing ratio and reducing processing, response time, and delay. The simulation is performed for the varying user density and traffic flows.","2327-4662","","10.1109/JIOT.2020.3022322","Natural Science and Engineering Research Council of Canada (NSERC)(grant numbers:RGPIN-2020-05363); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9187266","Basis function;cyber–physical systems (CPSs);Internet of Things (IoT);multivariate spline regression;traffic offloading","Task analysis;Resource management;Computer architecture;Job shop scheduling;Cloud computing;Internet of Things;Reliability","","28","","28","IEEE","7 Sep 2020","","","IEEE","IEEE Journals"
"6LE-SDN: An Edge-Based Software-Defined Network for Internet of Things","R. K. Das; N. Ahmed; F. H. Pohrmen; A. K. Maji; G. Saha","Department of Information Technology, North–Eastern Hill University, Shillong, India; Department of Information Technology, North–Eastern Hill University, Shillong, India; Department of Information Technology, North–Eastern Hill University, Shillong, India; Department of Information Technology, North–Eastern Hill University, Shillong, India; Department of Information Technology, North–Eastern Hill University, Shillong, India","IEEE Internet of Things Journal","12 Aug 2020","2020","7","8","7725","7733","IPv6 over low-power wireless personal area network (6LoWPAN) has been widely used for large-scale sensing and actuating purposes in the Internet of Things (IoT). Though promising, many challenges, such as high latency, heterogeneity, and packet loss persist. To mitigate these challenges, the software-defined network (SDN) technique can be hybridized with existing IoT structures that can address many of them. In this article, we propose an approach-edge-based 6LoWPAN-SDN (6LE-SDN) architecture, which can improve the system limitations mentioned. It uses an edge-based computational capability to improve the network performance over 6LoWPAN. To reduce heterogeneity, we develop a hybrid-edge switch that helps to enable communication among 6LoWPAN and SDN entities. For efficient communication between different devices, a new protocol-edge-based 6LoWPAN-SDN protocol (6LE-SDNP) is proposed, which is capable of ensuring optimal routing of the packet for efficient communication among the devices. We use the SDN-based edge controller for reducing the latency of the network apart from improving the interoperability feature. The testbed evaluation of the proposed solution indicates satisfactory performance in terms of reducing latency by 60% and network overhead by 91%. The 6LE-SDN network also succeeded in reducing the average round trip time (RTT) by 31% and the packet loss by 70% as compared to that of the traditional 6LoWPAN-based IoT.","2327-4662","","10.1109/JIOT.2020.2990936","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9080075","Edge computing;heterogeneity;Internet of Things (IoT);IPv6 over low-power wireless personal area network (6LoWPAN);openflow;software-defined network (SDN)","Switches;Protocols;Computer architecture;Internet of Things;Delays;Performance evaluation","","20","","32","IEEE","28 Apr 2020","","","IEEE","IEEE Journals"
"An Experimental Study on Microservices based Edge Computing Platforms","Q. Qu; R. Xu; S. Y. Nikouei; Y. Chen","Dept. of Electrical & Computer Engineering, Binghamton University, SUNY, Binghamton, NY, USA; Dept. of Electrical & Computer Engineering, Binghamton University, SUNY, Binghamton, NY, USA; Dept. of Electrical & Computer Engineering, Binghamton University, SUNY, Binghamton, NY, USA; Dept. of Electrical & Computer Engineering, Binghamton University, SUNY, Binghamton, NY, USA","IEEE INFOCOM 2020 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)","10 Aug 2020","2020","","","836","841","The rapid technological advances in the Internet of Things (IoT) allows the blueprint of Smart Cities to become feasible by integrating heterogeneous cloud/fog/edge computing paradigms to collaboratively provide variant smart services in our cities and communities. Thanks to attractive features like fine granularity and loose coupling, the microservices architecture has been proposed to provide scalable and extensible services in large scale distributed IoT systems. Recent studies have evaluated and analyzed the performance interference between microservices based on scenarios on the cloud computing environment. However, they are not holistic for IoT applications given the restriction of the edge device like computation consumption and network capacity. This paper investigates multiple microservice deployment policies on edge computing platform. The microservices are developed as docker containers, and comprehensive experimental results demonstrate the performance and interference of microservices running on benchmark scenarios.","","978-1-7281-8695-5","10.1109/INFOCOMWKSHPS50562.2020.9163068","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9163068","Edge Computing;Internet of Things (IoT);Microservices Architecture;Container","Containers;Benchmark testing;Performance evaluation;Cloud computing;Computer architecture;Edge computing;Service-oriented architecture","","14","","36","IEEE","10 Aug 2020","","","IEEE","IEEE Conferences"
"LoRa-SDN: Providing Wireless IoT Edge Network Functions via SDN","F. Holik; U. Roedig; N. Race","Faculty of Electrical Engineering and Informatics, University of Pardubice, Pardubice, Czech Republic; School of Computer Science and Information Technology, University College Cork, Cork, Ireland; School of Computing and Communications, Lancaster University, Lancaster, United Kingdom","2020 43rd International Convention on Information, Communication and Electronic Technology (MIPRO)","6 Nov 2020","2020","","","1795","1800","Large-scale Internet of Things (IoT) deployments such as smart cities and smart grids are becoming a reality. In these topologies, extensive numbers of wireless devices transmit data to gateways that forward the collected data to back-end systems over a fixed network infrastructure - the core network. It is expected that in the near future the core network will utilize software-defined networking (SDN), as has already happened in data centres and networks of service providers. This enables simplified deployment of network functions and dynamic reactions to observed network conditions. This paper explores how SDN mechanisms can be applied beyond the traditional core network to include wireless IoT edge networks as well. The most popular IoT technology - Long Range (LoRa) - was selected as the main use case technology. The paper describes the LoRa integration with SDN and proposes the LoRa-SDN integration architecture.","2623-8764","978-953-233-099-1","10.23919/MIPRO48935.2020.9245378","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9245378","LoRa;SDN;IoT;wireless edge networks","Wireless communication;Protocols;Smart cities;Computer architecture;Switches;Software;Communication system security","","3","","29","","6 Nov 2020","","","IEEE","IEEE Conferences"
"Is LoRaWAN Really Wide? Fine-grained LoRa Link-level Measurement in An Urban Environment","Y. Ren; L. Liu; C. Li; Z. Cao; S. Chen",Michigan State University; Michigan State University; Michigan State University; Michigan State University; University of Florida,"2022 IEEE 30th International Conference on Network Protocols (ICNP)","14 Nov 2022","2022","","","1","12","Internet-of-Things (IoT) aims to connect billions of low-date rate and energy-constrained end-devices in the near future. Although many IoT systems have been commercialized, most of them focus on home and body scale applications. To establish a low-cost IoT at the city scale, LoRa Wide Area Networks (LoRaWAN) have become attractive in recent years due to their desirable kilometer or even longer communication distance with low energy consumption. However, due to the expensive cost of densely deploying end-nodes, the understanding of LoRa link behavior is still coarse-grained, and hard to fully realize the link dynamics, networking coverage, and localization accuracy of LoRaWAN in an urban environment. This paper shows a fine-grained LoRa link-level measurement via mobile end-nodes. We deploy two gateways and six mobile end-nodes and collect data packets over four months at a $6\times 6\ km^{2}$ urban area. The evaluation mainly focuses on answering three questions: 1) Does a LoRa link stably perform in both spatial and temporal dimensions? 2) How large area can be covered for reliable communication by each gateway in the urban environment? 3) What accuracy can be achieved to localize an end-node through LoRa links? According to our measurement, our key findings are 1) The spatial and temporal behavior of LoRa links is quite dynamic due to the different types of land covers and the frequent micro-environment changes in the urban areas; 2) Each gateway can cover about 11.3 km2 area and marginal SNR gains (e.g., 2 dB) of LoRa links are efficient enough to enlarge 32.6% coverage area of a gateway; and 3). The median localization error is about 400 m. Without densely deployed LoRa gateways, the SOTA LoRa localization can support road-level localization, even when an end node is close to one of the gateways.","2643-3303","978-1-6654-8234-9","10.1109/ICNP55882.2022.9940375","NSF(grant numbers:CNS-1909177); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9940375","","Location awareness;Wide area networks;Protocols;Urban areas;Logic gates;Gain measurement;Behavioral sciences","","6","","53","IEEE","14 Nov 2022","","","IEEE","IEEE Conferences"
"IoT-Enabled Automatic Synthesis of Distributed Feedback Control Schemes in Smart Buildings","G. M. Milis; C. G. Panayiotou; M. M. Polycarpou","PHOEBE Research and Innovation Ltd., Nicosia, Cyprus; Department of Electrical and Computer Engineering, KIOS Research and Innovation Center of Excellence, University of Cyprus, Nicosia, Cyprus; Department of Electrical and Computer Engineering, KIOS Research and Innovation Center of Excellence, University of Cyprus, Nicosia, Cyprus","IEEE Internet of Things Journal","5 Feb 2021","2021","8","4","2615","2626","There is currently a rapid evolution of technologies enabling the “Internet-of-Things” paradigm, which leads to the design of systems with augmented sensing, analysis, and actuation capabilities. The intelligent control research community is beginning to recognize the challenge of designing flexible and adaptable control systems that will take advantage of the online evolution of the number and types of “things” in a large-scale system. Responding to this challenge, in a previous article, we designed and presented a semantically enhanced control system supervisor that integrates a knowledge graph and deductive inference capabilities, to achieve the online (re)configuration of feedback control schemes. In this article, we show that by exploiting the capabilities of this supervisor, we facilitate the automatic synthesis and plugging of model-based controllers for the space heating problem in multizone buildings. The supervisor retrieves stored knowledge about the building and the available control system components and uses it to configure online a scheme of distributed feedback controllers, one per building zone. The controllers are designed to utilize information online and optimally allocate the control signal to multiple heating devices in each building zone.","2327-4662","","10.1109/JIOT.2020.3019662","European Union’s Horizon 2020 Research and Innovation Programme(grant numbers:739551 (KIOS CoE)); Government of the Republic of Cyprus through the Directorate General for European Programmes, Coordination and Development; Cyprus Research and Innovation Foundation(grant numbers:ENTERPRISES/0618/0132 (Domognostics+)); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9178361","Cyber–physical systems (CPSs);semantic data and services;service-oriented architecture","Buildings;Heating systems;Internet of Things;Feedback control;Architecture;Technological innovation","","5","","29","IEEE","26 Aug 2020","","","IEEE","IEEE Journals"
"DLSTM: Distributed Long Short-Term Memory Neural Networks for the Internet of Things","G. Wen; J. Qin; X. Fu; W. Yu","Department of Systems Science, School of Mathematics, Southeast University, Nanjing, China; Department of Systems Science, School of Mathematics, Southeast University, Nanjing, China; School of Cyber Science and Engineering, Southeast University, Nanjing, China; Department of Systems Science, School of Mathematics, Southeast University, Nanjing, China","IEEE Transactions on Network Science and Engineering","12 Jan 2022","2022","9","1","111","120","Although the development of Internet of Things (IoT) provides a significant boost for the applications of deep learning algorithms, it is generally hard to fully implement the deep learning algorithms by IoT devices due to their limited calculation capacity. The problem could be alleviated by deploying the deep learning algorithms with edge computing. Herein, in this article, we propose a kind of distributed long short-term memory (DLSTM) neural networks and deploy them on the IoT environment to handle the large-scale spatiotemporal correlation regression tasks. Specifically, the presented DLSTM neural networks adopt the collaborative computing architecture with the terminals, edges and cloud, in order to realize the lightweight deep learning on the IoT devices and improve the learning efficiency. The generalization ability of LSTM neural networks is promoted through introducing the distributed memory cells to implement the information sharing between different edge servers and employing the attention mechanism in LSTM neural networks. Meanwhile, the deep fully connected networks are deployed among the cloud to extract the spatiotemporal correlations in the variety of data from different time and space regions, which enhances the transferability of LSTM neural networks. Numerical experiment shows that the proposed DLSTM neural networks reduce 36% model parameters size, 32% memory consumption among the cloud, and more than half of the prediction errors compared with traditional LSTM neural networks. Besides, the favourable transferability of the present DLSTM neural networks is also verified via numerical experiment.","2327-4697","","10.1109/TNSE.2021.3054244","National Natural Science Foundation of China(grant numbers:62073079); Six Talent Peaks of Jiangsu Province(grant numbers:2019-DZXX-006); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9335488","Deep learning;distributed long short-term memory;edge computing;Internet of Things.","Neural networks;Servers;Deep learning;Internet of Things;Cloud computing;Logic gates;Computational modeling","","9","","25","IEEE","25 Jan 2021","","","IEEE","IEEE Journals"
"A Spatiotemporal Model for Hard-Deadline Multistream Traffic in Uplink IoT Networks","W. Tang; R. Zhang; S. Feng","School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; Department of Electronic and Information Engineering, Shantou University, Shantou, China; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China","IEEE Internet of Things Journal","22 Dec 2021","2022","9","1","601","615","Ultrareliable and delay-intolerant message delivery is one of the key components for Internet of Things (IoT) and cyber–physical systems to support real-time control and real-time interaction. In this article, we provide a spatiotemporal framework that captures the packet loss rate (PLR) for large-scale grant-free uplink IoT networks with multiple types of hard-deadline traffic. An independent and a prioritized packet scheduling schemes are proposed and investigated for efficiently realizing frequency diversity. Tools from stochastic geometry and queuing theory are utilized to account for the macroscopic coverage probability and microscopic PLR. The expressions of devices’ coverage, steady state distribution, and PLR of services are derived for both scheduling schemes. Detailed system-level simulations are used to identify network design guidelines. The results show that the independent scheme provides better network scalability and consumes lower average transmit power at the devices, while the prioritized scheme enhances the PLR performance of high priority service and requires lower peak transmit power of devices.","2327-4662","","10.1109/JIOT.2021.3085899","China Postdoctoral Science Foundation(grant numbers:2020M672629); Fundamental Research Funds for the Central Universities; Scientific Research Foundation for Talents of Shantou University(grant numbers:NTF21024); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9446476","Grant-free access;hard deadlines;Internet of Things (IoT);priority queuing;stochastic geometry","Internet of Things;Uplink;Spatiotemporal phenomena;Performance evaluation;Ultra reliable low latency communication;Scalability;Quality of service","","1","","45","IEEE","3 Jun 2021","","","IEEE","IEEE Journals"
"An Advanced Intrusion Detection System for IIoT Based on GA and Tree Based Algorithms","S. M. Kasongo","Department of Industrial Engineering, Stellenbosch University, Stellenbosch, South Africa","IEEE Access","18 Aug 2021","2021","9","","113199","113212","The evolution of the Internet and cloud-based technologies have empowered several organizations with the capacity to implement large-scale Internet of Things (IoT)-based ecosystems, such as Industrial IoT (IIoT). The IoT and, by virtue, the IIoT, are vulnerable to new types of threats and intrusions because of the nature of their networks. So it is crucial to develop Intrusion Detection Systems (IDSs) that can provide the security, privacy, and integrity of IIoT networks. In this research, we propose an IDS for IIoT that was implemented using the Genetic Algorithm (GA) for feature selection, and the Random Forest (RF) model was employed in the GA fitness function. The models used for the intrusion detection processes include classifiers such as the RF, Linear Regression (LR), Naïve Bayes (NB), Decision Tree (DT), Extra-Trees (ET), and Extreme Gradient Boosting (XGB). The GA-RF generated 10 feature vectors for the binary classification scheme and 7 feature vectors for the multiclass classification procedure. The UNSW-NB15 is used to assess the effectiveness and the robustness of our proposed approach. The experimental outcomes demonstrated that for the binary modeling process, the GA-RF achieved a test accuracy (TAC) of 87.61% and an Area Under the Curve (AUC) of 0.98, using a feature vector that contained 16 features. These results were superior to existing IDS frameworks.","2169-3536","","10.1109/ACCESS.2021.3104113","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9511416","Internet of Things;intrusion detection;genetic algorithm;machine learning","Industrial Internet of Things;Feature extraction;Intrusion detection;Genetic algorithms;Radio frequency;Support vector machines;Random forests","","53","","54","CCBY","11 Aug 2021","","","IEEE","IEEE Journals"
"Cache-Aided MEC for IoT: Resource Allocation Using Deep Graph Reinforcement Learning","D. Wang; Y. Bai; G. Huang; B. Song; F. R. Yu","State Key Laboratory of Integrated Services Networks, Xidian University, Xi’an, China; State Key Laboratory of Integrated Services Networks, Xidian University, Xi’an, China; Zhejiang Laboratory, Hangzhou, China; State Key Laboratory of Integrated Services Networks, Xidian University, Xi’an, China; Department of Systems and Computer Engineering, Carleton University, Ottawa, Canada","IEEE Internet of Things Journal","22 Jun 2023","2023","10","13","11486","11496","With the growing demand for latency-sensitive and compute-intensive services in the Internet of Things (IoT), multiaccess edge computing (MEC)-enabled IoT is envisioned as a promising technique that allows network nodes to have computing and caching capabilities. In this article, we propose a cache-aided MEC (CA-MEC) offloading framework for joint optimization of communication, computing, and caching (3C) resources in the MEC-enabled IoT. Our goal is to optimize the offloading decision and resource allocation strategy to minimize the system latency subject to dynamic cache capacities and computing resource constraints. We first formulate this optimization problem as a multiagent decision problem, a partially observable Markov decision process (POMDP). Then, the deep graph convolution reinforcement learning (DGRL) method is applied to motivate the agents to learn optimal strategies cooperatively in a highly dynamic environment. Simulations show that our method is highly effective for computation offloading and resource allocation and performs superior results in a large-scale network.","2327-4662","","10.1109/JIOT.2023.3244909","National Natural Science Foundation of China(grant numbers:62201419,62071354,52007173); Key Research and Development Projects of Shaanxi Province(grant numbers:2022ZDLGY05-08); Open Research Projects of Zhejiang Lab(grant numbers:2019KD0AD01/013); State Key Laboratory of Integrated Services Networks; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10044184","Computation offloading;deep reinforcement learning;graph convolutional network;Internet of Things (IoT);multiaccess edge computing (MEC)","Resource management;Task analysis;Servers;Internet of Things;Optimization;Reinforcement learning;Graph neural networks","","","","43","IEEE","14 Feb 2023","","","IEEE","IEEE Journals"
"LP-SBA-XACML: Lightweight Semantics Based Scheme Enabling Intelligent Behavior-Aware Privacy for IoT","M. Chehab; A. Mourad","Department of Computer Science and Mathematics, Lebanese American University, Beirut, Lebanon; Department of Computer Science and Mathematics, Lebanese American University, Beirut, Lebanon","IEEE Transactions on Dependable and Secure Computing","14 Jan 2022","2022","19","1","161","175","The broad applicability of Internet of Things (IoT) would truly enable the pervasiveness of smart devices for sensing data. In this context, achieving service personalization requires collecting sensitive data about users. That yields to privacy concerns due to the possibility of abusing the data through unauthorized access. Moreover, IoT devices have limited computing resources, making them difficult to perform heavy protection mechanisms. Despite several existing solutions for privacy protection, they were not designed to run on limited resources in large scale environment. In addition, existing access control solutions, including XACML, are heavy to run on resource constraint devices and lack behavior-based customization of user privacy where users have little to no control over their private data. In this regard, we address the aforementioned problems by proposing LP-SBA-XACML, which embeds an efficient and lightweight semantics-based scheme targeting user privacy and providing efficient policy evaluation. LP-SBA-XACML is a scalable and lightweight solution suitable for the IoT context while preserving the assumptions of XACML. Moreover, an intelligent model for real-time behavior/activity prediction is integrated to systematically customize user’s privacy and services. Experiments conducted on synthetic and real-life scenarios demonstrate the feasibility and relevance of our proposed framework within a mobile IoT resource-constrained environment.","1941-0018","","10.1109/TDSC.2020.2999866","Lebanese American University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9107456","Machine learning;deep learning, access control;customized user privacy;behavior based privacy;IoT;XACML;limited resource devices","Privacy;Internet of Things;Data privacy;Authorization;Performance evaluation","","13","","49","IEEE","3 Jun 2020","","","IEEE","IEEE Journals"
"Attacking and Protecting Data Privacy in Edge–Cloud Collaborative Inference Systems","Z. He; T. Zhang; R. B. Lee","Department of Electrical Engineering, Princeton University, Princeton, NJ, USA; School of Computer Science and Engineering, Nanyang Technological University, Singapore; Department of Electrical Engineering, Princeton University, Princeton, NJ, USA","IEEE Internet of Things Journal","4 Jun 2021","2021","8","12","9706","9716","Benefiting from the advance of deep learning (DL) technology, Internet-of-Things (IoT) devices and systems are becoming more intelligent and multifunctional. They are expected to run various DL inference tasks with high efficiency and performance. This requirement is challenged by the mismatch between the limited computing capability of edge devices and large-scale deep neural networks. Edge-cloud collaborative systems are then introduced to mitigate this conflict, enabling resource-constrained IoT devices to host arbitrary DL applications. However, the introduction of third-party clouds can bring potential privacy issues to edge computing. In this article, we conduct a systematic study about the opportunities of attacking and protecting the privacy of edge-cloud collaborative systems. Our contributions are twofold: 1) we first devise a set of new attacks for an untrusted cloud to recover arbitrary inputs fed into the system, even if the attacker has no access to the edge device's data or computations, or permissions to query this system and 2) we empirically demonstrate that solutions that add noise fail to defeat our proposed attacks, and then propose two more effective defense methods. This provides insights and guidelines to develop more privacy-preserving collaborative systems and algorithms.","2327-4662","","10.1109/JIOT.2020.3022358","NSF STARSS(grant numbers:1526493); a research gift from Siemens; Singapore MoE AcRF Tier1(grant numbers:RS02/19); Qualcomm Faculty Award; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9187880","Artificial intelligence;collaborative inference;edge–cloud computing;security and privacy","Cloud computing;Collaboration;Data privacy;Machine learning;Privacy;Internet of Things;Performance evaluation","","25","","53","IEEE","8 Sep 2020","","","IEEE","IEEE Journals"
"Cybersecurity Analysis of Data-Driven Power System Stability Assessment","Z. Zhang; K. Zuo; R. Deng; F. Teng; M. Sun","State Key Laboratory of Public Big Data and College of Computer Science and Technology, Guizhou University, Guiyang, China; State Key Laboratory of Industrial Control Technology and the College of Control Science and Engineering, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology and the College of Control Science and Engineering, Zhejiang University, Hangzhou, China; Department of Electrical and Electronic Engineering, Imperial College London, London, U.K.; State Key Laboratory of Industrial Control Technology and the College of Control Science and Engineering, Zhejiang University, Hangzhou, China","IEEE Internet of Things Journal","23 Aug 2023","2023","10","17","15723","15735","Machine learning-based intelligent systems enhanced with Internet of Things (IoT) technologies have been widely developed and exploited to enable the real-time stability assessment of a large-scale electricity grid. However, it has been extensively recognized that the IoT-enabled communication network of power systems is vulnerable to cyberattacks. In particular, system operating states, critical attributes that act as input to the data-driven stability assessment, can be manipulated by malicious actors to mislead the system operator into making disastrous decisions and thus cause major blackouts and cascading events. In this article, we explore the vulnerability of the data-driven power system stability assessment, with a special emphasis on decision tree-based stability assessment (DTSA) approaches, and investigate the feasibility of constructing a physics-constrained adversarial attack (PCAA) to undermine the DTSA. The PCAA is formulated as a nonlinear programming problem considering the misclassification constraint, power limits, and bad data detection, computing potential adversarial perturbations that reverse the “stable/unstable” prediction of the real-time input while remaining invisible/stealthy. Extensive experiments based on the IEEE 68-bus system are conducted to evaluate the impact of PCAAs on predictions of DTSA and their transferability.","2327-4662","","10.1109/JIOT.2023.3264492","National Natural Science Foundation of China(grant numbers:62103371); Guizhou Provincial Science and Technology(grant numbers:ZK[2022]149); Natural Science Special Foundation of Guizhou University(grant numbers:[2021]47); Guizhou Provincial Research Project (Youth) for Universities(grant numbers:[2022]104); GZU Cultivation Project of NSFC(grant numbers:[2020]80); National Natural Science Foundation of China(grant numbers:62293503,62073285); Natural Science Foundation of Zhejiang Province(grant numbers:LR23F030001,LZ21F020006); Xiaomi Foundation, the Fundamental Research Funds for the Central Universities(grant numbers:226-2022-00120); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10100624","Adversarial examples;cyber security;decision trees (DTs);physics-constrained machine learning (ML);transient stability assessment (TSA)","Power system stability;Stability criteria;Power measurement;Perturbation methods;Voltage measurement;Phasor measurement units;Transmission line measurements","","1","","47","IEEE","11 Apr 2023","","","IEEE","IEEE Journals"
"Reliability and Security of CR-STAR-RIS-NOMA Assisted IoT Networks","X. Li; J. Zhang; C. Han; W. Hao; M. Zeng; Z. Zhu; H. Wang","School of Physics and Electronic Information Engineering, Henan Polytechnic University, China; School of Physics and Electronic Information Engineering, Henan Polytechnic University, China; Institute of atmospheric physics, Key Laboratory of Atmospheric Environment and Extreme Meteorology, Chinese Academy of Sciences, Beijing, China; School of Electrical and Information Engineering, Zhengzhou University, Zhengzhou, China; Department of Electrical Engineering and Computer Engineering, Universit Laval, Quebec, QC, Canada; School of Electrical and Information Engineering, Zhengzhou University, Zhengzhou, China; College of Physical Science and Engineering, Yichun University, Yichun, China","IEEE Internet of Things Journal","","2023","PP","99","1","1","The Internet-of-Things (IoT) has greatly facilitated our daily lives. Nevertheless, how to achieve higher spectral efficiency, large-scale device access, and lower latency for the next-generation IoT is still a challenge. Inspired by this, a non-orthogonal multiple access (NOMA) assisted cognitive radio (CR) IoT network is proposed in this paper, where the communication between the indoor secondary transmitter and secondary receivers is performed in the presence of an eavesdropper and under the constraint of secondary transmit power. In particular, we introduce simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) into the secondary network to assist the secondary transmitter to communicate with its receivers in different rooms. To characterize the reliability and security of the proposed system, we derive analytical approximate expressions for the outage probabilitys (OPs) and intercept probabilitys (IPs) by using Gaussian-Chebyshev quadrature. With the aim of providing a deeper understanding, we also explore the impacts of transmission signal-to-noise ratios (SNRs), power allocation coefficient and the number of STAR-RIS elements on the system performance. Presented numerical results show that: 1) the OPs of near and far users gradually decrease with SNRs until floors appear at high SNR, and the floors of near user is always lower than that of far user; 2) IPs increasing with SNRs and near user is always less than far user, which proves that near user has better security; 3) under appropriate parameters, the trade-off between reliability and security of the considered system can be arisen.","2327-4662","","10.1109/JIOT.2023.3340371","Key Laboratory of Middle Atmosphere and Global environment Observation (LAGEO) Institute of Atmospheric Physics, Chinese Academy of Sciences(grant numbers:LAGEO-2022-02); Key Laboratory of Cognitive Radio and Information Processing, Ministry of Education (Guilin University of Electronic Technology)(grant numbers:CRKL220203); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10347404","Cognitive radio;intercept probability;Internet-of-Things;non-orthogonal multiple access;outage probability;simultaneous transmitting and reflecting reconfigurable intelligent surface","NOMA;Security;Reliability;Internet of Things;Receivers;Power system reliability;Resource management","","2","","","IEEE","7 Dec 2023","","","IEEE","IEEE Early Access Articles"
"Thermostatically Controlled Loads in the Power System Under Cyberattacks","K. Yan; X. Liu; Y. Lu; Z. Yu","College of Electrical and Information Engineering, Hunan University, Changsha, China; College of Electrical and Information Engineering, Hunan University, Changsha, China; College of Electrical and Information Engineering, Hunan University, Changsha, China; Energy and Electric Economics Research Center, State Grid Hunan Electric Power Company Limited Economic and Technical Research Institute, Changsha, China","IEEE Internet of Things Journal","7 Mar 2023","2023","10","6","5256","5267","More and more thermostatic loads in power systems are transformed into thermostatically controlled loads (TCLs) through the heterogeneous Internet of Things (IoT) devices. The proportion of TCLs exposed to the Internet has also further increased. Considering TCLs’ response characteristics and the network security vulnerability of their associated IoT devices, it is possible to form a new threat to power systems, manipulation of demand (MAD) attacks. In this article, we reveal a potential attack scenario of this threat in the electricity market and propose a highly concealable and destructive cross-domain MAD attack strategy based on compromised TCLs, causing a tremendous economic loss for the power retailer (PR) and end-use consumers (EUCs). Finally, the effectiveness of the proposed MAD attack strategy is verified by simulation cases, highlighting the endanger of large-scale compromised TCLs in power systems and the importance of their associated IoT devices’ network security.","2327-4662","","10.1109/JIOT.2022.3222304","National Natural Science Foundation of China(grant numbers:51777062); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9951148","Heterogeneous;Internet of Thing (IoT);manipulation of demand (MAD);network security;response characteristic;thermostatically controlled loads (TCLs)","Internet of Things;Power systems;Network security;Economics;Electricity supply industry;Load modeling;Electric potential","","2","","31","IEEE","15 Nov 2022","","","IEEE","IEEE Journals"
"Scalable Real-Time Analytics for IoT Applications","K. Mahmood; T. Risch","Department of Information Technology, Uppsala University, Sweden; Stream Analyze Sweden, Uppsala, Sweden","2021 IEEE International Conference on Smart Computing (SMARTCOMP)","8 Oct 2021","2021","","","404","406","Large-scale industrial internet of things (IIoT) applications usually access distributed equipment where high-volume sensor streams are processed. The building of scalable analytic queries and models over such streams could potentially enhance various industrial processes management tasks, e.g., distribution, delivery, and predictive online maintenance. To enable real-time and historical analytics over distributed IIoT applications, we have combined an edge data stream management system (EDSMS), sa.engine, with the highly distributed NoSQL database MongoDB. For supporting advanced analytics and high-volume stream injection into MongoDB, we integrated an extended query processing (EQP) system with sa.engine and MongoDB. This work demonstrates how EQP provides a holistic data management solution for IIoT based on a use case for sound anomaly detection of distributed equipment.","2693-8340","978-1-6654-1252-0","10.1109/SMARTCOMP52413.2021.00084","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9556235","IoT;Edge Computing;NoSQL;Data Streams","Data analysis;Query processing;NoSQL databases;Image edge detection;Distributed databases;Predictive models;Maintenance engineering","","1","","13","IEEE","8 Oct 2021","","","IEEE","IEEE Conferences"
"Research on Logistics Big Data Asset Management and Data Mining Based on Particle Swarm Optimization","S. Guo","Yunnan University of Business Management, Kunming, China","2022 International Conference on Artificial Intelligence and Autonomous Robot Systems (AIARS)","14 Nov 2022","2022","","","391","394","The increasing progress of mobile Internet provides more opportunities for asset management technology, such as the rise of Internet of things, cloud computing and big data technology. In the field of logistics distribution, with the increasing transaction volume generated by mobile devices, the huge amount of data generated continuously also needs more and more efficient and practical data processing methods. In the field of logistics, logistics big data asset management has also become a new technical means to optimize logistics management and improve distribution efficiency. With the increasing progress of logistics informatization, the scale of logistics data increases geometrically. At present, many logistics information platforms have huge databases, but the data in them are lack of effective analysis and mining, which hides the law and value behind the data. Therefore, it is very necessary to establish a data mining (DM) system based on logistics information platform. According to the characteristics of large amount of cloud data and complex structure, this paper plans and implements a system that can manage the whole life cycle of data from collection to processing, then to cleaning, and finally to production, and capitalize these disordered data.","","978-1-6654-5457-5","10.1109/AIARS57204.2022.00094","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9943237","Particle swarm optimization;Logistics big data asset management;DM","Cloud computing;Technological innovation;Software algorithms;Production;Big Data;Asset management;Classification algorithms","","","","12","IEEE","14 Nov 2022","","","IEEE","IEEE Conferences"
"Electric Power Gateway Metering Monitoring and Analysis Platform Based on Random Forest Algorithm","Z. Li; Y. Sun; T. Jiao; Y. Sun; R. Hou; Y. Su; N. Samanvita","Marketing Service Center of State Grid Liaoning Electric Power Co., LTD, Shenyang, Liaoning, China; Marketing Service Center of State Grid Liaoning Electric Power Co., LTD, Shenyang, Liaoning, China; Marketing Service Center of State Grid Liaoning Electric Power Co., LTD, Shenyang, Liaoning, China; Marketing Service Center of State Grid Liaoning Electric Power Co., LTD, Shenyang, Liaoning, China; Marketing Service Center of State Grid Liaoning Electric Power Co., LTD, Shenyang, Liaoning, China; College of General Education, Shenyang City University, Shenyang, Liaoning, China; Department of Electrical & Electronics Engineering, Nitte Meenakshi Institute of Technology, Bengaluru, India","2022 International Conference on Knowledge Engineering and Communication Systems (ICKES)","17 Mar 2023","2022","","","1","6","Under the concept of “emerging Internet of Things”, computing and intelligence have become the guideline for the development of smart grids. On the one hand, communication technology is used to realize large-scale communication between underlying electronic devices and cloud platforms; on the other hand, with the gradual development of artificial intelligence and data mining technology, the value of power grid data must be further indexed. The main purpose of this paper is to design and study the power gateway metering monitoring and analysis platform based on the random forest (RF) algorithm. This question is mainly aimed at the problem that most devices on the power user side cannot directly transmit data to the cloud platform, and designed and implemented a power gateway device system. In addition, in terms of power data analysis, relying on machine learning theory, through the research and analysis on the detection of abnormal user behavior, a multi-classifier combination-based abnormal power behavior detection model is proposed. In this paper, the function and performance of the researched and designed intelligent power distribution monitoring system are tested. The accuracy of its functionality and technical indicators is verified in the laboratory environment, and it is found that for a single classifier, the RF algorithm is more suitable for the detection of abnormal electrical behavior, which meets the design requirements.","","978-1-6654-5637-1","10.1109/ICKECS56523.2022.10059671","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10059671","random forest algorithm;power gateway;current metering;power monitoring","Analytical models;Cloud computing;Logic gates;Big Data;Data models;Behavioral sciences;Classification algorithms","","","","12","IEEE","17 Mar 2023","","","IEEE","IEEE Conferences"
"Application of Unmanned Aerial Vehicle Image Denoising Based on FPGA in Unmanned Aerial Vehicle Tilt Photography Assisted Intelligent Construction Site Management","Y. Wang","Xiamen Institute of Technology, Xiamen, Fujian, China","2023 2nd International Conference on 3D Immersion, Interaction and Multi-sensory Experiences (ICDIIME)","31 Aug 2023","2023","","","357","361","Smart construction site is a smart management platform built by means of Internet, Internet of Things, big data, BIM technology, digital technology and tilt photography technology. Managers can obtain a high-precision, high-resolution real three-dimensional real-life model of the construction site through oblique photography technology. In this paper, the application of UAV(Unmanned Aerial Vehicle) tilt photography aerial survey technology combined with FPGA in smart site system effectively integrates various resources in engineering construction, cost control, safety supervision, data analysis and decision efficiency, and realizes the monitoring and management of engineering projects. According to the actual survey data information, before planning the route, the system automatically matches the points with the same name in all the images through dense matching technology, and extracts more feature points from the images to form dense point clouds, thus more accurately expressing the details of the ground objects and effectively utilizing and expressing the underground information around the rail transit line; Finally, it provides basic conditions for spatial analysis such as personnel or large-scale equipment positioning analysis, rationality analysis of underground pipeline relocation and reconstruction, and regional management of key buildings in shield area.","","979-8-3503-2381-8","10.1109/ICDIIME59043.2023.00075","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10229576","FPGA;Unmanned Aerial Vehicle image denoising;Tilt photography;Smart site management","Photography;Surveys;Point cloud compression;Autonomous aerial vehicles;Feature extraction;Safety;Planning","","","","10","IEEE","31 Aug 2023","","","IEEE","IEEE Conferences"
"Micro-cantilever electric field sensors based on Piezoelectric-piezoresistive Coupling","Z. Han; F. Xue; J. Hu; J. He","Tsinghua University, Beijing, China; Tsinghua University, Beijing, China; Tsinghua University, Beijing, China; Tsinghua University, Beijing, China","22nd International Symposium on High Voltage Engineering (ISH 2021)","20 Jun 2022","2021","2021","","1645","1650","With the development of the ubiquitous power Internet of Things, online monitoring and status awareness of power systems and equipment has become an important method to ensure the safe operation of the power grid. The measurement of electric fields can be used for fault diagnosis of power equipment such as such as insulator failure. At the same time, by inverting the line voltage through the electric field, wide-area online monitoring of the power system can be achieved. Therefore, miniature electric-field sensors (E-sensors) with high sensitivity and high amplitude are needed. In this paper, we proposed a novel miniature E-sensor with cantilever structure. The proposed E-sensor combines the piezoelectric effect and the piezoresistive effect. Experimental results show that our sensor has a high resolution of 156 V/m and a magnitude of over 1.5 MV/m. Moreover, silicon-based micro-fabrication makes our sensor has low cost and are suitable for mass production, which is suitable for large-scale sensor arrays and wide-area monitoring.","","978-1-83953-605-2","10.1049/icp.2022.0277","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9800222","","","","","","","","20 Jun 2022","","","IET","IET Conferences"
"16 IoT: Applications and Case Study in Smart Farming","",,"Advanced Technologies for Smart Agriculture","","2023","","","339","358","This book brings new smart farming methodologies to the forefront, sparked by pervasive applications with automated farming technology. New indigenous expertise on smart agricultural technologies is presented along with conceptual prototypes showing how the Internet of Things, cloud computing, machine learning, deep learning, precision farming, crop management systems, etc., will be used in large-scale production in the future. The necessity of available welfare systems for farmers’ well-being is also discussed in the book. It draws the conclusion that there is a greater need and demand today for smart farming methodologies driven by technology than ever before.","","9788770228831","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10286351.pdf&bkn=10286317&pdfType=chapter","","","","","","","","16 Oct 2023","","","River Publishers","River eBook Chapters"
"8 Image Analysis for Better Yield in Farming","",,"Advanced Technologies for Smart Agriculture","","2023","","","177","194","This book brings new smart farming methodologies to the forefront, sparked by pervasive applications with automated farming technology. New indigenous expertise on smart agricultural technologies is presented along with conceptual prototypes showing how the Internet of Things, cloud computing, machine learning, deep learning, precision farming, crop management systems, etc., will be used in large-scale production in the future. The necessity of available welfare systems for farmers’ well-being is also discussed in the book. It draws the conclusion that there is a greater need and demand today for smart farming methodologies driven by technology than ever before.","","9788770228831","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10286318.pdf&bkn=10286317&pdfType=chapter","","","","","","","","16 Oct 2023","","","River Publishers","River eBook Chapters"
"Fabric-iot: A Blockchain-Based Access Control System in IoT","H. Liu; D. Han; D. Li","College of Information Engineering, Shanghai Maritime University, Shanghai, China; College of Information Engineering, Shanghai Maritime University, Shanghai, China; College of Information Engineering, Shanghai Maritime University, Shanghai, China","IEEE Access","28 Jan 2020","2020","8","","18207","18218","IoT devices have some special characteristics, such as mobility, limited performance, and distributed deployment, which makes it difficult for traditional centralized access control methods to support access control in current large-scale IoT environment. To address these challenges, this paper proposes an access control system in IoT named fabric-iot, which is based on Hyperledger Fabric blockchain framework and attributed based access control (ABAC). The system contains three kinds of smart contracts, which are Device Contract (DC), Policy Contract (PC), and Access Contract (AC). DC provides a method to store the URL of resource data produced by devices, and a method to query it. PC provides functions to manage ABAC policies for admin users. AC is the core program to implement an access control method for normal users. Combined with ABAC and blockchain technology, fabric-iot can provide decentralized, fine-grained and dynamic access control management in IoT. To verify the performance of this system, two groups of simulation experiments are designed. The results show that fabric-iot can maintain high throughput in large-scale request environment and reach consensus efficiently in a distributed system to ensure data consistency.","2169-3536","","10.1109/ACCESS.2020.2968492","National Natural Science Foundation of China(grant numbers:61672338,61873160); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8964343","Blockchain;IoT;ABAC;hyperledger fabric;distributed system","Access control;Blockchain;Peer-to-peer computing;Fabrics;Distributed ledger;Smart contracts","","171","","26","CCBY","22 Jan 2020","","","IEEE","IEEE Journals"
"Edge Intelligence for Smart Metro Systems: Architecture and Enabling Technologies","X. Liu; M. Zhang; C. Zou; J. Yang; X. Yan","Wuhan University of Technology, China; Wuhan University of Technology, China; Wuhan University of Technology, China; Wuhan University, China; Wuhan University of Technology, China","IEEE Network","23 Mar 2022","2022","36","1","136","143","Safety and operational efficiency (SOE) are of great significance for the development of a smart metro system (SMS). To improve the SOE of SMS, Internet-of-Things technology is applied first to collect metro environmental data (MED), and then these data are analyzed by intelligent algorithms to achieve safety risk prediction, defect detection or operational efficiency improvement. As MEDs are generated quickly in the practical engineering field and most algorithms to process these data also have high computational complexity, the SMS must have sufficient computing power to process these MEDs in time. However, modern train computing resources are insufficient to meet this requirement. To address this challenge, edge intelligence (EI) technology, which enables trains to offload computationally-intensive tasks to nearby EI systems, is proposed. This article aims to develop an energy-efficient and high-performance EI system to improve the SOE of SMSs. An EI architecture that considers the three driving forces, data, algorithms and computing power, is proposed first, and then the enabling techniques of this EI architecture, including intelligent algorithms, domain-specific architecture (DSA)-based hardware acceleration, end-edge-cloud collaborative computing, hardware platform management, and security issues, are investigated. This EI system can enable SMS to process the large-scale MEDs with not only high accuracy but also low latency and low energy cost. As a study case, a real-world EI system is built to run three kinds of SMS applications to assess the safety risks of SMSs. The evaluation results demonstrate the effectiveness of the proposed schemes in this article.","1558-156X","","10.1109/MNET.211.2100302","National Natural Science Foundation of China(grant numbers:61702387,61771354); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9599640","","Computer architecture;Task analysis;Safety;Smart devices;Costs;Heuristic algorithms;Cloud computing","","2","","15","IEEE","2 Nov 2021","","","IEEE","IEEE Magazines"
"Efficient IoT Compatible Sparse Recovery-Based Detectors for Differential Space Shift Keying MIMO System","M. Shawaqfeh; B. Maqableh; R. Mesleh","Electrical Engineering Department, German Jordanian University, Amman, Jordan; Engineering and Technology Department, American College of Middle East, Eqaila, Kuwait; Electrical Engineering Department, German Jordanian University, Amman, Jordan","2021 8th International Conference on Electrical and Electronics Engineering (ICEEE)","10 May 2021","2021","","","299","304","Space shift keying (SSK) presents itself as promising multi-input multi-output (MIMO) modulation technique that comply with the crucial need for high throughput and low complexity transmission schemes for Internet-of-Things (IoT) applications. This efficiency stems from the fundamental property of SSK scheme of activating only one single antenna at any time instant, which eliminates the inter-channel interference (ICI) and enables the use of single RF-chain at the transmitter. Conventional SSK is of coherent nature, which requires the channel state information (CSI) to be available at the receiver. Obtaining accurate CSI introduces significant complexity to the system. The non-coherent counterpart of SSK, namely Differential space shift keying (DSSK), overcomes the need to have the CSI at the receiver while retaining the inherent advantages of coherent SSK. The detection in DSSK is based on the received blocks at two consecutive time slots. However, the computational complexity and memory-size requirements of the existing optimal maximum-likelihood receiver of the DSSK system grow exponentially with the number of transmit antennas. This hinders the practical implementation of large-scale DSSK systems. Thus, this work aims at utilizing the inherent sparsity of DSSK schemes to propose a reduced complexity, yet reliable, detectors for DSSK schemes based on the theory of sparse recovery (SR). Achieved results demonstrate significant computational complexity reduction with pragmatic error rate, especially for large-scale scenarios.","","978-1-6654-4071-4","10.1109/ICEEE52452.2021.9415960","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9415960","IoT;MIMO;sparse recovery;matching pur-suit;complexity;DSSK","Transmitting antennas;Receiving antennas;Receivers;Detectors;Reliability theory;Throughput;Table lookup","","1","","16","IEEE","10 May 2021","","","IEEE","IEEE Conferences"
"Low-Cost Subarrayed Sensor Array Design Strategy for IoT and Future 6G Applications","W. Dong; Z. -H. Xu; X. -X. Li; S. -P. Xiao","State Key Laboratory of Complex Electromagnetic Environment Effects on Electronics and Information System, National University of Defense Technology, Changsha, China; State Key Laboratory of Complex Electromagnetic Environment Effects on Electronics and Information System, National University of Defense Technology, Changsha, China; College of Electronic Engineering, National University of Defense Technology, Changsha, China; State Key Laboratory of Complex Electromagnetic Environment Effects on Electronics and Information System, National University of Defense Technology, Changsha, China","IEEE Internet of Things Journal","12 Jun 2020","2020","7","6","4816","4826","The low-cost sensor array, an effective way to provide sufficient degrees of freedom (DoFs) and affordable costs, is one of the most important foundation devices for large-scale applications of the Internet of Things (IoT) and sixth-generation (6G) spaceborne communication systems. In this article, we propose an irregular subarray-based low-cost sensor array design strategy, which decomposes the practical application problem into two subproblems according to the scene scale. For the small-size cases, a user-defined DoF control strategy is presented, which is flexibly defined and establishes an effective tradeoff between the sensor array radiation performance and manufacturing cost. Moreover, for large-size cases, a hierarchical subarray design strategy is presented. A module panel structure composed of subarray tiles is proposed to avoid both the convergence problem in high-dimensional optimization and engineering complexity. Both design strategies are able to ensure good sensor radiation performance while maintaining engineering convenience. The effectiveness and potential of the proposed method are verified by various numerical examples.","2327-4662","","10.1109/JIOT.2020.2969247","National Natural Science Foundation of China(grant numbers:61471372); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8968351","Degree of freedom (DoF) control;irregular subarray;low cost;module panel;sensor array","Sensor arrays;Internet of Things;Apertures;6G mobile communication;Optimization;Manufacturing","","30","","26","IEEE","24 Jan 2020","","","IEEE","IEEE Journals"
"Cloud-Based Testbed for Large-Scale Data Collection System with Network-Edge","Y. Dong; H. Nakada; Y. Tanimura","University of Tsukuba, Tsukuba, Japan; Digital Architecture Research Center, National Institute of Advanced Industrial Science and Technology, Tokyo, Japan; Digital Architecture Research Center, National Institute of Advanced Industrial Science and Technology, Tokyo, Japan","2024 18th International Conference on Ubiquitous Information Management and Communication (IMCOM)","12 Feb 2024","2024","","","1","6","With the recent development of IoT technology, it is becoming necessary to design systems that utilize not only the cloud but also the edge. We are studying systems that reduce the load on the cloud by performing various processes at the edge. Although experimentation in a large-scale environment is essential for such research, it is impractical to set up such an environment using actual computers. In this study, we attempted to construct a large-scale experimental environment on top of EKS, a container framework on Amazon Web Service and confirmed that it is possible to easily construct a large-scale experimental environment by using containers. Furthermore, we conducted several experiments on the constructed large-scale experimental environment and confirmed the following: 1) The computational load for the MQTT broker is sufficiently small even with high message frequency, 2) With a relay server, we can reduce the broker burden preserving the message delivery latency.","","979-8-3503-3101-1","10.1109/IMCOM60618.2024.10418367","New Energy and Industrial Technology Development Organization(grant numbers:JPNP20017); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10418367","IoT;MQTT;Kubernetes;EKS","Temperature sensors;Cloud computing;Web services;Containers;Throughput;Servers;Relays","","","","18","IEEE","12 Feb 2024","","","IEEE","IEEE Conferences"
"RiLoc: Representative guided subarea to exact localization from crowdsourced samples","A. T. Abraha; B. Wang","School of Electronic Information and Communications, Huazhong University of Science and Technology (HUST), Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology (HUST), Wuhan, China","2022 IEEE Smartworld, Ubiquitous Intelligence & Computing, Scalable Computing & Communications, Digital Twin, Privacy Computing, Metaverse, Autonomous & Trusted Vehicles (SmartWorld/UIC/ScalCom/DigitalTwin/PriComp/Meta)","27 Jul 2023","2022","","","144","151","With the emergence of the Internet of Things (IoT), indoor localization has become a critical infrastructure to be installed in large-scale environments such as airports, train stations, and shopping malls. Many systems have been proposed for accurate localization using the site survey, which is costly and tedious to implement in large-scale indoor environments. The high accuracy is also at the expense of computation time and memory. To deal with these challenges, we propose a representative guided subarea to exact localization from crowdsourced samples (RiLoc) for large-scale indoor environments. The basic idea of RiLoc is that online test points near each other in the signal space are also close to each other in the physical space. We cluster the crowdsourced samples in the offline phase to form subarea fingerprints and virtual anchors. We propose a novel virtual anchor-based dimension reduction algorithm using virtual anchors. In the online phase, the test points’ dimension is reduced and clustered to nominate a representative fingerprint. The representative identifies a more relevant and reduced search space and guides its members for exact localization. We conduct experiments on two field-measured datasets, and the results show significant improvements over the peer schemes in terms of lower localization errors.","","979-8-3503-4655-8","10.1109/SmartWorld-UIC-ATC-ScalCom-DigitalTwin-PriComp-Metaverse56740.2022.00046","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10189677","Wi-Fi fingerprint;Crowdsourcing;Dimension reduction;Clustering;Representative;Subarea","Location awareness;Surveys;Dimensionality reduction;Clustering algorithms;Fingerprint recognition;Airports;Indoor environment","","","","41","IEEE","27 Jul 2023","","","IEEE","IEEE Conferences"
"Intelligent inspection trolley based on YOLO","Z. Hu; Y. Lin; X. He; R. Xie; Z. Shen; Z. Zhou","Tianjin University of Science and Technology, Tianjin, China; Tianjin University of Science and Technology, Tianjin, China; Tianjin University of Science and Technology, Tianjin, China; Tianjin University of Science and Technology, Tianjin, China; Tianjin University of Science and Technology, Tianjin, China; Tianjin University of Science and Technology, Tianjin, China","2023 IEEE 5th International Conference on Civil Aviation Safety and Information Technology (ICCASIT)","15 Dec 2023","2023","","","1208","1217","With the arrival of the era of 5G Internet of everything, the Internet plus intelligent inspection and testing has become a development trend. Our country is the world's largest manufacturing country, testing industry has a large scale. In recent years, under the trend of intelligent upgrading of manufacturing industry, intelligent testing system is gradually widely used in the fields of environmental protection, scientific research, aerospace, medical, electronics, communications, military, chemical industry and other fields. Although intelligent detection technology is deeply involved in public life, its application in the field of traffic detection still belongs to the blue ocean stage. In recent years, the pace of intelligent transportation has been accelerating as our country has been striving to build a higher level of safe transportation. It is imperative to make the intelligent detection system strengthen the fine management of urban traffic and improve the ability of safety risk monitoring and early warning. This paper mainly takes the development of intelligent detection industry as the background, carries out software design and hardware research and development to solve the industry detection pain points, and develops patrol vehicles suitable for various monitoring scenarios through the actual test in traffic identification and instrument monitoring scenarios, so as to help the development of national intelligent monitoring field. The YOLO-based intelligent patrol vehicle independently developed in this paper is capable of monitoring machines and equipment at work, warehouses and other places as well as identifying and detecting traffic road signs by remote control through Raspberry PI, Internet of Things technology and deep learning algorithm. The inspection car can be controlled by the user remotely, or the car can automatically detect the equipment according to the user's route setting. At the same time, the car has the automatic obstacle avoidance function, which can avoid obstacles intelligently. In addition, the patrol car can run on the highway so as to play the function of road condition detection, including traffic sign recognition, road fault recognition, abnormal situation capture, etc. The intelligent patrol vehicle developed in this paper reduces the human monitoring labor, and can effectively improve the detection efficiency, greatly convenient people's lives, and has strong implementability.","","979-8-3503-1060-3","10.1109/ICCASIT58768.2023.10351695","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10351695","Intelligent recognition;YOLO;OpenCV;traffic signs;equipment monitoring","Roads;Transportation;Inspection;Market research;Production facilities;Safety;Automobiles","","","","16","IEEE","15 Dec 2023","","","IEEE","IEEE Conferences"
"6G-Enabled Short-Term Forecasting for Large-Scale Traffic Flow in Massive IoT Based on Time-Aware Locality-Sensitive Hashing","F. Wang; M. Zhu; M. Wang; M. R. Khosravi; Q. Ni; S. Yu; L. Qi","School of Computer Science, Qufu Normal University, Rizhao, China; Facility Horticulture Laboratory of Universities in Shandong, Weifang University of Science and Technology, Shouguang, China; School of Cyber Science and Engineering, Qufu Normal University, Rizhao, China; Department of Computer Engineering, Persian Gulf University, Bushehr, Iran; School of Computing and Communications, Lancaster University, Lancaster, U.K.; Faculty of Engineering and Information Technology, University of Technology Sydney, Sydney, NSW, Australia; School of Computer Science, Qufu Normal University, Rizhao, China","IEEE Internet of Things Journal","24 Mar 2021","2021","8","7","5321","5331","With the advent of the Internet of Things (IoT) and the increasing popularity of the intelligent transportation system, a large number of sensing devices are installed on the road for monitoring traffic dynamics in real time. These sensors can collect streaming traffic data distributed across different traffic sites, which constitute the main source of big traffic data. Analyzing and mining such big traffic data in massive IoT can help traffic administrations to make scientific and reasonable traffic scheduling decisions, so as to avoid prospective traffic congestions in the future. However, the above traffic decision making often requires frequent and massive data transmissions between distributed sensors and centralized cloud computing centers, which calls for lightweight data integrations and accurate data analyses based on large-scale traffic data. In view of this challenge, a big data-driven and nonparametric model aided by 6G is proposed in this article to extract similar traffic patterns over time for accurate and efficient short-term traffic flow prediction in massive IoT, which is mainly based on time-aware locality-sensitive hashing (LSH). We design a wide range of experiments based on a real-world big traffic data set to validate the feasibility of our proposal. Experimental reports demonstrate that the prediction accuracy and efficiency of our proposal are increased by 32.6% and 97.3%, respectively, compared with the other two competitive approaches.","2327-4662","","10.1109/JIOT.2020.3037669","National Natural Science Foundation of China(grant numbers:61872219); Natural Science Foundation of Shandong Province(grant numbers:ZR2019MF001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9257467","6G;intelligent transportation system (ITS);large-scale traffic management;massive Internet of Things (IoT);short-term traffic forecasting;time-aware locality-sensitive hashing (LSH)","6G mobile communication;Roads;Distributed databases;Transportation;Traffic control;Internet of Things;Proposals","","32","","30","IEEE","12 Nov 2020","","","IEEE","IEEE Journals"
"A Hardware-Assisted Heartbeat Mechanism for Fault Identification in Large-Scale IoT Systems","M. Banerjee; C. Borges; K. -K. R. Choo; J. Lee; C. Nicopoulos","Department of Electrical and Computer Engineering, University of Texas at San Antonio, San Antonio, TX, USA; Department of Electrical and Computer Engineering, University of Texas at San Antonio, San Antonio, TX, USA; Department of Electrical and Computer Engineering, the University of Texas at San Antonio, San Antonio, TX, USA; Institute of Cyber Security and Privacy, Korea University, Seoul, Korea; Department of Electrical and Computer Engineering, the University of Cyprus, Nicosia, Cyprus","IEEE Transactions on Dependable and Secure Computing","11 Mar 2022","2022","19","2","1254","1265","With increased inter-connectivity among disparate devices, such as Internet-of-Things (IoT) devices, including those deployed in a nation’s critical infrastructure, there is a need to ensure that any failure in the deployed devices can be detected. The capability to automatically detect device failures is particularly crucial in a large-scale, complex IoT system, since it can be very time-consuming and challenging to investigate a large number of geographically-dispersed devices that are also of different makes and types. In this paper, we present a faulty-device identification technique that is designed to achieve lightweight processor-level architectural support. Specifically, a hardware-based monitoring agent is incorporated within a processor and connected to a separate monitoring program when an examination is required. By analyzing information collected by the agent, the monitoring program determines whether the device being monitored is functioning. Findings from our detailed evaluation demonstrate that the proposed approach can detect around 90 percent of the failures with minimal hardware overhead of approximately 5k gates. This area overhead is reasonable and amounts to 7.69 percent of the ARM Cortex-M4 – a lightweight IoT-class processor – that has a total area (excluding optional caches and scratch-pad memory) of 65k gates.","1941-0018","","10.1109/TDSC.2020.3009212","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9142419","Self testing;control-flow integrity;Internet-of-Things (IoT)","Monitoring;Heart beat;Biomedical monitoring;Circuit faults;Logic gates;Computer security;Task analysis","","9","","45","IEEE","16 Jul 2020","","","IEEE","IEEE Journals"
"Through the Soil Long Range Wireless Power Transfer for Agricultural IoT Networks","B. Nieman; C. S. Johnson; M. Pearce; T. Marcrum; M. C. Thorne; C. Ashby; C. W. Van Neste","Center for Energy Systems Research, Tennessee Technological University, Cookeville, TN, USA; Electrical and Computer Engineering Department, Tennessee Technological University, Cookeville, TN, USA; Center for Energy Systems Research, Tennessee Technological University, Cookeville, TN, USA; Center for Energy Systems Research, Tennessee Technological University, Cookeville, TN, USA; Electrical and Computer Engineering Department, Tennessee Technological University, Cookeville, TN, USA; Electrical and Computer Engineering Department, Tennessee Technological University, Cookeville, TN, USA; Electrical and Computer Engineering Department, Tennessee Technological University, Cookeville, TN, USA","IEEE Transactions on Industrial Electronics","17 Aug 2023","2024","71","2","2090","2099","Increasing the spatial and temporal density of data using networked sensors, known as the Internet of Things (IoT), can lead to enhanced productivity and cost savings in a host of industries. Where applications involve large outdoor expanses, such as farming, oil and gas, or defense, large regions of unelectrified land could yield significant benefits if instrumented with a high density of IoT systems. The major limitation of expanding IoT networks in such applications stems from the challenge of delivering power to each sensing device. Batteries, generators, and renewable sources have predominately been used to address the challenge, but these solutions require constant maintenance or are sensitive to environmental factors. This work presents a novel approach where conduction currents through soil are utilized for the wireless powering of sensor networks, initial investigation is within an 0.8-ha (2-acre) area. The technique is not line-of-sight, powers all devices simultaneously through near-field mechanics, and has the ability to be minimally invasive to the working environment. A theory of operation is presented and the technique is experimentally demonstrated in an agricultural setting. Scaling and transfer parameters are discussed.","1557-9948","","10.1109/TIE.2023.3250743","National Science Foundation(grant numbers:1841469,2226612); Center for Energy Systems Research; Electrical and Computer Engineering Department at Tennessee Technological University, Cookeville, TN, USA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10061422","Conduction;long range;through the soil;wireless power transfer","Soil;Robot sensing systems;Integrated circuit modeling;Geometry;Electrodes;Mathematical models;Electric potential","","3","","31","CCBY","6 Mar 2023","","","IEEE","IEEE Journals"
"Multi-panel extra-large scale MIMO based joint activity detection and channel estimation for near-field massive IoT access","Z. Gao; H. Xiu; Y. Mei; A. Liao; M. Ke; C. Hu; M. -S. Alouini","School of Information and Electronics, Beijing Institute of Technology, Jiaxing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China; MIIT Key Laboratory of Complex-Field Intelligent Sensing, Beijing Institute of Technology, Beijing, China; Division of Physical Sciences and Engineering, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia","China Communications","22 May 2023","2023","20","5","232","243","The extra-large scale multiple-input multiple-output (XL-MIMO) for the beyond fifth/sixth generation mobile communications is a promising technology to provide Tbps data transmission and stable access service. However, the extremely large antenna array aperture arouses the channel near-field effect, resulting in the deteriorated data rate and other challenges in the practice communication systems. Meanwhile, multi-panel MIMO technology has attracted extensive attention due to its flexible configuration, low hardware cost, and wider coverage. By combining the XL-MIMO and multi-panel array structure, we construct multi-panel XL-MIMO and apply it to massive Internet of Things (IoT) access. First, we model the multi-panel XL-MIMO-based near-field channels for massive IoT access scenarios, where the electromagnetic waves corresponding to different panels have different angles of arrival/departure (AoAs/AoDs). Then, by exploiting the sparsity of the near-field massive IoT access channels, we formulate a compressed sensing based joint active user detection (AUD) and channel estimation (CE) problem which is solved by AMP-EM-MMV algorithm. The simulation results exhibit the superiority of the AMP-EM-MMV based joint AUD and CE scheme over the baseline algorithms.","1673-5447","","10.23919/JCC.fa.2022-0138.202305","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10130736","extra-large scale MIMO;massive IoT access;active user detection;channel estimation;multipanel;approximate message passing","MIMO communication;Radio frequency;Millimeter wave communication;Channel estimation;Antenna arrays;Signal processing algorithms;Apertures","","","","","","22 May 2023","","","IEEE","IEEE Magazines"
"HCloud: A trusted JointCloud serverless platform for IoT systems with blockchain","Z. Huang; Z. Mi; Z. Hua","Institute of Parallel and Distributed Systems, Shanghai Jiao Tong University, Shanghai, China; Institute of Parallel and Distributed Systems, Shanghai Jiao Tong University, Shanghai, China; Institute of Parallel and Distributed Systems, Shanghai Jiao Tong University, Shanghai, China","China Communications","25 Sep 2020","2020","17","9","1","10","Cloud computing has been exploited in managing large-scale IoT systems. IoT cloud servers usually handle a large number of requests from various IoT devices. Due to the fluctuant and heavy workload, the servers require the cloud to provide high scalability, stable performance, low price and necessary functionalities. However, traditional clouds usually offer computing service with the abstraction of virtual machine (VM), which can hardly meet these requirements. Meanwhile, different cloud vendors provide different performance stabilities and price models, which fluctuate according to the dynamic workload. A single cloud cannot satisfy all the requirements of the IoT scenario well. The JointCloud computing model empowers the cooperation among multiple public clouds. However, it is still difficult to dynamically schedule the workload on different clouds based on the VM abstraction. This paper introduces HCloud, a trusted JointCloud platform for IoT systems using serverless computing model. HCloud allows an IoT server to be implemented with multiple serverless functions and schedules these functions on different clouds based on a schedule policy. The policy is specified by the client and includes the required functionalities, execution resources, latency, price and so on. HCloud collects the status of each cloud and dispatches serverless functions to the most suitable cloud based on the schedule policy. By leveraging the blockchain technology, we further enforce that our system can neither fake the cloud status nor wrongly dispatch the target functions. We have implemented a prototype of HCloud and evaluated it by simulating multiple cloud providers. The evaluation results show that HCloud can greatly improve the performance of serverless workloads with negligible costs.","1673-5447","","10.23919/JCC.2020.09.001","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9205972","IoT;blockchain;serverless;joint-cloud","Cloud computing;Blockchain;Schedules;Internet of Things;Servers;Monitoring;Libraries","","12","","","","25 Sep 2020","","","IEEE","IEEE Magazines"
"Catena: A Near-Threshold, Sub-0.4-mW, 16-Core Programmable Spatial Array Accelerator for the Ultralow-Power Mobile and Embedded Internet of Things","J. P. Cerqueira; T. J. Repetti; Y. Pu; S. Priyadarshi; M. A. Kim; M. Seok","Department of Electrical Engineering, Columbia University, New York, USA; Department of Computer Science, Columbia University, New York, USA; Qualcomm Inc., Raleigh, USA; Qualcomm Inc., Raleigh, USA; Department of Computer Science, Columbia University, New York, USA; Department of Electrical Engineering, Columbia University, New York, USA","IEEE Journal of Solid-State Circuits","22 Jul 2020","2020","55","8","2270","2284","In this article, we present Catena, a near-threshold voltage 16-core programmable spatial array accelerator supporting workloads for ultralow-power (ULP) mobile and embedded Internet of Things applications. We observe that employing supply voltage scaling alone in a large-scale, massively parallel spatial architecture, such as Catena, results in marginal runtime energy efficiency. The reason is that ultralow-voltage operation magnifies the energy waste of underutilized and always-on hardware in portion to the system's total energy consumption. Hence, we propose circuit and architecture techniques to minimize such energy waste and extend the energy efficiency of our spatial array accelerator architecture. To demonstrate the effectiveness of the proposed techniques, we design and prototype Catena in a 65-nm low-power CMOS. Our prototype achieves 228 pJ/cycle. As compared to a spatial-like architecture running the same workload, Catena achieves 2.7× higher energy efficiency.","1558-173X","","10.1109/JSSC.2020.2978137","Qualcomm Inc. through the Qualcomm Innovation Fellowship; Catalyst Foundation; NSF(grant numbers:1453142); Coordenação de Aperfeiçoamento de Pessoal de Nível Superior (CAPES)(grant numbers:13289-13-6); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9034145","Coarse-grain reconfigurable architecture;coarse-grain reconfigurable array (CGRA);energy-efficient;fine-grain power gating;Internet of Things (IoT);leakage suppression;near-threshold voltage;power management;programmability;spatial architecture;spatial array accelerator;spatially programmed architecture;static power reduction;ultralow-power (ULP);ultralow-voltage;ZSCCMOS","Computer architecture;Hardware;Instruction sets;Internet of Things;System-on-chip;Prototypes;Random access memory","","12","","28","IEEE","12 Mar 2020","","","IEEE","IEEE Journals"
"A FIWARE-based IoT Framework for Smart Water Distribution Management","T. Panagiotakopoulos; D. P. Vlachos; T. V. Bakalakos; A. Kanavos; A. Kameas","School of Technology and Science, Hellenic Open University, Patras, Greece; Department of Electrical and Computer Engineering, University of Patras, Patras, Greece; Department of Electrical and Computer Engineering, University of Patras, Patras, Greece; School of Technology and Science, Hellenic Open University, Patras, Greece; School of Technology and Science, Hellenic Open University, Patras, Greece","2021 12th International Conference on Information, Intelligence, Systems & Applications (IISA)","8 Oct 2021","2021","","","1","6","A key axis of design and implementation of sustainable water management solutions is based on the application of IoT, which enable the deployment of monitoring systems across the water distribution network, facilitate data acquisition in an automated manner and provide a rich set of data. Distributed software architectures are acknowledged as vital to realize smart water management systems, especially in large-scale and complex deployments with heterogeneous interacting entities. Current smart water systems mainly use commercial IoT platforms with only a few researches rooting for open source software solutions. However, both approaches have limitations as the closed APIs of commercial IoT platforms have been accused of hindering open market evolution, while open source solutions lack interoperability and data integration/sharing mechanisms. This paper presents an IoT framework based on FIWARE that aims to realize a highly flexible standards-based open source software solution for the development of smart water systems. We designed an architecture consisting of various FIWARE software components and two dashboard applications. We have also constructed a digital model of a part of a water distribution network and used a simulation dataset to showcase the framework’s functionality and data visualization aspects.","","978-1-6654-0032-9","10.1109/IISA52424.2021.9555509","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9555509","Smart Water;FIWARE;IoT Frameworks;Smart Cities","Software architecture;Urban areas;Data acquisition;Data visualization;Distribution networks;Data models;Water resources","","16","","16","IEEE","8 Oct 2021","","","IEEE","IEEE Conferences"
"Fabrication and Characterization of Evaporated ZINC Anodes for Small-Scale ZINC-Air Batteries","V. Venkatesh; Q. Yang; J. Zhang; J. Pikul; M. G. Allen","University of Pennsylvania, Philadelphia, PA, USA; University of Pennsylvania, Philadelphia, PA, USA; University of Pennsylvania, Philadelphia, PA, USA; University of Pennsylvania, Philadelphia, PA, USA; University of Pennsylvania, Philadelphia, PA, USA","2021 21st International Conference on Solid-State Sensors, Actuators and Microsystems (Transducers)","6 Aug 2021","2021","","","1134","1137","Miniaturization of modern devices, including the advent of highly distributed Internet of Things nodes, has created a need for miniaturization in energy systems. Air batteries can be an attractive power source for such small-scale devices. This paper investigates fabrication of thin zinc anodes for zinc-air batteries using a thermal evaporation technique. Zinc anodes produced by thermal evaporation are found to be of high purity, approximately 96% dense, and smooth (roughness less than 0.1 micron). Anodes up to 8 microns in thickness are demonstrated. The structural characterization of the evaporated zinc films was performed by profilometry and scanning electron microscopy. The purity of the evaporated film was determined by the energy dispersive X-ray spectroscopy. Thin zinc anodes fabricated by evaporation exhibited utilization of 96.5% at 10 mA (5C rate) discharge. Specific capacity was 791mAh/g, approaching the theoretical limit of zinc-air batteries (820mAh/g). The anodes produced by evaporation offer the potential to fabricate high energy density thin film microbatteries.","2167-0021","978-1-6654-1267-4","10.1109/Transducers50396.2021.9495470","Defense Advanced Research Projects Agency (DARPA)(grant numbers:HR0011-19C0039); NSF(grant numbers:NNCI-2025608); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9495470","Zinc-air batteries;thin anodes;microbatteries;MEMS fabrication;Evaporation","Fabrication;Micrometers;Scanning electron microscopy;Transducers;Films;Thick films;Discharges (electric)","","2","","10","IEEE","6 Aug 2021","","","IEEE","IEEE Conferences"
"Moss-Based Biotechnological Air Purification Control System","S. Kusdavletov; A. Sapargali; D. Yedilkhan; A. Yermekov","Department of Intelligent Systems and Cybersecurity, Astana IT University, Astana, Kazakhstan; Department of Intelligent Systems and Cybersecurity, Astana IT University, Astana, Kazakhstan; Department of Computer Engineering, Astana IT University, Astana, Kazakhstan; “Smart City” Research Center, Astana IT University, Astana, Kazakhstan","2022 International Conference on Electrical and Computing Technologies and Applications (ICECTA)","26 Dec 2022","2022","","","343","346","Nowadays, air pollution is one of the acute problems that humanity faces as the world further develops and more technology comes into use. Pollution is produced both outside and inside buildings mostly from the machinery we use for convenience. In this paper, a non-standard approach is being explored to solve the problem at hand. Since excessive ventilation can lead to more pollution and infection, and is also a loss of energy, it was decided to focus not on ventilation, but on air purification. To purify the air, a filter created by living plants has been used. For the project, we chose moss, which is unpretentious and small, unlike trees and bushes. Due to the autonomy and scale, our solution is easy to use and brings enormous ecological and social impact. During the research, a biotechnological prototype is created, where it is possible to observe and control moss growth and its productivity. For the algorithm to work correctly, data about the environment is required. For this reason, in this paper, we have described not only the modeling of the system we suggest but also the process of collecting information from the biofilter. By reducing pollution, we will shortly save and stabilize the ecological situation. In this project, the effective biofilter is developed based on various solutions from biology, control engineering, as well as internet of things fields.","","978-1-6654-5600-5","10.1109/ICECTA57148.2022.9990344","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9990344","Control Systems;Optimal Control Moss;Dataset Collection","Productivity;Meters;Purification;Urban areas;Prototypes;Ventilation;Information filters","","2","","10","IEEE","26 Dec 2022","","","IEEE","IEEE Conferences"
"On the Performance of Cooperative IoT Using NOMA With Indoor–Outdoor Device Deployment","A. Alqahtani; E. Alsusa; A. Al-Dweik","Computer Engineering Department, King Khalid University, Abha, Saudi Arabia; EEE Department, University of Manchester, Manchester, U.K.; 6G Research Center, Department of Computer and Communication Engineering, Khalifa University, Abu Dhabi, UAE","IEEE Systems Journal","","2024","PP","99","1","12","This work studies applying power-domain downlink nonorthogonal multiple accesses (NOMA) to connect devices in urban environments to nearby Internet of Things (IoT). Therefore, attenuation caused by walls and other obstacles is exploited to treat indoor devices akin to far users in conventional NOMA. The system model considered incorporates a mobile relay, such as unmanned aerial vehicle, to support the link between the base station and IoT devices, highlighting its unique advantages in optimizing the communication link, addressing dynamic challenges, and improving the IoT connectivity experience in urban settings. To capture a wide range of small-scale fading scenarios, the outdoor channel is modeled using the generalized $\kappa$-$\mu$ fading. The performance of this system is analytically evaluated by deriving accurate closed-form expressions for the outage probability, erodic capacity, throughput, and energy efficiency. The obtained results, corroborated by Monte Carlo simulation, show that outdoor–indoor pairing is an efficient pairing approach given that the power allocated to the paired users is appropriately selected.","1937-9234","","10.1109/JSYST.2024.3359236","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10433232"," $\kappa$ - $\mu$  fading model;ergodic capacity (EC);energy efficiency (EE);Internet of Things (IoT);nonorthogonal multiple accesses (NOMA);outage probability (OP)","Relays;Autonomous aerial vehicles;NOMA;Internet of Things;Fading channels;Propagation losses;Analytical models","","","","","IEEE","12 Feb 2024","","","IEEE","IEEE Early Access Articles"
"Profit-Maximized Collaborative Computation Offloading and Resource Allocation in Distributed Cloud and Edge Computing Systems","H. Yuan; M. Zhou","Department of Electrical and Computer Engineering, New Jersey Institute of Technology, Newark, NJ, USA; Department of Electrical and Computer Engineering, New Jersey Institute of Technology, Newark, NJ, USA","IEEE Transactions on Automation Science and Engineering","1 Jul 2021","2021","18","3","1277","1287","Edge computing is a new architecture to provide computing, storage, and networking resources for achieving the Internet of Things. It brings computation to the network edge in close proximity to users. However, nodes in the edge have limited energy and resources. Completely running tasks in the edge may cause poor performance. Cloud data centers (CDCs) have rich resources for executing tasks, but they are located in places far away from users. CDCs lead to long transmission delays and large financial costs for utilizing resources. Therefore, it is essential to smartly offload users’ tasks between a CDC layer and an edge computing layer. This work proposes a cloud and edge computing system, which has a terminal layer, edge computing layer, and CDC layer. Based on it, this work designs a profit-maximized collaborative computation offloading and resource allocation algorithm to maximize the profit of systems and guarantee that response time limits of tasks are strictly met. In each time slot, this work jointly considers CPU, memory, and bandwidth resources, load balance of all heterogeneous nodes in the edge layer, maximum amount of energy, maximum number of servers, and task queue stability in the CDC layer. Considering the abovementioned factors, a single-objective constrained optimization problem is formulated and solved by a proposed simulated-annealing-based migrating birds optimization procedure to obtain a close-to-optimal solution. The proposed method achieves joint optimization of computation offloading between CDC and edge, and resource allocation in CDC. Realistic data-based simulation results demonstrate that it realizes higher profit than its peers. Note to Practitioners—This work considers the joint optimization of computation offloading between Cloud data center (CDC) and edge computing layers, and resource allocation in CDC. It is important to maximize the profit of distributed cloud and edge computing systems by optimally scheduling all tasks between them given user-specific response time limits of tasks. It is challenging to execute them in nodes in the edge computing layer because their computation resources and battery capacities are often constrained and heterogeneous. Current offloading methods fail to jointly optimize computation offloading and resource allocation for nodes in the edge and servers in CDC. They are insufficient and coarse-grained to schedule arriving tasks. In this work, a novel algorithm is proposed to maximize the profit of distributed cloud and edge computing systems while meeting response time limits of tasks. It explicitly specifies the task service rate and the selected node for each task in each time slot by considering resource limits, load balance requirement, and processing capacities of nodes in the edge, and server and energy constraints in CDC. Real-life data-driven simulations show that the proposed method realizes a larger profit than several typical offloading strategies. It can be readily implemented and incorporated into large-scale industrial computing systems.","1558-3783","","10.1109/TASE.2020.3000946","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9140317","Cloud data centers (CDCs);computation offloading;edge computing;intelligent optimization;migrating birds optimization (MBO);simulated annealing (SA)","Edge computing;Resource management;Optimization;Cloud computing;Data centers;Simulated annealing","","108","","35","IEEE","14 Jul 2020","","","IEEE","IEEE Journals"
"Multi-Layer Aggregate Verification for IoT Blockchain","J. Wu; M. -F. Sie; S. A. Harding; C. -L. Lin; S. -T. Wang; S. -w. Liao","Department of Computer Science, National Taiwan University; Department of Computer Science, National Taiwan University; Department of Computer Science, National Taiwan University; Department of Computer Science, National Taiwan University; Department of Computer Science, National Taiwan University; Department of Computer Science, National Taiwan University","2021 3rd Conference on Blockchain Research & Applications for Innovative Networks and Services (BRAINS)","25 Oct 2021","2021","","","43","44","We design a Multi-Layer Aggregate Verification (MLAV) solution to improve supply chain management with IoT Blockchain devices. We apply MLAV to IoT Blockchain applications in Agriculture 4.0 to demonstrate the feasibility of our solutions and models. In the current Agriculture 4.0 structure, large companies have successfully applied blockchain solutions and ecosystems for tracking and tracing agricultural produce, achieving transparency, traceability, and digitalization. However, these existing blockchain solutions are not comprehensive. First, the upstream nodes they serve are all large-scale production suppliers, and smallholders are not taken into consideration. In order to solve this problem, we use a multi-layer architecture that serves three purposes: facilitating smallholders in joining the agricultural blockchain as equal-opportunity nodes, uploading of production activity data, and reducing costs (ex. Ethereum gas fee). Second, the majority of IoT blockchains adopt an ID-based signature scheme in IoT devices, which frequently has lower efficiency. In applying aggregate verification, we may effectively increase ID-based verification efficiency while processing large clusters of data transferred by IoT devices. Finally, we design a blockchain management framework using smart contracts to facilitate the financing of upstream producers.","","978-1-6654-3924-4","10.1109/BRAINS52497.2021.9569817","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9569817","IoT;Blockchain;ID-based Signature;Aggregate Verification;Agriculture 4.0;Supply Chain Management","Handwriting recognition;Supply chain management;Costs;Aggregates;Smart contracts;Ecosystems;Production","","3","","11","IEEE","25 Oct 2021","","","IEEE","IEEE Conferences"
"Integrating Low-Power Wide-Area Networks for Enhanced Scalability and Extended Coverage","M. Rahman; A. Saifullah","Department of Computer Science, Wayne State University, Detroit, USA; Department of Computer Science, Wayne State University, Detroit, USA","IEEE/ACM Transactions on Networking","14 Feb 2020","2020","28","1","413","426","Low-Power Wide-Area Networks (LPWANs) are evolving as an enabling technology for Internet-of-Things (IoT) due to their capability of communicating over long distances at very low transmission power. Existing LPWAN technologies, however, face limitations in meeting scalability and covering very wide areas which make their adoption challenging for future IoT applications, especially in infrastructure-limited rural areas. To address this limitation, in this paper, we consider achieving scalability and extended coverage by integrating multiple LPWANs. SNOW (Sensor Network Over White Spaces), a recently proposed LPWAN architecture over the TV white spaces, has demonstrated its advantages over existing LPWANs in performance and energy-efficiency. In this paper, we propose to scale up LPWANs through a seamless integration of multiple SNOWs which enables concurrent inter-SNOW and intra-SNOW communications. We then formulate the tradeoff between scalability and inter-SNOW interference as a constrained optimization problem whose objective is to maximize scalability by managing white space spectrum sharing across multiple SNOWs. We also prove the NP-hardness of this problem. To this extent, We propose an intuitive polynomial-time heuristic algorithm for solving the scalability optimization problem which is highly efficient in practice. For the sake of theoretical bound, we also propose a simple polynomial-time 1/2-approximation algorithm for the scalability optimization problem. Hardware experiments through deployment in an area of (25x 15 )km2 as well as large scale simulations demonstrate the effectiveness of our algorithms and feasibility of achieving scalability through seamless integration of SNOWs with high reliability, low latency, and energy efficiency.","1558-2566","","10.1109/TNET.2020.2963886","National Science Foundation(grant numbers:CNS-1742985,CAREER-1846126); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8963868","Low-power wide-area network;white spaces;sensor network","Snow;Scalability;White spaces;Wireless sensor networks;Interference;Optimization;Approximation algorithms","","9","","51","IEEE","20 Jan 2020","","","IEEE","IEEE Journals"
"Heat Behind the Meter: A Hidden Threat of Thermal Attacks in Edge Colocation Data Centers","Z. Shao; M. A. Islam; S. Ren","University of California, Riverside; University of Texas at Arlington; University of California, Riverside","2021 IEEE International Symposium on High-Performance Computer Architecture (HPCA)","22 Apr 2021","2021","","","318","331","The widespread adoption of Internet of Things and latency-critical applications has fueled the burgeoning development of edge colocation data centers (a.k. a., edge colocation) — small-scale data centers in distributed locations. In an edge colocation, multiple entities/tenants house their own physical servers together, sharing the power and cooling infrastructures for cost efficiency and scalability. In this paper, we discover that the sharing of cooling systems also exposes edge colocations’ potential vulnerabilities to cooling load injection attacks (called thermal attacks) by an attacker which, if left at large, may create thermal emergencies and even trigger system outages. Importantly, thermal attacks can be launched by leveraging the emerging architecture of built-in batteries integrated with servers that can conceal the attacker’s actual server power (or cooling load). We consider both one-shot attacks (which aim at creating system outages) and repeated attacks (which aim at causing frequent thermal emergencies). For repeated attacks, we present a foresighted attack strategy which, using reinforcement learning, learns on the fly a good timing for attacks based on the battery state and benign tenants’ load. We also combine prototype experiments with simulations to validate our attacks and show that, for a small 8kW edge colocation, an attacker can potentially cause significant losses. Finally, we suggest effective countermeasures to the potential threat of thermal attacks.","2378-203X","978-1-6654-2235-2","10.1109/HPCA51647.2021.00035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9407172","","Data centers;Cooling;Scalability;Prototypes;Reinforcement learning;Computer architecture;Batteries","","5","","74","IEEE","22 Apr 2021","","","IEEE","IEEE Conferences"
"Physical Layer Security of Cognitive Ambient Backscatter Communications for Green Internet-of-Things","X. Li; Y. Zheng; W. U. Khan; M. Zeng; D. Li; G. K. Ragesh; L. Li","School of Physics and Electronic Information Engineering, Henan Polytechnic University, Jiaozuo, China; School of Physics and Electronic Information Engineering, Henan Polytechnic University, Jiaozuo, China; School of Information Science and Engineering, Shandong University, Qingdao, China; Department of Electrical and Computer Engineering, Laval University, Quebec, QC, Canada; Faculty of Information Technology, Macau University of Science and Technology, Macau, China; Department of Electronics and Communication Engineering, Adi Shankara Institute of Engineering and Technology, Kalady, India; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China","IEEE Transactions on Green Communications and Networking","23 Aug 2021","2021","5","3","1066","1076","The future sixth generation (6G) wireless communication networks will face the challenges of large-scale connections green communication. To meet these requirements, cognitive ambient backscatter communication (C-AmBC) has been proposed as a new spectrum paradigm for the green Internet-of-Things (IoT) with stringent energy and spectrum constraints, in which the backscatter device (BD) can achieve communications by simultaneously sharing both spectrum and radio-frequency (RF) sources. However, due to the broadcasting nature of wireless communication channels, BD is vulnerable to eavesdropping from unlicensed eavesdroppers. To address this, this paper proposes a framework of C-AmBC networks in the presence of an unlicensed eavesdropper. Specifically, we investigate the reliability and security of the proposed framework by invoking the outage probability (OP) and intercept probability (IP) with analytical derivations. In addition, the asymptotic behaviors are conducted for the OP in the high signal-to-noise ratio (SNR) regime and IP in the high main-to-eavesdropper ratio (MER) regime. Extensive analytical and computer simulated performance evaluation results show that: 1) when the considered system is under high SNR, the OP of the legitimate user and BD tends to be a non-zero fixed constant, indicating that the existence of error floors for the diversity orders; 2) the performance trade-off of reliability and security can be optimized by adjusting various parameters of the considered system; 3) with the increase of MER, the security of the legitimate user increases, while that of BD decreases.","2473-2400","","10.1109/TGCN.2021.3062060","Henan Provincial Science and Technology Research Project(grant numbers:212102210557); Key Scientific Research Projects of Higher Education Institutions in Henan Province(grant numbers:20A510007); National Natural Science Foundation of China(grant numbers:61901367); The Science and Technology Development Fund, Macau, China(grant numbers:0003/2019/A1); Joint Research Funding Project launched by the Ministry of Science and Technology of the People’s Republic of China and The Science and Technology Development Fund, Macau, China(grant numbers:0018/2019/AMJ); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9363336","Ambient backscatter communication;Internet-of-Things;physical layer security;cognitive radio network;outage probability;intercept probability","Backscatter;Security;Wireless communication;Signal to noise ratio;Reliability;IP networks;Communication system security","","91","","52","IEEE","25 Feb 2021","","","IEEE","IEEE Journals"
"Deep Reinforcement Learning for Online Resource Allocation in IoT Networks: Technology, Development, and Future Challenges","P. Cheng; Y. Chen; M. Ding; Z. Chen; S. Liu; Y. -P. P. Chen","La Trobe University, Australia; Fuzhou University, China; CSIRO DATA61, Australia; CSIRO DATA61, Australia; University of Sydney, Australia; La Trobe University, Australia","IEEE Communications Magazine","19 Jun 2023","2023","61","6","111","117","The growing number of complex and heterogeneous Internet of Things (IoT) applications has imposed a high demand for scarce communications and computing resources. To meet this stringent requirement, it is desirable to develop large-scale highly adaptive online resource allocation strategies to streamline existing network operations. Deep reinforcement learning (DRL), which combines the merits of reinforcement learning and deep learning, is capable of addressing complex decision-making tasks, thus enabling efficient online resource allocation. In this article, we present a DRL-based resource allocation framework. We begin a discussion on DRL basics and review its several recent applications. Then, we develop two new DRL algorithms that facilitate unlocking the potential of DRL and offer viable solutions to many more complex resource allocation problems. The first one tackles an optimization problem exposed to mixed (discrete and continuous) action spaces and bound by a number of highly non-linear quality-of-service (QoS) constraints. The second one extends the single-agent DRL to a more challenging multi-agent DRL by introducing a novel semi-distributed architecture. Finally, we discuss the challenges and future visions of applying DRL to real-world IoT networks.","1558-1896","","10.1109/MCOM.001.2200526","Australian Research Council (ARC)(grant numbers:DP210103410,DP220101634); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10155733","","Deep learning;Industries;Decision making;Reinforcement learning;Quality of service;Computer architecture;Resource management","","1","","15","IEEE","19 Jun 2023","","","IEEE","IEEE Magazines"
"Intellevator: An Intelligent Elevator System Proactive in Traffic Control for Time-Efficiency Improvement","G. Hangli; T. Hamada; T. Sumitomo; N. Koshizuka","Interfaculty Initiative in Information Studies, The University of Tokyo, Tokyo, Japan; Interfaculty Initiative in Information Studies, The University of Tokyo, Tokyo, Japan; Interfaculty Initiative in Information Studies, The University of Tokyo, Tokyo, Japan; Interfaculty Initiative in Information Studies, The University of Tokyo, Tokyo, Japan","IEEE Access","27 Feb 2020","2020","8","","35535","35545","Elevator functioning as a vertical transport facility remains stand-alone and incapable of accessing the fine-grained traffic information. It significantly restricts the flexibility and efficiency of vertical transporting. In particular, while in peak-time, the limited elevator physical capacity with the momentary traffic increment gives rise to the vertical traffic bottleneck problem in large-scale buildings. The problem further results in the long waiting, dissatisfaction, frustration of passengers. In this paper, we present our proposal named Intellevator: an intelligent elevator system that enables the passively functioning elevator system be proactive and intelligent in traffic control for optimizing the transport efficiency. The proposal is an end-to-end architecture that composed of three aspects: Internet of things (IoT)-enabling technology on a conventional elevator; an agent server to enhance elevator computational capability and a novel user interface for delivering system intelligence to end-users. The proposal was experimented on a conventional elevator in a built smart-building environment. Numerical simulation results have demonstrated the system efficiency improvement. In addition, the system usability and user experience have been evaluated by a user study as well.","2169-3536","","10.1109/ACCESS.2020.2975020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9003300","Elevator;Internet of Things;traffic control;adaptive computing;user interface","Elevators;User interfaces;Proposals;Optimization;Internet of Things;Servers","","6","","34","CCBY","19 Feb 2020","","","IEEE","IEEE Journals"
"Deep-Deterministic Policy Gradient Based Multi-Resource Allocation in Edge-Cloud System: A Distributed Approach","A. Qadeer; M. J. Lee","Department of Electrical Engineering, The City College of New York, New York, NY, USA; Department of Electrical Engineering, The City College of New York, New York, NY, USA","IEEE Access","2 Mar 2023","2023","11","","20381","20398","Edge Cloud (EC) empowers the beyond 5G (B5G) wireless networks to cope with large-scale and real-time traffics of Internet-of-Things (IoT) by minimizing the latency and providing compute power at the edge of the network. Due to a limited amount of resources at the EC compared to the back-end cloud (BC), intelligent resource management techniques become imperative. This paper studies the problem of multi-resource allocation (MRA) in terms of compute and wireless resources in an integrated EC and BC environment. Machine learning-based approaches are emerging to solve such optimization problems. However, it is challenging to adopt traditional discrete action space-based methods due to their high dimensionality issue. To this end, we propose a deep-deterministic policy gradient (DDPG) based temporal feature learning attentional network (TFLAN) model to address the MRA problem. TFLAN combines convolution, gated recurrent unit and attention layers together to mine local and long term temporal information from the task sequences for excellent function approximation. A novel heuristic-based priority experience replay (hPER) method is formulated to accelerate the convergence speed. Further, a pruning principle helps the TFLAN agent to significantly reduce the computational complexity and balance the load among base stations and servers to minimize the rejection-rate. Lastly, data parallelism technique is adopted for distributed training to meet the needs of a high-volume of IoT traffic in the EC environment. Experimental results demonstrate that the distributed training approach suites well to the problem scale and can magnify the speed of the learning process. We validate the proposed framework by comparing with five state-of-the-art RL agents. Our proposed agent converges fast and achieves up to 28% and 72% reduction in operational cost and rejection-rate, and achieves up to 32% gain in the quality of experience on average, compared to the most advanced DDPG agent.","2169-3536","","10.1109/ACCESS.2023.3249153","NSF PAWR COSMOS(grant numbers:1827923); NSF IRNC COSMIC(grant numbers:2029295); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10054044","Edge cloud computing;wireless networks;deep deterministic policy gradient;resource allocation;smart city;IoT;beyond 5G;distributed training;heuristic priority experience replay","Resource management;Internet of Things;Edge computing;Costs;Computational modeling;5G mobile communication;Cloud computing;Heuristic algorithms;Wireless networks","","1","","59","CCBY","27 Feb 2023","","","IEEE","IEEE Journals"
"Design and Implementation of the Intelligent Parking System for Large Communities","C. -W. Yang; W. -Q. Wang; F. -Y. Li","Department of Computer Science and Technology, Southwest University, Chongqing, China; Department of Management Science and Engineering, Southwest University, Chongqing, China; Department of Environmental Science, Nanjing University of Information Science & Technology, Nanjing, China","2021 International Conference on Computer, Internet of Things and Control Engineering (CITCE)","4 Mar 2022","2021","","","107","117","Nowadays, the scale of a community is expanding and the regional transportation network is ever more intricate against the backdrop of the population explosion. It posed an obstacle to people especially guests in finding spaces to park. It also disturbs residents and increases traffic risks. This paper proposes a multi-technology intelligent parking system that manages and guides vehicles in a large community to avoid chaos. A number of vehicles in a community are served by the system concurrently, which puts forward higher requirements for the performance of the system, so a parking space allocation algorithm and parallel path-finding algorithm are introduced. To monitor parking spaces and provide navigation service, Internet of Things (IoT) devices are deployed and they are generally controlled by the server computer. Furthermore, a client/server (C/S) architecture software project is developed and users are able to access the system via the Android or iOS application. In reality test, the performance and robustness of the system are exactly suitable for given conditions.","","978-1-6654-2184-3","10.1109/CITCE54390.2021.00028","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9723842","Internet of Things;parallel algorithm;software engineering;indoor navigation;intelligent parking system","Performance evaluation;Space vehicles;Navigation;Software algorithms;Sociology;Transportation;Aerospace electronics","","","","22","IEEE","4 Mar 2022","","","IEEE","IEEE Conferences"
"Simple and power efficient interface for AC-excited differential sensors","A. Depari; A. Flammini; E. Sisinni; G. Barile; G. Ferri; V. Stornelli","Dept.of Information Engineering, University of Brescia, Brescia, Italy; Dept.of Information Engineering, University of Brescia, Brescia, Italy; Dept.of Information Engineering, University of Brescia, Brescia, Italy; Dept.of Information Engineering, University of Brescia, Brescia, Italy; Dept.of Information Engineering, University of Brescia, Brescia, Italy; Dept.of Information Engineering, University of Brescia, Brescia, Italy","2020 IEEE International Instrumentation and Measurement Technology Conference (I2MTC)","30 Jun 2020","2020","","","1","6","Capacitive sensors are low-cost and robust devices that can be easily scaled to very small sizes, thus making them suitable for implementation as a micro electro-mechanical system (MEMS). Differential arrangements of the sensors are also available, providing improved rejection of common mode interference. Due to their nature, an AC (sinusoidal) excitation signal is usually adopted. Various types of front-end circuits have been proposed in the past, exploiting different techniques such as conversion of capacitance to current or frequency or analog-to-digital conversion and adopting different approaches, such as full analog or full digital architectures. This paper proposes a digital and microcontroller-based system for AC-excited differential sensors aiming at minimizing cost and power needs, in sight of future large volume applications as for Internet of Things (IoT) paradigm. A proof of concept implementation has been realized and experimentally validated, obtaining a relative error in the measurand estimation on the order of 1%, when the parasitic effects can be neglected.","2642-2077","978-1-7281-4460-3","10.1109/I2MTC43012.2020.9128997","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9128997","Differential sensors;capacitive sensors;AC excitation;synchronous demodulation","Micromechanical devices;Microcontrollers;Measurement uncertainty;Prototypes;Linearity;Interference;Capacitive sensors","","1","","27","IEEE","30 Jun 2020","","","IEEE","IEEE Conferences"
"LightAMC: Lightweight Automatic Modulation Classification via Deep Learning and Compressive Sensing","Y. Wang; J. Yang; M. Liu; G. Gui","College of Telecommunications and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China; College of Telecommunications and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China; College of Telecommunications and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China; College of Telecommunications and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China","IEEE Transactions on Vehicular Technology","13 Mar 2020","2020","69","3","3491","3495","Automatic modulation classification (AMC) is an promising technology for non-cooperative communication systems in both military and civilian scenarios. Recently, deep learning (DL) based AMC methods have been proposed with outstanding performances. However, both high computing cost and large model sizes are the biggest hinders for deployment of the conventional DL based methods, particularly in the application of internet-of-things (IoT) networks and unmanned aerial vehicle (UAV)-aided systems. In this correspondence, a novel DL based lightweight AMC (LightAMC) method is proposed with smaller model sizes and faster computational speed. We first introduce a scaling factor for each neuron in convolutional neural network (CNN) and enforce scaling factors sparsity via compressive sensing. It can give an assist to screen out redundant neurons and then these neurons are pruned. Experimental results show that the proposed LightAMC method can effectively reduce model sizes and accelerate computation with the slight performance loss.","1939-9359","","10.1109/TVT.2020.2971001","National Science and Technology Major Project of the Ministry of Science and Technology of China(grant numbers:TC190A3WZ-2); National Natural Science Foundation of China(grant numbers:61671253); Jiangsu Specially Appointed Professor(grant numbers:RK002STP16001); Innovation and Entrepreneurship of Jiangsu High-level Talent(grant numbers:CZ0010617002); Six Top Talents Program of Jiangsu(grant numbers:XYDXX-010); Nanjing University of Posts and Telecommunications; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8978670","Lightweight automatic modulation classification (LightAMC);convolutional neural network (CNN);neuron pruning;compressive sensing","Neurons;Signal to noise ratio;Modulation;Feature extraction;Training;Support vector machines;Computational modeling","","177","","26","IEEE","3 Feb 2020","","","IEEE","IEEE Journals"
"An End-to-End Recommendation System for Urban Traffic Controls and Management Under a Parallel Learning Framework","J. Jin; H. Guo; J. Xu; X. Wang; F. -Y. Wang","Enjoyor Co., Ltd., Hangzhou, China; Enjoyor Co., Ltd., Hangzhou, China; Enjoyor Co., Ltd., Hangzhou, China; State Key Laboratory for Management and Control of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; State Key Laboratory for Management and Control of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Intelligent Transportation Systems","1 Mar 2021","2021","22","3","1616","1626","A paradigm shift towards agile and adaptive traffic signal control empowered with the massive growth of Big Data and Internet of Things (IoT) technologies is emerging rapidly for Intelligent Transportation Systems. Generally, an adaptive signal control system fine-tunes signal timing parameters based on pre-defined control hyperparameters using instantaneous traffic detection information. Once traffic pattern changes, those hyperparameters (e.g., maximum and minimum green times) need to be adjusted according to the evolution of traffic dynamics over a very short-term period. Such adjustment processes are usually conducted by professional and experienced traffic engineers. Here we present a human-in-the-loop parallel learning framework and its utilization in an end-to-end recommendation system that mimics and enhances professional signal control engineers' behaviors. The system has been deployed into a real-world application for an extended period in Hangzhou, China, where signal control hyperparameters are recommended based on large-scale multidimensional traffic datasets. Experimental evaluations demonstrate significant improvements in traffic efficiency through the use of our signal recommendation system.","1558-0016","","10.1109/TITS.2020.2973736","China Post-Doctoral Science Foundation(grant numbers:2019M660136); Natural Science Foundation of Zhejiang Province(grant numbers:LY20E080023); National Natural Science Foundation of China(grant numbers:U1811463); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9005386","Intelligent traffic control;traffic signal control;parallel learning;recommendation systems;deep neural networks","Control systems;Urban areas;Timing;Adaptive systems;Real-time systems;Recurrent neural networks;Process control","","46","","37","IEEE","20 Feb 2020","","","IEEE","IEEE Journals"
"Feature-Aided Adaptive-Tuning Deep Learning for Massive Device Detection","X. Shao; X. Chen; Y. Qiang; C. Zhong; Z. Zhang","College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China","IEEE Journal on Selected Areas in Communications","16 Jun 2021","2021","39","7","1899","1914","With the increasing development of Internet of Things (IoT), the upcoming sixth-generation (6G) wireless network is required to support grant-free random access of a massive number of sporadic traffic devices. In particular, at the beginning of each time slot, the base station (BS) performs joint activity detection and channel estimation (JADCE) based on the received pilot sequences sent from active devices. Due to the deployment of a large-scale antenna array and the existence of a massive number of IoT devices, conventional JADCE approaches usually have high computational complexity and need long pilot sequences. To solve these challenges, this paper proposes a novel deep learning framework for JADCE in 6G wireless networks, which contains a dimension reduction module, a deep learning network module, an active device detection module, and a channel estimation module. Then, prior-feature learning followed by an adaptive-tuning strategy is proposed, where an inner network composed of the Expectation-maximization (EM) and back-propagation is introduced to jointly tune the precision and learn the distribution parameters of the device state matrix. Finally, by designing the inner layer-by-layer and outer layer-by-layer training method, a feature-aided adaptive-tuning deep learning network is built. Both theoretical analysis and simulation results confirm that the proposed deep learning framework has low computational complexity and needs short pilot sequences in practical scenarios.","1558-0008","","10.1109/JSAC.2021.3078500","National Key Research and Development Program of China(grant numbers:2018YFB1801104); Zhejiang Provincial Natural Science Foundation of China(grant numbers:LR20F010002); National Natural Science Foundation of China(grant numbers:61871344); National Natural Science Foundation of China(grant numbers:61922071); National Natural Science Foundation of China(grant numbers:61725104); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9432908","6G;grant-free random access;active device detection;channel estimation;deep learning","Deep learning;Performance evaluation;6G mobile communication;Wireless networks;Channel estimation;Antenna arrays;Feature extraction","","22","","46","IEEE","17 May 2021","","","IEEE","IEEE Journals"
"Mosaic Privacy-Preserving Mechanisms for Healthcare Analytics","A. Krall; D. Finke; H. Yang","the Complex Systems Monitoring, Modeling and Control lab, The Pennsylvania State University, University Park, PA, USA; the Applied Research Lab, University Park, PA, USA; the Complex Systems Monitoring, Modeling and Control lab, The Pennsylvania State University, University Park, PA, USA","IEEE Journal of Biomedical and Health Informatics","11 Jun 2021","2021","25","6","2184","2192","The Internet of Things (IoT) has propelled the evolution of medical sensing technologies to greater heights. Thus, traditional health systems have been transformed into new data-rich environments. This provides an unprecedented opportunity to develop new analytical methods and tools towards a new paradigm of smart and interconnected health systems. Nevertheless, there are risks pertinent to increasing levels of system connectivity and data accessibility. Cyber-attacks become more prevalent and complex, leading to greater likelihood of data breaches. These events bring sudden disruptions to routine operations and cause the loss of billions of dollars. Adversaries often attempt to leverage models to learn a target's sensitive attributes or extrapolate its inclusion within a database. As healthcare systems are critical to improving the wellbeing of our society, there is an urgent need to protect the privacy of patients and minimize the risk of model inversion attacks. This paper presents a new approach, named Mosaic Gradient Perturbation (MGP), to preserve privacy in the framework of predictive modeling, which meets the requirement of differential privacy while mitigating the risk of model inversion. MGP is flexible in fine-tuning the trade-offs between model performance and attack accuracy while being highly scalable for large-scale computing. Experimental results show that the proposed MGP method improves upon traditional gradient perturbation to mitigate the risk of model inversion while offering greater preservation of model accuracy. The MGP technique shows strong potential to circumvent paramount costs due to privacy breaches while maintaining the quality of existing decision-support systems, thereby ushering in a privacy-preserving smart health system.","2168-2208","","10.1109/JBHI.2020.3036422","NSF I/UCRC Center for Healthcare Organization Transformation (CHOT), NSF I/UCRC(grant numbers:#1624727); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9250511","Differential privacy;model inversion attack;Internet of Things;predictive modeling;machine learning;health informatics;mosaic gradient perturbation","Differential privacy;Predictive models;Data models;Computational modeling;Perturbation methods;Bioinformatics;Internet of Things","Delivery of Health Care;Humans;Internet of Things;Privacy;Software","13","","20","IEEE","6 Nov 2020","","","IEEE","IEEE Journals"
"Learning-based Multivariate Real-Time Data Pruning for Smart PMU Communication","R. Gupta; V. Gupta; A. K. Mandal; S. De","Department of Electrical Engineering, IIT Delhi, New Delhi, India; Department of Electrical Engineering, IIT Delhi, New Delhi, India; Department of Electrical Engineering, IIT Delhi, New Delhi, India; Department of Electrical Engineering, IIT Delhi, New Delhi, India","2022 IEEE 19th Annual Consumer Communications & Networking Conference (CCNC)","10 Feb 2022","2022","","","326","331","This paper proposes a novel machine learning-based multivariate real-time data pruning and prediction framework for smart PMU (phasor measurement unit) communication. In an Internet-of-Things (IoT) enabled smart grid monitoring application, the proposed data-driven pruning technique exploits cross- and auto-correlation in multiple attributes sensed by a PMU (IoT node). The attributes are classified into base and nonbase groups based on their ability to aid prediction of the remaining attributes. The idea of transmitting only base attributes reduces the data dimensionality significantly. A reconstruction algorithm is designed for the edge node (local Phasor Data Concentrator) for efficient data reconstruction. The performance of the proposed framework is evaluated on large-scale real-time data from the PMUs. Comparison of the proposed technique with the closest state-of-the-art multi-threaded uni-variate data pruning algorithm in literature demonstrates around 40% more bandwidth saving and ∼42% reduction in retraining count.","2331-9860","978-1-6654-3161-3","10.1109/CCNC49033.2022.9700543","Science and Engineering Research Board; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9700543","Smart PMU data communication;learning algorithm;multivariate data pruning;support vector regression;low latency","Estimation;Bandwidth;Reconstruction algorithms;Rendering (computer graphics);Prediction algorithms;Phasor measurement units;Real-time systems","","4","","18","IEEE","10 Feb 2022","","","IEEE","IEEE Conferences"
"Automating and Optimizing Reliability-Driven Deployment in Energy-Harvesting IoT Networks","X. Yu; K. Ergun; X. Song; L. Cherkasova; T. Š. Rosing","University of California at San Diego, La Jolla, CA, USA; University of California at San Diego, La Jolla, CA, USA; University of California at San Diego, La Jolla, CA, USA; Arm Research, San Jose, CA, USA; University of California at San Diego, La Jolla, CA, USA","IEEE Transactions on Network and Service Management","10 Mar 2023","2023","20","1","787","799","Recent years have witnessed a significant expansion in Internet-of-Things (IoT) applications. Although the battery energy availability can be improved with energy harvesting, the overall device reliability management has been overlooked in the existing literature. State-of-the-art reliability models of solar panels, electronics and rechargeable batteries show exponential dependence of failures on temperature. This work is the first to develop a comprehensive reliability deployment framework for energy-harvesting IoT networks, reflecting the non-negligible thermal stresses on each hardware component. Our framework improves the reliability on both pre-deployment and post-deployment stages. Prior to deployment, given the historical temperature and solar radiation of the region, we formulate a Mixed Integer Linear Program (MILP) to place the minimum number of nodes, while ensuring (i) full target coverage, (ii) complete connectivity, (iii) energy-neutral operation, and (iv) reliability constraints at each deployed node. We propose a polynomial-time heuristic, R-TSH, to approximate the optimal placement in large-scale deployments. While R-TSH optimizes long-term reliability, the prompt temperature or link quality differences from the historical patterns can significantly degrade device reliability after deployment. The post-deployment section of our design consists of a reliability-driven routing algorithm, AODV-Rel, that adapts to real-time environmental and link quality changes. Extensive analysis is done using a real-world dataset from the National Solar Radiation Database. Simulations in ns-3 show that R-TSH meets all reliability constraints even after 5 years of deployment as compared to the state of the art. In addition, it is 2000x faster than the optimal solution, while placing only 28% more nodes. AODV-Rel further extends the minimal operational lifetime by 1.5 and 2.8 months under temperature deviation and wireless interference.","1932-4537","","10.1109/TNSM.2022.3208083","Semiconductor Research Corporation task(grant numbers:#2805.001); National Science Foundation(grant numbers:#1911095,#1826967,#1730158,#1527034,#2100237,#2112167,#2003279); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9896167","IoT networks;energy harvesting;reliability;sensor deployment;adaptive routing","Reliability;Batteries;Temperature sensors;Internet of Things;Aging;Routing;Reliability engineering","","","","39","IEEE","20 Sep 2022","","","IEEE","IEEE Journals"
"Toward Highly-Efficient and Accurate Services QoS Prediction via Machine Unlearning","Y. Zeng; J. Xu; Y. Li; C. Chen; Q. Dai; Z. Du","College of Engineering, Shantou University, Shantou, China; College of Engineering, Shantou University, Shantou, China; College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; College of Engineering, Shantou University, Shantou, China; College of Engineering, Shantou University, Shantou, China; College of Engineering, Shantou University, Shantou, China","IEEE Access","28 Jul 2023","2023","11","","76242","76254","Personalized Internet of Things (IoT) services prediction based on Quality-of-Service (QoS) is an indispensable technique for selecting appropriate services for each user. However, existing collaborative prediction models do not take into account the user’s authority to manage their own generated data. From the standpoint of users, the expectation is for models to eliminate the impact of their sensitive data to the greatest extent possible. Meanwhile, IoT service providers face the challenge of data contamination during service provision, which necessitates models to forget data quickly and accurately to restore performance. Furthermore, existing QoS prediction methods usually suffer from low model availability when handling unlearning requests by full retraining. This underscores the need to address security, availability, fidelity, privacy, and related issues, highlighting the urgency of unlearning. To solve the problem, we propose Context-Aware Data Driven Eraser (CADDEraser), a novel efficient machine unlearning framework for QoS prediction tasks. Firstly, we divide the training data into multiple shards to train submodels and obtain node embeddings by utilizing contextual information to derive graph embeddings. Then these embeddings are employed in a balanced clustering partition, ensuring the preservation of the QoS record between users and services. Finally, we use a concatenate aggregation method and stacking & attention-based aggregation methods to synthesize information from sub-models more efficiently. Experiments on large-scale datasets show that our CADDEraser framework not only improves efficiency but also enhances the accuracy of QoS prediction, achieving efficient unlearning and outperforms state-of-the-art unlearning approaches. Source codes are available at https://github.com/ZengYuXiang7/CADDEraser.","2169-3536","","10.1109/ACCESS.2023.3291410","Guangdong Province Special Fund for Science and Technology (“Major Special Projects + Task List”)(grant numbers:STKJ2021201,STKJ202209017); 2020 Li Ka Shing Foundation Cross-Disciplinary Research(grant numbers:2020LKSFG08D); Special Projects in Key Fields of Guangdong Universities(grant numbers:2022ZDZX1008); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2023A1515010707); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10171348","Internet of Things;machine unlearning;context-aware;QoS prediction","Quality of service;Data models;Predictive models;Training;Task analysis;Collaboration;Stacking;Internet of Things;Context awareness","","","","45","CCBYNCND","3 Jul 2023","","","IEEE","IEEE Journals"
"Web of Things: Security Challenges and Mechanisms","R. Sardar; T. Anees","School of Systems and Technology, University of Management and Technology, Lahore, Pakistan; School of Systems and Technology, University of Management and Technology, Lahore, Pakistan","IEEE Access","26 Feb 2021","2021","9","","31695","31711","Web of things (WoT) is an improved and most promising infrastructure of the internet of things (IoT) which permits the smart things to not only integrate to the internet but also to the web. It allows the users to share and create content as well as provide capabilities for data aggregation and analysis through a network to become part of the World Wide Web (W3). Despite these advances, it has shown several security challenges that need to be addressed for the successful deployment of WoT on a commercially variable and large scale. In this paper, authors have analyzed the most noticeable security challenges related to WoT such as unauthorized access, eavesdropping, denial of service attack, tempering, and impersonating, through an analysis of already published empirical studies. Further, we have discussed some of the available mechanisms to overcome security related issues while taking into account the network size and mobility. Authors have used Threat analysis and attack modeling methods to inform the users about defensive measures and to prevent security threats from taking advantage of system flaws Authors have provided the necessary insight into how security can be improved by using certain existing mechanisms and algorithms. The findings of the study revealed that security mechanisms to secure WoT are still immature and future research is required to resolve these challenges.","2169-3536","","10.1109/ACCESS.2021.3057655","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9349366","Web of things;Internet of Things;security challenges;security mechanisms;World Wide Web;security analysis;attack modeling","Security;Internet of Things;Privacy;Protocols;Authentication;Computer architecture;Standards","","15","","75","CCBY","8 Feb 2021","","","IEEE","IEEE Journals"
"Efficient and Secure Image Communication System Based on Compressed Sensing for IoT Monitoring Applications","L. Li; G. Wen; Z. Wang; Y. Yang","Information Security Center, State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; Information Security Center, State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; Information Security Center, State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; Information Security Center, State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China","IEEE Transactions on Multimedia","3 Jan 2020","2020","22","1","82","95","The Internet of Things (IoT) has attracted extensive attention in the information field. Its rapid development has promoted several monitoring application domains. However, the resource constraint of sensor nodes and the security of data transmission have emerged as significant issues. In this paper, an image communication system for IoT monitoring applications is exploited to solve the above-mentioned problems simultaneously. The proposed system can satisfy the requirements of sensor nodes for low computational complexity, low-energy consumption, and low storage overhead. We also present a new compressed sensing (CS) model, as well as the corresponding parallel reconstruction algorithm, which help to reduce the image encryption/decryption time. Based on chaotic systems, we integrate the quantization and diffusion operations into the system to further enhance the transmission security. The simulations are executed to demonstrate the feasibility and the effectiveness of the proposed method. Compared with the traditional CS, our numerical results indicate that the proposed model reduces 413 ms computation time and 3.13 × 106 elements stored for large-scale images. Besides, we verify the flexibility and the diversity of choosing two submatrices for different-sized images. Experimental results also show the proposed system performs well in terms of security performance. Particularly the key space reaches 2253.","1941-0077","","10.1109/TMM.2019.2923111","National Key R&D Program of China(grant numbers:2016YFB0800602); National Natural Science Foundation of China(grant numbers:61771071,61573067); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8736710","Internet of Things (IoT);image transmission;compressed sensing;chaotic systems","Monitoring;Internet of Things;Compressed sensing;Wireless sensor networks;Image communication;Image reconstruction;Cryptography","","42","","46","IEEE","14 Jun 2019","","","IEEE","IEEE Journals"
"A Novel Deep Learning Based Automated Academic Activities Recognition in Cyber-Physical Systems","M. Wasim; I. Ahmed; J. Ahmad; M. M. Hassan","Center of Excellence in IT, Institute of Management Sciences, Peshawar, Pakistan; Center of Excellence in IT, Institute of Management Sciences, Peshawar, Pakistan; Center of Excellence in IT, Institute of Management Sciences, Peshawar, Pakistan; Research Chair of Smart Technologies, College of Computer and Information Science, King Saud University, Riyadh, Saudi Arabia","IEEE Access","30 Apr 2021","2021","9","","63718","63728","Internet of Things (IoT) has rapidly developed in multidisciplinary research topics, particularly in Cyber-Physical infrastructures, such as smart-health care, transportation systems, vehicle management surveillance systems. The smart-video surveillance system has become an essential part of almost all security applications, including academic institutions. University campuses have rich video repositories comprising almost all kinds of academic and non-academic activities. Researchers have introduced many state-of-art activity recognition methods for various application domains with the availability of several activity data sets. Unfortunately, none of these data sets or methods have been developed explicitly for academia and do not cover academic activities. With the advancement of deep learning and IoT, the processing of large-scale video data has become convenient for performing various video analysis tasks. Thus, in this work, an automated deep learning-based academic activities recognition system is presented in smart-cyber infrastructure. We explore a new academic campus domain for research and proposed a novel Convolutional Neural Network (CNN) model for academic activities recognition utilizing a realistic campus dataset. The video database typically contains long, 24-hour video streams recorded by surveillance cameras installed in campus environments. The proposed model's efficiency is tested through extensive experimentation in terms of accuracy, computation time, and memory requirement. The experimental results reveal that the proposed method attains good results with an accuracy of 98%.","2169-3536","","10.1109/ACCESS.2021.3073890","Deanship of Scientific Research, King Saud University through the Vice Deanship of Scientific Research Chairs: Research Chair of Smart Technologies; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9406808","Cyber-physical system;academic activity recognition;campus data set;CNN;deep learning model","Activity recognition;Task analysis;Solid modeling;Feature extraction;Deep learning;Streaming media;Cameras","","8","","41","CCBY","19 Apr 2021","","","IEEE","IEEE Journals"
"Stein Variational Recommendation System with Knowledge Embedding Enabling the IoT Services","J. Liu; Y. Chen; S. M. N. Islam; P. Siano","School of Cyberspace, Hangzhou Dianzi University, China; School of Cyberspace, Hangzhou Dianzi University, China; Institute for Sustainable Industries and Liveable Cities, Victoria University, Australia; Department of Industrial Engineering, University of Salerno, Fisciano (SA), Italy","IECON 2021 – 47th Annual Conference of the IEEE Industrial Electronics Society","10 Nov 2021","2021","","","1","6","The Internet of Things (IoT) interconnects various devices and services, of which recommendation services are an important component to help the development of IoT applications. Furthermore, without the aid of suitable online recommendation systems, Internet users will be overwhelmed by the tremendous amount of contents. Researchers have thus developed a large volume of recommendations. However, they are all flawed with high complexity, cold start issues, inability to generalize, etc. In recent years, some researchers had turned to variational inference (VI)-based recommendation systems, which can solve the above problems to some extent. However, these VI-based recommendations are merely hybrid methods of VI with the existing recommendation algorithms and are unable to be implemented well in real practices. Therefore, developing algorithms that can overcome these limitations of the existing online recommendation systems is essential for convenient and useful Internet searches. In this paper, we propose, develop, implement and test a more general, new and innovative Stein Variational Recommendation System algorithm (SVRS) to tackle the long plaguing recommendation problems. Based on Stein’s identity, the SVRS algorithm can compute the feature vector of existing users and items it had rated, and further predict the ratings for users that have not been engaged with certain content. SVRS provides more general insights into the forming of user ratings, can be easily extended to higher dimensions and has the merits of low complexity, easy scaling and generalizability. Experiments show that SVRS outperforms the other existing type of recommendation algorithms and it has higher accuracy in terms of mean absolute error (MAE) and root mean square error (RMSE).","2577-1647","978-1-6654-3554-3","10.1109/IECON48115.2021.9589064","National Science Foundation; Natural Science Foundation of Jiangsu Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9589064","Online Recommendation System;Stein Variational;Variational Inference;Internet of Things;Knowledge Embedding","Industrial electronics;Electric potential;Conferences;Prediction algorithms;Inference algorithms;Complexity theory;Internet of Things","","","","32","IEEE","10 Nov 2021","","","IEEE","IEEE Conferences"
"Adaptive Dynamic Programming and Zero-Sum Game-Based Distributed Control for Energy Management Systems With Internet of Things","L. N. Tan; N. Gupta; M. Derawi","Faculty of Electrical-Electronics Engineering, Ho Chi Minh City University of Technology, Ho Chi Minh City, Vietnam; Department of Electronic Systems, Faculty of Information Technology and Electrical Engineering, Norwegian University of Science and Technology, Gjøvik, Norway; Department of Electronic Systems, Faculty of Information Technology and Electrical Engineering, Norwegian University of Science and Technology, Gjøvik, Norway","IEEE Internet of Things Journal","11 Dec 2023","2023","10","24","22371","22385","Energy management systems (EMS) in smart grids provide end users with the optimal operational efficiency of power from nonsmart microgrids, including power grids, energy storage systems (ESS), and residential loads. This article proposes a novel distributed online control policy for Ambient Intelligence (AmI)-based Internet of Things (IoT) environments, optimizing a consensus utility function, including electricity cost and the lifespan of ESS. Different from the existing methods, the distributed EMS via IoT can gain cooperative  $\boldsymbol {L_{2}}$  performance by rejecting external disturbances and providing consensus policies for robust optimal charging and discharging. First, consensus dynamics of AmI-agents are constructed, and the Hamilton–Jacobi-Isaacs (HJI) equations are established, where the Nash equilibrium points are approximated by ADP and zero-sum game theory. Second, with the aid of an actor-critic structure, a robust optimal distributed control algorithm in an online manner for EMS is proposed. Therefore, collecting sample sets and training offline are completely avoided. Third, to deal with the unknown internal dynamics of ESS, the  $Q$ -learning algorithm is employed instead of system identification techniques that require available sample sets. The algorithm guarantees that the global load is balanced and that the consensus tracking error and the function approximation error are uniformly ultimately bounded. Finally, numerical simulations are provided to verify the effectiveness of the proposed algorithm for a large-scale system of nonsmart microgrids.","2327-4662","","10.1109/JIOT.2023.3303448","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10214080","Adaptive dynamic programming;energy management;energy storage;Internet of Things (IoT);zero-sum game","Energy management;Internet of Things;Smart grids;Renewable energy sources;Game theory;Heuristic algorithms;Decentralized control","","","","53","IEEE","9 Aug 2023","","","IEEE","IEEE Journals"
"BC-Mobile Device Cloud: A Blockchain-Based Decentralized Truthful Framework for Mobile Device Cloud","M. Wang; C. Xu; X. Chen; L. Zhong; Z. Wu; D. O. Wu","State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; Information Engineering College, Capital Normal University, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA","IEEE Transactions on Industrial Informatics","19 Nov 2020","2021","17","2","1208","1219","By exploiting the massive data generated from the numerous interconnected machines and control systems, industrial Internet-of-Things (IIoT) provides unprecedented opportunities for facilitating the intelligence and smartness of manufacturing. Timely processing the large-scaled IIoT data by the conventional computation framework, such as Cloud computing, however, is nontrivial due to its costly resource usage, intolerable delay, and unbearable backbone pressures. By leveraging the idle resources of smart objects at the edge, mobile device cloud (MDC) becomes promising for the IIoT data analysis, thanks to the flexible resource provision and nearby task offloading. However, MDC workers are mostly human-carried devices with large scale, high dynamic resource provision, and untruthful behaviors, which pose significant challenges on MDC task allocation. In this article, we propose a blockchain-based decentralized and truthful framework for MDC (BC-MDC). BC-MDC enables the decentralization and prevents dishonesty by incorporating a plasma-based blockchain into the MDC. We design four smart contracts for distributedly managing the worker registration, task posting/allocation, rewarding, and penalizing. Furthermore, MDC task allocation is formulated as a stochastic optimization problem that jointly minimizes the long-term processing cost and risk of task failing. We also design a truthful reward/penalty algorithm that stimulates workers to provide resources and enforce them to keep the promise as well. Collaborated by the extensive simulation tests, we show how our proposed scheme achieves low cost on usage and high truthfulness and outperforms state-of-the-art solutions.","1941-0050","","10.1109/TII.2020.2983209","National Key R&D Program of China(grant numbers:2018YFE0205502); National Natural Science Foundation of China(grant numbers:6187104,61872253); National Science Foundation(grant numbers:CCF-1617815); Higher Education Discipline Innovation Project(grant numbers:B18008); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9051813","Decentralization;mobile device cloud (MDC);stochastic optimization;task allocation;truthfulness","Task analysis;Resource management;Blockchain;Smart contracts;Cloud computing;Mobile handsets;Informatics","","20","","31","IEEE","31 Mar 2020","","","IEEE","IEEE Journals"
"Towards 6G Joint HAPS-MEC-Cloud 3C Resource Allocation for Delay-Aware Computation Offloading","Y. Yang; X. Chang; Z. Jia; Z. Han; Z. Han","Beijing Key Laboratory of Security and Privacy in Intelligent Transportation, Beijing Jiaotong University, Beijing, China; Beijing Key Laboratory of Security and Privacy in Intelligent Transportation, Beijing Jiaotong University, Beijing, China; State Key Laboratory of ISN, Information Science Institute, Xidian University, Xi'an, China; Department of Electrical and Computer Engineering, University of Houston, Houston, TX, US; Beijing Key Laboratory of Security and Privacy in Intelligent Transportation, Beijing Jiaotong University, Beijing, China","2020 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)","4 Jun 2021","2020","","","175","182","The past years witnessed the tremendous growth of Internet of things (IoT) service, each of which demands different amounts of physical resources consisting of computation, communication, and caching, which is also recognized as 3C. The fifth-generation (5G) technique is a promising answer to serve delay-sensitive IoT applications with diverse popular emerging techniques such as multi-access edge computing (MEC) and cloud computing. However, when we get to 2030, the requirements will hard to satisfied. The sixth-generation (6G) aims to provide global coverage, enhanced energy and cost efficiency, better intelligence level, and security. A potential solution for the 6G system is the aerial access network (AAN). The high altitude platform system (HAPS) is also a candidate for deploying wireless communications applying the terrestrial communication infrastructure. However, how to efficiently utilize the 3C resources in the HAPS-terrestrial networks is a non-trivial issue. We study the offloading computation problem of the IoT applications which ask 3C resources in the HAPS-MEC-cloud networks with high efficiency. In detail, We formulate the computation offloading problem into an optimization problem to minimize costs under multiple resource constraints. Since the problem is integer linear programming (ILP), it is hard to apply the general exhaustive searching to solve the problem when there are a lot of mobile terminal devices. The column generation algorithm can solve the large-scale ILP problem efficiently. Thus, we propose a column generation computation offloading (CG-CO) algorithm based on it. Meanwhile, we proposed a greedy computation offloading algorithm (G-CO) based on a greedy algorithm for comparison to make the simulation results in more convictive. We use the task acceptance ratio, service providers' total revenue, and cost as the metrics. Experiment results demonstrate that CG-CO can help get good results in both resource-abundant and resource-limited scenarios.","","978-1-6654-1485-2","10.1109/ISPA-BDCloud-SocialCom-SustainCom51426.2020.00048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9443997","multi-access edge computing;computation of-floading;aerial access network;high altitude platform system;column generation","6G mobile communication;Wireless communication;Measurement;Simulation;Search problems;Internet of Things;Security","","8","","25","IEEE","4 Jun 2021","","","IEEE","IEEE Conferences"
"Voting-Based Multiagent Reinforcement Learning for Intelligent IoT","Y. Xu; Z. Deng; M. Wang; W. Xu; A. M. -C. So; S. Cui","Key Laboratory of Universal Wireless Communications, Ministry of Education, Beijing University of Posts and Telecommunications, Beijing, China; Department of Systems Engineering and Engineering Management, Chinese University of Hong Kong, Hong Kong; Department of Electrical Engineering, Center for Statistics and Machine Learning, Department of Operations Research and Financial Engineering, and Department of Computer Science, Princeton University, Princeton, NJ, USA; Key Laboratory of Universal Wireless Communications, Ministry of Education, Beijing University of Posts and Telecommunications, Beijing, China; Department of Systems Engineering and Engineering Management, Chinese University of Hong Kong, Hong Kong; Shenzhen Research Institute of Big Data and Future Network of Intelligence Institute, Chinese University of Hong Kong, Shenzhen, China","IEEE Internet of Things Journal","5 Feb 2021","2021","8","4","2681","2693","The recent success of single-agent reinforcement learning (RL) in Internet of Things (IoT) systems motivates the study of multiagent RL (MARL), which is more challenging but more useful in large-scale IoT. In this article, we consider a voting-based MARL problem, in which the agents vote to make group decisions and the goal is to maximize the globally averaged returns. To this end, we formulate the MARL problem based on the linear programming form of the policy optimization problem and propose a primal–dual algorithm to obtain the optimal solution. We also propose a voting mechanism through which the distributed learning achieves the same sublinear convergence rate as centralized learning. In other words, the distributed decision making does not slow down the process of achieving global consensus on optimality. Finally, we verify the convergence of our proposed algorithm with numerical simulations and conduct case studies in practical multiagent IoT systems.","2327-4662","","10.1109/JIOT.2020.3021017","National Key Research and Development Program of China(grant numbers:2018YFB1800800/802); Special Project for Research and Development in Key areas of Guangdong Province(grant numbers:2018B030338001); Natural Science Foundation of China(grant numbers:NSFC-61629101,NSFC- 61771066); Guangdong Research Project(grant numbers:2017ZT07X152); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9184075","Multiagent reinforcement learning (MARL);primal–dual algorithm;voting mechanism","Convergence;Internet of Things;Optimization;Collaboration;Task analysis;Learning (artificial intelligence);Games","","6","","63","IEEE","1 Sep 2020","","","IEEE","IEEE Journals"
"Cross Technology Distributed MIMO for Low Power IoT","R. Narayanan; S. Kumar; C. S. R. Murthy","Department of Computer Science and Engineering, Indian Institute of Technology Madras, Chennai, Tamil Nadu, India; Carnegie Mellon University, Pittsburgh, PA, USA; Department of Computer Science and Engineering, Indian Institute of Technology Madras, Chennai, Tamil Nadu, India","IEEE Transactions on Mobile Computing","4 Apr 2022","2022","21","5","1609","1624","The Internet of Things (IoT) is scaling rapidly to billions of low power devices, with diverse radio technologies sharing common unlicensed spectrum. Inevitably, this results in rampant cross-technology collisions between the devices that lead to wasteful re-transmissions, draining the battery life of low-power devices significantly. We present CharIoT, the first cross-technology distributed MIMO receiver system that exploits the potential of distributed MIMO to facilitate better co-existence and decoding of a large number of simultaneous low power uplink transmissions from unmodified low-power clients. CharIoT is a recovery-based system that intelligently collects radio samples from teams of light-weight IoT gateways and streams them to the cloud to effectively resolve collisions. At the cloud, CharIoT develops a suite of technology-specific software filters that decouple collisions across diverse technologies, facilitating seamless co-existence across low power radios. An implementation of CharIoT on inexpensive RTL-SDR gateways connected to Raspberry Pis decode collisions of four popular IoT technologies in the 868MHz ISM bands – LoRa, XBee, Z-Wave, and SIGFOX showing gains in throughput of up to 4× and battery life of up to 3.5 years.","1558-0660","","10.1109/TMC.2020.3029218","Department of Science and Technology, Republic of the Philippines(grant numbers:SB/S2/JCB-008/2016); National Science Foundation(grant numbers:1942902,1718435,1837607,2030154); Kavcic-Moura; CMU Cylab-IoT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9215047","Internet of Things;Low Power;Iot Radio Technologies;Iot Gateway;Distributed MIMO","Logic gates;MIMO communication;Software;Internet of Things;Synchronization;Receivers;Decoding","","2","","63","IEEE","6 Oct 2020","","","IEEE","IEEE Journals"
"A Lightweight Smart Meter Framework using a Scalable Blockchain for Smart Cities","J. -L. Lee; P. BusiReddyGari; B. Thompson","Department of Mathematics and Computer Science, The University of North Carolina at Pembroke, Pembroke, NC; Department of Mathematics and Computer Science, The University of North Carolina at Pembroke, Pembroke, NC; Department of Computer Science, The University of North Carolina, Chapel Hill, NC","2021 IEEE 7th World Forum on Internet of Things (WF-IoT)","9 Nov 2021","2021","","","433","438","The role of smart meters in the smart cities is becoming increasingly important. These smart meters are always connected to the network and this connectivity may leads to security risks. And, blockchain (BC) technology has recently received a lot of attention due to its data security stability and a distributed platform. BC has been applied to a plethora of different applications. However, BC requires high performance to be applied directly to a smart meter, which is an Internet of Things (IoT) device with low memory and slow CPU computation power. And, it cannot be scale up easily due to the nature of the distributed system. In order to compensate for this shortcoming, we propose a lightweight smart meter framework using BC technology, which is scalable and requires low computation power. In this proposed framework, data blockchain (dBC) and meta blockchain (mBC) are divided, and smart meters are divided into small groups to support scalability. The two proposed grouping algorithms are a delay-aware grouping algorithm that considers network delay and a random grouping algorithm that can improve security with a randomness. We also propose a new Enhanced Privacy Piggy Bank Protocol (EPPB) using bilinear pairing of cryptographic keys to authenticate the communicating parties for smart meters. We presented simulation results and security analysis to verify our proposed framework. From this simulation results, we can see that even if the number of smart meters increases, the performance is not affected.","","978-1-6654-4431-6","10.1109/WF-IoT51360.2021.9595691","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9595691","Smart City;Smart Meter;Blockchain;Internet of Things;Security.","Performance evaluation;Privacy;Protocols;Smart cities;Simulation;Scalability;Smart meters","","2","","17","IEEE","9 Nov 2021","","","IEEE","IEEE Conferences"
"Compact Fault Dictionaries for Efficient Sensor Fault Diagnosis in IoT-enabled CPSs","S. A. Viktoros; M. K. Michael; M. M. Polycarpou","Dept. of Electrical and Computer Engineering, University of Cyprus; Dept. of Electrical and Computer Engineering, University of Cyprus; Dept. of Electrical and Computer Engineering, University of Cyprus","2020 IEEE International Conference on Smart Internet of Things (SmartIoT)","10 Sep 2020","2020","","","236","243","The recent advances in the area of Internet-of-Things (IoT) have allowed for the implementation of complex large-scale Cyber-Physical Systems (CPSs). This phenomenon calls for efficient and scalable solutions for the new challenges being introduced. Sensor fault diagnosis has emerged as a priority in various IoT-enabled CPSs, especially for critical infrastructure applications where multiple IoT devices might be in use. In this work, we examine the problem of building a compact fault dictionary which allows for efficient real-time model-based multiple sensor fault detection and isolation. The problem under consideration is formulated as a combinatorial set problem and then efficiently encoded using Zero-suppressed binary Decision Diagrams (ZDDs), which are specialized data structures based on Boolean theory. The proposed approach is highly scalable with respect to the total number of sensor fault scenarios considered. Using the respective ZDD as a fault dictionary reduces the memory requirements by several orders of magnitude when compared to the conventional approach. This is achieved while allowing the fault isolation process to occur in linear time to the size of the dictionary. Our experimental results show that it takes between 0.002s to 0.012s for performing the fault isolation process in the range of tested systems.","","978-1-7281-6514-1","10.1109/SmartIoT49966.2020.00042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9192014","Sensor fault Detection and Isolation;Fault Dictionaries;Internet-of-Things;Cyber-Physical Systems;Decision Diagrams","Dictionaries;Monitoring;Fault diagnosis;Fault detection;Binary decision diagrams;Cyber-physical systems;Automation","","1","","18","IEEE","10 Sep 2020","","","IEEE","IEEE Conferences"
"Survey On Smart Agriculture Using Iot","B. SakthiKumar; M. I. Niranjana; M. Abinath; I. G. Prasath; K. Jugasri; S. Kailash","ECE Department, Sri Eshwar College of Engineering, Coimbatore, INDIA; ECE Department, Sri Eshwar College of Engineering, Coimbatore, INDIA; ECE Department, Sri Eshwar College of Engineering, Coimbatore, INDIA; ECE Department, Sri Eshwar College of Engineering, Coimbatore, INDIA; ECE Department, Sri Eshwar College of Engineering, Coimbatore, INDIA; ECE Department, Sri Eshwar College of Engineering, Coimbatore, INDIA","2023 International Conference on Computer Communication and Informatics (ICCCI)","24 May 2023","2023","","","1","5","Each day, the agriculture sector in India loses ground on both sides, which reduces the ecosystem’s potential for production. To resuscitate agriculture and return it to a path of higher growth, a solution is increasingly needed. It takes a lot of maintenance, expertise, and management to maintain a large-scale agricultural system. The Internet of Things (IoT) is a system of networked devices that enables both automated job fulfilment and data transmission and reception through the internet. The crop yields are boosted by the abundance of data analysis parameters offered by the agricultural sector. Information and communication are modernized through the usage of IoT devices in smart farming. Soil moisture, minerals, light, and other elements can be expected for better crop growth. This study examines a handful of these traits for data analysis in an effort to help consumers use IoT to make better agricultural decisions in farming and irrigation. The method is designed to assist farmers in boosting agricultural productivity.","2473-7577","979-8-3503-4821-7","10.1109/ICCCI56745.2023.10128531","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10128531","Smart agriculture;Irrigation;Soil;IoT;Sensor","Smart agriculture;Temperature sensors;Surveys;Productivity;Irrigation;Temperature distribution;Data analysis","","1","","14","IEEE","24 May 2023","","","IEEE","IEEE Conferences"
"Performance Analysis of STAR-RIS-CR-NOMA Based Consumer IoT Networks for Resilient Industry 5.0","X. Li; X. Gao; L. Yang; H. Liu; J. Wang; K. M. Rabie","School of Physics and Electronic Information Engineering, Henan Polytechnic University, Jiaozuo, China; School of Physics and Electronic Information Engineering, Henan Polytechnic University, Jiaozuo, China; College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; School of Information Science and Electrical Engineering, Shandong Jiaotong University, Jinan, China; Department of Electronics and Information Engineering Central China Normal University, Wuha, China; Department of Engineering, Manchester Metropolitan University, Manchester, U.K.","IEEE Transactions on Consumer Electronics","","2023","PP","99","1","1","The arrival of the sixth generation (6G) wireless communication will intensify the developments of the Internet of Things (IoT) for widely applications in resilient industry 5.0. Driving the development of the intelligent consumer industry, consumer electronic devices have progressively become indispensable components of the constantly rising IoT. However, the steady rise of consumer IoT intelligent terminals has led to large-scale connections, spectrum scarcity, and energy consumption emerging as crucial challenges for the future wireless communication in resilient industry 5.0. To mitigate the aforementioned issues, a novel simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) assisted cognitive radio (CR)-non-orthogonal multiple access (NOMA) network are proposed. Specifically, we comprehensively elaborate on systems performance in terms of outage probability (OP), ergodic rate (ER) and energy efficiency (EE). Furthermore, the asymptotic OP and ER of the primary and secondary consumer electronic devices under the high signal-to-noise ratio (SNR) regions are investigated to undertake a thorough analysis. We find that the outage and ER performance gradually increase with the transmit SNR, and tend to a fixed value at high SNR regions. In addition, increasing the number of STAR-RIS components will enhance the reliable, ER and EE performance of the considered systems. Finally, the accuracy of analysis and the superiority of the proposed scheme are verified through Monte Carlo simulations.","1558-4127","","10.1109/TCE.2023.3319402","Key Laboratory of Middle Atmosphere and Global environment Observation (LAGEO) Institute of Atmospheric Physics, Chinese Academy of Sciences(grant numbers:LAGEO-2022-02); Key Laboratory of Cognitive Radio and Information Processing, Ministry of Education (Guilin University of Electronic Technology)(grant numbers:CRKL220203); Henan Provincial Science and Technology Research Project(grant numbers:232102211073); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10263782","Cognitive radio (CR);non-orthogonal multiple access (NOMA);resilient industry 5.0;simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS)","NOMA;Industries;Internet of Things;Signal to noise ratio;Performance evaluation;Consumer electronics;Reliability","","","","","IEEE","26 Sep 2023","","","IEEE","IEEE Early Access Articles"
"Wireless IoT Network Design in Adversarial Environments","J. Farooq; Q. Zhu",NA; NA,"Resource Management for On-Demand Mission-Critical Internet of Things Applications","","2021","","","69","96","The Internet of things (IoT) is revolutionizing the management and control of automated systems leading to a paradigm shift in areas such as smart homes, smart cities, health care, transportation, etc. The IoT technology is also envisioned to play an important role in improving the effectiveness of military operations in battlefields. Effective network design is essential to the secure operation of IoT systems particularly under adversarial environments. This chapter introduces a novel mechanism to model large scale networks, analyze their performance, and make decisions from an operational standpoint.","","9781119716105","10.1002/9781119716112.ch7","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9536297.pdf&bkn=9536218&pdfType=chapter","","Probability distribution;Mission critical systems;Mathematical model;Stochastic processes;Random variables;Planning;Multiplexing","","","","","","13 Sep 2021","","","IEEE","Wiley-IEEE Press eBook Chapters"
"Optimizing AoI in UAV-RIS-Assisted IoT Networks: Off Policy Versus On Policy","M. Sherman; S. Shao; X. Sun; J. Zheng","Department of Electrical Engineering, New Mexico Tech, Socorro, NM, USA; Department of Electrical Engineering, New Mexico Tech, Socorro, NM, USA; Department of Electrical and Computer Engineering, University of New Mexico, Albuquerque, NM, USA; Department of Computer Science and Engineering, New Mexico Tech, Socorro, NM, USA","IEEE Internet of Things Journal","6 Jul 2023","2023","10","14","12401","12415","In urban environments, tall buildings or structures can pose limits on the direct channel link between a base station (BS) and an Internet of Thing device (IoTD) for wireless communication. Unmanned aerial vehicles (UAVs) with a mounted reconfigurable intelligent surface (RIS), denoted as UAV-RIS, have been introduced in recent works to enhance the system throughput capacity by acting as a relay node between the BS and the IoTDs in wireless access networks. Uncoordinated UAVs or RIS phase shift elements will make unnecessary adjustments that can significantly impact the signal transmission to IoTDs in the area. The concept of Age of Information (AoI) is proposed in wireless network research to categorize the freshness of the received update message. To minimize the Average Sum of AoI (ASoA) in the network, two model-free deep reinforcement learning (DRL) approaches—Off-Policy deep Q-network (DQN) and On-Policy proximal policy optimization (PPO)—are developed to solve the problem by jointly optimizing the RIS phase shift, the location of the UAV-RIS, and the IoTD transmission scheduling for large-scale Internet of Things wireless networks. Analysis of loss functions and extensive simulations is performed to compare the stability and convergence performance of the two algorithms. The results reveal the superiority of the On-Policy approach, PPO, over the Off-Policy approach, DQN, in terms of stability, convergence speed, and under diverse environment settings.","2327-4662","","10.1109/JIOT.2023.3246925","National Science Foundation (NSF)(grant numbers:OIA-1757207); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10049119","Age of Information (AoI);deep Q-network (DQN);large-scale wireless networks;off-policy;on-policy;proximal policy optimization (PPO);unmanned aerial vehicles with-reconfigurable intelligent surface (UAV-RIS)","Internet of Things;Wireless networks;Optimization;Heuristic algorithms;Array signal processing;Resource management;Convergence","","4","","47","IEEE","20 Feb 2023","","","IEEE","IEEE Journals"
"Evaluation and Optimization of Distributed Machine Learning Techniques for Internet of Things","Y. Gao; M. Kim; C. Thapa; A. Abuadbba; Z. Zhang; S. Camtepe; H. Kim; S. Nepal","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, Jiangsu, China; Department of Computer Science and Engineering, College of Computing, Sungkyunkwan University, Seoul, South Korea; CSIRO, Data61, Sydney, NSW, Australia; CSIRO, Data61, Sydney, NSW, Australia; CSIRO, Data61, Sydney, NSW, Australia; CSIRO, Data61, Sydney, NSW, Australia; Department of Computer Science and Engineering, College of Computing, Sungkyunkwan University, Seoul, South Korea; CSIRO, Data61, Sydney, NSW, Australia","IEEE Transactions on Computers","7 Sep 2022","2022","71","10","2538","2552","Federated learning (FL) and split learning (SL) are state-of-the-art distributed machine learning techniques to enable machine learning training without accessing raw data on clients or end devices. However, their comparative training performance under real-world resource-restricted Internet of Things (IoT) device settings remains barely studied. This work provides empirical comparisons of FL and SL in real-world IoT settings regarding (i) learning performance with heterogeneous data distributions and (ii) on-device execution overhead. Our analyses in this work demonstrate that the learning performance of SL is better than FL under an imbalanced data distribution but worse than FL under an extreme non-IID data distribution. Recently, FL and SL are combined to form splitfed learning (SFL) to leverage each of their benefits (e.g., parallel training of FL and lightweight on-device computation requirement of SL). Our work considers FL, SL, and SFL, and mounts them on Raspberry Pi devices to evaluate their performance, including training time, communication overhead, power consumption, and memory usage with resource-restricted IoT devices. Besides evaluations, we apply two optimizations. First, we generalize SFL by carefully examining the possibility of a hybrid type of model training at the server-side. The generalized SFL merges sequential (dependent) and parallel (independent) processes of model training and thus is beneficial to a system with a large scale of IoT devices, specifically at the server-side operations. Second, we propose pragmatic techniques to substantially reduce the communication overhead by up to four times for the SL and (generalized) SFL.","1557-9956","","10.1109/TC.2021.3135752","Cyber Security Research Centre Limited; National Natural Science Foundation of China(grant numbers:62002167,61973161,61991404); Natural Science Foundation of Jiangsu Province(grant numbers:BK20200461); Future network research fund project(grant numbers:FNSRFP-2021-YB-05); High-Potential Individuals Global Training Program(grant numbers:IITP-2021-0-02104); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9652119","Split federated learning;split learning;federated learning;distributed machine learning;Internet of Things (IoT)","Training;Internet of Things;Performance evaluation;Distributed databases;Servers;Data models;Distance learning","","22","","47","IEEE","15 Dec 2021","","","IEEE","IEEE Journals"
"Lattice: A Vision for Machine Learning, Data Engineering, and Policy Considerations for Digital Agriculture at Scale","S. Chaterji; N. DeLay; J. Evans; N. Mosier; B. Engel; D. Buckmaster; M. R. Ladisch; R. Chandra","Department of Agricultural and Biological Engineering, Purdue University, West Lafayette, IN, USA; Department of Agricultural and Biological Engineering, Purdue University, West Lafayette, IN, USA; Department of Agricultural and Biological Engineering, Purdue University, West Lafayette, IN, USA; Department of Agricultural and Biological Engineering, Purdue University, West Lafayette, IN, USA; Department of Agricultural and Biological Engineering, Purdue University, West Lafayette, IN, USA; Department of Agricultural and Biological Engineering, Purdue University, West Lafayette, IN, USA; Department of Agricultural and Biological Engineering, Purdue University, West Lafayette, IN, USA; Microsoft Research, Microsoft Azure, Redmond, WA, USA","IEEE Open Journal of the Computer Society","2 Jul 2021","2021","2","","227","240","Digital agriculture, with the incorporation of Internet-of-Things (IoT)-based technologies, presents the ability to control a system at multiple levels (individual, local, regional, and global) and generates tools that allow for improved decision making and higher productivity. Recent advances in IoT hardware, e.g., networks of heterogeneous embedded devices, and software, e.g., lightweight computer vision algorithms and cloud optimization solutions, make it possible to efficiently process data from diverse sources in a connected (smart) farm. By interconnecting these IoT devices, often across large geographical distances, it is possible to collect data at different time scales, including in near real-time (i.e., with delays of only a few tens of seconds). This data can then be used for actionable insights, e.g., precise applications of soil supplements and reduced environmental footprint. Through LATTICE, we present an integrated vision for IoT solutions, data processing, and actionable analytics for digital agriculture. We couple this with discussion of economics and policy considerations that will underlie adoption of such IoT and ML technologies. Our paper starts off with the types of datasets in typical field operations, followed by the lifecycle for the data and storage, cloud and edge analytics, and fast information-retrieval solutions. We discuss what algorithms are proving to be most impactful in this space, e.g., approximate data analytics and on-device/in-network processing. We conclude by discussing analytics for alternative agriculture for generation of biofuels and policy challenges in the implementation of digital agriculture in the wild.","2644-1268","","10.1109/OJCS.2021.3085846","Purdue University; Lilly Endowment; Microsoft Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9444818","Data integration;data analysis;internet of things;Sensor systems;cloud computing","Data integration;Soil;Digital agriculture;Fertilizers;Distributed databases;Cloud computing;Internet of Things;Data analysis;Intelligent sensors","","12","","72","CCBY","1 Jun 2021","","","IEEE","IEEE Journals"
"Security in the Internet of Things Application Layer: Requirements, Threats, and Solutions","M. Abbasi; M. Plaza-Hernández; J. Prieto; J. M. Corchado","BISITE Research Group, Edificio Multiusos I+D+I, University of Salamanca, Salamanca, Spain; BISITE Research Group, Edificio Multiusos I+D+I, University of Salamanca, Salamanca, Spain; BISITE Research Group, Edificio Multiusos I+D+I, University of Salamanca, Salamanca, Spain; BISITE Research Group, Edificio Multiusos I+D+I, University of Salamanca, Salamanca, Spain","IEEE Access","21 Sep 2022","2022","10","","97197","97216","Communication systems and networks are evolving as an integral part of not only of our everyday life but also as a part of the industry, fundamental infrastructures, companies, etc. Current directions and concepts, such as the Internet of Things (IoT), promise the enhanced quality of life, greater business opportunities, cost-effective manufacturing, and efficient operation management through ubiquitous connectivity and deployment of smart physical objects. IoT networks can collect, preprocess, and transmit vast amounts of data. A considerable portion of this data is security- and privacy-critical data, which makes IoT networks a tempting option for attackers. Given that these networks deal with the actual aspects of our lives and fundamental infrastructures (e.g. smart grids), security in such networks is crucial. The large scale of these networks and their unique characteristics and complexity bring further vulnerabilities. In this study, we focus on the IoT application layer, security requirements, threats, and countermeasures in this layer, and some of the open issues and future research lines.","2169-3536","","10.1109/ACCESS.2022.3205351","IoTalentum Project within the Framework of Marie Skłodowska-Curie Actions Innovative Training Networks (ITN)-European Training Networks (ETN), which is funded by the European Union Horizon 2020 Research and Innovation Program(grant numbers:953442); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9882112","Internet of Things;security;privacy;requirements;taxonomy","Internet of Things;Complexity theory;Privacy;Smart grids;Computer security;Communication systems;Business;Threat assessment","","9","","166","CCBY","8 Sep 2022","","","IEEE","IEEE Journals"
"Edge Learning With Unmanned Ground Vehicle: Joint Path, Energy, and Sample Size Planning","D. Liu; S. Wang; Z. Wen; L. Cheng; M. Wen; Y. -C. Wu","Department of Electronic Engineering, Beijing Key Laboratory of Work Safety Intelligent Monitoring, Beijing University of Posts and Telecommunications, Beijing, China; Department of Electrical and Electronic Engineering and Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Electronic Engineering, Beijing Key Laboratory of Work Safety Intelligent Monitoring, Beijing University of Posts and Telecommunications, Beijing, China; Shenzhen Research Institute of Big Data, Shenzhen, China; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; Department of Electrical and Electronic Engineering, University of Hong Kong, Hong Kong","IEEE Internet of Things Journal","5 Feb 2021","2021","8","4","2959","2975","Edge learning (EL), which uses edge computing as a platform to execute machine learning algorithms, is able to fully exploit the massive sensing data generated by Internet of Things (IoT). However, due to the limited transmit power at IoT devices, collecting the sensing data in EL systems is a challenging task. To address this challenge, this article proposes to integrate unmanned ground vehicle (UGV) with EL. With such a scheme, the UGV could improve the communication quality by approaching various IoT devices. However, different devices may transmit different data for different machine learning jobs and a fundamental question is how to jointly plan the UGV path, the devices’ energy consumption, and the number of samples for different jobs? This article further proposes a graph-based path planning model, a network energy consumption model, and a sample size planning model that characterizes F-measure as a function of the minority class sample size. With these models, the joint path, energy and sample size planning (JPESP) problem is formulated as a large-scale mixed-integer nonlinear programming (MINLP) problem, which is nontrivial to solve due to the high-dimensional discontinuous variables related to UGV movement. To this end, it is proved that each IoT device should be served only once along the path, thus the problem dimension is significantly reduced. Furthermore, to handle the discontinuous variables, a tabu search (TS)-based algorithm is derived, which converges in expectation to the optimal solution to the JPESP problem. Simulation results under different task scenarios show that our optimization schemes outperform the fixed EL and the full path EL schemes.","2327-4662","","10.1109/JIOT.2020.3023000","National Key Research and Development Program of China(grant numbers:2019YFF0302601); Shenzhen Fundamental Research Program(grant numbers:JCYJ20190809142403596); Guangdong Basic and Applied Basic Research Foundation(grant numbers:2019A1515111140); Fundamental Research Funds for the Central Universities(grant numbers:2019SJ02); Open Research Fund from Shenzhen Research Institute of Big Data(grant numbers:2019ORF01012); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9189854","Edge learning (EL);Internet of Things (IoT);mixed-integer nonlinear programming (MINLP);unmanned ground vehicle (UGV)","Planning;Wireless communication;Internet of Things;Path planning;Task analysis;Machine learning;Energy consumption","","8","","56","IEEE","9 Sep 2020","","","IEEE","IEEE Journals"
"Profiling IoT Botnet Activity in the Wild","H. A. Almazarqi; A. K. Marnerides; T. Mursch; M. Woodyard; D. Pezaros","School of Computing Science, University of Glasgow, Glasgow, Scotland, UK; School of Computing Science, University of Glasgow, Glasgow, Scotland, UK; Bad Packets LLC, Chicago, IL, USA; Bad Packets LLC, Chicago, IL, USA; School of Computing Science, University of Glasgow, Glasgow, Scotland, UK","2021 IEEE Global Communications Conference (GLOBECOM)","2 Feb 2022","2021","","","1","6","Undoubtedly, the Internet of Things (IoT) contributes significantly to daily mission-critical processes underpinning a number of socio-technical systems. Conversely, its rapid adoption has extensively broadened the cyber-threat landscape by virtue of low-cost IoT devices that are manufactured and deployed with minimal security. Evidently, vulnerable IoT devices are utilised by attackers to participate into Internet-wide botnets in order to instrument large-scale cyber-attacks and disrupt critical Internet services. Since the 2016 outbreak of the first IoT Mirai botnet there has been a continuous evolution of Mirai-like variants. Tracking these botnets is challenging due to their varying structural characteristics, and also due to the fact that malicious actors continuously adopt new evasion and propagation strategies. This work provides a new measurement study highlighting specific behavioural properties of Mirai-like botnets in terms of their propagation. We provide a comprehensive analysis conducted on real Cyber Threat Intelligence (CTI) feeds gathered for a period of 7 months from globally distributed attack honeypots and pinpoint the evolutionary port scanning patterns, targeted vulnerabilities and preferred services pursued by Mirai-like botnets. We identify the most frequently active Mirai-like malware binaries and we are the first to report the evolution of a new, P2P-based variant. In parallel, we provide evidence related to the lack of vendor-specific patching through highlighting unpatched vulnerabilities. Moreover, we pinpoint the inadequacy of widely used IP blacklisting databases to timely list malicious IP addresses. Thus, arguing in fair of integrating honeypot information from diverse Internet vantage points within the design of next generation botnet defence mechanisms.","","978-1-7281-8104-2","10.1109/GLOBECOM46510.2021.9686012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9686012","IoT;botnets;Internet measurements;Mirai;malware;attack honeypots;cyber threat intelligence","Sociotechnical systems;Databases;Botnet;Instruments;Malware;Internet of Things;IP networks","","2","","12","IEEE","2 Feb 2022","","","IEEE","IEEE Conferences"
"RUAP: Random rearrangement block matrix-based ultra-lightweight RFID authentication protocol for end-edge-cloud collaborative environment","Y. Luo; K. Fan; X. Wang; H. Li; Y. Yang","State Key Laboratory of Integrated Service Networks, Xidian University, Xi'an, China; State Key Laboratory of Integrated Service Networks, Xidian University, Xi'an, China; State Key Laboratory of Integrated Service Networks, Xidian University, Xi'an, China; State Key Laboratory of Integrated Service Networks, Xidian University, Xi'an, China; State Key Laboratory of Integrated Service Networks, Xidian University, Xi'an, China","China Communications","22 Jul 2022","2022","19","7","197","213","Cloud computing provides powerful processing capabilities for large-scale intelligent Internet of things (IoT) terminals. However, the massive realtime data processing requirements challenge the existing cloud computing model. The edge server is closer to the data source. The end-edge-cloud collaboration offloads the cloud computing tasks to the edge environment, which solves the shortcomings of the cloud in resource storage, computing performance, and energy consumption. IoT terminals and sensors have caused security and privacy challenges due to resource constraints and exponential growth. As the key technology of IoT, Radio-Frequency Identification (RFID) authentication protocol tremendously strengthens privacy protection and improves IoT security. However, it inevitably increases system overhead while improving security, which is a major blow to low-cost RFID tags. The existing RFID authentication protocols are difficult to balance overhead and security. This paper designs an ultra-lightweight encryption function and proposes an RFID authentication scheme based on this function for the end-edge-cloud collaborative environment. The BAN logic proof and protocol verification tools AVISPA formally verify the protocol's security. We use VIVADO to implement the encryption function and tag's overhead on the FPGA platform. Performance evaluation indicates that the proposed protocol balances low computing costs and high-security requirements.","1673-5447","","10.23919/JCC.2022.07.016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9837859","end-edge-cloud orchestration;mutual authentication;ultra-lightweight;RFID;random rearrangement block matrix;IoT","Protocols;Cloud computing;Authentication;Radiofrequency identification;Servers;Internet of Things;Encryption","","2","","","","22 Jul 2022","","","IEEE","IEEE Magazines"
"Survey on Incentive Strategies for Mobile Crowdsensing System","R. She","Department of Mathematics and Computer, HeTao College, Bayannur, China","2020 IEEE 11th International Conference on Software Engineering and Service Science (ICSESS)","4 Nov 2020","2020","","","511","514","An emerging trend of computing mode in Internet of Things is mobile crowdsensing, it takes advantage of intelligent terminals people carried around to obtain sensed data and complete large-scale complex social task. However, performing variety sensing tasks may cause some extra cost, such as battery consumption, data traffic consumption, data uploading costs, potential privacy threats, mobile users may lose enthusiasm for participation, which will lead to the failure of sensing activities. Therefore, the incentive mechanism is one of the key issues that must be considered in the mobile crowdsensing system (MCS). In this paper, we review the recently proposed incentive mechanisms and give a comparison. Finally, we give the future research direction of the incentive mechanism in MCS.","2327-0594","978-1-7281-6579-0","10.1109/ICSESS49938.2020.9237745","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9237745","mobile crowdsensing;incentive strategy;monetary incentives","Data privacy;Crowdsensing;Market research;Sensors;Internet of Things;Task analysis;Software engineering","","4","","26","IEEE","4 Nov 2020","","","IEEE","IEEE Conferences"
"The Spatio-Temporal Modeling and Integration of Manufacturing Big Data in Job Shop: An Ontology-Based Approach","W. Fang; Y. Guo; W. Liao; S. Huang; C. Yang; K. Cui","College of Mechanical and Electrical Engineering (CMEE), Nanjing University of Aeronautics and Astronautics (NUAA), Nanjing City, Jiangsu Province, China; College of Mechanical and Electrical Engineering (CMEE), Nanjing University of Aeronautics and Astronautics (NUAA), Nanjing City, Jiangsu Province, China; College of Mechanical and Electrical Engineering (CMEE), Nanjing University of Aeronautics and Astronautics (NUAA), Nanjing City, Jiangsu Province, China; College of Mechanical and Electrical Engineering (CMEE), Nanjing University of Aeronautics and Astronautics (NUAA), Nanjing City, Jiangsu Province, China; College of Mechanical and Electrical Engineering (CMEE), Nanjing University of Aeronautics and Astronautics (NUAA), Nanjing City, Jiangsu Province, China; College of Mechanical and Electrical Engineering (CMEE), Nanjing University of Aeronautics and Astronautics (NUAA), Nanjing City, Jiangsu Province, China","2020 IEEE 7th International Conference on Industrial Engineering and Applications (ICIEA)","27 May 2020","2020","","","394","398","Manufacturing big data provide the factory with a tremendous opportunity for transforming the current manufacturing paradigm to smart manufacturing. However, the multi-source data modeling and integration problems are the existing gaps between the collected big data and the data-driven smart applications. With the large-scale deployment of Internet of things on the shop floor, it is essential to develop adequate data modeling and integration methods to manage and organize the generated manufacturing big data. In this study, the spatiotemporal modeling is firstly presented to organize the data in temporal, spatial and attributive dimensions respectively. Furthermore, the ontology-based big data integration approach is proposed to manage the multisource manufacturing data and ensure the data can be easily indexed and conveniently reused for different subsequent applications. Finally, the proposed data modeling and integration methods are implemented and verified through the developed manufacturing big data-driven analysis and decision-making system.","","978-1-7281-6785-5","10.1109/ICIEA49774.2020.9101999","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9101999","manufacturing big data;data modeling;data integration;ontology;spatio-temporal model","Ontologies;Data models;Manufacturing;Production;Big Data;Solid modeling;Indexing","","3","","11","IEEE","27 May 2020","","","IEEE","IEEE Conferences"
"Importance Sampling-Based Missing Tag Identification Protocol for Large-Scale RFID System","H. Liang; J. Wu; H. Zhang; X. Shao; L. Zhang","College of Electronic and Information Engineering / College of Integrated Circuits, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Electronic and Information Engineering / College of Integrated Circuits, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Electronic and Information Engineering / College of Integrated Circuits, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Electronic and Information Engineering / College of Integrated Circuits, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Electronic and Information Engineering / College of Integrated Circuits, Nanjing University of Aeronautics and Astronautics, Nanjing, China","2022 2nd Asia-Pacific Conference on Communications Technology and Computer Science (ACCTCS)","18 Jul 2022","2022","","","494","499","As a low-cost technology with good application prospects, RFID plays a key role in physical entity perception to enable Internet of Things networks. In large-scale RFID systems, one of the most vital problems is to identify missing tags duly. However, the existing missing tag identification protocols use the same probability for all tags, resulting in the incapability of discovering the loss of valuable goods in time. In this work, an importance sampling-based missing tag identification (ISMTI) protocol is proposed to improve the identification efficiency of important tags. With importance assignment, bloom filter-based unknown tag deactivation and multi-hashed based missing tag identification strategies, ISMTI reduces the number of slots to identify missing tags especially for important tags. Simulation results demonstrates its effectiveness.","","978-1-6654-0034-3","10.1109/ACCTCS53867.2022.00106","National Natural Science Foundation of China(grant numbers:61902182); Natural Science Foundation of Jiangsu Province of China(grant numbers:BK20190409); Aeronautical Science Foundation of China(grant numbers:2016ZC52029); China Postdoctoral Science Foundation(grant numbers:2019TQ0153); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9820893","Radio Frequency Identification (RFID);tag importance;missing tag identification;Bloom filter","Computer science;Protocols;Costs;Simulation;Communications technology;Internet of Things;Radiofrequency identification","","1","","10","IEEE","18 Jul 2022","","","IEEE","IEEE Conferences"
"Highly Conductive Flexible Printed PEDOT:PSS films for Green Humidity Sensing Applications","J. Shi; M. Wagih; S. Beeby","School of Electronics and Computer Science, University of Southampton, Southampton, United Kingdom; School of Electronics and Computer Science, University of Southampton, Southampton, United Kingdom; School of Electronics and Computer Science, University of Southampton, Southampton, United Kingdom","2022 IEEE International Conference on Flexible and Printable Sensors and Systems (FLEPS)","10 Jun 2022","2022","","","1","4","Over the past decades, humidity sensors have been an important sensing component in climate monitoring, agriculture, medical diagnostics and industrial process control systems. With emerging applications such as wearable devices and the internet of things in 5G scenarios, there is a growing demand for accurate humidity measurements, low-cost manufacturing processes for high-volume, high-performance sensors with flexible form factors, and the use of environmentally friendly materials. We present a simple, fast, and cost-effective method for the large-scale fabrication of highly-conductive, all-polymer, and bio-degradable humidity sensors on flexible organic polymer (polyimide) and paper substrates. We investigate the resistive properties of different thicknesses of poly(3,4-ethylenedioxythiophehe) polystyrene sulfonate (PEDOT:PSS) on Kapton and paper substrates in response to humidity, demonstrating a 3—8 Ω/square sheet resistance, suitable for all-polymer circuits. A relative resistance variation of 36.3% at levels of relative humidity ranging from 20% to 80% is demonstrated for a pristine sample, along with 1-month ageing tests to investigate the lifetime of the proposed sensor.","","978-1-6654-4273-2","10.1109/FLEPS53764.2022.9781556","Engineering and Physical Sciences Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9781556","biodegradable conductors;conductive polymers;PEDOT:PSS;Screen printing;Printed humidity sensor;flexible substrate","Wearable computers;Humidity;Sensor phenomena and characterization;Sensor systems;Sensors;Biosensors;Substrates","","1","","24","IEEE","10 Jun 2022","","","IEEE","IEEE Conferences"
"Intrusion Two-Level Detection System Using Machine Learning Techniques for Industrial Internet of Things (IIoT)","A. Bushnag","Faculty of Computers and Information Technology, University of Tabuk, Tabuk, Saudi Arabia","2023 IEEE International Conference on Internet of Things and Intelligence Systems (IoTaIS)","14 Dec 2023","2023","","","8","13","The Industrial Internet of Things (IIoT) can be distributed on a large scale with thousands of devices. The massive number of devices can lead to security flows since the IIoT devices have limited resources such as memory and battery. Therefore, there is a need for a fast Intrusion Detection System (IDS) that can identify the behavior of the IIoT network. A proposed model with two detection levels based on machine learning techniques is developed. The first detection level is to detect if the record is normal or an attack. The second detection level in case the record is attack, the type of the attack is determined. The results show that the Decision Tree and Random Forest have the best performance in terms of accuracy. However, the Naive Bayes has the upper hand regarding average processing time with lower accuracy in the first detection level. In the second detection level, the Random Forest outperformed other techniques in terms of accuracy, whereas Naive Bayes still performs the best in average processing time with less accuracy. The proposed model shows high efficiency not only in detecting the attack but also in determining the type of the attack.","2832-1383","979-8-3503-1904-0","10.1109/IoTaIS60147.2023.10346060","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10346060","Intrusion Detection;Industrial Internet of Things (IIoT);Machine Learning;Artificial Intelligence","Intrusion detection;Robustness;Naive Bayes methods;Security;Decision trees;Time factors;Task analysis","","","","21","IEEE","14 Dec 2023","","","IEEE","IEEE Conferences"
"A Measurement Campaign of Industrial Environment for Ultra Reliable IIoT Systems","Q. Zhang; T. H. Loh; D. Zhou; F. Shen; Z. Huang; F. Qin","School of Electronics, Electrical and Communication Engineering University of Chinese Academy of Sciences, Beijing, China; Electromagnetic & Electrochemical Technologies Department, National Physical Laboratory, Teddington, UK; Department of Electronic Control and Intelligent, Qiqihar Heavy CNC Equipment Corp, Heilongjiang, China; Shanghai Institute of Microsystem and Information Technology Chinese Academy of Sciences, Shanghai, China; School of Electronics, Electrical and Communication Engineering University of Chinese Academy of Sciences, Beijing, China; School of Electronics, Electrical and Communication Engineering University of Chinese Academy of Sciences, Beijing, China","2022 14th International Conference on Wireless Communications and Signal Processing (WCSP)","15 Feb 2023","2022","","","644","648","The large-scale deployment of Industrial Internet of Things (IIoT) is still facing the challenge of providing reliable service with wireless networks, which is envisaged due to the severe multipath fading caused by numerous metal reflectors in industrial environments. Therefore, the channel measurement for different multipath fading scenarios is an important part of exploring the channel characteristics of industrial environments. In this paper, we measured the wideband channel characteristics of a microelectronic manufacturing and a classroom environment with the similar volume. The comparison between them has demonstrated the essential empirical characterisations of wireless industrial channel. Based on these findings, we then propose an empirical PDP model and investigate the root mean square delay spread and coherent bandwidth in these two scenarios, which enabling insight understanding of the channel characteristics and the deployment of IIoT systems operating in industrial scenarios.","","978-1-6654-5085-0","10.1109/WCSP55476.2022.10039245","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10039245","industrial fading channel;power delay profile;Rician distribution;delay spread","Fading channels;Wireless networks;Volume measurement;Metals;Delays;Microelectronics;Reliability","","","","11","IEEE","15 Feb 2023","","","IEEE","IEEE Conferences"
"RF IoT Design for Underground Pipeline Inspection","L. Zhou; J. Cao","School of Mechanical and Electrical Engineering, Wuhan University of Technology, Wuhan, China; School of Mechanical and Electrical Engineering, Wuhan University of Technology, Wuhan, China","2022 IEEE 4th International Conference on Civil Aviation Safety and Information Technology (ICCASIT)","27 Dec 2022","2022","","","1183","1187","The application of multi-sensor and communication and network technology, combined with mechanical mechanism design, explores the application of RF Internet of Things in the detection of underground drainage pipes. A new type of underground drainage pipeline inspection device is designed to achieve the purpose of large-scale intelligent inspection, recording parameters in the underground drainage pipeline, and discovering and investigating potential safety hazards. The research content includes innovative design of mechanical structure, embedded system design, data transmission design, gateway and front-end design, and the operation effect of each module is calculated and simulated through theoretical analysis.","","978-1-6654-6766-7","10.1109/ICCASIT55263.2022.9986581","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9986581","RF IoT;multi-sensor;Pipeline inspection;Mechanical trolley","Radio frequency;Power system measurements;Embedded systems;Pipelines;Inspection;Logic gates;Recording","","","","2","IEEE","27 Dec 2022","","","IEEE","IEEE Conferences"
"A digital twin-driven water plant flocculation and precipitation pharmacy control system","W. Yingxin; H. Xintong; M. Jiangang","School of Mechanical and Electrical Engineering, Wuhan University of Technology Wuhan, Hubei, China; School of Mechanical and Electrical Engineering, Wuhan University of Technology Wuhan, Hubei, China; School of Mechanical and Electrical Engineering, Wuhan University of Technology Wuhan, Hubei, China","2022 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA)","5 Aug 2022","2022","","","802","804","As an indispensable part of production and life, tap water has a large scale of consumption every year. Among them, coagulation drug injection is an important link in purifying water quality in the production process of tap water treatment. At present, the drug injection mode of domestic water purification plants is mainly feedforward control or single-factor closed-loop control based on flow current. The parameter response to multiple parameters cannot be responded quickly, which limits the control effect and causes the problem of flocculant drug waste. Therefore, in view of the above problems, the project has built an intelligent control system of waterworks flocculant drugs based on big data by comprehensively using big data, digital twin, Internet of Things and deep learning, so as to realize the precise dosage of flocculant.","","978-1-6654-9991-0","10.1109/ICAICA54878.2022.9844466","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9844466","digital twin;water plant to add medicine;cloud edge collaboration;big data","Drugs;Deep learning;Purification;Production;Water quality;Big Data;Control systems","","","","5","IEEE","5 Aug 2022","","","IEEE","IEEE Conferences"
"Implementation of a Multisensors Fire-Fighting Monitoring System for Forest Protection","G. Pettorru; M. Bertolusso; M. Spanu; M. Sole; M. Anedda; D. Giusto","DIEE Department of Electrical and Electronic Engineering, University of Cagliari - UdR CNIT Cagliari; DIEE Department of Electrical and Electronic Engineering, University of Cagliari - UdR CNIT Cagliari; DIEE Department of Electrical and Electronic Engineering, University of Cagliari - UdR CNIT Cagliari; DIEE Department of Electrical and Electronic Engineering, University of Cagliari - UdR CNIT Cagliari; DIEE Department of Electrical and Electronic Engineering, University of Cagliari - UdR CNIT Cagliari; DIEE Department of Electrical and Electronic Engineering, University of Cagliari - UdR CNIT Cagliari","2022 International Conference on Computational Science and Computational Intelligence (CSCI)","25 Aug 2023","2022","","","1205","1209","Monitoring and control of natural environments is becoming increasingly sensitive in the face of climate change. This work proposes a solution for the protection to safeguard forests and woodlands against natural or arson fires. Currently, existing solutions have critical issues in terms of early detection of outbreaks, or rely on expensive solutions if implemented on a large scale. Electronic noses for fire smoke detection have been developed. The data is transmitted in real time to a Social Internet of Things (SIoT) cloud platform that analyzes the data and detects potential critical situations. Preliminary results obtained show the effectiveness of the system in detecting the change in detected parameters during the occurrence of a fire front.","2769-5654","979-8-3503-2028-2","10.1109/CSCI58124.2022.00216","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10216586","Intelligent system for IoT;Environmental Monitoring;Network Design and Architecture;Wireless Systems and Applications","Intelligent systems;Internet of Things;Environmental monitoring;Climate change;Wireless communication;Forestry;Fires;Social Internet of Things;Electronic noses","","","","16","IEEE","25 Aug 2023","","","IEEE","IEEE Conferences"
"A Review on Sensing Technologies for High-Throughput Plant Phenotyping","Z. Ma; R. Rayhana; K. Feng; Z. Liu; G. Xiao; Y. Ruan; J. S. Sangha","School of Engineering, The University of British Columbia, Kelowna, Canada; School of Engineering, The University of British Columbia, Kelowna, Canada; School of Engineering, The University of British Columbia, Kelowna, Canada; Agriculture and Agri-Food Canada, Saskatchewan, Canada; National Research Council (NRC) Canada, Ottawa, Canada; Agriculture and Agri-Food Canada, Saskatchewan, Canada; Agriculture and Agri-Food Canada, Saskatchewan, Canada","IEEE Open Journal of Instrumentation and Measurement","22 Jun 2022","2022","1","","1","21","The current epidemic, population growth, and decreasing arable lands lead to a severe food crisis, which calls for productive and efficient agricultural methods to ensure a sustainable food supply for mankind. Crop monitoring is considered to be a potential solution for the improvement of food production. Current crop monitoring combines agriculture methodologies with other advanced technologies, including sensing technology, geographical information systems (GIS), Internet of Things (IoT), information and communication technology (ICT), robotics, and drone techniques to increase production with low labor cost. The high-throughput plant phenotyping is crucial for crop monitoring on the data acquisition of large-scale crop characteristics. The high-throughput plant phenotyping studies aim to achieve fast and precise large-scale crop monitoring techniques with minimum environmental impact by applying special plant phenotyping platforms. The phenotyping platforms are integrated with various sensors and data communication systems, which can help to achieve automatic data acquisition and transmission. This paper reviews the current high-throughput plant phenotyping development in crop monitoring, including sensors, communication protocols, data management, and plant phenotyping platforms. State-of-art challenges are reviewed and discussed. Also, the paper provides discussions on the current situation, upcoming challenges, and possible future trends for researchers in this field.","2768-7236","","10.1109/OJIM.2022.3178468","NRC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9783139","High-throughput;plant phenotyping platforms;crop monitoring;sensing technology;communication protocols","Crops;Protocols;Monitoring;Data communication;Plants;Robot sensing systems;Wireless fidelity","","6","","152","CCBY","27 May 2022","","","IEEE","IEEE Journals"
"OpenPubSub: Supporting Large Semantic Content Spaces in Peer-to-Peer Publish/Subscribe Systems for the Internet of Multimedia Things","T. Zaarour; A. Bhattacharya; E. Curry","Insight Centre for Data Analytics, National University of Ireland, Galway, Ireland; Insight Centre for Data Analytics, National University of Ireland, Galway, Ireland; Insight Centre for Data Analytics, National University of Ireland, Galway, Ireland","IEEE Internet of Things Journal","7 Sep 2022","2022","9","18","17640","17659","The decentralized and highly scalable nature of structured peer-to-peer networks, based on distributed hash tables (DHTs), makes them a great fit for facilitating the interaction and exchange of information between dynamic and geographically dispersed autonomous entities. The recent emergence of multimedia-based services and applications in the Internet of Things (IoT) has led to a noticeable shift in the type of data traffic generated by sensing devices from structured textual and numerical content to unstructured and bulky multimedia content. The wide semantic spectrum of human recognizable concepts that can be stemmed from multimedia data, e.g., video and audio, introduces a very large semantic content space. The scale of the content space poses a semantic boundary between data consumers and producers in large-scale peer-to-peer publish/subscribe systems. The exact-match query model of DHTs falls short when participants use different terms to describe the same semantic concepts. In this work, we present OpenPubSub, a peer-to-peer content-based approximate semantic publish/subscribe system. We propose a hybrid event routing model that combines rendezvous routing and gossiping over a structured peer-to-peer network. The network is built on the basis of a high-dimensional semantic vector space as opposed to conventional logical key spaces. We propose methods to partition the space, construct a semantic DHT via bootstrapping, perform approximate semantic lookup operations, and cluster nodes based on their shared interests. Results show that for an approximate event matching upper bound recall of 56.7%, rendezvous-based routing achieves up to 54% recall while decreasing the messaging overhead by 44%, whereas, the hybrid routing approach achieves up to 43.8% recall while decreasing the messaging overhead by 59%.","2327-4662","","10.1109/JIOT.2022.3158088","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9731505","Decentralized systems;distributional semantics;information search and retrieval;peer-to-peer networks;publish/subscribe systems;vector spaces","Semantics;Peer-to-peer computing;Internet of Things;Routing;Multimedia communication;Cloud computing;Multimedia computing","","4","","78","CCBY","9 Mar 2022","","","IEEE","IEEE Journals"
"Methodology for on-machine calibration of low-cost wireless sensors","K. S. Saleeby; M. Foley; M. Kosmala; T. R. Kurfess","Georgia Tech Manufacturing Institute, Georgia Institute of Technology, 813 Ferst Drive, Atlanta, GA, USA; Dept. of Mechanical Engineering, Georgia Institute of Technology, 813 Ferst Drive, Atlanta, GA, USA; Georgia Tech Manufacturing Institute, Georgia Institute of Technology, 813 Ferst Drive, Atlanta, GA, USA; Georgia Tech Manufacturing Institute, Georgia Institute of Technology, 813 Ferst Drive, Atlanta, GA, USA","Low-Cost Digital Solutions for Industrial Automation (LoDiSA 2023)","21 Nov 2023","2023","2023","","1","5","Increased accessibility of Industry 4.0 technologies for manufacturing has driven adoption of low-cost disposable sensor packs. These sensors often mount magnetically to a rotational component within a manufacturing system, such as the spindle in a computer numeric controlled (CNC) machining center, aimed at detecting signs of bearing failure through accelerometer measurements. To be affordable for small and medium enterprise (SME) manufacturers, sensors packs are often constructed from lower quality products with a high degree of performance variance. When a sensor pack is replaced with nominally identical components, variance in sensitivity, axis rotation, and scaling results in a different frequency response under the same operating conditions. Measurement variance results in challenges for anomaly detection models trained on previous data that are applied to the replacement sensor system. This research investigates a method to calibrate low-cost accelerometer based IoT sensors using the CNC manufacturing system itself. A reference point is created with the first sensor installed on the machine. A second replacement sensor is installed before the reference sensor is disposed and measurements are compared against the first sensor to calculate scaling, rotational shift, and sensitivity variance coefficients. The resulting correction factor is applied to the second sensor, reducing the effect of measurement variations between devices. The results of this work increase the consistency and reliability of acceleration measurements across different low-cost IoT sensors by providing a calibration method leveraging the manufacturing system itself, assisting in the adoption of low-cost IoT technologies for SMEs.","","978-1-83953-932-9","10.1049/icp.2023.1727","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10324512","","","","","","","","21 Nov 2023","","","IET","IET Conferences"
"Low-Latency In-Band Integration of Multiple Low-Power Wide-Area Networks","V. P. Modekurthy; D. Ismail; M. Rahman; A. Saifullah","University of Nevada Las Vegas, NV, USA; Wayne State University, MI, USA; Queens College, City University of New York, NY, USA; Wayne State University, MI, USA","2021 IEEE 27th Real-Time and Embedded Technology and Applications Symposium (RTAS)","7 Jul 2021","2021","","","333","346","Today, industrial and agricultural Internet of Things (IoT) are emerging in very large-scale and wide-area applications (e.g., oil-field management, smart farming) that may spread over hundreds of square miles (e.g., 45mi×12mi East Texas Oil-field). Although a single Low-Power Wide-Area Network (LPWAN) covers several miles, it faces coverage challenge in such extremely large-area IoT applications, specially in rural or remote areas with no/limited infrastructure, requiring an in-band integration of multiple LPWANs. To avoid the crowd in the limited ISM band and the cost of licensed band and infrastructure, SNOW (Sensor Network Over White spaces) is an LPWAN architecture over the TV white spaces. It offers high scalability through concurrent and bi-directional communication between a base station and numerous nodes. We consider a seamless integration of multiple SNOWs. Existing approach does not consider minimizing network latency and is less suitable for delay-sensitive or real-time applications. We propose the first scalable in-band integration of multiple SNOWs that minimizes network latency. By taking into account the impact of bandwidth on latency and base station power dissipation, we formulate lowlatency integration of multiple SNOWs as a constrained spectrum allocation problem. It is solved through a greedy algorithm by analyzing network latency and by adopting a latency- and traffic- aware bandwidth allocation along the links to achieve an integrated network. We have implemented the proposed integration both on SNOW hardware and in NS-3 simulator. Both physical experiments and simulations show a significant reduction (44% and 97%, resp.) in network latency under our approach compared to existing approach.","2642-7346","978-1-6654-0386-3","10.1109/RTAS52030.2021.00034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9470474","LPWAN;Sensor Networks;Low Latency;Wide area network","Base stations;TV;Snow;Scalability;White spaces;Real-time systems;Power dissipation","","2","","65","IEEE","7 Jul 2021","","","IEEE","IEEE Conferences"
"Automating Switchgear Asset Supply Chain Management with IoT and RFID Technology","M. S. Sidhu; S. Saif; N. E. Ghazali; S. M. Shah; T. W. Chun; T. J. Hussain","Institute of Informatics and Computing, (IICE), Universiti Tenaga Nasional, (UNITEN), Selangor, Malaysia; Institute of Informatics and Computing, (IICE), Universiti Tenaga Nasional, (UNITEN), Selangor, Malaysia; ICT Division, Tenaga Nasional Berhad (TNB), Selangor, Malaysia; ICT Division, Digital Business & Technology Advisory, Tenaga Nasional Berhad (TNB), Selangor, Malaysia; Institute of Informatics and Computing, (IICE), (UNITEN), Selangor; Dept. Graphics & Multimedia, College of Computing & Informatics, Universiti Tenaga Nasional, (UNITEN)","2020 8th International Conference on Information Technology and Multimedia (ICIMU)","11 Nov 2020","2020","","","404","408","Resources, for example, switch gears may travel a large number of miles, changing hands a few times or more, before they arrive at their last goals. In this intricate circumstance, slips up or resources being taken along the gracefully chain are unavoidable. Regardless of how strong the coordinations arrange for a specific resource, sooner or later a transporter will stall out in rush hour gridlock, or a carton will be deferred at a stockroom, or a benefit will disappear by and large. With customary gracefully chain the executives arrangements, coordinations administrators frequently do not get some answers concerning postponed or misrouted resources until those advantages show up after the expected time or not under any condition at their goals. These hours convert into lost efficiency, postponed creation and harmed customer connections. However, with newer technological advancements such as Internet of Things (IoT) and Radio Frequency Integrated Devices (RFID), these problems could be avoided or minimized and significantly reduce losses whereby the location of assets could be monitored in real time, as they travel along worldwide transportation routes. Furthermore, the technology allows the industry to visualize and manage critical goods from anywhere, at any time, on a global scale. In this research, we aim to design a conceptual framework and a physical design of automating switch gear asset supply chain management system for a TNB subsidiary company and test its effectiveness as a futuristic system for asset tracking. However this paper reports on the conceptual design approach.","","978-1-7281-7310-8","10.1109/ICIMU49871.2020.9243528","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9243528","Asset;IoT;RFID;management;switchgear","Wireless sensor networks;Supply chain management;Switchgear;Switches;Real-time systems;Internet of Things;Radiofrequency identification","","1","","18","IEEE","11 Nov 2020","","","IEEE","IEEE Conferences"
"Hierarchical Distribution Grid Intelligence: Using Edge Compute, Communications, and IoT Technologies","J. Stoupis; R. Rodrigues; M. Razeghi-Jahromi; A. Melese; J. I. Xavier","ABB U.S. Research Center, Raleigh, NC, USA; ABB U.S. Research Center, Raleigh, NC, USA; ABB U.S. Research Center, Raleigh, NC, USA; ABB U.S. Research Center, Raleigh, NC, USA; ABB U.S. Research Center, Raleigh, NC, USA","IEEE Power and Energy Magazine","22 Aug 2023","2023","21","5","38","47","Due to the proliferation of internet-of-things (IoT)-based technologies in the last several years, digital computing hardware and software technologies have seen massive performance improvement. Additionally, these technologies provide lower costs for comparatively higher computation and storage, more compact size hardware, and compatibility with a large selection of operating systems. Furthermore, communication protocols have increased the penetration of single-board computers in many consumer and industrial applications. This article presents the application of a state-of-the-art edge computing infrastructure to the electrical power distribution grid. Electrical power distribution is becoming increasingly complex with the large degree of integration of distributed energy resources (DERs). The distribution system also experiences many different undesired events, such as different types of temporary and permanent faults, loss of measurement data, and cyberattacks. This article highlights a small-scale experimental validation of edge computing in power distribution automation that can be used for classifying different faults, detecting anomalies in the grid, measurement data recovery, and other advanced analytics techniques.","1558-4216","","10.1109/MPE.2023.3288596","U.S. Department of Energy; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10226362","","Automation;Protocols;Substations;Power distribution;SCADA systems;Loss measurement;Hierarchical systems;Power grids;Edge computing;Internet of Things;Communications technology;Distributed power generation;Costs","","1","","6","IEEE","22 Aug 2023","","","IEEE","IEEE Magazines"
"Optimizing Heterogeneous Task Allocation for Edge Compute Micro Clusters Using PSO Metaheuristic","Y. Alhaizaey; J. Singer; A. L. Michala","School of Computing Science, University of Glasgow, United Kingdom; School of Computing Science, University of Glasgow, United Kingdom; School of Computing Science, University of Glasgow, United Kingdom","2022 Seventh International Conference on Fog and Mobile Edge Computing (FMEC)","14 Mar 2023","2022","","","1","8","Optimised task allocation is essential for efficient and effective edge computing; however, task allocation differs in edge systems compared to the powerful centralised cloud data centres, given the limited resource capacities in edge and the strict QoS requirements of many innovative Internet of Things (IoT) applications. This paper aims to optimise heterogeneous task allocation specifically for edge micro-cluster platforms. We extend our previous work on optimising task allocation for micro-clusters by presenting a linear-based model and propose a metaheuristic Particle Swarm Optimisation (PSO) technique to minimise the makespan time and the allocation overhead time of heterogeneous workloads in batch execution. We present a comparative performance evaluation of metaheuristic PSO, mixed-integer programming (MIP) and randomised allocation based on the computation overhead time and the quality of the solutions. Our results show a crossover implying that mixed-integer programming is efficient for small-scale clusters, whereas PSO scales better and provides near-optimal solutions for larger-scale micro-clusters.","","979-8-3503-3452-4","10.1109/FMEC57183.2022.10062755","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10062755","Edge Micro-Clusters;Edge Systems;Edge Computing;Task Allocation;Resource Management;PSO;Optimisation","Performance evaluation;Multi-access edge computing;Metaheuristics;Quality of service;Programming;Resource management;Internet of Things","","1","","22","IEEE","14 Mar 2023","","","IEEE","IEEE Conferences"
"Dominant Data Set Selection Algorithms for Electricity Consumption Time-Series Data Analysis Based on Affine Transformation","Y. Wu; Y. Liu; S. H. Ahmed; J. Peng; A. A. Abd El-Latif","School of Data Science and Technology, Heilongjiang University, Harbin, China; School of Data Science and Technology, Heilongjiang University, Harbin, China; Department of Computer Science, Georgia Southern University, Statesboro, USA; School of Data Science and Technology, Heilongjiang University, Harbin, China; Mathematics and Computer Science Department, Faculty of Science, Menoufia University, Shebin El-Koom, Egypt","IEEE Internet of Things Journal","13 May 2020","2020","7","5","4347","4360","In the explosive growth of time-series data (TSD), the scale of TSD suggests that the scale and capability of many Internet of Things (IoT)-based applications has already been exceeded. Moreover, redundancy persists in TSD due to the correlation between information acquired via different sources. In this article, we propose a cohort of dominant data set selection algorithms for electricity consumption TSD with a focus on discriminating the dominant data set that is a small data set but capable of representing the kernel information carried by TSD with an arbitrarily small error rate less than  $\varepsilon $ . Furthermore, we prove that the selection problem of the minimum dominant data set is an NP-complete problem. The affine transformation model is introduced to define the linear correlation relationship between TSD objects. Our proposed framework consists of the scanning selection algorithm with  $O({n^{3}})$  time complexity and the greedy selection algorithm with  $O({n^{4}})$  time complexity, which are, respectively, proposed to select the dominant data set based on the linear correlation distance between TSD objects. The proposed algorithms are evaluated on the real electricity consumption data of Harbin city in China. The experimental results show that the proposed algorithms not only reduce the size of the extracted kernel data set but also ensure the TSD integrity in terms of accuracy and efficiency.","2327-4662","","10.1109/JIOT.2019.2946753","Heilongjiang Provincial Natural Science Foundation of China(grant numbers:F2016035); Science and Technology Project of State Grid Corporation of China(grant numbers:SGHL0000DKJS1900883); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8863967","Affine transformation;dominant data set;linear correlation;time-series data (TSD)","Correlation;Data mining;Error analysis;Internet of Things;Power systems;Big Data;Real-time systems","","52","","46","IEEE","11 Oct 2019","","","IEEE","IEEE Journals"
"Communication Network Model for a Computer Management and Control System implemented using FIWARE platform: Case Study","W. Velasquez; M. Filian-Gomez",Escuela Superior Politecnica del Litoral; Escuela Superior Politecnica del Litoral,"IEEE Latin America Transactions","12 Apr 2021","2020","18","12","2073","2080","In the last two decades, different organizations have used computing management resources systems based on client-server architecture. The Escuela Superior Politecnica del Litoral uses a computer management system; which has been adapted to versions Windows OS to manage computer labs. However, these adaptations have not considered improvements in the system architecture, to correct pre-existing communication problems. This paper states a solution based on a distributed model of computer management using the architecture of the FIWARE platform, to provide a smart system that converts a computer on an IoT device to improve the system communication. Finally, communication tests show that the proposed model can be implemented on a large scale, due to the distributed architecture, resources management, and real-time processing to manage events.","1548-0992","","10.1109/TLA.2020.9400434","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9400434","Architecture;Computer;Draco;FIWARE;Management;Orion;System","Computational modeling;Monitoring;Visualization;Silicon compounds;Java;IEEE transactions;Computer architecture","","2","","","IEEE","12 Apr 2021","","","IEEE","IEEE Journals"
"Self-Healing Dilemmas in Distributed Systems: Fault Correction vs. Fault Tolerance","J. Nikolić; N. Jubatyrov; E. Pournaras","Google, Zurich, Zürich, Switzerland; Facebook, London, U.K.; School of Computing, University of Leeds, Leeds, U.K.","IEEE Transactions on Network and Service Management","8 Sep 2021","2021","18","3","2728","2741","Large-scale decentralized systems of autonomous agents interacting via asynchronous communication often experience the following self-healing dilemma: fault detection inherits network uncertainties making a remote faulty process indistinguishable from a slow process. In the case of a slow process without fault, fault correction is undesirable as it can trigger new faults that could be prevented with fault tolerance that is a more proactive system maintenance. But in the case of an actual faulty process, fault tolerance alone without eventually correcting persistent faults can make systems underperforming. Measuring, understanding and resolving such self-healing dilemmas is a timely challenge and critical requirement given the rise of distributed ledgers, edge computing, the Internet of Things in several energy, transport and health applications. This paper contributes a novel and general-purpose modeling of fault scenarios during system runtime. They are used to accurately measure and predict inconsistencies generated by the undesirable outcomes of fault correction and fault tolerance as the means to improve self-healing of large-scale decentralized systems at the design phase. A rigorous experimental methodology is designed that evaluates 696 experimental settings of different fault scales, fault profiles and fault detection thresholds in a prototyped decentralized network of 3000 nodes. Almost 9 million measurements of inconsistencies were collected in a network, where each node monitors the health status of another node, while both can defect. The prediction performance of the modeled fault scenarios is validated in a challenging application scenario of decentralized and dynamic in-network data aggregation using real-world data from a Smart Grid pilot project. Findings confirm the origin of inconsistencies at design phase and provide new insights how to tune self-healing at an early stage. Strikingly, the aggregation accuracy is well predicted as shown by high correlations and low root mean square errors.","1932-4537","","10.1109/TNSM.2021.3092939","Swiss National Science Foundation (SNSF) as part of the National Research Programme NRP77 Digital Transformation(grant numbers:187249); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9466159","Self-healing;fault correction;fault tolerance;fault detection;distributed system;agent;gossip;aggregation","Fault tolerant systems;Fault tolerance;Computational modeling;Fault detection;Uncertainty;Maintenance engineering;Predictive models","","7","","54","IEEE","28 Jun 2021","","","IEEE","IEEE Journals"
"Leveraging Networked Sensors to Improve Apple Orchard Irrigation: A Lab Prototype","A. Tumanyan; G. Grigoryan; T. P. Raptis","Yerevan State University, Yerevan, Armenia; Yerevan State University, Yerevan, Armenia; Institute of Informatics and Telematics, National Research Council, Pisa, Italy","2023 19th International Conference on Distributed Computing in Smart Systems and the Internet of Things (DCOSS-IoT)","27 Sep 2023","2023","","","389","396","Research on Internet of Things (IoT) technology in agriculture has gained significant attention in recent years, as it offers the potential to revolutionise traditional farming practices by enabling more efficient resource management, increased crop yields, and reduced environmental impact. Similarly, there has been a growing interest in the application of IoT technology specifically for apple orchards; research in this respect needs to be tailored to the unique requirements and constraints of this vertical. This paper proposes a smart irrigation solution for apple orchards using networked sensors that aims to reduce watering costs and efficiently address related practical agricultural constraints. After exploring the various requirements of the apple orchards watering problem, we design a lab prototype for the networked smart irrigation system and conduct measurements to evaluate its effectiveness. As the fieldwork is not possible at the moment of the paper writing due to seasonal limitations, we perform initial, small-scale lab experiments and network emulations. Specifically, we test the effectiveness of the soil moisture sensors, and we emulate in the Cooja simulator the performance of diverse spatial topologies of the networked sensors. The results of the experiments and simulations demonstrate that our proposed approach has the potential to (i) effectively reduce water consumption (ii) align to the corresponding universally accepted soil moisture best practices, and, (ii) tune its performance according to the eventual sensor topology application requirements, by scaling accordingly the number of sensors.","2325-2944","979-8-3503-4649-7","10.1109/DCOSS-IoT58021.2023.00069","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10257237","Irrigation control;smart watering;wireless sensor networks;Internet of things;Cooja","Irrigation;Network topology;Soil measurements;Soil moisture;Prototypes;Writing;Sensor systems","","","","23","IEEE","27 Sep 2023","","","IEEE","IEEE Conferences"
"Modeling on Energy-Efficiency Computation Offloading Using Probabilistic Action Generating","C. Wang; W. Lu; S. Peng; Y. Qu; G. Wang; S. Yu","School of Computer and Communication Engineering, Northeastern University at Qinhuangdao, Qinhuangdao, China; School of Computer and Communication Engineering, Northeastern University at Qinhuangdao, Qinhuangdao, China; Laboratory of Language Engineering and Computing, Guangdong University of Foreign Studies, Guangzhou, China; Data61, Commonwealth Scientific and Industrial Research Organization, Eveleigh, NSW, Australia; School of Computer Science and Cyber Engineering, Guangzhou University, Guangzhou, China; School of Computer Science, University of Technology Sydney, Ultimo, NSW, Australia","IEEE Internet of Things Journal","6 Oct 2022","2022","9","20","20681","20692","Wireless-powered mobile-edge computing (MEC) emerges as a crucial component in the Internet of Things (IoTs). It can cope with the fundamental performance limitations of low-power networks, such as wireless sensor networks or mobile networks. Although computation offloading and resource allocation in MEC have been studied with different optimization objectives, performance optimization in larger-scale systems still needs to be further improved. More importantly, energy efficiency is also a key issue as well as computation offloading and resource allocation for wireless-powered MEC. In this article, we investigate the joint optimization of computation rate and energy consumption under limited resources, and propose an online offloading model to search for the asymptotically optimal offloading and resource allocation strategy. First, the joint optimization problem is modeled as a mixed integer programming (MIP) problem. Second, a deep reinforcement learning (DRL)-based method, energy efficiency computation offloading using probabilistic action generating (ECOPG), is designed to generate the joint optimization policy for computation offloading and resource allocation. Finally, to avoid the curse of dimensionality in large network scales, an action exploration mechanism based on probability is introduced to accelerate the convergence rate by targeted sampling and dynamic experience replay. The experimental results demonstrate that the proposed methods significantly outperform other DRL-based methods in energy consumption, and gain better computation rate and execution efficiency at the same time. With the expansion of the network scale, the improvements become more apparent.","2327-4662","","10.1109/JIOT.2022.3175760","Science and Technology Project of Hebei Education Department(grant numbers:ZD2019306); Fundamental Research Funds for the Central Universities(grant numbers:N2123023); China Scholarship Council(grant numbers:201908130244); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9776526","Computation offloading;deep reinforcement learning (DRL);energy efficiency;mobile-edge computing (MEC)","Task analysis;Wireless communication;Energy consumption;Resource management;Computational efficiency;Optimization;Internet of Things","","3","","31","IEEE","17 May 2022","","","IEEE","IEEE Journals"
"Lightweight Open Data Assimilation of Pan-European Urban Air Quality","L. Miasayedava; J. Kaugerand; J. A. Tuhtan","Research Laboratory for Proactive Technologies, Tallinn University of Technology, Tallinn, Estonia; Research Laboratory for Proactive Technologies, Tallinn University of Technology, Tallinn, Estonia; Department of Computer Systems, Tallinn University of Technology, Tallinn, Estonia","IEEE Access","16 Aug 2023","2023","11","","84670","84688","The number of ambient air quality monitoring stations is growing globally, driven by the need to quantify potential health risks posed by air pollution on urban populations. Reliable, robust and interoperable air quality monitoring requires observations with consistent accuracy and low amounts of missing data. In practice, this is challenging to achieve due to the measurement limitations and complexity of the physical phenomena. Data assimilation methods are widely used to fill missing or faulty observations and improve data quality by combining observations from fixed air quality monitoring ground stations with large-scale numerical models. A further advantage of data assimilation is that it can decrease costs by reusing existing open government data. A key requirement for assimilation is that uncertainty estimates are available for both measurements and model data. However, this poses a major bottleneck for widespread data assimilation with open data because uncertainty estimates are frequently unavailable. Additional challenges addressed in this work include the needs to impute missing data and process observations and model simulation results at different temporal and spatial scales. To address these challenges, we have developed novel, lightweight data assimilation algorithms based on recursive least-squares. The algorithms provide a fully data-driven way to estimate unknown uncertainties by defining the weights of the input data sources using least-squares data assimilation. The lightweight data assimilation algorithms can be executed to update the current state estimate in near real-time scenarios to improve the accuracy, completeness, and precision of the analysis estimate. A sensitivity analysis is conducted using synthetic data based on logistic maps with increasing noise levels. In addition, the proposed assimilation algorithms are applied to large-scale open pan-European air quality monitoring station data. The data were obtained from 86 stations for CO, 593 stations for NO2, 462 stations for O3, 137 stations for SO2, 254 stations for PM2.5, and 445 stations for PM10 in the period from 2022-01-27 01:00:00 to 2022-02-25 15:00:00 from the European Environmental Agency (EEA) and corresponding simulation results from the System for Integrated modeLling of Atmospheric composition (SILAM, global, version 5.7, FRC forecasts at the surface). The proposed lightweight data assimilation methods were found suitable to improve the completeness (filling in all missing data), accuracy (taken as the RMSE between the assimilation results and ground station observations) and precision for all of the open air quality parameters evaluated in this work. Furthermore, the proposed lightweight assimilation algorithms may also provide new and cost-effective methods to improve the data quality of the growing number of Internet of Things (IoT) urban air quality sensors.","2169-3536","","10.1109/ACCESS.2023.3302348","European Union through the European Social Fund as part of the “Information and Communication Technology (ICT) Programme.”; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10210046","Ambient air quality;data assimilation;environmental monitoring;open data;uncertainty quantification","Uncertainty;Monitoring;Numerical models;Data models;Europe;Data assimilation;Air quality;Environmental monitoring;Open data","","","","32","CCBY","7 Aug 2023","","","IEEE","IEEE Journals"
"SALLoc: An Accurate Target Localization in WiFi-Enabled Indoor Environments via SAE-ALSTM","S. L. Ayinla; A. A. Aziz; M. Drieberg","Department of Electrical and Electronic Engineering, Universiti Teknologi PETRONAS, Seri Iskandar, Perak, Malaysia; Department of Electrical and Electronic Engineering, Universiti Teknologi PETRONAS, Seri Iskandar, Perak, Malaysia; Department of Electrical and Electronic Engineering, Universiti Teknologi PETRONAS, Seri Iskandar, Perak, Malaysia","IEEE Access","8 Feb 2024","2024","12","","19694","19710","Developing a reliable and accurate indoor localization system is a crucial step for creating a seamless and interactive user-device experience in nearly all intelligent internet of things (IIoTs) and smart applications. Indoor localization systems based on WiFi fingerprinting have been considered as a promising alternative to model-based approaches owing to their accuracy, low cost, availability, and ease of configuration. However, recent studies have revealed that in complex environments, WiFi fingerprinting techniques are faced with a lot of challenges as the coverage area increases. These challenges include fingerprint spatial uncertainty, instability in the received signal strength indicator (RSSI) and discrepancy in fingerprint distribution. Furthermore, there is frequent need for database upgrades or even recreation whenever there is a change in the architecture of the location. These challenges have questioned the robustness and efficiency of most of the existing schemes. In this paper, we present an indoor localization architecture for complex multi-building multi-floor location prediction and subsequently propose SALLoc (SAE-ALSTM Localization), a WiFi fingerprinting indoor localization scheme based on Stacked Autoencoder (SAE) and Attention-based Long Short-Time Memory (ALSTM) framework. Firstly, stratified sampling technique is used to separate validation set from the entire uneven RSSI training set which ensures that the same proportion of RSSI samples are present in both sets. Secondly, SAE is utilized to select core features and decrease the dimensions of the RSSI samples. Finally, ALSTM is trained to focus on these features to achieve robust location prediction. Extensive investigations were conducted using UJIIndoorLoc, Tampere and UTSIndoorLoc datasets, and the results obtained demonstrated the superiority of the proposed scheme in terms of prediction accuracy, robustness, and generalizations when compared to state-of-the-art methods. The mean localization error (MLE) on UJIIndoorLoc, Tampere and UTSIndoorLoc datasets are 8.28 m, 9.52 m, and 6.48 m respectively. Consequently, it can be concluded that the proposed scheme is accurate and well-suited for large-scale indoor environment location prediction.","2169-3536","","10.1109/ACCESS.2024.3360228","Graduate Assistantship (GA) Scheme and the Institute of Health and Analytics (IHA) through Universiti Teknologi PETRONAS (UTP), Seri Iskandar, Perak, Malaysia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10416861","WiFi fingerprinting;indoor localization;mean localization error;stacked autoencoder;long short-time memory;attention mechanism","Location awareness;Fingerprint recognition;Wireless fidelity;Feature extraction;Robustness;Target tracking;Databases","","","","60","CCBYNCND","30 Jan 2024","","","IEEE","IEEE Journals"
"Wireless Communications for Collaborative Federated Learning","M. Chen; H. V. Poor; W. Saad; S. Cui","Chinese University of Hong Kong, Shenzhen; Princeton University; Virginia Tech.; Shenzhen Research Institute of Big Data, Chinese University of Hong Kong, Shenzhen","IEEE Communications Magazine","1 Jan 2021","2020","58","12","48","54","To facilitate the deployment of machine learning in resource and privacy-constrained systems such as the Internet of Things, federated learning (FL) has been proposed as a means for enabling edge devices to train a shared learning model while promoting privacy. However, Google's seminal FL algorithm requires all devices to be directly connected with a central controller, which limits its applications. In contrast, this article introduces a novel FL framework, called collaborative FL (CFL), which enables edge devices to implement FL with less reliance on a central controller. The fundamentals of this framework are developed and a number of communication techniques are proposed so as to improve CFL performance. An overview of centralized learning, Google's FL, and CFL is presented. For each type of learning, the basic architecture as well as its advantages, drawbacks, and operating conditions are introduced. Then four CFL performance metrics are presented, and a suite of communication techniques ranging from network formation, device scheduling, mobility management, to coding are introduced to optimize the performance of CFL. For each technique, future research opportunities are discussed. In a nutshell, this article showcases how CFL can be effectively implemented at the edge of large-scale wireless systems.","1558-1896","","10.1109/MCOM.001.2000397","National Natural Science Foundation of China(grant numbers:NSFC-61629101); U.S. National Science Foundation(grant numbers:CCF-1908308,CNS-1814477); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9311931","","Wireless communication;Performance evaluation;Privacy;Collaborative work;Reliability;Object recognition","","87","","15","IEEE","1 Jan 2021","","","IEEE","IEEE Magazines"
"Toward Communication-Efficient Digital Twin via AI-Powered Transmission and Reconstruction","M. Li; C. Chen; X. Yang; J. T. Zhou; T. Zhang; Y. Li","College of Information Science and Engineering, Jiaxing University, Jiaxing, China; School of Future Technology, South China University of Technology, Guangzhou, China; Institute for Infocomm Research (I2R), A*STAR, Connexis, Singapore; Centre for Frontier AI Research (CFAR) and Institute of High Performance Computing (IHPC), A*STAR, Connexis, Singapore; School of Computer Science and Engineering, Changsha University, Changsha, China; School of Computer Science and Engineering, Central South University, Changsha, China","IEEE Journal on Selected Areas in Communications","26 Oct 2023","2023","41","11","3624","3635","Digital twin technology has recently gathered pace in engineering communities as it allows for the convergence of the real structure and its digital counterpart. 3D point cloud data is a more effective way to describe the real world and to reconstruct the digital counterpart than the conventional 2D images or 360-degree images. Large-scale, e.g., city-scale digital twins, typically collect point cloud data via internet-of-things (IoT) devices and transmit it over wireless networks. However, the existing wireless transmission technology can not carry real-time point cloud transmission for digital twin reconstruction due to mass data volume, high processing overheads, and low delay-tolerance. We propose a novel artificial intelligence (AI) powered end-to-end framework, termed AIRec, for efficient digital twin communication from point cloud compression, wireless channel coding, and digital twin reconstruction. AIRec adopts the encoder-decoder architecture. In the encoder, a novel importance-aware pooling scheme is designed to adaptively select important points with learnable thresholds to reduce the transmission volume. We also design a novel noise-aware joint source and channel coding is proposed to adaptively adjust the transmission strategy based on SNR and map the features to error-resilient channel symbols for wireless transmission to achieve a good tradeoff between the transmission rate and reconstruction quality. The decoder can accurately reconstruct the digital twins from the received symbols. Extensive experiments of typical datasets and comparison with baselines show that we achieve a good reconstruction quality under  $24\times $  compression ratio.","1558-0008","","10.1109/JSAC.2023.3310089","Cultivation of Shenzhen Excellent Technological and Innovative Talents (Ph.D. Basic Research Started)(grant numbers:RCBS20200714114943014); Basic Research of Shenzhen Science and Technology Plan(grant numbers:JCYJ20210324123802006); Fundamental Research Funds for the Central Universities(grant numbers:x2wjD2230230); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10242296","Communication-efficient;digital twin;deep neural networks;point cloud","Point cloud compression;Digital twins;Three-dimensional displays;Image reconstruction;Wireless communication;Image coding;Symbols","","","","46","IEEE","6 Sep 2023","","","IEEE","IEEE Journals"
"Blockchain for Managing Heterogeneous Internet of Things: A Perspective Architecture","L. Tseng; L. Wong; S. Otoum; M. Aloqaily; J. B. Othman","Boston College, Boston, MA, USA; Boston College, Boston, MA, USA; Zayed University, Dubai, United Arab Emirates; Al Ain University, Al Ain, United Arab Emirates; L2S Lab., Centrale Supélec, University Paris Sud, Paris, France","IEEE Network","31 Jan 2020","2020","34","1","16","23","IoT has the potential to transform the way we think about information and communication technology. IoT has been studied extensively across many disciplines such as the networking, communication, security, business, and management communities. However, many unsolved challenges, especially in managing heterogeneous IoTs, remain to be discussed. Recent studies propose using blockchain, an emerging technology that enables decentralized coordination, to address inherent challenges in IoT. This article presents a preliminary study on an architecture that implements blockchain in managing heterogeneous IoT systems. We start by pointing out the limitations of prior IoT systems and the difficulties of integrating IoT and blockchain. Then we outline an architecture to manage a large-scale heterogeneous IoT system. Our main goal is to stimulate further effort and cross-disciplinary collaboration by providing guidance and reference for future studies.","1558-156X","","10.1109/MNET.001.1900103","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8977441","","Blockchain;Internet of Things;Distributed databases;Peer-to-peer computing;Security;Business;Privacy","","100","","15","IEEE","31 Jan 2020","","","IEEE","IEEE Magazines"
"Massive MU-MIMO Relaying IIoT Networks with Short-Packet: Timely Status Updates","T. Yu; B. Yu; S. Liu; X. Wang; Y. Cai; Z. Zhu; Z. Li","Army Engineering University of PLA, Nanjing, China; Army Engineering University of PLA, Nanjing, China; Unit 31401 of PLA, Jinan, China; Unit 31401 of PLA, Jinan, China; Army Engineering University of PLA, Nanjing, China; Army Engineering University of PLA, Nanjing, China; Unit 31401 of PLA, Jinan, China","2021 13th International Conference on Wireless Communications and Signal Processing (WCSP)","1 Dec 2021","2021","","","1","5","The fourth industrial revolution (Industrial 4.0) is coming, and the connection between devices will fundamentally change. Large-scale wireless connection has become the main connection method of the future factory version in the Industrial 4.0. However, The short-packet based status update scenario is not well investigated in the Industrial Internet of Things (IIoT) with large scale wireless connections. In this paper, we analyze the state update process of the massive multiuser multiple-input-multiple-output (MU-MIMO) relaying system with short-packet, propose and derive a system average age of information (AoI). Then, we study an asymptotic case with a large number of antennas, and obtain its closed-form expression. Numerical results verify the theoretical analysis and show that the system status update performance can be improved by increasing the number of antennas at the relay. We also find there exists optimal status packet length and pilot length that lead to the minimum system average AoI.","2472-7628","978-1-6654-0785-4","10.1109/WCSP52459.2021.9613368","National Natural Science Foundation of China(grant numbers:62171464,61771487); National Key R&D Program of China(grant numbers:2018YFB1801103); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9613368","massive MU-MIMO;age of information (AoI);short-packet;decode-and-forward (DF)","Wireless communication;Closed-form solutions;Antenna theory;Signal processing;Reliability theory;Information age;Production facilities","","1","","18","IEEE","1 Dec 2021","","","IEEE","IEEE Conferences"
"Deep-Learning-Based Joint Resource Scheduling Algorithms for Hybrid MEC Networks","F. Jiang; K. Wang; L. Dong; C. Pan; W. Xu; K. Yang","Hunan Provincial Key Laboratory of Intelligent Computing and Language Information Processing, Hunan Normal University, Changsha, China; Department of Computer and Information Sciences, Northumbria University, Newcastle upon Tyne, U.K.; Key Laboratory of Hunan Province for New Retail Virtual Reality Technology, Hunan University of Technology and Business, Changsha; School of Electronic Engineering and Computer Science, Queen Mary University of London, London, U.K.; National Mobile Communications Research Laboratory, Southeast University, Nanjing, China; School of Computer Technology and Engineering, Changchun Institute of Technology, Changchun, China","IEEE Internet of Things Journal","10 Jul 2020","2020","7","7","6252","6265","In this article, we consider a hybrid mobile edge computing (H-MEC) platform, which includes ground stations (GSs), ground vehicles (GVs), and unmanned aerial vehicles (UAVs), all with the mobile edge cloud installed to enable user equipments (UEs) or Internet of Things (IoT) devices with intensive computing tasks to offload. Our objective is to obtain an online offloading algorithm to minimize the energy consumption of all the UEs, by jointly optimizing the positions of GVs and UAVs, user association and resource allocation in real time, while considering the dynamic environment. To this end, we propose a hybrid deep-learning-based online offloading (H2O) framework where a large-scale path-loss fuzzy c-means (LS-FCM) algorithm is first proposed and used to predict the optimal positions of GVs and UAVs. Second, a fuzzy membership matrix U-based particle swarm optimization (U-PSO) algorithm is applied to solve the mixed-integer nonlinear programming (MINLP) problems and generate the sample data sets for the deep neural network (DNN) where the fuzzy membership matrix can capture the small-scale fading effects and the information of mutual interference. Third, a DNN with the scheduling layer is introduced to provide the user association and computing resource allocation under the practical latency requirement of the tasks and limited available computing resource of H-MEC. In addition, different from the traditional DNN predictor, we only input one UE's information to the DNN at one time, which will be suitable for the scenarios where the number of UE is varying and avoid the curse of dimensionality in DNN.","2327-4662","","10.1109/JIOT.2019.2954503","National Natural Science Foundation of China(grant numbers:41604117,41904127,41874148,61620106011,61572389,61871109); Royal Academy of Engineering through the Distinguished Visiting Fellowship Scheme(grant numbers:DVFS21819\9\7); Scientific Research Fund of Hunan Provincial Education Department in China(grant numbers:18A031); Hunan Provincial Science and Technology Project Foundation(grant numbers:2018TP1018,2018RS3065); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8907406","Deep neural network (DNN);fuzzy c-means;mobile edge computing (MEC);particle swarm optimization (PSO);resource allocation;unmanned aerial vehicle (UAV)","Task analysis;Heuristic algorithms;Water;Resource management;Deep learning;Real-time systems;Internet of Things","","116","","28","IEEE","20 Nov 2019","","","IEEE","IEEE Journals"
"Modeling of Deep Neural Network (DNN) Placement and Inference in Edge Computing","M. Bensalem; J. Dizdarevć; A. Jukan","Technische Universität Braunschweig, Germany; Technische Universität Braunschweig, Braunschweig, Germany; Technische Universität Braunschweig, Germany","2020 IEEE International Conference on Communications Workshops (ICC Workshops)","21 Jul 2020","2020","","","1","6","With the edge computing becoming an increasingly adopted concept in system architectures, it is expected its utilization will be additionally heightened when combined with deep learning (DL) techniques. The idea behind integrating demanding processing algorithms in Internet of Things (IoT) and edge devices, such as Deep Neural Network (DNN), has in large measure benefited from the development of edge computing hardware, as well as from adapting the algorithms for use in resource constrained IoT devices. Surprisingly, there are no models yet to optimally place and use machine learning in edge computing. In this paper, we propose the first model of optimal placement of Deep Neural Network (DNN) Placement and Inference in edge computing. We present a mathematical formulation to the DNN Model Variant Selection and Placement (MVSP) problem considering the inference latency of different model-variants, communication latency between nodes, and utilization cost of edge computing nodes. We evaluate our model numerically, and show that for low load increasing model co-location decreases the average latency by 33% of millisecond-scale per request, and for high load, by 21%.","2474-9133","978-1-7281-7440-2","10.1109/ICCWorkshops49005.2020.9145449","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9145449","","Computational modeling;Load modeling;Mathematical model;Edge computing;Numerical models;Delays;Hardware","","6","","15","IEEE","21 Jul 2020","","","IEEE","IEEE Conferences"
"Toward long-range adaptive communication via information centric networking","A. Dowling; L. Huie; L. Njilla; H. Zhao; Y. Liu","Department of Electrical and Computer Engineering, Clarkson University, Potsdam, NY, USA; Information Directorate in Rome, Air Force Research Laboratory, Rome, NY, USA; Information Directorate in Rome, Air Force Research Laboratory, Rome, NY, USA; Department of Electrical and Computer Engineering, Fairleigh Dickinson University, Teaneck, NJ, USA; Department of Electrical and Computer Engineering, Fairleigh Dickinson University, Teaneck, NJ, USA","Intelligent and Converged Networks","12 May 2021","2021","2","1","1","15","As Internet of Things (IoT) applications become more prevalent and grow in their use, a limited number ofwireless communication methods may be unable to enable dependable, robust delivery of information. It is necessary to enable adaptive communication and interoperability over a variety of wireless communication media to meet the requirements of large-scale IoT applications. This paper utilizes Named Data Networking (NDN), an up-and-coming Information-Centric Network architecture, to interconnect differing communication links via the network layer, and implements dynamic forwarding strategies and routing mechanisms which aid in the efficient dissemination of information. This work targets the creation of an interface technique to allow NDN to be transported via LoRa. This is acheived via the coupling of LoRa and WiFi using the NDN Forwarding Daemon (NFD) to create a universal ad hoc network. This network has the capacity for high range and multi-hop Device-to-Device (D2D) communication together with compatibility with other network communication media. Testing of the system in a real environment has shown that the newly created ad hoc network is capable of communicating over a several kilometer radius, while making use of the features provided by NDN to capitalize upon various links available to enable the efficient dissemination of data. Furthermore, the newly created network leverages NDN features to enable content-based routing within the LoRa network and utilize content-based routing techniques.","2708-6240","","10.23919/ICN.2021.0001","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9430092","Named Data Networking (NDN);ad hoc network;device-to-device communication","Ad hoc networks;Wireless communication;Wireless fidelity;Routing;Communication system security;Smart cities;Internet of Things","","5","","","","12 May 2021","","","TUP","TUP Journals"
"Peak Age of Information Optimization of Slotted Aloha","D. Wu; W. Zhan; X. Sun; B. Zhou; J. Liu","School of Electronics and Communication Engineering, Shenzhen Campus of Sun Yat-sen University; School of Electronics and Communication Engineering, Shenzhen Campus of Sun Yat-sen University; School of Electronics and Communication Engineering, Shenzhen Campus of Sun Yat-sen University; School of Electronics and Communication Engineering, Shenzhen Campus of Sun Yat-sen University; School of Electronics and Communication Engineering, Shenzhen Campus of Sun Yat-sen University","2022 IEEE 96th Vehicular Technology Conference (VTC2022-Fall)","18 Jan 2023","2022","","","1","7","The timeliness of information is of capital importance for numerous Internet of Things (IoT) services. To improve the information freshness in large-scale distributed IoT systems, this paper focuses on the Peak Age of Information (PAoI) optimization of slotted Aloha networks. Specifically, by assuming the first-come-first-served (FCFS) service discipline and Bernoulli packet arrival model, the mean PAoI is characterized and then optimized by either individually tuning the channel access probability or jointly tuning the channel access probability and packet arrival rate of each sensor. The explicit expressions of optimal parameter settings and the corresponding minimum PAoI are obtained, based on which the age-throughput tradeoff is evaluated. The analysis is verified by simulations. It is found that in the massive access scenarios, the minimum PAoI linearly increases with the network scale in both individual optimization and joint optimization cases, while the latter attains a lower increasing rate, better age performance, and less throughput loss.","2577-2465","978-1-6654-5468-1","10.1109/VTC2022-Fall57202.2022.10012799","Research and Development; National Natural Science Foundation of China; Natural Science Foundation of Guangdong Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10012799","Age of information;slotted Aloha;channel access probability;packet arrival rate","Vehicular and wireless technologies;Analytical models;Closed-form solutions;Throughput;Information age;Behavioral sciences;Internet of Things","","","","20","IEEE","18 Jan 2023","","","IEEE","IEEE Conferences"
"PIoT: A Performance IoT Simulation System for a Large-Scale City-Wide Assessment","A. D. Firouzabadi; H. Mellah; O. Manzanilla-Salazar; R. Khalvandi; V. Therrien; V. Boutin; B. Sansò","Department of Electrical Engineering, Polytechnique Montréal, Montréal, Canada; Department of Electrical Engineering, Polytechnique Montréal, Montréal, Canada; Department of Electrical Engineering, Polytechnique Montréal, Montréal, Canada; Department of Electrical Engineering, Polytechnique Montréal, Montréal, Canada; Department of Electrical Engineering, Polytechnique Montréal, Montréal, Canada; Department of Electrical Engineering, Polytechnique Montréal, Montréal, Canada; Department of Electrical Engineering, Polytechnique Montréal, Montréal, Canada","IEEE Access","12 Jun 2023","2023","11","","56273","56286","Given the proliferation of sensors and actuators, evaluating the network performance of current and forthcoming city-wide Internet of Things (IoT) applications is a challenging task. To overcome this challenge, we created a large-scale simulator called PIoT over the years that can assess the performance of multiple millions of mobile/static IoT devices using a 4G/5G cellular infrastructure. In PIoT, different Key Performance Indicators (KPIs) are defined and collected to produce data to evaluate applications and network performance. PIoT is an on-going academic simulator project, and its most recent version is accessible to the public through the user interface found on https://www.piotsimulation.com without any installation requirements. It uses a realistic database that contains the real locations and features of Base Stations (BSs) and the real locations of IoT user equipment devices. The interface can be used by operators and researchers to understand network behavior when deploying new applications or to gather data to feed artificial intelligence and machine learning algorithms. The objective of this paper is to present a detailed description of the PIoT modeling architecture, as well as some use cases to help potential users understand the type of capabilities that are available when using the simulator. Limitations and comparisons with other popular engines are also included in the paper.","2169-3536","","10.1109/ACCESS.2023.3282729","Natural Sciences and Engineering Research Council of Canada (NSERC); Telefonaktiebolaget LM Ericsson(grant numbers:CRDPJ 520642); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10143545","PIoT;large-scale simulator;performance assessment;LTE/5G/B5G networks;data gathering;data mining;key performance indicators","Internet of Things;Computational modeling;Electrical engineering;Delays;Smart cities;Databases;Mathematical models","","2","","63","CCBYNCND","5 Jun 2023","","","IEEE","IEEE Journals"
"Relay Placement Algorithms for IoT Connectivity and Coverage in an Outdoor Heterogeneous Propagation Environment","N. Rathod; R. Sundaresan","Department of Electrical Communication Engineering, Robert Bosch Centre for Cyber-Physical Systems, Indian Institute of Science (IISc), Bengaluru, India; Department of Electrical Communication Engineering, Robert Bosch Centre for Cyber-Physical Systems, Indian Institute of Science (IISc), Bengaluru, India","IEEE Access","4 Feb 2022","2022","10","","13270","13289","A vast majority of the Internet of Things (IoT) devices will be connected in a topology where the edge-devices push data to a local gateway, which forwards the data to a cloud for further processing. In sizeable outdoor deployment regions, the edge-devices may experience poor connectivity due to their distant locations and limited transmission power. Repeaters or relays must be placed at a few locations to ensure reliable connectivity to either a gateway or another node in the network. A big challenge in achieving reliable connectivity and coverage is the outdoor propagation environment being heterogeneous. Engineers often deploy networks based on resource-intensive field visits, detailed surveys, measurements, initial test deployments, followed by fine-tuning. For scalability to large scale IoT deployments, automated network planning tools are essential. Such tools should predict connectivity based on the edge-device locations using available Geographical Information System (GIS) data, identify the need for relays/repeaters, and, if needed, suggest the number of relays needed with their locations. Furthermore, such tools should also be extended to suggest the minimum number and locations of base stations that maximise coverage. In this paper, we propose an automated network deployment framework using a black box received signal strength estimation oracle that provides signal strength estimates between candidate pairs of transceiver locations in a heterogeneous deployment region. Our proposed methodology uses either Ant Colony Optimisation (ACO) or Differential Evolution (DE) to identify the number and locations of relays for meeting specified quality of service constraints. We discuss adaptations of our techniques to handle scenarios with multiple gateways. Further, we show the effectiveness of these algorithms to find suitable candidate base station locations to provide coverage in a heterogeneous propagation environment that meets the specified quality of service constraints. We then demonstrate the effectiveness of our algorithms in two deployment regions.","2169-3536","","10.1109/ACCESS.2022.3147488","Science and Engineering Research Board, Department of Science and Technology, Government of India; Robert Bosch Centre for Cyber-Physical Systems, Indian Institute of Science, Bengaluru; Centre for Networked Intelligence (a Cisco CSR initiative) of the Indian Institute of Science, Bengaluru; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9696351","Coverage;GIS;heterogeneous propagation environment;Internet of Things;IoT;RF propagation tool;RSSI;sub giga hertz;sub-GHz","Relays;Logic gates;Quality of service;Internet of Things;Wireless sensor networks;Optimization;Base stations","","3","","45","CCBY","28 Jan 2022","","","IEEE","IEEE Journals"
"DR-TSP: A Data Repairing Framework for Time Synchronization Problems in ERI Data","D. Xia; L. Zheng; L. Chen; W. Liu; D. Sun","College of Computer Science and Key Laboratory of Dependable Service Computing in Cyber Physical Society of Ministry of Education, Chongqing University, Chongqing, China; College of Computer Science and Key Laboratory of Dependable Service Computing in Cyber Physical Society of Ministry of Education, Chongqing University, Chongqing, China; College of Computer Science and Key Laboratory of Dependable Service Computing in Cyber Physical Society of Ministry of Education, Chongqing University, Chongqing, China; College of Computer Science and Key Laboratory of Dependable Service Computing in Cyber Physical Society of Ministry of Education, Chongqing University, Chongqing, China; College of Computer Science and Key Laboratory of Dependable Service Computing in Cyber Physical Society of Ministry of Education, Chongqing University, Chongqing, China","IEEE Internet of Things Journal","6 Jul 2021","2021","8","14","11666","11677","Timestamps are often problematic in Internet-of-Things (IoT) systems due to time synchronization problems of distributed radio-frequency identification (RFID) readers or sensors. This issue may seriously affect the data quality in some fields, such as transportation. A typical IoT application in transportation is electronic registration identification of the motor vehicle (ERI), an emerging traffic data acquisition technology based on RFID. ERI data play a vital role in intelligent transportation. However, the data quality is often affected seriously by the inaccurate timestamps, which arise from the time-unsynchronized distributed ERI readers. To solve this issue, we propose a novel framework, data repairing of time synchronization problems (DR-TSP), which can detect the time-unsynchronized ERI readers and correct timestamp-deviated ERI data. Precisely, DR-TSP consists of three components. Problem reader discovery component employs a statistics-based method to detect the time-unsynchronized ERI readers and discovers the clock leaps of the problematic ERI reader through a smoothing-based method. Travel-time estimation component constructs a spatial correlative travel-time estimation model based on the neural network to infer timestamp deviation. The influence of clock deviation is considered in the model training. Data correction component utilizes the above results to correct the timestamp-deviated data. Experiments over large-scale ERI data collected from a big China city, Chongqing, show that our method can significantly improve data quality.","2327-4662","","10.1109/JIOT.2021.3058640","National Key Research and Development Program of China(grant numbers:2017YFC0212103); Key Research and Development Program of Chongqing(grant numbers:cstc2018jszx-cyztzxX0019); Ford University Research Program(grant numbers:DEPT2018-J030.1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9352961","Data cleaning and repairing;radio-frequency identification (RFID);time synchronization problem;travel-time estimation model","Internet of Things;Clocks;Synchronization;Sensors;Roads;Data models;Radiofrequency identification","","3","","42","IEEE","11 Feb 2021","","","IEEE","IEEE Journals"
"Pricing and Resource Allocation Optimization for IoT Fog Computing and NFV: An EPEC and Matching Based Perspective","N. Raveendran; H. Zhang; L. Song; L. -C. Wang; C. S. Hong; Z. Han","PoLTE Corp, Addison, TX, USA; Google LLC, Mountain View, CA, USA; School of Electrical Engineering and Computer Science, Peking University, Beijing, China; Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan; Department of Computer Science and Engineering, Kyung Hee University, Yongin, South Korea; University of Houston, Houston, TX, USA","IEEE Transactions on Mobile Computing","4 Mar 2022","2022","21","4","1349","1361","The number of devices connected to the Internet of Things (IoT) is growing at an enormous rate globally. In the next generation networks, distributed fog computing deployments at the network edge can provide computing resources to the users, especially for latency-sensitive applications. Further, the heterogeneous needs of the fifth generation (5G) networks demand the virtualization of network functions, termed as network function virtualization (NFV). Therefore, an integrated NFV and fog computing resource allocation framework for IoT is of prime importance. Accordingly, in this paper, we model the interactions between the data service operators (DSOs) and the authorized data service subscribers (ADSSs) as an equilibrium problem with equilibrium constraints (EPEC), and utilize the alternating direction method of multipliers (ADMM) as a large-scale optimization tool to obtain solutions. This results in the optimization of resource pricing for the DSOs and the amount of resources to be purchased by the ADSSs. Moreover, we propose a many-to-many matching based model to allocate the fog node (FN) resources according to the VNF resource requirements of the ADSSs. Simulation results show the effectiveness of our proposed approach in achieving efficient resource allocation in NFV enabled IoT fog computing.","1558-0660","","10.1109/TMC.2020.3025189","National Science Foundation(grant numbers:EARS-1839818,CNS-1717454,CNS-1731424,CNS-1702850); Ministry of Science and Technology(grant numbers:MOST 109-2634-F-009-018-); Pervasive Artificial Intelligence Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9200548","Fog computing;NFV;IoT;resource allocation;EPEC;ADMM;many-to-many matching","Edge computing;Resource management;Virtualization;Optimization;Cloud computing;Computational modeling;Internet of Things","","15","","50","IEEE","18 Sep 2020","","","IEEE","IEEE Journals"
"A Genetic Algorithm Based on Auxiliary-Individual-Directed Crossover for Internet-of-Things Applications","Q. Fan; S. Wu; X. Zhou; L. Li; Z. Wang","Faculty of Information Technology, Beijing University of Technology, Beijing, China; School of Information Technology, Illinois State University, Normal, IL, USA; Faculty of Information Technology, Beijing University of Technology, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China","IEEE Internet of Things Journal","24 Mar 2021","2021","8","7","5518","5530","In order to solve the large-scale, strong coupling, and nonlinear optimization problems in many Internet-of-Things (IoT) applications, such as intelligent infrastructure and smart city, this article proposes a real-coded genetic algorithm based on an auxiliary-individual-directed crossover operator (AIDX). AIDX is an alternative offspring framework of the directed crossover which uses auxiliary individual to reduce the search space of alternative offspring for the rapid optimization of multidimensional problems. In our solution AIDX, the parents-center distribution is adopted to reduce the risk of convergence to local optimization and enhance the stability of the algorithm. In addition, in order to increase the diversity of the population at the late stage of optimization, K-Bit-Swap (KBS) is used as a supplement for the exchange of genetic information among individuals in different dimensions. In the extensive experiments, 24 benchmarks with different dimensions are used to evaluate the performance of AIDX-GA. The results show that the proposed AIDX-GA has a significantly improved optimization effect on multidimensional optimization problems, and the stability of the algorithm is largely enhanced even when the global optimum is located near the boundary. AIDX-GA has also been evaluated in an industrial IoT case that identifies the resistance coefficients of a pipe network in the city infrastructure. The results show that the accuracy of AIDX-GA is high, and it has excellent universality and stability, which can be used to solve many IoT problems.","2327-4662","","10.1109/JIOT.2020.3031922","National Natural Science Foundation of China(grant numbers:61873007,61890935); Major Science and Technology Program for Water Pollution Control and Treatment of China(grant numbers:2018ZX07111005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9229187","Auxiliary individual;directed crossover;evolutionary algorithm (EA);real-coded genetic algorithm (GA);smart network","Optimization;Genetic algorithms;Internet of Things;Sociology;Statistics;Task analysis;Search problems","","1","","44","IEEE","19 Oct 2020","","","IEEE","IEEE Journals"
"Directed acyclic graph blockchain for secure spectrum sharing and energy trading in power IoT","Z. Zhang; M. Zhang; Y. Li; B. Fan; L. Jiang","School of Automation, Guangdong University of Technology, Guangzhou, China; School of Automation, Guangdong University of Technology, Guangzhou, China; Chongqing Key Laboratory of Intelligent Perception and BlockChain Technology, (Chongqing Technology and Business University), Chongqing, China; Beijing Key Laboratory of Traffic Engineering, Beijing University of Technology, Beijing, China; School of Automation, Guangdong University of Technology, Guangzhou, China","China Communications","22 May 2023","2023","20","5","182","197","Peer-to-peer (P2P) spectrum sharing and energy trading are promising solutions to locally satisfy spectrum and energy demands in power Internet of Things(IoT). However, implementation of large-scale P2P spectrum sharing and energy trading confronts security and privacy challenges. In this paper, we exploit consortium blockchain and Directed Acyclic Graph (DAG) to propose a new secure and distributed spectrum sharing and energy trading framework in power IoT, named spectrum-energy chain, where a set of local aggregators (LAGs) cooperatively confirm the identity of the power devices by utilizing consortium blockchain, so as to form a main chain. Then, the local power devices verify spectrum and energy micro-transactions simultaneously but asynchronously to form local spectrum tangle and local energy tangle, respectively. Moreover, an iterative double auction based micro transactions scheme is designed to solve the spectrum and energy pricing and the amount of shared spectrum and energy among power devices. Security analysis and numerical results illustrate that the developed spectrum-energy chain and the designed iterative double auction based micro-transactions scheme are secure and efficient for spectrum sharing and energy trading in power IoT.","1673-5447","","10.23919/JCC.2023.00.013","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10056788","power Internet of Things (IoT);spectrum sharing;energy trading;security and privacy;consortium blockchain;Directed Acyclic Graph (DAG);iterative double auction","Blockchains;Security;Internet of Things;Privacy;Directed acyclic graph;Smart meters;Peer-to-peer computing","","","","","","28 Feb 2023","","","IEEE","IEEE Magazines"
"Efficient Traceability Systems of Steel Products Using Blockchain-Based Industrial Internet of Things","Y. Cao; F. Jia; G. Manogaran","School of Mechatronic Engineering, Xi'an Technological University, Xi'an, China; School of Mechatronic Engineering, Xi'an Technological University, Xi'an, China; University of California Davis, Davis, USA","IEEE Transactions on Industrial Informatics","2 Jun 2020","2020","16","9","6004","6012","With the development of the industrial Internet of Things (IIoT), the existing IIoT platform has gradually formed a large-scale, heterogeneous distributed environment. How to ensure information security and achieve efficient product traceability is an urgent problem to be solved in the development of the steel IoT platform. In view of the low transparency of information traceability of current steel products and the defects of information islands, in this article the blockchain-based steel IoT quality traceability system is developed and adopted the alliance chain mode and the Hyperledger blockchain platform. Experimental tests prove that production companies, logistics, and consumers can participate in the information certification of steel products via the system. Consumers can understand the real product manufacturing process, effectively avoiding the incomplete information and low transparency in the traditional information traceability process, and effectively trace the quality of steel products. The system provides an effective scheme for promoting the transformation and upgrading of the steel industry.","1941-0050","","10.1109/TII.2019.2942211","Shaanxi Innovation Capability Support Plan(grant numbers:2018TD-036); Shaanxi Key Research and Development Plan(grant numbers:2018ZDXM-GY-077); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8843946","Blockchain;industrial Internet of Things;steel products;traceability systems","Blockchain;Steel;Radiofrequency identification;Internet of Things;Industries;Supply chains;Security","","90","","29","IEEE","18 Sep 2019","","","IEEE","IEEE Journals"
"DQN-Based Optimization Framework for Secure Sharded Blockchain Systems","J. Yun; Y. Goh; J. -M. Chung","School of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea; School of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea; School of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea","IEEE Internet of Things Journal","6 Jan 2021","2021","8","2","708","722","High levels of scalability and reliability are needed to support the massive Internet-of-Things (IoT) services. In particular, blockchains can be effectively used to safely manage data from large-scale IoT networks. However, current blockchain systems have low transactions per second (TPS) rates and scalability limitations that make them unsuitable. To solve the above issues, this article proposes a deep Q network shard-based blockchain (DQNSB) scheme that dynamically finds the optimal throughput configuration. In this article, a novel analysis of sharded blockchain latency and security-level characterization is provided. Using the analysis equations, the DQNSB scheme estimates the level of maliciousness and adapts the blockchain parameters to enhance the security level considering the amount of malicious attacks on the consensus process. To achieve this purpose, deep reinforcement learning (DRL) agents are trained to find the optimal system parameters in response to the network status, and adaptively optimizes the system throughput and security level. The simulation results show that the proposed DQNSB scheme provides a much higher TPS than the existing DRL-enabled blockchain technology while maintaining a high security level.","2327-4662","","10.1109/JIOT.2020.3006896","Ministry of Science and ICT (MSIT), South Korea, through the Information Technology Research Center; Institute for Information and communications Technology Planning and Evaluation (IITP)(grant numbers:IITP-2020-2018-0-01799); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9133069","Deep reinforcement learning (DRL);Internet of Things (IoT);optimization;scalable blockchain;sharding","Blockchain;Security;Throughput;Scalability;Internet of Things;Optimization;Reinforcement learning","","51","","44","IEEE","3 Jul 2020","","","IEEE","IEEE Journals"
"Wi-SUN FAN Multi-hop Network in Coexistence of IEEE 802.15.4 FSK and OFDM Transmission Schemes","H. Ochiai; K. Mizutani; H. Harada","Graduate School of Informatics, Kyoto University, Yoshida-honmachi, Sakyo-ku, Kyoto, Japan; Graduate School of Informatics, Kyoto University, Yoshida-honmachi, Sakyo-ku, Kyoto, Japan; Graduate School of Informatics, Kyoto University, Yoshida-honmachi, Sakyo-ku, Kyoto, Japan","2021 24th International Symposium on Wireless Personal Multimedia Communications (WPMC)","7 Feb 2022","2021","","","1","6","The wireless smart ubiquitous network field area network (Wi-SUN FAN) is a wireless communication standard for the Internet of things (IoT) in outdoor large-scale multi-hop networks. Currently, frequency shift keying (FSK) standardized in IEEE 802.15.4 is employed as the physical layer of the Wi-SUN FAN. Improving data rate of the physical layer is essential to realize expected requirements toward the next-generation IoT systems. In this paper, we introduce the orthogonal frequency division multiplexing (OFDM) standardized in IEEE 802.15.4 into the Wi-SUN FAN to improve data rate without increasing the system bandwidth. We evaluated the packet error rate (PER) characteristics under inter-signal interference in the transition period of the physical layer from FSK to OFDM through a computer simulation. Results showed that the new interference caused by the mixture of OFDM degraded the PER characteristics, in comparison with the interference between FSKs. However, the interference between different channels was limited because the required carrier-to-interference power ratio to achieve PER=10% was below –10dB. Furthermore, we evaluated the transmission characteristics of the Wi-SUN FAN in the media access control layer and verified that the introduction of the OFDM is effective for improving the maximum system throughput by 1.9 times when performing frequency hopping.","1882-5621","978-1-6654-2760-9","10.1109/WPMC52694.2021.9700449","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9700449","Frequency hopping;FSK;IEEE S02.15.4;OFDM;Throughput enhancement;Wi-SUN FAN","IEEE 802.15 Standard;Wireless communication;Fans;OFDM;Computer simulation;Frequency shift keying;Interference","","2","","11","IEEE","7 Feb 2022","","","IEEE","IEEE Conferences"
"Predictive Resource Management in Energy-constrained Embedded Systems","S. Crippa; G. Massari; F. Reghenzani; M. Zanella; W. Fornaciari","DEIB, Politecnico di Milano, Italy; DEIB, Politecnico di Milano, Italy; DEIB, Politecnico di Milano, Italy; DEIB, Politecnico di Milano, Italy; DEIB, Politecnico di Milano, Italy","2020 23rd Euromicro Conference on Digital System Design (DSD)","8 Oct 2020","2020","","","159","166","The current trends in Internet of Things (IoT) lead to the deployment of low-power devices covering a wide range of application scenarios. These devices have the goal of executing simple tasks, automatically, usually with strict requirements in terms of space and cost. Typically, these devices have to rely on batteries or by harvesting energy devices (e.g., solar panels), in order to operate. On the other hand, IoT devices may be equipped with powerful multi-core CPUs to achieve performance goals, making the management of the energy budget a challenging task. This requires the development of an effective management system, that takes into account current and future energy budget availability, to dynamically bound the actual allocation of processing resources. Specifically, when exploiting solar panels for power supply, we can leverage on the weather forecast, to estimate the availability of energy in the near future. This paper introduces a predictive energy budget management system, targeting multi-core based embedded platforms. Thanks to both local and large-scale weather information, our solution aims at predicting the future incoming power and, accordingly, tuning the exploitable performance level to keep the system running under any environmental condition.","","978-1-7281-9535-3","10.1109/DSD51259.2020.00035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9217840","IoT;energy-aware;embedded system;power management;machine learning;fault detection;solar energy;scheduling;multi-core","Batteries;Solar panels;Weather forecasting;Task analysis;Predictive models;Power supplies","","","","19","IEEE","8 Oct 2020","","","IEEE","IEEE Conferences"
"Smart Water Management: a Self-Sufficient IoT-Based Application for Pressure and Flow Monitoring in Water Distribution Systems","L. D. de Oliveira; J. V. S. De Araújo; J. H. B. Da Silva; J. M. M. Villanueva; C. A. de Souza Filho; M. N. Ochoa","Undergraduate in Electrical Engineering, Federal University of Paraíba, João Pessoa, Brazil; Graduate in Electrical Engineering, Federal University of Paraíba, João Pessoa, Brazil; Undergraduate in Electrical Engineering, Federal University of Paraíba, João Pessoa, Brazil; Department of Electrical Engineering, Federal University of Paraíba, João Pessoa, Brazil; Department of Electrical Engineering, Federal University of Paraíba, João Pessoa, Brazil; Department of Electrical Engineering, Universidad de Ingenieria y Tecnologia – UTEC, Lima, Peru","2023 7th International Symposium on Instrumentation Systems, Circuits and Transducers (INSCIT)","25 Sep 2023","2023","","","1","6","Water distribution in municipalities involves various challenges, such as maintenance of pipelines, pressure and flow control, water quality monitoring, among others. In this sense, measuring the flow and pressure of a system is a key issue for optimizing water distribution in cities. Therefore, this information is important to ensure that water is delivered with quality and in adequate quantity to consumers. With the advent of technology, some advanced solutions have been proposed in the literature to address these challenges, such as hydraulic modeling software, intelligent sensors, and automated control systems. Among these, one of the most commonly used techniques to increase system efficiency is wireless sensor networks. However, monitoring in a wide coverage area, such as metropolises, becomes difficult to implement, involving high costs and infeasibility of large-scale sensor installation. Therefore, applications involving IoT (Internet of Things) have been proposed as a low-cost and low energy consumption alternative. Thus, this article describes the steps, challenges, and solutions necessary for the development of a self-sufficient IoT application aimed at monitoring pressure and flow in a water supply network.","","979-8-3503-2651-2","10.1109/INSCIT59673.2023.10258484","Conselho Nacional de Desenvolvimento Científico e Tecnológico; Universidade Federal da Paraíba; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10258484","Water Pressure;Water Flow;Internet of Things;Self-sufficient system;Micro Hydro Turbine","Wireless communication;Wireless sensor networks;Costs;Transducers;Urban areas;Refining;Water quality","","","","12","IEEE","25 Sep 2023","","","IEEE","IEEE Conferences"
"Crowd Safety Sensing (CroSS) for the Post Pandemic Era","K. J. Almalki; M. Mohzary; B. -Y. Choi; S. Song; Y. Chen","School of Computing and Engineering, University of Missouri, Kansas City, MO, USA; School of Computing and Engineering, University of Missouri, Kansas City, MO, USA; School of Computing and Engineering, University of Missouri, Kansas City, MO, USA; School of Computing and Engineering, University of Missouri, Kansas City, MO, USA; Dept. of Electrical and Computer Engineering, Binghamton University, Binghamton, NY, USA","2021 IEEE Globecom Workshops (GC Wkshps)","24 Jan 2022","2021","","","1","6","Due to its long incubation period, aggressive asymptomatic transmission, and new mutations of the virus, COVID-19 is causing multiple pandemic waves worldwide. Despite recent vaccination, social distancing, and social restriction efforts, false negatives, and dormant positives can make pandemics challenging to restrain. In addition to rapid vaccination, effective contact tracing, mask-wearing, and social distancing are critical for out-break containment and for achieving herd immunity. However, the existing technology solutions, such as contact tracing apps and social-distance sensing, have been met with suspicion due to privacy and accuracy concerns and have not been widely adopted. Without achieving a critical mass of individual users, these personal technologies have been rendered useless. On the other hand, large-scale policy efforts have been complicated, requiring the coordination of federal, state, and local governments and regulation enforcement logistics. However, local communities balance these approaches and are an unrealized, powerful resource to prevent future outbreaks.This paper proposes a novel Crowd Safety Sensing (CroSS) for building a sustainable safe community cluster against COVID-19 and beyond using affordable Internet of Things (IoT) technologies. CroSS monitors social distancing policies to small, focused communities for accommodating efficient technology penetration, greater accuracy, effective practices, and privacy policy assistance. We implemented a social distancing method and integrated it into an edge-based IoT system. The experimental results show that CroSS detects false-positive social distancing cases.","","978-1-6654-2390-8","10.1109/GCWkshps52748.2021.9682120","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9682120","COVID-19;Social Distancing;Internet of Things","COVID-19;Privacy;Pandemics;Image edge detection;Human factors;Social factors;Sensors","","1","","16","IEEE","24 Jan 2022","","","IEEE","IEEE Conferences"
"A Derivative PBFT Blockchain Consensus Algorithm With Dual Primary Nodes Based on Separation of Powers-DPNPBFT","Y. Na; Z. Wen; J. Fang; Y. Tang; Y. Li","College of Communication Engineering, Chengdu University of Information Technology, Chengdu, China; College of Communication Engineering, Chengdu University of Information Technology, Chengdu, China; College of Communication Engineering, Chengdu University of Information Technology, Chengdu, China; College of Communication Engineering, Chengdu University of Information Technology, Chengdu, China; College of Communication Engineering, Chengdu University of Information Technology, Chengdu, China","IEEE Access","26 Jul 2022","2022","10","","76114","76124","The Practical Byzantine Fault Tolerant (PBFT) consensus algorithm has many advantages, which makes PBFT utilized widely. Nonetheless, PBFT is not suitable for large-scale node scenarios due to its high communication complexity and it also has an apparent disadvantage of inadequate fault tolerance. The typically derived PBFT algorithms focus on reducing communication complexity at the cost of diminished system security or fault tolerance. In this paper, Dual-Primary-Node derived Practical Byzantine Fault Tolerance (DPNPBFT) is proposed to achieve the best balance of the above three performances. First, DPNPBFT selects dual master nodes based on the idea of power separation. The two master nodes check balance and supervise each other to avoid excessive centralization as a single master node system. It also reduces the communication complexity of the replica node, which only communicates with the master node. Furthermore, we designed the architecture of DPNPBFT to get a practical 49% fault tolerance rate, and it is close to the current mainstream Proof of Work and Proof of Stake algorithms. Experimental results demonstrate that DPNPBFT has O(N) level communication complexity and excellent anti-host node malicious performance. The Transactions Per Second of DPNPBFT is stable at 1700. It proves DPNPBFT has the best performance balance and excellent comprehensive performance for large-scale Internet of Things application scenarios.","2169-3536","","10.1109/ACCESS.2022.3192426","Sichuan Science and Technology Program, Soft Science Project(grant numbers:2022JDR0076); Strategic Research and Consulting Project of Chinese Academy of Engineering through the Project ”New Infrastructure” Blockchain Core Key Technology Development Strategy Research(grant numbers:2022-XY-111); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9832872","Blockchain;PBFT;consensus algorithm;communication complexity","Complexity theory;Consensus algorithm;Fault tolerant systems;Fault tolerance;Blockchains;Security;Internet of Things","","9","","20","CCBY","19 Jul 2022","","","IEEE","IEEE Journals"
"Cost Effective Routing in Large-scale Multi-hop LoRa Networks","S. Feng; J. Chen; Z. Zhao","University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China","IEEE INFOCOM 2022 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)","20 Jun 2022","2022","","","1","6","Low-Power Wide-Area Network (LPWAN) technologies promoted the communication capacities of Internet of Things (IoT) to several or even dozens of kilometers. LoRa is one of these technologies characterized with longrange, low data rates and low power consumption. The LoRaWAN architecture is applied to a star-of-stars topology. However, in several non-line-of-sight or larger scale deployment scenarios, such as underground deployment and large-scale military launch, the single-hop topology may not meet the requirements. Adding gateways to increase coverage may increase deployment complexity and reduce information sharing. Furthermore, the exhaustion of a single node in the network will bring extra cost of replacing the battery, further reducing the network lifetime. Consequently, this paper introduces a multi-hop protocol MLoRa to solve these problems. MLoRa gives a routing strategy upon network layer, which not only brings cost-effective coverage but also lower and balanced energy consumption for the same coverage in LoRa networks.","","978-1-6654-0926-1","10.1109/INFOCOMWKSHPS54753.2022.9798302","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9798302","","Costs;Protocols;Network topology;Conferences;Spread spectrum communication;Routing;Topology","","4","","20","IEEE","20 Jun 2022","","","IEEE","IEEE Conferences"
"Video Big Data Analytics in the Cloud: A Reference Architecture, Survey, Opportunities, and Open Research Issues","A. Alam; I. Ullah; Y. -K. Lee","Department of Computer Science and Engineering, Kyung Hee University (Global Campus), Yongin, South Korea; Department of Computer Science and Engineering, Kyung Hee University (Global Campus), Yongin, South Korea; Department of Computer Science and Engineering, Kyung Hee University (Global Campus), Yongin, South Korea","IEEE Access","26 Aug 2020","2020","8","","152377","152422","The proliferation of multimedia devices over the Internet of Things (IoT) generates an unprecedented amount of data. Consequently, the world has stepped into the era of big data. Recently, on the rise of distributed computing technologies, video big data analytics in the cloud has attracted the attention of researchers and practitioners. The current technology and market trends demand an efficient framework for video big data analytics. However, the current work is too limited to provide a complete survey of recent research work on video big data analytics in the cloud, including the management and analysis of a large amount of video data, the challenges, opportunities, and promising research directions. To serve this purpose, we present this study, which conducts a broad overview of the state-of-the-art literature on video big data analytics in the cloud. It also aims to bridge the gap among large-scale video analytics challenges, big data solutions, and cloud computing. In this study, we clarify the basic nomenclatures that govern the video analytics domain and the characteristics of video big data while establishing its relationship with cloud computing. We propose a service-oriented layered reference architecture for intelligent video big data analytics in the cloud. Then, a comprehensive and keen review has been conducted to examine cutting-edge research trends in video big data analytics. Finally, we identify and articulate several open research issues and challenges, which have been raised by the deployment of big data technologies in the cloud for video big data analytics. To the best of our knowledge, this is the first study that presents the generalized view of the video big data analytics in the cloud. This paper provides the research studies and technologies advancing the video analyses in the era of big data and cloud computing.","2169-3536","","10.1109/ACCESS.2020.3017135","Institute for Information and Communications Technology Promotion Grant through the Korean Government (MSIT) (SIAT CCTV Cloud Platform)(grant numbers:R7120-17-1007); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9169636","Big data;intelligent video analytics;cloud-based video analytics system;video analytics survey;deep learning;distributed computing;intermediate results orchestration;cloud computing","Big Data;Cloud computing;Streaming media;Computer architecture;Surveillance;Market research;Cameras","","15","","404","CCBY","17 Aug 2020","","","IEEE","IEEE Journals"
"Dynamic Dispatching for Large-Scale Heterogeneous Fleet via Multi-agent Deep Reinforcement Learning","C. Zhang; P. Odonkor; S. Zheng; H. Khorasgani; S. Serita; C. Gupta; H. Wang","Industrial AI Lab Hitachi America Ltd., Santa Clara, CA; Stevens Institute of Technology, Hoboken, NJ; Industrial AI Lab Hitachi America Ltd., Santa Clara, CA; Industrial AI Lab Hitachi America Ltd., Santa Clara, CA; Industrial AI Lab Hitachi America Ltd., Santa Clara, CA; Industrial AI Lab Hitachi America Ltd., Santa Clara, CA; Industrial AI Lab Hitachi America Ltd., Santa Clara, CA","2020 IEEE International Conference on Big Data (Big Data)","19 Mar 2021","2020","","","1436","1441","Dynamic dispatching is one of the core problems for operation optimization in traditional industries such as mining, as it is about how to smartly allocate the right resources to the right place at the right time. Conventionally, the industry relies on heuristics or even human intuitions which are often short-sighted and sub-optimal solutions. Leveraging the power of AI and Internet of Things (IoT), data-driven automation is reshaping this area. However, facing its own challenges such as large-scale and heterogenous trucks running in a highly dynamic environment, it can barely adopt methods developed in other domains (e.g., ride-sharing). In this paper, we propose a novel Deep Reinforcement Learning approach to solve the dynamic dispatching problem in mining. We first develop an event-based mining simulator with parameters calibrated in real mines. Then we propose an experience-sharing Deep Q Network with a novel abstract state/action representation to learn memories from heterogeneous agents altogether and realizes learning in a centralized way. We demonstrate that the proposed methods significantly outperform the most widely adopted approaches in the industry by 5.56% in terms of productivity. The proposed approach has great potential in a broader range of industries (e.g., manufacturing, logistics) which have a large-scale of heterogenous equipment working in a highly dynamic environment, as a general framework for dynamic resource allocation.","","978-1-7281-6251-5","10.1109/BigData50022.2020.9378191","Hitachi; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9378191","Dispatching;Reinforcement Learning;Mining","Industries;Reinforcement learning;Big Data;Dynamic scheduling;Dispatching;Internet of Things;Optimization","","12","","22","IEEE","19 Mar 2021","","","IEEE","IEEE Conferences"
"Applying t-Distributed Stochastic Neighbor Embedding for Improving Fingerprinting-Based Localization System","G. B. Tarekegn; L. -C. Tai; H. -P. Lin; B. A. Tesfaw; R. -T. Juang; H. -C. Hsu; K. -L. Huang; K. Singh","Department of Electrical and Computer Engineering, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Department of Electrical and Computer Engineering, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Department of Electronic Engineering, National Taipei University of Technology, Taipei, Taiwan; Department of Electrical Engineering and Computer Science, National Taipei University of Technology, Taipei, Taiwan; Institute of Aerospace and System Engineering, National Taipei University of Technology, Taipei, Taiwan; Information and Communications Research Laboratories, Industrial Technology Research Institute, Hsinchu, Taiwan; Information and Communications Research Laboratories, Industrial Technology Research Institute, Hsinchu, Taiwan; Information and Communications Research Laboratories, Industrial Technology Research Institute, Hsinchu, Taiwan","IEEE Sensors Letters","16 Aug 2023","2023","7","9","1","4","Large-scale location estimation is crucial for many artificial intelligence Internet of Things (IoT) applications in the era of smart cities. This letter proposes a deep learning-based outdoor positioning scheme for large-scale wireless settings using fingerprinting techniques. We first developed a feature extraction technique using t-distributed stochastic neighbor embedding (t-SNE) to extract dominant and distinguishable features while eliminating noises from the radio fingerprints. Afterward, we developed a deep learning-based coarse-fine localization framework to improve positioning performance significantly. Based on our numerical analysis, the proposed scheme reduces computation time by 64.41%, and the average positioning error is 38 cm. Therefore, the proposed approach significantly improved positioning accuracy and reduced computation time.","2475-1472","","10.1109/LSENS.2023.3301838","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10209169","Feature extraction technique;fingerprinting method;location estimation;long short-term memory (LSTM);signal fingerprints;support vector machine (SVM)","Fingerprint recognition;Location awareness;Feature extraction;Internet of Things;Support vector machines;Databases;Wireless LAN","","1","","13","IEEE","4 Aug 2023","","","IEEE","IEEE Journals"
"STBCIoT: Securing the Transmission of Biometric Images in Customer IoT","D. Zhang; M. Shafiq; G. Srivastava; T. R. Gadekallu; L. Wang; Z. Gu","Cyberspace Institute of Advanced Technology, Guangzhou University, Guangzhou, China; Cyberspace Institute of Advanced Technology, Guangzhou University, Guangzhou, China; Dept. of Math and Computer Science, Brandon University, Canada; Zhongda Group, Haiyan County, Jiaxing City, China; Cyberspace Institute of Advanced Technology, Guangzhou University, Guangzhou, China; School of Computer Science and Technology, Harbin Institute of Technology (Shenzhen), Shenzhen, China","IEEE Internet of Things Journal","","2024","PP","99","1","1","The recent advancement of the Internet of Things (IoT) and information technology has led to the rapid expansion of interconnectivity among a billion devices across various applications. The advent of massive data has resulted in greater computational dependence, posing obstacles to applying security policies in energy-sensitive devices. However, public-key-based encryption algorithms are impractical or impossible to execute on these resource-limited terminals. In this paper, we propose a lightweight framework called STBCIoT based on a visual cryptography (VC) scheme to achieve low-latency encryption for large-scale data like biometric images. To reduce noise in encryption, we utilize central recognition and gray-level features of QR codes to integrate the visually friendly feature of QR into VC. we further propose a high-quality image generation model with the halftoning effect of VC to improve the quality of decrypted images. The experimental results demonstrate that our proposed method achieves high recognition performance on lossy decrypted images, effectively overcoming the performance limitations of traditional public key encryption methods for large-scale images.","2327-4662","","10.1109/JIOT.2024.3351988","National Natural Science Foundation of China(grant numbers:62250410365); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10388029","IoT;Sustainability;Privacy Protection;Secret Sharing","Biometrics (access control);Encryption;Internet of Things;Artificial intelligence;QR codes;Privacy;Performance evaluation","","","","","IEEE","10 Jan 2024","","","IEEE","IEEE Early Access Articles"
"Full Graph Autoencoder for One-Class Group Anomaly Detection of IIoT System","Y. Feng; J. Chen; Z. Liu; H. Lv; J. Wang","State Key Laboratory for Manufacturing and Systems Engineering, Xi’an Jiaotong University, Xi’an, China; State Key Laboratory for Manufacturing and Systems Engineering, Xi’an Jiaotong University, Xi’an, China; Mechanics & Environment Research Center of Rocket Engine, Science and Technology on Liquid Rocket Engine Laboratory, Xi’an, China; State Key Laboratory for Manufacturing and Systems Engineering, Xi’an Jiaotong University, Xi’an, China; Mechanics & Environment Research Center of Rocket Engine, Science and Technology on Liquid Rocket Engine Laboratory, Xi’an, China","IEEE Internet of Things Journal","21 Oct 2022","2022","9","21","21886","21898","With the increasing automation and integration of equipment, it is urgent to carry out anomaly detection (AD) for the large-scale system to ensure security, in virtue of Industrial Internet of Things (IIoT). Recently developed intelligent methods focus on component-level diagnosis or detection, resulting in difficulty in the health assessment of system with multisource data coupling. In addition, data-driven methods rarely emphasize the use of knowledge from the real physical system. In this article, we propose a full graph autoencoder to perform one-class group AD for the large-scale IIoT system. The proposed model takes as input data of normal status at training and only comprises several normalized graph convolutional layers, thus it is simple and fast. Different from Euclidean-based methods, the proposed model can handle various irregular structures together. For graph learning, multivariate time series are converted into graph data fused with prior knowledge. To achieve AD, we propose to reconstruct the full graph for the first time to obtain a reliable anomaly score. Besides, we extend a variational model to fully learn the graph representation. Moreover, a graph augmentation operation is employed to improve the accuracy and robustness. The proposed models are evaluated on two multisensor data sets from liquid rocket engine (LRE) systems, and the experimental results demonstrate the effectiveness and generalization of the IIoT system.","2327-4662","","10.1109/JIOT.2022.3181737","National Natural Science Foundation of China(grant numbers:51875436); Guangxi Science and Technology Major Project(grant numbers:Guike AA22068001); National Key Research and Development Program of China(grant numbers:2019YFF0302204); Scientific Research and Technology Development in Liuzhou(grant numbers:2021AAA0112); Open Fund of State Key Laboratory(grant numbers:sklms2022005); Guangxi Natural Science Foundation Program(grant numbers:2020GXNSFAA159081); Fundamental Research Funds for the Central Universities(grant numbers:XZY022020007,XZY022021006); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9792242","Graph autoencoder;group anomaly detection (GAD);Industrial Internet of Things (IIoT);multivariate time series (MTS)","Industrial Internet of Things;Anomaly detection;Rockets;Liquids;Engines;Data models;Time series analysis","","10","","62","IEEE","9 Jun 2022","","","IEEE","IEEE Journals"
"SecFact: Secure Large-scale QR and LU Factorizations","C. Luo; K. Zhang; S. Salinas; P. Li","Department of Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, OH, USA; Department of Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, OH, USA; Department of Electrical Engineering and Computer Science, Wichita State University, Wichita, KS, USA; Department of Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, OH, USA","IEEE Transactions on Big Data","10 Aug 2021","2021","7","4","796","807","We are now in the big data era. Due to the emerging various systems and applications, such as the Internet of Things, cyber-physical systems, smart cities, smart healthcare, we are able to collect more data than ever before. On the other hand, it makes it very difficult to analyze such massive data in order to advance our science and engineering fields. We note that QR and LU factorizations are two of the most fundamental mathematical tools for data analysis. However, conducting QR or LU factorization of an m×n matrix requires computational complexity of O(m2n). This incurs a formidable challenge in efficiently analyzing large-scale data sets by normal users or small companies on traditional resource-limited computers. To overcome this limitation, industry and academia propose to employ cloud computing that can offer abundant computing resources. This, however, obviously raises security concerns and hence a lot of users are reluctant to reveal their data to the cloud. To this end, we propose two secure outsourcing algorithms for efficiently performing large-scale QR and LU factorizations, respectively. We implement the proposed algorithms on the Amazon Elastic Compute Cloud (EC2) platform and a laptop. The experiment results show significant time saving for the user.","2332-7790","","10.1109/TBDATA.2017.2782809","National Science Foundation(grant numbers:CNS-1602172,CNS-1566479); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8194901","Big data;QR factorization;LU factorization;secure outsourcing","Outsourcing;Matrix decomposition;Sparse matrices;Big Data;Cloud computing;Algorithm design and analysis;Computational complexity","","16","","41","IEEE","13 Dec 2017","","","IEEE","IEEE Journals"
"Edge Intelligence for Smart Grid: A Survey on Application Potentials","H. B. Gooi; T. Wang; Y. Tang","Nanyang Technological University, Singapore, Singapore; Nanyang Technological University, Singapore, Singapore; China Electric Power Research Institute, Beijing, China","CSEE Journal of Power and Energy Systems","20 Oct 2023","2023","9","5","1623","1640","With the booming of artificial intelligence (AI), Internet of Things (IoT), and high-speed communication technology, integrating these technologies to innovate the smart grid (SG) further is future development direction of the power grid. Driven by this trend, billions of devices in the SG are connected to the Internet and generate a large amount of data at network edge. To reduce pressure of cloud computing and overcome defects of centralized learning, emergence of edge computing (EC) makes the computing task transfer from the network center to the network edge. When further exploring the relationship between EC and AI, edge intelligence (EI) has become one of the research hotspots. Advantages of EI in flexibly utilizing EC resources and improving AI model learning efficiency make its application in SG a good prospect. However, since only a few existing studies have applied EI to SG, this paper focuses on the application potential of EI in SG. First, the concepts, characteristics, frameworks, and key technologies of EI are investigated. Then, a comprehensive review of AI and EC applications in SG is presented. Furthermore, application potentials for EI in SG are explored, and four application scenarios of EI for SG are proposed. Finally, challenges and future directions for EI in SG are discussed. This application survey of EI on SG is carried out before EI enters the large-scale commercial stage to provide references and guidelines for developing future EI frameworks in the SG paradigm.","2096-0042","","10.17775/CSEEJPES.2022.02210","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10165655","Artificial intelligence;edge computing;edge intelligence;federated learning;smart grid","Computational modeling;Artificial intelligence;Training;Data models;Cloud computing;Resource management;Hardware","","2","","149","","27 Jun 2023","","","CSEE","CSEE Journals"
"Smart Systems as Futuristic Approach Towards Agriculture Development:A Review","K. Kalbande; W. Patil","G H Raisoni College of Engineering, G H Raisoni University, Amravati, Nagpur; Electronics Engineering G H Raisoni College of Engineering, Nagpur, India","2023 2nd International Conference for Innovation in Technology (INOCON)","19 Apr 2023","2023","","","1","6","The evolution of intelligent systems and large-scale use of internet finds the way to develop smart systems for agricultural industry. To design such smart system, there is need to identify lacunas in earlier developed system in agricultural domain. This paper aims to provide brief review on developed systems for different domain of agriculture like robotic, farm monitoring, water management and crop health management, pest detection system etc. On the basis of literature reviewed, it has been analyzed that there is large scope of improvement in agricultural system for real time applications as less attention was given towards intelligence, modularity and human-centric design aspect. Agricultural industry demands more intelligent, powerful and efficient autonomous systems (Smart System) to fulfill future needs. Hence, there is a need to utilize advance technologies like Internet of Things, Machine Learning and Artificial Intelligence towards the development of smart systems for agricultural industry. Therefore this paper aim to propose smart robotic system for greenhouse management.","","979-8-3503-2092-3","10.1109/INOCON57975.2023.10101109","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10101109","Internet of Things (IoT);Agricultural System;Machine Learning;Artificial Intelligence;Smart System;Robotic System","Wireless communication;Technological innovation;Plant diseases;Service robots;Crops;Spraying;Machine learning","","","","31","IEEE","19 Apr 2023","","","IEEE","IEEE Conferences"
"A Framework for Sustainable Federated Learning","B. Güler; A. Yener","University of California, Riverside, Riverside, California; The Ohio State University, Columbus, Ohio","2021 19th International Symposium on Modeling and Optimization in Mobile, Ad hoc, and Wireless Networks (WiOpt)","8 Nov 2021","2021","","","1","8","Potential environmental impact of machine learning in large-scale wireless networks is a major challenge for the sustainability of next-generation intelligent systems. Federated learning is a recent framework for communication-efficient training of machine learning models over the data collected, stored, and processed by millions of wireless devices. In this paper, we introduce a sustainable machine learning framework for federated learning, using rechargeable devices that can collect energy from the ambient environment. In particular, we propose a practical federated learning framework that utilizes intermittent energy arrivals for training, with provable convergence guarantees. Our framework can be applied to both cross-device and cross-silo federated learning settings, including federated learning in wireless edge networks and the Internet-of-Things. Our experiments demonstrate that the proposed framework can provide significant performance improvement over the benchmark energy-agnostic federated learning settings.","","978-3-903176-37-9","10.23919/WiOpt52861.2021.9589930","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9589930","","Training;Performance evaluation;Wireless networks;Machine learning;Benchmark testing;Collaborative work;Ad hoc networks","","3","","42","","8 Nov 2021","","","IEEE","IEEE Conferences"
"Device, Circuit, and System Design for Enabling Giga-Hertz Large-Area Electronics","Y. Ma; C. Wu; N. M. Fata; P. Kumar; S. Wagner; J. C. Sturm; N. Verma","Department of Electrical and Computer Engineering, Princeton University, Princeton, NJ, USA; Department of Electrical and Computer Engineering, Princeton University, Princeton, NJ, USA; Department of Electrical and Computer Engineering, Princeton University, Princeton, NJ, USA; Department of Electrical and Computer Engineering, Princeton University, Princeton, NJ, USA; Department of Electrical and Computer Engineering, Princeton University, Princeton, NJ, USA; Department of Electrical and Computer Engineering, Princeton University, Princeton, NJ, USA; Department of Electrical and Computer Engineering, Princeton University, Princeton, NJ, USA","IEEE Open Journal of the Solid-State Circuits Society","14 Dec 2022","2022","2","","177","192","Recent progress has substantially increased the operating frequency of large-area electronic (LAE) devices. Their integration into circuits has enabled unprecedented system-level capabilities, toward future wireless applications for the Internet of Things (IoT) and 5G/6G. These exploit large dimensions and flexible form factors. In this work, we focus on giga-Hertz (GHz) zinc-oxide (ZnO) thin-film transistors (TFTs) as a foundational device for enabling GHz LAE circuits and systems. To further understand their operation and limits in the newly possible frequency regime, we incorporate the effects of temperature and of non-quasi-static (NQS) physics into the device models. We then analyze operation including these effects on a fundamental circuit block, the cross-coupled inductor-capacitor (LC) oscillator. It is used in representative LAE systems, namely, a 13.56-MHz radio-frequency identification (RFID) reader array for near-field energy transfer, and a 1-GHz phased array for far-field radiation beam steering. The co-design of devices, circuits, and systems is essential for achieving flexible and meter-scale monolithic-integrated LAE wireless systems. For these, understanding temperature limitations and the NQS effect is crucial.","2644-1349","","10.1109/OJSSCS.2022.3217759","Center for Brain-Inspired Computing (C-BRIC), one of six centers in JUMP sponsored by DARPA(grant numbers:40001859-075); Princeton Program in Plasma Science and Technology (PPST); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9933352","5G/6G;Internet of Things (IoT);large-area electronics (LAEs);thin-film transistor (TFT);wireless communication","Zinc oxide;II-VI semiconductor materials;Substrates;Thin film transistors;Logic gates;Fabrication;Circuits and systems","","","","67","CCBYNCND","31 Oct 2022","","","IEEE","IEEE Journals"
"Cache Control of Edge Computing System for Tradeoff Between Delays and Cache Storage Costs","C. Hou; C. Zhou; Q. Huang; C. -B. Yan","College of Information and Electrical Engineering, China Agricultural University, Beijing, China; School of Computer Science and Engineering, School of Artificial Intelligence, Nanjing University of Science and Technology, Nanjing, China; School of Automation, Nanjing University of Science and Technology, Nanjing, China; State Key Laboratory for Manufacturing Systems Engineering, School of Automation Science and Engineering, Faculty of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China","IEEE Transactions on Automation Science and Engineering","4 Jan 2024","2024","21","1","827","843","This paper studies the edge computing system (ECS) in which caching the frequently reusable service (FRS) at the edge server (ES) is an effective way to reduce delays. The larger cache space available in the ES (we call it ES cache space) might buffer the larger scale of FRS, and subsequently decrease the delays while bringing higher cache storage costs. Meanwhile, the distribution of FRS is not always known in advance. Therefore, how much ES cache space should be supplied to make the optimal tradeoff between the delays and cache storage costs arises as an interesting issue in practice. To address this issue, this paper first formulates the problem of determining the amount of ES cache space supply as a constrained Markov decision process (CMDP), then adopts the Zipf’s distribution to estimate the probability distribution of FRS, and finally proposes an effective cache space control algorithm (CSCA) guiding the ES to determine the amount of ES cache space supply to minimize the cache storage costs while maintaining the delays at the acceptable level. Theoretical analysis, simulations and field experiments document and illustrate its performance. Note to Practitioners—This paper addresses the interesting trade-off between the delays and cache storage costs for the edge computing system that operates with limited cache storage budgets while must satisfy the required real-time performances. It helps to improve the operation efficiency of the systems with edge computing setting in the area of Internet of Things (IoT) or Cyber-Physical Systems (CPS) that employ the edge server to cache the frequently reusable services, arriving at the minimization of the accumulative cache storage costs while maintaining the accumulative delays at the acceptable level. Theoretical analysis, simulation and field experimental investigations jointly show that the solution proposed here outperforms existing solutions.","1558-3783","","10.1109/TASE.2022.3228250","Key Research and Development Program of Sichuan Province(grant numbers:2022YFSY0022); National Natural Science Foundation of China(grant numbers:61902186,62103191); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9983987","Edge computing system;constrained Markov decision process;cache space supply;delay;cache storage costs","Delays;Costs;Cache storage;Edge computing;Data models;Principal component analysis;Servers","","","","45","IEEE","13 Dec 2022","","","IEEE","IEEE Journals"
"FLIC: A Distributed Fog Cache for City-Scale Applications","J. West; N. Klingensmith; G. Thiruvathukal","Department of Computer Science, Loyola University Chicago, Chicago, Illinois, USA; Department of Computer Science, Loyola University Chicago, Chicago, Illinois, USA; Department of Computer Science, Loyola University Chicago, Chicago, Illinois, USA","2020 IEEE International Conference on Fog Computing (ICFC)","29 May 2020","2020","","","73","78","We present FLIC, a distributed software data caching framework for fogs that reduces network traffic and latency. FLIC is targeted toward city-scale deployments of cooperative IoT devices in which each node gathers and shares data with surrounding devices. As machine learning and other data processing techniques that require large volumes of training data are ported to low-cost and low-power IoT systems, we expect that data analysis will be moved away from the cloud. Separation from the cloud will reduce reliance on power-hungry centralized cloud-based infrastructure. However, city-scale deployments of cooperative IoT devices often connect to the Internet with cellular service, in which service charges are proportional to network usage. IoT system architects must be clever in order to keep costs down in these scenarios. To reduce the network bandwidth required to operate city-scale deployments of cooperative IoT systems, FLIC implements a distributed cache on the IoT nodes in the fog. FLIC allows the IoT network to share its data without repetitively interacting with a simple cloud storage service, reducing calls out to a backing store. Our results displayed a less than 2% miss rate on reads. Thus, allowing for only 5% of requests needing the backing store. We were also able to achieve more than 50% reduction in bytes transmitted per second.","","978-1-7281-1086-8","10.1109/ICFC49376.2020.00019","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9103479","","Coherence;Distributed databases;Cloud computing;Software;Bandwidth;Computer architecture;Containers","","1","","14","IEEE","29 May 2020","","","IEEE","IEEE Conferences"
"A Low-Cost Low-Power LoRa Mesh Network for Large-Scale Environmental Sensing","D. Wu; J. Liebeherr","Department of Electrical and Computer Engineering, University of Toronto, Toronto, Canada; Department of Electrical and Computer Engineering, University of Toronto, Toronto, Canada","IEEE Internet of Things Journal","22 Sep 2023","2023","10","19","16700","16714","Sustainability and climate monitoring efforts create a need for long-term in-situ sensing of large geographic areas. However, environmental monitoring in remote areas of developing countries remains impeded by a lack of low-cost, scalable Internet of Things (IoT) solutions. Whereas IoT systems for in-situ sensing abound, they mostly are either low-cost or suitable for large areas, but not both. In this article, we present a low-cost low-power network solution for in-situ sensing of areas up to hundreds of square kilometers. Taking advantage of LoRa technology, we develop a self-organizing mesh network that can be scaled to a hundred and more nodes. Scalability is achieved by developing methods that mitigate packet collisions during data collection. We present a protocol, called CottonCandy, with which nodes self-organize in a spanning-tree network topology in a distributed fashion. A power profile on a custom-built circuit board shows that CottonCandy nodes can run thousands of duty cycles on 2 AA batteries, sufficient to operate for years in many applications. Using off-the-shelf components, the cost of a CottonCandy node is less than U.S.  $\$ $ 15. Evaluations by simulation show that CottonCandy networks with 100 nodes achieve a packet delivery ratio (PDR) of >90%. Measurements of an outdoor deployment with 15 nodes corroborate the high PDR in a real-life setting.","2327-4662","","10.1109/JIOT.2023.3270237","University of Toronto Centre for Global Engineering (CGEN); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10108395","LoRa media access control (MAC) layer;LoRa mesh network;low-power wide-area network (LPWAN);network protocols","Logic gates;Protocols;Media Access Protocol;Wireless sensor networks;Low-power wide area networks;Costs;Sensors","","2","","57","IEEE","25 Apr 2023","","","IEEE","IEEE Journals"
"Secure and Anonymous Authentication Scheme for Mobile Edge Computing Environments","H. Lee; J. Ryu; D. Won","Department of Computer Engineering, Kyungnam University, Changwon, Republic of Korea; School of Computer and Information Engineering, Kwangwoon University, Seoul, Republic of Korea; Department of Computer Science and Engineering, Sungkyunkwan University, Suwon, Republic of Korea","IEEE Internet of Things Journal","5 Feb 2024","2024","11","4","5798","5815","The Internet of Things (IoT) is progressively being integrated into everyday life, with cloud computing systems being widely employed to monitor and manage IoT devices. Cloud servers offer centralized high-performance processing of large-scale data utilizing millions of connected sensors and geographically distributed devices. Distributed data processing with low latency is important for autonomous driving, healthcare, virtual reality, and augmented reality in cloud services based on 5G technology. mobile edge computing (MEC) infrastructure enables cloud services at the edge of the network in a 5G ecosystem, allowing for real-time processing of large amounts of data. MEC involves an open infrastructure that allows for access by heterogeneous devices, increasing the complexity of security challenge. This, in turn, brings the potential risk of attacks that could result in information leakage and compromise the privacy of users. In extreme cases, attacks may even pose a risk to human life. Thus, an effective authentication mechanism is required to prevent attacks and protect privacy in MEC environments. To address this issue, we propose a secure and anonymous authentication scheme that enhances security in MEC environments. In the proposed scheme, the user and MEC server establish a secure session key without the need of a trusted third party. The proposed scheme is designed to be secure from various known attacks attempted by internal and external adversaries. We have conducted both formal and informal analyses to prove the security of the proposed scheme and compared its performance with related schemes to validate its effectiveness and practical application.","2327-4662","","10.1109/JIOT.2023.3308568","“Regional Innovation Strategy (RIS)” through the National Research Foundation of Korea (NRF); Ministry of Education (MOE)(grant numbers:2021RIS-003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10230274","Authentication;Internet of Things (IoT);key agreement;mobile edge computing (MEC)","Authentication;Security;Servers;Cloud computing;Internet of Things;Cryptography;Protocols","","","","50","IEEE","25 Aug 2023","","","IEEE","IEEE Journals"
"Permission Token Segmentation Scheme Based on Blockchain Access Control","J. Shi; R. Li","College of Computer Science, Inner Mongolia University, Hohhot, China; College of Computer Science, Inner Mongolia University, Hohhot, China","2020 IEEE 19th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)","9 Feb 2021","2020","","","1956","1964","The Internet of Things (IoT) is a large-scale complex network composed of a large number of heterogeneous devices, and due to the complexity of permission management in some scenarios of IoT, such as smart cities and smart healthcare, access control systems need to support strong flexibility. Permission delegation is an effective means to improve flexibility, but the delegated permission token in the current permission delegation scheme is a whole, and the recipient cannot re-delegate part of the permission in the received token. In this paper, a blockchain-based permission token segmentation scheme is proposed, which splits out part of the permissions in a permission token owned by the subject to generate a new token, so that the subject can control the fine-grained permissions in the token, enabling the subject to manage the permissions more flexibly. The permission combination scheme is then provided, and the permission invalidation problem in the token segmentation scheme is analyzed and discussed, and a token invalidation scheme is given. The security analysis shows that the scheme can reliably guarantee the security of authorized access.","2324-9013","978-1-6654-0392-4","10.1109/TrustCom50675.2020.00267","National Natural Science Foundation of China(grant numbers:61862046); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9343075","access control;blockchain;permission delegation;token segmentation;Internet of Things","Access control;Privacy;Smart cities;Blockchain;Medical services;Internet of Things;Reliability","","","","15","IEEE","9 Feb 2021","","","IEEE","IEEE Conferences"
"No Radio Left Behind: Radio Fingerprinting Through Deep Learning of Physical-Layer Hardware Impairments","K. Sankhe; M. Belgiovine; F. Zhou; L. Angioloni; F. Restuccia; S. D’Oro; T. Melodia; S. Ioannidis; K. Chowdhury","Department of Electrical and Computer Engineering, Northeastern University, Boston, USA; Department of Electrical and Computer Engineering, Northeastern University, Boston, USA; Department of Electrical and Computer Engineering, Northeastern University, Boston, USA; Department of Electrical and Computer Engineering, Northeastern University, Boston, USA; Department of Electrical and Computer Engineering, Northeastern University, Boston, USA; Department of Electrical and Computer Engineering, Northeastern University, Boston, USA; Department of Electrical and Computer Engineering, Northeastern University, Boston, USA; Department of Electrical and Computer Engineering, Northeastern University, Boston, USA; Department of Electrical and Computer Engineering, Northeastern University, Boston, USA","IEEE Transactions on Cognitive Communications and Networking","6 Mar 2020","2020","6","1","165","178","Due to the unprecedented scale of the Internet of Things, designing scalable, accurate, energy-efficient and tamper-proof authentication mechanisms has now become more important than ever. To this end, in this paper we present ORACLE, a novel system based on convolutional neural networks (CNNs) to “fingerprint” (i.e., identify) a unique radio from a large pool of devices by deep-learning the fine-grained hardware impairments imposed by radio circuitry on physical-layer I/Q samples. First, we show how hardware-specific imperfections are learned by the CNN framework. Then, we extensively evaluate the performance of ORACLE on several first-of-its-kind large-scale datasets of WiFi-transmissions collected “in the wild”, as well as a dataset of nominally-identical (i.e., equal baseband signals) WiFi devices, reaching 80-90% accuracy is many cases with the error gap arising due to channel-induced effects. Finally, we show through an experimental testbed, how this accuracy can reach over 99% by intentionally inserting and learning the effect of controlled impairments at the transmitter side, to completely remove the impact of the wireless channel. Furthermore, to scale this approach for classifying potential thousands of radios, we propose an impairment hopping spread spectrum (IHOP) technique that is resilient to spoofing attacks.","2332-7731","","10.1109/TCCN.2019.2949308","Defense Advanced Research Projects Agency(grant numbers:N00164-18-R-WQ80); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8882379","Wireless communication;OFDM;neural networks;learning (artificial intelligence)","Radio transmitters;Radio frequency;Hardware;Wireless communication;Feature extraction;Deep learning;Wireless fidelity","","105","","30","IEEE","24 Oct 2019","","","IEEE","IEEE Journals"
"Cyclic CNN: Image Classification With Multiscale and Multilocation Contexts","X. Chen; L. Xie; J. Wu; Q. Tian","College of Electronics and Information Engineering, Tongji University, Shanghai, China; Huawei Inc., Shenzhen, China; School of Computer Science, Fudan University, Shanghai, China; Huawei Inc., Shenzhen, China","IEEE Internet of Things Journal","23 Apr 2021","2021","8","9","7466","7475","Improving the capability of models at limited computational cost is an urgent demand in many vision-based Internet-of-Things applications. Recent progress on deep convolutional neural network (CNN) has largely accelerated the development of image classification. Although the hierarchical structure of CNN naturally helps to extract image features in different scales and locations progressively, conventional convolution can only handle contexts of one scale and on a limited area of a single location in a specific layer, limiting the utilization of multiscale and multilocation information. In this work, we present a cyclic CNN framework, which enables sufficient utilization of multiscale and multilocation contexts in a single layer of convolution. The cyclic CNN is an extremely simple but effective improvement upon conventional convolution, which occupies no additional parameter and negligible computation (even less than 0.1%). Moreover, cyclic CNN can be easily plugged into many existing CNN pipelines, e.g., the ResNet family, obtaining extremely low-cost performance gain upon them. Extensive experiments on both small-scale (CIFAR10 and CIFAR100) and large-scale (ILSVRC2012) image classification benchmarks demonstrate that a consistent performance promotion is obtained with the help of cyclic CNN.","2327-4662","","10.1109/JIOT.2020.3038644","Guangdong Province Key Research and Development Program Major Science and Technology Projects(grant numbers:2018B010115002); National Natural Science Foundation of China(grant numbers:61831018,61631017); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9261577","Cyclic convolutional neural network (CNN);image classification;multilocation contexts;multiscale contexts","Convolution;Feature extraction;Task analysis;Internet of Things;Image resolution;Deep learning;Pipelines","","8","","51","IEEE","17 Nov 2020","","","IEEE","IEEE Journals"
"Performance Improvement of MEMS Electromagnetic Vibration Energy Harvester Using Optimized Patterns of Micromagnet Arrays","K. Paul; D. Mallick; S. Roy","Micro-Nano-Systems-Centre, Tyndall National Institute, Cork, Ireland; Department of Electrical Engineering, Indian Institute of Technology Delhi, New Delhi, India; Micro-Nano-Systems-Centre, Tyndall National Institute, Cork, Ireland","IEEE Magnetics Letters","6 Aug 2021","2021","12","","1","5","Scavenging mechanical energy from ubiquitous vibrations through miniaturized electromagnetic (EM) transducers is a potential solution to the problem of powering wireless sensor networks for the Internet of Things (IoT). This letter presents the design and performance analysis of fully integrated EM vibration energy harvesters on the scale of microelectromechanical systems (MEMS). Through analytical formulation and finite element analysis, we present a systematic design study to optimize the magnet-coil interaction in a precise location within a small surface area (“footprint”). The compact device topology yielded an EM coupling as high as 62.9 mWb/m with optimized stripe-shaped micromagnets and rectangular microcoils. The nonlinear spring topology demonstrated six times improvement in the half-power bandwidth compared to its linear counterpart, at a cost of reduced power density. The designs can be implemented using standard MEMS fabrication methods leveraging CMOS-compatible integration at the system level for potential applications in the IoT.","1949-3088","","10.1109/LMAG.2021.3088403","EU Horizon 2020 research and innovation programme project Enables(grant numbers:730957); CONNECT- a research center on IoT funded by the Science Foundation Ireland SFI(grant numbers:13/RC/ 2077); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9451592","Electromagnetics;demagnetizing field;patterned magnet;electromagnetic coupling;electromagnetic vibration energy harvester;in-plane vibration","Magnetic flux density;Magnetic resonance;Magnetic films;Saturation magnetization;Magnetic separation;Micromechanical devices;Vibrations","","8","","26","IEEE","10 Jun 2021","","","IEEE","IEEE Journals"
"SATSS: A Self-Adaptive Task Scheduling Scheme for Mobile Edge Computing","J. Yang; C. Poellabauer","Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, Indiana, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, Indiana, USA","2021 International Conference on Computer Communications and Networks (ICCCN)","31 Aug 2021","2021","","","1","9","Mobile edge computing (MEC) is an emerging paradigm that supports low-latency applications in resource-constrained scenarios, such as the Internet of Things (IoT) and vehicular networks. MEC makes it feasible to process and handle massive amounts of data and service requests generated by mobile end users or IoT devices and to deliver timely responses or interventions. However, the computers forming an MEC system typically have limited computing resources, which must be shared by multiple tasks and many simultaneous service requests. How to dispatch and schedule computational tasks from end users in an MEC system is a challenging problem, especially for latency-sensitive applications. In this paper, we propose a self-adaptive task dispatching and scheduling scheme to deliver low-latency service responses in a resource-efficient way. The proposed approach prioritizes computational tasks based on their attributes (e.g., CPU and RAM requirements, priority level, and expiration time) and solves the scheduling problem using a reinforcement learning approach. The feasibility and effectiveness of the proposed scheme are verified using simulation and a small-scale case study on an MEC testbed, demonstrating that the proposed scheme is effective and efficient.","2637-9430","978-1-6654-1278-0","10.1109/ICCCN52240.2021.9522242","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9522242","Mobile edge computing (MEC);IoT;Task scheduling;Reinforcement learning","Computers;Schedules;Processor scheduling;Smart cities;Random access memory;Reinforcement learning;Internet of Things","","3","","24","IEEE","31 Aug 2021","","","IEEE","IEEE Conferences"
"Improved Advance Encryption Standard with a Privacy Database Structure for IoT Nodes","J. H. Anajemba; C. Iwendi; M. Mittal; T. Yue","College of Internet of Things, Hohai University, Changzhou, China; Department of Electronics, BCC of CSUFT, Changsha, Chin; Faculty of Info. Sci. and Engineering, Kyoto Sangyo University, Japan; College of Internet of Things, Hohai University, Changzhou, China","2020 IEEE 9th International Conference on Communication Systems and Network Technologies (CSNT)","12 Jun 2020","2020","","","201","206","The Internet of Things (IoT) contains huge number of devices and objects that have very low or nonexistent processing and communication resources, connected to a small number of high-powered devices as envisaged in the coming 5G Networks. In the foreseeable future, the backend systems will not be able to provide security and privacy via cryptographic primitives due to the sheer number of IoT devices. This research presents cloud approximate nearest neighbors (CANN) mechanism of a Mesh network based on an improved advanced encryption standard (I-AES) with a privacy database structure (PDS). In addition, it provides a theoretical basis considering the huge number of 5G devices and physical unclonable functions (PUF) applicable in IoT for the coming 5G Network. Comparing our proposed I-AES algorithm against the advanced encryption standard (AES) and the Data Encryption Standard (DES), it is observed that our algorithm outperforms the previously existing algorithms in terms of encryption execution time and throughput. Finally, it was discovered that the time of encryption was slower using privacy-preserving database structures and improved AES algorithms with good scaling behavior.","2329-7182","978-1-7281-4976-9","10.1109/CSNT48778.2020.9115741","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9115741","IoT;physical unclonable function;privacy database structure;encryption time;advanced encryption standard","","","19","","26","IEEE","12 Jun 2020","","","IEEE","IEEE Conferences"
"Reinforced Spatiotemporal Attentive Graph Neural Networks for Traffic Forecasting","F. Zhou; Q. Yang; K. Zhang; G. Trajcevski; T. Zhong; A. Khokhar","School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Decision Operations and Information Technologies, University of Maryland at College Park, College Park, USA; Department of Electrical and Computer Engineering, Iowa State University, Ames, USA; School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Electrical and Computer Engineering, Iowa State University, Ames, USA","IEEE Internet of Things Journal","10 Jul 2020","2020","7","7","6414","6428","The advances in the Internet of Things (IoT) and increased availability of the road sensors allow for fine-grained traffic forecasting, which is of particular importance toward building an intelligent transportation system. In the literature, recent efforts have applied various deep learning methods for traffic forecasting, e.g., leveraging graph convolutional networks (GCNs) for spatial dependency modeling, and utilizing recurrent neural networks (RNNs) for capturing temporal dynamics. However, most of the existing approaches assume that spatial correlations are static and temporal correlations have only sequential dependencies and do not consider temporal periodicity of traffic across multiple time steps. The real challenge lies in using the dynamic spatiotemporal correlations while also considering the influence of the nontraffic-related factors, such as time-of-day and weekday-or-weekend in the learning architectures. We propose a novel framework titled “reinforced spatial-temporal attention graph (RSTAG) neural networks” for traffic prediction. Our method captures dynamic spatial correlations through diffusion network graphs, while temporal dependencies are represented through the sequence-to-sequence model with an attention mechanism. In addition, we utilize the policy gradient to update the model parameters while largely alleviating the exposure bias issue that exists in previous traffic prediction models. We conduct extensive experiments on two large-scale traffic data sets collected from the road sensor networks in Los Angles and Bay Area of California. The results demonstrate that our method significantly outperforms the state-of-the-art baselines.","2327-4662","","10.1109/JIOT.2020.2974494","National Natural Science Foundation of China(grant numbers:61602097,61472064); NSF(grant numbers:III 1213038,CNS 1646107); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9003261","Diffusion network convolution;policy gradient;reinforcement learning;spatial???temporal attention;traffic forecasting","Sensors;Roads;Forecasting;Predictive models;Correlation;Neural networks;Data models","","38","","67","IEEE","19 Feb 2020","","","IEEE","IEEE Journals"
"Comparative Assessment of Process Mining for Supporting IoT Predictive Security","A. Hemmer; M. Abderrahim; R. Badonnel; J. François; I. Chrisment","Inria Nancy Grand Est–Loria, University of Lorraine (Campus Scientifique), Villers-les-Nancy, France; Inria Nancy Grand Est–Loria, University of Lorraine (Campus Scientifique), Villers-les-Nancy, France; Inria Nancy Grand Est–Loria, University of Lorraine (Campus Scientifique), Villers-les-Nancy, France; Inria Nancy Grand Est–Loria, University of Lorraine (Campus Scientifique), Villers-les-Nancy, France; Inria Nancy Grand Est–Loria, University of Lorraine (Campus Scientifique), Villers-les-Nancy, France","IEEE Transactions on Network and Service Management","10 Mar 2021","2021","18","1","1092","1103","The growth of the Internet-of-Things (IoT) has been characterized by the large-scale deployment of sensors and connected objects. These ones are integrated with other Internet resources in order to elaborate more complex systems and applications. Security management is a major challenge for these systems due to their complexity, their heterogeneity and the limited resources of their devices. In this article we evaluate the exploitability and performance of a process mining approach for detecting misbehaviors in such systems. We describe the considered architecture and detail its operation, from the generation of behavioral models to the detection of potential attacks. We formalize several alternative commonly-used detection methods, including elliptic envelope, support-vector machine, local outlier factor, and isolation forest techniques. After presenting a proof-of-concept prototype, we quantify comparatively the benefits and limits of our process mining solution combined with data pre-processing, through extensive experiments based on different industrial datasets.","1932-4537","","10.1109/TNSM.2020.3038172","SecureIoT project, funded by the European Union’s Horizon 2020 research and innovation programme(grant numbers:779899); exploited datasets have been provided by IDIADA U.K., it’s OWL, which has worked with FUJITSU, and LuxAI; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9260227","Security management;Internet-of-Things;process mining;data mining;machine learning","Security;Data mining;Hidden Markov models;Data models;Decision trees;Buildings;Random forests","","7","","43","IEEE","16 Nov 2020","","","IEEE","IEEE Journals"
"NSEDS: One Implementation of Lambda Architecture in Large-scale Seismic Exploration Scenes","Z. Ding; S. Wu; W. Sun; Q. Luo; J. Wang; Y. Yang","The Third Research Institute of Ministry of Public Security, Shanghai, China; The Third Research Institute of Ministry of Public Security, Shanghai, China; The Third Research Institute of Ministry of Public Security, Shanghai, China; The Third Research Institute of Ministry of Public Security, Shanghai, China; The Third Research Institute of Ministry of Public Security, Shanghai, China; The Third Research Institute of Ministry of Public Security, Shanghai, China","2022 7th International Conference on Big Data Analytics (ICBDA)","21 Apr 2022","2022","","","58","61","The lambda architecture is a well-proven and successful system architecture approach in the field of big data, with the qualities of being resilient and fault-tolerant, scalable, and extensible, and many big data systems are built using this solution. Simultaneously, due to the seismic exploration industry being very specialized, the construction concept for its data collecting and processing system remained in the ""stand-alone"" system developing era. However, with the advancement of low-power integrated sensor technology such as MEMS, the sensor network of seismic exploration equipment is getting larger, the data collected (velocity, acceleration, electric field, magnetic field, and gravitational field) is getting much more accurate, and the system transmission and processing bandwidth required by the system is getting higher. The ""stand-alone"" system developing mode is obviously incapable of keeping up with the industry's development. As a result, we developed an experimental system for data acquisition and processing in large-scale seismic exploration based on the lambda system architecture, which is named NSEDS (Next Seismic Exploration Data System). The evaluation results demonstrate that NSEDS can achieve the design goals. This paper will have some reference values for seismic exploration and other IoT systems that have the same characteristics.","","978-1-6654-7938-7","10.1109/ICBDA55095.2022.9760322","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9760322","seismic exploration;lambda architecture;big data","Industries;Micromechanical devices;Fault tolerance;Fault tolerant systems;Data acquisition;Systems architecture;Bandwidth","","","","9","IEEE","21 Apr 2022","","","IEEE","IEEE Conferences"
"Artificial Intelligence (AI)-Centric Management of Resources in Modern Distributed Computing Systems","S. Ilager; R. Muralidhar; R. Buyya","Cloud Computing and Distributed Systems (CLOUDS) Laboratory, School of Computing and Information Systems, The University of Melbourne, Australia; Amazon Web Services (AWS), Australia; Cloud Computing and Distributed Systems (CLOUDS) Laboratory, School of Computing and Information Systems, The University of Melbourne, Australia","2020 IEEE Cloud Summit","15 Dec 2020","2020","","","1","10","Contemporary Distributed Computing Systems (DCS) such as Cloud Data Centers are large scale, complex, heterogeneous, and distributed across multiple networks and geographical boundaries. On the other hand, the Internet of Things (IoT)-driven applications are producing a huge amount of data that requires real-time processing and fast response. Managing these resources efficiently to provide reliable services to end-users or applications is a challenging task. The existing Resource Management Systems (RMS) rely on either static or heuristic solutions inadequate for such composite and dynamic systems. The advent of Artificial Intelligence (AI) due to data availability and processing capabilities manifested into possibilities of exploring data-driven solutions in RMS tasks that are adaptive, accurate, and efficient. In this regard, this paper aims to draw the motivations and necessities for data-driven solutions in resource management. It identifies the challenges associated with it and outlines the potential future research directions detailing where and how to apply the data-driven techniques in the different RMS tasks. Finally, it provides a conceptual data-driven RMS model for DCS and presents the two real-time use cases (GPU frequency scaling and data centre resource management from Google Cloud and Microsoft Azure) demonstrating AI-centric approaches' feasibility.","","978-1-7281-8266-7","10.1109/IEEECloudSummit48914.2020.00007","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9283696","Distributed Computing;Resource Management;AI Techniques;Edge Computing;Cloud Computing","Data centers;Cloud computing;Computational modeling;Real-time systems;Resource management;Artificial intelligence;Task analysis","","8","","39","IEEE","15 Dec 2020","","","IEEE","IEEE Conferences"
"Lightweight and Scalable DAG based distributed ledger for verifying IoT data integrity","S. R. Cherupally; S. Boga; P. Podili; K. Kataoka","Indian Institute of Technology, Hyderabad; Indian Institute of Technology, Hyderabad; Indian Institute of Technology, Hyderabad; Indian Institute of Technology, Hyderabad","2021 International Conference on Information Networking (ICOIN)","2 Feb 2021","2021","","","267","272","Verifying the integrity of IoT data in cloud-based IoT architectures is crucial for building reliable IoT applications. Traditional data integrity verification methods rely on a Trusted Third Party (TTP) that has issues of risk and operational cost by centralization. Distributed Ledger Technology (DLT) has a high potential to verify IoT data integrity and overcome the problems with TTPs. However, the existing DLTs have low transaction throughput, high computational and storage overhead, and are unsuitable for IoT environments, where a massive scale of data is generated. Recently, Directed Acyclic Graph (DAG) based DLTs have been proposed to address the low transaction throughput of linear DLTs. However, the integration of IoT Gateways (GWs) into the peer to peer (P2P) DLT network is challenging because of their low storage and computational capacity. This paper proposes Lightweight and Scalable DAG based distributed ledger for IoT (LSDI) that can work with resource-constrained IoT GWs to provide fast and scalable IoT data integrity verification. LSDI uses two key techniques: Pruning and Clustering, to reduce 1) storage overhead in IoT GWs by removing sufficiently old transactions, and 2) computational overhead of IoT GWs by partitioning a large P2P network into smaller P2P networks. The evaluation results of the proof of concept implementation showed that the proposed LSDI system achieves high transaction throughput and scalability while efficiently managing storage and computation overhead of the IoT GWs.","1976-7684","978-1-7281-9101-0","10.1109/ICOIN50884.2021.9334000","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9334000","Blockchain;DAG;IoT;Data Integrity","Distributed ledger;Data integrity;Scalability;Throughput;Peer-to-peer computing;Internet of Things;Reliability","","9","","17","IEEE","2 Feb 2021","","","IEEE","IEEE Conferences"
"Real-Time Event-Driven Learning in Highly Volatile Systems: A Case for Embedded Machine Learning for SCADA Systems","M. Gonçalves; P. Sousa; J. Mendes; M. Danishvar; A. Mousavi","Department of Electrical and Computer Engineering, Institute of Systems and Robotics, University of Coimbra, Pólo II, Coimbra, Portugal; Oncontrol Technologies, Coimbra, Portugal; Department of Electrical and Computer Engineering, Institute of Systems and Robotics, University of Coimbra, Pólo II, Coimbra, Portugal; Department of Mechanical and Aerospace Engineering, College of Engineering, Design and Physical Sciences, Brunel University London, London, Uxbridge, U.K.; Department of Mechanical and Aerospace Engineering, College of Engineering, Design and Physical Sciences, Brunel University London, London, Uxbridge, U.K.","IEEE Access","17 May 2022","2022","10","","50794","50806","Extracting key system parameters and their impact on state transition is a necessity for knowledge and data engineering. In Decision Support Systems, the quest for yet more efficient and faster methods of sensitivity analysis (SA) and feature extraction in complex and volatile systems persists. A new improved event tracking methodology, the fastTracker, for real-time SA in large scale complex systems is proposed in this paper. The main feature of fastTracker is its high-frequency analytics using meager computational cost. It is suitable for data processing and prioritization in embedded systems, Internet of Things (IoT), distributed computing (e.g. Edge computing) applications. The presented algorithm’s underpinning rationale is event driven; its objective is to correctly and succinctly quantify the sensitivity of observable changes in the system (output) with respect to the input variables. To demonstrate the performance of the proposed fastTracker methodology, fastTracker was deployed in the Supervisory control and data acquisition (SCADA) system from real cement industry. fastTracker has been verified by system experts in real industrial application. Its performance was compared with other real-time event-based SA techniques. The comparison revealed savings of 98.8% in processing time per sensitivity index and 20% in memory usage when compared with EventTracker, its closest rival. The proposed methodology is more accurate and 80.9% faster than an entropy-based method. Its application is recommended for reinforced learning and/or formulating system key performance indicators from raw data.","2169-3536","","10.1109/ACCESS.2022.3173376","project “Eco-Healing-Intelligent Eco-Controller with Self-Healing Capability” through OE-national funds of FCT/MCTES (PIDDAC)(grant numbers:UIDB/00048/2020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9770808","Event Tracking;sensitivity analysis (SA);discrete event systems;input variable selection;real-time systems;distributed computing","Real-time systems;Sensitivity analysis;Indexes;Input variables;SCADA systems;Internet of Things;Analytical models","","6","","39","CCBY","9 May 2022","","","IEEE","IEEE Journals"
"Computer Vision Based Approach for Overspeeding Problem in Smart Traffic System","G. P. Singh; A. Gupta; B. Gupta; S. Ghosh","Department of ECE, National Institute of Technology Patna, Patna, India; Department of ECE, National Institute of Technology Patna, Patna, India; Department of ECE, National Institute of Technology Patna, Patna, India; Department of CSE, Institute of Engineering and Management, Kolkata, India","2021 IEEE Transportation Electrification Conference (ITEC-India)","9 Nov 2022","2021","","","1","6","With the growth in the urban population, count of vehicles on the road is also increasing drastically, traffic control in cities has become one of the most pressing challenges for the transportation system. A variety of different systems have been implemented across the country and around the world to resolve this issue. But most of them have proved inefficient to be implemented on a large scale that too in a developing country like India. Traffic management and related creative technologies are needed in the era of Machine Learning, Internet of Things (IoT), Image and Video processing, and Computer Vision in order to create more viable future cities. This paper presents a computer vision based approach for overspeed vehicle detection in Smart Traffic System (STS). Proposed overspeed vehicle detection system is based on centroid tracking and mark gap distance concept followed by OpenCV and Tesseract based method for license plate recognition. Primary purpose of the proposed system is to decrease cases of overspeeding and high death rates because of accidents. The accuracy of the proposed system is approximately 80% in detection of the overspeed vehicles.","","978-1-6654-2146-1","10.1109/ITEC-India53713.2021.9932508","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9932508","Computer Vision;Smart Traffic System (STS) Overspeeding;OpenCV;Tesseract","Computer vision;Roads;Sociology;Transportation;Traffic control;Reliability;Internet of Things","","","","16","IEEE","9 Nov 2022","","","IEEE","IEEE Conferences"
"FactDAG: Formalizing Data Interoperability in an Internet of Production","L. Gleim; J. Pennekamp; M. Liebenberg; M. Buchsbaum; P. Niemietz; S. Knape; A. Epple; S. Storms; D. Trauth; T. Bergs; C. Brecher; S. Decker; G. Lakemeyer; K. Wehrle","Chair of Databases and Information Systems, RWTH Aachen University, Aachen, Germany; Chair of Communication and Distributed Systems, RWTH Aachen University, Aachen, Germany; Knowledge-Based Systems Group, RWTH Aachen University, Aachen, Germany; Laboratory of Machine Tools and Production Engineering, RWTH Aachen University, Aachen, Germany; Laboratory of Machine Tools and Production Engineering, RWTH Aachen University, Aachen, Germany; Laboratory of Machine Tools and Production Engineering, RWTH Aachen University, Aachen, Germany; Laboratory of Machine Tools and Production Engineering, RWTH Aachen University, Aachen, Germany; Laboratory of Machine Tools and Production Engineering, RWTH Aachen University, Aachen, Germany; Laboratory of Machine Tools and Production Engineering, RWTH Aachen University, Aachen, Germany; Laboratory of Machine Tools and Production Engineering and Fraunhofer IPT, RWTH Aachen University, Aachen, Germany; Laboratory of Machine Tools and Production Engineering, RWTH Aachen University, Aachen, Germany; Chair of Databases and Information Systems and Fraunhofer FIT, RWTH Aachen University, Aachen, Germany; Knowledge-Based Systems Group, RWTH Aachen University, Aachen, Germany; Chair of Communication and Distributed Systems, RWTH Aachen University, Aachen, Germany","IEEE Internet of Things Journal","14 Apr 2020","2020","7","4","3243","3253","In the production industry, the volume, variety, and velocity of data as well as the number of deployed protocols increase exponentially due to the influences of the Internet-of-Things (IoT) advances. While hundreds of isolated solutions exist to utilize these data, e.g., optimizing processes or monitoring machine conditions, the lack of a unified data handling and exchange mechanism hinders the implementation of approaches to improve the quality of decisions and processes in such an interconnected environment. The vision of an Internet of Production promises the establishment of a Worldwide Lab, where data from every process in the network can be utilized, even interorganizational and across domains. While numerous existing approaches consider interoperability from an interface and communication system perspective, fundamental questions of data and information interoperability remain insufficiently addressed. In this article, we identify ten key issues, derived from three distinctive real-world use cases that hinder large-scale data interoperability for industrial processes. Based on these issues, we derive a set of five key requirements for future (IoT) data layers, building upon the FAIR data principles. We propose to address them by creating FactDAG, a conceptual data layer model for maintaining a provenance-based, directed acyclic graph of facts, inspired by successful distributed version-control and collaboration systems. Eventually, such a standardization should greatly shape the future of interoperability in an interconnected production industry.","2327-4662","","10.1109/JIOT.2020.2966402","Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) through Germany’s Excellence Strategy—EXC-2023 Internet of Production(grant numbers:390621612); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8957690","Data management;data versioning;Industrial Internet of Things (IoT);interoperability;Worldwide Lab (WWL)","Interoperability;Data models;Collaboration;Process control;Internet of Things;Machine tools","","38","","61","IEEE","13 Jan 2020","","","IEEE","IEEE Journals"
"Zero Knowledge Clustering Based Adversarial Mitigation in Heterogeneous Federated Learning","Z. Chen; P. Tian; W. Liao; W. Yu","Department of Computer and Information Sciences, Towson University, Towson, MD, USA; Department of Computer and Information Sciences, Towson University, Towson, MD, USA; Department of Computer and Information Sciences, Towson University, Towson, MD, USA; Department of Computer and Information Sciences, Towson University, Towson, MD, USA","IEEE Transactions on Network Science and Engineering","7 Jul 2021","2021","8","2","1070","1083","The simultaneous development of deep learning techniques and Internet of Things (IoT)/Cyber-physical Systems (CPS) technologies has afforded untold possibilities for improving distributed computing, sensing, and data analysis. Among these technologies, federated learning has received increased attention as a privacy-preserving collaborative learning paradigm, and has shown significant potential in IoT/CPS-driven large-scale smart-world systems. At the same time, the vulnerabilities of deep neural networks, especially to adversarial attacks, cannot be overstated and should not be minimized. Moreover, the distributed nature of federated learning makes defense against such adversarial attacks a more challenging problem due to the unavailability of local data and resource heterogeneity. To tackle these challenges, in this paper, we propose ZeKoC, a Zero Knowledge Clustering approach to mitigating adversarial attacks. Particularly, we first formulate the problem of resource-constrained adversarial mitigation. Specifically, noting that a global server has no access to training samples, we reformulate the unsupervised weight clustering problem. Our proposed ZeKoC approach allows the server to automatically split and merge weight clusters for weight selection and aggregation. Theoretical analysis demonstrates that convergence is guaranteed. Further, our experimental results illustrate that, in a non-i.i.d. (i.e., independent and identically distributed) data setting, the proposed ZeKoC approach successfully mitigates general attacks while outperforming state-of-art schemes.","2327-4697","","10.1109/TNSE.2020.3002796","National Science Foundation(grant numbers:NSF-1350145); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9119145","Non-i.i.d. data;adversarial mitigation;federated learning","Training;Servers;Peer-to-peer computing;Machine learning;Data models;Security;Distributed databases","","37","","42","IEEE","16 Jun 2020","","","IEEE","IEEE Journals"
"An Extensible and Effective Anonymous Batch Authentication Scheme for Smart Vehicular Networks","J. Zhang; H. Zhong; J. Cui; Y. Xu; L. Liu","Key Laboratory of Intelligent Computing and Signal Processing of Ministry of Education, School of Computer Science and Technology, Anhui Engineering Laboratory of IoT Security Technologies, Institute of Physical Science and Information Technology, Anhui University, Hefei, China; Key Laboratory of Intelligent Computing and Signal Processing of Ministry of Education, School of Computer Science and Technology, Anhui Engineering Laboratory of IoT Security Technologies, Institute of Physical Science and Information Technology, Anhui University, Hefei, China; Key Laboratory of Intelligent Computing and Signal Processing of Ministry of Education, School of Computer Science and Technology, Anhui Engineering Laboratory of IoT Security Technologies, Institute of Physical Science and Information Technology, Anhui University, Hefei, China; Key Laboratory of Intelligent Computing and Signal Processing of Ministry of Education, School of Computer Science and Technology, Anhui Engineering Laboratory of IoT Security Technologies, Institute of Physical Science and Information Technology, Anhui University, Hefei, China; School of Informatics, University of Leicester, Leicester, U.K.","IEEE Internet of Things Journal","14 Apr 2020","2020","7","4","3462","3473","In recent years, research on the security of Industry 4.0 and the Internet of Things (IoT) has attracted a close attention from industry, government, and the scientific community. Smart vehicular networks, as a type of industrial IoT, inevitably exchange large amounts of security and privacy-sensitive data, which make them attractive targets for attackers. For protecting network security and privacy, we have proposed an extensible and effective anonymous batch authentication scheme. In contrast to traditional pseudonym authentication schemes, the same system private key need not to be preloaded in our scheme, effectively avoiding a system failure when destroying a vehicle. Besides, the certificate revocation list (CRL) size is merely related to the number of vehicles that have been revoked, regardless of the number of pseudonym certificates for revoked vehicles. Moreover, this scheme maintains the effectiveness of the traditional scheme, effectively reduces the scale of the CRL, and employs an identity revocation scheme that supports rapid distribution. The scheme supports conditional privacy protection, namely, only the trusted authority (TA) can uniquely trace and revoke vehicles. For illegal vehicles, the TA releases the two hashed seeds to facilitate traceability by all entities in its domain. Furthermore, security analysis indicates that our solution is secure under the random oracle model and fulfills a series of security requirements of vehicular networks. Compared to existing authentication schemes, performance evaluations show that the scheme offers relatively good performance in terms of time consumption.","2327-4662","","10.1109/JIOT.2020.2970092","National Natural Science Foundation of China(grant numbers:6191101332,61872001,U1936220,61702005); Open Fund of Key Laboratory of Embedded System and Service Computing (Tongji University), Ministry of Education(grant numbers:ESSCKF2018-03); Open Fund for Discipline Construction, Institute of Physical Science and Information Technology, Anhui University and the Excellent Talent Project of Anhui University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8978836","Certificate revocation list (CRL);conditional privacy protection;Industrial Internet of Things (IIoT);pseudonym authentication;smart vehicular networks","Authentication;Privacy;Roads;Cryptography","","31","","47","IEEE","3 Feb 2020","","","IEEE","IEEE Journals"
"A Brief Survey on Recent Advances in Cloud Control Systems","Y. Xia; Y. Zhang; L. Dai; Y. Zhan; Z. Guo","School of Automation, Beijing Institute of Technology, Beijing, China; School of Automation, Beijing Institute of Technology, Beijing, China; School of Automation, Beijing Institute of Technology, Beijing, China; School of Automation, Beijing Institute of Technology, Beijing, China; School of Automation, Beijing Institute of Technology, Beijing, China","IEEE Transactions on Circuits and Systems II: Express Briefs","28 Jun 2022","2022","69","7","3108","3114","Networked control systems (NCSs) have played a key role in Internet of Things (IoTs) to realize the vision of a fully interactive and responsive intelligent environment. However, traditional NCSs cannot address the challenges of big data collection, storage and analysis brought by large-scale IoTs applications. Thanks to the rapid development of cloud computing and control theory, a new paradigm of NCSs named cloud control systems (CCSs) has been proposed to address the challenges. Since proposed in 2012, it has drawn wide attentions from industry and academia. In this brief, we survey the recent advances of CCSs. Particularly, we present a taxonomy of existing results for CCSs, which include cloud control perspectives of traditional control techniques, security and privacy of cloud-based control, and CCSs for industry automation. We discuss each category in depth by comparing and contrasting different approaches subsequently. Finally, some future directions of how to design more efficient and practical CCSs have been discussed.","1558-3791","","10.1109/TCSII.2022.3178975","National Natural Science Foundation of China(grant numbers:62122014,62173036,62102022,62002019); Beijing Institute of Technology Research Fund Program for Young Scholars; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9785607","Networked control systems;cloud computing;cloud control systems;security and privacy","Cloud computing;Control systems;Privacy;Computer architecture;Security;Circuits and systems;Optimization","","9","","92","IEEE","30 May 2022","","","IEEE","IEEE Journals"
"Novel Workload Balancing Method for UAV-based Edge Cloud Computing Systems with Handover","H. Shimaday; Y. Kawamotoy; N. Katoy","Graduate School of Information Sciences, Tohoku University, Sendai, Japan; Graduate School of Information Sciences, Tohoku University, Sendai, Japan; Graduate School of Information Sciences, Tohoku University, Sendai, Japan","ICC 2020 - 2020 IEEE International Conference on Communications (ICC)","27 Jul 2020","2020","","","1","6","Internet of Things (IoT) has become an integral and pervasive part of everyday life, e.g. the infrastructure of intelligent traffic systems and smart cities. Such next-generation IoT applications require intelligent data processing that is performed via edge cloud computing (ECC) within a short period. In ECC, the edge server executes data processing; this is expected to reduce service delay. However, in the existing ECC research, infrastructure such as radio towers for communication and base stations for installing edge servers is indispensable; thus, it cannot respond to the demand for computing resources in the event of large-scale disasters and in infrastructureless areas. Therefore, researchers are studying the provision of computing resources using unmanned aerial vehicles (UAVs). On account of these studies, computation resources may be provided in several situations. However, in the face of this technology, to provide services with the delay time that the application allows, it is necessary to consider the workload balance and communication range of the UAV. In this paper, we propose a handover solution method considering workload balance and create a mathematical model with a transparent system. Moreover, numerical analyses show the effectiveness of the proposed method. With this contribution, it is possible to provide communication and computational resources in infrastructureless areas.","1938-1883","978-1-7281-5089-5","10.1109/ICC40277.2020.9149072","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9149072","","Delays;Servers;Relays;Task analysis;Handover;Cloud computing","","4","","13","IEEE","27 Jul 2020","","","IEEE","IEEE Conferences"
"ATWR-SMR: An Area-Constrained Truthful-Worker Recruitment-Based Sensing Map Recovery Scheme for Sparse MCS in Extreme-Environment Internet of Things","X. Fu; A. Liu; N. N. Xiong; T. Wang; S. Zhang","School of Computer Science and Engineering, Central South University, Changsha, China; School of Computer Science and Engineering, Central South University, Changsha, China; Department of Computer Science and Mathematics, Sul Ross State University, Alpine, TX, USA; Artificial Intelligence and Future Networks, Beijing Normal University & UIC, Zhuhai, China; School of Computer Science and Engineering, Hunan University of Science and Technology, Xiangtan, China","IEEE Internet of Things Journal","24 Jan 2024","2024","11","3","3711","3724","Sparse mobile crowdsensing (SMCS) is a prospective solution for large-scale data sensing through mobile devices of Internet of Things (IoT) systems where IoT systems cannot obtain the sensing data of the area under extreme environments. The unsensed area data can be obtained by the data inference algorithm trained by the sensed data of recruited workers. However, recruited workers may upload false data in exchange for payment, and the platform is unable to distinguish between true and false data. In this article, our goal is to maximize the SMCS platform’s total profit, where the platform cannot verify the authenticity of the sensed data, and the requester’s payment is based on the sensing task’s data quality. To meet the objective, we propose the area-constrained truthful worker recruitment-based sensing map recovery (ATWR-SMR) scheme, which includes the area constraint, the area-constrained truthful worker recruitment, and the sensing map recovery. 1) The area constraint establishes the importance of areas by history data differences in the sliding window. 2) The truthful worker recruitment identifies trustworthy workers by the truthful upper confidence bound algorithm and recruits low-cost trustworthy workers to sense high-importance areas. 3) The sensing map recovery infers the unsensed data by the deep matrix factorization algorithm trained by the history truthful data set. Finally, we verify the effectiveness of the ATWR-SMR scheme in improving the total profit of the platform through extensive comparison experiments based on the China air quality data set.","2327-4662","","10.1109/JIOT.2023.3314615","National Natural Science Foundation of China(grant numbers:62072475); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10247511","Internet of Things (IoT);sensing map recovery;sparse mobile crowdsensing (SMCS);truthful worker recruitment;upper confidence bound algorithm","Sensors;History;Internet of Things;Recruitment;Inference algorithms;Crowdsensing;Costs","","1","","38","IEEE","12 Sep 2023","","","IEEE","IEEE Journals"
"Effects of Dynamic Blockage in Multi‐Connectivity Millimeter‐Wave Radio Access","V. Petrov; M. Gapeyenko; D. Moltchanov; A. Samuylov; S. Andreev; Y. Koucheryavy","Tampere University, Tampere, Finland; Tampere University, Tampere, Finland; Tampere University, Tampere, Finland; Tampere University, Tampere, Finland; Tampere University, Tampere, Finland; Tampere University, Tampere, Finland","5G Verticals: Customizing Applications, Technologies and Deployment Techniques","","2020","","","93","117","This chapter outlines the methods to capture and characterize the blockage effects in cellular millimeter‐wave (mmWave) systems together with the state‐of‐the‐art techniques to mitigate the negative effects of dynamic blockage on both user‐ and network‐centric performance indicators. It first discusses the key aspects of mmWave signal blockage by various objects in urban deployments and its consecutive impact on link‐level performance. Further, the chapter summarizes mathematical methods to model the dynamic blockage processes in different Internet‐of‐Things (IoT) scenarios and deployment configurations, such as massive augmented and virtual reality setups, connected vehicles, etc. The presented results can be used in design and optimization of cellular mmWave systems for the emerging delay‐, availability‐, and reliability‐sensitive services across many 5G verticals. The chapter also addresses possible solutions to mitigate blockage in large‐scale 5G‐grade consumer IoT deployments equipped with mmWave New Radio connectivity.","","9781119514831","10.1002/9781119514848.ch4","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9116659.pdf&bkn=9116609&pdfType=chapter","","Vehicle dynamics;Millimeter wave technology;Millimeter wave communication;Attenuation;Computational modeling;5G mobile communication;Automobiles","","1","","","","15 Jun 2020","","","IEEE","Wiley-IEEE Press eBook Chapters"
"Neighborhood Rough Residual Network–Based Outlier Detection Method in IoT-Enabled Maritime Transportation Systems","Q. Chen; L. Xie; L. Zeng; S. Jiang; W. Ding; X. Huang; H. Wang","Department of Earth System Science, Ministry of Education Key Laboratory for Earth System Modeling, Institute for Global Change Studies, Tsinghua University, Beijing, China; Kingsoft Office Software, Jinshan Software Park, Zhuhai, China; State Key Laboratory of Marine Resource Utilization in South China Sea and the School of Information and Communication Engineering, Hainan University, Haikou, China; Department of Information Science and Engineering, Ocean University of China, Qingdao, China; School of Information Science and Technology, Nantong University, Nantong, China; Department of Earth System Science, Ministry of Education Key Laboratory for Earth System Modeling, Institute for Global Change Studies, Tsinghua University, Beijing, China; Department of Computer Science, Norwegian University of Science and Technology, Gjøvik, Norway","IEEE Transactions on Intelligent Transportation Systems","1 Nov 2023","2023","24","11","11800","11811","Outlier detection can identify anomalies in large-scale data. To provide reliability and security for Internet of Things (IoT)-enabled maritime transportation systems (MTSs), in this paper we propose an outlier detection method based on the neighborhood rough residual network (NRRN). We calculate the neighborhood approximation accuracy and neighborhood conditional entropy to obtain the neighborhood combined entropy describing the discrimination ability of the condition attribute subset to the information system. We then delete the redundant attributes according to the attribute combination importance derived from the neighborhood combined entropy. The data after attribute reduction are used to train the convolutional neural network, and the residual network (ResNet50) is used to avoid the degradation of model performance caused by the increase in the number of network layers. The proposed method is compared with mainstream outlier detection algorithms on a fishing vessel operation dataset. Experiments show that the proposed method can greatly improve the accuracy of outlier detection while taking into account interpretability and computational efficiency, thereby ensuring the data integrity of IoT-enabled MTSs.","1558-0016","","10.1109/TITS.2023.3285615","National Key Research and Development Program of China(grant numbers:2020YFA0607900,2021YFC3101600); Open Foundation of Key Laboratory of Marine Science and Numerical Modeling(grant numbers:2020-ZD-05); National Natural Science Foundation of China(grant numbers:42075137,41776010,61976120); Natural Science Key Foundation of Jiangsu Education Department(grant numbers:21KJA510004); China Postdoctoral Science Foundation(grant numbers:2021M701838); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10161585","Outlier detection;IoT-enabled maritime transportation systems;neighborhood combined entropy;residual network;data integrity","Anomaly detection;Data models;Entropy;Transportation;Marine vehicles;Residual neural networks;Behavioral sciences","","1","","60","IEEE","23 Jun 2023","","","IEEE","IEEE Journals"
"Intelligent Connectivity","A. Yarali",NA,"Intelligent Connectivity: AI, IoT, and 5G","","2022","","","133","151","Intelligent connectivity is the newest phenomenon and promises a revolution in the way things will be done shortly. This chapter explores intelligent connectivity components, their applications in different fields, challenges, and possibilities. The development of artificial intelligence (AI) is to create specialized expert systems and develop human intelligence into computer systems. The different technologies involved in AI encompass natural language processing, machine learning, and deep learning. Machine‐to‐Machine involves isolated cases of device‐to‐device signaling and communication. The Internet of Things (IoT) is more of a larger scale that works in synergy with vertical software stacks to automate and manage communication between several devices and objects. The combination of 5G, AI, and the IoT will usher in a new intelligent connectivity age. There are key areas where intelligent connectivity is expected to make key changes, mainly in transportation/logistics, education, healthcare, entertainment, public safety/security, and industrial and manufacturing operations.","","9781119685234","10.1002/9781119685265.ch7","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9622486.pdf&bkn=9622345&pdfType=chapter","","Artificial intelligence;Internet of Things;5G mobile communication;Machine-to-machine communications;Wireless sensor networks;Wireless communication;Radiofrequency identification","","","","","","22 Nov 2021","","","IEEE","Wiley-IEEE Press eBook Chapters"
"Improving the Security and Reliability of Embedded Networks With TTMAC-CAN","I. Ghodsollahee; Y. Sedaghat; M. R. Pourmoghadam","Department of Computer Engineering, Deppendable Distributed Embedded Systems (DDEms) Laboratory, Ferdowsi University of Mashhad, Mashhad, Iran; Department of Computer Engineering, Deppendable Distributed Embedded Systems (DDEms) Laboratory, Ferdowsi University of Mashhad, Mashhad, Iran; Department of Computer Engineering, Deppendable Distributed Embedded Systems (DDEms) Laboratory, Ferdowsi University of Mashhad, Mashhad, Iran","2020 10th International Conference on Computer and Knowledge Engineering (ICCKE)","31 Dec 2020","2020","","","488","494","The widespread use of distributed embedded systems to monitor and control large-scale industrial facilities (e.g., power plants, and electrical power grids), and the growing development of Internet of Things (IoT) have led to Industrial IoT (IIoT). In a typical IIoT, distributed embedded systems, composed of processors, sensors and actuators which are connected through embedded network protocols, are connected to the internet for remote management. However, embedded networks and therefore industrial facilities are very vulnerable to cyber-attacks. In this paper TTMAC-CAN, a novel scheduling algorithm is proposed which utilizes a multi-objective evolutionary algorithm to improve security, reliability, and performance of Time Triggered Controller Area Network (TTCAN) protocol. The proposed technique in comparison with TOUCAN reduces the risk of guessing the tag by about 86% and improve receiving cycle time by 98%.","2643-279X","978-1-7281-8566-8","10.1109/ICCKE50421.2020.9303726","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9303726","Message Authentication Code;Controller Area Network (CAN);Non-Dominated Sorting Genetic Algorithm (NSGA);Reliability;Security","Security;Reliability;Protocols;Throughput;Authentication;Real-time systems;Microcontrollers","","","","29","IEEE","31 Dec 2020","","","IEEE","IEEE Conferences"
"Energy-Efficient Space–Air–Ground–Ocean-Integrated Network Based on Intelligent Autonomous Underwater Glider","Z. Li; J. Wen; J. Yang; J. He; T. Ni; Y. Li","School of Electrical and Information Engineering, Tianjin University, Tianjin, China; School of Electrical and Information Engineering, Tianjin University, Tianjin, China; School of Electrical and Information Engineering, Tianjin University, Tianjin, China; School of Electrical and Information Engineering, Tianjin University, Tianjin, China; School of Electrical and Information Engineering, Tianjin University, Tianjin, China; School of Electrical and Information Engineering, Tianjin University, Tianjin, China","IEEE Internet of Things Journal","17 May 2023","2023","10","11","9329","9341","Internet of Things (IoT) has extended its coverage to various spatial domains and has established interconnection to serve widespread applications of a larger spatial scale. Such IoT is called the space–air–ground–ocean-integrated network (SAGOI-Net), which consists of multiple battery-powered heterogeneous devices. Hence, energy efficiency is the key point of SAGOI-Net to be stably operated for a long time without manual maintenance. This article proposes a novel scheme of energy-efficient autonomous and decentralized SAGOI-Net establishment using an intelligent autonomous underwater glider (AUG) to serve marine applications. The proposed SAGOI-Net is energy efficient because the energy consumption is minimized by: 1) employing nonpropeller-driven AUG; 2) navigating AUG under water without acoustic sensor or extra energy-consuming vision sensors; and 3) equipping the self-navigation (SN) system based on lightweight neural network model to save the energy consumption of onboard computing resource. Moreover, assuming the AUG navigation problem as time-series regression, the proposed scheme designs SAGOI-Net to be autonomous and decentralized with the aid of lightweight long short-term memory (LSTM) network-based SN (SN-LSTM) system of AUG. The lightweight SN-LSTM model is trained end-to-end on dynamically modeled AUG motion information along with numerically modeled ocean environment data to quantitatively analyze the impact of the ocean environment on AUG. The simulation results demonstrate a superior performance of the AUG SN along with energy efficiency of the proposed SAGOI-Net.","2327-4662","","10.1109/JIOT.2022.3227912","National Natural Science Foundation of China(grant numbers:61871283,62271345); Postdoctoral Science Foundation of China(grant numbers:2021M702441); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9979795","Green Internet of Things (IoT);long short-term memory network-based self-navigation (SN-LSTM);numerical modeling;self-navigation (SN);space–air–ground–ocean-integrated network (SAGOI-Net);underwater glider","Oceans;Numerical models;Navigation;Energy efficiency;Analytical models;Sensors;Data models","","","","37","IEEE","12 Dec 2022","","","IEEE","IEEE Journals"
"Unlocking Edge Intelligence Through Tiny Machine Learning (TinyML)","S. A. R. Zaidi; A. M. Hayajneh; M. Hafeez; Q. Z. Ahmed","School of Electronic and Electrical Engineering, University of Leeds, Leeds, U.K.; Department of Electrical Engineering, Faculty of Engineering, The Hashemite University, Zarqa, Jordan; School of Computing & Engineering, University of Huddersfield, Huddersfield, U.K.; School of Computing & Engineering, University of Huddersfield, Huddersfield, U.K.","IEEE Access","28 Sep 2022","2022","10","","100867","100877","Machine Learning (ML) on the edge is key to enabling a new breed of IoT and autonomous system applications. The departure from the traditional cloud-centric architecture means that new deployments can be more power-efficient, provide better privacy and reduce latency for inference. At the core of this paradigm is TinyML, a framework allowing the execution of ML models on low-power embedded devices. TinyML allows importing pre-trained ML models on the edge for providing ML-as-a-Service (MLaaS) to IoT devices. This article presents a TinyMLaaS (TMLaaS) architecture for future IoT deployments. The TMLaaS architecture inherently presents several design trade-offs in terms of energy consumption, security, privacy, and latency. We also present how TMLaaS architecture can be implemented, deployed, and maintained for large-scale IoT deployment. The feasibility of implementation for the TMLaaS architecture has been demonstrated with the help of a case study.","2169-3536","","10.1109/ACCESS.2022.3207200","Engineering and Physical Sciences Research Council (EPSRC)(grant numbers:UK EP/S016813/1,EP/N010523/1); Royal Academy of Engineering, Transforming Systems through Partnership TSP1040(grant numbers:UK 122040); Royal Academy through the Distinguished International Associates(grant numbers:DIA-2021-18); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9893787","Tiny machine learning;IoT;edge computing;5G;LoRa;gesture recognition;deep learning;transfer learning;federated learning;implementation;MLOps;energy efficiency","Internet of Things;Logic gates;Cloud computing;Performance evaluation;Computational modeling;Memory management;Machine learning;Edge computing;Internet of Things;Deep learning;Transfer learning;Collaborative work;Energy efficiency","","20","","26","CCBY","16 Sep 2022","","","IEEE","IEEE Journals"
"Toward Massive Connectivity for IoT in Mixed-ADC Distributed Massive MIMO","J. Yuan; Q. He; M. Matthaiou; T. Q. S. Quek; S. Jin","National Mobile Communications Research Laboratory, Southeast University, Nanjing, China; School of Engineering, Westlake University, Hangzhou, China; Institute of Electronics, Communications and Information Technology, Queen’s University Belfast, Belfast, U.K.; Information Systems Technology and Design Pillar, Singapore University of Technology and Design, Singapore; National Mobile Communications Research Laboratory, Southeast University, Nanjing, China","IEEE Internet of Things Journal","12 Mar 2020","2020","7","3","1841","1856","Massive connectivity is a key requirement for the Internet of Things (IoT). In practice, the network should be capable of accommodating thousands of devices and meeting their traffic demands. In this article, we consider the access phase for IoT in a mixed-analog-to-digital converter distributed massive multiple-input-multiple-output system, in which users are classified into light-load users and heavy-load users depending on their traffic load requirements. To meet the low-latency and low-cost demands in IoT, the access scheme for both types of users are designed in a grant-free fashion. For users with light-load traffic demands, by formulating the user activity detection (UAD) and channel estimation (CE) into a compressed sensing problem, we provide a low-complexity algorithm solver which requires no prior information. The simulation results verify that the proposed algorithm can effectively detect user activity and estimate channel state information (CSI) between the users and access points (APs). To satisfy the throughput requirements of heavy-load users, after UAD and CE, a two-step dynamic clustering is proposed for coordinated multipoint transmission using the large-scale fading (LSF) information. The impact of quantization noise on LSF estimation is investigated, as well as, a corresponding compensation method and accuracy bound. By detecting the clustering behavior among users in the first step, the complexity of the joint user and AP clustering is substantially reduced. The numerical results reveal that the proposed algorithm can offer significant performance gains in various scenarios with fast convergence.","2327-4662","","10.1109/JIOT.2019.2957281","National Natural Science Foundation of China(grant numbers:61531011); National Natural Science Foundation of China(grant numbers:61625106); Leverhulme Trust(grant numbers:LTSRF1718\14\2); Singapore University of Technology and Design(grant numbers:SUTDZJU/RES/01/2016); SUTD-ZJU Research Collaboration(grant numbers:SUTD-ZJU/RES/05/2016); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8920097","Channel estimation (CE);distributed massive MIMO (mMIMO);dynamic clustering;Internet of Things (IoT);user activity detection (UAD);weighted sum-rate maximization","Internet of Things;Clustering algorithms;Throughput;Heuristic algorithms;MIMO communication;Estimation;Complexity theory","","24","","52","IEEE","3 Dec 2019","","","IEEE","IEEE Journals"
"ReapIoT: Reliable, Energy-Aware Network Protocol for Large-Scale Internet-of-Things (IoT) Applications","A. Badi; I. Mahgoub","Computer Science and Engineering Department, Bethune-Cookman University, Daytona Beach, FL, USA; CEECS Department, Florida Atlantic University, Boca Raton, FL, USA","IEEE Internet of Things Journal","23 Aug 2021","2021","8","17","13582","13592","A new era is emerging where buildings, vehicles, factories, and appliances, among many other entities will communicate with each other over the Internet, with limited or no human interaction. Collectively known as the Internet of Things (IoT), these systems share a common technology foundation. They are built on wireless communication between stationary or mobile large-scale electronic sensor and actuator networks. For the vast majority of IoT applications, energy-efficient operations are a critical requirement since they will use battery-powered devices. Another requirement is communication reliability, due to unattended network operations. We introduce ReapIoT, reliable energy-aware protocol for IoT WSNs. ReapIoT is an energy-efficient network communication protocol that considers reliability as a design parameter and as a constraint. The protocol introduces message classification based on reliability. This is used to implement new energy saving techniques. The protocol also introduces the individualized link power settings algorithm, and the link rating parameter. They are used to optimize the network clusters formation and for intracluster communication, under reliability constraint. Consequently, the protocol optimizes energy consumption while providing a reliable data delivery network.","2327-4662","","10.1109/JIOT.2021.3066531","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9380667","Communication network reliability;Internet of Things (IoT);wireless communication protocols;wireless sensor networks (WSNs)","Reliability;Wireless sensor networks;Internet of Things;Protocols;Computer network reliability;Wireless communication;Telecommunication network reliability","","13","","42","IEEE","17 Mar 2021","","","IEEE","IEEE Journals"
"Game-Based Multitype Task Offloading Among Mobile-Edge-Computing-Enabled Base Stations","W. Fan; L. Yao; J. Han; F. Wu; Y. Liu","School of Electronic Engineering and the Beijing Key Laboratory of Work Safety Intelligent Monitoring, Beijing University of Posts and Telecommunications, Beijing, China; School of Electronic Engineering and the Beijing Key Laboratory of Work Safety Intelligent Monitoring, Beijing University of Posts and Telecommunications, Beijing, China; School of Electronic Engineering and the Beijing Key Laboratory of Work Safety Intelligent Monitoring, Beijing University of Posts and Telecommunications, Beijing, China; School of Electronic Engineering and the Beijing Key Laboratory of Work Safety Intelligent Monitoring, Beijing University of Posts and Telecommunications, Beijing, China; School of Electronic Engineering and the Beijing Key Laboratory of Work Safety Intelligent Monitoring, Beijing University of Posts and Telecommunications, Beijing, China","IEEE Internet of Things Journal","7 Dec 2021","2021","8","24","17691","17704","The widely used Internet of Things (IoT) mobile devices (MDs) require fast processing capability to handle a large volume of computing tasks. Mobile-edge computing (MEC) can augment the capability of IoT MDs through offloading their computing tasks to the MEC-enabled base station (MEC-BS) that covers them. Most of the existing research works only focus on the computation offloading problems for a single MEC-BS. However, the load of a MEC-BS will rise as the increase of the scale of the offloaded tasks, especially during rush hours, and further it will result in deterioration of system performance. In this article, we propose a game-based multitype task offloading scheme among MEC-BSs. The tasks offloaded from IoT MDs can be further offloaded among MEC-BSs to alleviate high-load MEC-BSs. Aiming at balancing the computing delays of the tasks on each MEC-BS, a noncooperative game is formulated to model the computation offloading for the tasks with different types, indicated by computation amount, data size, and delay tolerance. The existence and convergence of the Nash equilibrium of the game are first proved using the variational inequality and regularization techniques. Then, we design a distributed iterative algorithm to efficiently solve the game problem. Simulation results show the fast convergence of our algorithm. The reduction of total computing delay optimized by our scheme can reach 45%–50% on average in multiple scenarios, and the superiority of our scheme is also demonstrated in comparisons with reference schemes.","2327-4662","","10.1109/JIOT.2021.3082291","National Natural Science Foundations of China(grant numbers:61821001); Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9437337","Computation offloading;Internet of Things (IoT);load balancing;mobile-edge computing (MEC);noncooperative game theory","Edge computing;Internet of Things;Delays;Cloud computing;Computational modeling;Servers;Game theory","","10","","34","IEEE","20 May 2021","","","IEEE","IEEE Journals"
"A Novel Multi-Agent and Multilayered Game Formulation for Intrusion Detection in Internet of Things (IoT)","B. U. I. Khan; F. Anwar; R. F. Olanrewaju; B. R. Pampori; R. N. Mir","Department of Electrical and Computer Engineering, Kulliyyah of Engineering, International Islamic University Malaysia, Kuala Lumpur, Malaysia; Department of Electrical and Computer Engineering, Kulliyyah of Engineering, International Islamic University Malaysia, Kuala Lumpur, Malaysia; Department of Electrical and Computer Engineering, Kulliyyah of Engineering, International Islamic University Malaysia, Kuala Lumpur, Malaysia; Department of Information Technology, Central University of Kashmir, Srinagar, India; Department of Computer Science and Engineering, National Institute of Technology Srinagar, Srinagar, India","IEEE Access","3 Jun 2020","2020","8","","98481","98490","The current era of smart computing and enabling technologies encompasses the Internet of Things (IoT) as a network of connected, intelligent objects where objects range from sensors to smartphones and wearables. Here, nodes or objects cooperate during communication scenarios to accomplish effective throughput performance. Despite the deployment of large-scale infrastructure-based communications with faster access technologies, IoT communication layers can still be affected with security vulnerabilities if nodes/objects do not cooperate and intend to take advantage of other nodes for fulfilling their malevolent interest. Therefore, it is essential to formulate an intrusion detection/prevention system that can effectively identify the malicious node and restrict it from further communication activities - thus, the throughput, and energy performance can be maximized to a significant extent. This study introduces a combined multi-agent and multilayered game formulation where it incorporates a trust model to assess each node/object, which is participating in IoT communications from a security perspective. The experimental test scenarios are numerically evaluated, where it is observed that the proposed approach attains significantly improves intrusion detection accuracy, delay, and throughput performance as compared to the existing baseline approaches.","2169-3536","","10.1109/ACCESS.2020.2997711","Ministry of Higher Education Malaysia (Kementerian Pendidikan Tinggi) through the Fundamental Research Grant Scheme (FRGS) (Ministry Project ID: FRGS/1/2019/ICT03/UIAM/01/2)(grant numbers:FRGS19-137-0746); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9099822","Internet of Things;intrusion detection;multi-layer games;security measures","Games;Intrusion detection;Throughput;Game theory;Internet of Things;Mathematical model","","10","","34","CCBY","26 May 2020","","","IEEE","IEEE Journals"
"MicroVault: Reliable Storage Unit for IoT Devices","E. Aras; M. Ammar; F. Yang; W. Joosen; D. Hughes","imec-DistriNet, KU Leuven, Belgium; imec-DistriNet, KU Leuven, Belgium; imec-DistriNet, KU Leuven, Belgium; imec-DistriNet, KU Leuven, Belgium; imec-DistriNet, KU Leuven, Belgium","2020 16th International Conference on Distributed Computing in Sensor Systems (DCOSS)","1 Sep 2020","2020","","","132","140","The Internet of Things (IoT) is being deployed at large scale in a wide range of long-life applications. Examples range from Industry 4.0 to smart lighting systems. These applications have diverse requirements of non-volatile storage. However, the flash memory that is used in today's IoT devices offers limited write endurance and must therefore be carefully managed if applications are to deliver on their promises of multiyear lifetimes. Managing the health of flash memory is difficult for application developers, as it requires in-depth hardware and software knowledge, which often needs to the problem being neglected. While various techniques have been proposed to preserve the health of flash memory, prior work tends to focus on a single hardware platform and data type. Furthermore, prior work does not provide lifetime guarantees. This paper tackles this problem by proposing MicroVault, a simple and unified interface for reliable non-volatile data storage on resource-constrained IoT devices. MicroVault enforces developer-specified lifetime guarantees through a range of lifetime extension techniques, which are adaptively applied based upon the needs of the application. Evaluation shows that MicroVault dramatically extends the lifetime of flash memory while minimising overhead.","2325-2944","978-1-7281-4351-4","10.1109/DCOSS49796.2020.00031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9183456","Embedded Software;Data Storage;Memory Management;Reliability;Internet of Things","EPROM;Nonvolatile memory;Random access memory;Software;Software reliability;Flash memories","","6","","26","IEEE","1 Sep 2020","","","IEEE","IEEE Conferences"
"Multiple Thermal Sensor Array Fusion Toward Enabling Privacy-Preserving Human Monitoring Applications","A. Naser; A. Lotfi; J. Zhong","Computational Intelligence and Applications Research Group, Nottingham Trent University, Nottingham, NG11 8NS, U.K; Computational Intelligence and Applications Research Group, Nottingham Trent University, Nottingham, NG11 8NS, U.K; Department of Rehabilitation Sciences, The Hong Kong Polytechnic University, Hong Kong","IEEE Internet of Things Journal","24 Aug 2022","2022","9","17","16677","16688","Human-centric applications of a single thermal sensor array (TSA) have performed extremely well in many areas. However, most of these works have not yet reached the real applicability stage of the Internet of Things (IoT) applications. The main limitation of deploying such systems on a large scale is the challenge of fusing multiple TSAs to cover a wide inspection area, e.g., smart homes, hospitals, and many other domestic environments. On the other hand, objects that appear in the low-resolution thermal images acquired from TSA have low intraclass variations and high interclass similarities, making the identification of the overlapping regions through matching a comparable template image in multiple images very difficult. This article proposes a motion-based approach to fuse multiple TSAs and learn the domestic environment layout to enable further human-centred IoT applications to run in the cloud. Besides, a privacy improvement on utilizing these sensors in IoT applications is proposed. The proposed approach is evaluated with comprehensive experiments on different sensor placements and domestic environment conditions. This article shows an average performance of 92.5% accuracy using various machine learning techniques and use case scenarios.","2327-4662","","10.1109/JIOT.2022.3150566","Nottingham Trent University through a Fully-Funded Scholarship Scheme; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9709569","Human-centred approach;Internet of Things (IoT);machine learning;optical flow;privacy-preserving approach;sensor fusion;thermal sensor array (TSA)","Internet of Things;Thermal sensors;Inspection;Layout;Monitoring;Thermal noise;Sensor arrays","","5","","54","IEEE","10 Feb 2022","","","IEEE","IEEE Journals"
"Speeding at the Edge: An Efficient and Secure Redactable Blockchain for IoT-Based Smart Grid Systems","Y. Lu; X. Tang; L. Liu; F. R. Yu; S. Dustdar","School of Electrical Engineering, Xi’an Jiaotong University, Xi’an, China; School of Electrical Engineering, Xi’an Jiaotong University, Xi’an, China; Guangzhou Institute of Technology, Xidian University, Guangzhou, China; Department of Systems and Computer Engineering, Carleton University, Ottawa, ON, Canada; Distributed Systems Group, Vienna University of Technology, Vienna, Austria","IEEE Internet of Things Journal","6 Jul 2023","2023","10","14","12886","12897","As a promising approach to extending cloud resources and services, blockchain-enabled Internet of Things (IoT)-based smart grid edge computing has attracted much attention. However, the edge node’s resource-constraint nature makes it difficult to store the entire chain as the sensing IoT data volume increases. To address this issue, we propose an FS scheme, a fast and secure multithreshold trapdoor Chameleon hash scheme which serves as the basis for block substitution at the edge nodes to solve the storage limitation problem. The FS scheme is used to achieve a consensus-based block substitution, which allows  $t$ -out-of- $n$  edge nodes to compute a hash collision collaboratively to reliably substitute a historical block without leaking the randomness  $R$ . Also, inspired by the rationale of fast polynomial interpolation, we optimize the FS scheme to FS-I to reduce the time complexity from  $\mathcal {O}(nt)$  to  $\mathcal {O}(t{\mathrm{ log}}^{2}t)$ . In addition, we further optimize FS-I to FS-II by using a fast Fourier transform (FFT) to dramatically improve the computational efficiency of Lagrange interpolation, which leads to a significant improvement in terms of block substitution performance. Finally, We provide security analysis and evaluate the performance through comprehensive experiments and the results show that FS can achieve up to several magnitudes better than DTTCH. The results also demonstrate that the FS scheme can provide high service quality for large-scale IoT-based smart grid systems.","2327-4662","","10.1109/JIOT.2023.3253601","National Key Research and Development Program of China(grant numbers:2022YFF0903400); Open Research Fund Program of Key Laboratory of Agricultural Blockchain Application, Ministry of Agriculture and Rural Affairs(grant numbers:2022KLABA01); China Postdoctoral Science Foundation(grant numbers:2022M712535); Natural Science Foundation Research Program of Shaanxi Province(grant numbers:2023-JC-QN-0749); Key Research and Development Program of Shaanxi Province(grant numbers:2021GXLH-Z-054); Key Research and Development, Guangdong High Level Innovation Research Institution Project(grant numbers:2021B0909050008); Transformation Program of Qinghai Province(grant numbers:2021-GX-112); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10061610","Blockchain;Chameleon hash (CH);edge computing;industrial Internet of Things (IoT);redactable blockchain","Blockchains;Smart grids;Edge computing;Security;Interpolation;Reliability;Public key","","2","","29","IEEE","7 Mar 2023","","","IEEE","IEEE Journals"
"Evaluation of Real-Time Monitoring on the Growth of Spirulina Microalgae: Internet of Things and Microalgae Technologies","H. R. Lim; K. S. Khoo; K. W. Chew; M. Y. M. Teo; T. C. Ling; S. Alharthi; W. F. Alsanie; P. L. Show","Department of Chemical and Environmental Engineering, Faculty of Science and Engineering, University of Nottingham Malaysia, Semenyih, Malaysia; Department of Chemical Engineering and Materials Science, Yuan Ze University, Taoyuan, Taiwan; School of Chemistry, Chemical Engineering and Biotechnology, Nanyang Technological University, Jurong West, Singapore; Department of Biotechnology, Faculty of Applied Sciences, UCSI University, Kuala Lumpur, Malaysia; Institut Sains Biologi, Fakulti Sains, Universiti Malaya, Kuala Lumpur, Malaysia; Department of Chemistry, College of Science, Taif University, Taif, Saudi Arabia; Department of Clinical Laboratory Sciences, Faculty of Applied Medical Sciences, and the Centre of BiomedicalSciences Research, Deanship of Scientific Research, Taif University, Taif, Saudi Arabia; Zhejiang Provincial Key Laboratory for Subtropical Water Environment and Marine Biological Resources Protection, Wenzhou University, Wenzhou, China","IEEE Internet of Things Journal","8 Jan 2024","2024","11","2","3274","3281","Microalgae farming is still in its infancy phase to implement Internet of Things (IoT) technologies. Spirulina microalgae was selected to be investigated in this study because it is the most commercially viable microalgae for large-scale production. There are various methods to measure the biomass concentration of microalgae. However, the conventional methods are time consuming, laborious, or expensive. Therefore, this research aims to integrate IoT with a biomass concentration sensor (TCS3200), to monitor the biomass concentration of Spirulina in real time and remotely through the cloud-based system (ThingSpeak). The TCS3200 sensor was programmed and set up to measure the absorbance of the Spirulina culture in a 10-L cultivation tank. The data was collected and stored in the cloud Thingspeak platform. Besides, additional parameters, such as temperature, light intensity, and water level, were monitored to gain a comprehensive understanding of the entire cultivation process. These sensors were all controlled by a Lolin NodeMCU ESP8266 microcontroller. The TCS3200 sensor was found to be better suited for measuring low-biomass concentrations, while a UV-Vis spectrophotometer was able to measure higher biomass concentrations after the sample was diluted. Real-time monitoring of these parameters allows for timely adjustments to be made to the cultivation conditions to optimize the growth and productivity of the Spirulina culture and detect any problems or abnormalities in the process. The use of IoT technologies in the cultivation of microalgae can improve the efficiency and sustainability of the process and provide valuable data for further research and development.","2327-4662","","10.1109/JIOT.2023.3296525","Biolina Corporation Sdn Bhd., Malaysia(grant numbers:NVEC0018); UCSI University for the Research Excellence and Innovation Grant (REIG)(grant numbers:REIG-FAS-2022/003); Taif University Researchers Supporting Project, Taif University, Saudi Arabia(grant numbers:TURSP-HC2023/3); Khalifa University (FSU-2024-001)(grant numbers:8474000580); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10185959","Fourth industrial revolution (IR 40);Internet of Things (IoT);microalgae;sensors;Spirulina","Temperature measurement;Robot sensing systems;Biomass;Monitoring;Real-time systems;Internet of Things;Cloud computing","","1","","25","IEEE","18 Jul 2023","","","IEEE","IEEE Journals"
"Active User Detection for Uplink NOMA Communication: Deep Learning Approach","C. Yu; C. Li; G. Wu","National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China, Chengdu, China; National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China, Chengdu, China; National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China, Chengdu, China","2022 14th International Conference on Wireless Communications and Signal Processing (WCSP)","15 Feb 2023","2022","","","592","597","Recently, with the rapid increase in the number of internet of things (IoT) devices, wireless communications based on orthogonal multiple access (OMA) are greatly limited by limited spectrum resources and the data conflicts and loss caused by large-scale IoT device. In order to support massive user devices, non-orthogonal multiple access (NOMA) have been suggested. In this paper, we focus on the problem of active user detection (AUD) of NOMA-based systems in IoT scenarios, and propose a long short-term memory (LSTM) based detection algorithm to solve the problems of low accuracy and high complexity of conventional AUD algorithms. The simulation results demonstrate that the proposed AUD algorithm based on LSTM network is superior to the conventional orthogonal matching pursuit (OMP) algorithm and the sparse Bayesian learning (SBL) algorithm in terms of both the error detection rate and the missed detection rate. Moreover, when the pilot scheme is designed for sparse code multiple access (SCMA), these two rates are further reduced compared with traditional pilot scheme. Furthermore, we present a detailed complexity analysis and comparison between conventional and deep learing (DL) AUD algorithm, which show the DL-based method greatly reduces the computational complexity.","","978-1-6654-5085-0","10.1109/WCSP55476.2022.10039265","Fundamental Research Funds for the Central Universities(grant numbers:ZYGX2020ZB042); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10039265","internet of things;non-orthogonal multiple access;sparse code multiple access;active user detection;long short-term memory","Wireless communication;NOMA;Codes;Simulation;Matching pursuit algorithms;Signal processing algorithms;Signal processing","","","","22","IEEE","15 Feb 2023","","","IEEE","IEEE Conferences"
"Security Dashboard Design for Non-Experts in Sigfox-based Smart Spaces","H. Zhao; T. Schafeitel-Tähtinen; H. Verkkosaari; M. Helenius; B. Silverajan","Tampere University, Finland; Tampere University, Finland; Tampere University, Finland; Tampere University, Finland; Tampere University, Finland","2022 IEEE 8th World Forum on Internet of Things (WF-IoT)","22 Jun 2023","2022","","","1","6","As one of the Internet of Things (IoT) technology, the Sigfox network has brought digitization to smart spaces in terms of automation and operational management, for example, smart building and cities. However, the large-scale installed sensors and devices expand the attack surfaces, as a vulnerable device exposed to cyber threats may also cause physical harm. Thus, monitoring and understanding cybersecurity status in a smart environment is critical. In this paper, we present the cyber-threats analysis of the layered Sigfox IoT system. To increase cybersecurity awareness in smart residential buildings, we propose visual analytic dashboards for monitoring both cybersecurity and safety status. The developed dashboards are tailored to three user groups - Admin users, House managers and Residents. Such security dashboards are applicable to other IoT use cases such as smart cities and smart logistics.","","978-1-6654-9153-2","10.1109/WF-IoT54382.2022.10152204","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10152204","Sigfox;Security Dashboard;Smart Spaces","Smart cities;Visual analytics;Visual systems;Safety;Internet of Things;Stakeholders;Computer security","","","","16","IEEE","22 Jun 2023","","","IEEE","IEEE Conferences"
"A Tutorial-Cum-Survey on Percolation Theory With Applications in Large-Scale Wireless Networks","H. ElSawy; A. Zhaikhan; M. A. Kishk; M. -S. Alouini","School of Computing, Queen’s University, ON, Canada; École Polytechnique Fédérale de Lausanne (EPFL), Lausanne, Switzerland; Electronic Engineering Department, Maynooth University, Ireland; King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia","IEEE Communications Surveys & Tutorials","","2023","PP","99","1","1","Connectivity is an important key performance indicator and a focal point of research in large-scale wireless networks. Due to path-loss attenuation of electromagnetic waves, direct wireless connectivity is limited to proximate devices. Nevertheless, connectivity among distant devices can still be attained through a sequence of consecutive multi-hop communication links, which enables routing and disseminating legitimate information across wireless ad hoc networks. Multi-hop connectivity is also foundational for data aggregation in the Internet of things (IoT) and cyberphysical systems (CPS). On the downside, multi-hop wireless transmissions increase susceptibility to eavesdropping and enable malicious network attacks. Hence, security-aware network connectivity is required to maintain communication privacy, detect and isolate malicious devices, and thwart the spreading of illegitimate traffic (e.g., viruses, worms, falsified data, illegitimate control, etc.). In 5G and beyond networks, an intricate balance between connectivity, privacy, and security is a necessity due to the proliferating IoT and CPS, which are featured with massive number of wireless devices that can directly communicate together (e.g., device-to-device, machine-to-machine, and vehicle-to-vehicle communication). In this regards, graph theory represents a foundational mathematical tool to model the network physical topology. In particular, random geometric graphs (RGGs) capture the inherently random locations and wireless interconnections among the spatially distributed devices. Percolation theory is then utilized to characterize and control distant multi-hop connectivity on network graphs. Recently, percolation theory over RGGs has been widely utilized to study connectivity, privacy, and security of several types of wireless networks. The impact and utilization of percolation theory are expected to further increase in the IoT/CPS era, which motivates this tutorial. Towards this end, we first introduce the preliminaries of graph and percolation theories in the context of wireless networks. Next, we overview and explain their application to various types of wireless networks.","1553-877X","","10.1109/COMST.2023.3336194","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10330785","","Wireless networks;Signal to noise ratio;Tutorials;Interference;Communication system security;Surveys;Graph theory","","","","","IEEE","28 Nov 2023","","","IEEE","IEEE Early Access Articles"
"Grace: Low-Cost Time-Synchronized GPIO Tracing for IoT Testbeds","O. Harms; C. Richter; O. Landsiedel","Kiel University, Germany; Kiel University, Germany; Kiel University, Germany","2022 18th International Conference on Distributed Computing in Sensor Systems (DCOSS)","12 Sep 2022","2022","","","9","16","Testbeds have become a vital tool for evaluating and benchmarking applications and algorithms in the Internet of Things (IoT). Testbeds commonly consist of low-power IoT de-vices augmented with observer nodes providing control, logging, and often also power-profiling. Today, the research community operates numerous testbeds, sometimes with hundreds of IoT nodes, to allow for detailed and large-scale evaluation. Most testbeds, however, lack opportunities for tracing distributed program execution with high accuracy in time, for example, via minimally invasive, distributed GPIO tracing. And the ones that do, like Flocklab, are built from custom hardware, which is often too complex, inflexible, or expensive to use for other research groups.This paper closes this gap and introduces Grace, a low-cost, retrofittable, distributed, and time-synchronized GPIO tracing system built from off-the-shelf components, costing less than €20 per node. Grace extends observer nodes in a testbed with (1) time-synchronization via wireless sub-GHz transceivers and (2) logic analyzers for GPIO tracing and logging, enabling time-synchronized GPIO tracing at a frequency of up to 8 MHz. We deploy Grace in a testbed and show that it achieves an average time synchronization error between nodes of 1.53 μs.","2325-2944","978-1-6654-9512-7","10.1109/DCOSS54816.2022.00013","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9881786","GPIO Logging;GPIO Tracing;Testbed;Internet of Things;IoT;Time-Synchronization","Wireless communication;Wireless sensor networks;Time-frequency analysis;Protocols;Observers;Transceivers;Sensor systems","","","","20","IEEE","12 Sep 2022","","","IEEE","IEEE Conferences"
"EfficientFi: Toward Large-Scale Lightweight WiFi Sensing via CSI Compression","J. Yang; X. Chen; H. Zou; D. Wang; Q. Xu; L. Xie","School of Electrical and Electronics Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronics Engineering, Nanyang Technological University, Singapore; Department of Electrical Engineering and Computer Sciences, University of California at Berkeley, Berkeley, CA, USA; School of Electrical and Electronics Engineering, Nanyang Technological University, Singapore; Department of Electric Power and Energy Systems, KTH Royal Institute of Technology, Stockholm, Sweden; School of Electrical and Electronics Engineering, Nanyang Technological University, Singapore","IEEE Internet of Things Journal","25 Jul 2022","2022","9","15","13086","13095","WiFi technology has been applied to various places due to the increasing requirement of high-speed Internet access. Recently, besides network services, WiFi sensing is appealing in smart homes since it is device free, cost effective and privacy preserving. Though numerous WiFi sensing methods have been developed, most of them only consider single smart home scenario. Without the connection of powerful cloud server and massive users, large-scale WiFi sensing is still difficult. In this article, we first analyze and summarize these obstacles, and propose an efficient large-scale WiFi sensing framework, namely, EfficientFi. The EfficientFi works with edge computing at WiFi access points and cloud computing at center servers. It consists of a novel deep neural network that can compress fine-grained WiFi channel state information (CSI) at edge, restore CSI at cloud, and perform sensing tasks simultaneously. A quantized autoencoder and a joint classifier are designed to achieve these goals in an end-to-end fashion. To the best of our knowledge, the EfficientFi is the first Internet of Things-cloud-enabled WiFi sensing framework that significantly reduces communication overhead while realizing sensing tasks accurately. We utilized human activity recognition (HAR) and identification via WiFi sensing as two case studies, and conduct extensive experiments to evaluate the EfficientFi. The results show that it compresses CSI data from 1.368 Mb/s to 0.768 kb/s with extremely low error of data reconstruction and achieves over 98% accuracy for HAR.","2327-4662","","10.1109/JIOT.2021.3139958","NTU Presidential Postdoctoral Fellowship, “Adaptive Multimodal Learning for Robust Sensing and Recognition in Smart Cities” Project Fund, in Nanyang Technological University, Singapore; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9667414","Channel state information (CSI);deep neural network;discrete representation learning;multitask learning;variational autoencoder;WiFi-based sensing","Sensors;Wireless fidelity;Servers;Cloud computing;Feature extraction;Internet of Things;Deep learning","","21","","43","IEEE","3 Jan 2022","","","IEEE","IEEE Journals"
"FLIP-FLexible IoT Path Programming Framework for Large-scale IoT","S. Shahzad; E. -S. Jung","Department of Electronics and Computer Engineering, Hongik University, Korea; Department of Software and Communication Engineering, Hongik University, Korea","2020 20th IEEE/ACM International Symposium on Cluster, Cloud and Internet Computing (CCGRID)","14 Jul 2020","2020","","","881","888","With the rapid increase in smart objects forming IoT fabric, it is likely to see billions of devices connected to the internet, forming large-scale IoT networks. This fast growth in IoT gave rise to network complexity and increased user requirements. Collecting data from these IoT devices with optimal network utilization and simplicity is becoming more and more challenging. This paper proposes FLIP- FLexible IoT Path Programming Framework for Large-scale IoT. FLIP focuses on the IoT fabric from the perspective of user requirements. It uses Software Defined Networking (SDN) techniques along with Deep Packet Inspection (DPI) technology to efficiently fulfill these requirements and establish datapath in the network in an automated and distributed manner. FLIP utilizes SDN’s core capabilities like datapath programming and centralized view of the network to apply in-network computing and automated datapath establishment to optimize overall network utilization. We evaluated our framework through experiments, and results indicate that FLIP has the potential to fulfill user requirements in an automated fashion and optimize network utilization.","","978-1-7281-6095-5","10.1109/CCGrid49817.2020.00014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9139679","SDN;DPI;Fog computing;Large-scale IoT","Engines;Cloud computing;Network topology;Topology;Delays;Routing;Base stations","","1","","18","IEEE","14 Jul 2020","","","IEEE","IEEE Conferences"
"Over-the-Air Computation for Distributed Systems: Something Old and Something New","Z. Chen; E. G. Larsson; C. Fischione; M. Johansson; Y. Malitsky",NA; NA; NA; NA; NA,"IEEE Network","","2023","PP","99","1","7","Facing the upcoming era of Internet-of-Things and connected intelligence, efficient information processing, computation, and communication design becomes a key challenge in large-scale intelligent systems. Recently, Over-the-Air (OtA) computation has been proposed for data aggregation and distributed computation of functions over a large set of network nodes. Theoretical foundations for this concept exist for a long time, but it was mainly investigated within the context of wireless sensor networks. There are still many open questions when applying OtA computation in different types of distributed systems where modern wireless communication technology is applied. In this article, we provide a comprehensive overview of the OtA computation principle and its applications in distributed learning, control, and inference systems, for both server-coordinated and fully decentralized architectures. Particularly, we highlight the importance of the statistical heterogeneity of data and wireless channels, the temporal evolution of model updates, and the choice of performance metrics, for the communication design in OtA federated learning (FL) systems. Several key challenges in privacy, security, and robustness aspects of OtA FL are also identified for further investigation.","1558-156X","","10.1109/MNET.126.2200205","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10155550","","Wireless communication;Computational modeling;Servers;Wireless sensor networks;Data models;Distributed databases;Communication system security","","1","","","IEEE","19 Jun 2023","","","IEEE","IEEE Early Access Articles"
"Large-Scale Expensive Optimization with a Switching Strategy","M. Sun; C. Sun; X. Li; G. Zhang; F. Akhtar","School of Computer Science and Technology, Taiyuan University of Science and Technology, Taiyuan, China; School of Computer Science and Technology, Taiyuan University of Science and Technology, Taiyuan, China; School of Computer Science and Technology, Taiyuan University of Science and Technology, Taiyuan, China; School of Computer Science and Technology, Taiyuan University of Science and Technology, Taiyuan, China; Department of Computer Sciences and Information Technology, University of Kotli Azad Jammu and Kashmir, Kotli, Pakistan","Complex System Modeling and Simulation","30 Sep 2022","2022","2","3","253","263","Some optimization problems in scientific research, such as the robustness optimization for the Internet of Things and the neural architecture search, are large-scale in decision space and expensive for objective evaluation. In order to get a good solution in a limited budget for the large-scale expensive optimization, a random grouping strategy is adopted to divide the problem into some low-dimensional sub-problems. A surrogate model is then trained for each sub-problem using different strategies to select training data adaptively. After that, a dynamic infill criterion is proposed corresponding to the models currently used in the surrogate-assisted sub-problem optimization. Furthermore, an escape mechanism is proposed to keep the diversity of the population. The performance of the method is evaluated on CEC'2013 benchmark functions. Experimental results show that the algorithm has better performance in solving expensive large-scale optimization problems.","2097-3705","","10.23919/CSMS.2022.0013","National Natural Science Foundation of China(grant numbers:61876123); Shanxi Key Research and Development Program(grant numbers:202102020101002); Natural Science Foundation of Shanxi Province(grant numbers:201901D111264,201901D111262); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9906551","large-scale optimization problems;computationally expensive problems;random grouping;surrogate models","Adaptation models;Heuristic algorithms;Sociology;Training data;Switches;Search problems;Robustness","","3","","46","","30 Sep 2022","","","TUP","TUP Journals"
"On Predicting Sensor Readings With Sequence Modeling and Reinforcement Learning for Energy-Efficient IoT Applications","R. Laidi; D. Djenouri; I. Balasingham","CERIST, Algiers, Algeria; Department of Computer Science and Creative Technologies, CSRS, University of the West of England, Bristol, U.K.; Department of Electronic Systems, Norwegian University of Science and Technology, Trondheim, Norway","IEEE Transactions on Systems, Man, and Cybernetics: Systems","18 Jul 2022","2022","52","8","5140","5151","Prediction of sensor readings in event-based Internet-of-Things (IoT) applications is considered. A new approach is proposed, which allows turning off sensors in periods when their readings can be predicted, thus preserving energy that would be consumed for sensing and communications. The proposed approach uses a long short-term memory (LSTM) model that learns spatiotemporal patterns in sequences of sensorial data for future predictions. The LSTM model and the sensors collaboratively monitor the environment. They are controlled by a reinforcement learning (RL) agent that dynamically decides about using the LSTM prediction versus physical sensing in a way that maximizes energy saving while maintaining prediction accuracy. Two approaches are used for the RL: 1) the Markov decision process (MDP) model-based for low scale applications and 2) deep  ${Q}$ -Network-based for larger scales. Compared to the current literature, the proposed solution is unique in predicting all sensor readings for real-time event detection and providing a model capable of learning long-term spatiotemporal correlations, enabling power conservation and detection accuracy balance. We compare the proposed solutions to the most relevant state-of-the-art approaches using a large real dataset collected in a dynamic space by measuring the accuracy, consumed energy, network lifetime, latency, and missed events’ ratio. To investigate the scalability of the solutions, these parameters are calculated for different network sizes. The results show that the system achieves 50% accuracy with 32% of activation time and 75% accuracy with 60% activation time.","2168-2232","","10.1109/TSMC.2021.3116141","CERIST Algeria; UWE Bristol, U.K.; NTNU Trondheim, Norway; Arab–German Young Academy of Sciences and Humanities (AGYA) through the German Federal Ministry of Education and Research (BMBF)(grant numbers:01DL20003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9563048","Deep learning;deep Q-learning;dynamic programming (DP);energy-efficient Internet-of-Things (IoT) applications;recurrent neural networks (RNN);reinforcement learning (RL);sensor readings prediction;sequence modeling","Sensors;Data models;Spatiotemporal phenomena;Predictive models;Correlation;Internet of Things;Reinforcement learning","","4","","45","IEEE","7 Oct 2021","","","IEEE","IEEE Journals"
"A Complementary Sensing Platform for a holistic approach to Allergic Rhinitis monitoring","A. Bardoutsos; G. Matzarapis; S. Nikoletseas; P. G. Spirakis; P. Tzamalis","Computer Engineering and Informatics Department, University of Patras, Patras, Greece; Computer Engineering and Informatics Department, University of Patras, Patras, Greece; Computer Engineering and Informatics Department, University of Patras, Patras, Greece; Computer Engineering and Informatics Department, University of Patras, Patras, Greece; Computer Engineering and Informatics Department, University of Patras, Patras, Greece","2021 17th International Conference on Distributed Computing in Sensor Systems (DCOSS)","17 Nov 2021","2021","","","171","180","Allergic diseases and, in particular, allergic rhinitis are among the most common chronic diseases, inducing disturbances in daily activities. They are caused primarily by the pollens of allergenic plants and symptoms can deteriorate due to various ambient conditions which work as irritants, such as humidity. In this paper, we present the development of an eHealth/mHealth holistic platform that utilizes the technologies of Internet of Things (IoT), Mobile Crowdsensing (MCS), Social Networking Services, Natural Language Processing (NLP), and Machine Learning (ML), in order to work as a sentinel and disease prevention tool for patients with allergic rhinitis symptoms. By efficiently combining human with machine intelligence, we provide a complementary sensing method for the comprehensive and large-scale monitoring of the disease in broad regions, and in real-time. Moreover, the users of our platform are encouraged to engage in the sensing process through a personalized health monitoring system in order to keep a constant awareness of their symptoms and, thus, deliver a successful adherence to their treatment. As an important use case, we adapted our platform to the USA region, but it can be easily extended to any other area with minor modifications. The design and complete implementation of our platform has been performed and validated in close cooperation with well-recognized academic medical doctors based in Greece who specialize in the control of allergic diseases (and rhinitis in particular) and provided valuable insights and detailed requirements analysis about the functionality and usability of the platform. To the best of our knowledge, this is the first study that examines allergic rhinitis monitoring in a complementary manner and on large scale, with the utilization of hybrid data sources.","2325-2944","978-1-6654-3929-9","10.1109/DCOSS52077.2021.00039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9600063","allergic rhinitis;ehealth;mhealth;IoT;sensors;social media;mobile crowdsensing;machine learning;natural language processing","Social networking (online);Medical services;Tools;Natural language processing;Sensor systems;Real-time systems;Internet of Things","","1","","16","IEEE","17 Nov 2021","","","IEEE","IEEE Conferences"
"Environment Friendly based Industry Safety System with IoT","P. Anandan; G. Suresh; N. Anbuselvan; N. Kumaratharan; K. Sasikala","Department of Electronics and Communication Engineering, Saveetha School of Engineering, Saveetha Institute of Medical and Technical Sciences, Saveetha University, Chennai, Tamnilnadu, India; Department of Electronics and Communication Engineering, Sri Indu College of Engineering and Technology, Hyderabad, Telangana, India; Department of Electronics and Communication Engineering, Saveetha School of Engineering, Saveetha Institute of Medical and Technical Sciences, Saveetha University, Chennai, Tamnilnadu, India; Department of Electronics and Communication Engineering, Sri Venkateswara College ofEngineering, Chennai, Tamil Nadu, India; Department of Electrical and Electronics Engineering, Vels Institute of Science Technology & Advanced Studies (VISTAS), Chennai, Tamil Nadu, India","2023 7th International Conference on Computing Methodologies and Communication (ICCMC)","4 Apr 2023","2023","","","1365","1369","In today's fast-paced environment, industrial monitoring is essential because everyone expects to obtain a scalable outcome. Presently days, monitoring and controlling industrial parameters like temperature, humidity, gas, and so forth takes more manual labor. This is the industrial sectors' most pressing concern right now. A dangerous condition results from improper parameter monitoring and control. Due to human error, the majority of industries are currently experiencing this. The industrial monitoring and Internet of Things (IoT) module is used to reduce manual errors. In general, there are various ways available today to do this. Using GSM, this article demonstrates how a person may monitor and control industrial equipment. Regularly transmitting precise and trustworthy measurements is essential for monitoring large-scale businesses and nuclear power plants. Sensors are used to measure temperature, pressure, gas, and other variables, such as the need for accuracy. These sensor readings must be updated in real-time. A microcontroller is connected to sensors in this system. ZIGBEE wireless technology is used for data transmission, and WAN is used if necessary to connect to the Internet. To determine the threshold value, all measured values are compared against when a discrepancy occurs, and staff will be notified so they may take remedial as a novel strategy. Microcontrollers are used in nuclear power plants and large-scale enterprises to prevent severe disasters.","","978-1-6654-6408-6","10.1109/ICCMC56507.2023.10083604","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10083604","Monitoring;Power;Alert;Global System for Mobile communication;Safety","Temperature measurement;Temperature sensors;Industries;Microcontrollers;Zigbee;Manuals;Sensors;Internet of Things;Monitoring;Power generation","","","","17","IEEE","4 Apr 2023","","","IEEE","IEEE Conferences"
"Lime: Low-Cost and Incremental Learning for Dynamic Heterogeneous Information Networks","H. Peng; R. Yang; Z. Wang; J. Li; L. He; P. S. Yu; A. Y. Zomaya; R. Ranjan","State Key Laboratory of Software Development Environment, Beijing Advanced Innovation Center for Big Data and Brain Computing, Beihang University, Beijing, China; School of Computing, University of Leeds, Leeds, U.K; School of Computing, University of Leeds, Leeds, U.K; State Key Laboratory of Software Development Environment, Beijing Advanced Innovation Center for Big Data and Brain Computing, Beihang University, Beijing, China; Department of Computer Science and Engineering, Lehigh University, Bethlehem, PA, USA; Department of Computer Science, University of Illinois at Chicago, Chicago, IL, USA; University of Sydney, Camperdown, NSW, Australia; Computing Science and Internet of Things, Newcastle University, Newcastle upon Tyne, U.K","IEEE Transactions on Computers","10 Feb 2022","2022","71","3","628","642","Understanding the interconnected relationships of large-scale information networks like social, scholar and Internet of Things networks is vital for tasks like recommendation and fraud detection. The vast majority of the real-world networks are inherently heterogeneous and dynamic, containing many different types of nodes and edges and can change drastically over time. The dynamicity and heterogeneity make it extremely challenging to reason about the network structure. Unfortunately, existing approaches are inadequate in modeling real-life dynamical networks as they either have strong assumption of a given stochastic process or fail to capture the heterogeneity of network structure, and they all require extensive computational resources. We introduce Lime, a better approach for modeling dynamic and heterogeneous information networks. Lime is designed to extract high-quality network representation with significantly lower memory resources and computational time over the state-of-the-arts. Unlike prior work that uses a vector to encode each network node, we exploit the semantic relationships among network nodes to encode multiple nodes with similar semantics in shared vectors. By using many fewer node vectors, our approach significantly reduces the required memory space for encoding large-scale networks. To effectively trade information sharing for reduced memory footprint, we employ the recursive neural network (RsNN) with carefully designed optimization strategies to explore the node semantics in a novel cuboid space. We then go further by showing, for the first time, how an effective incremental learning approach can be developed – with the help of RsNN, our cuboid structure, and a set of novel optimization techniques – to allow a learning framework to quickly and efficiently adapt to a constantly evolving network. We evaluate Lime by applying it to three representative network-based tasks, node classification, node clustering and anomaly detection, performing on three large-scale datasets. We compare Lime against eleven prior state-of-the-art approaches for learning network representation. Our extensive experiments demonstrate that Lime not only reduces the memory footprint by over 80 percent and the processing time over 2x when learning network representation but also delivers comparable performance for downstream processing tasks. We show that our incremental learning method can boost the learning time by up to 20x without compromising the quality of the learned network representation.","1557-9956","","10.1109/TC.2021.3057082","National Natural Science Foundation of China(grant numbers:62002007,U20B2053); Key Research and Development Project of Hebei Province(grant numbers:20310101D); U.K. EPSRC(grant numbers:EP/T01461X/1,EP/T021985/1); UK Royal Society International Collaboration(grant numbers:NERC (NE/P017134/1),SKLSDE-2020ZX-12); Australian Research Council(grant numbers:DP200103494); NSF ONR(grant numbers:N00014-18-1-2009); National Science Foundation(grant numbers:III-1763325,III-1909323,SaTC-1930941); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9353275","Network representation learning;heterogeneous information networks;incremental learning;memory optimization","Task analysis;Social networking (online);Heuristic algorithms;Computational modeling;Optimization;Semantics;Recurrent neural networks","","40","","43","IEEE","11 Feb 2021","","","IEEE","IEEE Journals"
"Cooperative-Evolution-Based WPT Resource Allocation for Large-Scale Cognitive Industrial IoT","L. Sun; L. Wan; K. Liu; X. Wang","Department of Communication Engineering, Institute of Information Science Technology, Dalian Maritime University, Dalian, China; Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, School of Software, Dalian University of Technology, Dalian, China; National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China, Chengdu, China; State Key Laboratory of Marine Resource Utilization in South China Sea and College of Information Science and Technology, Hainan University, Haikou, China","IEEE Transactions on Industrial Informatics","29 Apr 2020","2020","16","8","5401","5411","The recently developed technique of wireless power transfer (WPT) provides a promising way to charge the wireless sensor networks (WSNs) of cognitive industrial Internet of Things (IoT) deployed in areas that are difficult for humans to access. Previous work has focused on the power allocation strategy at the wireless node level. However, the priority among different modes in an identical wireless node has not been taken into consideration, and different modes equipped with different types of batteries accomplish different tasks in an identical wireless node. One challenging scenario is rechargeable WSNs with a large number of wireless nodes. In this article, we aim to optimize the power allocation strategy in priority constraint WPT systems with a large number of wireless nodes. Traditional WPT systems consist of a rechargeable WSN and a mobile charger, which are deployed for charging wireless nodes in a wireless manner. However, the constructed WPT system consists of a rechargeable WSN and multiple mobile chargers with adequate power, which can charge wireless nodes simultaneously. Each solution of the power allocation strategy can be represented as one disjunctive graph, and the critical path (CP) in the disjunctive graph is the core factor in determining the final maximum cost. Thus, we propose a decomposition strategy that can identify the interacting variables based on the CP by exploiting the perturbation technique. Then, the decomposed subcomponents are cooperatively evolved by adopting a cooperative evolutionary algorithm (CEA). The proposed CP-based grouping strategy combined with CEA is named CPCEA. Three state-of-the-art methods are tested and compared with CPCEA, and three scales of datasets are considered. The experimental results demonstrate the validity of CPCEA.","1941-0050","","10.1109/TII.2019.2961659","National Natural Science Foundation of China(grant numbers:61701144,61801076); Program of Hainan Association for Science and Technology Plans to Youth R&D Innovation(grant numbers:QCXM201706); Scientific Research Projects of University in Hainan Province(grant numbers:Hnky2018ZD-4); Young Elite Scientists Sponsorship Program by CAST(grant numbers:2018QNRC001); Scientific Research Setup Fund of Hainan University(grant numbers:(ZR)1731); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8939416","Cooperative coevolution;large-scale optimization;priority constraint;wireless power transfer (WPT)","Wireless sensor networks;Wireless communication;Sensors;Resource management;Batteries;Task analysis;Indexes","","38","","25","IEEE","23 Dec 2019","","","IEEE","IEEE Journals"
"Enabling Variable High Spatial Resolution Retrieval From a Long Pulse BOTDA Sensor","Z. Ge; L. Shen; C. Zhao; H. Wu; Z. Zhao; M. Tang","School of Optical and Electronic Information, Huazhong University of Science and Technology, Wuhan, China; School of Optical and Electronic Information, Huazhong University of Science and Technology, Wuhan, China; School of Optical and Electronic Information, Huazhong University of Science and Technology, Wuhan, China; School of Optical and Electronic Information, Huazhong University of Science and Technology, Wuhan, China; School of Optical and Electronic Information, Huazhong University of Science and Technology, Wuhan, China; School of Optical and Electronic Information, Huazhong University of Science and Technology, Wuhan, China","IEEE Internet of Things Journal","5 Jan 2023","2023","10","2","1813","1821","Spatial resolution (SR) is one of the most important parameters of Brillouin optical time-domain analysis (BOTDA) sensors, which determines the minimum length that a perturbation event can be distinguished. In the field of Internet of Things (IoT), there is an urgent need for sensors with large-scale high-precision sensing capability for scenarios, such as intelligent monitoring of production lines and urban infrastructure. Conventionally, the SR is normally restricted to be longer than 1 m due to the  $\sim 10$ -ns acoustic lifetime limitation in silica optical fibers. For long-distance smart monitoring systems, the SR is generally on the order of several meters or even worse. However, it does not meet the needs of many applications. Therefore, there is an urgent need to achieve SR in the submeter magnitude. In this work, for the first time to the best of our knowledge, we propose a convolutional neural network (CNN) to process the data of conventional BOTDA sensors, which achieves unprecedented performance improvement that allows to directly retrieve submeter SR from the sensing system that use long pump pulses. By using the simulated Brillouin gain spectrums (BGSs) as the CNN input and the corresponding high SR Brillouin frequency shift (BFS) as the output target, the trained CNN is able to obtain an SR higher than the theoretical value determined by the pump pulse width. In the experiment, the CNN accurately retrieves 0.5-m hotspots from the measured BGS with pump pulses from 20 to 50 ns, and the acquired BFS is in great agreement with 45/40 ns differential pulse-width pair (DPP) measurement results. Compared with the DPP technique, the proposed CNN demonstrates a twofold improvement in BFS uncertainty with only half the measurement time. In addition, by changing the training data sets, the proposed CNN can obtain tunable high SR retrieval based on conventional BOTDA sensors that use long pulses without any requirement of hardware modifications. It is worth mentioning that the proposed method is also applicable to larger pulse widths to retrieve a submeter SR. The proposed data post-processing approach paves the way to enable novel high SR BOTDA sensors, which brings substantial improvement over the state-of-the-art techniques in terms of system complexity, measurement time, reliability, etc.","2327-4662","","10.1109/JIOT.2022.3209674","National Key Research and Development Program of China(grant numbers:2018YFB1801002); National Natural Science Foundation of China(grant numbers:61931010); Fundamental Research Funds for the Central Universities(grant numbers:HUST: 2021XXJS026); Hubei Province Key Research and Development Program(grant numbers:2020BAA006); Innovation Fund of WNLO; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9903805","Brillouin scattering;convolutional neural network (CNN);distributed optical fiber sensors;signal processing","Convolutional neural networks;Pulse measurements;Scattering;Optical fiber sensors;Monitoring;Time measurement;Optical fibers","","3","","39","IEEE","27 Sep 2022","","","IEEE","IEEE Journals"
"Enhanced edge offloading using Reinforcement learning","A. Jain; N. Goveas","BITS Pilani, Goa campus; BITS Pilani, Goa campus","2022 International Conference on Connected Systems & Intelligence (CSI)","1 Nov 2022","2022","","","1","9","Internet of Things (IoT) based solutions requiring real time results from intensive computation tasks or having large scale data analysis have traditionally been designed with offloading of the work to cloud infrastructure. This has been found to be not an ideal solution due to several issues related to network uncertainties, cost of cloud usage etc. This is especially true for systems with both hard time constraints and large amount of data. Edge computing, with its hierarchical configuration has been proposed to solve these issues. This has led to researchers proposing several algorithms to optimise offloading of computation to the layers of this hierarchy. In this work we propose the use of an actor-critic based reinforcement learning mechanism to solve the offloading planning for a general hierarchical system with multiple end nodes and multiple edge servers. Our simulation based results shows that the proposed method improves the performance of the system as compared to the existing benchmark offloading policies.","","978-1-6654-5815-3","10.1109/CSI54720.2022.9924023","NVIDIA; Abdus Salam International Center for Theoretical Physics; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9924023","edge computing;offloading;reinforcement learning;actor-critic;deep learning","Energy consumption;Cloud computing;Uncertainty;Computational modeling;Simulation;Reinforcement learning;Delays","","1","","24","IEEE","1 Nov 2022","","","IEEE","IEEE Conferences"
"HRMP3+TECS: Component Framework for Multiprocessor Real-time Operating System with Memory Protection","Y. Takaso; H. Oyama; H. Takada; T. Azumi","Graduate School of Science and Engineering, Saitama University; OKUMA Corporation; Institutes of Innovation for Future Society Nagoya University; Graduate School of Science and Engineering, Saitama University","2023 IEEE 26th International Symposium on Real-Time Distributed Computing (ISORC)","2 Aug 2023","2023","","","86","96","The scale and demand for protection functionalities in embedded systems continue to grow as Internet of things technology develops. Simultaneously, multiprocessor real-time operating systems (RTOSs) with memory protection functionalities are broadening in use. On the other hand, the large development effort and poor reusability of multiprocessor RTOS-based development remain hindrances to their use. To solve this problem, this paper proposes a component framework for multiprocessor RTOSs that includes memory protection. In the proposed framework, OS functionalities are reframed as components. The allocation of objects to processors and protection settings, which are supported by the OS, can then be configured based on the component description. Plugins are implemented here to generate files for object generation from component descriptions of OS functionalities. In addition, access to the protection domain can be defined based on the component description. Finally, test programs are used in a performance evaluation. The proposed framework enables extensions to the component-based OS while maintaining most of the functionality and performance of the target OS.","2770-162X","979-8-3503-3902-4","10.1109/ISORC58943.2023.00021","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10196974","Embedded Systems;Component-based Development;Multiprocessors;Real-time Operating Systems;Memory Protection","Performance evaluation;Couplings;Program processors;Embedded systems;Real-time systems;Reliability;Resource management","","","","23","IEEE","2 Aug 2023","","","IEEE","IEEE Conferences"
"Monitoring Cyber SentiHate Social Behavior During COVID-19 Pandemic in North America","F. Alzamzami; A. E. Saddik","Multimedia Communication Research Laboratory, School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, Canada; Multimedia Communication Research Laboratory, School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, Canada","IEEE Access","29 Jun 2021","2021","9","","91184","91208","With communications being shifted to online social networks (OSNs) as a result of travel and social restrictions during COVID-19 pandemic, the need has arisen for discovering emerging trends and concerns formed during the pandemic as well as understanding the corresponding online social behavior that reflects its offline settings. The online connectivity of devices through social media is one example of Internet of Things (IoT) in which a two-way communication between societies and officials, could be created. Therefore, it is possible to monitor people’s behavior through OSNs, especially during pandemics, to prevent potential social and psychological instabilities that might lead to undesired consequences. This is particularly crucial for governmental and non-governmental organizations to ensure the stability and well-being in societies. In response, we propose a pandemic-friendly real-time framework for monitoring cyber social behavior by utilizing unsupervised and supervised learning approaches. Two BERT-based supervised classifiers are trained and constructed to analyze two types of online social behaviors, hate and sentiment. Unsupervised framework is proposed for OSNs data exploration and coherent interpretation that is used as a complementary tool to facilitate the analysis of online social behaviors during pandemics. Extensive experimentation and evaluation have been conducted to validate the effectiveness of the proposed work. Our results have shown superior performance of our BERT-based models in two classification tasks: 1) binary classification for hate behavior detection and 2) multi-class classification for sentiment behavior detection. In addition to our experimentation results, our large-scale analysis of COVID-19 pandemic has illustrated the capability of our unsupervised framework for concerns and trends discoveries using OSNs data, along with reliability in automatically and dynamically providing phrase-based interpenetration of the inferred trends and concerns. This paper provides a twelve-month comparison analysis of data discoveries and online social behavior between Canada and USA during COVID-19 pandemic.","2169-3536","","10.1109/ACCESS.2021.3088410","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9452177","Hate speech;sentiment;topic modeling;BERT;topic interpretation;phrase extraction;RAKE;online social media;online social behavior;Covid-19;tweets;twitter","Pandemics;COVID-19;Social networking (online);Market research;Monitoring;Data models;Real-time systems","","7","","85","CCBY","11 Jun 2021","","","IEEE","IEEE Journals"
"SAVIOR: A Sustainable Network of Vehicles with Near-Perpetual Mobility","P. Chakraborty; R. N. Dizon-Paradis; S. Bhunia","University of Maine, USA; University of Florida, USA; University of Florida, USA","IEEE Internet of Things Magazine","6 Jun 2023","2023","6","2","108","114","Switching to Battery Electric Vehicles (BEV) can have a significant positive impact on our environment. However, the adoption of BEVs is vastly impeded by battery-related concerns, such as limited travel range, long charging time, high purchasing cost (battery-induced) and lack of charging stations. Additionally, it is very expensive to build a large infrastructure of fast charging stations that can cater to a full-scale BEV fleet. Alternative solutions, such as charging from the road and BEV-to-BEV stationary charge sharing, have been proposed to counteract range anxiety, but they are mostly ineffective and suffer from scalability issues. In this article, we present SAVIOR, an innovative Internet-of-Things (IoT) framework for replenishing BEV batteries on-the-go with the help of unmanned aerial vehicles (UAVs) and mobile charging stations (MoCS). This will allow rapid BEV battery replenishment, eliminating the need for BEVs to make prolonged and pre-planned halts for re-charging. We also observe that package delivery UAVs can utilize this framework to make long-distance trips with the help of mobile charging stations and BEVs. We quantitatively analyze the effectiveness of such a framework through a simulation platform that we have developed. There is a drastic improvement in the mobility of BEVs and UAVs. Through statistical analysis, we also observe that greenhouse gas emissions (even for BEVs and UAVs) can be significantly reduced by SAVIOR if the MoCS are powered by renewable energy sources (e.g., solar).","2576-3199","","10.1109/IOTM.001.2200201","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10145032","","Symbiosis;Statistical analysis;Scalability;Switches;Charging stations;Autonomous aerial vehicles;Batteries","","","","15","IEEE","6 Jun 2023","","","IEEE","IEEE Magazines"
"A Millimeter-Scale Computing System with Adaptive Dynamic Load Power Tracking","S. Jeong; Y. Kim; Y. Li; I. Lee",CubeWorks; CubeWorks; University of Pittsburgh; University of Pittsburgh,"2021 IEEE Asian Solid-State Circuits Conference (A-SSCC)","10 Dec 2021","2021","","","1","3","A computing system has been continuously miniaturized, and larger number of small IoT devices become a part of our ubiquitous lives. Recently, the size of the systems reached down to a millimeter scale, and they demonstrate new sensing approaches in ecological, biomedical, and security applications [1] –[3]. As an example, Fig. 1(a) shows a millimeter-scale layer-stacked system, constructed by vertically stacking bare die, maximizing the planar circuit area for a given volume. This platform miniaturizes a computing system down to a millimeter scale mainly by avoiding individually packaged discrete components [4]. The miniaturization results in reduced battery capacity, limiting energy available for the integrated circuits. For example, a 9.8-mm2 thin-film lithium battery stores charge of only $15 \mu$ Ah, allowing the average current draw of 21nA (84nW) for system lifetime of 1 month [5]. The lithium battery provides higher voltage (e.g., 4V) than what a standard CMOS transistor can tolerate, requiring a high-efficient Power Management Unit (PMU) that converts the battery voltage to lower voltages (e.g., 1.5V). Due to size constraint, PMUs for the small systems have been designed with on-chip capacitors instead of bulky discrete inductors [4], [6].","","978-1-6654-4350-0","10.1109/A-SSCC53895.2021.9634758","University of Pittsburgh; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9634758","","Power system management;Stacking;Voltage;Lithium batteries;Phasor measurement units;System-on-chip;Sensors","","","","7","IEEE","10 Dec 2021","","","IEEE","IEEE Conferences"
"UMUcast: A Framework for Massive Small-Data Delivering in Industrial Internet of Things","W. -K. Jia; Y. -C. Chen; X. Wang","College of Photonic and Electronic Engineering, Fujian Normal University, Fuzhou, China; Department of Computer Science, National Chiao Tung University, Hsinchu, Taiwan; College of Photonic and Electronic Engineering, Fujian Normal University, Fuzhou, China","IEEE Journal on Selected Areas in Communications","16 Mar 2021","2021","39","4","1160","1176","As a key infrastructure of Industry 4.0, Industrial Internet-of-Things (IIoT) promises the opportunity to build powerful industrial environments by leveraging the growing ubiquity of wired and wireless communication technologies. Designing a data delivery scheme in the future IIoT networks is undoubtedly a challenging task, as it should satisfy several conflicting requirements: massive-scale, data-intensive, and mission-critical, the requirements of which have motivated the desired need for feasible IIoT network architecture. In particular, the traffic characteristics of certain IIoT applications feature small-data patterns especially in typical automation control scenarios such as robot control on the downlink. In order to reduce the huge overhead associated with each individual unicast transmission of the small-data message, we propose a novel “multipoint-to-multipoint” and/or “point-to-multipoint with different contents” communication paradigm-Uni-Multi-Unicast (UMUcast), which is based-on traditional 4G technologies such as evolved Multimedia Broadcast Multicast Service (eMBMS) and Group Communication System Enablers (GCSE), and novel 5G technologies such as Multi-Access Edge Computing (MEC). For the downlink, the UMUcast transmitter can jointly encode multiple-sources' small-data messages into a single chunk at MEC equipment in conjoint with a gNB, where chunk can be one-off transmission to multiple receivers simultaneously through an eMBMS frame, whereas the chunk is decoded into multiple small-data by each individual IIoT devices separately and respectively. The simulation results show that UMUcast has remarkable improvements over conventional point-to-point unicasting in handling multi-source, multi-destination, and massive small-data delivery with characteristics of low-overhead, high-throughput, and ultra-low-latency for future 5G-based IIoT networks.","1558-0008","","10.1109/JSAC.2020.3018828","National Natural Science Foundation of China(grant numbers:61871131,61701118,U1805262); Natural Science Foundation of Fujian Province, China(grant numbers:2018J05101,2018H6007,2019J01267); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9174812","mMTC;small-data;arithmetic aggregation;massive access;IIoT;LTE","Industries;Downlink;5G mobile communication;Wireless communication;Automation;Servers;Uplink","","5","","48","IEEE","24 Aug 2020","","","IEEE","IEEE Journals"
"Cost-Efficient and Trust-Aware Virtual Network Embedding for Dense Industrial IoT Systems Using Multiagent Systems","P. Rezaeimoghaddam; I. Al-Anbagi","Faculty of Engineering and Applied Science, University of Regina, Regina, Canada; Faculty of Engineering and Applied Science, University of Regina, Regina, Canada","IEEE Transactions on Network and Service Management","7 Feb 2024","2024","21","1","1100","1114","Network virtualization in wireless sensor networks (WSNs) enables the utilization of shared sensing capabilities in many industrial Internet of Things (IIoT) applications. Efficient assignment of WSN resources can be achieved through virtual network embedding (VNE) while considering the quality of information (QoI) (as the accuracy of sensing), the quality of service (QoS) (as the reliability), and wireless interference handling constraints. The more the virtual networks can be mapped onto the substrate network, the more revenue the infrastructure provider will acquire. Therefore improving the acceptance rate of VNE is essential. However, this may lead to occupying more network resources and links and increase the cost, especially in dense networks. On the other hand, the shared and complex nature of VNE exposes WSNs to security risks. In this paper, we develop a novel offline distributed trust-aware virtual wireless sensor networks (DTA-VWSN) algorithm to maximize the virtual networks acceptance rate while minimizing the cost. Our proposed algorithm considers the QoI, QoS, and security, by adding required trust level constraints to virtual nodes and links and trust level constraints to the substrate counterparts. Since centralized algorithms suffer from scalability issues, this paper presents our new approach to the virtual network embedding problem in a distributed manner. In this paper, we use the techniques of multiagent systems as a well-known approach for distributed systems to scale these algorithms to network size. Our DTA-VWSN algorithm achieves a high-quality sub-optimal solution in a short duration, enabling us to investigate the tradeoff between solution quality and search time. Our algorithm is also evaluated in large-scale network scenarios to verify all enforced limitations by the WSN substrate. Simulation results show that DTA-VWSN improves the virtual network acceptance ratio, cost, and execution time in large-scale substrate networks. For instance, in a scenario with 150 substrate nodes and 6 VNRs, the accuracy of DTA-VWSN compared with the optimal value in terms of the VNR acceptance rate and the cost is 91.6% and 94.5%, respectively, while the execution time is 68.35% faster.","1932-4537","","10.1109/TNSM.2023.3307013","Natural Sciences and Engineering Research Council of Canada (NSERC)(grant numbers:RGPIN-2019-06060); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10225589","Graph partitioning;multiagent systems;virtual network embedding (VNE);industrial Internet of Things (IIoT);wireless sensor networks (WSNs);quality of information (QoI);quality of service (QoS);trustawareness","Wireless sensor networks;Substrates;Security;Quality of service;Industrial Internet of Things;Costs;Scalability","","","","40","IEEE","21 Aug 2023","","","IEEE","IEEE Journals"
"Maximum Likelihood Estimators for Three-Dimensional Rigid Body Localization in Internet of Things Environments","L. Ai; C. Jing; Y. Chen; S. Wu; T. Zhang","IoT Engineering Research Center of the Ministry of Education, Jiangnan University, Wuxi, China; Department of Informatics, Linyi University, Linyi, China; Department of Computer Science, University of California at Davis, Davis, CA, USA; IoT Engineering Research Center of the Ministry of Education, Jiangnan University, Wuxi, China; IoT Engineering Research Center of the Ministry of Education, Jiangnan University, Wuxi, China","IEEE Access","18 Nov 2020","2020","8","","201458","201467","Different from the conventional point source localization, rigid body localization (RBL) not only aims to estimate the position of the target but also to acquire the attitude information, which is also essential information in many Internet of Things (IoT) applications, such as the virtual reality systems, smart parking systems. This paper develops three maximum likelihood estimators (MLEs) for the RBL purpose in 3 dimensional space via a single base station. The MLEs are designed for the RBL framework, which adopts the direction of arrival (DoA) of the signal from a small scale wireless sensor network (SSWSN) mounted on the surface of the rigid target as measurement and can be realized by a single base station. The three MLEs respectively exploit the SSWSN topology information, the DoA measurement information only, as well as the equality constraint of the rotation matrix and the DoA measurement information. In addition, we implement the modified Guass-newton algorithm for the MLEs of the rotation matrix and the translation vector. Simulations show that the proposed MLE fusing the equality constraint of the rotation matrix and the DoA measurement information most approaches the Cramer-Rao Lower Bound and also outperforms the other two MLEs in terms of convergence success rate and the computational cost.","2169-3536","","10.1109/ACCESS.2020.3035850","National Natural Science Foundation of China(grant numbers:61703185,61901206); Natural Science Foundation of Jiangsu Province(grant numbers:BK20180597); Higher Education Discipline Innovation Project(grant numbers:B12018); Shandong Provincial Key Research and Development Program (Major Science and Technological Innovation Project)(grant numbers:2019JZZY010134); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9248013","Internet of Things (IoT);maximum likelihood estimator;rigid body localization;direction of arrival;convergence success rate","Maximum likelihood estimation;Wireless sensor networks;Direction-of-arrival estimation;Antenna arrays;Topology;Wireless communication;Base stations","","3","","33","CCBY","4 Nov 2020","","","IEEE","IEEE Journals"
"A Pattern-Based API for Mapping Applications to a Hierarchy of Multi-Core Devices","J. Guo; R. Teodorescu; G. Agrawal","Computer Science and Engineering, Ohio State University, Columbus, OH, 43210; Computer Science and Engineering, Ohio State University, Columbus, OH, 43210; Computer and Cyber Sciences, Augusta University, Augusta, GA","2020 20th IEEE/ACM International Symposium on Cluster, Cloud and Internet Computing (CCGRID)","14 Jul 2020","2020","","","11","20","Recent years have witnessed an evolution of Internet of Things (IoT) devices. This has lead to the emergence of (related) paradigms of Edge/Fog computing, where the goal is to exploit the power of interconnected heterogeneous devices together with distributed/cloud computing. In Edge/Fog computing, one of the challenges is automatically distributing the work between different devices to reduce application latency. At the same time, with increasing transistor density and the end of Denard scaling, even small edge devices have parallelism. Thus, we need a programming model that can help distribute the work between different devices and yet parallelize operations on each device. Motivated by the popularity of MapReduce(-like) frame-works, we develop a pattern-based high-level programming API targeting computer vision applications for the Edge/Fog paradigm with parallelism within devices. Based on this API, parallelization, workload distribution, and optimizations that account for resource limitations of IoT devices, are implemented. Our evaluation with three image processing applications shows that while using a single device, we achieve 17-45% speedup over OpenCV, one of the most popular frameworks for image processing. In addition, we further gain benefits from distributing the work between multiple devices.","","978-1-7281-6095-5","10.1109/CCGrid49817.2020.00-92","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9139746","","Parallel processing;Image edge detection;Programming;Histograms;Optimization;Transforms","","","","36","IEEE","14 Jul 2020","","","IEEE","IEEE Conferences"
"Wi-Fi Based Positioning System for Application in Child Safety","A. L. H. P. S.; V. I. B; R. R. S; V. Kumar","Department of ECE, Ballari Institute of Technology & Management, Ballari, India; Department of ECE, Ballari Institute of Technology & Management, Ballari, India; Department of ECE, Ballari Institute of Technology & Management, Ballari, India; Department of ECE, Ballari Institute of Technology & Management, Ballari, India","2023 International Conference on Distributed Computing and Electrical Circuits and Electronics (ICDCECE)","21 Jun 2023","2023","","","1","5","Parents and event organizers are often concerned about the safety and security of children during large-scale public events. This study addresses the crucial issue and suggests an architecture model for a smart, IoT-enabled digital system for tracking child safety. The Cloud, Mobile, and Wi-Fi modules are integrated into this IoT-enabled digital system architecture to precisely pinpoint a child’s geographic location on an event map. The sophisticated IoT-enabled smart child safety tracking digital system’s complex people, information, process, and technology architecture elements are described, along with their relationships, in the suggested architecture model.","","979-8-3503-4745-6","10.1109/ICDCECE57866.2023.10151356","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10151356","tracking;IoT;Cloud;Mobile and WIFI module","Digital systems;Computational modeling;Computer architecture;Safety;Security;Integrated circuit modeling;Distributed computing","","","","9","IEEE","21 Jun 2023","","","IEEE","IEEE Conferences"
"Data-Driven Many-Objective Crowd Worker Selection for Mobile Crowdsourcing in Industrial IoT","Z. Lu; Y. Wang; X. Tong; C. Mu; Y. Chen; Y. Li","School of Computer and Control Engineering, Yantai University, Yantai, China; School of Computer and Control Engineering, Yantai University, Yantai, China; School of Computer and Control Engineering, Yantai University, Yantai, China; School of Computer and Control Engineering, Yantai University, Yantai, China; CIMC Ocean Engineering Research Institute Company Ltd, Yantai, China; Department of Computer Science, Georgia State University, Atlanta, GA, USA","IEEE Transactions on Industrial Informatics","9 Nov 2022","2023","19","1","531","540","With the development of mobile networks and intelligent equipment, as a new intelligent data sensing paradigm in large-scale sensor applications such as the industrial Internet of Things, mobile crowd sensing (MCS) assigns industrial sensing tasks to workers for data collection and sharing, which has created a bright future for building a strong industrial system and improving industrial services. How to design an effective worker selection mechanism to maximize the utility of crowdsourcing is the research hotspot of mobile sensing technologies. This article studies the problem of least workers selection to make large MCS system perform sensing tasks more effective and achieve certain coverage with certain constraints being meeting. A many-objective worker selection method is proposed to achieve the desired tradeoff and an optimization mechanism is designed based on the enhanced differential evolution algorithm to ensure data integrity and search solution optimality. The effectiveness of the proposed method is verified through a large scale of experimental evaluation datasets collected from real world.","1941-0050","","10.1109/TII.2021.3076811","National Natural Science Foundation of China(grant numbers:62072392,61822602,61772207,61802331,61572418,61602399,61702439,61773331); China Postdoctoral Science Foundation(grant numbers:2019T120732,2017M622691); Key projects of Shandong Natural Science Foundation(grant numbers:ZR2020KF019); Key projects of Shandong Natural Science Foundation(grant numbers:ZR2020KF019); Major scientific and technological innovation projects of Shandong Province(grant numbers:2019JZZY020131); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9420265","Enhanced differential evolution;industrial Internet of Things (IIoT);many-objective optimization;mobile crowd sensing (MCS);worker selection","Task analysis;Sensors;Optimization;Quality of service;Informatics;Crowdsourcing;Real-time systems","","32","","30","IEEE","30 Apr 2021","","","IEEE","IEEE Journals"
"TrustFed: A Framework for Fair and Trustworthy Cross-Device Federated Learning in IIoT","M. H. u. Rehman; A. M. Dirir; K. Salah; E. Damiani; D. Svetinovic","Center for Cyber-Physical Systems, Department of Electrical Engineering and Computer Science, Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates; Center for Cyber-Physical Systems, Department of Electrical Engineering and Computer Science, Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates; Center for Cyber-Physical Systems, Department of Electrical Engineering and Computer Science, Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates; Center for Cyber-Physical Systems, Department of Electrical Engineering and Computer Science, Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates; Center for Cyber-Physical Systems, Department of Electrical Engineering and Computer Science, Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates","IEEE Transactions on Industrial Informatics","26 Aug 2021","2021","17","12","8485","8494","Cross-device federated learning (CDFL) systems enable fully decentralized training networks whereby each participating device can act as a model-owner and a model-producer. CDFL systems need to ensure fairness, trustworthiness, and high-quality model availability across all the participants in the underlying training networks. This article presents a blockchain-based framework, TrustFed, for CDFL systems to detect the model poisoning attacks, enable fair training settings, and maintain the participating devices' reputation. TrustFed provides fairness by detecting and removing the attackers from the training distributions. It uses blockchain smart contracts to maintain participating devices' reputations to compel the participants in bringing active and honest model contributions. We implemented the TrustFed using a Python-simulated federated learning framework, blockchain smart contracts, and statistical outlier detection techniques. We tested it over the large-scale industrial Internet of things dataset and multiple attack models. We found that TrustFed produces better results regarding multiple aspects compared with the conventional baseline approaches.","1941-0050","","10.1109/TII.2021.3075706","Cyber-Physical Systems, Khalifa University of Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9416805","Blockchain;fairness;federated learning;industrial Internet of things (IIoT);reputation;security;trust","Training;Blockchain;Computational modeling;Servers;Data models;Performance evaluation;Industrial Internet of Things","","55","","20","CCBY","27 Apr 2021","","","IEEE","IEEE Journals"
"Deepening Research on the Comprehensive Application and Development of Railway Intelligent Detection and Monitoring System and Key Technologies","Z. Zihui; T. Xinyu; S. Zhiwei","Infrastructure Inspection Reasearch Institute, China Academy of Railway Sciences Corporation Limited, Beijing, China; Infrastructure Inspection Reasearch Institute, China Academy of Railway Sciences Corporation Limited, Beijing, China; Infrastructure Inspection Reasearch Institute, China Academy of Railway Sciences Corporation Limited, Beijing, China","2023 IEEE 7th Information Technology and Mechatronics Engineering Conference (ITOEC)","30 Oct 2023","2023","7","","425","433","By analyzing the current problems in railway transportation safety and the reform status of ""reform of integration of track, communication&signaling and power supply"" of China State Railway Group Co., Ltd, the development trend of railway intelligent inspections and monitoring is proposed, and the integration application of new information technology is analyzed. According to the overall development goal of intelligent high-speed railway 2.0, the research content and technical route of intelligent inspections and monitoring technology are sorted out, and the railway intelligent inspections and monitoring system and management framework of ""platform + application"" mode is proposed. Based on the ""14th Five-Year Plan"" and in accordance with the idea of ""specialty + technology + platform + application"", the paper sorts out the professional safety suggestions and puts forward the development path of intelligent inspections and monitoring system framework. A data service platform was built to gather, store, manage and share multi-professional and multi-type inspections and monitoring data, to provide support for security assessment and maintenance decisions of high-speed railway infrastructure, and to carry out tests for typical application scenarios of perimeter intrusion. With the help of ""millimeter wave radar + intelligent video"" real-time monitoring of dynamic targets within the limit, comprehensive solutions are provided by space-time calibration. The real-time monitoring, efficient transmission, fusion analysis, prediction and early warning of large-scale density natural disasters and other abnormal events covering railway were realized through the test of eastern suburbs railway ring line. The deepening of railway intelligent inspections and monitoring system and the comprehensive application of technology promote the railway business to continuously strengthen the deep integration and innovative application of cloud computing, Internet of Things, big data and other technologies, comprehensively understand and master the change law of high-speed railway infrastructure, and improve the safety, reliability and economy of railway equipment.","2693-289X","979-8-3503-3421-0","10.1109/ITOEC57671.2023.10291609","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10291609","high-speed railway;intelligent;detection and monitoring;framework;application research","Transportation;Inspection;Streaming media;Millimeter wave radar;Big Data;Rail transportation;Real-time systems","","","","23","IEEE","30 Oct 2023","","","IEEE","IEEE Conferences"
"Life jacket based energy harvesting to assist search and rescue - a review","J. To; L. Huang","School of Engineering, Computer and Math.Sciences, Auckland University of Technology, Auckland, New Zealand; School of Engineering, Computer and Math.Sciences, Auckland University of Technology, Auckland, New Zealand","2022 17th International Conference on Control, Automation, Robotics and Vision (ICARCV)","10 Jan 2023","2022","","","925","930","Water activities are common in New Zealand, both recreationally and commercially. The fourth most common cause of accidental death in New Zealand is drowning. One of the most common devices for preventing drowning is a life jacket, which keeps the wearer afloat in an accident, however, until rescue arrives the wearer is still at risk of drowning. Reducing the waiting time for search and rescue and extending the survival time for the victim in the water are two areas that can be improved. It is well known that Internet of Things (IoT) lifejackets can assist with this by providing more functionality, but little progress has been made on energy harvesting to support those functions. In this paper, a review on the potential and feasibility of using life jacket as a medium to harvest energy from the movement of humans during drowning events is presented. A review of life jacket design with IoT and energy source identification is included in the paper. Although the design of the harvesting devices for life jackets will differ from that of typical wearable devices because of the unpredictable ambient environment and safety consideration, a variety of common wearable energy harvesters are reviewed. There is potential for adjusting or scaling up these methods for life jackets. The methods for dynamic modelling of the drowning person's movement and deformation of the life jacket which can be the source of energy to be harvested necessary for the analysis and design of energy harvesting systems. The research gaps and questions are presented.","","978-1-6654-7687-4","10.1109/ICARCV57592.2022.10004366","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10004366","","Electric potential;Wearable computers;Safety;Energy harvesting;Internet of Things;Kinetic energy;Electromagnetics","","","","30","IEEE","10 Jan 2023","","","IEEE","IEEE Conferences"
"End-to-End Prediction of Parcel Delivery Time With Deep Learning for Smart-City Applications","A. C. de Araujo; A. Etemad","Department of Electrical and Computer Engineering, Queen’s University, Kingston, ON, Canada; Department of Electrical and Computer Engineering, Queen’s University, Kingston, ON, Canada","IEEE Internet of Things Journal","19 Nov 2021","2021","8","23","17043","17056","The acquisition of massive data on parcel delivery motivates postal operators to foster the development of predictive systems to improve customer service. Predicting delivery times successive to being shipped out of the final depot, referred to as last-mile prediction, deals with complicating factors such as traffic, drivers’ behaviors, and weather. This work studies the use of deep learning for solving a real-world case of last-mile parcel delivery time prediction. We present our solution under the Internet-of-Things (IoT) paradigm and discuss its feasibility on a cloud-based architecture as a smart city application. We focus on a large-scale parcel data set provided by Canada Post, covering the Greater Toronto Area (GTA). We utilize an origin-destination (OD) formulation, in which routes are not available, but only the start and end delivery points. We investigate three categories of convolutional-based neural networks and assess their performances on the task. We further demonstrate how our modeling outperforms several baselines, from classical machine learning models to referenced OD solutions. We perform a thorough error analysis across the data and visualize the deep features learned to better understand the model behavior, making interesting remarks on data predictability. Our work provides an end-to-end neural pipeline that leverages parcel OD data as well as weather to accurately predict delivery durations. We believe that our system has the potential not only to improve user experience by better modeling their anticipation but also to aid last-mile postal logistics as a whole.","2327-4662","","10.1109/JIOT.2021.3077007","Innovapost Inc.; Natural Sciences and Engineering Research Council of Canada (NSERC); Ontario Centres of Excellence (OCE); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9420706","Deep learning;last mile;origin–destination (OD);parcel delivery;predictive modeling","Estimation;Logistics;Internet of Things;Deep learning;Global Positioning System;Data models;Smart transportation","","19","","54","IEEE","3 May 2021","","","IEEE","IEEE Journals"
"Offloading Mechanisms Based on Reinforcement Learning and Deep Learning Algorithms in the Fog Computing Environment","D. H. Abdulazeez; S. K. Askar","Department of Computer Science, University of Duhok, Duhok, Iraq; Erbil Technical Engineering College, Erbil Polytechnic University, Erbil, Iraq","IEEE Access","10 Feb 2023","2023","11","","12555","12586","Fog computing has emerged as a computing paradigm for resource-restricted Internet of things (IoT) devices to support time-sensitive and computationally intensive applications. Offloading can be utilized to transfer resource-intensive tasks from resource-limited end devices to a resource-rich fog or cloud layer to reduce end-to-end latency and enhance the performance of the system. However, this advantage is still challenging to achieve in systems with a high request rate because it leads to long queues of tasks in fog nodes and reveals inefficiencies in terms of delays. In this regard, reinforcement learning (RL) is a well-known method for addressing such decision-making issues. However, in large-scale wireless networks, both action and state spaces are complex and extremely extensive. Consequently, reinforcement learning techniques may not be able to identify an efficient strategy within an acceptable time frame. Hence, deep reinforcement learning (DRL) was developed to integrate RL and deep learning (DL) to address this problem. This paper presents a systematic analysis of using RL or DRL algorithms to address offloading-related issues in fog computing. First, the taxonomy of fog computing offloading mechanisms based on RL and DRL algorithms was divided into three major categories: value-based, policy-based, and hybrid-based algorithms. These categories were then compared based on important features, including offloading problem formulation, utilized techniques, performance metrics, evaluation tools, case studies, their strengths and drawbacks, offloading directions, offloading mode, SDN-based architecture, and offloading decisions. Finally, the future research directions and open issues are discussed thoroughly.","2169-3536","","10.1109/ACCESS.2023.3241881","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10035389","Fog computing;Internet of Things (IoT);offloading;reinforcement learning;deep reinforcement learning","Deep learning;Edge computing;Reinforcement learning;Systematics;Resource management;Heuristic algorithms;Internet of Things","","8","","147","CCBY","2 Feb 2023","","","IEEE","IEEE Journals"
"Smart Grid vs. Intelligent Grid; Artificial Intelligence Takes the Power System to the Next Level","S. Liasi; N. S. Ghiasi; R. Hadidi","Holcombe Department of Electrical and Computer Engineering, Clemson University, Charleston, SC, USA; Holcombe Department of Electrical and Computer Engineering, Clemson University, Charleston, SC, USA; Holcombe Department of Electrical and Computer Engineering, Clemson University, Charleston, SC, USA","2023 IEEE 3rd International Conference on Digital Twins and Parallel Intelligence (DTPI)","26 Dec 2023","2023","","","1","6","This paper discusses the concept of intelligent power systems, particularly the distinction between smart grids and intelligent grids. Smart grids represent a convergence of various energy technologies and communication systems, enabling multidomain interactions. However, in such a grid, humans are still the ultimate decision maker based on the gathered information. By adding artificial intelligence to the system, smart grids can be upgraded to intelligent grids. This article explores the cutting-edge methods and propositions of machine learning and artificial intelligence, and their influence on a plethora of smart grid applications, aiding their transition to truly intelligent grids. The piece highlights the surge in interest and rapid advancement in employing machine learning and AI techniques to effectively tackle technical obstacles across various facets of the smart grid. However, it notes unresolved issues meriting additional research, such as high-performance data processing for informed decision-making in large, intricate multi-energy systems, and lightweight solutions based on machine learning. Additionally, the article spotlights the potential of harnessing progressive computing and communication technologies such as edge computing, pervasive internet of things, and 5G wireless networks within the smart grid framework. Simulating smart grids requires overcoming challenges posed by the integration of diverse subsystems with varying time scales. Co-simulation is employed for these cases. This paper presents the state-of-the-art in simulating intelligent power systems and addresses challenges in applying co-simulation to test cases spanning various domains, including information and communication technology (ICT) and power systems. We anticipate that this study will serve as a launching pad for continued exploration and advancement in this burgeoning area of knowledge and practice.","","979-8-3503-1847-0","10.1109/DTPI59677.2023.10365429","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10365429","smart grid;machine learning;artificial intelligence;parallel intelligence;intelligent grid","Wireless networks;Decision making;Machine learning;Data processing;Smart grids;Power systems;Information and communication technology","","","","38","IEEE","26 Dec 2023","","","IEEE","IEEE Conferences"
"Non-Orthogonal Multiple Access Based Radio Resource Management for M2M Communications","J. Fang; S. Xu","School of Electronics and Information Engineering, Beijing Jiaotong University, Beijing, China; School of Electronics and Information Engineering, Beijing Jiaotong University, Beijing, China","2020 IEEE International Conference on Communications Workshops (ICC Workshops)","21 Jul 2020","2020","","","1","6","Machine to machine (M2M) communication plays an important role in Internet of Things (IoT) for 5G because of its full automation and ready-to-use properties. However, the large-scale connections, periodic and frequent communication and requirements for low latency generated by the M2M services put higher demands on the communication system with the limited wireless resources. To solve this problem, we propose a M2M communication system model based on non-orthogonal multiple access (NOMA) with cloud radio access network (C-RAN) architecture, and a power allocation method based on fairness and a user grouping strategy based on matching algorithm are raised for the cells with multiple base stations in this paper. The simulation results show that the proposed algorithm can achieve good performance in massive connection scenarios. Furthermore, the results reveal the superior performance of the NOMA scheme with multiple base stations over the traditional orthogonal multiple access (OMA) scheme.","2474-9133","978-1-7281-7440-2","10.1109/ICCWorkshops49005.2020.9145238","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9145238","Machine to machine (M2M);Non-orthogonal multiple access (NOMA);Cloud radio access network (C-RAN);Resource allocation;fairness","Resource management;Machine-to-machine communications;Base stations;NOMA;Optimization;Linear programming","","","","9","IEEE","21 Jul 2020","","","IEEE","IEEE Conferences"
"Integration of Distributed Energy Resources into a Virtual Power Plant-A Pilot Project in Dubai","F. Sattar; A. Husnain; T. Ghaoud","Research and Development Centre, Dubai Electricity and Water Authority, Dubai, UAE; Research and Development Centre, Dubai Electricity and Water Authority, Dubai, UAE; Research and Development Centre, Dubai Electricity and Water Authority, Dubai, UAE","2023 IEEE/IAS Industrial and Commercial Power System Asia (I&CPS Asia)","3 Nov 2023","2023","","","526","531","The high penetration of Distributed Energy Resources (DERs) brings new challenges in the operation of the power grid such as generation-demand imbalance, voltage violations, reverse power flow, etc. To address the aforementioned challenges, Virtual Power Plant (VPP) can be used, which would be best deployed as a cloud-based system due to its ease of implementation, scalability, and ease of service and support. VPP can effectively integrate, aggregate, optimize, control, and dispatch various Behind-The-Meter (BTM) DERs to support grid operations. Therefore, this work discusses the integration and control of DERs such as rooftop solar PV, electric vehicle charging stations, flexible loads, and battery energy storage systems (BESS) through a VPP platform that has been implemented on a pilot scale in Dubai. The connectivity of the VPP with DERs has been established using an Internet of Things (IoT) gateway as well as cloud-to-cloud communication via REST application programming interface (API). The test results are presented to show the response of various DERs based on the instructions through the VPP platform. The current work forms the basis for future work to scale up the VPP connectivity with DERs on a larger network and evaluate the best-suited VPP use cases for the Dubai power network.","","979-8-3503-3934-5","10.1109/ICPSAsia58343.2023.10294691","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10294691","Virtual Power Plant;DERs monitoring and control;distributed energy resources;electric vehicles;battery energy storage system;flexible load;PV system;IoT Gateway","Cloud computing;Battery energy storage system;Scalability;Logic gates;Virtual power plants;Power grids;Electric vehicle charging","","","","14","IEEE","3 Nov 2023","","","IEEE","IEEE Conferences"
"Unified Stationary and Nonstationary Data Representation for Process Monitoring in IIoT","K. Huang; L. Zhang; C. Yang; W. Gui; S. Hu","School of Automation, Central South University, Changsha, China; School of Automation, Central South University, Changsha, China; School of Automation, Central South University, Changsha, China; School of Automation, Central South University, Changsha, China; School of Electronics and Computer Science, University of Southampton, Southampton, U.K.","IEEE Transactions on Instrumentation and Measurement","19 May 2022","2022","71","","1","12","The Industrial Internet of Things (IIoT), which integrates industrial systems with advanced computing, communication, and control technologies, has become the mainstream of industrial manufacturing. Due to the large scale and complexity of the modern industry, industrial processes are characterized by multimode and mixed stationary and nonstationary variables. At the same time, faulty data in industrial processes, especially the small ones, are easily concealed by the normal variation trend of nonstationary data, which brings challenges to the process monitoring task. To facilitate the process monitoring within the framework of IIoT, a stationary and nonstationary data representation method for process monitoring is proposed, which combines the cointegration analysis and the representation learning synergistically. In detail, a cointegration model is established to extract the long-term equilibrium relationship between nonstationary variables to eliminate their negative effects. The equilibrium relationship, namely, stationary residuals, is fused with stationary variables and then reconstructed by a joint dictionary learning method. Hereafter, using the kernel density estimation method, the control limit can be calculated by the reconstruction error. Consequently, when online data samples arrive, we use the cointegration model and dictionary to reconstruct the data. Process monitoring can be realized timely by the reconstruction error. Extensive experiments, including a numerical simulation, a benchmark penicillin fermentation process, and an industrial roasting process, are used to verify the superiority and effectiveness of the proposed method for process monitoring based on IIoT. Our experimental results also demonstrate that the proposed method can detect small faults of the multimode process with mixed stationary and nonstationary variables.","1557-9662","","10.1109/TIM.2022.3173631","National Natural Science Foundation of China(grant numbers:62073340,61860206014); Major Key Project of Peng Cheng Laboratory (PCL)(grant numbers:PCL2021A09); National Key Research and Development Program of China(grant numbers:2019YFB1705300); Science and Technology Innovation Program of Hunan Province(grant numbers:2021RC3018,2021RC4054); Innovation-Driven Plan in Central South University, China(grant numbers:2019CX020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9771194","Cointegration analysis (CA);dictionary learning;fault detection;Industrial Internet of Things (IIoT);nonstationary","Process monitoring;Industrial Internet of Things;Machine learning;Fault diagnosis;Physical layer;Data models;Process control","","3","","37","IEEE","9 May 2022","","","IEEE","IEEE Journals"
"FDA$^3$: Federated Defense Against Adversarial Attacks for Cloud-Based IIoT Applications","Y. Song; T. Liu; T. Wei; X. Wang; Z. Tao; M. Chen","MoE Engineering Research Center of Software/Hardware Co-Design Technology and Application, East China Normal University, Shanghai, China; MoE Engineering Research Center of Software/Hardware Co-Design Technology and Application, East China Normal University, Shanghai, China; MoE Engineering Research Center of Software/Hardware Co-Design Technology and Application, East China Normal University, Shanghai, China; MoE Engineering Research Center of Software/Hardware Co-Design Technology and Application, East China Normal University, Shanghai, China; Godel Lab, Huawei, Shanghai, China; MoE Engineering Research Center of Software/Hardware Co-Design Technology and Application, East China Normal University, Shanghai, China","IEEE Transactions on Industrial Informatics","30 Jul 2021","2021","17","11","7830","7838","Along with the proliferation of artificial intelligence and Internet of things (IoT) techniques, various kinds of adversarial attacks are increasingly emerging to fool deep neural networks (DNNs) used by industrial IoT (IIoT) applications. Due to biased training data or vulnerable underlying models, imperceptible modifications on inputs made by adversarial attacks may result in devastating consequences. Although existing methods are promising in defending such malicious attacks, most of them can only deal with limited existing attack types, which makes the deployment of large-scale IIoT devices a great challenge. To address this problem, in this article, we present an effective federated defense approach named FDA3 that can aggregate defense knowledge against adversarial examples from different sources. Inspired by federated learning, our proposed cloud-based architecture enables the sharing of defense capabilities against different attacks among IIoT devices. Comprehensive experimental results show that the generated DNNs by our approach can not only resist more malicious attacks than existing attack-specific adversarial training methods, but also prevent IIoT applications from new attacks.","1941-0050","","10.1109/TII.2020.3005969","National Key Research and Development Program of China Stem Cell and Translational Research(grant numbers:2018YFB2101300); Natural Science Foundation of China(grant numbers:61872147); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9130128","Adversarial attack;adversarial training;convolutional neural network robustness;federated defense;industrial Internet of things (IIoT)","Training;Cloud computing;Collaborative work;Servers;Computational modeling","","32","","33","IEEE","30 Jun 2020","","","IEEE","IEEE Journals"
"DREAM: Online Control Mechanisms for Data Aggregation Error Minimization in Privacy-Preserving Crowdsensing","Y. Liu; T. Feng; M. Peng; J. Guan; Y. Wang","State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; Department of Computer and Information Sciences, Temple University, Philadelphia, PA, USA","IEEE Transactions on Dependable and Secure Computing","11 Mar 2022","2022","19","2","1266","1279","Nowadays, by integrating the smart devices carried by users with existing communication infrastructures to provide large-scale, fine-grained and complex sensing services, crowdsensing as a novel sensing paradigm has significantly enriched the applications of smart city and promoted the development of Internet of Things (IoT). However, privacy has become skyrocketing concern for crowdsensing and gravely affected the deployment of crowdsensing. In this article, we present a framework to make the tradeoff between minimizing data aggregation error and guaranteeing system stability by jointly considering the privacy of participants, the randomness of sensing task arrival and the cost of platform. We propose an online control mechanism by exploiting Lyapunov stochastic optimization technique. Additionally, considering that, in reality, it always takes different time for different tasks to make sensing decisions, we extend standard Lyapunov stochastic optimization technique to make separate decisions for different types of sensing tasks in consecutive time. Through rigorous theoretical analysis, we prove that our time-average data aggregation error is approximately optimal while still maintaining system stability. By carrying out extensive simulations, we demonstrate the superiority of our proposed mechanisms.","1941-0018","","10.1109/TDSC.2020.3011679","National Natural Science Foundation of China(grant numbers:61972049); State Major Science and Technology Special Project(grant numbers:2018ZX03001023); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9147025","Crowedsensing;data aggregation error minimization;privacy protection;online control mechanism;Lyapunov stochastic optimization","Sensors;Task analysis;Data aggregation;Privacy;Stability analysis","","28","","38","IEEE","24 Jul 2020","","","IEEE","IEEE Journals"
"A Tree-Structured LoRa Network for Energy Efficiency","Y. H. Tehrani; A. Amini; S. M. Atarodi","Electrical Engineering Department, Sharif University of Technology, Tehran, Iran; Electrical Engineering Department, Sharif University of Technology, Tehran, Iran; Electrical Engineering Department, Sharif University of Technology, Tehran, Iran","IEEE Internet of Things Journal","24 Mar 2021","2021","8","7","6002","6011","The LoRa technology is considered as one of the most potential solutions for Internet of Things (IoT) in the near future. The existing LoRa networks are based on the star topology. In this article, a tree network adopted for the LoRa technology and a communication protocol are proposed to mitigate the energy consumption constraints. In the proposed network, the nodes are self-configured based on the LoRa physical link behavior and can act as relays to propagate data from other nodes. The analysis, design, and evaluation of the proposed architecture for large scale LoRa networks are presented in detail. With analytical studies, the energy consumption of the star and tree LoRa networks are compared. The presented analytical results can provide developers with effective guidelines for scalable design and optimization of LoRa networks. Further, the results are verified using simulation and experimental tests. Both simulation and experimental results confirm that the presented method improves the energy consumption of the entire IoT network significantly. As a result, the presented tree network can be deployed in various applications.","2327-4662","","10.1109/JIOT.2020.3034142","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9241008","Energy efficient;LoRa;optimization;star topology;tree topology","Internet of Things;Energy consumption;Protocols;Bandwidth;Network topology;Receivers;Topology","","20","","37","IEEE","27 Oct 2020","","","IEEE","IEEE Journals"
"Online Microservice Orchestration for IoT via Multiobjective Deep Reinforcement Learning","Y. Yu; J. Liu; J. Fang","Research and Development InstituteResearch and Development Institute, Northwestern Polytechnical University in Shenzhen, Shenzhen, Guangdong, China; National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, School of Cybersecurity, Northwestern Polytechnical University, Xi’an, Shaanxi, China; School of Computer, Wuhan University, Wuhan, Hubei, China","IEEE Internet of Things Journal","7 Sep 2022","2022","9","18","17513","17525","By providing loosely coupled, lightweight, and independent services, the microservice architecture is promising for large-scale and complex service provision requirements in the Internet of Things (IoT). However, it requires more fine-grained resource management and orchestration for service provision. Most of the existing microservice orchestration solutions are based on those designed for the traditional cloud. They can only provide coarse-grained resource allocation using possibly conflicting weighted objectives. In this article, we present a fine-grained microservice orchestration approach to provide services online for dynamic requests of IoT applications. By using a fine-grained resource model of energy cost and service end-to-end response time of orchestrated microservices, we formulate the microservice orchestration problem as a multiobjective Markov decision process. We then propose a multiobjective optimization solution based on deep reinforcement learning (DRL) to simultaneously reduce energy consumption and response time. Through extensive experiments, our proposed algorithm presents significant performance results than the state of the art. To the best of our knowledge, this is the first work that addresses microservice orchestration using DRL for multiple conflicting objectives.","2327-4662","","10.1109/JIOT.2022.3155598","Basic Research Programs of Taicang(grant numbers:TC2020JC03); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2021A1515110279); Natural Science Basic Research Program of Shaanxi(grant numbers:2022JQ-611); Fundamental Research Funds for the Central Universities(grant numbers:D5000210588); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9723469","Deep reinforcement learning (DRL);energy consumption;Internet of Things (IoT);online microservice orchestration;Quality-of-Service (QoS) assurance","Microservice architectures;Internet of Things;Servers;Resource management;Costs;Containers;Quality of service","","6","","53","IEEE","1 Mar 2022","","","IEEE","IEEE Journals"
"Outage Analysis of AmBC-Enabled Vehicular Communications Under Mixed Nakagami-$m$ and Cascaded Nakagami-$m$ Fading Channels","A. Rastogi; S. Yadav; R. Gour; D. S. Gurjar","Department of ECE, Indian Institute of Information Technology Allahabad, Prayagraj, India; Department of ECE, Indian Institute of Information Technology Allahabad, Prayagraj, India; Department of ECE, Indian Institute of Information Technology Allahabad, Prayagraj, India; Department of ECE, National Institute of Technology, Silchar, Assam, India","TENCON 2023 - 2023 IEEE Region 10 Conference (TENCON)","22 Nov 2023","2023","","","1204","1209","Ambient backscatter communication (AmBC) is proposed as a prominent technology to support energy-efficient low power transmissions in 6G and beyond wireless networks. AmBC is capable of providing battery-free connectivity among large scale Internet-of-Things (IoT) devices. Also, it can satisfy the stringent delay and power saving requirements of intelligent transport systems (ITS) in seeking diverse vehicular applications. Motivated by these emerging trends, we consider an AmBC-assisted tag-reader-based vehicular scenario and carried out the outage analysis by deriving the exact expressions for the reader's outage probability (OP) considering tag being in reflective or non-reflective state over mixed Nakagami-m and double Nakagami-m fading environment. We also examine the asymptotic OP in the high signal-to-noise (SNR) regime, which is perfectly aligned with the exact OP values even at moderate SNRs. Further, this asymptotic analysis reveals some meaningful insights into the systems diversity order. Numerical and simulation studies are conducted to validate our mathematical framework.","2159-3450","979-8-3503-0219-6","10.1109/TENCON58879.2023.10322441","SERB-DST(grant numbers:MTR/2022/000035); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10322441","","Fading channels;Wireless networks;Simulation;Power transmission;Probability;Market research;Power system reliability","","","","26","IEEE","22 Nov 2023","","","IEEE","IEEE Conferences"
"Decentralized Federated Learning With Asynchronous Parameter Sharing for Large-Scale IoT Networks","H. Xie; M. Xia; P. Wu; S. Wang; K. Huang","School of Electronics and Information Technology, Sun Yat-sen University, Guangzhou, China; School of Electronics and Information Technology, Sun Yat-sen University, Guangzhou, China; School of Electronics and Information Technology, Sun Yat-sen University, Guangzhou, China; Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Department of Electrical and Electronic Engineering, The University of Hong Kong, Hong Kong, Hong Kong","IEEE Internet of Things Journal","","2024","PP","99","1","1","Federated learning (FL) enables wireless terminals to collaboratively learn a shared parameter model while keeping all the training data on devices per se. Parameter sharing consists of synchronous and asynchronous ways: the former transmits parameters as blocks or frames and waits until all transmissions finish, whereas the latter provides messages about the status of pending and failed parameter transmission requests. Whatever synchronous or asynchronous parameter sharing is applied, the learning model shall adapt to distinct network architectures as an improper learning model will deteriorate learning performance and, even worse, lead to model divergence for the asynchronous transmission in resource-limited large-scale Internet-of-Things (IoT) networks. This paper proposes a decentralized learning model and develops an asynchronous parameter-sharing algorithm for resource-limited distributed IoT networks. This decentralized learning model approaches a convex function as the number of nodes increases, and its learning process converges to a global stationary point with a higher probability than the centralized FL model. Moreover, by jointly accounting for the convergence bound of federated learning and the transmission delay of wireless communications, we develop a node scheduling and bandwidth allocation algorithm to minimize the transmission delay. Extensive simulation results corroborate the effectiveness of the distributed algorithm in terms of fast learning model convergence and low transmission delay.","2327-4662","","10.1109/JIOT.2024.3354869","National Natural Science Foundation of China(grant numbers:62171486,U2001213); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10400772","Asynchronous communications;distributed algorithm;federated learning;large-scale IoT networks;transmission delay","Delays;Convergence;Data models;Computational modeling;Adaptation models;Peer-to-peer computing;Wireless communication","","","","","IEEE","16 Jan 2024","","","IEEE","IEEE Early Access Articles"
"Ascend: a Scalable and Unified Architecture for Ubiquitous Deep Neural Network Computing : Industry Track Paper","H. Liao; J. Tu; J. Xia; H. Liu; X. Zhou; H. Yuan; Y. Hu","Huawei, China; Huawei, China; Huawei, China; Huawei, China; Huawei, China; Huawei, China; Huawei, China","2021 IEEE International Symposium on High-Performance Computer Architecture (HPCA)","22 Apr 2021","2021","","","789","801","Deep neural networks (DNNs) have been successfully applied to a great variety of applications, ranging from small IoT devices to large scale services in a data center. In order to improve the efficiency of processing these DNN models, dedicated hardware accelerators are required for all these scenarios. Theoretically, there exists an optimized acceleration architecture for each application. However, considering the cost of chip design and corresponding tool-chain development, researchers need to trade off between efficiency and generality. In this work, we demonstrate that it is practical to use a unified architecture, called Ascend, to support those applications, ranging from IoT devices to data-center services. We provide a lot of design details to explain that the success of Ascend relies on contributions from different levels. First, heterogeneous computing units are employed to support various DNN models. And the datapath is adapted according to the requirement of computing and data access. Second, when scaling the Ascend architecture from a single core to a cluster containing thousands of cores, it involves design efforts, such as memory hierarchy and system level integration. Third, a multi-tier compiler, which provides flexible choices for developers, is the last critical piece. Experimental results show that using accelerators based on the Ascend architecture can achieve comparable or even better performance in different applications. In addition, various chips based on the Ascend architecture have been successfully commercialized. More than 100 million chips have been used in real products.","2378-203X","978-1-6654-2235-2","10.1109/HPCA51647.2021.00071","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9407221","","Training;Neural networks;Memory management;Computer architecture;Software;Heterogeneous networks;Hardware","","19","","42","IEEE","22 Apr 2021","","","IEEE","IEEE Conferences"
"Blockchain-Based Dynamic Provable Data Possession for Smart Cities","R. Chen; Y. Li; Y. Yu; H. Li; X. Chen; W. Susilo","School of Computer Science, Shaanxi Normal University, Xi’an, China; Institute of Cybersecurity and Cryptology, School of Computing and Information Technology, University of Wollongong, Wollongong, Australia; School of Computer Science, Shaanxi Normal University, Xi’an, China; School of Computer Science, Shaanxi Normal University, Xi’an, China; School of Cyber Engineering, Xidian University, Xi’an, China; Institute of Cybersecurity and Cryptology, School of Computing and Information Technology, University of Wollongong, Wollongong, Australia","IEEE Internet of Things Journal","13 May 2020","2020","7","5","4143","4154","Smart cities have experienced rapid development with the advances of information and communication technologies such as Internet of Things (IoT). To tackle the data storage issues raised by large-scale data generated by IoT devices, an increasing number of enterprises and individuals prefer to outsource their data to cloud, where data integrity becomes a concern to cloud users. A variety of provable data possession (PDP) protocols have been proposed for centralized cloud storage scenarios so far. However, a centralized cloud relies too much on the trust of the central servers and, thus, is prone to the single point of failure. In this article, we describe a blockchain-based PDP model to realize the decentralized outsourcing storage framework, and then present a concrete construction of decentralized PDP by using multireplica storage tricks. Moreover, our protocol provides dynamic operations for outsourced data and at the same time, guarantees the fairness of all parties involved. We provide a detailed security proof for the proposed protocol and deploy a smart contract for the protocols as well. We finally evaluate the algorithms and the implementation results demonstrate the practicability of the proposed protocol.","2327-4662","","10.1109/JIOT.2019.2963789","National Key Research Development Program of China(grant numbers:2017YFB0802000); National Natural Science Foundation of China(grant numbers:61872229,U19B2021,61960206014); National Cryptography Development Fund during the 13th Five-Year Plan Period(grant numbers:MMJJ20170216); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8949534","Blockchain;Internet of Things (IoT);outsourcing storage;smart contract","Cloud computing;Protocols;Security;Smart cities;Internet of Things;Memory;Information and communication technology","","58","","31","IEEE","3 Jan 2020","","","IEEE","IEEE Journals"
"MetaCIDS: Privacy-Preserving Collaborative Intrusion Detection for Metaverse based on Blockchain and Online Federated Learning","V. T. Truong; L. B. Le","Institut National de la Recherche Scientifique, University of Québec, Montréal, QC, Canada; Institut National de la Recherche Scientifique, University of Québec, Montréal, QC, Canada","IEEE Open Journal of the Computer Society","18 Sep 2023","2023","4","","253","266","Metaverse is expected to rely on massive Internet of Things (IoT) connections so it inherits various security threats from the IoT network and also faces other sophisticated attacks related to virtual reality technology. As traditional security approaches show various limitations in the large-scale distributed metaverse, this paper proposes MetaCIDS, a novel collaborative intrusion detection (CID) framework that leverages metaverse devices to collaboratively protect the metaverse. In MetaCIDS, a federated learning (FL) scheme based on unsupervised autoencoder and an attention-based supervised classifier enables metaverse users to train a CID model using their local network data, while the blockchain network allows metaverse users to train a machine learning (ML) model to detect intrusion network flows over their monitored local network traffic, then submit verifiable intrusion alerts to the blockchain to earn metaverse tokens. Security analysis shows that MetaCIDS can efficiently detect zero-day attacks, while the training process is resistant to SPoF, data tampering, and up to 33% poisoning nodes. Performance evaluation illustrates the efficiency of MetaCIDS with 96% to 99% detection accuracy on four different network intrusion datasets, supporting both multi-class detection using labeled data and anomaly detection trained on unlabeled data.","2644-1268","","10.1109/OJCS.2023.3312299","Innovation for Defence Excellence and Security; Ministère de la Défense Nationale; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10239541","Blockchain;collaborative intrusion detection;federated learning;metaverse;semi-supervised learning","Metaverse;Training;Blockchains;Intrusion detection;Data models;Servers;Privacy","","3","","35","CCBYNCND","5 Sep 2023","","","IEEE","IEEE Journals"
"A Machine Learning and Optimization Framework for the Early Diagnosis of Bovine Respiratory Disease","E. Casella; M. C. Cantor; M. M. W. Setser; S. Silvestri; J. H. C. Costa","Department of Computer Science, University of Kentucky, Lexington, KY, USA; Department of Animal Science, Pennsylvania State University, University Park, PA, USA; Department of Animal and Food Sciences, University of Kentucky, Lexington, KY, USA; Department of Computer Science, University of Kentucky, Lexington, KY, USA; Department of Animal and Veterinary Sciences, University of Vermont, Burlington, VT, USA","IEEE Access","19 Jul 2023","2023","11","","71164","71179","Bovine Respiratory Disease (BRD) is an infection of the respiratory tract that is the leading reason for antimicrobial use in dairy calves and represents 22% of calf mortalities. The costs and effects of BRD can severely damage a farm’s economy, since raising dairy calves is one of the largest economic investments, and diagnosing BRD requires intensive and specialized labor that is hard to find. Precision technologies based on the Internet of Things (IoT), such as automatic feeders, scales, and accelerometers, can help detect behavioral changes before outward clinical signs of BRD. Such early detection enables early treatment, and thus faster recovery, with less long term effects. In this paper, we propose a framework for BRD diagnosis, its early detection, and identification of BRD persistency status using precision IoT technologies. We adopt a machine learning model paired with a cost-sensitive feature selection problem called Cost Optimization Worth (COW). COW maximizes prediction accuracy given a budget constraint. We show that COW is NP-Hard, and propose an efficient heuristic with polynomial complexity called Cost-Aware Learning Feature (CALF). We validate our methodology on a real dataset collected from 159 calves during the preweaning period. Results show that our approach outperforms a recent state-of-the-art solution. Numerically, we achieve an accuracy of 88% for labeling sick and healthy calves, 70% of sick calves are predicted 4 days prior to diagnosis, and 80% of persistency status calves are detected within the first five days of sickness.","2169-3536","","10.1109/ACCESS.2023.3291348","National Institute of Food and Agriculture(grant numbers:2021-68014-34139); NSF Smart and Connected Communities(grant numbers:1952045); U.S. Department of Agriculture National Institute of Food and Agriculture Hatch(grant numbers:KY007100); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168900","Dairy calves;precision IoT technologies;machine learning;cost-sensitive optimization","Cows;Costs;Pulmonary diseases;Machine learning;Labeling;Investment;Feature extraction;Complexity theory;Internet of Things;Pulmonary diseases;Accelerometers","","2","","40","CCBYNCND","30 Jun 2023","","","IEEE","IEEE Journals"
"Distributed Inference Over Linear Models Using Alternating Gaussian Belief Propagation","M. Cosovic; D. Miskovic; M. Delalic; D. Raca; D. Vukobratovic","Faculty of Electrical Engineering, University of Sarajevo, Sarajevo, Bosnia and Herzegovina; Institute for Artificial Intelligence Research and Development of Serbia, Novi Sad, Serbia; Faculty of Electrical Engineering, University of Sarajevo, Sarajevo, Bosnia and Herzegovina; Faculty of Electrical Engineering, University of Sarajevo, Sarajevo, Bosnia and Herzegovina; Faculty of Technical Sciences, University of Novi Sad, Novi Sad, Serbia","IEEE Internet of Things Journal","30 Oct 2023","2023","10","22","19949","19963","We consider the problem of maximum-likelihood estimation in linear models represented by factor graphs and solved via the Gaussian belief propagation algorithm. Motivated by massive Internet of Things (IoT) networks and edge computing, we set the above problem in a clustered scenario, where the factor graph is divided into clusters and assigned for processing in a distributed fashion across a number of edge computing nodes. For these scenarios, we show that an alternating Gaussian belief propagation (AGBP) algorithm that alternates between inter- and intracluster iterations, demonstrates superior performance in terms of convergence properties compared to the existing solutions in the literature. We present a comprehensive framework and introduce appropriate metrics to analyze the AGBP algorithm across a wide range of linear models characterized by symmetric and nonsymmetric, square, and rectangular matrices. We extend the analysis to the case of dynamic linear models by introducing the dynamic arrival of new data over time. Using a combination of analytical and extensive numerical results, we show the efficiency and scalability of the AGBP algorithm, making it a suitable solution for large-scale inference in massive IoT networks.","2327-4662","","10.1109/JIOT.2023.3282161","European Union’s Horizon 2020 Research and Innovation Programme(grant numbers:856967); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10141994","Distributed systems;factor graphs;Gaussian belief propagation (GBP);Internet of Things (IoT) networks;linear models","Heuristic algorithms;Inference algorithms;Maximum likelihood estimation;Internet of Things;Estimation;Signal processing algorithms;Computational modeling","","","","32","IEEE","1 Jun 2023","","","IEEE","IEEE Journals"
"Stochastic Geometry Based Performance Study for Wireless-Powered Backscatter Communications","J. Zan; Y. Ye; R. Q. Hu; G. Lu","Shaanxi Key Laboratory of Information Communication Network and Security, Xi’an University of Posts and Telecommunications, Xi’an, Shaanxi, China; Shaanxi Key Laboratory of Information Communication Network and Security, Xi’an University of Posts and Telecommunications, Xi’an, Shaanxi, China; Department of Electrical and Computer Engineering, Utah State University, Logan, UT, USA; Shaanxi Key Laboratory of Information Communication Network and Security, Xi’an University of Posts and Telecommunications, Xi’an, Shaanxi, China","IEEE Transactions on Vehicular Technology","17 Oct 2022","2022","71","10","11136","11149","Wirelessly powered backscatter communication (WP-BackCom) enables battery-free Internet of Things (IoT) nodes to passively modulate and backscatter information on the energy signals transmitted by power beacons (PBs) and to harvest energy for realizing energy self-sustainability. It has been deemed a promising solution for the large-scale deployment of IoT nodes. In this paper, we exploit stochastic geometry (SG) to develop a tractable framework to evaluate the successful transmission probability in WP-BackCom while considering the imperfect successive interference cancellation (SIC) at each gateway (GW) and the non-linear energy harvesting (EH) model and energy-causality constraint at each backscatter user (BU). The successful transmission probability is defined as the probability for the event that not only the BU can harvest sufficient power from PBs for sustaining its operation but also the backscattered information can be successfully decoded by the GW. We derive the active probability into a closed form and then obtain the successful transmission probability based on the random spectrum access (RSA) policy. The closed-form expression for the successful transmission probability is derived under three special cases. We also devise a closed-form expression for the sub-optimal reflection coefficient to obtain a sub-optimal successful transmission probability. The analysis reveals that the sub-optimal reflection coefficient increases with the SIC coefficient. Numerical simulations validate the correctness of the above theoretical derivations and examine the impacts of various parameters on the successful transmission probability.","1939-9359","","10.1109/TVT.2022.3188022","Young Talent Fund of University Association for Science and Technology in Shaanxi(grant numbers:20210121); Shaanxi Provincial Education Department through Scientific Research Program(grant numbers:21JK0914); Science and Technology Innovation Team of Shaanxi Province(grant numbers:2017KCT-30-02); National Natural Science Foundation of China(grant numbers:61902316); Postgraduate Innovation Fund of Xi'an University of Posts and Telecommunications(grant numbers:CXJJDL2021012); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9813592","Active probability;stochastic geometry;successful transmission probability;wirelessly powered backscatter communication","Backscatter;Lead;Internet of Things;Stochastic processes;Geometry;Symbols;Interference cancellation","","","","35","IEEE","4 Jul 2022","","","IEEE","IEEE Journals"
"Novel Computation and Communication Resources Allocation Using Relay Communications in UAV-Mounted Cloudlet Systems","H. Shimada; Y. Kawamoto; N. Kato","Graduate School of Information Sciences, Tohoku University, Sendai, Japan; Graduate School of Information Sciences, Tohoku University, Sendai, Japan; Graduate School of Information Sciences, Tohoku University, Sendai, Japan","IEEE Transactions on Network Science and Engineering","10 Dec 2021","2021","8","4","3140","3151","At present, the Internet of things (IoT) is widely employed in various systems. The operation of these systems requires intelligent data processing, which needs to be performed rapidly at the network edge. Hence, studies on mobile edge computing (MEC) have been increasingly conducted in recent years. In MEC, edge servers perform data processing to reduce service delay. To meet the demand for computational and communication resources in infrastructureless areas or during large-scale disasters, the use of unmanned aerial vehicles (UAVs) in providing computational resources has attracted considerable attention. However, in MEC using UAVs, it is necessary to consider the workload balance and communication range of vehicles used. In this study, we highlight problems associated with such systems from a new perspective. Furthermore, we propose a relay control method equalizing the workload balance between UAVs and reducing network delay. We modeled the proposed method as a complex system, mathematically formulating each delay element. Additionally, experimental results highlight the effectiveness of the proposed method in various environments. The reduction in delay considerably improved the feasibility of the system. This study is expected to help achieve a significant advancement in MEC using UAVs by establishing a foundation for further research.","2327-4697","","10.1109/TNSE.2021.3105455","Research and Development on Intellectual ICT System for Disaster Response and Recovery; National Institute of Information and Communications Technology; KDDI Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9516918","Internet of things;mobile edge computing;unmanned aerial vehicle;relay communication.","Relays;Internet of Things;Delays;Servers;Unmanned aerial vehicles;Cloud computing;Mathematical model","","9","","40","IEEE","18 Aug 2021","","","IEEE","IEEE Journals"
"FreeBack: Blind and Distributed Rate Adaptation in LoRa-based Backscatter Networks","G. Huang; P. Yang; H. Zhou; Y. Yan; X. He; X. Li","LINKE Lab, School of Computer Science and Technology, University of Science and Technology of China; LINKE Lab, School of Computer Science and Technology, University of Science and Technology of China; LINKE Lab, School of Computer Science and Technology, University of Science and Technology of China; LINKE Lab, School of Computer Science and Technology, University of Science and Technology of China; LINKE Lab, School of Computer Science and Technology, University of Science and Technology of China; LINKE Lab, School of Computer Science and Technology, University of Science and Technology of China","2021 IEEE Wireless Communications and Networking Conference (WCNC)","5 May 2021","2021","","","1","6","For large-scale Internet of Things (IoT), backscatter communication is a promising technology to reduce power consumption and simplify deployment. However, due to the variable excitation source (ES) signal strength and time-varying channel condition, backscatter communication lacks stability, along with limited communication range as a few meters. Adaptive date rate (ADR) is beneficial to solve such issues, but is burdensome when implement on the capability limited tags. In this paper, we design a system named FreeBack with rate adaptation in backscatter communication. Our modulation approach is denoted as Adaptive Chirp-OOK where the ES recursively generates chirp signal, and the tags reflect the chirp signal with the On-Off Key modulation. According to channel symmetry, the tags perform rate adaption only based on the received ES signal strength instead of feedback from receiver. Such adaptation method enables the receiver to successfully decode signal through the time-varying channel, even for signal under the noise floor. We have implemented the prototype system based on the USRP platform. Extensive experiment results demonstrate the effectiveness of the proposed system. Our system provides valid ES-tag distance up to 27m, which is 7× as compared with normal backscatter system. FreeBack significantly increases the backscatter communication stability, by supporting data rate adaptation ranges from 0. 33kbps to 1. 2Mbps, and guaranteeing the bit error rate (BER) below 1%.","1558-2612","978-1-7281-9505-6","10.1109/WCNC49053.2021.9417369","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9417369","Backscatter Communication;Rate Adaptation;Chirp-OOK","Chirp;Bit error rate;Modulation;Receivers;Time-varying channels;Circuit stability;Internet of Things","","1","","15","IEEE","5 May 2021","","","IEEE","IEEE Conferences"
"Validation of ESDS Using Epidemic-Based Data Dissemination Algorithms","L. Guegan; I. Raïs; O. Anshus","Department of Computer Science, UiT The Arctic University of Norway, Tromso, Norway; Department of Computer Science, UiT The Arctic University of Norway, Tromso, Norway; Department of Computer Science, UiT The Arctic University of Norway, Tromso, Norway","2023 19th International Conference on Distributed Computing in Smart Systems and the Internet of Things (DCOSS-IoT)","27 Sep 2023","2023","","","277","284","The study of Distributed Systems (DS) is important as novel solutions in this area impact many sub-fields of Computer Science. Although, studying DS is not an easy task. A common approach is to deploy a test-bed to perform a precise evaluation of the system. This can be costly and time consuming for large scale platforms. Another solution is to perform network simulations, allowing for more flexibility and simplicity. Simulators implement various models such as wired/wireless network models and power consumption models. Extensible Simulator for Distributed Systems (ESDS) is a simulator designed for simulation of systems that include edge platforms, namely Internet of Things (IoT), Wireless Sensor Networks (WSN) and Cyber-Physical Systems (CPS). ESDS uses coarse-grained (flow-level) models for wired and wireless networks, and provides nodes power consumption models. However, to ensure accurate predictions, these models must be validated. In this paper, we propose to validate the flow-level wire-less model and the power consumption model of ESDS using epidemic-based data dissemination simulations. We show that ESDS has similar predictions than another validated flow-level network simulator, in terms of network performance and energy consumption.","2325-2944","979-8-3503-4649-7","10.1109/DCOSS-IoT58021.2023.00054","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10257278","network simulation;distributed systems;data dissemination;Internet of Things;Wireless Sensors Networks;Cyber-Physical Systems;Energy Consumption","Wireless sensor networks;Energy consumption;Power demand;Wireless networks;Computational modeling;Data dissemination;Electrostatic discharges","","","","34","IEEE","27 Sep 2023","","","IEEE","IEEE Conferences"
"Secure and Efficient k NN Classification for Industrial Internet of Things","H. Yang; S. Liang; J. Ni; H. Li; X. S. Shen","School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Electrical and Computer Engineering, Queen’s University, Kingston, Canada; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, Canada","IEEE Internet of Things Journal","12 Nov 2020","2020","7","11","10945","10954","The k-nearest neighbors (kNN) classification has been widely used for defective product identification and anomaly detection in the Industrial Internet of Things (IIoT). In this article, we propose a secure and efficient distributed kNN classification algorithm (SEED-kNN) to prevent information and control flow exposure while supporting large-scale data classification on distributed servers. Specifically, we first design a secure and efficient vector homomorphic encryption (VHE) scheme by constructing a key-switching matrix and a noise matrix for data encryption. Based on the designed VHE, SEEDkNN is proposed to efficiently achieve the confidentiality of data flow, kNN query, and class label, while enabling homomorphic operations on the encrypted data. Moreover, by leveraging the Map/Reduce architecture, SEED-kNN enables the kNN classification over the large-scale encrypted data on distributed servers for industrial control systems. Finally, we demonstrate that SEEDkNN achieves semantic security and high classification accuracy, and is applicable in IIoT due to its high efficiency.","2327-4662","","10.1109/JIOT.2020.2992349","National Key Research and Development Program of China(grant numbers:2017YFB0802300,2017YFB0802000,2017YFB0802003); National Natural Science Foundation of China(grant numbers:U1633114); Sichuan Science and Technology Program(grant numbers:2018GZ0202); State Key Laboratory of Cryptography(grant numbers:MMKFKT201912); Research Grant of the Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9086811","Big data;Industrial Internet of Things (IIoT);intelligent systems;machine learning (ML);security and privacy","Servers;Industrial control;Cryptography;Cloud computing;Distributed databases","","29","","38","IEEE","5 May 2020","","","IEEE","IEEE Journals"
"Towards Reinforcing Healthcare 4.0: A Green Real-Time IIoT Scheduling and Nesting Architecture for COVID-19 Large-Scale 3D Printing Tasks","L. R. Darwish; M. M. Farag; M. T. El-Wakad","Biomedical Engineering Department, Faculty of Engineering, Helwan University, Cairo, Egypt; Mechanical Engineering Department, School of Sciences and Engineering, The American University in Cairo, Cairo, Egypt; Faculty of Engineering and Technology, Future University in Egypt, Cairo, Egypt","IEEE Access","7 Dec 2020","2020","8","","213916","213927","With declaring the highly transmissible COVID-19 as a pandemic, an unprecedented strain on healthcare infrastructures worldwide occurred. An enormous shortage in the personal protective equipment (PPE) and the spare parts (SP) for the mechanical ventilators ensued as a consequence of the failure of the centralized global supply chains. Additive manufacturing and Industrial Internet of Things (IIoT), as the pillars of Industry 4.0, arose as the robust noncentralized alternatives. When gathered and properly managed in the IIoT, 3D Printers (3DPs) can complement and support Healthcare 4.0 to face the current and future pandemics. Thus, this paper proposes a real-time green allocation and scheduling architecture designed and dedicated particularly for the large-scale distributed 3D printing tasks (3DPTs) of both PPE and SPs. Our proposed architecture comprises; a broker (B) and a cluster manager (CM). Dynamic status check for the 3DPs and admission control for 3DPTs are among the interconnected roles of CM. CM also performs task allocation and scheduling according to our proposed Online Ascending Load-Balancing Modified Best-Fit (OALMBF) allocation algorithm and Green Real-time Nesting Priority-Based Adaptive (GRNPA) scheduling algorithm. The performance of the proposed architecture was investigated under extremely high-load environments which resulted in a success ratio and a response rate of 99.9667% and 10.9665 seconds, respectively, for the 3000 3DPTs trial. These results proved the robustness and the scalability of our architecture that surpasses its state-of-the-art counterparts. Besides respecting the real-time requirements of the 3DPTs, the proposed architecture improves the utilization of the 3DPs and guarantees an even workload distribution.","2169-3536","","10.1109/ACCESS.2020.3040544","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9269973","3D printing;COVID-19;Healthcare 40;IIoT;Industry 40;nesting;scheduling","Three-dimensional printing;COVID-19;Medical services;Task analysis;Three-dimensional displays;Pandemics;Heuristic algorithms","","13","","57","CCBYNCND","25 Nov 2020","","","IEEE","IEEE Journals"
"Large-Scale Cellular Coverage Analyses for UAV Data Relay via Channel Modeling","Y. Zhang; T. Arakawa; J. V. Krogmeier; C. R. Anderson; D. J. Love; D. R. Buckmaster","School of Electrical and Computer Engineering, Purdue University, 465 Northwestern Avenue, West Lafayette, IN, USA; School of Electrical and Computer Engineering, Purdue University, 465 Northwestern Avenue, West Lafayette, IN, USA; School of Electrical and Computer Engineering, Purdue University, 465 Northwestern Avenue, West Lafayette, IN, USA; Department of Electrical and Computer Engineering, United States Naval Academy, 105 Maryland Ave, Annapolis, MD, USA; School of Electrical and Computer Engineering, Purdue University, 465 Northwestern Avenue, West Lafayette, IN, USA; College of Agriculture, Purdue University, 615 West State Street, West Lafayette, IN, USA","ICC 2020 - 2020 IEEE International Conference on Communications (ICC)","27 Jul 2020","2020","","","1","6","With the rapid popularity of unmanned aerial vehicles (UAVs, also known as drones), UAV data relay has demonstrated potential extending wireless communication coverage, especially for rural areas. The flexibility of this approach has attracted research attention from a variety of areas, including Internet of Things, intelligent transportation systems, and digital agriculture. However, most current research effort focuses on modeling and theoretically optimizing data relay systems via UAV trajectories in simplified geographic environments, while taking advantage of UAVs for practical wireless communication networks requires large-scale quantitative performance analysis results based on real-life environment information. In this paper, we propose algorithms for generating large-scale blockage and path loss maps via terrain-based channel modeling for cellular communication systems with fixed-height relay drones. Our analyses reveal the coverage ratios for Tippecanoe County and the Wabash Heartland Innovation Network region in Indiana, with relay drones simulated at different heights. A coverage ratio gain over 40% can be achieved at a drone height of 100 m, compared to a typical pedestrian height of 1.5 m. These site-specific analyses are important in locating poorly covered spots and quantifying the coverage improvement from UAV data relay.","1938-1883","978-1-7281-5089-5","10.1109/ICC40277.2020.9149403","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9149403","Cellular coverage analysis;data relay;site-specific channel modeling;unmanned aerial vehicles","Poles and towers;Drones;Relays;Laser radar;Wireless communication;Fresnel reflection","","4","","16","IEEE","27 Jul 2020","","","IEEE","IEEE Conferences"
"Design and Batch Microfabrication of a High Precision Conductivity and Temperature Sensor for Marine Measurement","C. Wu; W. Gao; J. Zou; Q. Jin; J. Jian","Faculty of Electrical Engineering and Computer Science, Ningbo University, Ningbo, China; Faculty of Electrical Engineering and Computer Science, Ningbo University, Ningbo, China; Faculty of Electrical Engineering and Computer Science, Ningbo University, Ningbo, China; Faculty of Electrical Engineering and Computer Science, Ningbo University, Ningbo, China; Faculty of Electrical Engineering and Computer Science, Ningbo University, Ningbo, China","IEEE Sensors Journal","4 Aug 2020","2020","20","17","10179","10186","Precise meshing and three-dimensional monitoring of the marine environment are very important for marine resources exploration, fishery development, and military activities. Therefore, a high-precision, low power consumption, low-cost and multiparameter integrated miniaturized sensor has been in a large-scale demand. Besides, conductivity and temperature are the basic dynamic parameters of the ocean. This paper presents a high-precision conductivity and temperature (CT) integrated sensor based on the microelectro-mechanical system (MEMS) batch microfabrication technology, which has small size, low cost, high uniformity, and efficiency in meshing and three-dimensional marine measurements. In this study, the miniaturized CT sensor shows excellent linearity of conductivity (R2 ≥0.99999) and temperature (R2 ≥0.999) measurements. The temperature sensitivity of the CT sensor is 0.0619 °C/Q, and the cell constant of the CT sensor is 2.559 cm-1. The temperature test also shows the high repeatability with the variance coefficient of 0.6%. Furthermore, it shows an excellent consistency for batch. The coefficient of variance of cell constants is ±0.019 cm-1 and the 95% confidence intervals for the conductivity is demonstrated to be ±0.0048 mS/cm. The variance coefficient of the temperature sensor is only 1.8%. The results indicate that the batch microfabricated sensors are suitable for a large-scale deployment in the Marine Internet of Things.","1558-1748","","10.1109/JSEN.2020.2992730","National Science Foundation of China(grant numbers:61871243,61701267); Zhejiang Provincial Natural Science Foundation(grant numbers:LGF18F010004); Marine Biotechnology and Marine Engineering Discipline Group; K. C. Wong Magna Fund in Ningbo University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9088245","Batch microfabrication;CT miniaturized sensors;high precision;marine measurement","Temperature sensors;Temperature measurement;Conductivity;Electrodes;Ocean temperature;Sea measurements","","12","","31","IEEE","6 May 2020","","","IEEE","IEEE Journals"
"TMANomaly: Time-Series Mutual Adversarial Networks for Industrial Anomaly Detection","L. Zhang; W. Bai; X. Xie; L. Chen; P. Dong","College of Information Science and Engineering, Hunan Normal University, Changsha, China; College of Information Science and Engineering, Hunan Normal University, Changsha, China; College of Information Science and Engineering, Hunan Normal University, Changsha, China; College of Information Science and Engineering, Hunan Normal University, Changsha, China; College of Information Science and Engineering, Hunan Normal University, Changsha, China","IEEE Transactions on Industrial Informatics","22 Jan 2024","2024","20","2","2263","2271","Large-scale sewage treatment plants are one of the typical Industrial Internet of Things systems, where the presence of a large number of sensors generates massive dynamic time series data, and such multivariate time series data are usually time-dependent and random. Therefore, there is a certain risk when fitting the potential anomalies of real-world data, which will bring great challenges to anomaly detection. In this article, we propose a time-series mutual adversarial network (TMAN), a novel reconstruction model for anomaly detection on multivariate time series. It is based on the idea of adversarial learning and consists of two identical subnetworks. During the training process, two subnetworks can independently complete the learning of the time distribution of normal samples of industrial time series data for mutual adversarial. In the process of detecting, we obtain the residual values of TMAN reconstructed for different time series samples to discriminate anomalies. We combine TMAN and anomaly determination mechanisms to build a new industrial time series anomaly detection framework named TMANomaly. In addition, we select the dataset features with a grey correlation algorithm to achieve very high performance with a small number of features. Experimental results show that our proposed TMANomaly outperforms five popular anomaly detection methods and effectively improves the accuracy of industrial multivariate time series anomaly detection.","1941-0050","","10.1109/TII.2023.3288226","Natural Science Foundation of Hunan Province(grant numbers:2022JJ30398,2022JJ40277,2021JJ30455); Scientific Research Fund of Hunan Provincial Education Department(grant numbers:22A0056,22B0102); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10167479","Anomaly detection;generative adversarial networks (GANs);mutlivariate time series;mutual adversarial networks","Time series analysis;Anomaly detection;Generative adversarial networks;Industrial Internet of Things;Data models;Image reconstruction;Correlation","","","","29","IEEE","27 Jun 2023","","","IEEE","IEEE Journals"
"Research on intelligent charging management system of electric vehicle based on Low power Bluetooth technology","Y. Sun; G. Ma; J. Zhu; Y. Duan","School of Electronic and Information, Jiangsu University of Science and Technology, Zhenjiang, China; School of Electronic and Information, Jiangsu University of Science and Technology, Zhenjiang, China; School of Electronic and Information, Jiangsu University of Science and Technology, Zhenjiang, China; School of Electronic and Information, Jiangsu University of Science and Technology, Zhenjiang, China","2021 IEEE International Conference on Recent Advances in Systems Science and Engineering (RASSE)","25 Jan 2022","2021","","","1","6","The emission of automobile exhaust is undoubtedly one of the reasons for the degradation of the ecological environment. The increase in the price of non-renewable energy gasoline has limited the implementation of ordinary commercial vehicles. With the development of the Internet of Things technology, electric cars have become the transportation carrier promoted by significant cities based on their low cost of energy and electricity and their friendliness to the environment. As the source of electric vehicle power supply, the construction cost, network access capacity, and charging time of charging pile have become the focus of the problem. Currently, charging piles are used for infrastructure construction in the form of laying communication cables, which has a long construction period and high construction cost, and is not suitable for large-scale construction of charging stations, limiting the popularity of charging piles. The charging operation management system for users adopts the card swiping mode for man-machine interaction, which has few functions for users, increasing the user’s cost and reducing the user’s sense of experience. In this paper, the intelligent charging management system of electric vehicles based on low power Bluetooth technology is studied and improved from three aspects. (1) In terms of charging pile Communication, Power Line Communication technology is adopted for information transmission through existing Power lines, which eliminates the need to lay the Communication cables and transform charging piles, thus reducing construction period, strong anti-interference ability and comprehensive total cost; (2) Using low power Bluetooth technology to build a charging operation management system, relying on the wechat platform with a large number of users to expand user groups, reduce the difficulty of system operation, and make the system more widely promoted; (3) Study the influence of time interval and device delay on bluetooth transmission power consumption, and find the most suitable time interval to ensure communication rate and reduce power consumption. The intelligent charging management system for electric vehicles based on low-power Bluetooth technology has the characteristics of low cost, easy operation and convenient control of charging piles by mobile phones, which is conducive to the promotion and popularization of charging banks.","","978-1-6654-3441-6","10.1109/RASSE53195.2021.9686912","National Natural Science Foundation of China; Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9686912","Low Power Bluetooth technology;charging management system;Power Line Communication technology;time interval;device delay","Bluetooth;Costs;Power demand;Social networking (online);Charging stations;Electric vehicles;Mobile handsets","","","","10","IEEE","25 Jan 2022","","","IEEE","IEEE Conferences"
"Noise-Aware DVFS for Efficient Transitions on Battery-Powered IoT Devices","C. Zhuo; S. Luo; H. Gan; J. Hu; Z. Shi","College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; 1600 Amphitheatre Pkwy, Google, Inc., Mountain View, USA; Department of Electrical and Computer Engineering, Texas A&M University, College Station, USA; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","17 Jun 2020","2020","39","7","1498","1510","Low power system-on-chips (SoCs) are now at the heart of Internet-of-Things (IoT) devices, which are well-known for their bursty workloads and limited energy storage-usually in the form of tiny batteries. To ensure battery lifetime, dynamic voltage frequency scaling (DVFS) has become an essential technique in such SoC chips. With continuously decreasing supply level, noise margins in these devices are already being squeezed. During DVFS transition, large current that accompanies the clock speed transition runs into or out of clock networks in a few clock cycles, induces large Ldi/dt noise, thereby stressing the power delivery system (PDS). Due to the limited area and cost target, adding additional decoupling capacitance to mitigate such noise is usually challenging. A common approach is to gradually introduce/remove the additional clock cycles to increase/decrease the clock frequency in steps, also known as, clock skipping. However, such a technique may increase DVFS transition time, and still cannot guarantee minimal noise. In this paper, we propose a new noise-aware DVFS sequence optimization technique by formulating a mixed 0/1 programming to resolve the problems of clock skipping sequence optimization. Moreover, the method is also extended to schedule extensive wake-up activities on different clock domains for the same purpose. The experiments show that the optimized sequence is able to significantly mitigate noise within the desired transition time, thereby saving both power and energy.","1937-4151","","10.1109/TCAD.2019.2917844","National Natural Science Foundation of China(grant numbers:61601406); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8718252","Clock;dynamic voltage frequency scaling (DVFS);noise;optimization;power delivery","Clocks;Optimization;Power system management;Batteries;Schedules;Performance evaluation;Complexity theory","","66","","37","IEEE","20 May 2019","","","IEEE","IEEE Journals"
"DLCD-CCE: A Local Community Detection Algorithm for Complex IoT Networks","X. Xu; N. Hu; M. Trovati; J. Ray; F. Palmieri; H. M. Pandey","Jiangsu Key Laboratory of Big Data Security Intelligent Processing, Nanjing University of Posts and Telecommunications, Nanjing, China; Jiangsu Key Laboratory of Big Data Security Intelligent Processing, Nanjing University of Posts and Telecommunications, Nanjing, China; Department of Computer Science, Edge Hill University, Ormskirk, U.K.; Department of Computer Science, Edge Hill University, Ormskirk, U.K.; Department of Computer Science, University of Salerno, Fisciano, Italy; Department of Computer Science, Edge Hill University, Ormskirk, U.K.","IEEE Internet of Things Journal","13 May 2020","2020","7","5","4607","4615","Internet of Things (IoT) refers to the complex systems generated by the interconnections among widely available objects. Such interactions generate large networks, whose complexity needs to be addressed to provide suitable computationally efficient approaches. In this article, we propose a distributed local community detection algorithm based on specific properties of community center expansions (DLCD-CCE) for large-scale complex networks. The algorithm is evaluated via a prototype system, based on Spark, to verify its accuracy and scalability. The results demonstrate that compared to the typical local community detection algorithms, DLCD-CCE has better accuracy, stability, and scalability, and effectively overcomes the problem that existing algorithms are sensitive to the location of initial seeds.","2327-4662","","10.1109/JIOT.2019.2960743","National Basic Research Program of China (973 Program)(grant numbers:2018YFB1003702); “333” project of Jiangsu Province(grant numbers:BRA2017228); Talent Project in Six Fields of Jiangsu Province(grant numbers:2015-JNHB-012); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936466","Community detection;complex networks;Internet of Things (IoT);network dynamics","Sparks;Internet of Things;Detection algorithms;Big Data;Task analysis;Indexes;Clustering algorithms","","6","","26","IEEE","18 Dec 2019","","","IEEE","IEEE Journals"
"Empowering Solar Energy with Advanced IoT-Based Forecasting: A Hybrid Deep Learning Model for Enhanced Efficiency with Big Data","B. Dhanwanth; B. Dhanasakkaravarthi; J. V. G. Belshi; M. T A; S. Saranya; N. P","Department of CSE, Panimalar Institute of Technology, Chennai, India; Department of Mechanical Engineering, Agni College of Technology, Chennai, India; Department of AI & DS, Velammal Engineering College, Chennai, India; Department of CSE, Panimalar Engineeering College, Chennai, India; Department of AI & DS, Rajalakshmi Institute of Technology, Chennai, India; Department of AI & DS, St.joseph's College of Engineering, OMR, Chennai, India","2023 International Conference on Sustainable Communication Networks and Application (ICSCNA)","1 Jan 2024","2023","","","241","249","Solar power is a sustainable energy source that converts sunlight into electricity through photovoltaic panels in large solar facilities. Inverters play a crucial role by converting DC power to usable AC power, albeit with some energy loss. Efficiency relies on factors like solar irradiance, clear skies, clean panels, and unhindered sun exposure. Sensors on panels and inverters in large-scale installations monitor performance and aid in forecasting power generation and maintenance. The Internet of Things (IoT) facilitates remote monitoring and data accessibility, streamlining site assessment for solar power. Smart systems with sensors connected to an Arduino enable continuous monitoring of panel parameters. Short-term energy generation forecasting models are essential for integrating solar systems into smart grids, especially in smart cities. An advanced hybrid deep learning model combines clustering techniques, convolutional neural networks (CNNs), long short-term memory (LSTM) networks, and attention mechanisms to provide accurate energy generation forecasts. The model consists of three stages: Big Data clustering, training, and forecasting. Clustering identifies relevant historical data, and the training stage constructs a hybrid machine learning model. The testing stage selects the best model, leading to significant improvements in prediction accuracy compared to traditional methods.","","979-8-3503-1398-7","10.1109/ICSCNA58489.2023.10370040","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10370040","Convolutional neural network;Long short-term memory;Photovoltaic;Machine Learning;Big data","Deep learning;Predictive models;Data models;Hybrid power systems;Internet of Things;Forecasting;Intelligent sensors","","","","25","IEEE","1 Jan 2024","","","IEEE","IEEE Conferences"
"A scalable home automation IoT ecosystem using open source technologies","A. Phand; R. Bangar; R. Dani; J. Lohokare","College of Engineering Pune, Pune, India; College of Engineering Pune, Pune, India; University of California San Diego, La Jolla, CA, USA; Stony Brook University","7th International Conference on Computing in Engineering & Technology (ICCET 2022)","20 Jun 2022","2022","2022","","186","190","Home Automation provides remote access to appliances and devices in a home via the internet. While this is easily achievable on a small scale, the challenge is making the system deployable in a manner that is scalable across a whole city in a developing nation. This paper proposes an end-to-end home automation suite with modular open source components. Our backend supports multiple IoT protocols and is horizontally scalable. We implement a ‘Rules engine’ that analyzes real-time data and triggers various actions pre-determined by users. We also implement energy monitoring for judicial energy consumption in a home. Our system, when deployed, can handle data coming from homes for an entire city. Each user will have remote control of devices in his home through an android application. The user will also be able to define rules to trigger actions in his home via a web dashboard. The architecture used ensures that the system scales as the data traffic increases. Our experiments on the prototype system show low latency for real time analytics even when there are large simultaneous data streams. Our main feature contributions are the modular and dynamic nature of our system, scalability, and real time analytics for quick decision making.","","978-1-83953-704-2","10.1049/icp.2022.0615","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9800239","","","","","","","","20 Jun 2022","","","IET","IET Conferences"
"Big Data Driven Secure IoT Analytics with Trusted Execution Environments","M. S. Islam; L. Khan","Department of Computer Science, The University of Texas at Dallas, Richardson, Texas; Department of Computer Science, The University of Texas at Dallas, Richardson, Texas","2019 International Conference on Advances in the Emerging Computing Technologies (AECT)","10 Sep 2020","2020","","","1","6","The growing adoption of IoT devices in our daily life engendered a need for secure systems to safely store or analyze sensitive data, as well as a decentralized data processing system to handle vast amount of streaming data. The cloud services used to store data and process sensitive data are often come out to be vulnerable to outside threats. Moreover, to analyze enormous streaming data swiftly, they are in need of a fast and efficient system. In this paper we propose a framework to maintain confidentiality and integrity of IoT data, which is of paramount importance, and manage large-scale data analytics. We design the framework to preserve data privacy utilizing Trusted Execution Environment (TEE) such as Intel SGX, and end-to-end data encryption mechanism. In addition, we utilize Apache Spark for fast real-time streaming data processing from many IoT devices. We evaluate the framework by performing simple decision making in the SGX securely that involves multiple IoT devices, and a real-time anomaly detection in the streaming data from IoT devices using Spark.","","978-1-7281-4452-8","10.1109/AECT47998.2020.9194185","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9194185","Intel SGX;Apache Spark;Data privacy","DH-HEMTs","","1","","21","IEEE","10 Sep 2020","","","IEEE","IEEE Conferences"
"Simplified Multi-objective Optimization for Flexible IoT Edge Computing","T. Ogino","Department of Information Science, Meisei University, Tokyo, JAPAN","2021 4th International Conference on Information and Computer Technologies (ICICT)","15 Jul 2021","2021","","","168","173","In large-scale, cloud-based IoT systems, challenges such as increased network load, response delays, and invasion of privacy are serious concerns in recent years. As a solution, edge computing (EC) has been introduced into these IoT systems. However, if too much of the cloud functionality is migrated to the edge, then the collected data cannot be shared between IoT systems, thereby decreasing its usefulness. We propose a multi-agent-based flexible IoT-EC architecture that balances the global optimization by the cloud with local optimization at the edges to optimize the roles of the cloud and edge servers dynamically. In this paper, we explain the simplified multi-objective optimization solutions for IoT EC. We also execute a simple traffic simulation to evaluate the proposed method.","","978-1-6654-1399-2","10.1109/ICICT52872.2021.00035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9476909","IoT;edge computing;cloud computing;flexible;multi-agent;multi-objective optimization","Privacy;Computer architecture;Traffic control;Delays;Servers;Optimization;Edge computing","","3","","8","IEEE","15 Jul 2021","","","IEEE","IEEE Conferences"
"Efficient Register Renaming Architectures for 8-bit AES Datapath at 0.55 pJ/bit in 16-nm FinFET","S. N. Dhanuskodi; S. Allen; D. E. Holcomb","Department of Electrical and Computer Engineering, University of Massachusetts, Amherst, USA; Department of Electrical and Computer Engineering, University of Massachusetts, Amherst, USA; Department of Electrical and Computer Engineering, University of Massachusetts, Amherst, USA","IEEE Transactions on Very Large Scale Integration (VLSI) Systems","28 Jul 2020","2020","28","8","1807","1820","Small-footprint implementations of the advanced encryption standard (AES) algorithm are of interest in resource-constrained applications like Internet of Things (IoT). Symmetries in AES allow the datapath to be scaled down to the S-Box width of 8 bits, but the ShiftRows operation leads to a potential data hazard that must be avoided. The common method for resolving the ShiftRows hazard wastes power by moving data through a sequence of pipelined registers. We present in this article a novel 8-bit AES architecture that solves data movement inefficiencies by renaming registers and saves clock power with a single state update per AES round. We then extend register renaming to include microarchitectural randomization to mitigate susceptibility to side-channel attacks, which are a concern especially for low power implementations of AES. We fabricate and evaluate our designs in a commercial 16-nm FinFET technology. Testchip measurements show that the register renaming architecture encrypts data at 0.55 pJ/bit at nominal voltage, a 2.2× improvement over a state-of-the-art reference 8-bit design implemented in the same technology. Side-channel evaluation indicates that the randomized variant of register renaming significantly reduces vulnerability to differential power analysis (DPA).","1557-9999","","10.1109/TVLSI.2020.2999593","National Science Foundation (NSF) through the STARSS Program(grant numbers:CNS-1619558); Semiconductor Research Corporation Task 2685.001; NSF(grant numbers:CNS-1749845); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9115902","Advanced encryption standard (AES);differential power analysis (DPA);energy efficiency;Internet of Things (IoT);low power;randomization;side channel","Registers;Computer architecture;Side-channel attacks;Encryption;Clocks;Power demand;Microarchitecture","","6","","44","IEEE","12 Jun 2020","","","IEEE","IEEE Journals"
"Research on the Construction and Application of Intelligent IoT System under Source Network Load Storage Collaboration","L. Chen; S. Zhou; H. Liu; M. Zhao; N. Niu","State Grid Zhejiang Electric Power Co., Ltd., China; State Grid Zhejiang Electric Power Co., Ltd., China; Beijing SGITG Accenture Information Technology Center CO., Ltd., China; Beijing SGITG Accenture Information Technology Center CO., Ltd., China; Beijing SGITG Accenture Information Technology Center CO., Ltd., China","2023 IEEE Sustainable Power and Energy Conference (iSPEC)","25 Jan 2024","2023","","","1","5","In recent years, with the large-scale development of the integration of source, network, load, and storage, as well as the innovative application of new technologies such as cloud, big, and mobile intelligent chains in the field of power, the IoT in power has developed rapidly and achieved certain results. However, in the process of development, problems such as insufficient real-time perception of various specialties, difficulty in sharing and reusing resources, and insufficient level of business intelligence have been exposed. This paper summarizes the principles of the current intelligent IoT system construction in the power grid, constructs the overall framework of the intelligent IoT system under the coordination of source network load storage, and explores IoT technology from typical scenarios, providing reference for the construction and application of intelligent IoT systems in the power industry.","2837-522X","979-8-3503-2269-9","10.1109/iSPEC58282.2023.10402809","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10402809","Source grid load storage;electricity IoT;resource reuse;intelligent IoT system;typical scenario","Collaboration;Solids;Real-time systems;Power industry;Power grids;Business intelligence","","","","15","IEEE","25 Jan 2024","","","IEEE","IEEE Conferences"
"IoT Based Greenhouse Environment Monitoring and Smart Irrigation System for Precision Farming Technology","A. Chakraborty; M. Islam; A. Dhar; M. S. Hossain","Dept. of EEE, University of Science and Technology, Chittagong, Chattogram, Bangladesh; Dept. of EEE, University of Science and Technology, Chittagong, Chattogram, Bangladesh; Dept. of EEE, University of Science and Technology, Chittagong, Chattogram, Bangladesh; Dept. of EEE, University of Science and Technology, Chittagong, Chattogram, Bangladesh","2022 International Conference on Innovations in Science, Engineering and Technology (ICISET)","23 May 2022","2022","","","123","128","Climate change and global warming, population bursts, shortages of water, lack of cultivable land, soil erosion, and other critical reasons have had a drastic effect on agricultural food production in recent decades. The incorporation of IoT and innovative technologies can help increase productivity and improve the quality of the farming industry. This research proposes an intelligent solution to the current agricultural problem by providing environmental monitoring and irrigation facilities with the help of IoT. The system offers monitoring of a greenhouse’s temperature, humidity, soil moisture, and light intensity onsite and remotely using IoT. Additionally, a smart irrigation system has been integrated for efficient water supply. For IoT communication and real-time data monitoring, the BLYNK application is used. The IoT system also features direct control of the water pump if any problem occurs in the smart irrigation system. Results from small-scale implementation are shown and analyzed. From the research results, it is predicted that the real-life performance of the IoT-based monitoring and smart irrigation systems will be a pioneer in the creation of an economically feasible solution for sustainable farming technology.","","978-1-6654-8397-1","10.1109/ICISET54810.2022.9775852","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9775852","Smart Farm;Precision Farming;Smart Irrigation;Internet of Things;BLYNK;NodeMCU ESP32;Sensor","Irrigation;Wireless sensor networks;Climate change;Green products;Crops;Air pollution;Water pumps","","12","","21","IEEE","23 May 2022","","","IEEE","IEEE Conferences"
"Smart Home/Office Energy Management based on Individual Data Analysis through IoT Networks","G. -L. Huang; A. Anwar; S. W. Loke; A. Zaslavsky; J. Choi","School of Information Technology, Deakin University, Geelong, Australia; School of Information Technology, Deakin University, Geelong, Australia; School of Information Technology, Deakin University, Geelong, Australia; School of Information Technology, Deakin University, Geelong, Australia; School of Information Technology, Deakin University, Geelong, Australia","2022 IEEE International Conference on Communications, Control, and Computing Technologies for Smart Grids (SmartGridComm)","1 Dec 2022","2022","","","302","308","Sustainable use of energy requires to achieve optimal energy utilization in smart grid systems. It is possible by empowering the Internet of Things (IoT) based Wireless connectivity through real-time energy monitoring and analyses of power consumption patterns. Modeling optimal energy utilization considering multi-user behaviors is particularly challenging in such context. To address the challenge of one-to-one-mapping of energy disaggregation in device-sharing environments by multiple co-existing users, a new method based on data-driven machine learning (e.g., individual energy usage pattern analysis) is proposed in this paper that aims to accurately match the energy consumption of electrical appliances with specific users. In particular, the machine learning model with the best performance is selected for real-time energy/power disaggregation on the local server (i.e., small-scale home/office) to ensure comparable or better performance with state-of-the-art disaggregation algorithms. In addition, energy usage patterns and individual power consumption data are analyzed comprehensively to match overall energy consumption and label datasets by events. Distributed learning is also discussed to exploit other local servers' datasets for better disaggregation through IoT networks. The effectiveness of the proposed method is verified by using simulated datasets in a motivating scenario.","","978-1-6654-3254-2","10.1109/SmartGridComm52983.2022.9961051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9961051","Smart Energy Management;Energy Data Analysis;Energy Disaggregation;Wireless IoT;Power consumption","Wireless communication;Energy consumption;Machine learning;Predictive models;Real-time systems;Smart grids;Servers","","","","39","IEEE","1 Dec 2022","","","IEEE","IEEE Conferences"
"Industrial IoT in 5G-and-Beyond Networks: Vision, Architecture, and Design Trends","A. Mahmood; L. Beltramelli; S. Fakhrul Abedin; S. Zeb; N. I. Mowla; S. A. Hassan; E. Sisinni; M. Gidlund","Department of Information Systems and Technology, Mid Sweden University, Sundsvall, Sweden; Department of Information Systems and Technology, Mid Sweden University, Sundsvall, Sweden; Department of Information Systems and Technology, Mid Sweden University, Sundsvall, Sweden; School of Electrical Engineering and Computer Science, National University of Science and Technology, Islamabad, Pakistan; Department of Mobility and Systems, RISE Research Institutes of Sweden, Gothenburg, Sweden; School of Electrical Engineering and Computer Science, National University of Science and Technology, Islamabad, Pakistan; Department of Information Engineering, University of Brescia, Brescia, Italy; Department of Information Systems and Technology, Mid Sweden University, Sundsvall, Sweden","IEEE Transactions on Industrial Informatics","21 Feb 2022","2022","18","6","4122","4137","Cellular networks are envisioned to be a cornerstone in future industrial Internet of Things (IIoT) wireless connectivity in terms of fulfilling the industrial-grade coverage, capacity, robustness, and timeliness requirements. This vision has led to the design of vertical-centric service-based architecture of 5G radio access and core networks. The design incorporates the capabilities to include 5G-AI-Edge ecosystem for computing, intelligence, and flexible deployment and integration options (e.g., centralized and distributed, physical, and virtual) while eliminating the privacy/security concerns of mission-critical systems. In this article, driven by the industrial interest in enabling large-scale wireless IIoT deployments for operational agility, flexible, and cost-efficient production, we present the state-of-the-art 5G architecture, transformative technologies, and recent design trends, which we also selectively supplemented with new results. We also identify several research challenges in these promising design trends that beyond-5G systems must overcome to support rapidly unfolding transition in creating value-centric industrial wireless networks.","1941-0050","","10.1109/TII.2021.3115697","KKS Research Profile NIIT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9548837","Industrial Internet of Things (IIoT);Industry 4.0;millimeter-wave (mmWave) multiple-input multiple-output (MIMO) capacity;new radio in unlicensed bands (NR-U);open radio access network (RAN);private 5G;security;time-sensitive networking (TSN);5G-and-beyond","5G mobile communication;Industrial Internet of Things;Wireless sensor networks;Wireless communication;Market research;Computer architecture;Industries","","72","","111","IEEE","27 Sep 2021","","","IEEE","IEEE Journals"
"Learning-Based Resource Allocation Strategy for Industrial IoT in UAV-Enabled MEC Systems","L. Sun; L. Wan; X. Wang","Institute of Information Science and Technology, Department of Communication Engineering, Dalian Maritime University, Dalian, China; School of Software, Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, Dalian University of Technology, Dalian, China; State Key Laboratory of Marine Resource Utilization in South China Sea and the College of Information Science, and Technology, Hainan University, Haikou, China","IEEE Transactions on Industrial Informatics","5 Apr 2021","2021","17","7","5031","5040","Forest fire monitoring plays an important role in forest resource protection. Although satellite remote sensing is an effective way for forest fire monitoring, satellite-based methods can only monitor large-scale forest areas, and they are weak in predicting the specific areas of forest fires. In this article, we first propose an unmanned aerial vehicle (UAV)-enabled system architecture consisting of multiple industrial Internet of Things (IIoTs), in which the data collected by sensors in IIoTs can be delivered to UAVs for processing directly. As the sensors of IIoTs are deployed to monitor different indexes of forest fires, fully considering the priority constraints among sensors can guarantee a quick response of forest fire monitoring. Thus, the priority constraints among the sensors are taken into consideration in this system architecture, and the objective is to minimize the maximum response time of forest fire monitoring. To search for the optimal UAV resource allocation strategy, a learning-based cooperative particle swarm optimization (LCPSO) algorithm with a Markov random field (MRF)-based decomposition strategy is proposed. The solution space of UAV resource allocation is decomposed into subsolution spaces according to the decomposed decision variables by the MRF network structure, and the optimal resource allocation strategy is searched by LCPSO in multiple subsolution spaces cooperatively. Three simulation experiments on two datasets are designed, and the simulation results compared with the state-of-the-art methods verify the validity of LCPSO, which are reflected by the quickest response time of forest fire monitoring.","1941-0050","","10.1109/TII.2020.3024170","National Natural Science Foundation of China(grant numbers:61701144,61801076); Program of Hainan Association for Science and Technology Plans to Youth R&D Innovation(grant numbers:QCXM201706); Scientific Research Projects of University in Hainan Province(grant numbers:Hnky2018ZD-4); Young Elite Scientists Sponsorship Program by CAST(grant numbers:2018QNRC001); Scientific Research Setup Fund of Hainan University(grant numbers:KYQD (ZR)1731); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9197688","Industrial Internet of things (IIoT);Markov random field (MRF);mobile edge computing (MEC) system;resource allocation;unmanned aerial vehicles (UAVs)","Forestry;Monitoring;Resource management;Temperature sensors;Task analysis;Systems architecture","","66","","41","IEEE","15 Sep 2020","","","IEEE","IEEE Journals"
"FCDedup: A Two-Level Deduplication System for Encrypted Data in Fog Computing","M. Song; Z. Hua; Y. Zheng; T. Xiang; X. Jia","School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, Guangdong, China; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, Guangdong, China; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, Guangdong, China; College of Computer Science, Chongqing University, Chongqing, China; Department of Computer Science, City University of Hong Kong, Kowloon Tong, Hong Kong","IEEE Transactions on Parallel and Distributed Systems","3 Aug 2023","2023","34","10","2642","2656","Distributed fog computing has received increasing attention recently and fog-assisted cloud storage can provide a real-time service to collect and manage large-scale data for the applications of Internet of Things. Encrypted data deduplication over cloud storage can significantly save storage space of the cloud server while protecting the confidentiality of the outsourced data. Previous encrypted data deduplication schemes are mostly designed for traditional cloud storage with a two-layer architecture and cannot be applied to the emerging fog-assisted cloud storage that has a more complex three-layer architecture (i.e., cloud server, fog node and endpoint device). In this paper, we design, analyze and implement FCDedup, a new encrypted data deduplication scheme for fog-assisted cloud storage. FCDedup is a two-level deduplication system that enables each fog node to detect duplicated encrypted data uploaded by different endpoint devices, as well as enables cloud server to detect duplicated encrypted data from different fog nodes. By doing so, FCDedup can achieve both intra-deduplication within a single data owner and inter-deduplication across different data owners. FCDedup is also designed to prevent cloud server and fog nodes launching the brute-force attacks, and to guarantee the reliability of files downloaded from the cloud. Formal analysis is provided to justify its deduplication correctness and security. Besides, we implement a prototype of FCDedup using Alibaba Cloud as backend storage. Our evaluations demonstrate that FCDedup is completely compatible with existing cloud storage systems and achieves modest performance overhead.","1558-2183","","10.1109/TPDS.2023.3298684","National Key R&D Program of China(grant numbers:2022YFB3103500); National Natural Science Foundation of China(grant numbers:62071142); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2021A1515110027,2021A1515011406,2023A1515010714); Shenzhen Science and Technology Program(grant numbers:RCBS20210609103056041,JCYJ20220531095416037); Guangdong Provincial Key Laboratory of Novel Security Intelligence Technologies(grant numbers:2022B1212010005); Shenzhen Science and Technology Program(grant numbers:ZDSYS20210623091809029); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10193829","Brute-force attacks;data reliability;encrypted data deduplication;fog-assisted cloud storage","Cloud computing;Servers;Encryption;Reliability;Edge computing;Costs;Fingerprint recognition","","1","","46","IEEE","25 Jul 2023","","","IEEE","IEEE Journals"
"Backbones for Internet of Battlefield Things","D. Papakostas; T. Kasidakis; E. Fragkou; D. Katsaros","Department of Electrical & Computer Engineering, University of Thessaly, Greece; Department of Electrical & Computer Engineering, University of Thessaly, Greece; Department of Electrical & Computer Engineering, University of Thessaly, Greece; Department of Electrical & Computer Engineering, University of Thessaly, Greece","2021 16th Annual Conference on Wireless On-demand Network Systems and Services Conference (WONS)","6 May 2021","2021","","","1","8","The Internet of Battlefield Things is a relatively new cyberphysical system and even though it shares a lot of concepts from the Internet of Things and wireless ad hoc networking in general, a lot of research is required to address its scale and peculiarities. In this article we examine a fundamental problem pertaining to the routing/dissemination of information, namely the construction of a backbone. We model an IoBT ad hoc network as a multilayer network and employ the concept of domination for multilayer networks which is a complete departure from the volume of earlier works, in order to select sets of nodes that will support the routing of information. Even though there is huge literature on similar topics during the past many years, the problem in military (IoBT) networks is quite different since these wireless networks are multilayer networks and treating them as a single (flat) network or treating each layer in isolation and calculating dominating set produces submoptimal or bad solutions; thus all the past literature which deals with single layer (flat) networks is in principle inappropriate. We design a new, distributed algorithm for calculating connected dominating sets which produces dominating sets of small cardinality. We evaluate the proposed algorithm on synthetic topologies, and compare it against the only two existing competitors. The proposed algorithm establishes itself as the clear winner in all experiments.","","978-3-903176-35-5","10.23919/WONS51326.2021.9415560","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9415560","Dominating sets;multilayer networks;Internet of Battlefield Things;adhoc networking","Solid modeling;Machine learning algorithms;Network topology;Wireless networks;Nonhomogeneous media;Ad hoc networks;Partitioning algorithms","","4","","30","","6 May 2021","","","IEEE","IEEE Conferences"
"Physical-Layer Security in Space Information Networks: A Survey","B. Li; Z. Fei; C. Zhou; Y. Zhang","School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China; Institute of High Energy Physics, Chinese Academy of Sciences, Beijing, China; Department of Informatics, University of Oslo, Oslo, Norway","IEEE Internet of Things Journal","10 Jan 2020","2020","7","1","33","52","Research and processing development on satellite communications has strongly re-emerged in recent years. Following the prosperity of various wireless services provided by satellite communications, the security issue has raised growing concerns since the space information network is susceptible to be eavesdropped by illegal adversaries in such a large-scale wireless network. Recently, the physical-layer security (PLS) has emerged as an alternative security paradigm that explores the randomness of the wireless channel to achieve confidentiality and authentication. The success story of the PLS technique now spans a decade and thrives to provide a layer of defense in satellite communications. With this position, a comprehensive survey of satellite communications is conducted in this article with an emphasis on PLS. We first briefly introduce essential background and the view of the satellite Internet of Things (IoT), as well as discuss related research challenges faced by the emerging integrated network architecture. Then, we revisit the most popular satellite channel model influenced by many factors and list the commonly used secrecy performance metrics. Also, we provide an exhaustive review of state-of-the-art research activity on PLS in satellite communications, which we categorize by different architectures including land mobile satellite communication networks, hybrid satellite-terrestrial relay networks, and satellite-terrestrial integrated networks. In addition, a number of open research problems are identified as possible future research directions.","2327-4662","","10.1109/JIOT.2019.2943900","National Natural Science Foundation of China(grant numbers:61871032,61901447); European Union’s Horizon 2020 Research and Innovation Programme under Marie Skłodowska-Curie(grant numbers:824019); Sichuan Science and Technology Program(grant numbers:2019YFH0033); Startup Foundation for Introducing Talent of Nanjing University of Information Science and Technology; Guilin University of Electronic Technology(grant numbers:CRKL190204); Priority Academic Program Development of Jiangsu Higher Education Institutions; Natural Science Foundation of Shandong Province(grant numbers:ZR2019PF018); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8850067","Fifth generation (5G) and beyond;heterogeneous networks;satellite communication;satellite Internet of Things (IoT);security","Satellite broadcasting;Security;Satellites;Internet of Things;Earth;Wireless communication","","129","","135","IEEE","26 Sep 2019","","","IEEE","IEEE Journals"
"Distributed-to-Centralized Data Management: A New Sense of Large-Scale ICT Management of Smart City IoT Networks","A. Sinaeepourfard; J. Krogstie; S. Sengupta","Norwegian University of Science and Technology (NTNU); IDI Department; Fundació i2CAT, Spain","IEEE Internet of Things Magazine","27 Oct 2020","2020","3","3","76","82","Modern cities are equipped with various information and communications technology (ICT) resources including Internet of Things (IoT) devices, computing platforms, and data storage media. Data are one of the most valuable ICT resources in smart cities. Data management strategies play a vital role in managing the requirements of user and business models in a city. Using the benefits of data makes an agile, creative, and smart city via the widespread use of appropriate city services. Centralized and distributed-to-centralized data management (D2CDM) architectures are recommended to organize the large-scale produced city data in smart city networks, including physical data resources (e.g., sensor data) and nonphysical data sources (e.g., city consumer personal databases). In this article, we explain two different ICT technology management solutions for smart city networks in which the ICT resources in a city can be managed and delivered: centralized and distributed-to-centralized. We also describe two main strategies for data management in smart cities, and the advantages of D2C-DM are discussed based on two ongoing case studies. We also mention there is much room for future works and development of this study, such as developing software services in smart cities based on edge-to-cloud orchestration and enhancing the effectiveness of machine learning (ML) and artificial intelligence (AI) techniques through multilevel ICT architecture.","2576-3199","","10.1109/IOTM.0001.1900038","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9241477","","Smart cities;Computer architecture;Distributed databases;Cloud computing;Internet of Things;Information and communications technology","","9","","20","IEEE","27 Oct 2020","","","IEEE","IEEE Magazines"
"DPS: Dynamic Pricing and Scheduling for Distributed Machine Learning Jobs in Edge-Cloud Networks","R. Zhou; N. Wang; Y. Huang; J. Pang; H. Chen","School of Computer Science and Engineering, Southeast University, NanJing, China; School of Computer Science, Wuhan University, Wuhan, China; Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Huawei, Nanjing, China","IEEE Transactions on Mobile Computing","3 Oct 2023","2023","22","11","6377","6393","5G and Internet of Things stimulate smart applications of edge computing, such as autonomous driving and smart city. As edge computing power increases, more and more machine learning (ML) jobs will be trained in the edge-cloud network, adopting the parameter server (PS) architecture. Due to the distinct features of the edge (low-latency and the scarcity of resources), the cloud (high delay and rich computing capacity) and ML jobs (frequent communication between workers and PSs and unfixed runtime), existing cloud job pricing and scheduling algorithms are not applicable. Therefore, how to price, deploy and schedule ML jobs in the edge-cloud network becomes a challenging problem. To solve it, we propose an auction-based online framework DPS. DPS consists of three major parts: job admission control, price function design and scheduling orchestrator. DPS dynamically prices workers and PSs based on historical job information and real-time system status, and decides whether to accept the job according to the deployment cost. DPS then deploys and schedules accepted ML jobs to pursue the maximum social welfare. Through theoretical analysis, we prove that DPS can achieve a good competition ratio and truthfulness in polynomial time. Large-scale simulations and testbed experiments show that DPS can improve social welfare by at least $95\%$95%, compared with benchmark algorithms in today's cloud system.","1558-0660","","10.1109/TMC.2022.3195765","National Natural Science Foundation of China(grant numbers:62072344,U20A20177); Hubei Science Foundation(grant numbers:2020CFB195); Compact Exponential Algorithm Project of Huawei(grant numbers:YBN2020035131); Huawei Project(grant numbers:FA2019071041); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9847354","Distributed machine learning;online pricing;online scheduling;parameter server architecture;edge-cloud networks","Pricing;Servers;Cloud computing;Biological system modeling;Computational modeling;Heuristic algorithms;Training","","3","","58","IEEE","2 Aug 2022","","","IEEE","IEEE Journals"
"Smart Watering System using Fuzzy Logic","V. Ramya; A. Kumar; A. H; A. Kumar; A. B. M","Department of Electronics and Communication, MVJ College of Engineering, Bangalore, India; Department of Electronics and Communication, MVJ College of Engineering, Bangalore, India; Department of Electronics and Communication, MVJ College of Engineering, Bangalore, India; Department of Electronics and Communication, MVJ College of Engineering, Bangalore, India; Department of Electronics and Communication, MVJ College of Engineering, Bangalore, India","2021 International Conference on Design Innovations for 3Cs Compute Communicate Control (ICDI3C)","27 Sep 2021","2021","","","297","300","This study tells an intelligent Smart Watering System (SWS) for smart water consumption in small and medium sized gardens, which is helped by an Android application. Gardens and fields of a medium scale. The system that has been proposed is based on a set of low-cost and inexpensive sensors obtain information on plants and their surroundings, such as moisture content of soil, intensity of light, humidity of air and Temperature in air.Data from sensors are gathered on a server, the suggested SWS uses a Block-chain and Fuzzy Logic technique to determine the watering schedule. In this scenario, Fuzzy Logic aids in making smart watering decisions, while Block-chain offers the necessary safety in an IoT-enabled system by accessing only trusted devices to allow and manage proposed watering schedules. In the proposed IoT base smart system, Block chain technology takes part an essential character in our approach by offering scalability, insularity, and dependability. Observing and engaging with plants with the help of the SWS Developed on Android (SWS) Application. The SWS triggers the actuators to perform watering activities such as switching water tunnels ON/OFF on a regular basis when the Fuzzy Logic-based system determine on an action based on the values of the input variables.","","978-1-6654-2569-8","10.1109/ICDI3C53598.2021.00066","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9545219","IOT;Block chain;Sensors;Fuzzy Logic Approach","Temperature sensors;Productivity;Fuzzy logic;Schedules;Humidity;Sensor systems;Real-time systems","","3","","5","IEEE","27 Sep 2021","","","IEEE","IEEE Conferences"
"Enhancing Smart Agriculture Scenarios with Low-code, Pattern-oriented functionalities for Cloud/Edge collaboration","G. Fatouros; G. Kousiouris; T. Lohier; G. Makridis; A. Polyviou; J. Soldatos; D. Kyriazis","Dept. of Digital Systems, University of Piraeus, Piraeus, Greece; Dept. of Informatics and Telematics, Harokopio University, Athens, Greece; CybeleTech, Montrouge, France; Dept. of Digital Systems, University of Piraeus, Piraeus, Greece; Dept. of Management, University of Nicosia, Nicosia, Cyprus; Innov-Acts Ltd, Nicosia, Cyprus; Dept. of Digital Systems, University of Piraeus, Piraeus, Greece","2023 19th International Conference on Distributed Computing in Smart Systems and the Internet of Things (DCOSS-IoT)","27 Sep 2023","2023","","","285","292","The integration of cloud computing and Internet of Things (IoT) technologies has brought significant advancements in the agriculture domain. However, the implementation of such systems often requires significant time and resources, making it challenging for smart agriculture providers to offer optimized yet affordable services for small and medium-sized farmers at scale. Low-code development platforms can be a viable solution to address these challenges, enabling non-experts to adapt or enhance existing applications with minimal coding. This paper presents a low-code approach to enhance smart agriculture scenarios with pattern-oriented functionality blocks for cloud/edge collaboration. It highlights the usage of a pattern collection for redesigning the implementation of smart agriculture applications that can enhance the data collection process as well as real-time decision-making and efficient resource management in the continuum. The effectiveness of the presented approach is demonstrated through the implementation of a case study in smart agriculture greenhouses. Evaluation results show that this approach can significantly reduce the time and effort required to deploy smart agriculture applications and provide data resilience.","2325-2944","979-8-3503-4649-7","10.1109/DCOSS-IoT58021.2023.00055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10257242","smart agriculture;low code;cloud patterns;data resilience;IoT;function as a service","Smart agriculture;Cloud computing;Collaboration;Greenhouses;Real-time systems;Encoding;Internet of Things","","","","43","IEEE","27 Sep 2023","","","IEEE","IEEE Conferences"
"Graph Attention Spatial-Temporal Network With Collaborative Global-Local Learning for Citywide Mobile Traffic Prediction","K. He; X. Chen; Q. Wu; S. Yu; Z. Zhou","School of Data and Computer Science, Sun Yat-Sen University, Guangzhou, Guangdong, China; School of Data and Computer Science, Sun Yat-Sen University, Guangzhou, Guangdong, China; School of Data and Computer Science, Sun Yat-Sen University, Guangzhou, Guangdong, China; School of Data and Computer Science, Sun Yat-Sen University, Guangzhou, Guangdong, China; School of Data and Computer Science, Sun Yat-Sen University, Guangzhou, Guangdong, China","IEEE Transactions on Mobile Computing","4 Mar 2022","2022","21","4","1244","1256","With the rapid development of mobile cellular technologies and the increasing popularity of mobile and Internet of Things (IoT) devices, timely mobile traffic forecasting with high accuracy becomes more and more critical for proactive network service provisioning and efficient network resource allocation in smart cities. Traditional traffic forecasting methods mostly rely on time series prediction techniques, which fail to capture the complicated dynamic nature and spatial relations of mobile traffic demand. In this paper, we propose a novel deep learning framework, graph attention spatial-temporal network (GASTN), for accurate citywide mobile traffic forecasting, which can capture not only local geographical dependency but also distant inter-region relationship when considering spatial factor. Specifically, GASTN considers spatial correlation through our constructed spatial relation graph and utilizes structural recurrent neural networks to model the global near-far spatial relationships as well as the temporal dependencies. In the framework of GASTN, two attention mechanisms are designed to integrate different effects in a holistic way. Besides, in order to further enhance the prediction performance, we propose a collaborative global-local learning strategy for the training of GASTN, which takes full advantage of the knowledge from both the global model and local models for individual regions and enhance the effectiveness of our model. Extensive experiments on a large-scale real-world mobile traffic dataset demonstrate that our GASTN model dramatically outperforms the state-of-the-art methods. And it reveals that a significant enhancement in the prediction performance of GASTN can be obtained by leveraging the collaborative global-local learning strategy.","1558-0660","","10.1109/TMC.2020.3020582","National Natural Science Foundation of China(grant numbers:U1711265,61972432); Program for Guangdong Introducing Innovative and Entrepreneurial Teams(grant numbers:2017ZT07X355); Guangdong Provincial Pearl River Talents Program(grant numbers:2017GC010465); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9184280","Mobile traffic prediction;collaborative learning;spatial-temporal network;smart city services","Predictive models;Correlation;Forecasting;Collaboration;Time series analysis;Urban areas;Collaborative work","","30","","43","IEEE","1 Sep 2020","","","IEEE","IEEE Journals"
"Spectrum Sharing for Massive Access in Ultra-Narrowband IoT Systems","G. Hattab; P. Popovski; D. Cabric","Department of Electrical and Computer Engineering, University of California at Los Angeles, Los Angeles, CA, USA; Department of Electronic Systems, Aalborg University, Aalborg, Denmark; Department of Electrical and Computer Engineering, University of California at Los Angeles, Los Angeles, CA, USA","IEEE Journal on Selected Areas in Communications","18 Feb 2021","2021","39","3","866","880","Ultra-narrowband (UNB) communications has become a signature feature for many emerging low-power wide-area (LPWA) networks. Specifically, using extremely narrowband signals helps the network connect more Internet-of-things (IoT) devices within a given band. It also improves robustness to interference, extending the coverage of the network. In this article, we study the coexistence capability of UNB networks and their scalability to enable massive access. To this end, we develop a stochastic geometry framework to analyze and model UNB networks on a large scale. The framework captures the unique characteristics of UNB communications, including the asynchronous time-frequency access, signal repetition, and the absence of base station (BS) association. Closed-form expressions of the transmission success probability and network connection density are presented for several UNB protocols. We further discuss multiband access for UNB networks, proposing a low-complexity protocol. Our analysis reveals several insights on the geographical diversity achieved when devices do not connect to a single BS, the optimal number of signal repetitions, and how to utilize multiple bands without increasing the complexity of BSs. Simulation results are provided to validate the analysis, and they show that UNB communications enables a single BS to connect thousands of devices even when the spectrum is shared with other networks.","1558-0008","","10.1109/JSAC.2020.3018797","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9180037","Internet of Things;LPWA;massive access;spectrum sharing;stochastic geometry;success probability;transmission capacity;ultra-narrowband","Time-frequency analysis;Interference;Bandwidth;Geometry;Stochastic processes;Protocols;Frequency division multiplexing","","3","","34","IEEE","28 Aug 2020","","","IEEE","IEEE Journals"
"Deep Learning-Based Joint Activity Detection and Channel Estimation for Massive Access: When More Antennas Meet Fewer Pilots","X. Shao; X. Chen; D. W. Kwan Ng; C. Zhong; Z. Zhang","College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; School of Electrical Engineering and Telecommunications, University of New South Wales, Sydney, Australia; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China","2020 International Conference on Wireless Communications and Signal Processing (WCSP)","28 Dec 2020","2020","","","975","980","We consider the problem of joint activity detection and channel estimation (JADCE) for massive grant-free random access with sporadic traffic devices. Due to the deployment of a large-scale antennas array and a massive number of Internet-of-Things (IoT) devices in the sixth-generation (6G) wireless networks, conventional JADCE approaches usually incur exceedingly high computational complexity and require long pilot sequences. To address these challenges, this paper develops a deep learning-based JADCE framework which consists of a dimension reduction module, a deep learning network module, an active device detection module, and a channel estimation module. In particular, a deep learning network is developed for the recovery of device state matrix based on a designed denoiser, which can adaptively adjust the density parameters characterizing the device state matrix and effectively adapt to general complex channel settings with a finite number of training data. Both theoretical analysis and simulation results confirm that the proposed deep learning framework is computationally-efficient for achieving excellent performance in practical scenarios.","2472-7628","978-1-7281-7236-1","10.1109/WCSP49889.2020.9299670","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9299670","6G;grant-free random access;active device detection;channel estimation;deep learning","Deep learning;Performance evaluation;Dimensionality reduction;6G mobile communication;Simulation;Channel estimation;Antenna arrays","","2","","19","IEEE","28 Dec 2020","","","IEEE","IEEE Conferences"
"Strategy to Validate Sensor-Placement Methodologies in the Context of Sparse Measurement in Complex Urban Systems","N. J. Bertola; A. Costa; I. F. C. Smith","Singapore-ETH Centre, Future Cities Laboratory, ETH Zürich, Singapore; Singapore-ETH Centre, Future Resilient Systems, ETH Zürich, Singapore; Applied Computing and Mechanics Laboratory (IMAC), Swiss Federal Institute of Technology (EPFL), Lausanne, Switzerland","IEEE Sensors Journal","17 Apr 2020","2020","20","10","5501","5509","The Internet of Things creates opportunities to develop data-driven design methodologies for smart cities. However, effects rather than causes are often measured in complex urban systems, requiring robust data-interpretation methodologies. Additionally, effective monitoring of large urban components, such as civil infrastructure, often involves multiple sensor devices and invasive sensor systems. In these situations, the design of measurement systems is an important task. Usually, this task is carried out by engineers using only qualitative rules of thumb and experience. Recently, researchers have developed quantitative sensor-placement methodologies to maximize the information gain of measurement systems. Nonetheless, these methodologies are only weakly validated using field measurements due to the small amount of data collected and the difficulties comparing the predicted information gain with observations. This paper proposes a validation strategy for sensor-placement methodologies. In this strategy, predictions of both individual sensor and sensor-configuration performances are compared with observations using statistical tests and hypothesis testing. The validation procedure is illustrated through three full-scale-bridge case studies. This strategy helps engineers select an appropriate methodology to design measurement systems in order to optimize data collection using sensors.","1558-1748","","10.1109/JSEN.2020.2969470","Singapore-ETH Centre, Future Cities Laboratory, ETH Zürich, Singapore, which was established collaboratively between ETH Zürich and the Singapore’s National Research Foundation, through the Research Excellence and Technological Enterprise Programme(grant numbers:FI 370074011); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8970368","Joint entropy;model updating;sensor placement;sparse measurements","Sensors;Predictive models;Uncertainty;Computational modeling;Monitoring;Task analysis;Entropy","","8","","26","IEEE","27 Jan 2020","","","IEEE","IEEE Journals"
"Energy-Efficient Online Data Sensing and Processing in Wireless Powered Edge Computing Systems","X. Li; S. Bi; Y. Zheng; H. Wang","College of Electronics and Information Engineering, Shenzhen University, Shenzhen, China; College of Electronics and Information Engineering, Shenzhen University, Shenzhen, China; College of Electronics and Information Engineering, Shenzhen University, Shenzhen, China; Shenzhen Institute of Information Technology, Shenzhen, China","IEEE Transactions on Communications","16 Aug 2022","2022","70","8","5612","5628","Wireless powered multi-access edge computing (MEC) has emerged as a promising paradigm to enable high-performance computation of energy-constrained wireless devices (WDs) in internet of things (IoT) systems. However, to overcome the severe path loss of both energy transfer and data communications, wireless powered MEC suffers from high operating power consumption. To achieve sustainable and economic system operation, this paper focuses on developing energy-efficient online data processing strategy for wireless powered MEC systems under stochastic fading channels. In particular, we consider a hybrid access point (HAP) transmitting RF energy to and processing the sensing data offloaded from multiple WDs. Under an average power constraint of the HAP, we target at maximizing the long-term average data sensing rate of the WDs while maintaining task data queue stability. To this end, we formulate a multi-stage stochastic optimization problem to control the energy transfer and task data processing in sequential time slots. Without the knowledge of future channel fading, it is very challenging to determine the sequential control actions that are tightly coupled by the battery and data buffer dynamics. To solve the problem, we propose a Lyapunov optimization-based online algorithm named LEESE, which decomposes the multi-stage stochastic problem into per-slot deterministic optimization problems. We show that each per-slot problem can be equivalently transformed into a convex optimization problem. To facilitate online implementation in large-scale MEC systems, instead of solving the per-slot problem with off-the-shelf convex algorithms, we propose a block coordinate descent (BCD)-based method that produces a close-to-optimal solution in less than 0.04% of the computation delay. Simulation results demonstrate that the proposed LEESE algorithm can provide 18% higher data sensing rate than the representative benchmark methods considered, while incurring sub-millisecond computation delay suitable for real-time control under fading channel.","1558-0857","","10.1109/TCOMM.2022.3186718","National Key Research and Development Program(grant numbers:2019YFB1803305); National Natural Science Foundation of China(grant numbers:61871271); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2022A1515010973); Key Project of Department of Education of Guangdong Province(grant numbers:2020ZDZX3050); Shenzhen Science and Technology Program(grant numbers:JCYJ20210324093011030); The Open Research Project Programme of the State Key Laboratory of Internet of Things for Smart City (University of Macau) (Ref. No.: SKL-IoTSC(UM)- 2021-2023/ORPF/A03/2022); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9808170","Mobile edge computing;wireless power transfer;computation offloading;resource allocation;real-time online optimization","Task analysis;Wireless sensor networks;Wireless communication;Sensors;Optimization;Fading channels;Servers","","3","","29","IEEE","27 Jun 2022","","","IEEE","IEEE Journals"
"Aggregation of DERs like Air Conditioners for Virtual Power Plant, based on IEEE 1547 Standards Family","M. Umejima; S. Manickam","Graduate School of Media and Governance, Keio University, Fujisawa, Japan; National Advanced IPv6 Centre, Universiti Sains Malaysia, Penang, Malaysia","2021 13th IEEE PES Asia Pacific Power & Energy Engineering Conference (APPEEC)","2 Feb 2022","2021","","","1","6","We live in a very connected world. As the world gets even more connected with the proliferation of connected devices, i.e., Internet of Things (IoT), a paradigm shift will happen in an electric utility system that relies on the mandatory balance of demand and supply. Balancing capabilities must be on standby at the power grid network to fulfill this requirement, showing high dependency on large-scale power plants on the supply side. However, Demand-side Energy Management System (D-EMS) accumulate loads like an air conditioner with network access is becoming the catalyst in influencing the design of the demand and supply balancing formula. IEEE 1547 standards family describe that Demand Response (DR) Aggregator acquires balancing capacities by aggregating DR units, namely Virtual Power Plant (VPP). This research presented and verified that aggregation of D-EMSs that refers to the accumulation of loads with network access like air conditioners showing a characteristic of Distributed Energy Resources (DERs), realized VPP with offering scalability. Significantly, the measurement of D-EMS by a smart power meter with the certification of the centralized authority was able to ensure transparency in VPP as a whole system, removing the weakness of a distributed system.","","978-1-6654-4878-9","10.1109/APPEEC50844.2021.9687690","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9687690","Sustainability;Green Energy;Energy Management System;Distributed Energy Resource;Virtual Power Plant;Smart Grid;IoT","Meters;Power measurement;Scalability;Virtual power plants;Power industry;Power grids;Internet of Things","","","","20","IEEE","2 Feb 2022","","","IEEE","IEEE Conferences"
"FlexiCast: A Structure-Adaptive Protocol for Efficient Data-Sharing in IoT","M. Tummula; M. K. H; S. Saha","School of Electrical Sciences, Indian Institute of Technology Bhubaneswar; School of Electrical Sciences, Indian Institute of Technology Bhubaneswar; School of Electrical Sciences, Indian Institute of Technology Bhubaneswar","2022 18th International Conference on Network and Service Management (CNSM)","2 Dec 2022","2022","","","100","108","IoT-technology is gaining a wide popularity over a large range of applications including not only monitoring of structures but also management and control of smart-systems. An IoT-system, in general, is composed of a number of IoT-devices which form a wireless decentralized setting as they get installed over a specific area to serve a particular purpose. The structure of the underlying wireless network depends on the structure of the target where the system gets deployed and hence, widely varies based on the exact application. Such structural variations often have an impact on the performance of the underlying IoT-protocols. Unfortunately most of the network protocols do not take care of such issues explicitly. For instance, although there have been quite significant development in the data-sharing protocols, especially with the advent of Synchronous-Transmission (ST), most of them are designed without considering the variation in the structural formation of the base networks. These protocols are tested over either in small scale simulated networks or in testbed settings bearing fixed/homogeneous structures. In this work, we demonstrate that the property of self-adaptability in an IoT-system can enable it not only to run faster but also save substantial energy which is an extremely important issue in the context of low-power system, in general. In particular, we design and implement a flexible and structure-adaptive many-to-many data-sharing protocol FlexiCast. Through extensive experiments under emulation-settings and IoT-testbeds we demonstrate that FlexiCast performs upto 49% faster and consumes upto 53% lesser energy compared to the case when it does not adapt to the network structure.","2165-963X","978-3-903176-51-5","10.23919/CNSM55787.2022.9964962","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9964962","Many-to-Many data sharing;WSN;IoT;Selfadjusting protocol;Concurrent-Transmission;Capture effect;TDMA;Time-varying schedule","Schedules;Adaptation models;Protocols;Runtime;Wireless networks;Monitoring;Design optimization","","4","","46","","2 Dec 2022","","","IEEE","IEEE Conferences"
"Joint-optimization of Node Placement and UAV’s Trajectory for Self-sustaining Air-Ground IoT system","W. Zhang; W. Wang; M. Sookhak; C. Pan","Department of Computer Science, Texas A&M University–Corpus Christi, Corpus Christi, USA; Department of Computer Science, Texas A&M University–Corpus Christi, Corpus Christi, USA; Department of Computer Science, Texas A&M University–Corpus Christi, Corpus Christi, USA; Department of Computer Science, Texas A&M University–Corpus Christi, Corpus Christi, USA","2022 23rd International Symposium on Quality Electronic Design (ISQED)","29 Jun 2022","2022","","","1","6","Due to the sustainable power supply and environment-friendly features, self-powered IoT devices have been increasingly employed in various fields such as providing observation data in remote areas, especially in rural areas or post-disaster scenarios. Generally, through multi-hop relay, the sensed data of those self-powered IoT devices are collected by the sink node which connects to the IoT backbones. However, due to the remoteness, the sink needs to be located at the border of the monitoring area where both the backbone of IoT and electrical infrastructures are accessible. Under such deployment, significant data flow and relay overhead will incur considering the large scale of the monitoring area. Motivated by this issue, this paper aims to design a UAV-assisted self-powered heterogeneous system to provide comprehensive monitoring data. In this system, because of the superiority of the unmanned aerial vehicle (UAV) in the easy deployment, We dispatch a UAV to collect data from self-powered IoT devices, periodically so as to alleviate the data overflow. Moreover, based on that the self-powered IoT devices are expected to have a more considerable capability in the heavy data flow area, we also developed a placement upgrade strategy to upgrade the general homogeneous self-powered IoT system to the heterogeneous self-powered IoT system. Simulation results indicated the developed UAV-assisted self-powered heterogeneous system can achieve around 1.28× the amount of data delivery to sink compared with the homogeneous self-powered IoT system.","1948-3295","978-1-6654-9466-3","10.1109/ISQED54688.2022.9806202","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9806202","","Power supplies;Simulation;Data collection;Autonomous aerial vehicles;Trajectory;Internet of Things;Relays","","","","16","IEEE","29 Jun 2022","","","IEEE","IEEE Conferences"
"Federated Learning With Cooperating Devices: A Consensus Approach for Massive IoT Networks","S. Savazzi; M. Nicoli; V. Rampa","Consiglio Nazionale delle Ricerche, IEIIT institute, Milan, Italy; DIG department, Politecnico di Milano, Milan, Italy; Consiglio Nazionale delle Ricerche, IEIIT institute, Milan, Italy","IEEE Internet of Things Journal","13 May 2020","2020","7","5","4641","4654","Federated learning (FL) is emerging as a new paradigm to train machine learning (ML) models in distributed systems. Rather than sharing and disclosing the training data set with the server, the model parameters (e.g., neural networks' weights and biases) are optimized collectively by large populations of interconnected devices, acting as local learners. FL can be applied to power-constrained Internet of Things (IoT) devices with slow and sporadic connections. In addition, it does not need data to be exported to third parties, preserving privacy. Despite these benefits, a main limit of existing approaches is the centralized optimization which relies on a server for aggregation and fusion of local parameters; this has the drawback of a single point of failure and scaling issues for increasing network size. This article proposes a fully distributed (or serverless) learning approach: the proposed FL algorithms leverage the cooperation of devices that perform data operations inside the network by iterating local computations and mutual interactions via consensus-based methods. The approach lays the groundwork for integration of FL within 5G and beyond networks characterized by decentralized connectivity and computing, with intelligence distributed over the end devices. The proposed methodology is verified by the experimental data sets collected inside an Industrial IoT (IIoT) environment.","2327-4662","","10.1109/JIOT.2020.2964162","ERA-NET CO-FUND H2020 CHISTERA III Project RadioSense; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8950073","5G and beyond networks;distributed signal processing;federated learning;internet of Things","Servers;Data models;Computational modeling;Artificial neural networks;Optimization;Convergence;Internet of Things","","220","","48","IEEE","6 Jan 2020","","","IEEE","IEEE Journals"
"A DAG Blockchain-Enhanced User-Autonomy Spectrum Sharing Framework for 6G-Enabled IoT","H. Zhang; S. Leng; F. Wu; H. Chai","School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China","IEEE Internet of Things Journal","23 May 2022","2022","9","11","8012","8023","The rapidly growing number of Internet-of-Things (IoT) devices poses new challenges for spectrum management in future wireless communication networks. It is critical to achieve efficient and dynamic spectrum management in the sixth-generation (6G) wireless communication networks era. To tackle the challenges of managing a large-scale IoT network with heterogeneous devices, we propose a directed acyclic graph (DAG) blockchain-enhanced user-autonomy spectrum sharing model. As the proposed consensus rule is closely related to system utility, the swarm intelligence of users gradually reaches the point of convergence in the process of blockchain consensus. We analyze the effect of the tip selection method of the DAG blockchain on spectrum allocation utility. A dynamic tip selection method is proposed to enhance the global utility, which is related to the spectrum supply–demand. In addition, the ring signature technique is utilized to realize privacy protection during the sharing process. Simulation indicates that the proposed tip selection method achieves a 10% enhancement in terms of the global utility. Furthermore, significant reductions in administrative expense and reliability improvement are demonstrated by simulation results. The stability of the tip number in the proposed model has been proved theoretically, which is also validated by simulation experiments.","2327-4662","","10.1109/JIOT.2021.3109959","National Key Research and Development Program of China(grant numbers:2018YFE0117500); EU H2020 Project COSAFE(grant numbers:MSCA-RISE-2018-824019); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9528845","Directed acyclic graph (DAG) blockchain;Internet of Things (IoT);sixth generation (6G);spectrum sharing","Blockchains;6G mobile communication;Regulators;Internet of Things;Wireless communication;Resource management;Particle swarm optimization","","17","","29","IEEE","3 Sep 2021","","","IEEE","IEEE Journals"
"Performance Analysis and Optimization of NOMA-Based Cell-Free Massive MIMO for IoT","J. Zhang; J. Fan; J. Zhang; D. W. K. Ng; Q. Sun; B. Ai","School of Information Science and Technology, Nantong University, Nantong, China; School of Electronic and Information Engineering, Beijing Jiaotong University, Beijing, China; School of Electronic and Information Engineering, Beijing Jiaotong University, Beijing, China; School of Electrical Engineering and Telecommunications, University of New South Wales, Sydney, NSW, Australia; School of Information Science and Technology, Nantong Research Institute for Advanced Communication Technologies, Nantong University, Nantong, China; State Key Laboratory of Rail Traffic Control and SafetyFrontiers Science Center for Smart High-Speed Railway System, Beijing Jiaotong University, Beijing, China","IEEE Internet of Things Journal","7 Jun 2022","2022","9","12","9625","9639","This article investigates the performance of nonorthogonal multiple access (NOMA)-based cell-free massive multiple-input–multiple-output (mMIMO) for the Internet of Things (IoT) considering spatially correlated Rician fading channels. The exact closed form of downlink spectral efficiency (SE) and energy efficiency expressions is derived with three estimators and the maximum ratio transmission by taking the impacts of imperfect successive interference cancellation and pilot contamination into account. Subsequently, the performance of a local-MMSE precoder with the three aforementioned estimators is analyzed. Then, a large-scale fading-based user pairing scheme is proposed to further analyze the system SE. Besides, we formulate the optimum power control design as a max–min problem and a computational efficient suboptimal algorithm is proposed based on the successive convex approximation. Furthermore, our results reveal that the magnitude of the spatial correlation negligibly effects the SE in spatially correlated Rician fading channels. Then, numerical results confirm the positive effect of the proposed power control scheme. Also, our results further illustrate that NOMA-based cell-free mMIMO for IoT provides significant performance gain compared with its counterpart deploying conventional orthogonal multiple-access schemes.","2327-4662","","10.1109/JIOT.2021.3130026","National Key Research and Development Program of China(grant numbers:2020YFB1807201); National Natural Science Foundation of China(grant numbers:61971027,61971467,U1834210,61961130391); Beijing Natural Science Foundation(grant numbers:L202013); UNSW Digital Grid Futures Institute, UNSW, Sydney, under a Cross-Disciplinary Fund Scheme; Australian Research Council’s Discovery Project(grant numbers:DP210102169); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9624950","Cell-free massive multiple-input–multiple-output (mMIMO);nonorthogonal multiple access (NOMA);performance analysis;power control","Channel estimation;Downlink;Correlation;Rician channels;NOMA;Internet of Things;Uplink","","14","","34","IEEE","23 Nov 2021","","","IEEE","IEEE Journals"
"Coverage and Deployment Analysis of Narrowband Internet of Things in the Wild","K. Kousias; G. Caso; O. Alay; A. Brunstrom; L. D. Nardis; M. -G. D. Benedetto; M. Neri","Simula Research Laboratory, Oslo, Norway; Simula Metropolitan, Oslo, Norway; University of Oslo, Oslo, Norway; Karlstad University, Karlstad, Sweden; Sapienza University of Rome, Rome, Italy; Sapienza University of Rome, Rome, Italy; Rohde & Schwarz, Munich, Germany","IEEE Communications Magazine","6 Oct 2020","2020","58","9","39","45","Narrowband Internet of Things (NB-IoT) is gaining momentum as a promising technology for massive machine type communication. Given that its deployment is rapidly progressing worldwide, measurement campaigns and performance analyses are needed to better understand the system and move toward its enhancement. With this aim, this article presents a large-scale measurement campaign and empirical analysis of NB-IoT on operational networks, and discloses valuable insights in terms of deployment strategies and radio coverage performance. The reported results also serve as examples showing the potential usage of the collected dataset, which we make open source along with a lightweight data visualization platform.","1558-1896","","10.1109/MCOM.001.2000131","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9214385","","Long Term Evolution;Internet of Things;GSM;Performance evaluation;Narrowband;3GPP;Complexity theory","","13","","15","IEEE","6 Oct 2020","","","IEEE","IEEE Magazines"
"Decentralized Attribute-Based Server-Aid Signature in the Internet of Things","J. Li; Y. Chen; J. Han; C. Liu; Y. Zhang; H. Wang","College of Computer and Cyber Security and the Fujian Provincial Key Laboratory of Network Security and Cryptology, Fujian Normal University, Fuzhou, China; College of Computer and Cyber Security, Fujian Normal University, Fuzhou, China; Jiangsu Provincial Key Laboratory of E-Business, Nanjing University of Finance and Economics, Nanjing, China; Beijing Application Institute of Information Technology, Beijing, China; College of Computer and Cyber Security, Fujian Normal University, Fuzhou, China; Jiangsu Key Laboratory of Big Data Security and Intelligent Processing, College of Computer, Nanjing University of Posts and Telecommunications, Nanjing, China","IEEE Internet of Things Journal","8 Mar 2022","2022","9","6","4573","4583","Devices of Internet of Things (IoT) play a significant role in people’s daily life. A large scale of data is generated, collected, and analyzed in these devices, which inevitably faces secure authentication and access control problem. Attribute-based signature (ABS), where a signer signs a message over a set of attributes, plays an elegant tool for privacy-preserving access control and data authentication. In multiauthority ABS scheme, multiple authorities distribute users’ private keys over their different attributes and these attribute authorities are managed by a central authority. Nevertheless, the whole ABS system can be broken if the central authority is compromised. Besides, the multiauthority ABS scheme needs a lot of pairing and exponentiation operations in the verification and signature algorithms. Therefore, it is very expensive for resource-limited devices (e.g., sensors in IoT) to utilize the ABS scheme. In order to solve above problems, we present a decentralized attribute-based server-aid signature (DABSAS) scheme. In the DABSAS scheme, a server can help users execute heavy computation in the signature and verification algorithms. The proposed scheme provides anonymity and unforgeability. In addition, our scheme mitigates the burden of the signature and verification phase. The proposed scheme is proved secure under the well-known computational co-Diffie–Hellman (co-CDH) assumption. Compared with the existing schemes, the presented DABSAS scheme is efficient.","2327-4662","","10.1109/JIOT.2021.3104585","National Natural Science Foundation of China(grant numbers:62072104,61972095,U1736112,61972190,61872192,61772009); Natural Science Foundation of the Fujian Province, China(grant numbers:2020J01159); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9513297","Anonymity;attribute-based signature (ABS);server aid;unforgeability","Internet of Things;Authentication;Servers;Access control;Sun;Sensor phenomena and characterization;Computer crime","","13","","50","IEEE","13 Aug 2021","","","IEEE","IEEE Journals"
"Access Control for Ambient Backscatter Enhanced Wireless Internet of Things","L. Zhang; G. Feng; S. Qin; Y. Sun; B. Cao","National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China, Chengdu, China; National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China, Chengdu, China; National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China, Chengdu, China; James Watt School of Engineering, University of Glasgow, Glasgow, U.K.; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China","IEEE Transactions on Wireless Communications","11 Jul 2022","2022","21","7","5614","5628","Beyond fifth-generation (B5G) and future networks face the challenges of spectral, energy and cost efficiency for large-scale machine-type communications. Recently, emerging ambient backscatter communication (AmBC) technology provides a promising paradigm for the development of green Internet of Things (IoT) networks in B5G era. Unlike existing work on AmBC which mostly focuses on physical layer with relatively ideal model, i.e., classic three-nodes model composed of radio frequency (RF), backscatter device (BD) and IoT device, this paper studies the access control strategy, including coefficient design and device association, from the perspective of networking. Assuming whether channel information is available a-priori, we propose online and offline access control strategies respectively. For offline access control strategy, we leverage the difference of two convex functions approximation (DCA) and dual decomposition to transform the non-concave optimization problem into the concave one, and design a distributed access control strategy called DCA-S. Furthermore, for the case that channel information is assumed to be unknown in advance due to the dynamics of primary and backscatter networks, we design a combinatorial multi-armed bandit (CMAB) access control strategy (CMAB-S). Numerical results show that the proposed DCA-S and CMAB-S can achieve significant performance improvement of the system in both cases of available and unavailable channel information compared with benchmark schemes.","1558-2248","","10.1109/TWC.2022.3142327","National Key Research Project(grant numbers:2020YFB1806804); Fundamental Research Funds for the Central Universities(grant numbers:ZYGX2020ZB044); ZTE Industry-Academia-Research Cooperation Funds; Chongqing Technological Innovation and Application Development Projects(grant numbers:cstc2019jscx-msxm1322); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9687127","Ambient backscatter network;Internet of Things;coefficient design;device association","Backscatter;Access control;Radio frequency;Internet of Things;Wireless communication;Optimization;Receiving antennas","","9","","32","IEEE","20 Jan 2022","","","IEEE","IEEE Journals"
"Collaborative Inference for AI-Empowered IoT Devices","N. Shlezinger; I. V. Bajić","Ben-Gurion University of the Negev, Beer-Sheva, Israel; Simon Fraser University, Canada","IEEE Internet of Things Magazine","9 Jan 2023","2022","5","4","92","98","Artificial intelligence (AI) technologies, and particularly deep learning systems, are traditionally the domain of large-scale cloud servers, which have access to high computational and energy resources. Nonetheless, in Internet-of-Things (IoT) networks, the interface with the real-world is carried out using edge devices; these devices an communicate with each other, and are each limited in hardware. The conventional approach to provide AI processing to data collected by edge devices involves sending samples to the cloud, at the cost of latency, communication, connectivity, and privacy concerns. Consequently, recent years have witnessed a growing interest in enabling AI-aided inference on edge devices by leveraging their communication capabilities to establish collaborative inference. This article reviews candidate strategies for facilitating the transition of AI to IoT devices via collaboration. We identify the need to operate in different mobility and connectivity constraints as a motivating factor to consider multiple schemes, which can be roughly divided into methods where inference is done remotely, i.e., on the cloud, and those that infer on the edge. We identify the key characteristics of each strategy in terms of inference accuracy, communication latency, privacy, and connectivity requirements, providing a systematic comparison between existing approaches. We conclude by presenting future research challenges and opportunities arising from the concept of collaborative inference.","2576-3199","","10.1109/IOTM.001.2200152","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10012474","","Deep learning;Cloud computing;Privacy;Systematics;Energy resources;Collaboration;Hardware","","7","","15","IEEE","9 Jan 2023","","","IEEE","IEEE Magazines"
"A deep neural network coordination model for electric heating and cooling loads based on IoT data","H. Jin; Y. Teng; T. Zhang; Z. Wang; Z. Chen","Shenyang University of Technology, Shenyang, China; Shenyang University of Technology, Shenyang, China; Shenyang University of Technology, Shenyang, China; Shenyang University of Technology, Shenyang, China; Aalborg University, Aalborg, Denmark","CSEE Journal of Power and Energy Systems","5 Mar 2020","2020","6","1","22","30","As the ubiquitous electric power internet of things (UEPIoT) evolves and IoT data increases, traditional scheduling modes for load dispatch centers have yielded a variety of challenges such as calculation of real-time optimization, extraction of time-varying characteristics and formulation of coordinated scheduling strategy for capacity optimization of electric heating and cooling loads. In this paper, a deep neural network coordination model for electric heating and cooling loads based on the situation awareness (SA) of thermostatically controlled loads (TCLs) is proposed. First, a sliding window is used to adaptively preprocess the IoT node data with uncertainty. According to personal thermal comfort (PTC) and peak shaving contribution (PSC), a dynamic model for loads is proposed; meanwhile, personalized behavior and consumer psychology are integrated into a flexible regulation model of TCLs. Then, a deep Q-network (DQN)-based approach, using the thermal comfort and electricity cost as the comprehensive reward function, is proposed to solve the sequential decision problem. Finally, the simulation model is designed to support the validity of the deep neural network coordination model for electric heating and cooling loads, by using UEPIoT intelligent dispatching system data. The case study demonstrates that the proposed method can efficiently manage coordination with large-scale electric heating and cooling loads.","2096-0042","","10.17775/CSEEJPES.2019.01700","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9020220","Deep neural network;electric heating and cooling load;IoT data;reinforcement learning","Load modeling;Resistance heating;Cooling;Neural networks;Data models;Dispatching;Power systems","","5","","","","5 Mar 2020","","","CSEE","CSEE Journals"
"Continuous Subsurface Tomography Over Cellular Internet of Things (IoT)","H. Jamali-Rad; V. van Beveren; X. Campman; J. van den Brand; D. Hohl","Shell Global Solution International B.V., Amsterdam, The Netherlands; National Institute for Subatomic Physics (Nikhef), Amsterdam, The Netherlands; Shell Global Solution International B.V., Amsterdam, The Netherlands; National Institute for Subatomic Physics (Nikhef), Amsterdam, The Netherlands; Shell Global Solution International B.V., Amsterdam, The Netherlands","IEEE Sensors Journal","4 Aug 2020","2020","20","17","10079","10091","Continuous monitoring of dynamic systems in the energy industry can lead to significant cost reductions by optimizing operations and reducing downtime through automatic integrity monitoring. In this paper, we focus on a challenging scenario, continuous subsurface monitoring through passive seismic tomography. Our proposed solution to address this challenge is enabled by marrying low-cost low-power sensing design, large-scale wireless (cellular) Internet of Things (IoT) networking, and advanced edge/cloud computing technologies. We demonstrate that the proposed data compression technique, application protocol design, and signal processing approach at edge sensors and cloud solution, enable us to handle data-demanding subsurface tomography problem using commodity cellular IoT technologies paving the way towards changing the traditional wisdom in our business. Compared to the state-of-the-art, the proposed solution is scalable, easily replicable, and considerably more power-efficient. The simulation results as well as a proof-of-concept (PoC) field test in collaboration with our partners (Vodafone and Nikhef) corroborate the feasibility of the proposed ideas.","1558-1748","","10.1109/JSEN.2020.2992464","Netherlands Organisation for Scientific Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9086612","Subsurface monitoring;wireless Internet of Things (IoT);cloud computing","Sensors;Wireless sensor networks;Wireless communication;Monitoring;Cloud computing;Tomography;Green's function methods","","4","","46","IEEE","5 May 2020","","","IEEE","IEEE Journals"
"Understanding Sub-GHz Signal Behavior in Deep-Indoor Scenarios","K. M. Malarski; J. Thrane; H. L. Christiansen; S. Ruepp","Department of Photonics Engineering, Technical University of Denmark, Kongens Lyngby, Denmark; Department of Photonics Engineering, Technical University of Denmark, Kongens Lyngby, Denmark; TDC NET, Copenhagen, Denmark; Department of Photonics Engineering, Technical University of Denmark, Kongens Lyngby, Denmark","IEEE Internet of Things Journal","7 Apr 2021","2021","8","8","6746","6756","Critical Internet-of-Things (IoT) services require seamless connectivity, which is not always simple to provide and particularly in deep-indoor scenarios, it can be even impossible in some cases. The existing outdoor-to-indoor path-loss models lack accuracy in underground situations, thus IoT coverage planning in such areas cannot rely on robust tools and becomes a process of trial and error. In this work, we derive and analyze various environmental features that can be useful in understanding sub-GHz deep-indoor signal propagation. Based on a large-scale field trial in an underground tunnel system, we formulate several parameters related to the TX-RX distance and tunnel geometry. Through feature relevance studies in linear (ordinary least-squares (OLS) regression) and nonlinear (the Gaussian process regression) realms, we show that 2-D indoor distance and the distances to the tunnel walls may be useful in sub-GHz signal strength prediction in deep-indoor situations. We construct a linear and a Gaussian process model for the indoor path-loss prediction that outperforms the 3rd Generation Partnership Project (3GPP) model by 1.8 and 4.1 dB, respectively.","2327-4662","","10.1109/JIOT.2020.3027829","Innovation Fund Denmark through the Eureka Turbo Project IoT Watch4Life; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9210025","Deep-indoor;Gaussian process regression (GPR);LIDAR;narrowband Internet of Things (NB-IoT);path loss;signal propagation;sub-GHz;tunnel","Predictive models;Mathematical model;Gaussian processes;Internet of Things;Propagation losses;3GPP;Linear regression","","3","","30","IEEE","30 Sep 2020","","","IEEE","IEEE Journals"
"Efficient and Robust Top-k Algorithms for Big Data IoT","R. Yang; Z. Zhou; L. Tseng; M. Aloqaily; A. Boukerche","Cornell University, Ithaca, NY, USA; Boston College, Boston, MA, USA; Boston College, Boston, MA, USA; Al Ain University, UAE; University of Ottawa, Ottawa, ON, Canada","ICC 2020 - 2020 IEEE International Conference on Communications (ICC)","27 Jul 2020","2020","","","1","6","Top-k considers as a technique to retrieve, from a hypothetically big data set, only the k (k ≥ 1) best (most relevant/important) candidates. Top-k query processing is a decisive necessity in various collaborative environments that comprise big data such as the Internet of Things (IoT) networks. Particularly, efficient top-k processing in large-scale distributed systems has shown a positively noticeable effect on their performance. This paper considers the distributed approximate top-k processing algorithms dedicated to the IoT-based networks and improve the accuracy of algorithms introduced previously. We then propose a safety-based fault-tolerance notation and contribute to improving a known algorithm in terms of accuracy. Our algorithms have been evaluated using simulation and real-world data and show superiority over conventional methods.","1938-1883","978-1-7281-5089-5","10.1109/ICC40277.2020.9148639","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9148639","IoT;Top-K query;fault-tolerance;distributed algorithms;approximate query","Approximation algorithms;Nickel;Fault tolerance;Fault tolerant systems;Random variables;Big Data;Query processing","","2","","27","IEEE","27 Jul 2020","","","IEEE","IEEE Conferences"
"The Study of Urban Residential’s Public Space Activeness Using Space-Centric Approach","B. P. L. Lau; B. K. K. Ng; C. Yuen; B. Tunçer; K. H. Chong","Department of Engineering Product Development, Singapore University of Technology and Design, Singapore; Department of Engineering Product Development, Singapore University of Technology and Design, Singapore; Department of Engineering Product Development, Singapore University of Technology and Design, Singapore; Department of Architecture and Sustainable Design, Singapore University of Technology and Design, Singapore; Department of Architecture and Sustainable Design, Singapore University of Technology and Design, Singapore","IEEE Internet of Things Journal","6 Jul 2021","2021","8","14","11503","11513","With the advancement of the Internet of Things (IoT) and communication platform, large-scale sensor deployment can be easily implemented in an urban city to collect various information. To date, there are only a handful of research studies about understanding the usage of urban public spaces. Leveraging IoT, various sensors have been deployed in an urban residential area to monitor and study public space utilization patterns. In this article, we propose a data processing system to generate space-centric insights about the utilization of an urban residential region of multiple Points of Interests (PoIs) that consists of 190 000 m2 real estate. We identify the activeness of each PoI based on the spectral clustering, and then study their corresponding static features, which are composed of transportation, commercial facilities, population density, along with other characteristics. Through the heuristic features inferring, the residential density and commercial facilities are the most significant factors affecting public place utilization.","2327-4662","","10.1109/JIOT.2021.3051343","Singapore Ministry of National Development and the National Research Foundation, Prime Minister’s Office through the Land and Liveability National Innovation Challenge (L2 NIC) Research Programme(grant numbers:L2NICTDF1-2017-4); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9321451","Internet of Things (IoT);public space utilization;smart city;space-centric monitoring;spatial–temporal","Monitoring;Internet of Things;Feature extraction;Data mining;Machine learning;Pipelines;Motion detection","","2","","41","IEEE","13 Jan 2021","","","IEEE","IEEE Journals"
"SUGAR: Efficient Subgraph-Level Training via Resource-Aware Graph Partitioning","Z. Xue; Y. Yang; R. Marculescu","Department of Electrical and Computer Engineering, The University of Texas at Austin, Austin, TX, USA; Department of Electrical and Computer Engineering, The University of Texas at Austin, Austin, TX, USA; Department of Electrical and Computer Engineering, The University of Texas at Austin, Austin, TX, USA","IEEE Transactions on Computers","9 Oct 2023","2023","72","11","3167","3177","Graph Neural Networks (GNNs) have demonstrated a great potential in a variety of graph-based applications, such as recommender systems, drug discovery, and object recognition. Nevertheless, resource-efficient GNN learning is a rarely explored topic despite its many benefits for edge computing and Internet of Things (IoT) applications. To improve this state of affairs, this work proposes efficient subgraph-level training via resource-aware graph partitioning (SUGAR). SUGAR first partitions the initial graph into a set of disjoint subgraphs and then performs local training at the subgraph-level We provide a theoretical analysis and conduct extensive experiments on five graph benchmarks to verify its efficacy in practice. Our results across five different hardware platforms demonstrate great runtime speedup and memory reduction of SUGAR on large-scale graphs. We believe SUGAR opens a new research direction towards developing GNN methods that are resource-efficient, hence suitable for IoT deployment.","1557-9956","","10.1109/TC.2023.3288755","National Science Foundation(grant numbers:CNS-2007284,CCF-2107085); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168538","Graph neural networks;resource-efficient learning;edge computing","Training;Sugar;Internet of Things;Graph neural networks;Convolution;Runtime;Memory management","","1","","35","IEEE","29 Jun 2023","","","IEEE","IEEE Journals"
"A Constraint-based Approach to Edge Resource Allocation for Complex Event Processing","B. Wei; D. Lin; S. Ding","Department of Social Informatics, Kyoto University, Kyoto, Japan; Department of Social Informatics, Kyoto University, Kyoto, Japan; Department of Social Informatics, Kyoto University, Kyoto, Japan","2020 IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT)","24 Jun 2021","2020","","","526","531","With the development of Internet of Things (IoT), the demand for event-driven service invocation continues to increase, which is attracting interest in the techniques of complex event processing (CEP) for recognizing event patterns in the physical world from stream sensor data. To process data with lower delay, edge computing is widely used in IoT, but there are many challenges in implementing event recognition on such distributed computing systems. This paper studies an edge resource allocation problem for complex event processing; the result is an allocation scheme that allows all complex events contained in stream data to be detected in minimal time. As the intricate composition of event patterns and the large scale of the problem makes finding an optimal solution a hard problem, we formulate the problem as a constraint-based optimization problem (COP) using features of resources and events. We then propose a CEP-efficient heuristic algorithm (CEED) for efficient solution determination. Experiments conform that our algorithm can greatly reduce the time needed for problem solving while yielding good approximation performance relative to the baseline approach.","","978-1-6654-1924-6","10.1109/WIIAT50758.2020.00079","Japan Society for the Promotion of Science; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9457745","edge computing;resource allocation;Internet of Things (IoT);complex event processing (CEP)","Heuristic algorithms;Approximation algorithms;Real-time systems;Pattern recognition;Resource management;Problem-solving;Internet of Things","","1","","11","IEEE","24 Jun 2021","","","IEEE","IEEE Conferences"
"Throughput Maximization for NOMA-Based Cognitive Backscatter Communication Networks With Imperfect CSI","Y. Xu; S. Jiang; Q. Xue; X. Li; C. Yuen","School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; School of Physics and Electronic Information Engineering, Henan Polytechnic University, Jiaozuo, China; School of Electrical and Electronics Engineering, Nanyang Technological University, Jurong West, Singapore","IEEE Internet of Things Journal","30 Oct 2023","2023","10","22","19595","19606","Cognitive radio and backscatter communication (BackCom) have been viewed as two promising technologies for the future green Internet of Things (IoT). The combination of these two technologies can not only enhance spectrum efficiency but also improve energy efficiency. However, most of the existing resource allocation (RA) algorithms in cognitive BackCom networks consider ideal channel state information and a time division multiple access protocol, which is unrealistic in practical systems and can not support the massive number of accessing users. To this end, in this article, we study a robust chance-constrained RA problem for nonorthogonal multiple access (NOMA)-based cognitive BackCom networks to overcome the influence of channel estimation errors and support for large-scale IoT nodes. Specifically, cognitive backscatter users (CBUs) can not only share the spectrum resource owned by primary users but also harvest surrounding radio frequency and transmit their own information over the primary signals. Moreover, CBUs can use the harvested energy to actively transmit information via an NOMA protocol. The robust RA problem with outage-probability constraints is formulated to maximize the total throughput of CBUs by jointly optimizing the transmission time, transmit power, and the reflection coefficients of CBUs. To tackle the nonconvex problem, the original problem is converted into an equivalent form by applying the linear objective function, an inequality transformation approach, and an auxiliary variable method. Then, an iteration-based RA algorithm is proposed to solve it. Simulation results demonstrate the effectiveness of the proposed algorithm by comparing it with the benchmark algorithms.","2327-4662","","10.1109/JIOT.2023.3289181","National Natural Science Foundation of China(grant numbers:62271094); Natural Science Foundation of Chongqing(grant numbers:CSTB2022NSCQ-LZX0009); Scientific and Technological Research Program of Chongqing Municipal Education Commission(grant numbers:KJZD-K202200601,KJQN202200617); China Postdoctoral Science Foundation(grant numbers:2022MD723725); Open Project of Zhejiang Provincial Key Laboratory of Information Processing, Communication and Networking, Zhejiang, China(grant numbers:IPCAN-2302); Ministry of Education Singapore(grant numbers:MOE-T2EP50220-0019); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10162184","Backscatter communication (BackCom);cognitive radio (CR);nonorthogonal multiple access (NOMA);robust resource allocation (RA)","Throughput;Backscatter;Resource management;Time division multiple access;Optimization;Interference;NOMA","","1","","44","IEEE","26 Jun 2023","","","IEEE","IEEE Journals"
"Exploiting Physical Layer Vulnerabilities in LoRaWAN-based IoT Networks","N. Torres; P. Pinto; S. I. Lopes","ADiT-LAB, Instituto Politécnico de Viana do Castelo, Viana do Castelo, Portugal; ADiT-LAB, Instituto Politécnico de Viana do Castelo, Viana do Castelo, Portugal; ADiT-LAB, Instituto Politécnico de Viana do Castelo, Viana do Castelo, Portugal","2022 IEEE 8th World Forum on Internet of Things (WF-IoT)","22 Jun 2023","2022","","","1","6","Low Power Wide Area Networks (LPWAN) are used worldwide in several Internet of Things (IoT) applications that rely on large-scale deployments. Despite most of these networks include their own security mechanisms with built-in encryption, they are still vulnerable to a range of attacks that can be performed using low-cost Software Defined Radio (SDR) hardware and low-complexity techniques. This work provides an experimental setup implemented to exploit physical layer vul-nerabilities with SDR techniques. Several attack vectors typically related to LPWAN within the IoT ecosystem are implemented and tested such as Global Positioning (GPS) Spoofing, Replay Attacks, Denial-of-Service (DoS) and Jamming, in environments that rely specifically on LoRaWAN networks. The results show that, in LoRAWAN networks, a set of vulnerabilities can be exploited leading to the incorrect functioning of the executed applications, and possible damage to the systems in which they operate. It was possible to verify that, depending on the type of activation method used between the devices and the LoRaWAN server, the communications and the devices can be compromised.","","978-1-6654-9153-2","10.1109/WF-IoT54382.2022.10152098","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10152098","Security;Vulnerabilities;IoT;LoRa;LoRaWAN;LPWAN","Logic gates;Physical layer;Hardware;Internet of Things;Servers;Security;Jamming","","","","19","IEEE","22 Jun 2023","","","IEEE","IEEE Conferences"
"Kaala 2.0: Scalable IoT/NextG System Simulator","U. K. Dayalan; T. J. Salo; R. A. K. Fezeu; Z. -L. Zhang","Trane Technologies, USA; University of Minnesota, USA; University of Minnesota, USA; University of Minnesota, USA","IEEE Network","6 Sep 2023","2023","37","3","240","246","The IoT world is evolving with the latest technology trends, like edge computing, augmented & virtual reality, machine learning, robotics, and 5G. With the digital transformation happening in Industry 4.0, many industries are moving toward private 5G networks. There are massive number (hundreds to thousands) of IoT devices in a single factory depending on the scale of the industry and these factories consists of critical IoT devices, like fire or gas sensors which need to operate reliably with less latency. To efficiently realize the capabilities, such as ultra reliable low latency communications (URLLC), enhanced mobile broadband (eMBB), and massive machine-type communications (mMTC) offered by 5G, the next generation IoT devices/applications need a paradigm shift in their design and need to be evaluated under simulation using 5G networks before getting deployed in the real-world. However, many IoT simulators run in isolation and do not interface with real-world IoT cloud systems or support 5G networks. This isolation makes it difficult to design, develop and evaluate IoT applications for industrial automation systems and for experiments to fully replicate the diversity that exists in end-to-end, real-world systems using 5G networks. Kaala 2.0 is the first scalable, hybrid, end-to-end IoT and NextG system simulator that can integrate with real-world IoT cloud services through simulated or real-world 5G networks. Kaala 2.0 is intended to bridge the gap between IoT simulation experiments and the real world using 5G networks. The simulator can interact with cloud IoT services, such as those offered by Amazon, Microsoft, and Google. Depending on the configuration, Kaala 2.0 supports simulation of User Equipment (UE), 5G Radio Access Network (RAN) and 5G Core and at the same time support real-world User Equipment (UE), 5G Radio Access Network (RAN) and 5G Core. Kaala 2.0 can simulate many diverse IoT devices to evaluate mMTC, simulate events that may simultaneously affect several sensors to evaluate URLLC and finally simulate large amount of data to evaluate eMBB.","1558-156X","","10.1109/MNET.002.2200498","NSF(grant numbers:CNS-1814322,CNS-1831140,CNS-1836772,CNS-1901103,CNS-2106771,CNS-2128489,CNS-2212318); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10242317","","Industries;Cloud computing;5G mobile communication;Service robots;Virtual reality;Ultra reliable low latency communication;Production facilities","","","","15","IEEE","6 Sep 2023","","","IEEE","IEEE Magazines"
"IoT Based Smart Crop Recommendation Using Macro Nutrient Analysis of Soil","S. Kavileswarapu; M. A. A. Khader; S. Ahmed; R. Radha","School of Computer Science Engineering, Vellore Institute of Technology, Chennai, India; School of Computer Science Engineering, Vellore Institute of Technology, Chennai, India; School of Computer Science Engineering, Vellore Institute of Technology, Chennai, India; School of Computer Science Engineering, Vellore Institute of Technology, Chennai, India","2022 Seventh International Conference on Parallel, Distributed and Grid Computing (PDGC)","1 Mar 2023","2022","","","501","506","Technology is developing at an exponential rate in every sector of the world. This trend is also easily visible in the agriculture sector too. It is of vital importance to not neglect the agriculture sector. This is so because even after exhausting all the conventional methods the supply/demand ratio is still deteriorating. By applying technology, the efficiency and production could be increased. In this research, we aim to address this problem using the Internet of Things (IoT) which is a fast-developing technology that connects standalone gadgets and equipment with internet in real-time with an aim to improve its throughput or to enhance an already present service. This research uses IoT to detect the presence and quantity of a set of nutrients whose readings are vital in monitoring the health of the soil which will, in turn, determine the health and growth of plants in horticulture and other farming activities. It is crucial that the soil used in farming activities have the optimal amount of minerals and water. While water can be easily detected using a moisture sensor, mineral detection is still in its nascent stages. This research aims to create a system by which this aspect of soil monitoring can be advanced so that even the monitoring can be automated and supplements or pre-plantation inspection can be achieved with lower latency. These parameters are used to further recommend a crop on a large scale.","2573-3079","978-1-6654-5401-8","10.1109/PDGC56933.2022.10053187","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10053187","IoT;Greenhouse;MQTT;Sensor;Recommendation","Crops;Moisture;Soil;Throughput;Real-time systems;Agriculture;Minerals","","","","21","IEEE","1 Mar 2023","","","IEEE","IEEE Conferences"
"Using Internet of Things Application for Energy-Efficient and Lightweight Internet of Drones Networks","N. N. Minhas; M. Naveed","Air University, Islamabad, Pakistan; Air University, Islamabad, Pakistan","IT Professional","18 Aug 2023","2023","25","4","21","28","The Internet of Drones (IoD) is a rapidly growing technology with the potential to revolutionize various industries, but it also raises concerns about security and efficiency in communication between drones. Blockchain technology has the potential to solve these issues but conventional blockchains face performance, computation, and scalability issues. This article proposes using Internet of Things Application (IOTA) distributed ledger technology (DLT) to address these concerns in the IoD. IOTA offers a highly energy-efficient alternative to major DLTs such as Bitcoin and Ethereum while providing fast and secure solutions. Our results show that IOTA not only outperforms Bitcoin but also low-energy DLTs like Ethereum by a huge margin. The use of IOTA DLTs in large-scale systems including the IoD can improve the efficiency and speed of tasks such as surveillance, delivery, and inspection. The article also discusses the potential challenges and future work for integrating IOTA DLTs in the IoD.","1941-045X","","10.1109/MITP.2023.3283329","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10224807","","Distributed ledger;Scalability;Surveillance;Bitcoin;Energy efficiency;Blockchains;Large-scale systems;Drones;Internet of Things","","","","23","IEEE","18 Aug 2023","","","IEEE","IEEE Magazines"
"Forming Dispatchable Region of Electric Vehicle Aggregation in Microgrid Bidding","M. Zhou; Z. Wu; J. Wang; G. Li","State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources, North China Electric Power University, Beijing, China; State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources, North China Electric Power University, Beijing, China; State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources, North China Electric Power University, Beijing, China; State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources, North China Electric Power University, Beijing, China","IEEE Transactions on Industrial Informatics","5 Apr 2021","2021","17","7","4755","4765","With the popularity of plug-in electric vehicles (EVs) and the development of the vehicle to grid (V2G) technology, EVs can be aggregated and behave as a controllable storage system via the Internet of Things. However, it remains an open question as to how large-scale EVs can be effectively integrated into the system-level operation. In this article, we propose a dispatchable region formation approach of EV aggregation to capture its available flexibility in microgrid (MG) bidding. The dispatchable region of EV aggregation describes the feasible operation strategy as a single entity, characterized by its power and cumulative energy limits. Instead of scheduling an individual EV, the dispatchable region of large-scale EVs enables the MG operator to directly schedule the EV aggregation toward market revenue maximization. The MG bidding strategy is formulated as a risk-constrained stochastic programming, which maximizes day-ahead market profits considering real-time imbalance settlement in a dual-pricing market. Case studies based on real-world datasets demonstrate that the proposed dispatchable region approach in MG biding can significantly improve both computation efficiency and forecasting accuracy.","1941-0050","","10.1109/TII.2020.3020166","National Natural Science Foundation of China(grant numbers:U1866204); National Natural Science Foundation of China(grant numbers:51907064); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9180050","Balancing market;dispatchable region;market bidding;microgrid (MG);plug-in electric vehicle (EV)","Vehicle-to-grid;Uncertainty;Microgrids;Real-time systems;Batteries","","48","","28","IEEE","28 Aug 2020","","","IEEE","IEEE Journals"
"Beamspace Joint Azimuth, Elevation, and Delay Estimation for Large-Scale MIMO-OFDM System","Z. Wang; L. Xie; Q. Wan","School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Sai Kung, Hong Kong; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China","IEEE Transactions on Instrumentation and Measurement","11 May 2023","2023","72","","1","12","Due to the capability to separate the line-of-sight (LOS) signal from multipath signals in both time-space domains, the joint azimuth, elevation angle, and time delay (TD) estimation technique is of great importance in the Internet of Things. However, as mainstream devices develop toward the large-scale multiple-input and multiple-output (MIMO) system, real-time processing gradually becomes computationally impractical for traditional element-space 3-D joint angle and delay estimation (JADE) methods. In this article, based on the measured channel state information (CSI) acquired from a large-scale uniform rectangular array (URA)-orthogonal frequency division multiplexing (OFDM) system, a computationally efficient 3-D beamspace JADE algorithm is proposed. Firstly, we develop a method to select the beam that contains the LOS path as the optimal beam. Then, for the parameter estimation, we transform the CSI into the beamspace by utilizing the discrete Fourier transform (DFT) sequence, and propose a modified 3-D beamspace matrix pencil (BMP) algorithm only with the optimal beam and its adjacent beams, which contributes to conspicuous computational savings. Moreover, the estimation of delay, elevation, and azimuth for the LOS path are paired automatically with only one eigenvalue decomposition (EVD), and the multidimensional grid search is avoided. Experiment results demonstrate that the proposed approach could correctly select the optimal beam with high probability, and its parameter estimation accuracy is superior to the state-of-the-art JADE techniques while significantly reducing the computational complexity.","1557-9662","","10.1109/TIM.2023.3270972","National Natural Science Foundation of China(grant numbers:61771108); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10109767","Beamspace;channel state information (CSI);joint angle and delay estimation (JADE);massive multiple-input and multiple-output (MIMO)-orthogonal frequency division multiplexing (OFDM);matrix pencil (MP);multipath","Discrete Fourier transforms;Azimuth;OFDM;Antenna arrays;Line-of-sight propagation;Array signal processing;Maximum likelihood estimation","","","","46","IEEE","27 Apr 2023","","","IEEE","IEEE Journals"
"An Urban-driven Service Request Management Model","C. Cabrera; A. Palade; G. White; S. Clarke","Distributed Systems Group, SCSS, Trinity College, Dublin, Dublin, Ireland; Distributed Systems Group, SCSS, Trinity College, Dublin, Dublin, Ireland; Distributed Systems Group, SCSS, Trinity College, Dublin, Dublin, Ireland; Distributed Systems Group, SCSS, Trinity College, Dublin, Dublin, Ireland","2020 IEEE International Conference on Pervasive Computing and Communications (PerCom)","29 Jun 2020","2020","","","1","7","Pervasive applications in smart cities rely on a large number of IoT devices, which are deployed in large geographic areas. Smart cities can manage these devices using Service-Oriented Architectures (e.g., micro-services) by encapsulating devices capabilities as IoT services. Distributed service discovery architectures reduce search spaces and perform discovery processes closer to consumers on edge devices. However, request management, a key task in distributed service discovery, is still challenging because requests must be forwarded through large networks where nodes have partial knowledge about other participants. Previous research has shown that social-based and bio-inspired methods can be used to manage requests in small-scale environments, but such approaches do not scale to large environments. This paper adds urban context to a social-based and bio-inspired mechanism to forward requests where they are most likely to be solved. Results show that our model has the best rate of solved requests, and intermediate latency.","2474-249X","978-1-7281-4657-7","10.1109/PerCom45495.2020.9127371","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9127371","Internet of Things;Smart Cities;Service Discovery;Context-aware;Bio-inspired;Social-based","Pervasive computing;Performance evaluation;Knowledge engineering;Smart cities;Computational modeling;Biological system modeling;Conferences","","4","","23","IEEE","29 Jun 2020","","","IEEE","IEEE Conferences"
"Reducing Operation Cost of LPWAN Roadside Sensors Using Cross Technology Communication","N. M. Imran; M. Won","Department of Computer Science, The University of Memphis, Memphis, TN, USA; Department of Computer Science, The University of Memphis, Memphis, TN, USA","IEEE Transactions on Intelligent Transportation Systems","10 Aug 2022","2022","23","8","11476","11489","Low-Power Wide-Area Network (LPWAN) is an emerging communication standard for Internet of Things (IoT) that has strong potential to support connectivity of a large number of roadside sensors with an extremely long communication range. However, the high operation cost to manage such a large-scale roadside sensor network remains as a significant challenge. In this article, we propose Low Operation-Cost LPWAN (LOC-LPWAN), a novel optimization framework that is designed to reduce the operation cost using the cross-technology communication (CTC). LOC-LPWAN allows roadside sensors to offload sensor data to passing vehicles that in turn forward the data to a LPWAN server using CTC aiming to reduce the data subscription cost. LOC-LPWAN finds the optimal communication schedule between sensors and vehicles to maximize the throughput given an available budget. Furthermore, LOC-LPWAN optimizes the fairness among sensors by preventing certain sensors from dominating the channel for data transmission. LOC-LPWAN can also be configured to ensure that data packets are received within a specific time bound. Extensive numerical analysis performed with real-world taxi data consisting of 40 vehicles with 24-hour trajectories demonstrate that LOC-LPWAN reduces the cost by 50% compared with the baseline approach where no vehicle is used to relay packets. The results also show that LOC-LPWAN improves the throughput by 72.6%, enhances the fairness by 65.7%, and reduces the delay by 28.8% compared with a greedy algorithm given the same amount of budget.","1558-0016","","10.1109/TITS.2021.3104786","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9517037","LPWAN;vehicular network;V2X","Sensors;Data communication;Performance evaluation;Sensor systems;Schedules;Intelligent sensors;Snow","","1","","67","IEEE","18 Aug 2021","","","IEEE","IEEE Journals"
"DAAC: Digital Asset Access Control in a Unified Blockchain Based E-Health System","S. Biswas; K. Sharif; F. Li; I. Alam; S. P. Mohanty","School of Computer Science, Beijing Institute of Technology, Beijing, China; School of Computer Science, Beijing Institute of Technology, Beijing, China; School of Computer Science, Beijing Institute of Technology, Beijing, China; School of Computer Science, Beijing Institute of Technology, Beijing, China; University of North Texas, Denton, TX, USA","IEEE Transactions on Big Data","31 Aug 2022","2022","8","5","1273","1287","The use of the Internet of Things and modern technologies has boosted the expansion of e-health solutions significantly and allowed access to better health services and remote monitoring of patients. Every service provider usually implements its information system to manage and access patient data for its unique purpose. Hence, the interoperability among independent e-health service providers is still a major challenge. From the structure of stored data to its large volume, the design of each such big data system varies, hence the cooperation among different e-health systems is almost impossible. In addition to this, the security and privacy of patient information is a challenging task. Building a unified solution for all creates significant business and economic issues. In this article, we present a solution to migrate existing e-health systems to a unified Blockchain-based model, where access to large scale medical data of patients can be achieved seamlessly by any service provider. A core blockchain network connects individual & independent e-health systems without requiring them to modify their internal processes. Access to patient data in the form of digital assets stored in off-chain storage is controlled through patient-centric channels and policy transactions. Through emulation, we show that the proposed solution can interconnect different e-health systems efficiently.","2332-7790","","10.1109/TBDATA.2020.3037914","National Natural Science Foundation of China(grant numbers:62072040,61772077); Beijing Natural Science Foundation(grant numbers:4192051); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9258958","Blockchain;e-health systems;digital assets;access control;electronic medical records (EMR);interoperability","Access control;Blockchain;Medical services;Big Data;Interoperability;Servers;Medical diagnostic imaging","","20","","43","IEEE","13 Nov 2020","","","IEEE","IEEE Journals"
"Downlink Transmission of Multicell Distributed Massive MIMO With Pilot Contamination Under Rician Fading","M. Wang; D. -W. Yue; S. -N. Jin","College of Information Science and Technology, Dalian Maritime University, Dalian, China; College of Information Science and Technology, Dalian Maritime University, Dalian, China; College of Information Science and Technology, Dalian Maritime University, Dalian, China","IEEE Access","24 Jul 2020","2020","8","","131835","131847","In this paper, we investigate the spectral efficiency (SE) of a multicell downlink (DL) distributed massive MIMO (DM-MIMO) system with pilot contamination operating over Rician fading channels in which each remote access unit (RAU) is equipped with a large number of distributed massive antenna arrays, while each user has a single antenna. In contrast to many previous works about DM-MIMO systems, the channel between users and the RAUs antennas in the same cell is modeled to be Rician fading, which is general for the 5G scenarios like Internet of Things. We explore maximum-ratio transmission (MRT) and line-of-sight (LOS) component-based equal-gain transmission (EGT) under imperfect channel state information. The tractable, but accurate closed-form expressions for the lower bounds of the achievable rate are derived for the MRT and the LOS component-based EGT over Rician fading channels in the DM-MIMO systems. Based on the obtained closed-form expressions, various power scaling laws concerning DL data transmit power and pilot transmit power are analyzed in detail. Numerical results are used to corroborate that these approximations are asymptotically tight, but accurate for systems. They also show that employing the LOS component-based EGT processing is more preferable than the MRT processing for DM-MIMO systems in conditions having a large number of RAU antennas and stronger LOS scenarios. Finally, the simulation results further show that when the number of all antennas for RAUs is fixed, the better SE performance can be obtained with more RAUs.","2169-3536","","10.1109/ACCESS.2020.3009657","Natural Science Foundation of Liaoning Province(grant numbers:20180551028,2019-ZD-0355); General Project of Science and Technology Research of Liaoning Provincial Education Department(grant numbers:JZR2019002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9142187","Distributed massive MIMO (DM-MIMO);Rician fading;line-of-sight (LOS) component;power scaling law","Rician channels;Antenna arrays;Fading channels;Precoding;Contamination","","6","","40","CCBY","16 Jul 2020","","","IEEE","IEEE Journals"
"mmWrite: Passive Handwriting Tracking Using a Single Millimeter-Wave Radio","S. D. Regani; C. Wu; B. Wang; M. Wu; K. J. R. Liu","Department of Electrical and Computer Engineering, University of Maryland at College Park, College Park, MD, USA; Department of Electrical and Computer Engineering, University of Maryland at College Park, College Park, MD, USA; Department of Electrical and Computer Engineering, University of Maryland at College Park, College Park, MD, USA; Department of Electrical and Computer Engineering, University of Maryland at College Park, College Park, MD, USA; Department of Electrical and Computer Engineering, University of Maryland at College Park, College Park, MD, USA","IEEE Internet of Things Journal","23 Aug 2021","2021","8","17","13291","13305","In the era of pervasively connected and sensed Internet of Things, many of our interactions with machines have been shifted from conventional computer keyboards and mouses to hand gestures and writing in the air. While gesture recognition and handwriting recognition have been well studied, many new methods are being investigated to enable pervasive handwriting tracking. Most of the existing handwriting tracking systems either require cameras and handheld sensors or involve dedicated hardware restricting user convenience and the scale of usage. In this article, we present mmWrite, the first high-precision passive handwriting tracking system using a single commodity millimeter-wave (mmWave) radio. Leveraging the short wavelength and large bandwidth of 60-GHz signals and the radar-like capabilities enabled by the large phased array, mmWrite transforms any flat region into an interactive writing surface that supports handwriting tracking at millimeter accuracy. MmWrite employs an end-to-end pipeline of signal processing to enhance the range and spatial resolution limited by the hardware, boost the coverage, and suppress interference from backgrounds and irrelevant objects. We implement and evaluate mmWrite on a commodity 60-GHz device. The experimental results show that mmWrite can track a finger/pen with a median error of 2.8 mm and thus can reproduce handwritten characters as small as 1 cm × 1 cm, with a coverage of up to 8 m2 supported. With minimal infrastructure needed, mmWrite promises ubiquitous handwriting tracking for new applications in the field of human-computer interactions.","2327-4662","","10.1109/JIOT.2021.3066507","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9380316","60 GHz;handwriting tracking;human - computer interaction (HCI);millimeter wave (mmWave);passive tracking;radar;WiFi sensing","Radar tracking;Target tracking;Radar;Writing;Sensors;Trajectory;Radar antennas","","17","","56","IEEE","17 Mar 2021","","","IEEE","IEEE Journals"
"ExaMon-X: A Predictive Maintenance Framework for Automatic Monitoring in Industrial IoT Systems","A. Borghesi; A. Burrello; A. Bartolini","Department of Computer Science and Engineering and Electrical Engineering, University of Bologna, Bologna, Italy; Department of Computer Science and Engineering and Electrical Engineering, University of Bologna, Bologna, Italy; Department of Computer Science and Engineering and Electrical Engineering, University of Bologna, Bologna, Italy","IEEE Internet of Things Journal","6 Feb 2023","2023","10","4","2995","3005","In recent years, the Industrial Internet of Things (IIoT) has led to significant steps forward in many industries, thanks to the exploitation of several technologies, ranging from Big Data processing to artificial intelligence (AI). Among the various IIoT scenarios, large-scale data centers can reap significant benefits from adopting Big Data analytics and AI-boosted approaches since these technologies can allow effective predictive maintenance. However, most of the off-the-shelf currently available solutions are not ideally suited to the high-performance computing (HPC) context, e.g., they do not sufficiently take into account the very heterogeneous data sources and the privacy issues that hinder the adoption of the cloud solution, or they do not fully exploit the computing capabilities available in loco in a supercomputing facility. In this article, we tackle this issue, and we propose an IIoT holistic and vertical framework for predictive maintenance in supercomputers. The framework is based on a big lightweight data monitoring infrastructure, specialized databases suited for heterogeneous data, and a set of high-level AI-based functionalities tailored to HPC actors’ specific needs. We present the deployment and assess the usage of this framework in several in-production HPC systems.","2327-4662","","10.1109/JIOT.2021.3125885","EU H2020-ICT-11-2018-2019 IoTwins Project(grant numbers:857191); H2020-JTIEuroHPC-2019-1 Regale Project(grant numbers:956560); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9606215","Artificial intelligence (AI);high-performance computing;Industrial IoT;industry 4.0;predictive maintenance","Industrial Internet of Things;Predictive maintenance;Predictive models;Monitoring;Analytical models;Data models;Artificial intelligence","","6","","55","IEEE","8 Nov 2021","","","IEEE","IEEE Journals"
"An IoT based Environment Monitoring System","M. N. Hassan; M. R. Islam; F. Faisal; F. H. Semantha; A. H. Siddique; M. Hasan","Department of Computer Science and Engineering, Daffodil International University (DIU), Dhaka, Bangladesh; College of Engineering, IT and Environment, Charles Darwin University, NT, Australia; Department of Computer Science and Engineering, Daffodil International University (DIU), Dhaka, Bangladesh; College of Engineering, IT and Environment, Charles Darwin University, NT, Australia; Department of Computer Science and Engineering, University of Science and Technology, Chittagong, Bangladesh; Department of Computer Science and Engineering, University of Science and Technology, Chittagong, Bangladesh","2020 3rd International Conference on Intelligent Sustainable Systems (ICISS)","18 Jan 2021","2020","","","1119","1124","In recent years, people are getting more conscious of the environment they are living in. This consciousness is driving the need to develop a reliable environmental monitoring system. An environmental air quality monitoring system also has industrial application. In mining or in heavy industry, there is a possibility of air contamination by different harmful gases. In such hazardous situations, an environmental monitoring system can potentially save the life of the workers. In such large-scale sensor deployment, there are data collection, data management, connection, and power consumption issues. IoT technology is specifically suited for this sort of need. This paper presents an IoT based framework that effectively monitors the change in an environment using sensors, microcontroller, and IoT based technology. Users can monitor temperature, humidity, detect the presence of harmful gases both in the indoor and outdoor environment using the proposed module. The data is stored in the web server and the user can access the data anywhere in the world through an internet connection. In the proposed work a web application is developed to provide vital information to the user. The user can also set up a notification for critical changes in the sensor data. In comparison to other closely related systems, the proposed system is a low-cost one, accurate and user friendly. It is also cloud-based and has easy monitoring and data visualization modules. The system has been evaluated in different stages. After testing all the functions in different conditions, it shows a high degree of accuracy and reliability.","","978-1-7281-7089-3","10.1109/ICISS49785.2020.9316050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9316050","IoT;environment;big data;machine learning","Monitoring;Temperature sensors;Temperature measurement;Humidity;Gases;Batteries;Gas detectors","","18","","35","IEEE","18 Jan 2021","","","IEEE","IEEE Conferences"
"Real-Time Communication over LoRa Networks","S. Fahmida; V. P. Modekurthy; D. Ismail; A. Jain; A. Saifullah","Wayne State University, Detroit, USA; University of Nevada Las Vegas, Las Vegas, USA; Southern Illinois University, Edwardsville, USA; Iowa State University, Ames, USA; Iowa State University, Ames, USA","2022 IEEE/ACM Seventh International Conference on Internet-of-Things Design and Implementation (IoTDI)","23 Jun 2022","2022","","","14","27","Today, industrial Internet of Things (IIoT) are emerging in large-scale and wide-area applications (e.g., oil-field management). Traditional wireless solutions for industrial automation depend on short-range wireless technologies (WirelessHART, ISA100.11a), posing a big challenge to support the scale of today's IIoT. To address this limitation, we propose to adopt LoRa, a prominent low-power wide-area network technology, for industrial automation. Adopting LoRa for industrial automation poses some unique challenges. The fundamental building blocks of any industrial automation system are feedback control loops that largely rely on real-time communication. LoRa usually adopts a simple protocol based on ALOHA with no collision avoidance to minimize energy consumption which is less suitable for real-time communication. Existing real-time protocols for short-range technologies cannot be applied to a LoRa network due to its unique characteristics such as asymmetry between downlink and the uplink spectrum, predefined modes (class) of operation, and concurrent reception through orthogonal spreading factors. In this paper, we address these challenges and propose RTPL- a Real-Time communication Protocol for LoRa networks. RTPL is a low-overhead and conflict-free communication protocol allowing autonomous real-time communication of low-energy devices and exploits LoRa's capability of parallel communication. We implement our approach on LoRa devices and evaluate through both physical experiments and large scale simulations. All results show that RTPL achieves on average 75% improvement in real-time performance without sacrificing throughput or energy compared to traditional LoRa.","","978-1-6654-9641-4","10.1109/IoTDI54339.2022.00019","NSF(grant numbers:CNS-2211510,CAREER-2211523,CCF-2118202); ONR(grant numbers:N00014-22-1-2155); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9797411","LoRa;Low Power Wide Area Networks;Real-Time;Industrial Internet-of-Things;Closed Loop;Internet-of-Things;Cyber Physical Systems","Wireless communication;Performance evaluation;Automation;Protocols;Job shop scheduling;Throughput;Downlink","","7","","67","IEEE","23 Jun 2022","","","IEEE","IEEE Conferences"
"Decentral and Incentivized Federated Learning Frameworks: A Systematic Literature Review","L. Witt; M. Heyer; K. Toyoda; W. Samek; D. Li","Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Industrial Engineering, Tsinghua University, Beijing, China; Institute of High Performance Computing, Agency for Science, Technology and Research, Connexis, Singapore; Department of Artificial Intelligence, Fraunhofer Heinrich Hertz Institute, Berlin, Germany; Department of Computer Science, Tsinghua University, Beijing, China","IEEE Internet of Things Journal","6 Feb 2023","2023","10","4","3642","3663","The advent of federated learning (FL) has sparked a new paradigm of parallel and confidential decentralized machine learning (ML) with the potential of utilizing the computational power of a vast number of Internet of Things (IoT), mobile, and edge devices without data leaving the respective device, thus ensuring privacy by design. Yet, simple FL frameworks (FLFs) naively assume an honest central server and altruistic client participation. In order to scale this new paradigm beyond small groups of already entrusted entities toward mass adoption, FLFs must be: 1) truly decentralized and 2) incentivized to participants. This systematic literature review is the first to analyze FLFs that holistically apply both, the blockchain technology to decentralize the process and reward mechanisms to incentivize participation. 422 publications were retrieved by querying 12 major scientific databases. After a systematic filtering process, 40 articles remained for an in-depth examination following our five research questions. To ensure the correctness of our findings, we verified the examination results with the respective authors. Although having the potential to direct the future of distributed and secure artificial intelligence, none of the analyzed FLFs is production ready. The approaches vary heavily in terms of use cases, system design, solved issues, and thoroughness. We provide a systematic approach to classify and quantify differences between FLFs, expose limitations of current works and derive future directions for research in this novel domain.","2327-4662","","10.1109/JIOT.2022.3231363","Key-Area Research and Development Program of Guangdong Province(grant numbers:2021B0101400001); Tsinghua University-China Mobile Communications Group Company, Ltd. Joint Institute, KAKENHI from MEXT/JSPS, Japan(grant numbers:18K18162); German Ministry for Education and Research (BMBF) through BIFOLD(grant numbers:01IS18025A,01IS18037I); European Union’s Horizon 2020 Research and Innovation Programme through COPA EUROPE(grant numbers:957059); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9997105","Blockchain;federated learning (FL);incentive mechanism (IM);survey","Systematics;Peer-to-peer computing;Internet of Things;Training;Machine learning;Smart contracts;Federated learning","","11","","116","CCBY","22 Dec 2022","","","IEEE","IEEE Journals"
"Quality Estimation for Scarce Scenarios Within Mobile Crowdsensing Systems","S. B. Azmy; N. Zorba; H. S. Hassanein","Department of Electrical and Computer Engineering, Queen’s University, Kingston, Canada; College of Engineering, Qatar University, Doha, Qatar; School of Computing, Queen’s University, Kingston, Canada","IEEE Internet of Things Journal","12 Nov 2020","2020","7","11","10955","10968","Mobile crowdsensing (MCS) is a paradigm that exploits the presence of a crowd of moving human participants to acquire, or generate, data from their environment. As a part of the Internet-of-Things (IoT) paradigm, MCS serves the quest for a more efficient operation of a smart city. Big data techniques employed on this data produce inferences about the participants' environment, the smart city. However, sufficient amounts of data are not always available. Sometimes, the available data are scarce as it is obtained at different times, locations, and from different MCS participants who may not be present. As a consequence, the scale of data acquired may be small and susceptible to errors. In such scenarios, the MCS system requires techniques that acquire reliable inferences from such limited data sets. To that end, we resort to small data (SD) techniques that are relevant for scarce and erroneous scenarios. In this article, we discuss SD and propose schemes to tackle the problems associated with such limited data sets, in the context of the smart city. We propose two novel quality metrics: 1) MAD quality metric (MAD-Q) and 2) MAD bootstrap quality metric (MADBS-Q), to deal with SD, focusing on evaluating the quality of a data set within MCS. We also propose an MCS-specific coverage metric that combines the spatial dimension with MAD-Q and MADBS-Q. We show the performance of all the presented techniques through closed-form mathematical expressions, with which simulation results were found to be consistent.","2327-4662","","10.1109/JIOT.2020.2994556","Natural Sciences and Engineering Research Council of Canada(grant numbers:RGPIN-2019-05667); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9093050","Data quality;Internet of Things (IoT);IoT architectures;IoT-based services;mobile crowdsensing (MCS);small data (SD)","Measurement;Internet of Things;Standards;Smart cities;Task analysis;Intelligent sensors","","7","","30","IEEE","13 May 2020","","","IEEE","IEEE Journals"
"Blockchain and Deep Learning for Cyber Threat-Hunting in Software-Defined Industrial IoT","R. Kumar; P. Kumar; A. Kumar; A. A. Franklin; A. Jolfaei","Department of Computer Science and Engineering, Indian Institute of Technology Hyderabad, Hyderabad; Department of Computer Science and Engineering, Indian Institute of Technology Hyderabad, Hyderabad; Department of Electrical Engineering, Indian Institute of Technology Hyderabad, Hyderabad; Department of Computer Science and Engineering, Indian Institute of Technology Hyderabad, Hyderabad; Department of Computing, Macquarie University, Sydney, NSW, Australia","2022 IEEE International Conference on Communications Workshops (ICC Workshops)","11 Jul 2022","2022","","","776","781","The softwarized infrastructure of Software-Defined Industrial Internet of Things (SDIIoT) offers a cost-effective solution to improve flexibility and reliability in network management but faces several critical challenges. First, th Majority of SDIIoT entities operate over wireless channel, which expose them to a variety of attacks (e.g., man-in-the-middle, replay, and impersonation attacks) and also the centralized nature of SDN controller is prone to single point attacks. Second, network traffic in the SDIIoT is associated with large scale, high dimension and redundant data, all of which present significant hurdles in the development of efficient flow analyzer. In this regard, we present a novel blockchain and Deep Learning (DL) integrated framework for protecting confidential information and hunting cyber threats against SDIIoT and their network traffic. First the blockchain module is proposed to securely transmit industrial data from IIoT sensors to controllers of SDN via forwarding nodes (i.e., OpenFLow switches) using Clique Proof-of-Authority (C-PoA) consensus mechanism. A novel flow analyzer based on DL architecture named LSTMSCAE-AGRU is designed by combining Long Short-Term Memory Stacked Contractive AutoEncoder (LSTMSCAE) with Attention-based Gated Recurrent Unit (AGRU) at the control plane. The latter first extracts low-dimensional features in an unsupervised manner, which is then fed to AGRU for hunting anomalous switch requests. The proposed framework can withstand a variety of well-known cyber threats and mitigate the single point of controller failure problem in SDIIoT.","2694-2941","978-1-6654-2671-8","10.1109/ICCWorkshops53468.2022.9814706","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9814706","Blockchain;Deep Learning;Industrial Internet of Things (IIoT);Intrusion Detection System (IDS);Software-Defined Networking (SDN)","Deep learning;Wireless communication;Wireless sensor networks;Conferences;Scalability;Telecommunication traffic;Feature extraction","","5","","14","IEEE","11 Jul 2022","","","IEEE","IEEE Conferences"
"MIDAS: Safeguarding IoT Devices Against Malware via Real-Time Behavior Auditing","Y. Xu; Z. Yin; Y. Hou; J. Liu; Y. Jiang","School of Software, Tsinghua University, Beijing, China; School of Software, Tsinghua University, Beijing, China; School of Software, Tsinghua University, Beijing, China; School of Software, Tsinghua University, Beijing, China; School of Software, Tsinghua University, Beijing, China","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","25 Oct 2022","2022","41","11","4373","4384","The number of IoT devices on the Internet has surged recently, accompanied by a barrage of large-scale IoT malware infections breakouts. Designing security mechanisms for IoT devices poses significant challenges due to constantly changing malware variants that have numerous camouflage strategies, limited hardware resources, and heterogeneous architectures. In this article, we propose MIDAS, an adaptive safeguard framework for Linux-based IoT devices to defend against malwares with the real-time behavior auditing mechanism. First, we construct a stable and abstract behavior paradigm through behavioral characteristic extraction of 115 970 malwares. Then, based on the behavior paradigm, MIDAS can: 1) monitor suspicious behaviors of break-in programs in real-time driven by our built-in SELinux policy customized for malware defense; 2) aggregate behaviors of the program’s submodules with homology tracing; and 3) summarize these behaviors into abstract behavior pairs to unveil a possible IoT malware. Using the aforementioned real-time behavior auditing, MIDAS can constrain mutating and camouflaged malwares to protect discrepant IoT devices from being compromised while maintaining low overheads. We thoroughly evaluated the defense capabilities of MIDAS. On the benchmark dataset, MIDAS successfully constrained up to 94.46%, 91.79%, and 88.34% of 115970 malware samples on ARM, MIPS, and MIPSEL architectures, with less than 1.8 MiB of memory consumption and 0.54% CPU usage. Furthermore, we deployed virtual IoT devices worldwide to examine the performance of MIDAS when defending against real-world attacks. Over a duration of 25 days, these devices suffered from 971 951 attacks originating from 71 979 intruding malwares and 48 805 unique IPs distributed in 167 countries. For devices with MIDAS protection, the number of compromised incidents decreases by  $343.1\times $ , and the duration of continuous operation is  $179.2\times $  greater than devices without MIDAS on average. The evaluation results demonstrate that MIDAS can effectively safeguard IoT devices with minimal resource consumption.","1937-4151","","10.1109/TCAD.2022.3200908","NSFC Program(grant numbers:62022046,92167101,U1911401,62021002,62192730); National Key Research and Development Project(grant numbers:2019YFB1706203,2021QY0604); MIIT Project-Design of Intelligent Networked Vehicle Based on SOA Central Control; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9920949","Adaptive safeguard;behavior auditing;embedded firmware;IoT malware","Behavioral sciences;Malware;Internet of Things;Security;Real-time systems;Monitoring;Benchmark testing","","1","","36","IEEE","17 Oct 2022","","","IEEE","IEEE Journals"
"Industrial Edge Intelligence: Federated-Meta Learning Framework for Few-Shot Fault Diagnosis","J. Chen; J. Tang; W. Li","Shien-Ming Wu School of Intelligent Engineering, South China University of Technology, Guangzhou, China; Shien-Ming Wu School of Intelligent Engineering, South China University of Technology, Guangzhou, China; School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou, China","IEEE Transactions on Network Science and Engineering","24 Oct 2023","2023","10","6","3561","3573","The scarcity of fault samples has been the bottleneck for the large-scale application of mechanical fault diagnosis (FD) methods in the industrial Internet of Things (IIoT). Traditional few-shot FD methods are fundamentally limited in that the models can only learn from the direct dataset, i.e., a limited number of local data samples. Federated learning (FL) has recently shown the capacity of collaborative artificial intelligence and privacy preservation. Based on these capabilities, we propose a novel approach to solve the few-shot FD problem, which includes a generic framework (i.e., FedMeta-FFD) and an easy-to-implement enhancement technique (i.e., AILR). The FedMeta-FFD framework allows clients to learn from indirect datasets owned by other collaborators while training a global meta-learner to solve the few-shot problem directly. More concretely, with only a few labeled examples and training iterations, the global meta-learner can quickly adapt to a new client (e.g., a machine under different operating conditions) or a newly encountered fault category. Adopting AILR can significantly improve the performance of the FedMeta-FFD framework while also increasing the stability of the learning process. Further, we conduct a theoretical analysis of the proposed framework's convergence in a non-convex setting. We thoroughly evaluate the proposed FedMeta-FFD on two fault diagnosis datasets and also perform the practical validation on real-world IIoT scenarios. They demonstrate that our proposed approach achieves significantly faster convergence and higher accuracy than the existing approaches.","2327-4697","","10.1109/TNSE.2023.3266942","National Nature Science Foundation of China(grant numbers:62001168); National Natural Science Foundation of China(grant numbers:52275111); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10102331","Fault diagnosis;federated learning;few-shot learning;industrial edge intelligence;meta-learning","Fault diagnosis;Industrial Internet of Things;Servers;Adaptation models;Training;Convergence;Task analysis;Federated learning;Edge computing;Metalearning","","1","","48","IEEE","13 Apr 2023","","","IEEE","IEEE Journals"
"A Cloud-Edge Artificial Intelligence Framework for Sensor Networks","G. Loseto; F. Scioscia; M. Ruta; F. Gramegna; S. Ieva; C. Fasciano; I. Bilenchi; D. Loconte; E. D. Sciascio","LUM University “G. Degennaro”, Casamassima, Italy; Polytechnic University of Bari, Bari, Italy; Polytechnic University of Bari, Bari, Italy; Polytechnic University of Bari, Bari, Italy; Polytechnic University of Bari, Bari, Italy; Polytechnic University of Bari, Bari, Italy; Polytechnic University of Bari, Bari, Italy; Polytechnic University of Bari, Bari, Italy; Polytechnic University of Bari, Bari, Italy","2023 9th International Workshop on Advances in Sensors and Interfaces (IWASI)","3 Jul 2023","2023","","","149","154","Internet of Things devices allow building increasingly large-scale sensor networks for gathering heterogeneous high-volume data streams. Artificial Intelligence (AI) applications typically collect them into centralized cloud infrastructures to run computationally intensive Machine Learning (ML) tasks. According to the emerging edge computing paradigm, instead, data preprocessing, model training and inference can be distributed among devices at the border of the local network, exploiting data locality to improve response latency, bandwidth usage and privacy, at the cost of suboptimal model accuracy due to smaller training sets. The paper proposes a cloud-edge framework for sensor-based AI applications, enabling a dynamic trade-off between edge and cloud layers by means of: (i) a novel containerized microservice architecture, allowing the execution of both model training and prediction either on edge or on cloud nodes; (ii) flexible automatic migration of tasks between the edge and the cloud, based on opportunistic management of resources and workloads. In order to facilitate implementations, a scouting of compatible device platforms for field sensing and edge computing nodes has been carried out, as well as a selection of suitable open-source off-the-shelf software tools. Early experiments validate the feasibility and core benefits of the proposal.","2836-7936","979-8-3503-3694-8","10.1109/IWASI58316.2023.10164335","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10164335","sensor networks;cloud-edge intelligence;machine learning;microservice architecture","Training;Cloud computing;Computational modeling;Microservice architectures;Computer architecture;Predictive models;Data models","","","","24","IEEE","3 Jul 2023","","","IEEE","IEEE Conferences"
"Intelligent Embedded Vision for Summarization of Multiview Videos in IIoT","T. Hussain; K. Muhammad; J. D. Ser; S. W. Baik; V. H. C. de Albuquerque","Intelligent Media Laboratory, Digital Contents Research Institute, Sejong University, Seoul, South Korea; Department of Software, Sejong University, Seoul, South Korea; TECNALIA, Derio, Spain; Intelligent Media Laboratory, Digital Contents Research Institute, Sejong University, Seoul, South Korea; Graduate Program in Applied Informatics, Universidade de Fortaleza, Fortaleza, Brazil","IEEE Transactions on Industrial Informatics","22 Jan 2020","2020","16","4","2592","2602","Nowadays, video sensors are used on a large scale for various applications, including security monitoring and smart transportation. However, the limited communication bandwidth and storage constraints make it challenging to process such heterogeneous nature of Big Data in real time. Multiview video summarization (MVS) enables us to suppress redundant data in distributed video sensors settings. The existing MVS approaches process video data in offline manner by transmitting them to the local or cloud server for analysis, which requires extra streaming to conduct summarization, huge bandwidth, and are not applicable for integration with industrial Internet of Things (IIoT). This article presents a light-weight convolutional neural network (CNN) and IIoT-based computationally intelligent (CI) MVS framework. Our method uses an IIoT network containing smart devices, Raspberry Pi (RPi) (clients and master) with embedded cameras to capture multiview video data. Each client RPi detects target in frames via light-weight CNN model, analyzes these targets for traffic and crowd density, and searches for suspicious objects to generate alert in the IIoT network. The frames of each client RPi are encoded and transmitted with approximately 17.02% smaller size of each frame to master RPi for final MVS. Empirical analysis shows that our proposed framework can be used in industrial environments for various applications such as security and smart transportation and can be proved beneficial for saving resources.11[Online]. Available: https://github.com/tanveer-hussain/Embedded-Vision-for-MVS.","1941-0050","","10.1109/TII.2019.2937905","National Research Foundation of Korea; Korea government (MSIT)(grant numbers:2019R1A2B5B01070067); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8815938","Artificial intelligence;Big Data;computational intelligence;computer vision;convolutional neural network (CNN);industrial Internet of Things (IIoT);Internet of Things (IoT);video summarization","Videos;Cameras;Big Data;Object detection;Economic indicators;Industries","","59","","40","IEEE","27 Aug 2019","","","IEEE","IEEE Journals"
"Passive Network Synchronization Based on Concurrent Observations in Industrial IoT Systems","P. Jia; X. Wang; X. Shen","Department of Electrical and Computer Engineering, Western University, London, Canada; Department of Electrical and Computer Engineering, Western University, London, Canada; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, Canada","IEEE Internet of Things Journal","6 Sep 2021","2021","8","18","14028","14038","Accurate network synchronization is crucial to orchestrate distributed infrastructures in Industrial Internet of Things (IIoT) systems for accomplishing network-wide tight temporal collaboration. Traditional clock synchronization can be achieved with extensive exchanges of explicit timestamps for estimating clock offsets, which becomes impractical due to high overhead with the expansion of the network scale. The performance of conventional synchronization will also be dramatically deteriorated due to various uncertainties of IIoT networks. In this article, we propose a passive network synchronization scheme based on concurrent passive observations to calibrate the distributed clocks in IIoT systems while significantly reducing the explicit interactions and network resource consumption during synchronization. By processing the physical phenomena observed concurrently by a group of selected IIoT devices, the local clock offsets of the passive observing devices can be efficiently estimated according to the common time reference linked to the event observed. Multiple relay nodes are further coordinated by the cloud center to disseminate the reference time information throughout the IIoT system. Simulation results demonstrate that by utilizing a series of concurrent observations with efficient coordination, the proposed scheme can achieve accurate and reliable network synchronization for large-scale IIoT systems with significantly reduced network overhead.","2327-4662","","10.1109/JIOT.2021.3070242","Natural Sciences and Engineering Research Council of Canada Discovery Program(grant numbers:RGPIN-2018-06254); Idea to Innovation Program(grant numbers:I2IPJ 538563-19); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9392007","Industrial Internet of Things (IIoT);passive network synchronization;principal component analysis (PCA);received signal strength;temporal correlation;timestamp-free","Industrial Internet of Things;Synchronization;Clocks;Reliability;Protocols;Cloud computing;Passive networks","","7","","23","IEEE","31 Mar 2021","","","IEEE","IEEE Journals"
"Privacy-Preserving Honeypot-Based Detector in Smart Grid Networks: A New Design for Quality-Assurance and Fair Incentives Federated Learning Framework","A. Albaseer; M. Abdallah","Division of Information and Computing Technology, College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar; Division of Information and Computing Technology, College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar","2023 IEEE 20th Consumer Communications & Networking Conference (CCNC)","17 Mar 2023","2023","","","722","727","Adopting honeypot defenses is a promising technology for protecting the industrial Internet of Things (IIoT), particularly the Advanced Metering Infrastructure (AMI). The effectiveness of AMI defense is entirely reliant on the deployment of honeypots by small-scale power suppliers (SPSs) and then sharing the defense data with traditional power retailers (TPRs) to build anomaly detectors. TPR encourages the SPSs to share their collected honeypot logs by designing proper rewards. However, TPRs cannot confirm the validity of the shared defense data unless they have access to SPSs' private data, compromising their privacy since SPSs may be reluctant to disclose their private collected data. In addition, the honeypot logs are large, which increases the sharing costs. Federated Learning (FL), as a promising privacy-preserving machine learning technique, can solve these problems. Yet, the conventional FL algorithm cannot optimally fit the security defense model and the associated returned rewards in the AMI network. Thus, using two proposed solutions, including a modified FedAvg algorithm, this paper proposes a privacy-preserving and cost-effective FL framework for efficient security model development and fair rewards, in which SPSs can share only the learned ML model while TPR can validate the quality of the uploaded models and compensate all participants with appropriate rewards that reflect their contributions. The proposed framework also considers malicious participants who claim high-quality data while sharing bad models. We run extensive simulations on realistic log datasets, and the results show that the proposed solutions outperform existing approaches.","2331-9860","978-1-6654-9734-3","10.1109/CCNC51644.2023.10060393","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10060393","Smart Grid Networks;Honeypot;DL-based detector;Privacy-preserving;Incentive mechanism;Federated Learning","Training;Machine learning algorithms;Federated learning;Detectors;Data models;Smart grids;Security","","3","","19","IEEE","17 Mar 2023","","","IEEE","IEEE Conferences"
"zkFDL: An efficient and privacy-preserving decentralized federated learning with zero knowledge proof","M. Ahmadi; R. Nourmohammadi","Shahid Beheshti University, Tehran, Iran; The University Of British Columbia, Kelowna, Canada","2024 IEEE 3rd International Conference on AI in Cybersecurity (ICAIC)","16 Feb 2024","2024","","","1","10","Federated leaning (FL) has been frequently used in various field of studies and businesses. Traditional centralized FL systems suffer from serious issues. To address these concerns, decentralized federated learning (DFL) systems have been introduced in recent years in which with the help of blockchains, try to achieve more integrity and efficiency. On the other hand, privacy-preserving is an uncovered part of these systems. To address this, and also scaling the blockchain-based computations, we propose a zero knowledge proof (ZKP) based aggregator (zkDFL) that allows clients to share their large-scale model parameters with a trusted centralized server without revealing their individual data to other clients. We utilize blockchain technology to manage the aggregation algorithm via smart contracts. The server performs a ZKP algorithm to prove to the clients that the aggregation is done according to the accepted algorithm. The server can also prove that all inputs of clients have been used. We evaluate our measure through a public dataset about wearable internet of things. As demonstrated by numerical evaluations, zkDFL introduces verifiability of correctness of aggregation process and enhances the privacy protection and scalability of DFL systems, while the gas cost has declined significantly.","","979-8-3503-8185-6","10.1109/ICAIC60265.2024.10433831","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10433831","federated learning;blockchain;zero knowledge proof;aggregator algorithm;scaling systems","Costs;Federated learning;Smart contracts;Blockchains;Servers;Zero knowledge proof;Task analysis","","","","59","IEEE","16 Feb 2024","","","IEEE","IEEE Conferences"
"Evaluating the Performance of a State-of-the-Art Group-oriented Encryption Scheme for Dynamic Groups in an IoT Scenario","T. Prantl; P. Ten; L. Iffländer; A. Dmitrenko; S. Kounev; C. Krupitzer",University of Würzburg; University of Würzburg; University of Würzburg; University of Würzburg; University of Würzburg; University of Würzburg,"2020 28th International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems (MASCOTS)","21 Dec 2020","2020","","","1","8","New emerging technologies, such as autonomous driving, intelligent buildings, and smart cities, are promising to revolutionize user experience and offer new services. The world has to undergo large scale deployment of billions of things - cost-efficient intelligent sensors that will be interconnected into extensive networks and will collect and supply data to intelligent algorithms - to make it happen. To date, however, it is challenging to secure such an infrastructure for many-fold reasons, such as resource constraints of things, large scale deployment, many-to-many communication patterns, and dynamically changing communication groups. All these factors rule out most of the state-of-the-art encryption and key-management techniques. Group encryption algorithms are well-suitable for many-to-many communication patterns typical for IoT networks, and many of them can deal with dynamic groups. There are, however, very few constructions that could potentially fulfill the computational and storage constraints of IoT devices while providing sufficient scalability for large networks. The promising candidates, such as construction by Nishat et al. [1], were not evaluated using IoT platforms and under constraints typical for IoT networks. In this paper, we aim to fill this gap and present the evaluation of a state-of-the-art group-oriented encryption scheme by Nishat et al. to identify its applicability to IoT systems. In detail, we provide a measurement workflow, a revised version of the approach, and describe a reproducible hardware testbed. Using this evaluation environment, we analyze the performance of the encryption scheme in a typical IoT scenario from a group member perspective. The results show that all calculation times can be assumed to be constant and are always below 2 seconds. The memory requirement for permanent parameters can also be considered to be constant and are below 8.5 kbit in each case. However, the information that has to be stored temporarily for group updates has turned out to be the bottleneck of the scheme, since their memory requirements increase linearly with the group size.","2375-0227","978-1-7281-9238-3","10.1109/MASCOTS50786.2020.9285948","Federal Ministry of Education and Research of Germany; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9285948","Security;Group Encryption;Performance Evaluation;Internet of Things","Analytical models;Heuristic algorithms;Computational modeling;Memory management;Hardware;Encryption;Guidelines","","9","","22","IEEE","21 Dec 2020","","","IEEE","IEEE Conferences"
"A Scalable Privacy Preserving Distributed Parallel Optimization for a Large-Scale Aggregation of Prosumers With Residential PV-Battery Systems","M. Dolatabadi; P. Siano","Department of Mathematics, Vali-e-Asr University of Rafsanjan, Rafsanjan, Iran; Department of Management and Innovation Systems, University of Salerno, Fisciano, Italy","IEEE Access","2 Dec 2020","2020","8","","210950","210960","A novel scalable and privacy-preserving distributed parallel optimization that allows the participation of large-scale aggregation of prosumers with residential PV-battery systems in the market for the ancillary service (ASM) is proposed in this paper. To consider both reserve capacity and energy, day-ahead and real-time stages in the ASM are considered. A method based on hybrid Variable Neighborhood Search (VNS) and distributed parallel optimization is designed for the day ahead and real-time optimization. Different distributed optimization methods are compared and designed and a new distributed optimization method based on Linear Programming (LP) is proposed that outperforms previous methods based on integer and Quadratic programming (QP). The proposed LP-based optimization can be easily coded up and implemented on microcontrollers and connected to a designed Internet of Things (IoT) based architecture. As confirmed by simulation results, carried out considering different realistic case studies, both day-ahead and real-time proposed optimization methods, by allocating the computational effort among local resources, are highly scalable and fulfil the privacy of prosumers.","2169-3536","","10.1109/ACCESS.2020.3035432","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9247187","Aggregator;PV-battery systems;battery energy storage systems;up and down-regulation;ancillary services market;linear programming;quadratic programming;distributed optimization;alternating direction method of multipliers (ADMM)","Privacy;Microcontrollers;Simulation;Linear programming;Real-time systems;Internet of Things;Quadratic programming","","17","","18","CCBY","3 Nov 2020","","","IEEE","IEEE Journals"
"Maximizing Energy Efficiency in UAV-Assisted NOMA–MEC Networks","Z. Liu; J. Qi; Y. Shen; K. Ma; X. Guan","School of Electrical Engineering, Yanshan University, Qinhuangdao, China; School of Electrical Engineering, Yanshan University, Qinhuangdao, China; Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; School of Electrical Engineering, Yanshan University, Qinhuangdao, China; School of Electronic, Information and Electrical Engineering, Shanghai Jiaotong University, Shanghai, China","IEEE Internet of Things Journal","11 Dec 2023","2023","10","24","22208","22222","Mobile-edge computing (MEC) is a key technology to enable multitasking and low-latency user experiences for 5G Internet of Things (IoT) devices. The nonorthogonal multiple access (NOMA) technology is used in this context to enable large-scale connectivity and improve spectrum efficiency, with the unmanned aerial vehicle (UAV) serving as both computing units and relays for mobile users (MUs). Energy efficiency (EE) remains challenging given the limited energy available to the UAV and MUs. In this article, a UAV-assisted NOMA–MEC communication network architecture is studied to maximize the EE of the total system by jointly optimizing the user’s communication scheduling, resource allocation, and UAV flight trajectory. Among them, the resource allocation problem can further be divided into the transmit power optimization problem and the task computation allocation problem, whereby the corresponding time slot scheduling is obtained. The objective function is a nonconvex mixed-integer nonlinear fractional programming (MINLFP) problem, which is too complex to solve directly. Therefore, it is decomposed into more manageable subproblems and solved iteratively. Fractional problems are solved using the Dinkelbach method, which transforms their original subproblems into convex forms with methods such as successive convex approximation (SCA). Simulation results demonstrate the convergence of our proposed algorithm and its significant advantage over existing strategies in terms of EE.","2327-4662","","10.1109/JIOT.2023.3303491","National Natural Science Foundation of China(grant numbers:62273298,62122065,61503368); Shenzhen Science and Technology Program(grant numbers:JCYJ20220818101607015); Natural Science Foundation of Guangdong Province(grant numbers:2021A1515011856); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10214196","Energy efficiency (EE);mobile-edge computing (MEC);nonorthogonal multiple access (NOMA);resource allocation;unmanned aerial vehicle (UAV)","Autonomous aerial vehicles;NOMA;Task analysis;Energy consumption;Resource management;Internet of Things;Servers;Energy efficiency;Multi-access edge computing","","3","","40","IEEE","9 Aug 2023","","","IEEE","IEEE Journals"
"The Polish perspective of using unmanned aerial vehicle systems in international firefighting and crisis management missions - legal and technological analysis","A. T. Balcerzak; B. E. Jasiuk; C. A. Fellner; D. M. Feltynowski","Faculty of Law and Administration, Lazarski University, Warsaw, Poland; Faculty of Law and Administration, Lazarski University, Warsaw, Poland; Silesian University of Technology, Katowice, Poland; National Center for Rescue Coordination and Civil Protection, National Headquarters of the State Fire Service of Poland, Warszawa, Poland","2021 International Conference on Unmanned Aircraft Systems (ICUAS)","19 Jul 2021","2021","","","1478","1487","The subject of using UAV (Unmanned Aerial Vehicle) in extinguishing activities during large-scale forest fires is described in the scientific literature. For example, the Web of Science service for the period 1990-2018 recorded 308 publications related to UAV and forest fires [1]. These are mainly analyzes and studies on remote fire detection, monitoring, mapping, architecture and technology integration. There is a noticeable growing interest of researchers in the subject of using machine learning to detect and predict the spread of fires using unmanned aerial vehicles [2]. At the same time, analyzes are carried out on the ad-hoc creation of local data networks using drones [3], or drones as an element of the Internet of Things (IoT) [4]. In the operational context, concepts and solutions such as water transfer and extinguishing with UAV are only being tested. [5]. Another important challenge is that current firefighting civil aviation regulations only allow firefighting manned aircrafts to operate between first and last flight due to safety concerns for pilots, limiting the operation time to an average of 12 hours, which leads to many fires reactivating at night. This paper will analyze the legal and technological polish perspective of Unmanned Aircraft Systems usage in international firefighting and crisis management missions.","2575-7296","978-1-6654-1535-4","10.1109/ICUAS51884.2021.9476800","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9476800","","Industries;Crisis management;Law;Europe;Organizations;Forestry;Streaming media","","3","","50","IEEE","19 Jul 2021","","","IEEE","IEEE Conferences"
"Data-Driven Distributed and Localized Model Predictive Control","C. A. Alonso; F. Yang; N. Matni","Department of Computing and Mathematical Sciences, California Institute of Technology, Pasadena, CA, USA; Department of Computer and Information Science, University of Pennsylvania, Philadelphia, PA, USA; Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA, USA","IEEE Open Journal of Control Systems","9 Jun 2022","2022","1","","29","40","Motivated by large-scale but computationally constrained settings, e.g., the Internet of Things, we present a novel data-driven distributed control algorithm that is synthesized directly from trajectory data. Our method, data-driven Distributed and Localized Model Predictive Control (D$^{3}$LMPC), builds upon the data-driven System Level Synthesis (SLS) framework, which allows one to parameterize closed-loop system responses directly from collected open-loop trajectories. The resulting model-predictive controller can be implemented with distributed computation and only local information sharing. By imposing locality constraints on the system response, we show that the amount of data needed for our synthesis problem is independent of the size of the global system. Moreover, we show that our algorithm enjoys theoretical guarantees for recursive feasibility and asymptotic stability. Finally, we also demonstrate the optimality and scalability of our algorithm in a simulation experiment.","2694-085X","","10.1109/OJCSYS.2022.3171787","NSF(grant numbers:CPS-2038873); CAREER(grant numbers:ECCS-2045834); Google Research Scholar; Caltech/Amazon AI4Science fellowship; NSF CAREER(grant numbers:ECCS-2045834); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9772975","Data-driven optimization;decentralized/distributed control;large-scale systems;optimal control","Trajectory;Computational modeling;Asymptotic stability;Data models;Prediction algorithms;Linear systems","","2","","35","CCBY","11 May 2022","","","IEEE","IEEE Journals"
"LoRaDrone: Enabling Low-Power LoRa Data Transmission via a Mobile Approach","C. Chen; J. Luo; Z. Xu; R. Xiong; Z. Yin; J. Lin; D. Shen","School of Computer Science and Engineering, Southeast University; School of Computer Science and Engineering, Southeast University; School of Computer Science and Engineering, Southeast University; School of Computer Science and Engineering, Southeast University; Department of Computer Science, City University of Hong Kong; School of Computer Science and Engineering, Southeast University; School of Computer Science and Engineering, Southeast University","2022 18th International Conference on Mobility, Sensing and Networking (MSN)","29 Mar 2023","2022","","","239","246","Low-Power Wide Area Networks (LPWANs) are widely used to connect large-scale Internet of Things (IoT) applications. Long Range (LoRa) is a promising LPWAN technology sensitive to energy consumption, since LoRa nodes are generally battery-powered, and the battery life will influence the lifetime of the LoRa network. In practice, the battery life of LoRa nodes is short in many scenarios, due to the long transmission distance form the gateway leading to high energy consumption. Existing techniques for energy-efficient data transmission mainly focus on static gateways, and will consume huge energy of remote nodes. In this paper, we propose to integrate LoRa with mobility to minimize the energy consumption of nodes by effectively shortening the transmission distances, and design the first mobile LoRa data transmission system called LoRaDrone by leveraging the unmanned aerial vehicle (UAV) gateway flying close to nodes. Specifically, we present a low-power communication mechanism and a dynamic channel allocation policy to minimize the energy consumed in sensing and communicating with the UAV gateway, while considering the distinctive LoRa parallel reception and complex transmission collisions. Then, an optimal speed scheduling strategy is designed to ensure the reliability of data transmission, and minimize the energy consumption of the UAV. Evaluations on various scales verify the effectiveness of LoRaDrone under different nodes' distributions and UAV paths. Compared with the baselines, the energy consumption of nodes using LoRaDrone is at most reduced by $\mathbf{70.37}\times$ at 5000 nodes.","","978-1-6654-6457-4","10.1109/MSN57253.2022.00050","National Key R&D Program of China(grant numbers:2021YFB2900100); NSFC(grant numbers:62232004,62172091,61602112); Jiangsu Provincial Key R&D Program(grant numbers:BE2022065-4); Key Laboratory of Network and Information Security(grant numbers:BM2003201,93K-9); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10076688","LoRa;mobility;low-power;data transmission;scheduling","Energy consumption;Logic gates;Autonomous aerial vehicles;Reliability engineering;Sensors;Batteries;Data communication","","","","23","IEEE","29 Mar 2023","","","IEEE","IEEE Conferences"
"AgriSegNet: Deep Aerial Semantic Segmentation Framework for IoT-Assisted Precision Agriculture","T. Anand; S. Sinha; M. Mandal; V. Chamola; F. R. Yu","Department of Electrical and Electronics Engineering, Birla Institute of Technology and Science (BITS), Pilani, Pilani, India; Smart Sensors Area, Council of Scientific and Industrial Research-Central Electronics Engineering Research Institute (CSIR-CEERI), Pilani, India; Department of Computer Science and Engineering, Indian Institute of Information Technology, Kota (IIIT Kota), Kota, India; Department of Electrical and Electronics Engineering, Birla Institute of Technology and Science (BITS), Pilani, Pilani, India; Department of Computer Science and Engineering, Carleton University, Ottawa, ON, Canada","IEEE Sensors Journal","13 Aug 2021","2021","21","16","17581","17590","Aerial inspection of agricultural regions can provide crucial information to safeguard from numerous obstacles to efficient farming. Farmland anomalies such as standing water, weed clusters, hamper the farming practices, which causes improper use of farm area and disrupts agricultural planning. Monitoring of farmland and crops through Internet-of-Things (IoT)-enabled smart systems has potential to increase the efficiency of modern farming techniques. Unmanned Aerial Vehicle (UAV)-based remote sensing is a powerful technique to acquire farmland images on a large scale. Visual data analytics for automatic pattern recognition from the collected data is useful for developing Artificial intelligence (AI)-assisted farming models, which holds great promise in improving the farming outputs by capturing the crop patterns, farmland anomalies and providing predictive solutions to the inherent challenges faced by farmers. In this work, we propose a deep learning framework AgriSegNet for automatic detection of farmland anomalies using multiscale attention semantic segmentation of UAV acquired images. The proposed model is useful for monitoring of farmland and crops to increase the efficiency of precision farming techniques.","1558-1748","","10.1109/JSEN.2021.3071290","SICI Shastri Institutional Collaborative Research Grant (SICRG) through the Project Artificial Intelligence Enabled Security Provisioning and Vehicular Vision innovations for Autonomous Vehicles; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9395478","Deep learning;IoT;agriculture;agriculture-vision;semantic segmentation;sensors","Agriculture;Image segmentation;Feature extraction;Semantics;Monitoring;Head;Deep learning","","61","","44","IEEE","5 Apr 2021","","","IEEE","IEEE Journals"
"Stacked Autoencoder-Based Deep Reinforcement Learning for Online Resource Scheduling in Large-Scale MEC Networks","F. Jiang; K. Wang; L. Dong; C. Pan; K. Yang","Hunan Provincial Key Laboratory of Intelligent Computing and Language Information Processing, Hunan Normal University, Changsha, China; Department of Computer and Information Sciences, Northumbria University, Newcastle upon Tyne, U.K.; Key Laboratory of Hunan Province for New Retail Virtual Reality Technology, Hunan University of Technology and Business, Changsha, China; School of Electronic Engineering and Computer Science, Queen Mary University of London, London, U.K.; School of Computer Technology and Engineering, Changchun Institute of Technology, Changchun, China","IEEE Internet of Things Journal","9 Oct 2020","2020","7","10","9278","9290","An online resource scheduling framework is proposed for minimizing the sum of weighted task latency for all the Internet-of-Things (IoT) users, by optimizing offloading decision, transmission power, and resource allocation in the large-scale mobile-edge computing (MEC) system. Toward this end, a deep reinforcement learning (DRL)-based solution is proposed, which includes the following components. First, a related and regularized stacked autoencoder (2r-SAE) with unsupervised learning is applied to perform data compression and representation for high-dimensional channel quality information (CQI) data, which can reduce the state space for DRL. Second, we present an adaptive simulated annealing approach (ASA) as the action search method of DRL, in which an adaptive ${h}$ -mutation is used to guide the search direction and an adaptive iteration is proposed to enhance the search efficiency during the DRL process. Third, a preserved and prioritized experience replay (2p-ER) is introduced to assist the DRL to train the policy network and find the optimal offloading policy. The numerical results are provided to demonstrate that the proposed algorithm can achieve near-optimal performance while significantly decreasing the computational time compared with existing benchmarks.","2327-4662","","10.1109/JIOT.2020.2988457","National Natural Science Foundation of China(grant numbers:41604117,41904127,41874148,61701179,61620106011,61572389); Scientific Research Fund of Hunan Provincial Education Department in China(grant numbers:18A031); Hunan Provincial Science Technology Project Foundation(grant numbers:2018TP1018,2018RS3065); U.K. EPSRC Project NIRVANA(grant numbers:EP/L026031/1); Degree & Postgraduate Education Reform Project of Hunan Normal University(grant numbers:18JG15); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070170","Adaptive simulated annealing;deep reinforcement learning (DRL);large-scale mobile-edge computing (MEC);stacked autoencoder","Task analysis;Resource management;Internet of Things;Machine learning;Edge computing;Data compression;Simulated annealing","","34","","38","IEEE","17 Apr 2020","","","IEEE","IEEE Journals"
"Federated Threat-Hunting Approach for Microservice-Based Industrial Cyber-Physical System","M. Abdel-Basset; H. Hawash; K. Sallam","Faculty of Computers and Informatics, Zagazig University, Zagazig, Egypt; Faculty of Computers and Informatics, Zagazig University, Zagazig, Egypt; Faculty of Computers and Informatics, Zagazig University, Zagazig, Egypt","IEEE Transactions on Industrial Informatics","7 Dec 2021","2022","18","3","1905","1917","The lightning convergence of industry 4.0 and the intelligent Internet of Things (IoT) technologies has significantly increased the vulnerability of industrial cyber-physical systems (ICPSs) to a large population of cyber threats. Intelligent threat detection for discovering cyber threats is a challenging task as it essentially deals with wide-scale, complicated, and heterogeneous ICPSs. This article presents a novel federated deep learning (DL) model (Fed-TH) for hunting cyber threats against ICPSs that captures the temporal and spatial representations of network data. Then, a container-based industrial edge computing framework is designed to deploy the Fed-TH as a threat-hunting microservice on suitable edge servers while maintaining decent resource orchestration. To tackle the latency issue of an ICSP, an exploratory microservice placement method is introduced to enable better microservice deployment based on the computational resources of the participants. The simulation results obtained from two public benchmarks validate the effectiveness of these approaches in terms of accuracy (92.97%, 92.84%) and f1-scores (91.61%, 90.49%).","1941-0050","","10.1109/TII.2021.3091150","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9462475","Cyber-physical system;deep learning (DL);industrial Internet of Things (IIoT);threat intelligence (TI)","Cloud computing;Industrial Internet of Things;Computational modeling;5G mobile communication;Servers;Data privacy;Task analysis","","22","","29","IEEE","22 Jun 2021","","","IEEE","IEEE Journals"
"PFQDN: SDN- and DNS-Assisted Transparent Communications Among Behind-NAT Networks","W. -K. Jia","College of Photonic and Electronic Engineering, Fujian Normal University, Fuzhou, China","IEEE Systems Journal","8 Jun 2023","2023","17","2","2271","2281","It is common knowledge that network address translation (NAT) is the most economical means of deployment large-scale users to access the IPv4-based Internet, which could be combined with a few, even single public IP addresses. Although the NAT issues do not catch more attention from the research community, it does not mean they are unimportant to modern network deployments, e.g., fifth-generation (5G) and Internet of Things (IoT). This article introduces a structured transparent communications service framework among NATed subdomains, consisting of software-defined networks and an authoritative domain name system. Through addressing via the private fully qualified domain name, the above components coordinate and provide bidirectional interconnect capability among NAT-enabled intranets. In other words, each internal host with a private IP address has a dedicated corresponding PFQDN on the outside. The proposed scheme emphasizes availability: which extends the IPv4 address space from 232 to 256 or even more; but at the expense of performance: which restricts the concurrent quantity of reverse connections during a time period (depending on the quantity of available public IP addresses). The proposed scheme features a high potential to solve the NAT traversal problems for Internet services and applications that may encounter IPv4 address exhaustion on the current Internet.","1937-9234","","10.1109/JSYST.2022.3177645","National Natural Science Foundation of China(grant numbers:61871131,U1805262); Key Laboratory of Optoelectronic Science and Technology for Medicine of Ministry of Education; Fujian Provincial Key Laboratory of Photonics Technology; Fujian Normal University, China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794301","Domain name system (DNS);fully qualified domain name (PFQDN);network address translation (NAT);software-defined networks (SDNs);transparent communications","IP networks;Logic gates;Internet of Things;Switches;Servers;Protocols;Middleware","","1","","33","IEEE","10 Jun 2022","","","IEEE","IEEE Journals"
"Anticipatory Control of Flexible Loads for System Resilience Enhancement Facing Accidental Outages","H. Hui; Q. Yang; N. Dai; H. Zhang; Y. Ding; Y. Song","State Key Laboratory of Internet of Things for Smart City, University of Macau, Macao, China; State Key Laboratory of Internet of Things for Smart City, University of Macau, Macao, China; State Key Laboratory of Internet of Things for Smart City, University of Macau, Macao, China; State Key Laboratory of Internet of Things for Smart City, University of Macau, Macao, China; College of Electrical Engineering, Zhejiang University, Hangzhou, China; State Key Laboratory of Internet of Things for Smart City, University of Macau, Macao, China","2021 International Conference on Power System Technology (POWERCON)","8 Feb 2022","2021","","","844","849","The accidental outages of generating units are increasing rapidly around the world due to extreme weather, cyber attacks and some manual misoperations, which are seriously impacting the stable and secure operation of urban power systems. To enhance the system resilience, more attentions are paid to regulating flexible loads (FLs) in demand-side by utilizing the progressed Internet of Things technologies. However, most previous control methods of FLs are based on the detected frequency deviations or voltage violations, i.e., the regulation on FLs are implemented after the imbalance really happens. This may lead to the expansion of the accident influence and cause large-scale blackouts. To address this issue, this paper proposes an anticipatory control method of FLs to provide faster-than-real-time contingency reserve for the power system. Firstly, a reconstructed power system model after accidental outages is proposed to quantify the disturbance of generating units’ outages. Then, an evaluation method of the system frequency deviation nadir is developed to prejudge the most serious damage caused by accidental outages. On this basis, an anticipatory control method of FLs is proposed to impede the fast drop of the system frequency and decrease the harm of accidental outages. Finally, the effectiveness of the proposed method is verified by numerical studies, where the evaluation accuracy of the system frequency nadir can reach about 95% and the maximum system frequency deviation can be reduced about 50%.","2642-6226","978-1-6654-0737-3","10.1109/POWERCON53785.2021.9697825","Technology Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9697825","Anticipatory control;flexible load;power system resilience;accidental outage","Fault tolerance;Time-frequency analysis;Proportional control;Regulation;Power systems;Internet of Things;Voltage control","","","","26","IEEE","8 Feb 2022","","","IEEE","IEEE Conferences"
"Cost-Effective Blockchain-based IoT Data Marketplaces with a Credit Invariant","J. Meijers; G. Dharma Putra; G. Kotsialou; S. S. Kanhere; A. Veneris","University of Toronto; UNSW, Sydney; London School of Economics and Political Science; UNSW, Sydney; University of Toronto","2021 IEEE International Conference on Blockchain and Cryptocurrency (ICBC)","24 Jun 2021","2021","","","1","9","Billions of Internet of Things (IoT) devices deployed today collect massive amounts of potentially valuable data. To efficiently utilize this data, markets must be developed where data can be traded in real time. Blockchain technology offers a potential platform for these types of markets. However, previous proposals using blockchain technology either require trusted third parties such as data brokers, or necessitate a large number of on-chain transactions to operate, incurring excessive overhead costs. This paper proposes a trustless data trading system that minimizes both the risk of fraud and the number of transactions performed on chain. In this system, data producers and consumers come to binding agreements while trading data off chain and they only settle on chain when a deposit or withdrawal of funds is required. A credit mechanism is also developed to further reduce the incurred fees. Additionally, the proposed marketplace is benchmarked on a private Ethereum network running on a lab-scale testbed and the proposed credit system is simulated so to analyze its risks and benefits.","","978-1-6654-3578-9","10.1109/ICBC51069.2021.9461127","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9461127","IoT;blockchain;data marketplace;mechanism design","Simulation;Scalability;Smart contracts;Ecosystems;Blockchain;Pricing;Games","","10","","24","IEEE","24 Jun 2021","","","IEEE","IEEE Conferences"
"IoT-Based Monitoring in Carbon Capture and Storage Systems","A. Chawla; Y. Arellano; M. V. Johansson; H. Darvishi; K. Shaneen; M. Vitali; F. Finotti; P. S. Rossi","Norwegian University of Science and Technology (NTNU), Norway; SINTEF Energy Research, Norway; SINTEF Energy Research, Norway; Norwegian University of Science and Technology (NTNU), Norway; Norwegian University of Science and Technology (NTNU), Norway; Marche Polytechnic University, Italy; SINTEF Energy Research, Norway; Norwegian University of Science and Technology (NTNU), Norway","IEEE Internet of Things Magazine","9 Jan 2023","2022","5","4","106","111","Carbon capture and storage (CCS) is critical for climate-change policies and strategies targeting global warming within the Paris Agreement. The overarching technological requirements are well described in the strategic plans, yet several barriers exist to the technology's wide-spread deployment, including improved cost-effectiveness and enhanced process integration. For the safe and reliable operation of large-scale CCS systems, the development of effective Internet of things (IoT)-based monitoring tools to ensure flow assurance of CO2 throughout the CCS value chain is crucial. Further, reliable sensor measurements related to different transport parameters such as temperature, pressure, and flow across the process are essential to develop these methods. However, sensors are prone to errors due to inherent issues or environmental conditions which result in performance degradation of the overall monitoring system. Developing techniques for detecting anomalies in the measurements, identifying the faulty sensors and accommodating them with appropriately estimated data is one of the paramount requirements for the reliable operation of the CCS systems. In such context, the present article provides an overview of CCS's monitoring and control requirements, emphasizing data-fusion synergies. This work investigates the state-of-the-art methods for sensor validation and proposes a roadmap to further deploy metering technologies for industrial needs.","2576-3199","","10.1109/IOTM.001.2200175","Norwegian Research council(grant numbers:311902); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10012404","","Fault diagnosis;Analytical models;Thermodynamics;Area measurement;Data models;Numerical models;Internet of Things;Climate change;Carbon capture and storage","","5","","15","IEEE","9 Jan 2023","","","IEEE","IEEE Magazines"
"A Cost-Quality Beneficial Cell Selection Approach for Sparse Mobile Crowdsensing With Diverse Sensing Costs","Z. Zhu; B. Chen; W. Liu; Y. Zhao; Z. Liu; Z. Zhao","College of Systems Engineering, National University of Defense Technology, Changsha, China; College of Systems Engineering, National University of Defense Technology, Changsha, China; College of Computer Science and Technology, Jilin University, Changchun, China; College of Systems Engineering, National University of Defense Technology, Changsha, China; College of Systems Engineering, National University of Defense Technology, Changsha, China; Research Group of Multi-Scale Networked Systems, University of Amsterdam, Amsterdam, The Netherlands","IEEE Internet of Things Journal","18 Feb 2021","2021","8","5","3831","3850","The Internet of Things (IoT) and mobile techniques enable real-time sensing for urban computing systems. By recruiting only a small number of users to sense data from selected subareas (namely, cells), sparse mobile crowdsensing (MCS) emerges as an effective paradigm to reduce sensing costs for monitoring the overall status of a large-scale area. The current sparse MCS solutions reduce the sensing subareas (by selecting the most informative cells) based on the assumption that each sample has the same cost, which is not always realistic in the real world, as the cost of sensing in a subarea can be diverse due to many factors, e.g., the condition of the device, location, and routing distance. To address this issue, we proposed a new cell selection approach consisting of three steps (information modeling, cost estimation, and cost-quality beneficial cell selection) to further reduce the total costs and improve the task quality. Specifically, we discussed the properties of the optimization goals and modeled the cell selection problem as a solvable biobjective optimization problem under certain assumptions and approximations. Then, we presented two selection strategies, i.e., the Pareto optimization selection (POS) and generalized cost-benefit greedy (GCB-GREEDY) selection along with our proposed cell selection algorithm. Finally, the superiority of our cell selection approach is assessed through four real-life urban monitoring data sets (Parking, Flow, Traffic, and Humidity) and three cost maps (independent identically distributed with dynamic cost map, monotonic with dynamic cost map, and spatial-correlated cost map). Results show that our proposed selection strategies POS and GCB-GREEDY can save up to 15.2% and 15.02% sample costs and reduce the inference errors to a maximum of 16.8% (15.5%) compared to the baseline-query by committee (QBC) in a sensing cycle. The findings show important implications in sparse MCS for urban context properties.","2327-4662","","10.1109/JIOT.2020.3024833","National Natural Science Foundation of China(grant numbers:71673292,21808181,61673388,71673294); National Social Science Foundation of China(grant numbers:17CGL047); EU Horizon 2020 Research and Innovation Program(grant numbers:825134 (ARTICONF),824068 (ENVRI-FAIR),862409 (BLUEClOUD)); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9201506","Biobjective optimization;cost inconstancy;cost-quality beneficial cell selection;sparse mobile crowdsensing (MCS)","Sensors;Task analysis;Internet of Things;Optimization;Monitoring;Estimation;Measurement","","20","","52","IEEE","21 Sep 2020","","","IEEE","IEEE Journals"
"Enhancing the Reliability of IoT Data Marketplaces through Security Validation of IoT Devices","Y. Na; Y. Joo; H. Lee; X. Zhao; K. K. Sajan; G. Ramachandran; B. Krishnamachari","Department of Computer Science and Engineering, Korea University, Seoul, South Korea; Department of Computer Science and Engineering, Korea University, Seoul, South Korea; Department of Computer Science and Engineering, Korea University, Seoul, South Korea; Viterbi School of Engineering, University of Southern California, Los Angeles, USA; Viterbi School of Engineering, University of Southern California, Los Angeles, USA; Viterbi School of Engineering, University of Southern California, Los Angeles, USA; Viterbi School of Engineering, University of Southern California, Los Angeles, USA","2020 16th International Conference on Distributed Computing in Sensor Systems (DCOSS)","1 Sep 2020","2020","","","265","272","IoT data marketplaces are being developed to help cities and communities create large scale IoT applications. Such data marketplaces let the IoT device owners sell their data to the application developers. Following this application development model, the application developers need not deploy their own IoT devices when developing IoT applications; instead, they can buy data from a data marketplace. In a marketplace-based IoT application, the application developers are making critical business and operation decisions using the data produced by seller's IoT devices. Under these circumstances, it is crucial to verify and validate the security of IoT devices.In this paper, we assess the security of IoT data marketplaces. In particular, we discuss what kind of vulnerabilities exist in IoT data marketplaces using the well-known STRIDE model, and present a security assessment and certification framework for IoT data marketplaces to help the device owners to examine the security vulnerabilities of their devices. Most importantly, our solution certifies the IoT devices when they connect to the data marketplace, which helps the application developers to make an informed decision when buying and consuming data from a data marketplace. To demonstrate the effectiveness of the proposed approach, we have developed a proof-of-concept using I3 (Intelligent IoT Integrator), which is an open-source IoT data marketplace developed at the University of Southern California, and IoTcube, which is a vulnerability detection toolkit developed by researchers at Korea University. Through this work, we show that it is possible to increase the reliability of a IoT data marketplace while not damaging the convenience of the users.","2325-2944","978-1-7281-4351-4","10.1109/DCOSS49796.2020.00050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9183447","IoT;security;data marketplace","Security;Data models;Middleware;Cloning;Open source software;Reliability","","2","","16","IEEE","1 Sep 2020","","","IEEE","IEEE Conferences"
"Cyber Threat Intelligence for Proactive Defense against Adversary in SDN-assisted IIoTs context","N. H. Khoa; D. M. Trung; B. C. N. Khoa; T. T. M. Au; V. -G. Ung; P. T. Duy; V. -H. Pham","Information Security Laboratory, University of Information Technology, Hochiminh City, Vietnam; Information Security Laboratory, University of Information Technology, Hochiminh City, Vietnam; Information Security Laboratory, University of Information Technology, Hochiminh City, Vietnam; Information Security Laboratory, University of Information Technology, Hochiminh City, Vietnam; Eastern International University, Binh Duong Province, Vietnam; Information Security Laboratory, University of Information Technology, Hochiminh City, Vietnam; Information Security Laboratory, University of Information Technology, Hochiminh City, Vietnam","2022 RIVF International Conference on Computing and Communication Technologies (RIVF)","18 Jan 2023","2022","","","1","6","In large-scale networks like the Industrial Internet of Things (IIoT), it is more important to monitor and enforce the security policy within an appropriate time due to the continuous widespread of cyberattacks. This is a tough challenge in traditional network architecture; thus, each network element's network management is unsuitable for a dynamic network with diverse types of devices in IIoT. In this context, Software-Defined Networking (SDN) is considered as enabling technology for flexible network management through programmability from a centralized controller. This work performs an experimental study on applying Cyber Threat Intelligence (CTI) to consecutively update the signatures of malicious actors from threat-hunting organizations to prepare the network defense strategy for IIoT networks. Such intelligence of network defenders from CTI is used as indicators to uncover the presence of malicious actors in the network. They are promptly transformed to security flow rules by the OpenFlow application through the SDN controller. The experimental results on the SDN environment show that this approach can help automatically generate and enforce security policy to protect the large-scale network against adversaries efficiently.","2162-786X","978-1-6654-6166-5","10.1109/RIVF55975.2022.10013811","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10013811","cyber threat intelligence;CTI;proactive defense;SDN;OpenFlow","Performance evaluation;Soft sensors;Prototypes;Organizations;Network architecture;Cyber threat intelligence;Security","","","","27","IEEE","18 Jan 2023","","","IEEE","IEEE Conferences"
"HyperChannel: A Secure Layer-2 Payment Network for Large-Scale IoT Ecosystem","Q. Wang; C. Zhang; L. Wei; Y. Xie","School of Cyber Science and Technology, University of Science and Technology of China, Hefei, P. R. China; School of Cyber Science and Technology, University of Science and Technology of China, Hefei, P. R. China; China Nanhu Academy of Electronics and Information Techology, Jiaxing, P. R. China; School of Cyber Science and Technology, University of Science and Technology of China, Hefei, P. R. China","ICC 2021 - IEEE International Conference on Communications","6 Aug 2021","2021","","","1","6","For the future large-scale IoT ecosystem, the number and frequency of micro-payments will increase dramatically. However, the mainstream of cryptocurrencies such as Bitcoin and Ethereum fail to meet the need for a large-scale IoT ecosystem due to limit transaction throughput and high transaction fee. Although Layer-2 solutions such as Lightning Network (LN) increases the throughput of cryptocurrencies by allowing participants to conduct off-chain transactions, LN still suffers from two main limitations: participants need to access the Blockchain within a short bounded time, and a payment channel can only accommodate two participants. To overcome these limitations, we propose HyperChannel, a novel distributed layer-2 payment network designed specifically for the IoT ecosystem which outsources the transaction processing task safely to a group of Intel Software Guard Extensions (SGXs) run by for-profit selfish third parties. Clients such as IoT devices and IoT service providers who often trade with each other will be assigned to a channel to conduct high-frequency in-channel transactions while being allowed to conduct crosschannel transactions in a fee-saving fashion. Compared with existing SGX-based layer-2 payment framework, HyperChannel achieves maximum throughput, addresses both limitations of LN, and further lightens the burden of participants so that IoT devices can conduct layer-2 transactions without running an SGX by themselves.","1938-1883","978-1-7281-7122-7","10.1109/ICC42927.2021.9500288","Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9500288","IoT;layer-2 solution;payment network;Software Guard Extension","Fault tolerance;Ecosystems;Fault tolerant systems;Lightning;Throughput;Software;Hardware","","2","","12","IEEE","6 Aug 2021","","","IEEE","IEEE Conferences"
"Web-Based Monitoring and Control of A Lab-Scaled Water Distribution System","J. Y. Low; M. S. B. A. Manaf; S. Sahlan; S. W. Nawawi; K. I. Rosli","School of Electrical Engineering, Faculty of Engineering, Universiti Teknologi Malaysia, Skudai, Johor, Malaysia; School of Electrical Engineering, Faculty of Engineering, Universiti Teknologi Malaysia, Skudai, Johor, Malaysia; School of Electrical Engineering, Faculty of Engineering, Universiti Teknologi Malaysia, Skudai, Johor, Malaysia; School of Electrical Engineering, Faculty of Engineering, Universiti Teknologi Malaysia, Skudai, Johor, Malaysia; ZEC Engineering Sdn. Bhd. No 23B, Jalan Sagu 33, Taman Daya, Johor Bahru, Johor, Malaysia","2022 IEEE 8th International Conference on Smart Instrumentation, Measurement and Applications (ICSIMA)","28 Oct 2022","2022","","","293","297","In Malaysia, Programmable Logic Controller (PLC) has been widely used in process industries, particularly for process system automation. To increase the efficiency of the process, implementation of Supervisory Control and Data Acquisition (SCADA) system is favorable. However, in Malaysia, for some small medium (SME) industries, SCADA has been considered as pricey and an uneconomical option. Therefore, in this paper, an open source and low-cost SCADA system design is developed and implemented on a lab-scaled water distribution system (WDS). The proposed system involved manipulating two flow rate sensors to achieve desirable water level of the reservoir tank, hence the water volume, controlled by OMRON PLC CPIH. The ThingsBoard IoT server utilized for data remote monitoring and controlling purposes, is in a local computer and the Hypertext Transfer Protocol (HTTP) is implemented for data transfer over serial communication via Node-RED. Through the implementation of the proposed system, the lab scaled WDS is successfully monitored and controlled remotely through the web-based application.","2640-6535","978-1-6654-8800-6","10.1109/ICSIMA55652.2022.9928817","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9928817","PLC;SCADA;Automation;Open Source;IoT;Serial Communication;Node-RED;Remote Terminal Unit","Industries;Protocols;Programmable logic devices;SCADA systems;Process control;Reservoirs;Sensor systems","","","","20","IEEE","28 Oct 2022","","","IEEE","IEEE Conferences"
"Video Anomaly Detection using Pre-Trained Deep Convolutional Neural Nets and Context Mining","C. Wu; S. Shao; C. Tunc; S. Hariri","NSF Center for Cloud and Autonomic Computing, The University of Arizona, Tucson, Arizona; NSF Center for Cloud and Autonomic Computing, The University of Arizona, Tucson, Arizona; Department of Computer Science & Engineering, The University of North Texas, Denton, Texas; NSF Center for Cloud and Autonomic Computing, The University of Arizona, Tucson, Arizona","2020 IEEE/ACS 17th International Conference on Computer Systems and Applications (AICCSA)","13 Jan 2021","2020","","","1","8","Anomaly detection is critically important for intelligent surveillance systems to detect in a timely manner any malicious activities. Many video anomaly detection approaches using deep learning methods focus on a single camera video stream with a fixed scenario. These deep learning methods use large-scale training data with large complexity. As a solution, in this paper, we show how to use pre-trained convolutional neural net models to perform feature extraction and context mining, and then use denoising autoencoder with relatively low model complexity to provide efficient and accurate surveillance anomaly detection, which can be useful for the resource-constrained devices such as edge devices of the Internet of Things (IoT). Our anomaly detection model makes decisions based on the high-level features derived from the selected embedded computer vision models such as object classification and object detection. Additionally, we derive contextual properties from the high-level features to further improve the performance of our video anomaly detection method. We use two UCSD datasets to demonstrate that our approach with relatively low model complexity can achieve comparable performance compared to the state-of-the-art approaches.","2161-5330","978-1-7281-8577-4","10.1109/AICCSA50499.2020.9316538","Air Force Office of Scientific Research (AFOSR); National Science Foundation(grant numbers:NSF-1624668,NSF-1849113,DUE-1303362); National Institute of Standards and Technology (NIST)(grant numbers:70NANB18H263); Department of Energy; National Nuclear Security Administration(grant numbers:DE-NA0003946); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9316538","Security;video surveillance;anomaly video analysis;abnormal event detection;deep features;context mining","Feature extraction;Anomaly detection;Computational modeling;Task analysis;Streaming media;Semantics;Cameras","","17","","36","IEEE","13 Jan 2021","","","IEEE","IEEE Conferences"
"Optimally Supporting IoT with Cell-Free Massive MIMO","H. Yan; A. Ashikhmin; H. Yang","NYU Wireless, New York, US; Bell Labs, Nokia, New Jersey, US; Bell Labs, Nokia, New Jersey, US","GLOBECOM 2020 - 2020 IEEE Global Communications Conference","12 Feb 2021","2020","","","1","6","We study internet of things (IoT) systems supported by cell-free (CF) massive MIMO (mMIMO) with optimal linear channel estimation. For the uplink, we consider optimal linear MIMO receiver and obtain an uplink SINR approximation involving only large-scale fading coefficients using random matrix (RM) theory. Using this approximation we design several max-min power control algorithms that incorporate power and rate weighting coefficients to achieve a target rate with high energy efficiency. For the downlink, we consider maximum ratio (MR) beamforming. Instead of solving a complex quasi-concave problem for downlink power control, we employ a neural network (NN) technique to obtain comparable power control with around 30 times reduction in computation time. For large networks we proposed a different NN based power control algorithm. This algorithm is sub-optimal, but its big advantage is that it is scalable.","2576-6813","978-1-7281-8298-8","10.1109/GLOBECOM42002.2020.9348004","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9348004","IoT;Cell-free;Massive MIMO;Optimal","Power control;Artificial neural networks;Receivers;Approximation algorithms;Energy efficiency;Uplink;Signal to noise ratio","","4","","16","IEEE","12 Feb 2021","","","IEEE","IEEE Conferences"
"Cluster-Aided Collision Resolution Random Access in Distributed Massive MIMO Systems","Y. He; G. Ren","State Key Laboratory of Integrated Services Network, Xidian University, Xi’an, China; State Key Laboratory of Integrated Services Network, Xidian University, Xi’an, China","IEEE Internet of Things Journal","17 Jun 2022","2022","9","13","11453","11463","Massive machine-type communication (MTC) is expected to be one of the key concerns in future B5G and 6G. However, the explosive growth of MTC devices (MTDs) in Internet of Things (IoT) poses great challenges for the initial access procedure. To address this issue, we propose a cluster-aided collision resolution random access (CACRRA) protocol for grant-based random access (RA) in the distributed massive multiple input multiple output (mMIMO) systems, which takes full advantage of the spatial multiplexing provided by distributed mMIMO. By exploiting the difference of large-scale fading coefficients between different access points (APs) and MTDs, we further propose an exclusive clustering algorithm to cluster APs for each pilot. Moreover, the pilot collision resolution is performed distributedly in each cluster by leveraging the channel hardening and the favorable propagation of mMIMO channels, which achieves a large reuse factor of pilots. Simulation results show that the proposed CACRRA can efficiently resolve the pilot collision and significantly improve the access performance. Specifically, the proposed protocol can improve the RA throughput more than nine times compared to the conventional protocol in incredibly crowded scenarios.","2327-4662","","10.1109/JIOT.2021.3127936","National Natural Science Foundation of China(grant numbers:91538105,61801352); China Postdoctoral Science Foundation(grant numbers:2016M590924); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9614337","Clustering;collision resolution;distributed massive MIMO;machine-type communication (MTC);random access (RA)","Protocols;Internet of Things;Space division multiplexing;Fading channels;Uplink;Spatial resolution;Throughput","","3","","26","IEEE","15 Nov 2021","","","IEEE","IEEE Journals"
"An Unsupervised Learning Paradigm for User Scheduling in Large Scale Multi-Antenna Systems","C. Feres; Z. Ding","Department of Electrical and Computer Engineering, University of California, Davis, Davis, CA, USA; Department of Electrical and Computer Engineering, University of California, Davis, Davis, CA, USA","IEEE Transactions on Wireless Communications","9 May 2023","2023","22","5","2932","2945","The tremendous growth of mobile networking and Internet of Things (IoT) demands efficient and reliable service for massive wireless systems. Multi-input-multi-output (MIMO) technologies successfully utilize spatial diversity to substantially improve spectral efficiency by scheduling multiple devices for simultaneous spectrum access. Efficient solutions to the NP-hard problem of scheduling large number of users are vital to interference mitigation and spectrum efficiency. Despite successes of machine learning in tackling large-scale optimization problems, direct adoption of supervised learning in MIMO user scheduling is difficult as there is no optimum solution to use as labeled training data, and unsupervised learning would identify similar user channel features instead of promoting channel diversity. In this work, we propose an effective and scalable user scheduling paradigm based on unsupervised learning to enhance spatial diversity in both uplink and downlink. Given users’ channel state information (CSI), we first cluster CSIs over the Grassmannian manifold to identify users with high CSI similarity, before scheduling them into MIMO access groups with low co- channel interference. Our paradigm is generalizable to a variety of different simple and scalable unsupervised learning tools and different diversity optimization criteria. Numerical tests demonstrate substantial gain in terms of spectrum efficiency and interference suppression at modest computation complexity.","1558-2248","","10.1109/TWC.2022.3215471","National Science Foundation(grant numbers:2009001,2029027); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9930883","User scheduling;unsupervised learning;manifold clustering;MIMO systems;co-channel interference","MIMO communication;Interference;Scheduling;Unsupervised learning;Signal to noise ratio;Uplink;Spatial diversity","","1","","61","IEEE","26 Oct 2022","","","IEEE","IEEE Journals"
"Capacity Bounds and User Identification Costs in Rayleigh-Fading Many-Access Channel","J. Robin; E. Erkip","Dept. of Electrical and Computer Engineering, Tandon School of Engineering, New York University, Brooklyn, NY, USA; Dept. of Electrical and Computer Engineering, Tandon School of Engineering, New York University, Brooklyn, NY, USA","2021 IEEE International Symposium on Information Theory (ISIT)","1 Sep 2021","2021","","","2477","2482","Many-access channel (MnAC) model allows the number of users in the system and the number of active users to scale as a function of the blocklength and as such is suited for dynamic communication systems with massive number of users such as the Internet of Things. Existing MnAC models assume a priori knowledge of channel gains which is impractical since acquiring Channel State Information (CSI) for massive number of users can overwhelm the available radio resources. This paper incorporates Rayleigh fading effects to the MnAC model and derives an upper bound on the symmetric message-length capacity of the Rayleigh-fading Gaussian MnAC. Furthermore, a lower bound on the minimum number of channel uses for discovering the active users is established. In addition, the performance of Noisy-Combinatorial Orthogonal Matching Pursuit (N-COMP) based group testing (GT) is studied as a practical strategy for active device discovery. Simulations show that, for a given SNR, as the number of users increase, the required number of channel uses for N-COMP GT scales approximately the same way as the lower bound on minimum user identification cost. Moreover, in the low SNR regime, for sufficiently large population sizes, the number of channel uses required by N-COMP GT was observed to be within a factor of two of the lower bound when the expected number of active users scales sub-linearly with the total population size.","","978-1-5386-8209-8","10.1109/ISIT45174.2021.9517965","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9517965","Many-Access channel;Group testing;Active device discovery;multiple-access;Rayleigh-fading","Performance evaluation;Upper bound;Sociology;Matching pursuit algorithms;Rayleigh channels;Object recognition;Noise measurement","","7","","11","IEEE","1 Sep 2021","","","IEEE","IEEE Conferences"
"A Novel Data Collection Framework for Telemetry and Anomaly Detection in Industrial IoT Systems","F. De Vita; D. Bruneo; S. K. Das","Department of Engineering, University of Messina, Italy; Department of Engineering, University of Messina, Italy; Department of Computer Science, Missouri University of Science and Technology, Rolla, USA","2020 IEEE/ACM Fifth International Conference on Internet-of-Things Design and Implementation (IoTDI)","21 May 2020","2020","","","245","251","The advent of IoTs has catalyzed the development of a variety of cyber-physical systems in which hundreds of sensor-actuator enabled devices (including industrial IoTs) cooperatively interact with the physical and human worlds. However, due to the large volume and heterogeneity of data generated by such systems and the stringent time requirements of industrial applications, the design of efficient frameworks to store, monitor and analyze the IoT data is quite challenging. This paper proposes an industrial IoT architectural framework that allows data offloading between the cloud and the edge. Specifically, we use this framework for telemetry of a set of heterogeneous sensors attached to a scale replica of an industrial assembly plant. We also design an anomaly detection algorithm that exploits deep learning techniques to assess the working conditions of the plant. Experimental results show that the proposed anomaly detector is able to detect 99% of the anomalies occurred in the industrial system demonstrating the feasibility of our approach.","","978-1-7281-6602-5","10.1109/IoTDI49375.2020.00032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9097595","","Anomaly detection;Protocols;Data collection;Cloud computing;Temperature measurement;Monitoring;Artificial intelligence","","11","","21","IEEE","21 May 2020","","","IEEE","IEEE Conferences"
"Heterogeneous Control Platform Design for Power Conversion Systems","A. Rüetschi; P. Syrpas; B. Flak; K. Tomzik; P. K. Steimer","ABB Corporate Research, Baden-Dättwil, Switzerland; ABB System Drives, Turgi, Switzerland; ABB Technology Center, Krakow, Poland; ABB Technology Center, Krakow, Poland; Hitachi Power Grids Research, Baden-Dättwil, Switzerland","IEEE Transactions on Industrial Informatics","3 Feb 2022","2022","18","5","2934","2942","Digitally controlled switch-mode power conversion systems require an embedded computing platform to execute, in real-time (RT), closed-loop algorithms that regulate the power flow. Since legacy control software design is traditionally rooted to single-core processors, recent trends in power electronics toward faster switching devices and multilevel topologies will challenge their computational capacity and reliability to meet RT deadlines. With Internet-of-Things driving down the cost of a general-purpose system-on-chip (SoC), combining a multicore application processor and a field-gate programmable array (FPGA) on single device, this article introduces a codesign workflow and a runtime architecture for the heterogeneous deployment of multirate control algorithms. Code migration toward the FPGA exploits high-level synthesis, while a Linux-Xenomai dual-kernel operating system manages the synchronization and the parallel execution of the tasks. Following sections will describe and benchmark the selected key technologies and validate them on a small-scale grid-connected converter emulator.","1941-0050","","10.1109/TII.2021.3104285","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9512386","Control design;field programmable gate arrays;high-level synthesis (HLS);multicore processing;power conversion;real-time (RT) systems;runtime;software (SW) architecture","Task analysis;Field programmable gate arrays;Kernel;Delays;Switches;Synchronization;Program processors","","4","","64","IEEE","12 Aug 2021","","","IEEE","IEEE Journals"
"Cooperative Network Model for Joint Mobile Sink Scheduling and Dynamic Buffer Management Using Q-Learning","S. Redhu; R. M. Hegde","Department of Electrical Engineering, Indian Institute of Technology Kanpur, Kanpur, India; Department of Electrical Engineering, Indian Institute of Technology Kanpur, Kanpur, India","IEEE Transactions on Network and Service Management","8 Sep 2020","2020","17","3","1853","1864","Development of energy-efficient wireless sensor networks is crucial in the deployment of IoT and IIoT for modern day applications like smart home, smart vehicles, and smart industries. Several methods like network clustering, mobile sink deployment and dynamic sensing rate have been used in improving the energy-efficiency of wireless sensor networks in IoT framework. However, these methods have been developed independently which can lead to certain network issues like reduced lifetime, network breakdown among others. In this work, an energy-efficient method that optimizes mobile sink scheduling while concurrently providing dynamic buffer management is proposed. A cooperative network model that incorporates node clustering and mobile sink deployment in variable node sensing rate scenario is first developed. However, in such cooperative network models, mobile sink scheduling and buffer overflow management which causes information loss become challenging. This is primarily due to limited buffer size, variable sensing rate of the nodes, and the unavailability of mobile sink at all times near a cluster. Therefore, a reinforcement Q-learning framework is developed for scheduling the mobile sink while minimizing the information loss caused by buffer overflow in each cluster of a clustered WSN. More specifically, the network behaviour is learnt in the context of buffer overflow using Q-learning approach. The proposed method computes the adaptive halt-times for the mobile sink based on information loss and buffer overflow in each cluster. Performance of the proposed joint mobile sink scheduling and dynamic buffer management method is evaluated on a medium scale WSN. A clustered wireless sensor network with a total of 600 sensor nodes is considered for performance evaluation. The proposed method is shown to learn the variable node sensing rate in a reasonable amount of time using convergence analysis. Numeric evaluations indicate that the proposed method minimizes the information loss in a medium scale wireless sensor network while improving the network lifetime simultaneously. The proposed cooperative network model also outperforms in terms of energy-efficiency when compared to conventional WSN. The results are motivating enough for the use of cooperative network model in practical WSNs for IoT applications.","1932-4537","","10.1109/TNSM.2020.3002828","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9119172","Clustering;mobile sink scheduling;variable sensing rate;buffer management;wireless sensor networks","Wireless sensor networks;Sensors;Cooperative systems;Protocols;Job shop scheduling;Dynamic scheduling","","21","","34","IEEE","16 Jun 2020","","","IEEE","IEEE Journals"
"Failure Detectors for 6LoWPAN: Model and Implementation","P. Raich; W. Kastner","Institute of Computer Engineering, TU Wien, Vienna, Austria; Institute of Computer Engineering, TU Wien, Vienna, Austria","2022 International Conference on Electrical, Computer and Energy Technologies (ICECET)","9 Sep 2022","2022","","","1","6","Consensus is a basic building block in distributed systems for a myriad of related problems that involve agreement. For asynchronous networks, consensus has been proven impossible, and is well known as Augean task. Failure Detectors (FDs) have since emerged as a possible remedy, able to solve consensus in asynchronous systems under certain assumptions. With the increasing use of asynchronous, wireless Internet of Things (IoT) technologies, such as IEEE 802.15.4/6LoWPAN, the demand of applications that require some form of reliability and agreement is on the rise. What was missing so far is an FD that can operate under the tight constraints offered by Low Power and Lossy Networks (LLNs) without compromising the efficiency of the network. We present 6LoFD, an FD specifically aimed at energy and memory efficient operation in small scale, unreliable networks, and evaluate its working principles by using an ns-3 implementation of 6LoFD.","","978-1-6654-7087-2","10.1109/ICECET55527.2022.9872784","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9872784","6LoWPAN;failure detector;agreement;reliability;LLN;IoT","Wireless communication;IEEE 802.15 Standard;Computer network reliability;Computational modeling;Memory management;Detectors;Internet of Things","","1","","16","IEEE","9 Sep 2022","","","IEEE","IEEE Conferences"
"An Optimization Approach of Container Startup Times for Time-Sensitive Embedded Systems","L. Stahlbock; J. Weber; F. Köster","IAV GmbH, Germany; IAV GmbH, Germany; German Aerospace Center (DLR), Germany","2022 IEEE 24th Int Conf on High Performance Computing & Communications; 8th Int Conf on Data Science & Systems; 20th Int Conf on Smart City; 8th Int Conf on Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys)","28 Mar 2023","2022","","","2019","2026","Containers are a lightweight virtualization method that is widely adopted in Cloud Environments, Internet of Things (IoT) and embedded devices. Apart from virtualization, containers provide an efficient way of building, storing and distributing layered filesystems for applications. This is one reason why containers became state of the art for service development, deployment and administration in IT systems. Although containers are lightweight, the image layering and container creation add overhead to the application startup time causing a cold start problem in serverless computing. Therefore, the overhead must be kept as small as possible, especially for resource-constrained devices in time-sensitive systems. We present a concept to decrease container startup times and perform analysis on a resource constrained device, a Renesas RCar H3. The study shows that using our concept, the average container startup time can be reduced by up to 64% on target hardware. Furthermore, we evaluate how the solution scales on different hardware setups and determine the impact of container configuration parameters on startup times.","","979-8-3503-1993-4","10.1109/HPCC-DSS-SmartCity-DependSys57074.2022.00300","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10074694","Embedded;Automotive;Container;Virtualization;IoT","Performance evaluation;Embedded systems;Buildings;Serverless computing;Containers;Hardware;Internet of Things","","","","32","IEEE","28 Mar 2023","","","IEEE","IEEE Conferences"
"A Blockchain-Enabled Framework for Enhancing Scalability and Security in IIoT","R. Li; Y. Qin; C. Wang; M. Li; X. Chu","College of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; College of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; Department of Computer Science, Hong Kong Baptist University, Hong Kong, SAR, China; College of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; Department of Computer Science, The Hong Kong University of Science and Technology, Guangzhou, China","IEEE Transactions on Industrial Informatics","24 May 2023","2023","19","6","7389","7400","Industrial Internet of Things (IIoT) technology is widely used in modern industrial fields like transportation, but data security remains a major challenge. The blockchain-based access control mechanism can address the data security issue by preventing unauthorized devices from accessing limited IIoT resources. However, most existing blockchain-based access control mechanism for IIoT still has scalability and privacy issues. To deal with the above-mentioned problems, we propose a new scalable and secure strategy for the blockchain-based access control framework for IIoT via sharding, which consists of two components. First, the network sharding scheme based on the access frequency set (N2SAF) is designed to 1) improve the scalability of our proposed strategy by transaction sharding to reduce the storage pressure on nodes, and 2) increase the transaction processing speed on a three-layer architecture based on cloud-edge-device in IIoT. Second, the privacy protection scheme based on a Bloom filter (P2BF) is designed to deal with the privacy leakage problem caused by anonymous address clustering. Simulation results show that our proposed strategy improves the scalability of the system compared to existing methods while ensuring the security of the shard network, especially in large-scale IIoT environments.","1941-0050","","10.1109/TII.2022.3210216","Shenzhen Fundamental Research Program(grant numbers:XMHT20190108009); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9904919","Blockchain;Industrial Internet of Things (IIoT);privacy protection;scalability;sharding","Blockchains;Industrial Internet of Things;Scalability;Costs;Privacy;Access control;Peer-to-peer computing","","4","","24","IEEE","28 Sep 2022","","","IEEE","IEEE Journals"
"Probe Delay Based Adaptive Port Scanning for IoT Devices with Private IP Address Behind NAT","F. Tang; Y. Kawamoto; N. Kato; K. Yano; Y. Suzuki","Tohoku University, Sendai, Japan; Tohoku University, Sendai, Japan; Tohoku University, Sendai, Japan; Telecommunications Research Institute International; Telecommunications Research Institute International","IEEE Network","2 Apr 2020","2020","34","2","195","201","Recently, the explosive increase in the number of IoT devices makes the IoT becomes extremely large-scaled, and the security of such a large scale IoT emerges as a big challenge. As a classic security technique, the port scan is widely used around the world. However, as IP resources are limited, a large number of devices are located in the LAN or WLAN behind the NAT which cannot be directly accessed by the port scanner. Furthermore, port scanning generated a tremendous number of probe and response packets which may cause heavy traffic load and frequent congestion. To conquer those problems, in this article, we first propose a reverse proxy based NAT penetration system for scanning ports behind NAT. Based on the NAT penetration system, we proposed a probe delay based adaptive scanning algorithm referred to as ProDASA, which adaptively changes port scanning frequency and scanning methods to balance the network performance and security requirements of the IoT. The experiment in a real environment demonstrates the feasibility of the proposed NAT penetration system and the computational simulation with multiple virtual devices shows the advantage of our proposed ProDASA in terms of both network performance and security by comparing with a conventional method.","1558-156X","","10.1109/MNET.001.1900264","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8869708","","IP networks;Probes;Delays;Security;Servers;Adaptive systems;Performance evaluation","","18","","15","IEEE","16 Oct 2019","","","IEEE","IEEE Magazines"
"Hybrid Workflow Scheduling on Edge Cloud Computing Systems","R. Alsurdeh; R. N. Calheiros; K. M. Matawie; B. Javadi","School of Computer, Data and Mathematical Sciences, Western Sydney University, Sydney, NSW, Australia; School of Computer, Data and Mathematical Sciences, Western Sydney University, Sydney, NSW, Australia; School of Computer, Data and Mathematical Sciences, Western Sydney University, Sydney, NSW, Australia; School of Computer, Data and Mathematical Sciences, Western Sydney University, Sydney, NSW, Australia","IEEE Access","6 Oct 2021","2021","9","","134783","134799","Internet of Things applications can be represented as workflows in which stream and batch processing are combined to accomplish data analytics objectives in many application domains such as smart home, health care, bioinformatics, astronomy, and education. The main challenge of this combination is the differentiation of service quality constraints between batch and stream computations. Stream processing is highly latency-sensitive while batch processing is more likely resource-intensive. In this work, we propose an end-to-end hybrid workflow scheduling on an edge cloud system as a two-stage framework. In the first stage, we propose a resource estimation algorithm based on a linear optimization approach, gradient descent search (GDS), and in the second stage, we propose a cluster-based provisioning and scheduling technique for hybrid workflows on heterogeneous edge cloud resources. We provide a multi-objective optimization model for execution time and monetary cost under constraints of deadline and throughput. Results demonstrate the framework performance in controlling the execution of hybrid workflows by efficiently tuning several parameters including stream arrival rate, processing throughput, and workflow complexity. In comparison to a meta-heuristics technique using Particle Swarm Optimization (PSO), the proposed scheduler provides significant improvement for large-scale hybrid workflows in terms of execution time and cost with an average of 8% and 35%, respectively.","2169-3536","","10.1109/ACCESS.2021.3116716","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552915","Hybrid workflow scheduling;streaming scheduling;gradient search optimization;resource estimation and provisioning","Task analysis;Cloud computing;Costs;Computational modeling;Data models;Resource management;Real-time systems","","11","","62","CCBY","29 Sep 2021","","","IEEE","IEEE Journals"
"Resource Cube: Multi-Virtual Resource Management for Integrated Satellite-Terrestrial Industrial IoT Networks","D. Chen; C. Yang; P. Gong; L. Chang; J. Shao; Q. Ni; A. Anpalagan; M. Guizani","State Key Laboratory on Integrated Services Networks, Xidian University, Xi’an, China; State Key Laboratory on Integrated Services Networks, Xidian University, Xi’an, China; Beijing Institute of Technology, Beijing, China; State Key Laboratory on Integrated Services Networks, Xidian University, Xi’an, China; State Key Laboratory on Integrated Services Networks, Xidian University, Xi’an, China; School of Computing and Communications, Lancaster University, Lancaster, U.K.; Department of Electrical and Computer Engineering, Ryerson University, Toronto, ON, Canada; Department Electrical and Computer Engineering, University of Idaho, Moscow, ID, USA","IEEE Transactions on Vehicular Technology","26 Oct 2020","2020","69","10","11963","11974","Industrial Internet of Things (IIoT) has found wider research, and satellite-terrestrial network (STN) can provide large-scale seamless connections for IIoT. With virtualization, we design resource cube to describe the integration and state of multi-dimensional virtual resources. To achieve higher resource utilization and smarter connections, we design a matching considered preferences (MCPR) algorithm to match IIoT nodes with service sides. The matching design considers the resource cube (MCRC) algorithm based on MCPR algorithm to lower the total system delay. In addition, in order to simplify the analysis of resource management, we adopt a layered architecture and multiple M/M/1 queuing models. We analyze the resource utilization and the total system delay for three different combinations of arrival rate and service rate of each resource cube. With MCRC algorithm, the utilization of resources is slightly reduced, while the total system delay is greatly reduced compared with MCPR algorithm.","1939-9359","","10.1109/TVT.2020.3007263","National Natural Science Foundation of China(grant numbers:61871454); Open Research fund of National Mobile Communications Research Laboratory, Southeast University(grant numbers:2019D10); Fundamental Research Funds for the Central Universities(grant numbers:JB190119); National Key Research and Development Program of China(grant numbers:2018YFC0823003); National Natural Science Foundation of China(grant numbers:61671062); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9133514","Internet of Things;multi-virtual resource management;satellite-terrestrial network;virtualization","Satellites;Resource management;Delays;Computer architecture;Markov processes;Low earth orbit satellites","","15","","35","IEEE","6 Jul 2020","","","IEEE","IEEE Journals"
"A Blockchain-Based Software Always-On System","H. -C. Jang; Y. -T. Chen","Dept. of Computer Science, National Chengchi University, Taipei, Taiwan, R.O.C.; Dept. of Computer Science, National Chengchi University, Taipei, Taiwan, R.O.C.","2021 IEEE 12th Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON)","6 Dec 2021","2021","","","0252","0257","Moving towards Industry 5.0, the Industrial Internet of Things (IIoT) has become an indispensable role. IIoT devices could help manufacturing companies to observe various production statuses hence improving production efficiency. However, its limitation on resources and features makes robust security implementation a big challenge. Implementing a secure, general and scalable system to adopt across industries is one of the most critical topics for IIoT. This paper proposed a blockchain-based system architecture to auto-update, monitor, and fix the IIoT devices' software. We take the software status snapshots and store them as a blockchain ledger to protect the software's integrity and the software from unauthorized modification. To achieve auto-update and auto fix, we also simulate the concept of a blockchain contract to create the ledger whenever there are changes. As a result, the changes could continuously be tracked. The performance and scalability are also evaluated. The result shows that the system could also be deployed in larger-scale IIoT devices. The software update and fix could be guaranteed authenticated, and the unauthorized software could be monitored and detected.","2644-3163","978-1-6654-0066-4","10.1109/IEMCON53756.2021.9623179","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623179","Blockchain;IIoT;Byzantine agreement;software monitor;software update","Industries;Performance evaluation;Scalability;Systems architecture;Production;Software;Blockchains","","","","9","IEEE","6 Dec 2021","","","IEEE","IEEE Conferences"
"Integrating DOTS With Blockchain Can Secure Massive IoT Sensors","S. Badruddoja; R. Dantu; L. Widick; Z. Zaccagni; K. Upadhyay","Department of Computer Science and Engineering, University of North Texas, Denton, TX, USA; Department of Computer Science and Engineering, University of North Texas, Denton, TX, USA; Department of Computer Science and Engineering, University of North Texas, Denton, TX, USA; Department of Computer Science and Engineering, University of North Texas, Denton, TX, USA; Department of Computer Science and Engineering, University of North Texas, Denton, TX, USA","2020 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)","28 Jul 2020","2020","","","937","946","This paper presents a novel approach to securing IoT devices by leveraging DDoS Open Threat Signaling (DOTS) architecture on a Blockchain framework. Like many areas of the information technology domain, IoT sensors are also prone to attacks but on a larger scale. There are millions of devices being connected to a central domain to provide different types of services. Since these low-powered IoT devices have constrained technical requirements with less computational capabilities, they lack the capacity to judge their behavior as benign or malignant. IoT relies heavily on the higher level of intelligent nodes to decide on their status. An IoT Controller/Edge server handles the registration and the limited management of devices. Since traditional security is unable to protect the IoT environment sufficiently, we present a Blockchain-based DDoS detection approach to secure and mitigate such attacks in the IoT environment. Our test setup includes dataset from four sensors over two months. These values were tested using a threshold calculation against the variation of temperature, humidity, pressure, and wind direction on that day to find out whether an IoT sensor is under a DDoS attack. Our results show how DOTS can help in detection of attack when mapped on IoT edge computing.","","978-1-7281-7445-7","10.1109/IPDPSW50202.2020.00156","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9150345","Cybersecurity;Blockchain;IoT;Edge Computing;Distributed Ledger;DDOS Protection;Smart Contracts","US Department of Transportation;Servers;Computer crime;Computer architecture;Sensors","","8","","29","IEEE","28 Jul 2020","","","IEEE","IEEE Conferences"
"Radio Channel Measurements and Characterization in Substation Scenarios for Power Grid Internet of Things","T. Zhou; Y. Lin; Z. Yang; B. Ai; L. Liu","Institute of Broadband Wireless Mobile Communications, Beijing Jiaotong University, Beijing, China; Institute of Broadband Wireless Mobile Communications, Beijing Jiaotong University, Beijing, China; High Voltage Department, China Electric Power Research Institute, Beijing, China; State Key Laboratory of Rail Traffic Control and Safety and the Frontiers Science Center for Smart High-Speed Railway System, Beijing Jiaotong University, Beijing, China; Institute of Broadband Wireless Mobile Communications, Beijing Jiaotong University, Beijing, China","IEEE Internet of Things Journal","21 Apr 2023","2023","10","9","7691","7704","Wireless communication technologies play a key role to support the implementation of Power grid Internet of Things (PIoT). An in-depth knowledge of the radio channel is vital to the application of wireless communication technologies in PIoT. This article investigates the radio channel measurements and characterization for PIoT substation scenarios. A novel channel sounder is designed for achieving omnidirectional measurements and phased array antennas-based directional measurements, and a directional multipath components extraction algorithm is proposed. The channel sounding system is verified and is used to perform a series of 3.35-GHz omnidirectional and directional channel measurements in four substation scenarios, involving a 10-kV switch room, a 110-kV GIS room, a semi-indoor 110-kV substation, and an outdoor 220-kV substation. Based on the measured channel impulse response data, both large-scale and small-scale fading characteristics of substation channels are extracted and analyzed. Empirical models of path loss, shadow fading, Rician  $K$ -factor and root-mean-square (RMS) delay spread are proposed. In addition, results of RMS angle spread (AS) of departure and RMS AS of arrival are presented. These results will provide useful reference for the deployment and optimization of wireless communication networks in PIoT substation scenarios.","2327-4662","","10.1109/JIOT.2022.3195512","National Key Research and Development Program of China(grant numbers:2020YFB1804901); National Natural Science Foundation of China(grant numbers:62071031); Beijing Natural Science Foundation(grant numbers:4212006,L212030); Open Research Fund through the National Mobile Communications Research Laboratory, Southeast University(grant numbers:2021D01); Science and Technology Project of State Grid Corporation of China (Research on Reliability Technologies for Transformer Substation Wireless Networks in Complex Electromagnetic Environments)(grant numbers:5500-202055070A-0-0-00); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9847227","Channel characterization;channel measurements;Power grid Internet of Things (PIoT);radio channels;substations","Substations;Antenna measurements;Frequency measurement;Fading channels;Phased arrays;Directive antennas;Transmitting antennas","","2","","35","IEEE","2 Aug 2022","","","IEEE","IEEE Journals"
"Learning the ODS by means of an IEQ monitoring IoT system in campus","I. Calvo; A. Armentia; J. M. Gil-García; E. Apiñaniz; O. Barambones","Escuela de Ingeniería de Vitoria-Gasteiz, Universidad del País Vasco (UPV/EHU), Vitoria-Gasteiz, Spain; Escuela de Ingeniería de Vitoria-Gasteiz, Universidad del País Vasco (UPV/EHU), Vitoria-Gasteiz, Spain; Escuela de Ingeniería de Vitoria-Gasteiz, Universidad del País Vasco (UPV/EHU), Vitoria-Gasteiz, Spain; Escuela de Ingeniería de Vitoria-Gasteiz, Universidad del País Vasco (UPV/EHU), Vitoria-Gasteiz, Spain; Escuela de Ingeniería de Vitoria-Gasteiz, Universidad del País Vasco (UPV/EHU), Vitoria-Gasteiz, Spain","2023 18th Iberian Conference on Information Systems and Technologies (CISTI)","15 Aug 2023","2023","","","1","6","The efficient management of the energy resources is a subject that, currently, is acquiring increasing relevance. In fact, it has a big impact in some of the major Sustainable Development Goals (SDG). Also, the new concepts introduced with the Industry 4.0 paradigm are being implemented successfully in other domains than manufacturing applications. One example may be found in architecture and construction. This article presents an IoT system aimed at monitoring the Indoors Environment Quality (IEQ) conditions in buildings. Typical technologies used at the Industry 4.0 have been used: Smart Sensors, wireless communications and monitoring and analysis tools. This IoT system was specifically designed to be implemented by engineering students following the Project Based Learning (PBL) methodology as part of the curriculum of an Industrial Informatics course (6 ECTS). Despite being a small scale system, it may be used to (1) monitor the IEQ parameters of one building; (2) learn to manage the tools frequently used in current Industry 4.0 applications; (3) make students aware about the need of doing an adequate use of the resources; and (4) illustrate how to apply the concepts learnt in the classroom to solve real problems.","2166-0727","978-989-33-4792-8","10.23919/CISTI58278.2023.10211505","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10211505","SDG;IEQ monitoring;IoT;Smart Sensors;MQTT;PBL;Arduino","Wireless communication;Energy resources;Buildings;Fourth Industrial Revolution;Indoor environment;Sustainable development;Informatics","","","","0","","15 Aug 2023","","","IEEE","IEEE Conferences"
"Nonlinear MIMO for Industrial Internet of Things in Cyber–Physical Systems","Y. Gong; L. Zhang; R. Liu; K. Yu; G. Srivastava","School of Information and Communication Engineering, Beijing University of Posts and Communications (BUPT), Beijing, China; School of Information and Communication Engineering, Beijing Information Science and Technology University (BISTU), Beijing, China; University of Technology Sydney (UTS), Global Big Data Technologies Center (GBDTC), Sydney, NSW, Australia; Global Information and Telecommunication Institute, Waseda University, Tokyo, Japan; Department of Math and Computer Science, Brandon University, Brandon, MB, Canada","IEEE Transactions on Industrial Informatics","4 May 2021","2021","17","8","5533","5541","Massive multiple-input multiple-output (MIMO) wireless communication technology with the characteristics of hyperconnectivity is an ideal channel to connect the industrial Internet of Things (IIoT) and the cyber-physical system. It provides stable and reliable connectivity from the data center to distributed user terminals and the IIoT. However, traditional massive MIMO suffers from high power consumption and fabrication cost. The design of energy-efficient massive MIMO technology is essential for larger scale industrial deployments. In this article, we design three types of nonlinear RF chain structures, which not only reduce the power consumption of massive MIMO systems but also save fabrication costs. Information theoretic analysis demonstrates the power efficiency performance of our nonlinear system design. Our nonlinear MIMO system designs can increase the power efficiency by up to 2.3 times compared with the traditional MIMO system. We have demonstrated that our systems can achieve the same uplink rate as traditional MIMO by increasing the number of receiving antennas but with less overall power consumption. We also proposed an algorithm to overcome the problem of low computational efficiency due to high-dimensional integration when calculating the uplink achievable rate of nonlinear MIMO. Moreover, we reveal that when the skew-normal distribution is used as signaling, the nonlinear MIMO systems can achieve better performance than the Gaussian distribution.","1941-0050","","10.1109/TII.2020.3024631","CERNET Innovation Project(grant numbers:NGIICS20190301); Construction of System-level Connected Vehicle Test and Verification Platform(grant numbers:2019-00892-2-1); University of Technology Sydney; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9200720","Cyber–physical systems;information theory;Internet of Things (IoT);low power consumption;nonlinear mimo systems;uplink achievable rate","Radio frequency;MIMO communication;Power demand;Detectors;Analog-digital conversion;Informatics;Antennas","","62","","31","IEEE","18 Sep 2020","","","IEEE","IEEE Journals"
"Machine-Learning-Based UAV-Assisted Agricultural Information Security Architecture and Intrusion Detection","R. Fu; X. Ren; Y. Li; Y. Wu; H. Sun; M. A. Al-Absi","Shandong Provincial University Laboratory for Protected Horticulture, Blockchain Laboratory of Agricultural Vegetables, Weifang University of Science and Technology, Weifang, China; Shandong Provincial University Laboratory for Protected Horticulture, Blockchain Laboratory of Agricultural Vegetables, Weifang University of Science and Technology, Weifang, China; Shandong Provincial University Laboratory for Protected Horticulture, Blockchain Laboratory of Agricultural Vegetables, Weifang University of Science and Technology, Weifang, China; Shandong Provincial University Laboratory for Protected Horticulture, Blockchain Laboratory of Agricultural Vegetables, Weifang University of Science and Technology, Weifang, China; Shandong Provincial University Laboratory for Protected Horticulture, Blockchain Laboratory of Agricultural Vegetables, Weifang University of Science and Technology, Weifang, China; Department of Computer Engineering, Graduate School, Dongseo University, Busan, South Korea","IEEE Internet of Things Journal","19 Oct 2023","2023","10","21","18589","18598","In recent years, unmanned aerial vehicle (UAV) remote sensing has developed rapidly in the field of farmland information monitoring. Real-time and accurate access to farmland information and crop growth dynamics is a prerequisite for the implementation of precision agriculture. Machine learning identifies existing knowledge to acquire new knowledge, promotes the development of Artificial Intelligence, and brings a large number of data training sets for machine learning. This article aims to ensure the safe operation of agricultural information systems and guarantee the data security of intelligent agriculture. The machine learning method explores the wireless network deployment of the UAV system. The geographical location deployment of agricultural information security can effectively carry out rapid security detection of agricultural information security. First, the UAV-assisted information acquisition system was studied. Besides, a double deep  $Q$ -network (DDQN) algorithm for location deployment based on geography position information (GPI) was proposed to quickly optimize the deployment location of UAVs. GPI can avoid the complicated calculation process of channel state information. The DDQN algorithm was introduced to obtain the functional relationship between the GPI and the optimal UAV deployment position, forming a new GPI-Learning strategy. In addition, the convolutional neural network (CNN) and long short-term memory (LSTM) are integrated as the CNN–LSTM algorithm to build the intrusion detection system for Agricultural Internet of Things (AIoT) for agriculture. In the integrated network structure of the system, LSTM is responsible for data transmission, and CNN is capable of network model building. Combined with the influence of various parameters on the performance of the UAV deployment location algorithm, the simulation experiment set the population size as 36, the discovery probability as 0.25, the step scaling factor as 0.8, and the Levy flight index as 1.25. The network throughput performance of the GPI-Learning algorithm combined with cuckoo search was better than other algorithms under different numbers of UAVs. On the KDD-CUP99 data set, the accuracy and detection rate of the AIoT intrusion detection system based on the CNN+LSTM algorithm reached 93.5% and 94.4%, respectively. In general, the AIoT intrusion detection system reported here has crucial practical reference value for the safe operation of agricultural information systems.","2327-4662","","10.1109/JIOT.2023.3236322","Weifang University of Science and Technology Doctoral Fund Project(grant numbers:2021KJBS13); Weifang Soft Science Research Program(grant numbers:2022RKX108); Weifang University of Science and Technology Doctoral Fund Project(grant numbers:2021RWBS07); Industry–University Cooperation and Collaborative Education Project of the Ministry of Education(grant numbers:220505265095631); Natural Science Foundation of Shandong Province(grant numbers:ZR2021MF086); Soft Science Project, Shandong Province Key R&D Plan(grant numbers:2021RKY02027); Discipline Construction Project of Weifang University of Science and Technology(grant numbers:2021XKJS09); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10032258","Agricultural information security;convolutional neural network (CNN);geographic position information (GPI);intrusion detection;machine learning;unmanned aerial vehicles (UAVs)","Autonomous aerial vehicles;Monitoring;Machine learning algorithms;Intrusion detection;Internet of Things;Sensors;Machine learning","","8","","44","IEEE","30 Jan 2023","","","IEEE","IEEE Journals"
"Micro-Cantilever Capacitive Sensor for High-Resolution Measurement of Electric Fields","Z. Han; F. Xue; G. Yang; Z. Yu; J. Hu; J. He","Department of Electrical Engineering, State Key Lab of Power Systems, Tsinghua University, Beijing, China; Department of Electrical Engineering, State Key Lab of Power Systems, Tsinghua University, Beijing, China; Department of Electrical Engineering, State Key Lab of Power Systems, Tsinghua University, Beijing, China; Department of Electrical Engineering, State Key Lab of Power Systems, Tsinghua University, Beijing, China; Department of Electrical Engineering, State Key Lab of Power Systems, Tsinghua University, Beijing, China; Department of Electrical Engineering, State Key Lab of Power Systems, Tsinghua University, Beijing, China","IEEE Sensors Journal","18 Jan 2021","2021","21","4","4317","4324","Electric-field (EF) microsensors with high resolution are crucial for the realization of real-time dynamic status monitoring of Ubiquitous Power Internet of Things (UPIoT), which is of great significance for the safe operation of power system and early-stage diagnostics of power equipment. Distortion-free and high-resolution measurement of electric fields is also important in applications such as meteorological monitoring and aerospace launch. Existing electric-field measurement methods are always costly, bulky, and low in resolution. We presented a capacitive EF sensor with small size and high resolution. The presented sensor is based on piezoelectric effect, and a micro cantilever structure is realized using microfabrication. Simulation and experimental results indicate that the presented sensor has a resolution of about 45 V/m and a measurable magnitude of over 1.5 MV/m. Owing to the characteristics of small size, low cost and low power consumption, the EF sensor is suitable for applications of large-scale sensing arrays.","1558-1748","","10.1109/JSEN.2020.3031291","National Natural Science Foundation of China(grant numbers:51720105004,51921005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9224801","Capacitive sensors;electric sensing devices;microfabrication;piezoelectric effect","Electric fields;Mechanical sensors;Capacitance;Silicon;Electric variables measurement;Optical sensors","","17","","30","IEEE","15 Oct 2020","","","IEEE","IEEE Journals"
"An Unsupervised Deep Learning Model for Early Network Traffic Anomaly Detection","R. -H. Hwang; M. -C. Peng; C. -W. Huang; P. -C. Lin; V. -L. Nguyen","Department of Computer Science and Information Engineering, National Chung Cheng University (CCU), Chiayi, Taiwan; Department of Computer Science and Information Engineering, National Chung Cheng University (CCU), Chiayi, Taiwan; Department of Computer Science and Information Engineering, National Chung Cheng University (CCU), Chiayi, Taiwan; Department of Computer Science and Information Engineering, National Chung Cheng University (CCU), Chiayi, Taiwan; Department of Computer Science and Information Engineering, National Chung Cheng University (CCU), Chiayi, Taiwan","IEEE Access","20 Feb 2020","2020","8","","30387","30399","Various attacks have emerged as the major threats to the success of a connected world like the Internet of Things (IoT), in which billions of devices interact with each other to facilitate human life. By exploiting the vulnerabilities of cheap and insecure devices such as IP cameras, an attacker can create hundreds of thousands of zombie devices and then launch massive volume attacks to take down any target. For example, in 2016, a record large-scale DDoS attack launched by millions of Mirai-injected IP cameras and smart printers blocked the accessibility of several high-profile websites. To date, the state-of-the-art defense systems against such attacks rely mostly on pre-defined features extracted from the entire flows or signatures. The feature definitions are manual, and it would be too late to block a malicious flow after extracting the flow features. In this work, we present an effective anomaly traffic detection mechanism, namely D-PACK, which consists of a Convolutional Neural Network (CNN) and an unsupervised deep learning model (e.g., Autoencoder) for auto-profiling the traffic patterns and filtering abnormal traffic. Notably, D-PACK inspects only the first few bytes of the first few packets in each flow for early detection. Our experimental results show that, by examining just the first two packets in each flow, D-PACK still performs with nearly 100% accuracy, while features an extremely low false-positive rate, e.g., 0.83%. The design can inspire the emerging efforts towards online anomaly detection systems that feature reducing the volume of processed packets and blocking malicious flows in time.","2169-3536","","10.1109/ACCESS.2020.2973023","Advanced Institute of Manufacturing With High-Tech Innovations (AIM-HI) from the Featured Areas Research Center Program within the framework of the Higher Education Sprout Project by the Ministry of Education (MOE) in Taiwan; Ministry of Science and Technology, Taiwan(grant numbers:MOST 107-2218-E-194-014,108-2221-E-194-022-MY3,MOST 108-2221-E-194-019-MY3); Taiwan Information Security Center, National Sun Yat-sen University; TWISC@NSYSU; TNU-University of Information and Communication Technology, Vietnam; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8990084","IoT security;anomaly detection;convolutional neural network;autoendcoder;online DL-based anomaly detection","Anomaly detection;Feature extraction;Deep learning;Internet of Things;Buildings;Telecommunication traffic;IP networks","","112","","32","CCBY","10 Feb 2020","","","IEEE","IEEE Journals"
"Multi-UAV-enabled AoI-aware WPCN: A Multi-agent Reinforcement Learning Strategy","O. S. Oubbati; M. Atiquzzaman; A. Lakas; A. Baz; H. Alhakami; W. Alhakami","Laboratory of Computer Science and Mathematics, University of Laghouat, Algeria; School of Computer Science, The University of Oklahoma, Norman, OK, USA; College of Information Technology, United Arab Emirates University, Al Ain, UAE; College of Computer and Information Systems, Umm Al-Qura University, Makkah, Saudi Arabia; College of Computer and Information Systems, Umm Al-Qura University, Makkah, Saudi Arabia; College of Computers and Information Technology, Taif University, Taif, Saudi Arabia","IEEE INFOCOM 2021 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)","19 Jul 2021","2021","","","1","6","Unmanned Aerial Vehicles (UAVs) have been deployed in virtually all tasks of enabling wireless powered communication networks (WPCNs). To ensure sustainable energy support and timely coverage of terrestrial Internet of Things (IoT) devices, a UAV needs to continuously hover and transmit wireless energy signals to charge these devices in the downlink. Then, the devices send their independent information to the UAV in the uplink. However, it was noted that the majority of existing schemes related to UAV-enabled WPCN are mainly based on a single UAV and cannot meet the requirements of a large-scale WPCN. In this paper, we design a separated UAV-assisted WPCN system, where two UAVs are deployed to behave as a UAV data collector (UAV-DC) and UAV energy transmitter (UAV-ET), respectively. Thus, the collection of fresh information and energy transfer are treated separately at the level of the two corresponding UAVs. These two tasks could be enhanced by optimizing the UAVs’ trajectories. For this purpose, we leverage a multi-agent deep Q-network (MADQN) strategy to provide appropriate UAVs’ trajectories that jointly minimize the expected age of information (AoI), enhance the energy transfer to devices, and minimize the energy consumption of UAVs. Simulation results show that our system enhances the performance of our strategy significantly in terms of AoI and energy transfer compared with baseline methods.","","978-1-6654-0443-3","10.1109/INFOCOMWKSHPS51825.2021.9484496","Taif University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9484496","AoI;Multi-agent DQN;Resource allocation;UAV;Wireless powered communication network (WPCN);Trajectory design","Wireless communication;Energy consumption;Energy exchange;Conferences;Unmanned aerial vehicles;Trajectory;Internet of Things","","22","","13","IEEE","19 Jul 2021","","","IEEE","IEEE Conferences"
"Channel Measurements and Modeling for 400–600-MHz Bands in Urban and Suburban Scenarios","J. Huang; C. -X. Wang; Y. Yang; Y. Liu; J. Sun; W. Zhang","National Mobile Communications Research Laboratory, School of Information Science and Engineering, Southeast University, Nanjing, China; National Mobile Communications Research Laboratory, School of Information Science and Engineering, Southeast University, Nanjing, China; Shandong Provincial Key Laboratory of Wireless Communication Technologies, School of Information Science and Engineering, Shandong University, Qingdao, China; School of Microelectronics, Shandong University, Jinan, China; Shandong Provincial Key Laboratory of Wireless Communication Technologies, School of Information Science and Engineering, Shandong University, Qingdao, China; Shandong Provincial Key Laboratory of Wireless Communication Technologies, School of Information Science and Engineering, Shandong University, Qingdao, China","IEEE Internet of Things Journal","24 Mar 2021","2021","8","7","5531","5543","Sub-1 GHz bands have been used for many years and now some of them will be reallocated for new applications, including the fifth generation (5G) wireless communication systems and beyond, Internet of Things (IoT), smart grid, etc. As the well-known path-loss (PL) models are mainly applicable in 2-6-GHz frequency range, a new channel measurement campaign is needed to study the propagation characteristics at sub-1 GHz bands. In this article, we conduct fixed-to-mobile wideband channel measurements at 400-600-MHz bands in urban and suburban scenarios using the time domain channel sounder. As the interference and noise signals are severe, the transmitted waveform is carefully designed to enlarge the system dynamic range. Meanwhile, ray tracing simulation is applied to construct the measurement environments and do the mutual verification with measurement results. The two-slope PL model and lognormal shadowing fading model are proposed for large-scale fading channel modeling. The root mean square (RMS) delay spread (DS), number of paths, and diffraction characteristics are also analyzed. The results will have great importance for the coming new applications at sub-1 GHz bands.","2327-4662","","10.1109/JIOT.2020.3032615","National Key Research and Development Program of China(grant numbers:2018YFB1801101); National Natural Science Foundation of China(grant numbers:61901109,61960206006); Xinwei Project(grant numbers:11170011131701); National Postdoctoral Program for Innovative Talents(grant numbers:BX20180062); Frontiers Science Center for Mobile Information Communication and Security; High Level Innovation and Entrepreneurial Research Team Program in Jiangsu; High Level Innovation and Entrepreneurial Talent Introduction Program in Jiangsu; Research Fund of National Mobile Communications Research Laboratory, Southeast University(grant numbers:2020B01); Fundamental Research Funds for the Central Universities(grant numbers:2242020R30001); EU H2020 RISE TESTBED2 Project(grant numbers:872172); Taishan Scholar Program of Shandong Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9233437","Channel measurements;channel modeling;ray tracing;sub-1~GHz bands;urban and suburban scenarios","Wideband;Antenna measurements;Internet of Things;Wireless communication;Fading channels;Downlink;Uplink","","11","","37","IEEE","20 Oct 2020","","","IEEE","IEEE Journals"
"Efficient Multisource Data Delivery in Edge Cloud With Rateless Parallel Push","S. Luo; T. Ma; W. Shan; P. Fan; H. Xing; H. Yu","School of Information Science and Technology, Southwest Jiaotong University, Chengdu, China; School of Telecommunications Engineering, Xidian University, Xi’an; School of Telecommunications Engineering, Xidian University, Xi’an; School of Information Science and Technology, Southwest Jiaotong University, Chengdu, China; School of Information Science and Technology, Southwest Jiaotong University, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China","IEEE Internet of Things Journal","9 Oct 2020","2020","7","10","10495","10510","As the key infrastructure for emerging 5G and Internet-of-Things (IoT) applications, micro data centers would be widely deployed at network edges to provide high-bandwidth low-latency cloud service. In these systems, applications would deliver large-size data objects among servers for various purposes like service deployment, application scale-up, and data duplication on demand. Accordingly, reducing delivery time is crucial for the optimization of service delay and system utilization. To accelerate the delivery, this article proposes a multisource-aware adaptive data transmission solution, Parallel Push (PPUSH), by leveraging the fact that data objects in the cloud are generally replicated among servers by design. At the high level, PPUSH achieves efficient delivery of multisource data by launching multiple push flows in parallel; and at the low level, it decouples transfers from different sources by encoding data objects with rateless RaptorQ code, and further employing novel congestion controls to prioritize the bandwidth allocation of concurrent tasks respecting their remaining sizes. Fluid model analysis along with Mininet-based test and packet-level simulation shows that, unlike DCTCP and other proposals, push is robust to packet loss and achieves provable prioritized bandwidth allocation. Extensive simulation results imply that, with above advantages, PPUSH could achieve very efficient data delivery by making use of all available data sources: for instance, compared with the straightforward design of equal-size task split and fair bandwidth allocation, its adaptive task assignment and prioritized traffic scheduling reduce the average task completion time in a tested scenario by 1.495× and 1.329×, respectively, demonstrating a total improvement of 1.586×, when enabled at the same time.","2327-4662","","10.1109/JIOT.2020.2996800","China Postdoctoral Science Foundation(grant numbers:2019M663552); Fundamental Research Funds for the Central Universities(grant numbers:2682019CX61); NSFC Project(grant numbers:61731017); National Key Research and Development Program of China(grant numbers:2018YFB1801104); National Key Research and Development Program of China(grant numbers:2019YFB1802800); PCL Future Greater-Bay Area Network Facilities for Large-Scale Experiments and Applications(grant numbers:PCL2018KP001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9098934","Congestion control;data delivery;edge cloud;prioritized bandwidth allocation","Peer-to-peer computing;Task analysis;Channel allocation;Cloud computing;Servers;Data centers;Switches","","6","","49","IEEE","22 May 2020","","","IEEE","IEEE Journals"
"Multichannel ALOHA Optimization for Federated Learning With Multiple Models","R. V. da Silva; J. Choi; J. Park; G. Brante; R. D. Souza","Department of Electrical and Electronics Engineering, Federal University of Santa Catarina, Florianópolis, Brazil; School of Information Technology, Deakin University, Burwood, VIC, Australia; School of Information Technology, Deakin University, Burwood, VIC, Australia; CPGEI, Federal University of Technology-Paraná, Curitiba, Brazil; Department of Electrical and Electronics Engineering, Federal University of Santa Catarina, Florianópolis, Brazil","IEEE Wireless Communications Letters","6 Oct 2022","2022","11","10","2180","2184","Large-scale wireless sensor networks are instrumental for several Internet of Things (IoT) applications involving data analytics and machine learning. The huge data volume generated by such networks imposes a change of paradigm from centralized machine learning to decentralized. Federated Learning (FL) is a well-known type of decentralized machine learning, whose efficiency heavily depends on the use of wireless communication resources. Random Access (RA) protocols, such as ALOHA, despite their simplicity, can improve the convergence time of FL systems if multiple orthogonal channels are used. This letter considers that devices are involved in the optimization of more than one model in a FL system, and then proposes an optimum method to allocate wireless resources in a multi-channel ALOHA setup. The proposed method outperforms uniform and fully-shared channel allocations in terms of convergence time.","2162-2345","","10.1109/LWC.2022.3196241","CNPq, Brazil(grant numbers:402378/2021-0,305021/2021-4,307226/2021-2,164300/2021-0); RNP/MCTIC, Brazil (6G Mobile Communications Systems)(grant numbers:01245.010604/2020-14); Australian Government through the Australian Research Council’s Discovery Projects Funding Scheme(grant numbers:DP200100391); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9849112","Federated learning;sparsification;multi-channel aloha;wireless sensor networks","Wireless sensor networks;Convergence;Channel allocation;Machine learning;Internet of Things;Data models;Wireless communication","","4","","17","IEEE","3 Aug 2022","","","IEEE","IEEE Journals"
"Human Centric IoT Lighting Control based on Personalized Biological Clock Estimations","C. Papatsimpa; J. H. Bonarius; J. P. M. G. Linnartz","Eindhoven University of Technology, Eindhoven, the Netherlands; Eindhoven University of Technology, Eindhoven, the Netherlands; Eindhoven University of Technology, Eindhoven, the Netherlands","2020 IEEE 6th World Forum on Internet of Things (WF-IoT)","13 Oct 2020","2020","","","1","6","Smart Buildings with connected lighting and sensors have become one of the first large-scale applications of the Internet of Things. However, existing efforts to make buildings smarter focus mainly on energy conservation and cutting costs. In this paper, we further address the beneficial effects of light upon humans. People nowadays spend more than 90% indoors and as such the indoor environment becomes paramount for people’s health and wellbeing. We present a Human Centric Lighting solution that supports human health through the estimation of the biological effects of light. It exploits the possibility that IoT offers to monitor humans and their experience and to control internet-connected lights. Despite the existence of well-established and extensively tested models of the circadian mechanism, benefits of those models are not yet harvested in practical applications. We envision an application that controls the lighting system based on a suitable model that predicts the human response to light. Our work confirms that the statistical signal processing approach of a Particle Filter can account for sensor and model uncertainties. We show how the response of the biological clock to light depends largely on individual characteristics, such as the intrinsic characteristic duration of the day, and therefore we include such person characterization into our system design.","","978-1-7281-5503-6","10.1109/WF-IoT48130.2020.9221206","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9221206","biological clock;smart building;sensor network;circadian rhythms","Uncertainty;Smart buildings;Biological system modeling;Chronobiology;Lighting;Estimation;Signal processing","","2","","13","IEEE","13 Oct 2020","","","IEEE","IEEE Conferences"
"Analysis of Cascading Failures Due to Dynamic Load-Altering Attacks","M. P. Goodridge; A. Zocca; S. Lakshminarayana","Global Development Initiatives; Department of Mathematics, Vrije Universiteit Amsterdam, NL; School of Engineering, University of Warwick, UK","2023 IEEE International Conference on Communications, Control, and Computing Technologies for Smart Grids (SmartGridComm)","6 Dec 2023","2023","","","1","6","Large-scale load-altering attacks (LAAs) are known to severely disrupt power grid operations by manipulating several internet-of-things (IoT)-enabled load devices. In this work, we analyze power grid cascading failures induced by such attacks. The inherent security features in power grids such as the N–1 design philosophy dictate LAAs that can trigger cascading failures are rare events. We overcome the challenge of efficiently sampling critical LAAs scenarios for a wide range of attack parameters by using the so-called “skipping sampler” algorithm. We conduct extensive simulations using a three-area IEEE-39 bus system and provide several novel insights into the composition of cascades due to LAAs. Our results highlight the particular risks to modern power systems posed by strategically designed coordinated LAAs that exploit their structural and real-time operating characteristics.","2474-2902","978-1-6654-5556-5","10.1109/SmartGridComm57358.2023.10333960","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10333960","Load-altering attacks;cascading failures;rareevent sampling;N-l secure","Computers;Philosophical considerations;Power system protection;Power system dynamics;Real-time systems;Smart grids;Security","","1","","19","IEEE","6 Dec 2023","","","IEEE","IEEE Conferences"
"Latency-Sensitive Web Service Workflows: A Case for a Software-Defined Internet","P. Kathiravelu; P. V. Roy; L. Veiga; E. Benkhelifa","Emory Univeristy, Atlanta, GA, USA; Université catholique de Louvain, Louvain-la-Neuve, Belgium; Instituto Superior Técnico Universidade de Lisboa, Lisboa, Portugal; Staffordshire University, Staffordshire, UK","2020 Seventh International Conference on Software Defined Systems (SDS)","20 Jul 2020","2020","","","115","122","The Internet, at large, remains under the control of service providers and autonomous systems. The Internet of Things (IoT) and edge computing provide an increasing demand and potential for more user control for their web service workflows. Network Softwarization revolutionizes the network landscape in various stages, from building, incrementally deploying, and maintaining the environment. Software-Defined Networking (SDN) and Network Functions Virtualization (NFV) are two core tenets of network softwarization. SDN offers a logically centralized control plane by abstracting away the control of the network devices in the data plane. NFV virtualizes dedicated hardware middleboxes and deploys them on top of servers and data centers as network functions. Thus, network softwarization enables efficient management of the system by enhancing its control and improving the reusability of the network services. In this work, we propose our vision for a Software-Defined Internet (SDI) for latency-sensitive web service workflows. SDI extends network softwarization to the Internet-scale, to enable a latency-aware user workflow execution on the Internet.","","978-1-7281-7219-4","10.1109/SDS49854.2020.9143882","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9143882","","Cloud computing;Web services;Servers;Data centers;Bandwidth","","","","47","IEEE","20 Jul 2020","","","IEEE","IEEE Conferences"
"An Analysis on the Implementation of Deep Learning in Wireless Networks","J. S. Raj; S. Shobana","Department of ECE, Gnanamani College of Technology, Namakkal, India; Department of ECE, RVS College of Engineering and Technology, Coimbatore, India","2023 International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS)","6 Dec 2023","2023","","","1725","1732","The emerging modern wireless communication networks and systems such as mobile networks and Internet of Things (IoT) results in generating big data and enabling heterogeneous data transfer, which results in high amount of data traffic. Wireless Networks are broadly classified into local and wide area networks. Currently, managing the wide area networks to perform large-scale monitoring and data analytics faces several challenges in terms of real-time data processing and network analysis. Moreover, due to the emerging challenges in network interpretability and monitoring, the networking pattern of wireless networks, especially mobile networks have become more complex. Motivated by the recent success of applying Deep Learning in may real-time applications, this study explores the application of Deep Learning (DL) in different network layers and deep learning generated interpretations that assist the network operators to design and deploy the DL based networking systems. Further, this study discusses about the simulation tools that are currently used to simulate the Deep Learning (DL) based Wireless Networks. From the findings, we have finally listed out some of the unsolved challenges faced while integrating deep learning model in wireless networks.","","979-8-3503-0085-7","10.1109/ICSSAS57918.2023.10331706","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10331706","Deep learning;future wireless networks;network routing;Artificial Intelligence (AI)","Deep learning;Wide area networks;Performance evaluation;Wireless networks;Telecommunication traffic;Real-time systems;Internet of Things","","","","30","IEEE","6 Dec 2023","","","IEEE","IEEE Conferences"
"Secured Integration of Distributed Energy Resources into Energy Ecosystems","R. S. Ravi; D. Tripathy; V. Pathirana; S. Seifollahi; A. Jolfaei; H. Zhao","Swan Foresight Pty Ltd., Mount Waverley, VIC, Australia; Swan Foresight Pty Ltd., Mount Waverley, VIC, Australia; Swan Foresight Pty Ltd., Mount Waverley, VIC, Australia; RMIT University, Melbourne, VIC, Australia; Macquarie University, Sydney, NSW, Australia; Swan Foresight Pty Ltd., Mount Waverley, VIC, Australia","2021 31st Australasian Universities Power Engineering Conference (AUPEC)","16 Nov 2021","2021","","","1","6","With an increase in focus on renewable energy, the implementation and operation of new energy ecosystems along with existing systems is quite a challenge. Energy stakeholders are using various approaches to build renewable energy ecosystems for cost-cutting purposes while the standards are evolving and the legacy systems are yet to open for the Internet of Things (IoT). The article sets the context and importance of renewable energy ecosystems with the latest investments and industry developments across the world. A review is done in this changing/ new energy ecosystem, and cybersecurity challenges are highlighted in the operations of renewable energy-based Microgrids and Virtual Power Plants (VPP). This is followed by an in-depth analysis of different evolving standards in the operationalisation of these new energy ecosystems. Furthermore, the article provides the operational design details of these new ecosystems, focusing on Distributed Energy Resources (DER) interoperability, security, and integration. Observations from a lab experiment on a sample DER communication are shared. The article is concluded by highlighting the work involved in the institutionalisation of the lab experiments on a larger operational scale.","2474-1507","978-1-6654-3451-5","10.1109/AUPEC52110.2021.9597747","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9597747","DER;Microgrid;energy ecosystems;renewable energy;Australian Energy Market Operator;cybersecurity and operations","Renewable energy sources;Power engineering;Regulators;Ecosystems;Stakeholders;Internet of Things;Australia","","","","10","IEEE","16 Nov 2021","","","IEEE","IEEE Conferences"
"UAV Enabled Sustainable IoT Network with OTPDRL","T. Wang; L. Liu; H. Sun; J. Hu","School of Software, Shandong University, Jinan, China; School of Software, Shandong University, Jinan, China; School of Computer and Control Engineering, YanTai University, YanTai, China; Computer Science, Exeter University, United Kingdom","2023 26th International Conference on Computer Supported Cooperative Work in Design (CSCWD)","22 Jun 2023","2023","","","935","940","Integrating large-scale sensors into the network has become a research hotspot for its promising flexibility in monitoring vitally critical wild areas. However, the existing Internet of Things (IoT) systems are limited due to the lack of a stable power supply, which seriously affects the system’s sustainability. The combination of sensors equipped with cordless power batteries and long-distance power transmission has ushered in a new era. Using the unmanned aerial vehicles (UAVs) to charge the battery ensures the flexibility and sustainability of the sensor in environmental detection. In this work, we aim to provide a solution for maintaining the sustainability of the sensors while optimizing UAV trajectory to minimize the overall energy consumption of UAV. Since deep reinforcement learning successfully solves the NP-hard combinatorial optimization problem, deep reinforcement learning is introduced in this work to obtain a feasible solution. We formulate the trajectory planning of UAV as a Markov decision problem and employ a deep reinforcement learning (DRL) model based on an attention mechanism to find the optimal policy efficiently, named the optimal trajectory planning algorithm based on DRL (OTPDRL). The experimental results suggest the OTPDRL obtains a good trade-off between performance gain and computational time.","2768-1904","979-8-3503-3168-4","10.1109/CSCWD57460.2023.10152669","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10152669","Unmanned Aerial Vehicle;Deep reinforcement learning;Attention mechanism","Deep learning;Energy consumption;Trajectory planning;Reinforcement learning;Performance gain;Autonomous aerial vehicles;Sensors","","","","18","IEEE","22 Jun 2023","","","IEEE","IEEE Conferences"
"From Less Batteries to Battery-Less: Enabling A Greener World through Ultra-Wide Power-Performance Adaptation down to pWs","M. Alioto",NA,"ESSCIRC 2022- IEEE 48th European Solid State Circuits Conference (ESSCIRC)","20 Oct 2022","2022","","","33","40","This paper presents a holistic perspective on recent advances in silicon systems for distributed and decentralized systems (e.g., IoT, AIoT), whose count is trending towards the trillions exponentially. At such unprecedented scale, batteries impose severe scaling limitations in terms of form factor, system lifetime and uptime, sensor node cost, system cost (e.g., due to battery/sensor node replacement), and a heavy environmental impact at disposal time. Accordingly, sustained growth in the number of connected devices mandates drastic battery shrinking and ultimately elimination at scale. Beyond the straightforward reduction in the battery utilization via long sleep modes, this paper focuses on the prominent class of miniaturized (mm-scale) battery-indifferent and battery-less systems. Recent and unfolding design techniques are presented to enable purely-harvested operation, while still maintaining sensor nodes alert/available, long lived (e.g., beyond the battery shelf life), millimeter-sized and low cost. This paper and its keynote speech companion at ESSCIRC discusses how to achieve such goals through system peak power adaptation down to the nW level, rather than conventional average. Fundamental principles are demonstrated on silicon across all major sensor node sub-systems (e.g., processing, sensor interfaces, wireless communications). Overall, the design techniques described in this keynote paper aim to enable next-generation ubiquitous, low-cost, miniaturized yet alert sensor nodes for sustainable scale-up. From a technological viewpoint, the resulting advances aim to make scaling to the trillions economically and logistically sustainable. Even more importantly, they are crucially needed to make trillion-scale systems environmentally sustainable, addressing the gargantuan threat posed by trillions of batteries lying ahead, from production to disposal. Beyond the well-established notion of VLSI systems on a chip, sustainability in very large-scale (distributed/decentralized) systems really starts from design.","","978-1-6654-8494-7","10.1109/ESSCIRC55480.2022.9911465","NRF(grant numbers:MOE2019-T2-2-189,CRP20-2017-0003); TSMC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9911465","Internet of Things;sustainability;circular economy;ultra-low power;battery-less systems;battery-indifferent systems;green technologies;always-on","Wireless communication;Wireless sensor networks;Costs;Production;Very large scale integration;Silicon;Batteries","","","","43","IEEE","20 Oct 2022","","","IEEE","IEEE Conferences"
"A 194nW Energy-Performance-Aware loT SoC Employing a 5.2nW 92.6% Peak Efficiency Power Management Unit for System Performance Scaling, Fast DVFS and Energy Minimization","X. Liu; S. Kamineni; J. Breiholz; B. H. Calhoun; S. Li","University of Virginia, Charlottesville, VA; University of Virginia, Charlottesville, VA; University of Virginia, Charlottesville, VA; University of Virginia, Charlottesville, VA; University of Virginia, Charlottesville, VA","2022 IEEE International Solid-State Circuits Conference (ISSCC)","17 Mar 2022","2022","65","","1","3","A self-powered IoT system-on-chip (SoC) reduces power to sub-μw and employs multiple power-management techniques to trade-off ultra-low power (ULP), higher performance, smaller energy harvester footprint, and longer operating lifetime. Minimum Energy Point Tracking (MEPT) [1]–[4] keeps an SoC operating at the minimum energy point (MEP) to enhance system lifetime. Previous sample-and-hold MEPT schemes need frequent voltage comparisons and a high-frequency clock that increases power [2]. Current-ratio-based MEPT relies on specialized CMOS technology for body-bias tuning [3]. A switched-capacitor-based MEPT can achieve energy minimization at a targeted performance [4], but it uses a 30MHz clock $\text{wit}\mu \mathrm{W}$ power consumption and low power efficiency. For ULP IoT applications, SoCs need to have ultra-low quiescent power, high efficiency for energy delivery, performance scaling based on available energy, and energy minimization to increase system lifetime. In this work, we propose an ULP IoT SoC with a triple-mode power management unit (PMU) that integrates energy-performance scaling, event-driven fast DVFS, and MEPT features to improve the system energy efficiency, as shown in Fig. 13.8.1. This work achieves a minimum 194nW power consumption for the SoC and 5.2nW quiescent power for the PMU with a 92.6% peak efficiency and >104 dynamic range. The timing waveform in Fig. 13.8.1 (bottom), demonstrates the transition of the three modes including energy aware (EA), performance aware (PA), and MEPT based on event priority and input voltage level which reflects the energy availability. As such, the system energy consumption and performance could be well-balanced based on both the input and output conditions.","2376-8606","978-1-6654-2800-2","10.1109/ISSCC42614.2022.9731758","U.S. Department of Energy's Office of Energy Efficiency and Renewable Energy; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9731758","","Power demand;Power system management;Voltage;Minimization;Phasor measurement units;Timing;System-on-chip","","5","","5","IEEE","17 Mar 2022","","","IEEE","IEEE Conferences"
"Distributed Remote Estimation Over the Collision Channel With and Without Local Communication","X. Zhang; M. M. Vasconcelos; W. Cui; U. Mitra","School of Information and Electronics, Beijing Institute of Technology, Beijing, China; Commonwealth Cyber Initiative and the Bradley Department of Electrical Engineering, Virginia Tech, Arlington, VA, USA; School of Information and Electronics, Beijing Institute of Technology, Beijing, China; Ming Hsieh Department of Electrical Engineering, University of Southern California, Los Angeles, CA, USA","IEEE Transactions on Control of Network Systems","26 May 2022","2022","9","1","282","294","Internet of Things networks are the large-scale distributed systems consisting of a massive number of simple devices communicating, typically, over a shared wireless medium. This new paradigm requires novel ways of coordinating access to limited communication resources without introducing unreasonable delays. Herein, the optimal design of a remote estimation system with $n$ sensors communicating with a fusion center via a collision channel of limited capacity $k\leq n$ is considered. In particular, for independent and identically distributed observations with a symmetric probability density function, we show that the problem of minimizing the mean-squared error with respect to a threshold strategy is quasi-convex. When coordination among sensors via a local communication network is available, the online learning of possibly unknown parameters of the probabilistic model is possible, enabling each sensor to optimize its own threshold autonomously. We propose two strategies for remote estimation with local communication: 1) one strategy swiftly reaches the performance of the optimal decentralized threshold policy and 2) the second strategy approaches the performance of the optimal centralized scheme with a slower convergence rate. A hybrid scheme that combines the best of both approaches is proposed, offering fast convergence and excellent performance.","2325-5870","","10.1109/TCNS.2021.3100405","ONR(grant numbers:N00014-15-1-2550); NSF(grant numbers:CNS-1213128,CCF-1718560,CCF-1410009,CPS-1446901); Air Force Office of Scientific Research(grant numbers:FA9550-12-1-0215); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9497719","Decision theory;estimation;multi-agent systems;networked control systems;optimization","Sensors;Estimation;Sensor systems;Sensor fusion;Channel estimation;Internet of Things;Convergence","","4","","35","IEEE","27 Jul 2021","","","IEEE","IEEE Journals"
"Big Data Dimensionality Reduction at IoT Edge Through Optical Graph Signal Processing","A. Khodaei; J. Deogun; D. Alexander","University of Nebraska-Lincoln, Lincoln, NE, USA; University of Nebraska-Lincoln, Lincoln, NE, USA; University of Nebraska-Lincoln, Lincoln, NE, USA","2020 IEEE 6th International Conference on Computer and Communications (ICCC)","12 Feb 2021","2020","","","2491","2495","We introduce an innovative edge computing paradigm for big data dimensionality reduction in IoT networks through employing an underlying Graph Signal Processing (GSP) model-alternatively to von Neumann architecture for conventional computing. We realize a new breed of graph filters by instituting photonic wave interference in standard WDM optical communication systems, and thereby, we embody GSP in an optical computation context. Our proposed filter instantaneously takes the average of large-scale multidimensional data while is in transit from IoT edge to its core. Through co-using the communication resources for computation, our work motivates a modern IoT edge computing paradigm based on using a collective pool of computation and communication resources. Our solution saves a significant amount of processing delay, investment in cloud structure, and carbon footprint. It is, therefore, instrumental for breaking”the curse of dimensionality” in complex IoT applications such as self-driving vehicles that involve deploying lots of edge nodes and handling large volumes of high dimensional data with very low latency.","","978-1-7281-8635-1","10.1109/ICCC51575.2020.9345213","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9345213","Graph Signal Processing;IoT;big data;ultrashort laser;optical signal processing;edge computing","Optical filters;Integrated optics;Dimensionality reduction;Big Data;Internet of Things;Optical signal processing;Edge computing","","","","4","IEEE","12 Feb 2021","","","IEEE","IEEE Conferences"
"IoT Development In The Wild: Bug Taxonomy and Developer Challenges","A. Makhshari; A. Mesbah","University of British Columbia, Vancouver, BC, Canada; University of British Columbia, Vancouver, BC, Canada","2021 IEEE/ACM 43rd International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)","7 May 2021","2021","","","225","226","IoT systems are rapidly adopted in various domains, from embedded systems to smart homes. Despite their growing adoption and popularity, there has been no thorough study to understand IoT development challenges from the practitioners' point of view. We provide the first systematic study of bugs and challenges that IoT developers face in practice, through a large-scale empirical investigation. We highlight frequent bug categories and their root causes, correlations between them, and common pitfalls and challenges that IoT developers face. We recommend future directions for IoT areas that require research and development attention.","2574-1926","978-1-6654-1219-3","10.1109/ICSE-Companion52605.2021.00103","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9402389","Internet-of-Things;Software-Engineering;Mining-Software-Repositories;Empirical-Study","Correlation;Systematics;Computer bugs;Taxonomy;Tools;Faces;Software engineering","","1","","8","IEEE","7 May 2021","","","IEEE","IEEE Conferences"
"Fault Prediction of IoT Terminals based on Improved ResNet and BiLSTM Models","Y. Huo; Y. Liu; W. Huang; C. Fan; Y. Yang","School of Electronic and Information Engineering, Beijing Jiaotong University, Beijing, China; School of Electronic and Information Engineering, Beijing Jiaotong University, Beijing, China; School of Electronic and Information Engineering, Beijing Jiaotong University, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China","2023 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB)","16 Aug 2023","2023","","","1","6","With the rapid development of the IoT business, the IoT is showing a trend of large-scale and complex, and the types and quantities of terminal devices connected to the IoT system are constantly increasing, which puts forward higher requirements for the stability of the IoT. At present, the fault of IoT terminal device is unavoidable, and the existing research in the field of IoT terminals fault mainly focuses on the monitoring and diagnosis of faults. It is particularly important to make accurate and timely prediction before the fault occurs. In this paper, a IoT terminal fault prediction algorithm based on improved ResNet and BiLSTM and a Knowledge Review algorithm based on ECA module and Channel Connection loss are are proposed, which provides an effective solution for fault prediction of IoT terminal device.","2155-5052","979-8-3503-2152-4","10.1109/BMSB58369.2023.10211120","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10211120","Fault prediction;IoT terminals;Improved ResNet;BiLSTM;Knowledge Review","Predictive models;Broadcasting;Prediction algorithms;Feature extraction;Market research;Stability analysis;Multimedia communication","","","","11","IEEE","16 Aug 2023","","","IEEE","IEEE Conferences"
"Protecting IoT Devices through Localized Detection of BGP Hijacks for Individual Things","D. Kim; V. Andalibi; J. Camp",Indiana University; Indiana University; Indiana University,"2021 IEEE Security and Privacy Workshops (SPW)","8 Jul 2021","2021","","","260","267","In this paper, we leverage the limited functionality of IoT devices and the homophily of a single home network to identify control plane attacks. We illustrate the use of privacy-preserving data analysis in machine learning to evaluate the leptokurtic distributions of routes from a single device in an individual home in a specific geographic location. Previously, route hijacking has been approached as a large-scale systems problem, requiring network service providers to take action. Route information from the edge has traditionally been considered inactionable, however, small enterprises and homeowners may be targeted for such attacks for reasons ranging from nations attacking suppliers in critical systems to simple monetization of e-crime. We describe how a single small entity can leverage large-scale historical data with their individual histories to identify these attacks. We implement our proposed method in the form of a local agent that monitors the IoT devices and services for detecting BGP hijacking as well as an agent server that utilizes global history in initializing the local agents.","","978-1-6654-3732-5","10.1109/SPW53761.2021.00045","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9474276","BGP Hijacking;Cosine similarity;IoT security;Local agent;Machine Learning;User protection;IoT defense","Privacy;Home automation;Machine learning;Distance measurement;Large-scale systems;History;Servers","","3","","25","IEEE","8 Jul 2021","","","IEEE","IEEE Conferences"
"Persistence of RDF Data into NoSQL: A Survey and a Reference Architecture","L. H. Z. Santana; R. d. S. Mello","Departamento de Informática e Estatística, Universidade Federal de Santa Catarina, Florianópolis, Brasil; Departamento de Informática e Estatística, Universidade Federal de Santa Catarina, Florianópolis, Brasil","IEEE Transactions on Knowledge and Data Engineering","3 Feb 2022","2022","34","3","1370","1389","RDF is being increasingly considered in a broad range of information management scenarios. Governments, large corporations, startups, and other organizations around the world are using RDF as a data model to represent and share knowledge. However, there is still a long evolutionary track with multiple challenges for RDF reaching the scale of the most recent Big Data intensive applications (e.g., Smart Cities, Sensor Networks, eHealth, Internet of Things). In this survey, we review the usage of NoSQL databases to the storage of large RDF graphs by rehearsing the latest surveys and expanding their findings by updating proposals and bringing light to aspects such as model mapping between RDF and NoSQL, triple indexing and partitioning, graph fragmentation and data caching. Moreover, we explain how the surveyed works extended the RDF capabilities so the datasets can benefit of the characteristics of scalability, schemaless data, and better overall performance of NoSQL databases. The survey summarizes the current state of art, discusses open problems, and proposes a Reference Architecture (RA). For the best of our knowledge, this is the first survey where the focus is solely on papers that use one or more NoSQL systems for the RDF persistence.","1558-2191","","10.1109/TKDE.2020.2994521","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9093172","NoSQL;RDF;SPARQL;Semantic Web","Resource description framework;NoSQL databases;Data models;Indexing;Benchmark testing;Scalability","","2","","97","IEEE","13 May 2020","","","IEEE","IEEE Journals"
"LayerChain: A Hierarchical Edge-Cloud Blockchain for Large-Scale Low-Delay Industrial Internet of Things Applications","Y. Yu; S. Liu; P. L. Yeoh; B. Vucetic; Y. Li","School of Computer Science and Engineering, Northeastern University, Shenyang, China; School of Computer Science and Engineering, Northeastern University, Shenyang, China; School of Electrical and Information Engineering, University of Sydney, Sydney, NSW, Australia; School of Electrical and Information Engineering, University of Sydney, Sydney, NSW, Australia; School of Electrical and Information Engineering, University of Sydney, Sydney, NSW, Australia","IEEE Transactions on Industrial Informatics","5 Apr 2021","2021","17","7","5077","5086","The combination of pervasive edge computing and blockchain technologies opens up significant possibilities for industrial Internet of Things (IIoT) applications, but there are several critical limitations regarding efficient storage and rapid response for large-scale low-delay IIoT scenarios. To address these limitations, in this article we propose a hierarchical edge-cloud blockchain called LayerChain. Specifically, to promote scalability, we design a layered structure to hierarchically store the blockchain data in multiple distributed clouds and edge nodes. Next, we propose a node classification method to accommodate differences between the edge nodes when deploying the blockchain. Moreover, to mitigate lengthy delays during block propagation, we propose a tree-based clustering algorithm where blocks are propagated through different clusters with a compressed tree depth. Simulation results show that our LayerChain efficiently reduces the system's resource requirements and block propagation time, making it well-suited for large-scale low-delay IIoT applications.","1941-0050","","10.1109/TII.2020.3016025","National Key Research and Development Program of China Stem Cell and Translational Research(grant numbers:2018YFB1702003); National Natural Science Foundation of China(grant numbers:61941113,U1808207); Fundamental Research Funds for the Central Universities(grant numbers:N181613003); China Scholarship Council(grant numbers:201906085031); Australian Research Council Laureate Fellowship(grant numbers:FL160100032); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9165912","Block propagation;blockchain;cloud computing;industrial Internet of Things (IIoT);layered storage;pervasive edge computing","Edge computing;Cloud computing;Delays;Peer-to-peer computing;Informatics;Internet of Things","","33","","27","IEEE","12 Aug 2020","","","IEEE","IEEE Journals"
"Quasi-Distributed Fiber-Optic Acoustic Sensing With MIMO Technology","J. Jiang; J. Xiong; Z. Wang; Z. Wang; Z. Qiu; C. Liu; Z. Deng; Y. -J. Rao","Key Laboratory of Optical Fiber Sensing and Communications, University of Electronic Science and Technology of China, Chengdu, China; Key Laboratory of Optical Fiber Sensing and Communications, University of Electronic Science and Technology of China, Chengdu, China; Key Laboratory of Optical Fiber Sensing and Communications, University of Electronic Science and Technology of China, Chengdu, China; Key Laboratory of Optical Fiber Sensing and Communications and the Center for Information Geoscience, University of Electronic Science and Technology of China, Chengdu, China; Key Laboratory of Optical Fiber Sensing and Communications, University of Electronic Science and Technology of China, Chengdu, China; Key Laboratory of Optical Fiber Sensing and Communications, University of Electronic Science and Technology of China, Chengdu, China; Key Laboratory of Optical Fiber Sensing and Communications, University of Electronic Science and Technology of China, Chengdu, China; Key Laboratory of Optical Fiber Sensing and Communications, University of Electronic Science and Technology of China, Chengdu, China","IEEE Internet of Things Journal","6 Oct 2021","2021","8","20","15284","15291","In the field of the Internet of Things, sensors with large-scale perception ability are urgently needed for the scenarios, such as structure health monitoring, vehicle tracking, and so on. Quasi-distributed acoustic sensing (QDAS), which uses a sensing fiber with an ultraweak reflector array to perceive thousands of points at the same time, shows great advantages in these applications. The sensing fiber integrates sensing and transmission functionalities together and is easy to be deployed on large-scale targets. With the development of QDAS, the performance limitations caused by the finite frequency-domain resource are gradually emerging. Multiplexing the frequency-domain resource can be the key to further performance breakthroughs. For this purpose, the multiple-input–multiple-output (MIMO) technology, which has been widely used in communication/radar systems, is introduced into QDAS in this article. The principles of QDAS with the MIMO technology are elaborated, and the feasibility is verified through simulations and experiments, in which the response bandwidth is tripled compared to the traditional single-pulse QDAS. To the best of our knowledge, this is the first time that the MIMO coding technology, i.e., orthogonal codes with the same frequency (OCSF), is used in QDAS. This work paves a new way for breaking QDAS performance limitations that are bounded by the finite frequency resource.","2327-4662","","10.1109/JIOT.2021.3050924","Natural Science Foundation of China(grant numbers:62075030,41527805,61731006); Sichuan Provincial Project for Outstanding Young Scholars in Science and Technology(grant numbers:2020JDJQ0024); Higher Education Discipline Innovation Project(grant numbers:B14039); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9319705","Acoustic sensors;Internet of Things (IoT);multiple-input–multiple-output (MIMO);optical fiber sensors;orthogonal codes;response bandwidth","Sensors;MIMO communication;Bandwidth;Internet of Things;Probes;Spatial resolution;Optical scattering","","17","","43","IEEE","11 Jan 2021","","","IEEE","IEEE Journals"
"TemPredict: A Big Data Analytical Platform for Scalable Exploration and Monitoring of Personalized Multimodal Data for COVID-19","S. Purawat; S. Dasgupta; J. Song; S. Davis; K. T. Claypool; S. Chandra; A. Mason; V. Viswanath; A. Klein; P. Kasl; Y. Wen; B. Smarr; A. Gupta; I. Altintas","SDSC, UCSD, La Jolla, USA; SDSC, UCSD, La Jolla, USA; SDSC, UCSD, La Jolla, USA; Lincoln Laboratory, MIT, Boston, USA; Lincoln Laboratory, MIT, Boston, USA; SDSC, UCSD, La Jolla, USA; Department of Psychiatry, UCSF, San Francisco, USA; HDSI, UCSD, La Jolla, USA; Department of Bioengineering, UCSD, La Jolla, USA; Department of Bioengineering, UCSD, La Jolla, USA; HDSI, UCSD, La Jolla, USA; HDSI, UCSD, La Jolla, USA; SDSC, UCSD, La Jolla, USA; SDSC and HDSI, UCSD, La Jolla, USA","2021 IEEE International Conference on Big Data (Big Data)","13 Jan 2022","2021","","","4411","4420","A key takeaway from the COVID-19 crisis is the need for scalable methods and systems for ingestion of big data related to the disease, such as models of the virus, health surveys, and social data, and the ability to integrate and analyze the ingested data rapidly. One specific example is the use of the Internet of Things and wearables (i.e., the Oura ring) to collect large-scale individualized data (e.g., temperature and heart rate) continuously and to create personalized baselines for detection of disease symptoms. Individualized data, when collected, has great potential to be linked with other datasets making it possible to combine individual and societal scale models for further understanding the disease. However, the volume and variability of such data require novel big data approaches to be developed as infrastructure for scalable use. This paper presents the data pipeline and big data infrastructure for the TemPredict project, which, to the best of our knowledge, is the largest public effort to gather continuous physiological data for time-series analysis. This effort unifies data ingestion with the development of a novel end-to-end cyberinfrastructure to enable the curation, cleaning, alignment, sketching, and passing of the data, in a secure manner, by the researchers making use of the ingested data for their COVID-19 detection algorithm development efforts. We present the challenges, the closed-loop data pipelines, and the secure infrastructure to support the development of time-sensitive algorithms for alerting individuals based on physiological predictors illness, enabling early intervention.","","978-1-6654-3902-2","10.1109/BigData52589.2021.9671441","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671441","wearables;COVID-19;secure IoT;time series data;big data workflows;big data system","COVID-19;Temperature distribution;Wearable computers;Pipelines;Time series analysis;Big Data;Prediction algorithms","","3","","16","IEEE","13 Jan 2022","","","IEEE","IEEE Conferences"
"Monitoring State of Health and State of Charge of Lithium-Ion Batteries Using Machine Learning Techniques","A. Varshney; A. Singh; A. A. Pradeep; A. Joseph; G. P","Department of Electrical Engineering, National Institute of Technology Calicut; Department of Electrical Engineering, National Institute of Technology Calicut; Department of Electrical Engineering, National Institute of Technology Calicut; Department of Electrical Engineering, National Institute of Technology Calicut; Department of Electrical Engineering, National Institute of Technology Calicut","2021 IEEE 5th International Conference on Condition Assessment Techniques in Electrical Systems (CATCON)","10 Jan 2022","2021","","","022","027","Lithium-ion batteries are used in a wide range of applications. However, monitoring these batteries effectively is a challenge. There have been several attempts to efficiently estimate the battery state by fitting semi-empirical models. However, these methods tend to be computationally costly. This paper aims to solve this problem using a battery monitoring prototype based on supervised machine learning by estimating the battery’s health and the charge contained by it It can be efficiently designed by making a few changes in the production cycle. The dataset obtained by the manufacturer can be used to train a machine learning model. These models then can be used to estimate the behavioral patterns of the battery in real-time which gives the user an idea about the performance of the battery at any instance. Further, this monitoring system can be extended on a large scale with the help of Internet of Things as thousands of batteries can be monitored using a single server running all the algorithms, thus reducing cost for large-scale applications.","","978-1-6654-0317-7","10.1109/CATCON52335.2021.9670522","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9670522","Machine Learning;Battery Monitoring;Internet of Things;State of Health;State of Charge;Prognostics","Lithium-ion batteries;Prototypes;Voltage;Production;Real-time systems;State of charge;Servers","","2","","15","IEEE","10 Jan 2022","","","IEEE","IEEE Conferences"
"Delay-Efficient Joint Offloading and Resource Allocation Strategy in Multi-MEC Server Edge Cloud Combination Systems","Z. Sun; X. Chen; B. Yin; Y. Wang","Beijing Information Science and Technology University, Beijing, China; Beijing Information Science and Technology University, Beijing, China; Beijing Information Science and Technology University, Beijing, China; Beijing Information Science and Technology University, Beijing, China","2022 IEEE Smartworld, Ubiquitous Intelligence & Computing, Scalable Computing & Communications, Digital Twin, Privacy Computing, Metaverse, Autonomous & Trusted Vehicles (SmartWorld/UIC/ScalCom/DigitalTwin/PriComp/Meta)","27 Jul 2023","2022","","","1804","1811","With the Internet of Things devices becoming more intelligent, the emergence of large-scale cloud edge collaborative computing networks has made many emerging applications such as online monitoring, simulation reality possible. However, online processing of large-scale computing tasks brings huge delay between cloud, edge and terminal devices. In order to meet the demand of delay sensitive tasks, a cloud side cooperation mode of multi-user and multi MEC servers is considered in this paper. An optimization model with the goal of minimizing the average system delay is proposed, and a joint offloading and resource allocation algorithm based on bi-level particle swarm optimization (BLPSO-JRAA) is proposed to solve the above problems. The algorithm divides the optimization problem into two levels: offloading strategy and resource allocation, and applies the improved particle swarm optimization algorithm to solve the problem iteratively. It is can be show that BLPSO-JRAA reduces the average computing and communication delay by 38% compared with the average communication resource allocation algorithm when users are dense by the simulation results.","","979-8-3503-4655-8","10.1109/SmartWorld-UIC-ATC-ScalCom-DigitalTwin-PriComp-Metaverse56740.2022.00260","National Natural Science Foundation of China; Beijing Information Science and Technology University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10189562","Multiple access edge computing;task offloading scheduling;edge cloud collaboration;particle swarm optimization","Cloud computing;Sociology;Mathematical models;Delays;Resource management;Servers;Task analysis","","","","13","IEEE","27 Jul 2023","","","IEEE","IEEE Conferences"
"Hierarchical Computing Network Collaboration Architecture for Industrial Internet of Things","Z. Luo; X. Zheng; B. Wang; Q. Meng; H. Cui; X. Guo; L. Liu","Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; School of Computer Science, Northwestern Polytechnical University, Xi’an, China; Lenovo Research, Beijing, PR China; Beijing University of Posts and Telecommunications, Beijing, China","2022 IEEE 28th International Conference on Parallel and Distributed Systems (ICPADS)","27 Mar 2023","2023","","","57","64","The Industrial Internet of Things (IIoT) is deemed a promising direction to drive a new industrial revolution. However, due to the isolation of the existing OT network and IT network, the requirements of low latency, low jitter, and high reliability for transmission and processing of industrial time-sensitive tasks data traffic in IIoT scenarios with strong dynamic and complex topology face a series of non-trivial challenges. In this paper, we propose a hierarchical computing network collaboration architecture for IIoT based on edge/fog computing. Our architecture is built upon the Time-Sensitive Networking (TSN) to flexibly support different requirements of large-scale industrial production applications by constructing the hierarchical computing network collaboration domain, combined with an improved Cyclic Queuing and Forwarding (CQF) scheduling shaper mechanism. We tackle the critical problems of architecture design by presenting three essential components. Moreover, we build and implement our simulation testbed based on Omnet++, and evaluate our design.","2690-5965","978-1-6654-7315-6","10.1109/ICPADS56603.2022.00016","Research and Development; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10077954","IIoT;Computing Network Collaboration;Edge Computing;Fog Computing;Time-Sensitive Networking","Job shop scheduling;Processor scheduling;Collaboration;Computer architecture;Dynamic scheduling;Delays;Reliability","","","","22","IEEE","27 Mar 2023","","","IEEE","IEEE Conferences"
"Nonlinear Online Multioutput Gaussian Process for Multistream Data Informatics","Z. Hu; C. Wang","Department of Industrial Manufacturing and Systems Engineering, Texas Tech University, Lubbock, TX, USA; Department of Industrial and Systems Engineering, University of Iowa, Iowa City, IA, USA","IEEE Transactions on Industrial Informatics","21 Feb 2022","2022","18","6","3885","3893","The revolution of Industry 4.0 and Internet of Things facilitate large and cheap data acquisition from complex systems. However, the online processing and analytics of such multistream data still suffer difficulties. The key reason is that data from different sensors (multistream data) contain nonlinear within-and-cross sensor correlations, which poses challenges in the modeling and analysis of such data, especially for the online scenarios. To jointly model multistream data, multioutput Gaussian process (MGP) has become popular and achieved a great success. However, the existing methods assume that different outputs are linearly correlated, which significantly limits their applications. In this article, we propose a nonlinear online MGP framework to simultaneously realize nonlinear correlation modeling and online processing of multistream data. Specifically, a tailored covariance structure is developed based on the convolution process, which can capture nonlinear self-and-cross correlations. To realize online processing, Bayesian analysis and the marginalized particle filter are applied to estimate function values and model parameters. Comparing to the existing methods, the proposed method features superiorities in the nonlinear characterization of self-and-cross correlations and the efficient modeling and prediction capability. These features make the proposed method especially appropriate for industrial informatics with complex relationship and large-scale datasets. The proposed method is validated with simulation studies and a real-case study of biophysical signals.","1941-0050","","10.1109/TII.2021.3111632","Reducing EMbodied-Energy And Decreasing Emissions(grant numbers:20-01-RR-4038); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9535284","Bayesian analysis;high-dimensional data;multioutput Gaussian process (MGP);online processing","Correlation;Data models;Semiconductor process modeling;Predictive models;Gaussian processes;Convolution;Analytical models","","4","","26","IEEE","10 Sep 2021","","","IEEE","IEEE Journals"
"Intelligent Factory System Design Based on Single Chip Microcomputer","A. Li; Z. Wang; Y. Liu","Beijing Normal University School of Artificial Intelligence, Beijing, China; School of Mechanical Engineering, Hefei University of Technology, Hefei, China; School of Electrical & Information Engineering, Changsha University of Science & Technology, Changsha, China","2021 6th International Symposium on Computer and Information Processing Technology (ISCIPT)","23 Dec 2021","2021","","","32","42","With the advent of the “Internet plus” era, intelligent integration technology based on the Internet of Things technology has attracted widespread attention in industrial enterprises because of the large scale of large factories, management difficulties, fire, dangerous gas leakage, unknown personnel invasion, and other accidents that cannot be timely responded. The smart factory control system was designed based on a single-chip microcomputer. It is based on the CPS system, and it monitors environmental information through the close coordination of computational resources and physical resources and uses the wireless sensor network deployed in the monitoring plant area. Then the information is processed and transmitted to the host computer through the single-chip microcomputer so that the host computer can block the accident area in time. Thus, the goal of comprehensive and effective safety management of the whole factory is realized. At last, through the demonstration and Proteus software simulation results show that the system can effectively improve the response speed of factory personnel in emergencies, improve the management quality, but also save human resources, assist the safety supervision personnel in ensuring the safety of the factory to provide convenience, to promote the construction of intelligent society further to provide new ideas.","","978-1-6654-4137-7","10.1109/ISCIPT53667.2021.00014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9644458","component;CPSsystem;Single-chip microcomputer;Intelligent factory;Proteus simulation","Wireless sensor networks;Computational modeling;Microcomputers;Control systems;Production facilities;Data models;Personnel","","","","10","IEEE","23 Dec 2021","","","IEEE","IEEE Conferences"
"IoTFinder: Efficient Large-Scale Identification of IoT Devices via Passive DNS Traffic Analysis","R. Perdisci; T. Papastergiou; O. Alrawi; M. Antonakakis",Georgia Institute of Technology; University of Georgia; University of Georgia; University of Georgia,"2020 IEEE European Symposium on Security and Privacy (EuroS&P)","2 Nov 2020","2020","","","474","489","Being able to enumerate potentially vulnerable IoT devices across the Internet is important, because it allows for assessing global Internet risks and enables network operators to check the hygiene of their own networks. To this end, in this paper we propose IoTFinder, a system for efficient, large-scale passive identification of IoT devices. Specifically, we leverage distributed passive DNS data collection, and develop a machine learning-based system that aims to accurately identify a large variety of IoT devices based solely on their DNS fingerprints. Our system is independent of whether the devices reside behind a NAT or other middleboxes, or whether they are assigned an IPv4 or IPv6 address. We design IoTFinder as a multi-label classifier, and evaluate its accuracy in several different settings, including computing detection results over a third-party IoT traffic dataset and DNS traffic collected at a US-based ISP hosting more than 40 million clients. The experimental results show that our approach allows for accurately detecting many diverse IoT devices, even when they are hosted behind a NAT and their traffic is “mixed” with traffic generated by other IoT and non-IoT devices hosted in the same local network.","","978-1-7281-5087-1","10.1109/EuroSP48549.2020.00037","Defense Advanced Research Agency (DARPA)(grant numbers:2106EHP); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9230403","IoT Security;Traffic Modeling;Passive DNS","Fingerprint recognition;Data collection;Middleboxes;Object recognition;Internet of Things","","45","","43","IEEE","2 Nov 2020","","","IEEE","IEEE Conferences"
"Multi-protocol Aware Federated Matching for Architecture Design in Heterogeneous IoT","H. H. Esmat; X. Xia; B. Lorenzo; L. Guo","Dept. Electrical and Computer Engineering, University of Massachusetts, Amherst, USA; Dept. Electrical and Computer Engineering, University of Massachusetts, Amherst, USA; Dept. Electrical and Computer Engineering, University of Massachusetts, Amherst, USA; Dept. Electrical and Computer Engineering, Clemson University, USA","GLOBECOM 2022 - 2022 IEEE Global Communications Conference","11 Jan 2023","2022","","","6277","6282","Enabling timely data collection in heterogeneous IoT networks under different protocols and spectrum bands (e.g., WiFi, Bluetooth, Zigbee, LoR $a$) is crucial to implementing large-scale IoT systems. This paper presents a federated matching framework for heterogeneous IoT networks in which an intermediate layer of multi-protocol mobile gateways (M-MGs) is deployed by different service providers (SPs) to collect and relay data from IoT objects and perform computing tasks. The aim is to develop collaborative strategies between M-MGs and SPs to minimize the average weighted sum of the age-of-information and energy consumption. A novel collaborative framework based on a 2-level multi-protocol multi-agent actor-critic (MP-MAAC) is presented, where M-MGs and SPs can learn the interactive strategies through their own observations. The M-MGs strategies include the selection of IoT objects for data collection, execution, and offloading t o S Ps' a ccess points while SPs decide on the spectrum allocation. Moreover, we incorporate federated matching (Fed-Match) into the multi-agent collaborative framework to improve the convergence of the learning process. The numerical results show that our Fed-Match algorithm reduces the Aol by factor 4, collects twice more packets than existing approaches and establishes design principles for the stability of the training process.","","978-1-6654-3540-6","10.1109/GLOBECOM48099.2022.10000972","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10000972","Age of Information (Aol);federated learning;heterogeneous IoT;multi-agent deep reinforcement learning;mobile edge computing","Energy consumption;Protocols;Collaboration;Zigbee;Computer architecture;Data collection;Information age","","2","","11","IEEE","11 Jan 2023","","","IEEE","IEEE Conferences"
"Edge Reasoning on Context-Aware Environments: Application for the indoor displacement proble","A. T. Orozco; C. Nicolle; K. Yetongnon","Univ.Bourgogne Franche-Comté UB, Dijon, France; Univ.Bourgogne Franche-Comté UB, Dijon, France; Univ.Bourgogne Franche-Comté UB, Dijon, France","2020 IEEE International Conference on Internet of Things and Intelligence System (IoTaIS)","23 Feb 2021","2021","","","91","97","Nowadays, populations in buildings are heterogeneous. They cohabit with robots and machines that move inside buildings. The capacity of each individual to process and perceive its environment is as miscellaneous as the populations themselves. These individuals deal with simple and quotidian problems of indoor displacement, which reduce their productivity, comfort and even the performance of buildings. The need of a context-aware environment that provides quick, safe and direct solutions to this issue is evident. We present in this paper a Context-Aware Edge Layer named CAEL, made with Internet Of Things-based cyber-physical system and ontologies. CAEL takes reasoning skills on a context-aware system close to the source of data to create interoperability. This latter intends to improve mobility in indoor environments. Our approach addresses the displacement problem from two different perspectives: the occupants and the building. CAEL improves occupants' perception and processing by enriching their knowledge and reducing processing load respectively, while the building re-configures its topology to improve mobility. To validate our prototype, we constructed a physical scale model of a building. Inside, we placed small autonomous mobile robots to represent populations. We evaluate CAEL performance to improve indoor mobility by running multiple use cases. Results have shown evidence of cooperation between the environment and its occupants in terms of mobility. This study paves the work for a complete reasoning distributed architecture.","","978-1-7281-9448-6","10.1109/IoTaIS50849.2021.9359699","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9359699","Edge Computing;Context-aware;Mobility;IoT","Productivity;Buildings;Sociology;Prototypes;Cognition;Topology;Statistics","","","","29","IEEE","23 Feb 2021","","","IEEE","IEEE Conferences"
"Blockchain-Empowered Socially Optimal Transactive Energy System: Framework and Implementation","Q. Yang; H. Wang","Blockchain Technology Research Center and the College of Electronics and Information Engineering, Shenzhen University, Shenzhen, China; Department of Data Science and Artificial Intelligence, Faculty of Information Technology, Monash University, Melbourne, Australia","IEEE Transactions on Industrial Informatics","23 Feb 2021","2021","17","5","3122","3132","Transactive energy plays a key role in the operation and energy management of future power systems. However, the conventional operational mechanism, which follows a centralized design, is often less secure, vulnerable to malicious behaviors, and suffers from privacy leakage. In this article, we introduce blockchain technology in transactive energy to address these challenges. Specifically, we develop a novel blockchain-based transactive energy framework for prosumers and design a decentralized energy trading algorithm that matches the operation of the underlying blockchain system. We prove that the trading algorithm improves the individual benefit and guarantees the socially optimal performance, and thus, incentivizes prosumers to join the transactive energy platform. Moreover, we evaluate the feasibility of the transactive energy platform throughout the implementation of a small-scale network of Internet of Things devices and extensive simulations using real-world data. Our results show that this blockchain-based transactive energy platform is feasible in practice, and the decentralized trading algorithm reduces the user's individual cost by up to 77% and lowers the overall cost by 24%.","1941-0050","","10.1109/TII.2020.3027577","National Natural Science Foundation of China(grant numbers:61901280); Monash University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9208788","Blockchain;decentralized optimization;energy trading (ET);privacy;smart grid;transactive energy","Transactive energy;Smart grids;Privacy;Load modeling;Informatics;Internet of Things","","38","","30","IEEE","29 Sep 2020","","","IEEE","IEEE Journals"
"A New Lightweight In Situ Adversarial Sample Detector for Edge Deep Neural Network","S. Wang; W. Liu; C. -H. Chang","Department of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Department of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Department of Electrical and Electronic Engineering, Nanyang Technological University, Singapore","IEEE Journal on Emerging and Selected Topics in Circuits and Systems","11 Jun 2021","2021","11","2","252","266","The flourishing of Internet of Things (IoT) has rekindled on-premise computing to allow data to be analyzed closer to the source. To support edge Artificial Intelligence (AI), hardware accelerators, open-source AI model compilers and commercially available toolkits have evolved to facilitate the development and deployment of applications that use AI at its core. This paradigm shift in deep learning computations does not, however, reduce the vulnerability of deep neural networks (DNN) against adversarial attacks but introduces a difficult catch-up. This is because existing methodologies rely mainly on off-line analysis to detect adversarial inputs, assuming that the deep learning model is implemented on a 32-bit floating-point graphical processing unit (GPU) instance. In this paper, we propose a new hardware-oriented approach for in-situ detection of adversarial inputs feeding through a spatial DNN accelerator architecture or a third-party DNN Intellectual Property (IP) implemented on the edge. Our method exploits controlled glitch injection into the clock signal of the DNN accelerator to maximize the information gain for the discrimination of adversarial and benign inputs. A light gradient boosting machine (lightGBM) is constructed by analyzing the prediction probability of unmutated and mutated models and the label change inconsistency between the adversarial and benign samples in the training dataset. With negligibly small hardware overhead, the glitch injection circuit and the trained lightGBM detector can be easily implemented alongside with the deep learning model on a Xilinx ZU9EG chip. The effectiveness of the proposed detector is validated against four state-of-the-art adversarial attacks on two different types and scales of DNN models, VGG16 and ResNet50, for a thousand-class visual object recognition application. The results show a significant increase in true positive rate and a substantial reduction in false positive rate on the Fast Gradient Sign Method (FGSM), Iterative-FGSM (I-FGSM), C&W and universal perturbation attacks compared with modern software-oriented adversarial sample detection methods.","2156-3365","","10.1109/JETCAS.2021.3076101","National Research Foundation, Singapore, through the National Cybersecurity Research and Development Programme/Cyber-Hardware Forensic and Assurance Evaluation Research and Development Programme(grant numbers:CHFA-GC1-AW01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9416697","Deep neural network;deep learning accelerator;edge AI;adversarial examples;AI security","Hardware;Artificial intelligence;Computational modeling;Deep learning;Perturbation methods;Image edge detection;Detectors","","4","","51","IEEE","27 Apr 2021","","","IEEE","IEEE Journals"
"Backup Battery Allocation and Workload Migration Against Electrical Load Shedding at Edge","L. Shen; F. Wang; F. Wang; J. Liu","School of Computing Science, Simon Fraser University, Burnaby, BC, Canada; School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen, China; Department of Computer and Information Science, The University of Mississippi, University, MS, USA; School of Computing Science, Simon Fraser University, Burnaby, BC, Canada","IEEE Internet of Things Journal","22 Sep 2023","2023","10","19","16804","16815","In the 5G era (and the upcoming 6G), mobile edge computing (MEC) has been advocated to serve the massive amount of Internet of Things (IoT) devices by base stations (BSs) and edge data centers (EDCs). Geo-distributed EDCs are generally of much smaller scales as compared to mega data centers and hence of much lower costs, but can have fast response to their users so as to satisfy the demands of real-time applications. As their reliability and availability heavily depend on the electrical power supply, most EDCs are equipped with battery groups as backup power in case of power grid load shedding or outage. In a heterogeneous geo-distributed environment, the QoS of heavily loaded EDCs however can be severely impacted by limited backup power while lightly loaded EDCs may simply waste such precious resources. Moreover, a heavily loaded EDC may suffer from deep discharge of its battery group, which will cause a significant reduction of battery capacity and lifetime. This further aggravates the aforementioned situations should load shedding/outage happen again. In this article, we carefully analyze the workloads in EDCs and classify them into interactive workloads and batch workloads, respectively. We then develop a novel battery allocation framework with smart workload migration for EDCs, which simultaneously protects interactive workloads from being interrupted and minimizes the waiting time of batch workloads. Our extensive evaluations show that our strategies can optimize all the objectives within a limited overall cost as compared to state-of-the-art practical allocation.","2327-4662","","10.1109/JIOT.2023.3270436","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10109114","Backup battery;electrical load shedding;mobile edge computing (MEC);workload migration","Batteries;Data centers;Internet of Things;Costs;Load shedding;Servers;Resource management","","1","","43","IEEE","26 Apr 2023","","","IEEE","IEEE Journals"
"A Scalable and Energy-Efficient MAC Protocol for Linear Sensor Networks","I. Villordo-Jimenez; N. Torres-Cruz; R. Menchaca-Mendez; M. E. Rivero-Angeles","UPIITA, Instituto Politécnico Nacional, Mexico City, Mexico; UPIITA, Instituto Politécnico Nacional, Mexico City, Mexico; CIC, Instituto Politécnico Nacional, Mexico City, Mexico; CIC, Instituto Politécnico Nacional, Mexico City, Mexico","IEEE Access","11 Apr 2022","2022","10","","36697","36710","Linear topologies arise naturally in the context of Internet-of-Things (IoT) applications for smart cities, where the infrastructure itself commonly has a linear or semi-linear structure. This is the case of buildings, public transportation systems, road infrastructure, and utility distribution networks. Given the prevalence of this type of topologies, several Medium Access Control (MAC) protocols have been designed to take advantage of their particular properties. Unfortunately, most of them do not scale well as the node density and the distance in hops to the sink increases. The result is that packets generated many hops away from the sink tend to experience unacceptable high end-to-end delay and low delivery probabilities. This paper introduces HP-MAC, a synchronized duty-cycled MAC protocol for Linear Sensor Networks (LSNs) that assigns transmission priorities to nodes to avoid collisions, through the implementation of distributed elections based on hash functions. HP-MAC also implements a packet queuing scheme that acts as a mechanism to control the amount of network resources allocated to data flows generated at different distances to the sink. This way, packets can reach their destination with loss probability and end-to-end delay that do not depend on their distance to the sink. We use a Discrete-Time Markov Chain (DTMC) to model the performance of the proposed protocol. Numerical solutions of this model show that HP-MAC outperforms state-of-the-art representatives in terms of throughput, end-to-end delay, power consumption, and packet loss probability. These results are validated through extensive discrete-event simulations.","2169-3536","","10.1109/ACCESS.2022.3163728","Secretaría de Investigación y Posgrado del Instituto Politécnico Nacional (SIP-IPN)(grant numbers:20221996); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9745528","Linear sensor networks (LSN);synchronized duty-cycled MAC protocol;collision-free MAC protocol;Markov chain;energy-efficient Internet of Things (IoT)","Protocols;Media Access Protocol;Delays;Wireless sensor networks;Proposals;Throughput;Topology","","5","","40","CCBY","31 Mar 2022","","","IEEE","IEEE Journals"
"A Survey on Matching Theory for Distributed Computation Offloading in IoT-Fog-Cloud Systems: Perspectives and Open Issues","H. Tran-Dang; D. -S. Kim","Department of Electronic Engineering, Kumoh National Institute of Technology, Gumi-si, South Korea; Department of Electronic Engineering, Kumoh National Institute of Technology, Gumi-si, South Korea","IEEE Access","15 Nov 2022","2022","10","","118353","118369","Fog computing has been widely integrated in the IoT-based systems, creating IoT-Fog- Cloud (IFC) systems to improve the system performances and satisfy the quality of services (QoS) and quality of experience (QoE) requirements for the end users (EUs). This improvement is enabled by computational offloading schemes, which perform the task computation nearby the task generation sources (i.e., IoT devices, EUs) on behalf of remote cloud servers. To realize the benefits of offloading techniques, however, there is a need to incorporate efficient resource allocation frameworks, which can deal effectively with intrinsic properties of computing environment in the IFC systems such as resource heterogeneity of computing devices, various requirements of computation tasks, high task request rates, and so on. While the centralize optimization and non-cooperative game theory based solutions are applicable in a certain number of application scenarios, they fail to be efficient in many of cases, where the global information and control might be unavailable or cost-intensive to achieve it in the large-scale systems. The need of distributed computational offloading algorithms with low computation complexity has motivated a surge of solutions using matching theory. In the present review, we first describe the fundamental concept of this emerging tool enabling the distributed implementation in the computing environment. Then the key solution concepts and algorithmic implementations proposed in the framework of literature are highlighted and discussed. Given the powerful tool of matching theory, its full capability is still unexplored and unexploited in the literature. We thereby discover and discuss existing challenges and corresponding solutions that the matching theory can be applied to resolve them. Furthermore, new problems and open issues for application scenarios of modern IFC systems are also investigated thoroughly.","2169-3536","","10.1109/ACCESS.2022.3219427","Ministry of Science and ICT (MSIT), South Korea, under the Grand Information Technology Research Center Support Program Supervised by the Institute for Information & Communications Technology Planning & Evaluation (IITP)(grant numbers:IITP-2020-2020-0-01612); Priority Research Centers Program through the National Research Foundation of Korea (NRF); Ministry of Education, Science and Technology(grant numbers:2018R1A6A1A03024003); Korea Research Fellowship Program through the National Research Foundation of Korea (NRF); Ministry of Science and ICT(grant numbers:NRF-2020R1I1A1A01073019); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9938439","IoT-Fog-cloud systems;matching theory;distributed algorithm;computational offloading","Computational modeling;Optimization;Edge computing;Cloud computing;Resource management;Quality of service;Internet of Things;Distributed algorithms","","13","","84","CCBY","4 Nov 2022","","","IEEE","IEEE Journals"
"An Experimental Study of TSN-NonTSN Coexistence","S. Chouksey; H. S. Satheesh; J. Åkerberg","India Corporate Research Center, ABB Global Industries and Services Pvt Ltd, Bengaluru, India; India Corporate Research Center, ABB Global Industries and Services Pvt Ltd, Bengaluru, India; ABB Corporate Research, Västerås, Sweden","2021 IEEE 11th Annual Computing and Communication Workshop and Conference (CCWC)","17 Mar 2021","2021","","","1577","1584","Time sensitive networking (TSN) has a promising future in the Industrial Automation and Industrial Internet of Things, with advantages such as interoperability, coexistence of different types of data, data stream scheduling mechanisms, network configuration and management tools. The core technology of TSN includes precise clock synchronization, network bandwidth reservation, and traffic shaping, which ensures high reliability, low latency and other industrial needs. A key feature of TSN is the traffic scheduling mechanism, which can accommodate hard real time streams of critical data with bounded end to end delays. In this work we have setup a heterogeneous TSN test bed with five TSN-enabled devices from different vendors. This study summarizes the devices and tools used in the setup. We have prioritized testing the time-aware shaping feature of TSN as compared to time synchronization. While performing the time aware shaping feature testing we have come across the tools that support configuration of devices individually or as a group. This paper shares the hand-on experience on the TSN feature support from specific devices, their participation in a simple TSN system, their performance and the tools supported for the configuration. The results are articulated, and it is an ongoing work targeting future additions of application layer protocols and scale it up to understand what it takes for engineering a TSN enabled large scale system.","","978-1-6654-1490-6","10.1109/CCWC51732.2021.9376048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9376048","TSN;Deterministic Ethernet;TAS;Queuing Policy","Performance evaluation;Protocols;Job shop scheduling;Tools;Topology;Synchronization;Testing","","6","","23","IEEE","17 Mar 2021","","","IEEE","IEEE Conferences"
"A Comprehensive Survey: Benefits, Services, Recent Works, Challenges, Security, and Use Cases for SDN-VANET","O. S. Al-Heety; Z. Zakaria; M. Ismail; M. M. Shakir; S. Alani; H. Alsariera","Faculty of Electronic and Computer Engineering, Universiti Teknikal Malaysia Melaka (UTeM), Durian Tunggal, Malaysia; Faculty of Electronic and Computer Engineering, Universiti Teknikal Malaysia Melaka (UTeM), Durian Tunggal, Malaysia; Faculty of Engineering and Built Environment, Universiti Kebangsaan Malaysia (UKM), Bangi, Malaysia; Faculty of Engineering and Electronic Engineering, Universiti Tun Hussein Onn Malaysia (UTHM), Batu Pahat, Malaysia; Faculty of Electronic and Computer Engineering, Universiti Teknikal Malaysia Melaka (UTeM), Durian Tunggal, Malaysia; Faculty of Electronic and Computer Engineering, Universiti Teknikal Malaysia Melaka (UTeM), Durian Tunggal, Malaysia","IEEE Access","22 May 2020","2020","8","","91028","91047","Vehicular communication networks is a powerful tool that enables numerous vehicular data services and applications. The rapid growth in vehicles has also resulted in the vehicular network becoming heterogeneous, dynamic, and large-scale, making it hard to meet the strict requirements, such as extremely latency, high mobility, top security, and enormous connections of the fifth-generation network. Previous studies have shown that with the increase in the application of Software-Defined Networking (SDN) on Vehicular Ad-hoc Network (VANET) in industries, researchers have exerted considerable efforts to improve vehicular communications. This study presents an exhaustive review of previous works by classifying them based on based on wireless communication, particularly VANET. First, a concise summary of the VANET structure and SDN controller with layers and details of their infrastructure is provided. Second, a description of SDN-VANET applications in different wireless communications, such as the Internet of Things (IoT) and VANET is provided with concentration on the examination and comparison of SDN-VANET works on several parameters. This paper also provides a detailed analysis of the open issues and research directions accomplished while integrating the VANET with SDN. It also highlights the current and emerging technologies with use cases in vehicular networks to address the several challenges in the VANET infrastructure. This survey acts as a catalyst in raising the emergent robustness routing protocol, latency, connectivity and security issues of future SDN-VANET architectures.","2169-3536","","10.1109/ACCESS.2020.2992580","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9088232","Vehicular ad hoc network (VANET);SDN;5G;Internet of Vehicles (IoV);routing protocol;connectivity;mobility management;security","Vehicular ad hoc networks;Security;Wireless communication;Routing protocols;Industries;Quality of service","","123","","89","CCBY","6 May 2020","","","IEEE","IEEE Journals"
"UAV Path Planning using Global and Local Map Information with Deep Reinforcement Learning","M. Theile; H. Bayerlein; R. Nai; D. Gesbert; M. Caccamo","TUM School of Engineering and Design, Technical University of Munich, Germany; Communication Systems Department, EURECOM, Sophia Antipolis, France; TUM School of Engineering and Design, Technical University of Munich, Germany; Communication Systems Department, EURECOM, Sophia Antipolis, France; TUM School of Engineering and Design, Technical University of Munich, Germany","2021 20th International Conference on Advanced Robotics (ICAR)","5 Jan 2022","2021","","","539","546","Path planning methods for autonomous unmanned aerial vehicles (UAVs) are typically designed for one specific type of mission. This work presents a method for autonomous UAV path planning based on deep reinforcement learning (DRL) that can be applied to a wide range of mission scenarios. Specifically, we compare coverage path planning (CPP), where the UAV's goal is to survey an area of interest to data harvesting (DH), where the UAV collects data from distributed Internet of Things (IoT) sensor devices. By exploiting structured map information of the environment, we train double deep Q-networks (DDQNs) with identical architectures on both distinctly different mission scenarios to make movement decisions that balance the respective mission goal with navigation constraints. By introducing a novel approach exploiting a compressed global map of the environment combined with a cropped but uncompressed local map showing the vicinity of the UAV agent, we demonstrate that the proposed method can efficiently scale to large environments. We also extend previous results for generalizing control policies that require no retraining when scenario parameters change and offer a detailed analysis of crucial map processing parameters' effects on path planning performance.","","978-1-6654-3684-7","10.1109/ICAR53236.2021.9659413","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9659413","","Navigation;Distributed databases;Process control;Reinforcement learning;Autonomous aerial vehicles;Path planning;Internet of Things","","17","","17","IEEE","5 Jan 2022","","","IEEE","IEEE Conferences"
"A Multi-Attention Tensor Completion Network for Spatiotemporal Traffic Data Imputation","X. Wu; M. Xu; J. Fang; X. Wu","College of Civil Engineering, Fuzhou University, Fuzhou, Fujian, China; Intelligent Transport System Research Center, Wuhan University of Technology, Wuhan, Hubei, China; College of Civil Engineering, Fuzhou University, Fuzhou, Fujian, China; College of Civil Engineering, Fuzhou University, Fuzhou, Fujian, China","IEEE Internet of Things Journal","6 Oct 2022","2022","9","20","20203","20213","The widespread deployment of road sensors in the Internet of Things (IoT) allows for fine-grained data integration, which is a fundamental demand for data-driven applications. Sensing data with inevitable missing and substantial anomalies are unavoidable, due to unstable network communication, faulty sensors, etc. Recent tensor completion studies have demonstrated the superiority of deep learning in imputation tasks by precisely capturing the intricate spatiotemporal dependencies/correlations. However, ignoring the significance of initial interpolation in these methods results in unstable performance, especially for complicated missing scenarios across large-scale data. Additionally, the existing interpolation methods utilize recursive signal propagation along spatiotemporal dimensions, which produce noise accumulation where the dependencies are uncorrelated. In this study, we design a multiattention tensor completion network (MATCN) for modeling multidimensional representation in the presence of missing entries. MATCN sparsely sampled historical fragments and utilized a gated diffusion convolution layer to generate the initial schemes, which mitigate the exposure bias existing in previous traffic imputation models. In addition, we develop a spatial signal propagation module and a temporal self-attention module as the basic stack block of deep networks, which executes representation aggregation and dynamic dependencies extraction at the spatiotemporal level. This architecture empowers MATCN with progressive completion capacities for complex data missing scenarios. Numerical experiments on four real-world traffic data sets with various missing scenarios demonstrate the superiority of MATCN over multiple state-of-the-art imputation baselines.","2327-4662","","10.1109/JIOT.2022.3171780","National Natural Science Foundation of China through the project “Connected vehicle big data drove expressway multiobjective coordinated control fusing deep learning and traffic flow model”(grant numbers:71901070); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9766153","Attention mechanism;diffusion network convolution;missing data imputation;spatiotemporal traffic data;traffic pattern discovery","Tensors;Spatiotemporal phenomena;Sensors;Convolution;Internet of Things;Logic gates;Interpolation","","11","","48","IEEE","2 May 2022","","","IEEE","IEEE Journals"
"Optimization Over Time-Varying Networks and Unbounded Information Delays","A. Ramaswamy; A. Redder; D. E. Quevedo","Department of Computer Science, Paderborn University, Paderborn, Germany; Computer Networks Group, Department of Computer Science, Paderborn University, Paderborn, Germany; School of Electrical Engineering and Robotics, Queensland University of Technology, Brisbane, QLD, Australia","IEEE Transactions on Automatic Control","27 Jul 2022","2022","67","8","4131","4137","Solving optimization problems in multiagent systems involves information exchange between agents. The obtained solutions should be robust to information delays and errors that arise from an unreliable wireless network, which typically connects the multiagent system. In today’s large-scale dynamic Internet of Things style multiagent scenarios, the network topology changes and evolves over time. In this article, we present a simple distributed gradient-based optimization framework and an associated algorithm. Convergence to a minimum of a given objective is shown under mild conditions on the network topology and objective. A key feature of our approach is that we merely assume that the messages sent reach the intended receiver, possibly delayed, with some positive probability. To the best of authors’ knowledge, ours is the first analysis under such weak general network conditions. We also discuss in detail the verifiability of the assumptions involved. This article also makes a technical contribution in terms of the allowed class of objective functions. Specifically, we present an analysis wherein the objective function is such that its sample-gradient is merely locally Lipschitz continuous. The theory developed herein is supported by empirical results.","1558-2523","","10.1109/TAC.2021.3108492","Deutsche Forschungsgemeinschaft; Deutsche Forschungsgemeinschaft(grant numbers:315248657); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9525225","Age-of-information (AoI);approximate distributed gradient methods;distributed optimization;stochastic approximation algorithms;time-varying communication network topologies;unbounded stochastic communication delays","Optimization;Network topology;Clocks;Wireless networks;Delays;Topology;Stochastic processes","","3","","19","IEEE","30 Aug 2021","","","IEEE","IEEE Journals"
"Blockchain-Based Multidimensional Trust Management in Edge Computing","Y. Wang; Z. Wu","Institute of Robotics, Ningbo University of Technology, Ningbo, China; College of Computer Science, Zhongyuan University of Technology, Zhengzhou, China","IEEE Access","7 Nov 2023","2023","11","","122736","122748","Due to the resource limitations of Internet of Things (IoT) terminals and the distributed characteristics of edge computing architecture, trustworthy services management in dynamic edge computing is a very large challenge. A general and extensible blockchain-based multidimensional trust management (BMDTM) model suitable for edge computing is proposed in this paper. First, probabilistic linguistic terms sets (PLTSs) are adopted as a trust scaling method to integrate the multicriteria evaluation data of the whole domain to measure the performance of the service provider, and the stability degree of each attribute performance is calculated based on information entropy theory, which enables us to measure the dynamic performance accurately and precisely. Second, the dual characteristic of the associated criteria is utilized to filter out malicious or unprofessional evaluation information of requesting nodes and avoid malicious user collusion, ensuring the credibility of trust management. Third, blockchain technology and smart contracts (SCs) are adopted to store trust evidence, share trust information across domains, and execute multisource trust fusion automatically, avoiding the problems of information opacity and the single point of failure of the traditional centralized trust model. The experimental results demonstrate that our model can well manage trust problems in a dynamically hostile edge computing environment. The first finding is that the introduction of the domain trust value significantly improves the quality of service (QoS) compliance ratio due to an accurate description of the dynamic performance of services. The second finding is that our model performs better in attack resistance by leveraging blockchain technology and the dual characteristic of the associated criteria.","2169-3536","","10.1109/ACCESS.2023.3329126","Open Fund of Key Laboratory of Flight Techniques and Flight Safety, CAAC(grant numbers:FZ2022KF17); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10304210","Blockchain;edge computing;trust evaluation;smart contract;probabilistic linguistic terms set","Edge computing;Blockchains;Trust management;Quality of service;Linguistics;Computational modeling;Security;Smart contracts","","","","33","CCBYNCND","1 Nov 2023","","","IEEE","IEEE Journals"
"FedHome: Cloud-Edge Based Personalized Federated Learning for In-Home Health Monitoring","Q. Wu; X. Chen; Z. Zhou; J. Zhang","School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; School of Electrical, Computer and Energy Engineering, Arizona State University, Tempe, AZ, USA","IEEE Transactions on Mobile Computing","1 Jul 2022","2022","21","8","2818","2832","In-home health monitoring has attracted great attention for the ageing population worldwide. With the abundant user health data accessed by Internet of Things (IoT) devices and recent development in machine learning, smart healthcare has seen many successful stories. However, existing approaches for in-home health monitoring do not pay sufficient attention to user data privacy and thus are far from being ready for large-scale practical deployment. In this paper, we propose FedHome, a novel cloud-edge based federated learning framework for in-home health monitoring, which learns a shared global model in the cloud from multiple homes at the network edges and achieves data privacy protection by keeping user data locally. To cope with the imbalanced and non-IID distribution inherent in user’s monitoring data, we design a generative convolutional autoencoder (GCAE), which aims to achieve accurate and personalized health monitoring by refining the model with a generated class-balanced dataset from user’s personal data. Besides, GCAE is lightweight to transfer between the cloud and edges, which is useful to reduce the communication cost of federated learning in FedHome. Extensive experiments based on realistic human activity recognition data traces corroborate that FedHome significantly outperforms existing widely-adopted methods.","1558-0660","","10.1109/TMC.2020.3045266","National Key Research and Development Program of China(grant numbers:2017YFB1001703); National Natural Science Foundation of China(grant numbers:U20A20159,61972432); Program for Guangdong Introducing Innovative and Entrepreneurial Teams(grant numbers:2017ZT07X355); Guangdong Provincial Pearl River Talents Program(grant numbers:2017GC010465); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9296274","Federated learning;in-home health monitoring;personalization","Data models;Monitoring;Medical services;Collaborative work;Biomedical monitoring;Data privacy;Cloud computing","","100","","53","IEEE","16 Dec 2020","","","IEEE","IEEE Journals"
"A Deep-Learning Method for Device Activity Detection in mMTC Under Imperfect CSI Based on Variational-Autoencoder","T. Zhao; F. Li; P. Tian","School of Information and Communications Engineering, Faculty of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China; School of Information and Communications Engineering, Faculty of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China; School of Information and Communications Engineering, Faculty of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China","IEEE Transactions on Vehicular Technology","15 Jul 2020","2020","69","7","7981","7986","Large-scale deployment of massive device connectivity is a crucial communication challenge for Internet of Things (IoT) networks, which consist of a huge number of devices with sporadic traffic. In massive Machine Communication Scenario (mMTC), it is very important for the serving base-station (BS) to identify the active devices in each coherence block. This paper proposes a deep neural network (DNN) based on variational autoencoder (VAE) for device activity detection in mMTC under imperfect channel state information (CSI). A framework of variational optimization is constructed and the learning network structure is also designed. The derivation on the loss function for network training is presented and numerical results are provided to illustrate the accuracy of our method. The performance demonstrates the merits of the proposed method by comparison with the traditional compressed sensing algorithms, which are widely applied in multi-user detection.","1939-9359","","10.1109/TVT.2020.2992080","Fundamental Research Funds for the Central Universities(grant numbers:xzy012019047); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9085960","Activity detection;deep neural network;massive machine communication scenario;variational-autoencoder","Compressed sensing;Channel estimation;Neural networks;Coherence;Channel state information;Deep learning;Partial transmit sequences","","20","","23","IEEE","4 May 2020","","","IEEE","IEEE Journals"
"Spatiotemporal Modelling of Multi-Gateway LoRa Networks with Imperfect SF Orthogonality","Y. Bouazizi; F. Benkhelifa; J. McCann","Imperial College London, London, UK; Imperial College London, London, UK; Imperial College London, London, UK","GLOBECOM 2020 - 2020 IEEE Global Communications Conference","25 Jan 2021","2020","","","1","7","Meticulous modelling and performance analysis of Low-Power Wide-Area (LPWA) networks are essential for large scale dense Internet-of-Things (IoT) deployments. As Long Range (LoRa) is currently one of the most prominent LPWA technologies, we propose in this paper a stochastic-geometry-based framework to analyse the uplink transmission performance of a multi-gateway LoRa network modelled by a Matern Cluster Process (MCP). The proposed model is first to consider all together the multi-cell topology, imperfect spreading factor (SF) orthogonality, random start times, and geometric data arrival rates. Accounting for all of these factors, we initially develop the SF-dependent collision overlap time function for any start time distribution. We, then analyse the Laplace transforms of intra-cluster and inter-cluster interference and formulate the uplink transmission success probability. Through simulation results, we highlight the vulnerability of each SF to interference, illustrate the impact of parameters such as the network density and the power allocation scheme on the network performance. Uniquely, our results shed light on when it is better to activate adaptive power mechanisms, as we show that an SF-based power allocation that approximates LoRa Adaptive Data Rate (ADR) negatively impacts nodes near the cluster head. Moreover, we show that the interfering SFs degrading the performance the most depend on the decoding threshold range and the power allocation scheme.","2576-6813","978-1-7281-8298-8","10.1109/GLOBECOM42002.2020.9322640","National Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9322640","LoRa;Stochastic Geometry;imperfect SF orthogonality;random start time;collision time overlap;success probability","Interference;Logic gates;Resource management;Decoding;Spatiotemporal phenomena;Signal to noise ratio;Analytical models","","4","","18","IEEE","25 Jan 2021","","","IEEE","IEEE Conferences"
"An Adaptive Device-Edge Co-Inference Framework Based on Soft Actor-Critic","T. Niu; Y. Teng; Z. Han; P. Zou","Beijing Key Laboratory of Space-ground Interconnection and Convergence, Beijing University of Posts and Telecommunications (BUPT), China; Beijing Key Laboratory of Space-ground Interconnection and Convergence, Beijing University of Posts and Telecommunications (BUPT), China; University of Houston, Texas, USA; Beijing Key Laboratory of Space-ground Interconnection and Convergence, Beijing University of Posts and Telecommunications (BUPT), China","2022 IEEE Wireless Communications and Networking Conference (WCNC)","16 May 2022","2022","","","2571","2576","Recently, the applications of deep neural network (DNN) have been very prominent in many fields due to its superior feature extraction performance. However, the high-dimension parameter model and large-scale mathematical calculation restrict the execution efficiency, especially for the Internet of Things (IoT) devices. Different from the previous cloud/edge-only pattern that brings significant pressure for uplink communication and device-only fashion that undertakes unaffordable calculation strength, we highlight the collaborative computation between the device and edge for DNN models, which can achieve a good balance between the communication load and execution accuracy. Specifically, a systematic on-demand co-inference framework is proposed to exploit the multi-branch structure, in which the pre-trained Alexnet is right-sized through early-exit and partitioned at an intermediate DNN layer. The integer quantization is enforced to further compress transmission bits. As a result, we establish a new Deep Reinforcement Learning (DRL) optimizer-Soft Actor Critic for discrete (SAC-d), which generates the exit point, partition point, and compressing bits by soft policy iterations. Based on the latency and accuracy aware reward design, such an optimizer can well adapt to the complex environment like dynamic wireless channel and arbitrary CPU processing, and is capable of supporting the 5G URLLC. Real-world experiment on Raspberry Pi 4 and PC shows the effective performance of the proposed solution.","1558-2612","978-1-6654-4266-4","10.1109/WCNC51071.2022.9771550","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9771550","Deep Neural Network (DNN);Inference;Internet of Things (IoTs);Reinforcement Learning;Edge Computing","Deep learning;Performance evaluation;Wireless communication;Adaptation models;Image edge detection;Computational modeling;Neural networks","","4","","18","IEEE","16 May 2022","","","IEEE","IEEE Conferences"
"Privacy-Preserving Block-chain Framework Based on Ring Signatures (RSs) and Zero-Knowledge Proofs(ZKPs)","Z. Mahmood; J. Vacius","Department of Software Engineering, Kaunas Technology University, Kaunas, Lithuania; Department of Software Engineering, Kaunas Technology University, Kaunas, Lithuania","2020 International Conference on Innovation and Intelligence for Informatics, Computing and Technologies (3ICT)","8 Jan 2021","2020","","","1","6","Block-chain emerged as the technology of choice for most applications because of its immutability property. Block-chain's immutability property promotes network resilience against any removal or modification of data stored on the ledger. However, large scale networks such as the Internet of Things (IoT) that may contain millions of nodes can significantly increase Block-chain size and raise serious privacy challenges. Moreover, the General Data Protection Regulations (GDPRs) that were enforced in May 2018 by European countries allows individuals and organizations to take control of their data by establishing stringent rules which includes “the right to be forgotten”. In cases where there are ethical or legal reasons individuals and companies might want their personal data stored to be erased whether such data is stored locally or on the ledger. The philosophy underpinning Block-chains is that forcing nodes to erase data is akin to denying them a role to play in the Block-chain ecosystems as full nodes. In this paper, we attempt to challenge this notion by proposing a model framework for an enhanced privacy that is akin to Block-chain erasure. Our approaches combine ring signatures (that have long been used to generate anonymous signatures) and Zero-Knowledge Proofs (ZKPs) that can help to disguise user's wallet addresses.","","978-1-7281-9673-2","10.1109/3ICT51146.2020.9312014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9312014","Decentralized ledgers;Block-chain;General Data Protection Regulations (GDPRs);Ring Signatures (RSs);Zero Knowledge Proofs (ZKPs)","Blockchain;Distributed ledger;Fabrics;Privacy;Pragmatics;Contracts;Technological innovation","","1","","33","IEEE","8 Jan 2021","","","IEEE","IEEE Conferences"
"Improving Connectivity in Urban IoT-based Wireless Sensor Networks: A None-orthogonal Cognitive-based Power Allocation","K. M. Bataihah; H. B. Salameh; H. Al-Obiedollah; M. Al-Nairat; Y. Jararweh","Department of Basic & Applied Sciences, Al-Balqa Applied University, Salt, Jordan; College of Engineering, Al Ain University, Al Ain, UAE; Department of Electrical Engineering, Faculty of Engineering, The Hashemite University, Zarqa, Jordan; Department of Electrical Engineering, Faculty of Engineering Technology, Zarqa University, Jordan; Department of Computer Science, Jordan University of Science and Technology, Jordan","IEEE Sensors Journal","","2023","PP","99","1","1","Wireless sensor networks (WSN) have been recently deployed to support various Internet-of-Things (IoT) applications, including sensing in urban environments. Accordingly, several research efforts have been conducted to support the unprecedented massive connectivity requirements, where a massive number of urban sensors are expected to be connected to the Internet. To enable such large-scale urban connectivity, cognitive radio (CR) technology has been identified as an appealing solution. This can be achieved by opportunistically exploiting the under-utilized licensed spectrum. However, most existing CR-based communication protocols were designed under imposing the exclusive-channel occupancy constraint, in which an idle channel cannot be assigned to multiple users at a time. This constraint can significantly limit the number of served sensor devices, which negatively impacts spectral efficiency. This paper proposes a batch-based power-controlled non-orthogonal spectrum sharing protocol for CR-enabled WSNs, referred to as the Distance-Fading Factor MAC (DFF-MAC) protocol, aiming to maximize the number of per-channel served transmissions while minimizing the overall transmit power. Specifically, we develop a power-minimization framework, and thus we derive a closed-form expression for the required transmit power for each transmission. This can be achieved by employing a novel multi-stage power-allocation that considers channel gain and interference constraints. Simulation results show that DFF-MAC outperforms the benchmark, namely the exclusive-occupancy protocol, by serving up to three times more transmissions. Furthermore, DFF-MAC achieves a level of performance (in terms of serviced sensors and power consumption) within 4% of the optimal one obtained through exhaustive search while maintaining low complexity.","1558-1748","","10.1109/JSEN.2023.3301622","The ASPIRE Award for Research Excellence Program 2020, Abu Dhabi, UAE(grant numbers:AARE20?161); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10213419","Cognitive Radio (CR);Internet-of-Things (IoT);Urban Systems;Sensor Networks","Sensors;Wireless sensor networks;Interference;Urban areas;Resource management;Signal to noise ratio;Power control","","1","","","IEEE","8 Aug 2023","","","IEEE","IEEE Early Access Articles"
"A Game-Based Incentive-Driven Offloading Framework for Dispersed Computing","H. Wu; J. Nie; Z. Xiong; Z. Cai; T. Zhou; C. Yuen; D. Niyato","College of Computer, National University of Defense Technology, Changsha, China; School of Computer Science and Engineering, Nanyang Technological University, Jurong West, Singapore; Pillar of Information Systems Technology and Design, Singapore University of Technology and Design, Tampines, Singapore; College of Computer, National University of Defense Technology, Changsha, China; College of Computer, National University of Defense Technology, Changsha, China; School of Electrical and Electronics Engineering, Nanyang Technological University, Jurong West, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Jurong West, Singapore","IEEE Transactions on Communications","14 Jul 2023","2023","71","7","4034","4049","The popularization of smart Internet of Things (IoT) devices has facilitated the development of fog/edge computing. However, these infrastructure-based service paradigms may fail to complete tasks successfully due to computation and communication overload, or damage in challenging scenarios such as disasters or traffic jams. Noticing that a crowd of devices with considerable idle resources could be available, we investigate the problems of addressing the computation and communication unavailability with peer assistance in this work. To this end, we propose a dispersed service framework for resource-exhausted scenarios that adaptively offloads users’ data to available network computation points. However, the users may not be able to achieve the offloading due to geographical hindrances. Consequently, the relay is introduced as a bridge for data offloading between the users and the network computation points. Furthermore, a game-based incentive-driven offloading mechanism is designed by analyzing and balancing the cost and gain factors of three main entities (users, relays, and network computation points). Considering the interactions among the entities, a two-level Stackelberg game is established for efficiently allocating potential computation resource, as well as balancing the utility conflicts due to the data offloading. Given the hierarchical interaction structure, the upper level game involves network computation points as followers and the relay as a leader, while the lower level game includes the relay as a follower and users as leaders. Moreover, to facilitate applicability in large-scale scenarios with multiple relays, we decompose multiple relays into multiple single relay problems using a tripartite matching strategy that assigns appropriate relays to users and network computation points. The simulation results demonstrate the effectiveness of the proposed game-based incentive-driven mechanism and show that it outperforms the baselines in terms of the overall utilities of the involved entities and the average energy consumption of users.","1558-0857","","10.1109/TCOMM.2023.3266833","National Natural Science Foundation of China(grant numbers:62072465,62172155,62102425,62102429,U22B2005); Science and Technology Innovation Program of Hunan Province(grant numbers:2022RC3061,2021RC2071); Natural Science Foundation of Hunan Province(grant numbers:2022JJ40564); National Research Foundation (NRF) and Infocomm Media Development Authority under the Future Communications Research Development Programme (FCP); SUTD SRG-ISTD-2021-165, the SUTD-ZJU IDEA Grant (SUTD-ZJU (VP) 202102); Ministry of Education, Singapore, under its SUTD Kickstarter Initiative (SKI 20210204); A*STAR under its RIE2020 Advanced Manufacturing and Engineering (AME) Industry Alignment Fund-Pre Positioning (IAF-PP)(grant numbers:A19D6a0053); DSO National Laboratories under the AI Singapore Programme(grant numbers:AISG2-RP-2020-019); Energy Research Test-Bed and Industry Partnership Funding Initiative; Energy Grid (EG) 2.0 programme; DesCartes and the Campus for Research Excellence and Technological Enterprise (CREATE) programme; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10102098","Incentive-driven;IoT;mobile computing;task offloading;network computation points;idle resources;Stackelberg game","Relays;Task analysis;Games;Internet of Things;Bandwidth;Cloud computing;Performance evaluation","","","","46","IEEE","13 Apr 2023","","","IEEE","IEEE Journals"
"IoT-enabled Low Communication Cost Sentiment Analysis Architecture for Intelligent Healthcare","Y. Yao; D. Qiu; B. Li; C. Dong; L. Xu; X. Guo; C. Lai","College of Computer and Data Science, Fuzhou University, Fuzhou, China; College of Computer and Data Science, Fuzhou University, Fuzhou, China; College of Computer and Data Science, Fuzhou University, Fuzhou, China; College of Computer and Data Science, Fuzhou University, Fuzhou, China; College of Computer and Cyber Security, Fujian Normal University, Fuzhou, China; College of Computer and Data Science, Fuzhou University, Fuzhou, China; College of Computer and Data Science, Fuzhou University, Fuzhou, China","2023 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech)","25 Dec 2023","2023","","","0367","0374","The rapid development of the Internet of Things makes it possible to analyze and make decisions on complex tasks in human society based on big data and artificial intelligence technologies. Intelligent healthcare is a part of it that is closely related to human beings. Traditional intelligent healthcare lacks mental health diagnosis and monitoring. The mental health diagnosis method relies on subjective decision-making and cannot achieve mental health diagnosis and early warning on a large scale. This paper combines artificial intelligence and low communication cost edge cloud solutions with intelligent healthcare. Also, the paper proposed an IoT-based mental health diagnosis solution with the help of sentiment analysis technology. The scheme targets current speech in various scenarios and relies on sentiment analysis technology to quantify emotions. Then, it cooperates with algorithms to achieve real-time monitoring and early warning of mental health conditions. The experimental part uses self-collected data as well as publicly available data. The experimental results show that the framework proposed in this paper accomplishes the tasks on multiple data sets.","2837-0740","979-8-3503-0460-2","10.1109/DASC/PiCom/CBDCom/Cy59711.2023.10361503","National Natural Science Foundation of China(grant numbers:62372110); Natural Science Foundation of Fujian Province(grant numbers:2020J01500); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10361503","Intelligent Healthcare;Artificial Intelligence;Internet of Things","Sentiment analysis;Decision making;Medical services;Mental health;Big Data;Real-time systems;Internet of Things","","","","17","IEEE","25 Dec 2023","","","IEEE","IEEE Conferences"
"Sum Power Minimization With Mixed Power and QoS Bounded Constraints","P. He","Department of Electrical, Computer and Software Engineering, Ontario Tech University, Canada","IEEE Transactions on Communications","13 Aug 2020","2020","68","8","5259","5268","In the incoming communication system, especially for the battery constrained Internet of Things devices, consumption of power resources will be a critical performance metric. This point shows importance when throughput minimal requirement and interference limit have been carried out. This paper investigates such a power allocation problem in a multiple-parallel-channel wireless system to minimize the sum power consumed by the entire system, while meeting the sum power constrains for each group of channels and the whole system as well as meeting the throughput constraints for each of the groups and the system. Sum power minimization itself is also a key issue for margin-adaptive loading. Resorting to geometric concepts, an algorithm named as the group virtual bottom power water-filling (GVB-PWF) is proposed to solve the problem, including the large-scale problems, which computes the exact solution with a low degree of the polynomial computational complexity. Optimality of the proposed algorithm is also proved strictly. To the best of our knowledge, no prior algorithm in the open literature offered such an optimal solution to the proposed problem, with the merit of exactness and efficiency. Simulation results demonstrate that the proposed power allocation algorithm uses less power about 25%, compared with the popular primal-dual interior-point method with the same amount of computations.","1558-0857","","10.1109/TCOMM.2020.2996737","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9099316","Power minimization;QoS;interference;exactness;efficiency;geometric water-filling (GWF);quadratic computational complexity","Throughput;Minimization;Quality of service;Upper bound;Wireless communication;Resource management;Linear programming","","1","","34","IEEE","25 May 2020","","","IEEE","IEEE Journals"
"Performance Analysis of Clustering Car-Following V2X System With Wireless Power Transfer and Massive Connections","D. -T. Do; M. -S. Van Nguyen; M. Voznak; A. Kwasinski; J. N. de Souza","Department of Computer Science and Information Engineering, Asia University, Taichung, Taiwan; Faculty of Electronics Technology, Industrial University of Ho Chi Minh City, Ho Chi Minh City, Vietnam; Department of Telecommunications, VSB Technical University of Ostrava, Ostrava, Czech Republic; Department of Computer Engineering, Rochester Institute of Technology, Rochester, NY, USA; Computer Science Department, Federal University of Ceara, Fortaleza, Brazil","IEEE Internet of Things Journal","8 Aug 2022","2022","9","16","14610","14628","With the rapid growth of vehicles, the vehicular networks meet main challenges such as dynamic, heterogeneous, and large scaled. In addition, the cellular-based vehicular networks must satisfy further strict requirements, including ultralow latency, high reliability, high spectrum efficiency, and massive connections of the next-generation (6G) network. Recently, by exploiting vehicle clustering utilized for reducing the complexity of vehicle-to-everything (V2X) systems, it could ultimately improve road traffic efficiency. In some specific scenarios related to Internet of Things, a group of vehicles can be served effectively in terms of spectrum efficiency when two key techniques are enabled, i.e., nonorthogonal multiple access and cognitive radio (CR) schemes are joint deployed. These techniques certainly benefit to 6G V2X services to reduce specific challenges, such as traffic congestion and massive connections. Different from existing works, we propose wireless power transfer applied to the roadside unit to improve the situation that energy shortening in small devices deployed in V2X communications. In particular, we derive expressions of throughput to exhibit performance of the two grouped vehicles. To further indicate advantages of spectrum efficiency, we compare two schemes of V2X systems with and without CR schemes. The numerical results demonstrate that the non-CR NOMA-V2X scheme outperforms the CR-based NOMA-V2X scheme with fixed power allocation, but the non-CR NOMA-V2X scheme costs higher spectrum resource compared with the counterpart. Besides, by comparing with orthogonal multiple access (OMA)-assisted V2X, NOMA-V2X schemes demonstrate superiority in terms of throughput performance whilst achieving the benefits of both NOMA and CR schemes.","2327-4662","","10.1109/JIOT.2021.3070744","Czech Ministry of Education, Youth and Sports conducted at the VSB—Technical University of Ostrava(grant numbers:SP2020/65); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9394417","Cognitive radio (CR);nonorthogonal multiple access (NOMA);throughput;vehicle-to-everything","NOMA;Vehicle-to-everything;Throughput;6G mobile communication;Transmitting antennas;Internet of Things;Interference","","33","","44","IEEE","2 Apr 2021","","","IEEE","IEEE Journals"
"Mastering Kali Linux for Advanced Penetration Testing: Become a cybersecurity ethical hacking expert using Metasploit, Nmap, Wireshark, and Burp Suite","V. Kumar Velu",NA,"Mastering Kali Linux for Advanced Penetration Testing: Become a cybersecurity ethical hacking expert using Metasploit, Nmap, Wireshark, and Burp Suite","","2022","","","","","Master key approaches used by real attackers to perform advanced pentesting in tightly secured infrastructure, cloud and virtualized environments, and devices, and learn the latest phishing and hacking techniquesKey FeaturesExplore red teaming and play the hackers game to proactively defend your infrastructureUse OSINT, Google dorks, Nmap, recon-nag, and other tools for passive and active reconnaissanceLearn about the latest email, Wi-Fi, and mobile-based phishing techniquesBook DescriptionRemote working has given hackers plenty of opportunities as more confidential information is shared over the internet than ever before. In this new edition of Mastering Kali Linux for Advanced Penetration Testing, you’ll learn an offensive approach to enhance your penetration testing skills by testing the sophisticated tactics employed by real hackers. You’ll go through laboratory integration to cloud services so that you learn another dimension of exploitation that is typically forgotten during a penetration test. You'll explore different ways of installing and running Kali Linux in a VM and containerized environment and deploying vulnerable cloud services on AWS using containers, exploiting misconfigured S3 buckets to gain access to EC2 instances. This book delves into passive and active reconnaissance, from obtaining user information to large-scale port scanning. Building on this, different vulnerability assessments are explored, including threat modeling. See how hackers use lateral movement, privilege escalation, and command and control (C2) on compromised systems. By the end of this book, you’ll have explored many advanced pentesting approaches and hacking techniques employed on networks, IoT, embedded peripheral devices, and radio frequencies.What you will learnExploit networks using wired/wireless networks, cloud infrastructure, and web servicesLearn embedded peripheral device, Bluetooth, RFID, and IoT hacking techniquesMaster the art of bypassing traditional antivirus and endpoint detection and response (EDR) toolsTest for data system exploits using Metasploit, PowerShell Empire, and CrackMapExecPerform cloud security vulnerability assessment and exploitation of security misconfigurationsUse bettercap and Wireshark for network sniffingImplement complex attacks with Metasploit, Burp Suite, and OWASP ZAPWho this book is forThis fourth edition is for security analysts, pentesters, ethical hackers, red team operators, and security consultants wanting to learn and optimize infrastructure/application/cloud security using advanced Kali Linux features. Prior penetration testing experience and basic knowledge of ethical hacking will help you make the most of this book.","","9781801812672","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10162823.pdf&bkn=10162822&pdfType=book","","","","","","","","27 Jun 2023","","","Packt Publishing","Packt Publishing eBooks"
"IoT Bugs and Development Challenges","A. Makhshari; A. Mesbah","University of British Columbia, Vancouver, BC, Canada; University of British Columbia, Vancouver, BC, Canada","2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)","7 May 2021","2021","","","460","472","IoT systems are rapidly adopted in various domains, from embedded systems to smart homes. Despite their growing adoption and popularity, there has been no thorough study to understand IoT development challenges from the practitioners' point of view. We provide the first systematic study of bugs and challenges that IoT developers face in practice, through a large-scale empirical investigation. We collected 5,565 bug reports from 91 representative IoT project repositories and categorized a random sample of 323 based on the observed failures, root causes, and the locations of the faulty components. In addition, we conducted nine interviews with IoT experts to uncover more details about IoT bugs and to gain insight into IoT developers' challenges. Lastly, we surveyed 194 IoT developers to validate our findings and gain further insights. We propose the first bug taxonomy for IoT systems based on our results. We highlight frequent bug categories and their root causes, correlations between them, and common pitfalls and challenges that IoT developers face. We recommend future directions for IoT areas that require research and development attention.","1558-1225","978-1-6654-0296-5","10.1109/ICSE43902.2021.00051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9402092","Internet of Things;Software Engineering;Mining Software Repositories;Empirical Study","Correlation;Systematics;Computer bugs;Taxonomy;Tools;Internet of Things;Faces","","27","","75","IEEE","7 May 2021","","","IEEE","IEEE Conferences"
"Demand-Aware Distributed Link Allocation in a Multilayer Heterogeneous Satellite Network: A Game Theory Approach","Y. Liu; Y. Wang; Y. Shen","School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China","IEEE Internet of Things Journal","","2024","PP","99","1","1","Satellite networks play important roles in fields such as communication, meteorology, and the Internet of Things. However, in highly dynamic multilayer heterogeneous satellite networks, the diverse satellite transmission demands pose challenges for network management. In large-scale satellite networks, conventional centralized network management methods have various adverse effects, such as high latency, high communication overhead, and high computational complexity. In this article, to overcome these challenges, we propose a distributed scheme for allocating intersatellite links between satellites at different orbital heights considering their different transmission demands. Specifically, we model the distributed link allocation framework as a Stackelberg game. Low Earth orbit (LEO) satellites, as leaders, apply for access to medium Earth orbit (MEO) satellites using a proposed link selection algorithm based on a stochastic best response strategy. The MEO satellites, as followers, allocate link resources using a proposed heuristic-based time slot resource allocation algorithm in accordance with the accessing applications. Simulation results show that the proposed algorithm outperforms benchmark algorithms in terms of the degree of matching between the transmission capacity and transmission requirements.","2327-4662","","10.1109/JIOT.2024.3358388","The Scientific Instrument Developing Project of the Chinese Academy of Sciences(grant numbers:YJKYYQ20200069); National Natural Science Foundation of China(grant numbers:62101043); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10414048","Satellite Network;Link Allocation;Game Theory","Satellites;Resource management;Low earth orbit satellites;Nonhomogeneous media;Games;Internet of Things;Heuristic algorithms","","","","","IEEE","25 Jan 2024","","","IEEE","IEEE Early Access Articles"
"Blend CAC: Integration for the Blockchain for Distributed Potential Network Access for the Internet of Things","A. Malhotra","Chitkara University Institute of Engineering and Technology, Chitkara University, Punjab, India","2023 International Conference on Artificial Intelligence and Smart Communication (AISC)","3 Apr 2023","2023","","","1145","1149","Due to the rise of the IoT, disparate embedded smart devices may now work together to provide intelligent services, with or without human intervention. When used in massive IoT-based requests like Smart Grid or Smart Cities, IoTs also generate significant privacy and security problems. One of the main security challenges for IoTs is access authorization. For the sake of cooperation and information safety, it is crucial. One problem with current access control systems is the reliance on a centralized authorization server, which may act as either a performance bottleneck or a single point of failure (AC). In order to ensure the safety of IoT devices, this research offers Blend CAC, a blockchain-supported decentralized capability-based AC. With the Blend CAC, we want to provide effective mechanisms for controlling access to devices, facilities, and data in large-scale IoT networks. dependent upon A capacity allocation method is suggested to disseminate authorization credentials throughout a blockchain network. In order to have a secure identity-based capability token management approach, it is recommended to employ smart contracts for the permission registration, dissemination, and cancellation processes. Blend CAC is a proposal that might allow IoT systems to independently manage their controller and assets with having to communicate with any higher-ups. tried out on a Pic Microcontroller with a local private blockchain.","","979-8-3503-2230-9","10.1109/AISC56616.2023.10085656","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10085656","Blockchain;Blend CAC;Internet of Things (IoT);Smart Contract;Data Mining","Authorization;Computers;Smart cities;Smart contracts;Blockchains;Safety;Smart grids","","","","13","IEEE","3 Apr 2023","","","IEEE","IEEE Conferences"
"CODE: Compact IoT Data Collection with Precise Matrix Sampling and Efficient Inference","H. Lu; F. Lyu; J. Ren; J. Yu; F. Wu; Y. Zhang; X. S. Shen","School of Computer Science and Engineering, Central South University, Changsha, China; School of Computer Science and Engineering, Central South University, Changsha, China; Department of Computer Science and Technology, BNRist, Tsinghua University, Beijing, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Technology, BNRist, Tsinghua University, Beijing, China; Department of Computer Science and Technology, BNRist, Tsinghua University, Beijing, China; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, Ontario, Canada","2022 IEEE 42nd International Conference on Distributed Computing Systems (ICDCS)","13 Oct 2022","2022","","","743","753","It is unpractical to conduct full-size data collection in ubiquitous IoT data systems due to the energy constraints of IoT sensors and large system scales. Although sparse sensing technologies have been proposed to infer missing data based on partial sampled data, they usually focus on data inference while neglecting the sampling process, restraining the inference efficiency. In addition, their inferring methods highly depend on data linearity correlations, which become less effective when data are not linearly correlated. In this paper, we propose, Compact IOT Data CollEction, namely CODE, to conduct precise data matrix sampling and efficient inference. Particularly, CODE integrates two major components, i.e., cluster-based matrix sampling and Generative Adversarial Networks (GAN)-based matrix inference, to reduce the data collection cost and guarantee the data benefits, respectively. In the sampling component, a cluster-based sampling approach is devised, in which data clustering is first conducted and then a two-step sampling is performed in accordance with the number of clusters and clustering errors. For the inference component, a GAN-based model is developed to estimate the full matrix, which consists of a generator network that learns to generate a fake matrix, and a discriminator network that learns to discriminate the fake matrix from the real one. A reference implementation of CODE is conducted under three operational large-scale IoT systems, and extensive data-driven experiment results are provided to demonstrate its efficiency and robustness.","2575-8411","978-1-6654-7177-0","10.1109/ICDCS54860.2022.00077","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9912296","Compact Data Collection;Sparse Sensing;Data Inference;Generative Adversarial Networks","Codes;Costs;Linearity;Data collection;Generative adversarial networks;Robustness;Data systems","","1","","43","IEEE","13 Oct 2022","","","IEEE","IEEE Conferences"
"A Framework for Enabling Safe and Resilient Food Factories for Public Feeding Programs","N. Kuntagod; S. Podder; S. S. S. Abbabathula; V. Subramanian; G. Mathew; S. K. Mani","Accenture, Bangalore, India; Accenture, Bangalore, India; Accenture, Bangalore, India; Accenture, Bangalore, India; Accenture, Bangalore, India; Accenture, Bangalore, India","2021 IEEE/ACM 3rd International Workshop on Software Engineering for Healthcare (SEH)","7 Jul 2021","2021","","","1","4","Public feeding programs continue to be a major source of nutrition to a large part of the population across the world. Any disruption to food factories that support these activities, like the one during the Covid-19 pandemic, can lead to adverse health outcomes, especially among children. Policymakers and other stakeholders must balance the need for continuing food-factory operations while ensuring the health and safety of workers. This has led to several innovations that leverage advanced technologies like AI and IoT to monitor the health and safety of workers and ensure hygienic operations. However, there are practical challenges in its implementation on a large scale.This paper presents an implementation framework to build resilient food factories for public feeding using a combination of intelligent technologies. The framework is a result of piloting the technology solution at a facility run as part of a large mid-day meal feeding program in India. Using existing resources like CCTV cameras and new technologies like AI and IoT, hygiene and safety compliance anomalies can be detected and reported in a resource-efficient manner. It will guide stakeholders running food factories for public feeding as they seek to restart suspended operations and build systems that better adapt to future crises.","","978-1-6654-4458-3","10.1109/SEH52539.2021.00008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9470896","nutrition;health;public feeding;pandemic;artificial intelligence;safety;automation;cloud;edge computing","Technological innovation;Pediatrics;Sociology;Production facilities;Health and safety;Stakeholders;Artificial intelligence","","","","17","IEEE","7 Jul 2021","","","IEEE","IEEE Conferences"
"Energy Usage of Deep Learning in Smart Cities","S. Puangpontip; R. Hewett","Department of Computer Science, Texas Tech University, Lubbock, USA; Department of Computer Science, Texas Tech University, Lubbock, USA","2020 International Conference on Computational Science and Computational Intelligence (CSCI)","23 Jun 2021","2020","","","1143","1148","Deep learning has increasingly become an essential component of many Smart City functions including smart city lightings, emergency rescues, smart drainage, and smart parking. These functions operate continuously in real-time throughout the day. Thus, excessive energy usage of deep learning computation can negatively impact economic benefits and efficiency of smart cities. The situation can escalate when dealing with resource-constrained large-scale smart cities of huge Internet-of-Things and networks with large numbers and varieties of sensors. To effectively sustain, manage and protect smart cities from failures due to energy overload, the awareness of energy consumption by deep learning computation is unavoidably necessary. Most recent research in smart cities focuses on using deep learning to perform certain tasks but does not address energy issues. This paper presents a formal approach to estimating energy consumption of deep learning and illustrates its use in smart cities. In particular, we develop a fine-grained mathematical model that extends an existing model to include the quantification of MAC (multiply-and-accumulate) operations as well as data access from a memory hierarchy. This paper focuses on deep and convolutional neural networks. We describe the proposed approach and validate the results obtained from our model by comparing them against those of existing work. The proposed approach is applied to three (deep) neural systems in smart cities, namely smart drainage, smart transportation and smart parking systems, all of which yield promising results.","","978-1-7281-7624-6","10.1109/CSCI51800.2020.00214","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9457878","energy consumption;deep learning;smart city","Deep learning;Energy consumption;Smart cities;Scientific computing;Lighting;Real-time systems;Smart transportation","","2","","14","IEEE","23 Jun 2021","","","IEEE","IEEE Conferences"
"A Blockchain-based SDN East/West Interface","H. N. Nguyen; S. Souihi; H. -A. Tran; S. Fowler","School of Information and Communication Technology, Hanoi University of Science and Technology, Vietnam; LISSI-TincNET Research Team University Paris-Est Creteil, France; School of Information and Communication Technology, Hanoi University of Science and Technology, Vietnam; Department of Science and Technology, Linköping University, Sweden","GLOBECOM 2022 - 2022 IEEE Global Communications Conference","11 Jan 2023","2022","","","5759","5764","Software-Defined Networking (SDN) architecture was developed to address the shortcomings of traditional network architectures. It allows system administrators to easily manage and configure the network by separating and abstracting the control plane from the data plane. All the knowledge and intelligence of SDN is concentrated in a software entity called the SDN controller, making the network programmable. However, a large-scale SDN architecture, particularly in the IoT domain, requires the implementation of a physically distributed control mechanism. Such a mechanism, based on the East/West interface raises many challenges in terms of scalability, reliability, security, consistency, and traceability. The development of the Blockchain allows addressing some of these challenges. In this paper, we present a design using Blockchain technology to improve SDNs in terms of trackability and discuss the adaptations required for large-scale deployment. Experimental results clearly show that the use of a proof-of-authority consensus algorithm in combination with a Merkle tree approach reduces the impact in terms of latency as well as in terms of Gas consumption.","2576-6813","978-1-6654-3540-6","10.1109/GLOBECOM48099.2022.10001381","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10001381","Software-Defined networking;Blockchain;Internet of Things;Smart Contract","Sharding;Scalability;Computer architecture;Consensus algorithm;Network architecture;Software;Blockchains","","","","18","IEEE","11 Jan 2023","","","IEEE","IEEE Conferences"
"Vertical Farming Algorithm using Hydroponics for Smart Agriculture","B. Anuradha; R. Pradeep; E. Ahino; A. Dhanabal; R. J. Gokul; S. Lingeshwaran","Department of Electronics and Communication Engineering, Sri Eshwar College of Engineering, Coimbatore, India; Department of Electronics and Communication Engineering, Sri Ramakrishna Engineering College, Coimbatore, India; Department of Electronics and Communication Engineering, Sri Eshwar College of Engineering, Coimbatore, India; Department of Electronics and Communication Engineering, Sri Eshwar College of Engineering, Coimbatore, India; Department of Electronics and Communication Engineering, Sri Eshwar College of Engineering, Coimbatore, India; Department of Electronics and Communication Engineering, Sri Eshwar College of Engineering, Coimbatore, India","2023 International Conference on Intelligent Systems for Communication, IoT and Security (ICISCoIS)","19 Apr 2023","2023","","","432","437","The development of an Agricultural nation depends heavily on agriculture. Indian agriculture is primarily reliant on precipitation, soil, wetness, and environmental difficulties. Our farmers switched to the most cutting-edge agricultural technologies available today. Globally, IoT systems have successfully applied their use in a variety of industries. It is now necessary for Indian farmers to implement Smart Agricultural technologies in order to increase crop productivity. IoT technologies provide a service that helps farmers in the provision of historical and current data for predicting soil quality, weather, and crop health. For applications relating to smart farming, IoT may combine numerous delivering a full semantic processing pipeline and a single framework from cross-domain data sources. Large-scale data analytics and event detection are provided by Agri-IoT, enabling seamless communication between sensors. In order to meet the demand brought on by population expansion, urban planners and agricultural professionals believe that cities will need to produce their own food. Due to recent advancements in greenhouse technologies like hydroponics, aeroponics, and aquaponics, the idea of a vertical farm has a promising future. These innovative methods herald a paradigm shift in farming and food production.","","979-8-3503-3583-5","10.1109/ICISCoIS56541.2023.10100527","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10100527","Vertical Farming;Hydroponics;Smart Agriculture;Internet of Things","Smart agriculture;Soft sensors;Urban areas;Sociology;Hydroponics;Crops;Switches","","3","","20","IEEE","19 Apr 2023","","","IEEE","IEEE Conferences"
"A Transfer Learning-Based High Impedance Fault Detection Method Under a Cloud-Edge Collaboration Framework","Y. Zhang; X. Wang; J. He; Y. Xu; F. Zhang; Y. Luo","School of Electrical Engineering, Beijing Jiaotong University, Beijing, China; School of Electrical Engineering, Beijing Jiaotong University, Beijing, China; School of Electrical Engineering, Beijing Jiaotong University, Beijing, China; School of Electrical Engineering, Beijing Jiaotong University, Beijing, China; School of Electrical Engineering, Beijing Jiaotong University, Beijing, China; School of Electrical Engineering, Beijing Jiaotong University, Beijing, China","IEEE Access","18 Sep 2020","2020","8","","165099","165110","High impedance faults (HIFs) in distribution networks are hard to describe and be detected precisely because of the complexity and randomness of their features. Therefore, traditional feature analysis methods may lack sufficient reliability and generalization, which makes data-based methods a more appropriate option. However, according to previous statistical analyses, in practical scenarios, only a small quantity of historical HIF data (less than 20%) can be recorded and utilized. In this article, a transfer learning-based HIF detection method is proposed under a cloud-edge collaboration framework of the Internet of Things, which can solve the problem of insufficient data by integrating historical data from multiple distribution networks. Through the cloud-edge collaboration framework, all features from different distribution networks are first integrated to form a basic cloud convolutional neural network model for HIF detection. The features are extracted and updated by edge computers based on the accurate synchronous measurements provided by distribution-level phasor measurement units. To uniform the data scales of the different distribution networks, principal component analysis is adopted during feature extraction. Specific to each distribution network, the target HIF detection model is transferred from the basic cloud model by fine-tuning. Furthermore, a data augmentation method based on locality sensitive hashing is proposed to improve the performance of the transferred model. The proposed HIF detection method can be operated in both online and offline modes. The performance was verified by seven different distribution networks in numerical simulations and one practical experimental distribution network.","2169-3536","","10.1109/ACCESS.2020.3022639","National Key Research and Development Program of China(grant numbers:2017YFB0902800); Science and Technology Project of the State Grid Corporation of China(grant numbers:52094017003D); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9187881","High impedance faults;cloud-edge collaboration;distribution-level phasor measurement units;transfer learning","Cloud computing;Feature extraction;Collaboration;Data models;Computational modeling;Image edge detection;Protocols","","27","","35","CCBY","8 Sep 2020","","","IEEE","IEEE Journals"
"A Scalable and Secure Publish/Subscribe-Based Framework for Industrial IoT","M. Amoretti; R. Pecori; Y. Protskaya; L. Veltri; F. Zanichelli","Department of Engineering and Architecture, University of Parma, Parma, Italy; Department of Engineering, University of Sannio, Benevento, Italy; Maps Group, Parma, Italy; Department of Engineering and Architecture, University of Parma, Parma, Italy; Department of Engineering and Architecture, University of Parma, Parma, Italy","IEEE Transactions on Industrial Informatics","5 Mar 2021","2021","17","6","3815","3825","In the emerging industrial Internet of Things (IIoT) scenario, machine-to-machine communication is a key technology to set up environments, wherein sensors, actuators, and controllers can exchange information autonomously. However, many current communication frameworks do not provide enough dynamic interoperability and security. Hence, in this article, we propose a novel communication framework based on Message Queuing Telemetry Transport (MQTT) broker bridging, which, in an IIoT scenario, can foster dynamic interoperability across different production lines or industrial sites, guaranteeing, at the same time, a higher degree of isolation and control over the information flows, thereby increasing the overall security of the whole scenario. The solution we propose also supports dynamic authentication and authorization and has been practically implemented and evaluated in a proper small-scale IIoT testbed, encompassing PLCs, IIoT gateways, and MQTT brokers with novel and extended capabilities. The evaluation results demonstrate a linear time complexity for all the considered implementations and bridging modes of the extended brokers. Moreover, all considered access token encapsulation techniques demonstrate a minimum overhead in comparison with standard MQTT brokers.","1941-0050","","10.1109/TII.2020.3017227","Italian Ministry of University and Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9170891","Authentication;authorization;broker bridging;industrial Internet of Things (IIoT);Message Queuing Telemetry Transport (MQTT);security","Standards;Authentication;Production;Authorization;Informatics","","19","","28","IEEE","18 Aug 2020","","","IEEE","IEEE Journals"
"20.1 A 28µW IoT Tag That Can Communicate with Commodity WiFi Transceivers via a Single-Side-Band QPSK Backscatter Communication Technique","P. -H. P. Wang; C. Zhang; H. Yang; D. Bharadia; P. P. Mercier","Broadcom Inc., San Diego, CA; University of California, San Diego, La Jolla, CA; University of California, San Diego, La Jolla, CA; University of California, San Diego, La Jolla, CA; University of California, San Diego, La Jolla, CA","2020 IEEE International Solid-State Circuits Conference - (ISSCC)","13 Apr 2020","2020","","","312","314","Nearly all IoT devices require wireless connectivity, and to keep costs down and deployment opportunities up, communication should ideally occur with widely deployed commodity hardware such as WiFi. However, conventional WiFi transceivers (TRXs) require 10s to 100s of mW of active power. As a result, nearly all current WiFi-compatible IoT devices require either wall power, or large/frequently re-charged batteries (Fig. 20.1.1, left). While other standards such as BLE may require less power, very low power (<; <; 1mW) is only achievable at very low throughputs via duty-cycling; and yet, despite low average power, very small coin cell batteries or energy harvesters cannot be used due to still relatively high peak-power requirements (e.g., a few mW for BLE), thereby limiting new products to certain minimum device sizes. More importantly, standards such as BLE do not have widely distributed infrastructure in most homes, offices, or other environments, making rapid low-cost deployment difficult. To enable a new class of miniaturized, battery-powered or energy-harvested IoT devices, backscatter communication, where an incident RF source is reflected via a low-power impedance modulating tag, has been proposed [1]. However, most current solutions rely on custom tone generators [1], [2], and thus cannot be rapidly deployed at scale with low cost. To enable operation with existing infrastructure, recent work has shown that already-pervasive WiFi signals can be used as incident RF sources for backscattering, and through techniques such as codeword translation, commodity WiFi RXs can be used to receive backscattered data [3]. However, this prior art required a WiFi RF source (like a smartphone) within 6m of the tag, and two separate WiFi readers within 8m (Fig. 20.1.1, middle). More importantly, to date, there has not been any practical backscatter systems developed with low-power electronics to demonstrate the low-power potential of WiFi-based backscattering.","2376-8606","978-1-7281-3205-1","10.1109/ISSCC19947.2020.9063133","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9063133","","Wireless fidelity;Backscatter;Amplitude modulation;Frequency modulation;Phase shift keying;Wireless communication","","7","","5","IEEE","13 Apr 2020","","","IEEE","IEEE Conferences"
"An Elastic IoT Device Management Platform","R. D. Murthy; M. Liu","School of Electronic Engineering, Dublin City University, Dublin, Ireland; School of Electronic Engineering, Dublin City University, Dublin, Ireland","2020 IEEE Global Conference on Artificial Intelligence and Internet of Things (GCAIoT)","9 Feb 2021","2020","","","1","6","With the recent advancement of technologies over the past year, IoT has become a paradigm in which devices communicate with each other and the cloud to achieve various applications in multidisciplinary fields. However, developing, deploying, and experimenting with IoT applications are still tedious, expensive, and time-consuming due to the factors like heterogeneity of hardware and software. This is where an IoT testbed plays a vital role in aiding developers to test their applications without being deploying it to the target environment. In this paper, we present a testbed that is scalable for heterogeneous devices and mainly focused on a small scale and medium scale IoT application. This testbed would be best suited for testing applications which demand robust nature, remote monitoring and control, incorporation of heterogeneous devices, location tracking of devices, and easy troubleshooting with security and internet connectivity concerns. This testbed is also embraced with the feature to work limit access to the internet. A detailed explanation of the design and architecture of the proposed testbed is provided. We also present a conceptual prototype of the testbed and the results obtained on experimenting under various conditions.","","978-1-7281-8420-3","10.1109/GCAIoT51063.2020.9345907","Dublin City University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9345907","IoT;Testbed;Edge Computing;Fog Computing","Target tracking;Software architecture;Prototypes;Computer architecture;Hardware;Internet of Things;Testing","","","","16","IEEE","9 Feb 2021","","","IEEE","IEEE Conferences"
"Secure and Cost-Effective Micro Phasor Measurement Unit (PMU)-Like Metering for Behind-the-Meter (BTM) Solar Systems using Blockchain-Assisted Smart Inverters","A. A. Hadi; G. Bere; T. Kim; J. J. Ochoa; J. Zeng; G. -S. Seo","Electrical Engineering and Computer Science, Texas A&M University-Kingsville, Kingsville, USA; Electrical Engineering and Computer Science, Texas A&M University-Kingsville, Kingsville, USA; Electrical Engineering and Computer Science, Texas A&M University-Kingsville, Kingsville, USA; Electrical Engineering and Computer Science, Texas A&M University-Kingsville, Kingsville, USA; Electrical and Computer Engineering and Technology, Minnesota State University, Mankato, USA; Power Systems Engineering Center, National Renewable Energy Laboratory, Golden, USA","2020 IEEE Applied Power Electronics Conference and Exposition (APEC)","25 Jun 2020","2020","","","2369","2375","Recently, there is increasing interest in using behind-the-meter (BTM) solar systems for grid services. However, providing visibility and operational situational awareness of BTM solar systems mainly operated by small-scale solar inverters is challenging due to the requirement of relatively expansive networked observation tools (e.g., micro phasor measurement units (µPMUs)) and consequent cybersecurity threats through networks. This paper presents a secure, cost-effective, µPMUs-like metering method using a blockchain-assisted smart (BAS) inverters for a BTM solar system. The proposed BAS inverter consisting of an internet of things device as a node of a local blockchain network enables the secure provision of inverter measurement data for grid services. The BAS inverter sends the encrypted local measurement data with a timestamp to a local blockchain miner. Once the blockchain miner generates a tamper-resistant metering ledger including the measurements, it is used to assess the situational awareness of the BTM solar system. The concept of the proposed metering using the BAS inverters is validated by experimental studies.","2470-6647","978-1-7281-4829-8","10.1109/APEC39645.2020.9124385","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9124385","behind the meter;blockchain;cybersecurity;smart inverter;micro phasor measurement unit","Conferences;Estimation;Inverters;Phasor measurement units;Solar system;Blockchains;Synchronization","","9","","24","IEEE","25 Jun 2020","","","IEEE","IEEE Conferences"
"UAV-Assisted Wireless Information and Power Transfer for Self-Sustained IoT Communications","A. Prathima; D. S. Gurjar; S. Yadav; D. Krstic; N. Milosevic; J. Jokovic","Department of Electronics and Communication Engineering, National Institute of Technology Silchar, Silchar, Assam, India; Department of Electronics and Communication Engineering, National Institute of Technology Silchar, Silchar, Assam, India; Department of Electronics and Communications Engineering, Indian Institute of Information Technology Allahabad, Prayagraj, India; Faculty of Electronic Engineering, University of Niš, Niš, Serbia; Faculty of Electronic Engineering, University of Niš, Niš, Serbia; Faculty of Electronic Engineering, University of Niš, Niš, Serbia","IEEE Sensors Journal","14 Dec 2022","2022","22","24","24593","24606","This article investigates the performance of an unmanned aerial vehicle (UAV)-assisted wireless power transfer (WPT)-enabled communications for energy-constrained wireless devices. Herein, a UAV serves as a radio frequency (RF) energy harvesting (EH) transmitter for a pair of Internet-of-Things devices (IoDs). It also provides relay cooperation to IoDs using decode-and-forward (DF) operation. The composite fading channels associated with the UAV and IoDs are modeled by considering the probability of line-of-sight (LoS)/non-LoS (NLoS) and shadowing components, assuming log-normal distribution. Besides, the small-scale fading scenarios for LoS and NLoS communications are assumed to follow Nakagami- ${m}$  and Rayleigh distributions, respectively. In addition, considering relative mobility between the UAV and IoDs, we exploit the first-order autoregressive process to model the fading channels during the information transmission (IT) phase. For such a realistic system setup, we derive the expressions for the outage probability (OP) at the IoDs using Gauss-Hermite quadrature under different shadowing and fading channel combinations. The system throughput and energy efficiency are also quantified using the derived OP expressions. The analytical findings are verified through numerical and simulation results. Our results highlight the impact of various system/channel parameters on the system’s performance and provide significant insights into the system’s behavior.","1558-1748","","10.1109/JSEN.2022.3218269","India–Serbia Scientific and Technological Cooperation Program between the Department of Science and Technology (DST), Ministry of Science and Technology of the Republic of India, and the Ministry of Education, Science and Technological Development (MESTD) of the Republic of Serbia(grant numbers:DST/INT/Serbia/P-04/2022); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9939704","Composite fading channels;Internet-of-Things (IoT) systems;outage probability (OP);unmanned aerial vehicle (UAV)-assisted communication;wireless power transfer (WPT)","Fading channels;Wireless sensor networks;Energy efficiency;Wireless communication;Trajectory;Throughput;Shadow mapping","","3","","58","IEEE","4 Nov 2022","","","IEEE","IEEE Journals"
"Dynamic Task Division and Allocation in Mobile Edge Computing Systems: A Latency Oriented Approach via Deep Q-Learning Network","P. Tan; Y. Li; M. Dai; Y. Wu","State Key Laboratory of Internet of Things for Smart City, University of Macau, Macau, China; State Key Laboratory of Internet of Things for Smart City, University of Macau, Macau, China; State Key Laboratory of Internet of Things for Smart City, University of Macau, Macau, China; State Key Laboratory of Internet of Things for Smart City, University of Macau, Macau, China","2022 IEEE 23rd International Conference on High Performance Switching and Routing (HPSR)","22 Jul 2022","2022","","","252","259","With the rapid development of Internet of Things (IoTs), various sensors are deployed to collect different physical information. Smart surveillance is one of applications by analyzing the real-time video generated by camera sensors. However, due to the limited computing capability of camera sensors, running video analysis models (e.g., AlexNet and YOLO3) on camera sensors directly consumes a lot of computing time. In addition, transferring video to the remote cloud suffers a long-distance transmission latency. Fortunately, edge computing has been considered as a promising solution for enabling computation-intensive yet latency-sensitive applications at resource-constrained devices. Thanks to edge computing, camera sensors can upload video to different edge servers employed at the edge of networks for processing. Moreover, the lightweight Kubernetes for edge computing, i.e., K3s, enable a fine-grained task division and parallel computing. In this paper, we consider a heterogeneous edge cooperative video analysis, i.e., face recognition, with the objective of minimizing the processing latency. Specifically, we use a Deep Q-Learning network (DQN) to dynamically adjust the size of pieces video allocated to different edge servers connected via wireless networks. In addition, to improve the resource utilization of edge servers and reduce the processing latency, each edge server further divides the received video into multiple segments that are processed by different containers in parallel. To validate the effectiveness of our scheme, we implement a small-scale prototype system and conduct numerous experiments. Experimental results show that our proposed algorithm outperforms the other four schedule schemes by testing on the tasks of face recognition and pose recognition.","2325-5609","978-1-6654-0607-9","10.1109/HPSR54439.2022.9831237","National Natural Science Foundation of China; Science and Technology Development Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9831237","Computing resources;Task execution time;Edge intelligence;Task division;Deep learning","Q-learning;Face recognition;Wireless networks;Streaming media;Cameras;Resource management;Servers","","","","30","IEEE","22 Jul 2022","","","IEEE","IEEE Conferences"
"6LoFD: A Failure Detector for 6LoWPAN","P. Raich; W. Kastner","Institute of Computer Engineering, TU Wien, Vienna, Austria; Institute of Computer Engineering, TU Wien, Vienna, Austria","2022 IEEE 8th World Forum on Internet of Things (WF-IoT)","22 Jun 2023","2022","","","1","6","Failure Detectors (FDs) are a prominent building block for various consensus/agreement protocols in asynchronous systems, and one of several ways to overcome the theoretical limitation stemming from the impossibility result. With the increasing use of asynchronous, wireless Internet of Things (IoT) technologies such as IEEE 802.15.4/6LoWPAN, the demand of applications that require some form of reliability and agreement are on the rise. Yet practical implementations of FDs are less visible, and to our knowledge, entirely unavailable for the IEEE 802.15.4/6LoWPAN-stack until recently. We already presented 6LoFD, an FD specifically aimed at energy and memory efficient operation in small scale, unreliable networks. In this work we are able to validate key findings of our initial presentation, but also improve on some identified shortcomings of our preliminary evaluations. We further show significantly broadened evaluation results and related insights.","","978-1-6654-9153-2","10.1109/WF-IoT54382.2022.10152256","TU Wien; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10152256","6LoWPAN;failure detector;agreement;reliability;LLN;IoT","IEEE 802.15 Standard;Wireless communication;Protocols;Memory management;Detectors;Reliability theory;Internet of Things","","","","10","IEEE","22 Jun 2023","","","IEEE","IEEE Conferences"
"Greedy Behavior Detection With Machine Learning for LoRaWAN Network","M. Chen; J. Ben-Othman; L. Mokdad","Univ Paris Est Creteil, LACL, Creteil, France; CNRS, CentraleSupélec Lab. L2S, Univ Paris-Saclay, Gif-sur-Yvette, France; Univ Paris Est Creteil, LACL, Creteil, France","IEEE Transactions on Network and Service Management","","2024","PP","99","1","1","LoRaWAN (Long Range Wide Area Network) has garnered significant attention within the Internet of Things (IoT) due to its ability to establish a wireless network with massive devices over long distances while minimizing energy consumption. Our previous work shows its suitability for Intelligent Transportation Systems (ITS) scenarios. However, the utilization of the Aloha MAC protocol presents a challenge for LoRaWAN as it grapples with the presence of compromised nodes. These nodes may engage in greedy behaviors, disregarding network regulations to enhance their own performance or acquire additional network resources, and are often difficult to detect. This research contributes to machine learning-based greedy behavior detection methods. After proposing several end-to-end (E2E) methods with different ML algorithms, EDLoG (Encoder-based detection method of LoRaWAN Greedy behaviors) is proposed. It is a greedy behavior detection method combining a Multilayer Perceptron (MLP) encoder network and a statistical abnormal detection algorithm. The performance evaluations are conducted using simulation data under different scenarios given by MELoNS, a Modular and Extendable Simulator for the LoRaWAN Network developed in our previous work. The results show that the proposed method gives a detection recall 15%-20% higher than the baseline method by keeping a high detection precision. Moreover, the proposed methods show high timing efficiency with a running time much smaller than LoRaWAN’s time scale, making the method easily deployed to a real LoRaWAN network.","1932-4537","","10.1109/TNSM.2024.3351313","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10384417","Internet of Things (IoT);LoRaWAN;Security;Machine Learning;Greedy behavior;Malicious detection","Behavioral sciences;Resource management;Timing;Machine learning algorithms;Protocols;Packet loss;Internet of Things","","","","","IEEE","8 Jan 2024","","","IEEE","IEEE Early Access Articles"
"AoI Aware VNF Scheduling with Parallel Transmission for Delay-Sensitive Applications","L. Yu; L. Qu","Faculty of EECS, Ningbo University, Ningbo, China; Faculty of EECS, Ningbo University, Ningbo, China","2022 IEEE 24th Int Conf on High Performance Computing & Communications; 8th Int Conf on Data Science & Systems; 20th Int Conf on Smart City; 8th Int Conf on Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys)","28 Mar 2023","2022","","","1382","1387","For delay-sensitive network services, Age of Information (AoI) is appropriate to represent the freshness of information. Meanwhile, with the joint development of Network Function Virtualization (NFV) and Software Defined Network (SDN) technology, these network services can be managed as Service Function Chains (SFCs), composed of a collection of Virtual Network Functions (VNFs). Because the standard SFC architectures have been challenging to accommodate the low AoI demand for information in new scenarios like the Industrial Internet of Things (IIoT) and telemedicine, new SFC structures are constantly being proposed. In this paper, AoI is minimized by utilizing parallel paths to forward data between VNF instances. We formulate it as an Integer Linear Programming (ILP) problem. Moreover, a heuristic algorithm based on Particle Swarm Optimization (PSO) is proposed to solve it in large-scale networks. According to the simulation results analysis, our strategy can reduce the overall AoI of flows by at least 15% when compared to the conventional SFC architectures.","","979-8-3503-1993-4","10.1109/HPCC-DSS-SmartCity-DependSys57074.2022.00214","Ningbo Natural Science Foundation(grant numbers:2021J070); National Natural Science Foundation of China(grant numbers:61801254); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10074810","age of information;particle swarm optimization;VNF scheduling","Job shop scheduling;Smart cities;Service function chaining;Simulation;Telemedicine;Computer architecture;Routing","","","","15","IEEE","28 Mar 2023","","","IEEE","IEEE Conferences"
"Verifiable Data Mining Against Malicious Adversaries in Industrial Internet of Things","Z. Ma; J. Ma; Y. Miao; X. Liu; K. -K. R. Choo; Y. Gao; R. H. Deng","School of Cyber Engineering and the Shaanxi Key Laboratory of Network and System Security, Xidian University, Xi’an, China; School of Cyber Engineering and the Shaanxi Key Laboratory of Network and System Security, Xidian University, Xi’an, China; School of Cyber Engineering and the Shaanxi Key Laboratory of Network and System Security, Xidian University, Xi’an, China; Key Laboratory of Information Security of Network Systems, College of Mathematics and Computer Science, Fuzhou University, Fuzhou, China; Department of Information Systems and Cyber Security, The University of Texas at San Antonio, San Antonio, TX, USA; School of Cyber Engineering and the Shaanxi Key Laboratory of Network and System Security, Xidian University, Xi’an, China; School of Information Systems, Singapore Management University, Singapore, Singapore","IEEE Transactions on Industrial Informatics","29 Oct 2021","2022","18","2","953","964","With the large-scaled data generated from various interconnected machines and networks, Industrial Internet of Things (IIoT) provides unprecedented opportunities for facilitating data mining for industrial applications. The current IIoT architecture tends to adopt cloud computing for further timely mining IIoT data, however, the openness of security-critical IIoT becomes challenging in terms of unbearable privacy issues. Most existing privacy-preserving data mining (PPDM) techniques are designed to resist honest-but-curious adversaries (i.e., cloud servers and data users). Due to the complexity and openness in IIoT, PPDM is significantly difficult with the presence of malicious adversaries in IIoT who may incur incorrect learned models and inference results. To solve the aforementioned issues, we propose a framework to extend existing PPDM to guard linear regression against malicious behaviors (hereafter referred to as GuardLR). To prevent dishonest computations of cloud servers and inconsistent inputs of data users, we first design a privacy-preserving verifiable learning scheme for linear regression, which guarantees the correctness of learning. In this article, to avoid malicious clouds from returning incorrect inference results, we design a privacy-preserving prediction scheme with lightweight verification. Our formal security analysis shows that GuardLR achieves privacy, completeness, and soundness. Empirical experiments using real-world datasets also demonstrate that GuardLR has high computational efficiency and accuracy.","1941-0050","","10.1109/TII.2021.3077005","National Natural Science Foundation of China(grant numbers:62072361,62072109,U1804263,62072352); Key R&D Program of Shaanxi Province(grant numbers:2019ZDLGY12-04,2020ZDLGY09-06); Fundamental Research Funds for the Central Universities(grant numbers:JB211505); Guangxi Key Laboratory of Cryptography and Information Security(grant numbers:GCIS201917); Guangxi Key Laboratory of Trusted Software(grant numbers:KX202028); CCF-Tencent Open Fund WeBank Special Funding(grant numbers:20200102); CCF-NSFOCUS Kunpeng Research Fund(grant numbers:CCF-NSFOCUS 20200004); Hong Kong Scholar Program(grant numbers:XJ2019038); Henan Key Laboratory of Network Cryptography Technology(grant numbers:LNCT2020-A06); China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9422191","Industrial Internet of Things (IIoT);linear regression (LR);malicious adversaries;privacy-preserving;verifiable","Industrial Internet of Things;Servers;Cloud computing;Cryptography;Training;Computational modeling;Informatics","","9","","31","IEEE","3 May 2021","","","IEEE","IEEE Journals"
"NetBooster: Empowering Tiny Deep Learning By Standing on the Shoulders of Deep Giants","Z. Yu; Y. Fu; J. Yuan; H. You; Y. C. Lin",Georgia Institute of Technology; Georgia Institute of Technology; Rice University; Georgia Institute of Technology; Georgia Institute of Technology,"2023 60th ACM/IEEE Design Automation Conference (DAC)","15 Sep 2023","2023","","","1","6","Tiny deep learning has attracted increasing attention driven by the substantial demand for deploying deep learning on numerous intelligent Internet-of-Things devices. However, it is still challenging to unleash tiny deep learning’s full potential on both large-scale datasets and downstream tasks due to the under-fitting issues caused by the limited model capacity of tiny neural networks (TNNs). To this end, we propose a framework called NetBooster to empower tiny deep learning by augmenting the architectures of TNNs via an expansion-then-contraction strategy. Extensive experiments show that NetBooster consistently outperforms state-of-the-art tiny deep learning solutions.","","979-8-3503-2348-1","10.1109/DAC56929.2023.10247827","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10247827","Tiny Neural Networks;Efficient Deep Learning","Deep learning;Training;Design automation;Neural networks;Boosting;Task analysis","","","","31","IEEE","15 Sep 2023","","","IEEE","IEEE Conferences"
"LEO Satellite Constellation for Global-Scale Remote Sensing With On-Orbit Cloud AI Computing","Y. Li; M. Wang; K. Hwang; Z. Li; T. Ji","Chinese University of Hong Kong, (Shenzhen); Wuhan University, Wuhan, China; Chinese University of Hong Kong, (Shenzhen); Chinese University of Hong Kong, (Shenzhen); Chinese Academy of Sciences, Dongguan, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","20 Oct 2023","2023","16","","9369","9381","This article proposes a new satellite-based framework for global-scale remote sensing that is integrated with on-orbit cloud computing and artificial intelligence (AI) services. These spaced-based services cover the entire earth surfaces using massive low earth orbit (LEO) satellite constellation. Global-scale sensing of earth resources must be supported by massive number of LEO satellites equipped with cloud/AI computing services in real time. New satellite computer architectural features are presented along with some satellite constellation deployment topologies. We design satellite-based computers to support on-orbit remote sensing and AI scene analysis. This demands real-time performance without transmitting the sensed data back to earth for delayed processing. Notable space data services include on-orbit data sensing of large areas, machine learning from earth resources data, earth scene/event analysis, geomorphology observation, smart city management, disaster relief, global healthcare Internet of Things, environmental ecology protection, etc. We attempt to achieve high-efficiency earth resources utilization along with green energy, low cost, and robustness in real-life services.","2151-1535","","10.1109/JSTARS.2023.3316298","National Key Research and Development Program of Ministry of Science and Technology(grant numbers:2022YFB3902804); National Natural Science Foundation of China(grant numbers:61825103); Shenzhen Institute of Artificial Intelligence and Robotics for Society(grant numbers:BN00202309021); National Foreign Experts Program(grant numbers:G2022032011L); National Natural Science Foundation of China(grant numbers:62202410); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2021A1515110353); Shenzhen Science and Technology Program(grant numbers:JCYJ20220530143808019); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10254243","Cloud/Internet of Things (IoT) computing;low earth orbit (LEO) satellites;remote sensing;telecommunication","Satellites;Cloud computing;Remote sensing;Low earth orbit satellites;Satellite broadcasting;Space vehicles;Task analysis;Artificial intelligence","","","","48","CCBYNCND","18 Sep 2023","","","IEEE","IEEE Journals"
"Distributed Localization of Networked Agents in GPS-Denied 3D Environments","Y. Xia; C. He; C. Yu","School of Automation, Beijing Institute of Technology, Beijing, P. R. China; School of Automation, Beijing Institute of Technology, Beijing, P. R. China; School of Automation, Beijing Institute of Technology, Beijing, P. R. China","2021 40th Chinese Control Conference (CCC)","6 Oct 2021","2021","","","5735","5740","This paper studies the distributed localization of networked agents using only distance measurements in a GPS-Denied 3D environment, which extends the existing results to the 3D localization in the presence of measurement noise and greatly improves its applications in internet of things. To deal with the distributed 3D localization, the barycentric coordinates of an agent in a tetrahedron are introduced by employing the Cayley-Menger determinants, which enables the localization problem of networked agents to be equivalently transformed into a linear estimation problem. Then, a recursive estimation algorithm is developed under the Jacobi Over-Relaxation (JOR) framework which recursively solves the linear estimation problem in a distributed manner; as a result, the proposed method can be scaled to the localization of large-scale networked agents. Finally, a simulation example is given to show the effectiveness of the proposed algorithm.","1934-1768","978-9-8815-6380-4","10.23919/CCC52363.2021.9550474","National Natural Science Foundation of China; Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9550474","Networked agents;barycentric coordinates;distributed localization;GPS-denied environment","Location awareness;Jacobian matrices;Three-dimensional displays;Heuristic algorithms;Estimation;Distance measurement;Reliability","","","","18","","6 Oct 2021","","","IEEE","IEEE Conferences"
"Client-Transparent and Self-Managed MQTT Broker Federation at the Application Layer","J. F. d. L. Machado; M. A. Spohn; L. Z. Granville","Institute of Informatics - Federal University of Rio Grande do Sul, Porto Alegre, Brazil; Federal University of Fronteira Sul, Chapecó, Brazil; Institute of Informatics - Federal University of Rio Grande do Sul, Porto Alegre, Brazil","2023 International Conference on Computing, Networking and Communications (ICNC)","23 Mar 2023","2023","","","603","607","The use of IoT devices for monitoring and automation became very disseminated. Also, and as a consequence, IoT scalability issues evolved into one of the main challenges on large deployments. One of the most adopted architectures for the communication between IoT devices and other information systems is based on the Publish/Subscribe paradigm, mainly embraced by MQTT-capable devices. Some implementations aimed to solve scalability challenges on those environments, mainly using clustering solutions, while a few considered federation approaches. Existing solutions are predominantly proprietary, lacking public documentation, and may be considered incipient. In the present work, we propose a client-transparent and self-managed solution for scaling MQTT brokers using federation approach through a python-written wrapper, providing federation functionalities and message routing without customization of regular brokers. While clustering solutions usually target throughput improvement, the federation approach explores higher availability through distributed architecture. We present a validation to expose our solution’s flexible availability and its capability to deal with topology change issues.","","978-1-6654-5719-4","10.1109/ICNC57223.2023.10074556","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10074556","","Overlay networks;Scalability;Prototypes;Quality of service;Throughput;Routing;Topology","","","","14","IEEE","23 Mar 2023","","","IEEE","IEEE Conferences"
"Distributed Decision Fusion for Large Scale IoT- Ecosystem","A. Raut; D. Kumar; V. K. Chaurasiya; M. Kumar","Department of IT, IIIT-Allahabad, Allahabad, India; Department of IT, IIIT-Allahabad, Allahabad, India; Department of IT, IIIT-Allahabad, Allahabad, India; Department of IT, IIIT-Allahabad, Allahabad, India","2022 IEEE 15th International Symposium on Embedded Multicore/Many-core Systems-on-Chip (MCSoC)","16 Jan 2023","2022","","","112","119","IoT data analytics have numerous applications that generate huge data to gain new insights and information. How-ever, this work remains challenging due to the heterogeneity of IoT data sources, unnecessary data processing, uncertainty in decision-making, data biasness, and ever-increasing data size. To overcome these challenges, we propose distributed decision fusion framework for the large-scale IoT ecosystem. The proposed framework has divided into three-level. The first and second level provides the local decision of the small individual ecosystem using the filter method-based feature selection and dynamic classifier selection criteria for decision making; whereas the third level fuses the collected decision from the small ecosystems using Majority voting, Weighted majority voting and distributed Naive Bayes classifier. Lastly, we illustrate performance of the proposed solution on the US-Accidents dataset.","2771-3075","978-1-6654-6499-4","10.1109/MCSoC57363.2022.00027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10008471","Distributed decision fusion;centralized data processing;large scale IoT ecosystem;ensemble techniques","Uncertainty;Data analysis;Multicore processing;Fuses;Soft sensors;Ecosystems;Decision making","","1","","14","IEEE","16 Jan 2023","","","IEEE","IEEE Conferences"
"A Heterogeneous In-Memory Computing Cluster for Flexible End-to-End Inference of Real-World Deep Neural Networks","A. Garofalo; G. Ottavi; F. Conti; G. Karunaratne; I. Boybat; L. Benini; D. Rossi","Department of Electrical, Electronic and Information Engineering (DEI), University of Bologna, Bologna, Italy; Department of Electrical, Electronic and Information Engineering (DEI), University of Bologna, Bologna, Italy; Department of Electrical, Electronic and Information Engineering (DEI), University of Bologna, Bologna, Italy; IBM Research Europe, Zürich, Switzerland; IBM Research Europe, Zürich, Switzerland; Department of Electrical, Electronic and Information Engineering (DEI), University of Bologna, Bologna, Italy; Department of Electrical, Electronic and Information Engineering (DEI), University of Bologna, Bologna, Italy","IEEE Journal on Emerging and Selected Topics in Circuits and Systems","13 Jun 2022","2022","12","2","422","435","Deployment of modern TinyML tasks on small battery-constrained IoT devices requires high computational energy efficiency. Analog In-Memory Computing (IMC) using non-volatile memory (NVM) promises major efficiency improvements in deep neural network (DNN) inference and serves as on-chip memory storage for DNN weights. However, IMC’s functional flexibility limitations and their impact on performance, energy, and area efficiency are not yet fully understood at the system level. To target practical end-to-end IoT applications, IMC arrays must be enclosed in heterogeneous programmable systems, introducing new system-level challenges which we aim at addressing in this work. We present a heterogeneous tightly-coupled clustered architecture integrating 8 RISC-V cores, an in-memory computing accelerator (IMA), and digital accelerators. We benchmark the system on a highly heterogeneous workload such as the Bottleneck layer from a MobileNetV2, showing  $11.5\times $  performance and  $9.5\times $  energy efficiency improvements, compared to highly optimized parallel execution on the cores. Furthermore, we explore the requirements for end-to-end inference of a full mobile-grade DNN (MobileNetV2) in terms of IMC array resources, by scaling up our heterogeneous architecture to a multi-array accelerator. Our results show that our solution, on the end-to-end inference of the MobileNetV2, is one order of magnitude better in terms of execution latency than existing programmable architectures and two orders of magnitude better than state-of-the-art heterogeneous solutions integrating in-memory computing analog cores.","2156-3365","","10.1109/JETCAS.2022.3170152","European Union Horizon 2020 Research and Innovation projects WiPLASH(grant numbers:863337,European Pilot 101034126); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9764758","In-memory computing;RISC-V;heterogeneous computing architecture;MobileNetV2","Random access memory;Energy efficiency;Nonvolatile memory;Computational efficiency;Neural networks;Task analysis;Phase change materials","","17","","51","IEEE","28 Apr 2022","","","IEEE","IEEE Journals"
"Placement and Chaining for Run-Time IoT Service Deployment in Edge-Cloud","D. T. Nguyen; C. Pham; K. K. Nguyen; M. Cheriet","??cole de technologie sup??rieure, University of Quebec, Montreal, Canada; ??cole de technologie sup??rieure, University of Quebec, Montreal, Canada; ??cole de technologie sup??rieure, University of Quebec, Montreal, Canada; ??cole de technologie sup??rieure, University of Quebec, Montreal, Canada","IEEE Transactions on Network and Service Management","11 Mar 2020","2020","17","1","459","472","This paper investigates an efficient placement and chaining of Virtual Network Functions (VNFs) to provide cloud based IoT services with minimal resource usage cost. We take into account bandwidth capacity and link delay of network connection between clouds where VNFs are allocated and underlying IoT networks where sensors and IoT gateways are deployed. Regarding the constantly changing network dynamics, input traffic of service components is considered at the lower granularity level of messages based on the communication between each VNF and corresponding sensors via IoT gateways. From the algorithm perspective, the specific topology of multiple edge clouds is leveraged to improve the solution. In this paper, we present an NFV-based high-level architecture for a system that enables the deployment of IoT services across multiple edges and clouds. We formulate the VNF placement problem using a non-convex Integer Programming model. Taking into account different IoT topologies, we devise two algorithms for small- and large-scale networks to find the near optimal solution: i) a customized Markov approximation with two techniques, i.e., multi-start and batching, and a node ranking-based heuristic. Simulation and experimental results show that the proposed solution improves the cost up to 21% compared to state-of-the-art schemes.","1932-4537","","10.1109/TNSM.2019.2948137","Natural Sciences and Engineering Research Council of Canada(grant numbers:CRDPJ 469977); Canada Research Chair, Tier 1, hold by Mohamed Cheriet; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8873640","VNF placement;service function chain;IoT services;edge/cloud computing;QoS","Internet of Things;Cloud computing;Logic gates;Sensors;Delays;Network topology;Optimization","","29","","24","IEEE","17 Oct 2019","","","IEEE","IEEE Journals"
"Can Commercial Testing Automation Tools Work for IoT? A Case Study of Selenium and Node-Red","N. Varghese; R. Sinha","IT & Software Engineering Auckland University of Technology, Auckland, New Zealand; IT & Software Engineering Auckland University of Technology, Auckland, New Zealand","IECON 2020 The 46th Annual Conference of the IEEE Industrial Electronics Society","18 Nov 2020","2020","","","4519","4524","Background: Testing IoT software is challenging due to large scale, volume of data and heterogeneity. Testing automation is a much-needed feature in the domain.A ims: The first goal of this research is to explore the requirements and challenges of IoT testing automation. The second goal is to integrate testing automation tools used in commercial software into the IoT context. Method: A systematic literature review is carried out to elicit requirements for testing automation in IoT. A design science approach is followed to build a testing automation tool for IoT applications written in the Node-Red platform, using the commercial testing automation tool Selenium. The resulting framework uses the Selenium Web Driver for browser-based testing automation for IoT applications. Results: The proposed framework has been functionally tested on multiple browsers with preliminary evaluation on maintainability, browser capability and comprehensiveness. Conclusions: The use of commercial tools for testing automation in IoT is feasible. However, major challenges like high data volumes and parallel transmission and processing of data need to be addressed comprehensively for complete integration.","2577-1647","978-1-7281-5414-5","10.1109/IECON43393.2020.9254910","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9254910","Internet of Things;IoT reference architecture;automated testing;Selenium;testing automation","Testing;Internet of Things;Software;Automation;Computer architecture;Selenium;Tools","","1","","20","IEEE","18 Nov 2020","","","IEEE","IEEE Conferences"
"Flexible Pressure Sensor Based on Molybdenum Diselide/Multi-Walled Carbon Nanotubes for Human Motion Detection","J. Guan; D. Zhang; T. Li","College of Control Science and Engineering, China University of Petroleum (East China), Qingdao, China; College of Control Science and Engineering, China University of Petroleum (East China), Qingdao, China; College of Control Science and Engineering, China University of Petroleum (East China), Qingdao, China","IEEE Sensors Journal","5 Apr 2021","2021","21","9","10491","10497","In recent years, with the rapid development of artificial intelligence and Internet of Things, flexible pressure sensors are attracting more and more attentions. Because the flexible pressure sensor has good flexibility, the sensor can be attached to the surface of the human skin as well as the surface of the object with complex structure. In the text, we used molybdenum diselide (MoSe2)/multi-walled carbon nanotubes (MWNTs) as the sensing element, using polydimethylsiloxane (PDMS) stripped from sandpaper as the substrate, preparing a pressure sensor with a microscopic surface structure that is rough. This whole production process was simple, economical and could be used for large-scale production. MoSe2/MWNTs pressure sensors offer compelling performance, including fast response (~150 ms), good repeatability (~10000 cycles), and a large operating range (0-30 kPa). Not only could it detect large human movements in real time, such as finger bending, walking, running, and swallowing, but also could detect subtle human movements such as coughing, gargling, and breathing. All results indicated that MoSe2/MWNTs-based pressure sensors were promising candidates for medical monitoring and artificial intelligence wearable device applications, and could also be potential candidates for human-computer interaction systems.","1558-1748","","10.1109/JSEN.2021.3060425","National Natural Science Foundation of China(grant numbers:51777215); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9358201","Wearable pressure sensor;carbon nanotubes;molybdenum selenide;flexible device;human motion detection","Sensors;Pressure sensors;Surface roughness;Rough surfaces;Surface morphology;Substrates;Sensitivity","","14","","47","IEEE","19 Feb 2021","","","IEEE","IEEE Journals"
"ProvLight: Efficient Workflow Provenance Capture on the Edge-to-Cloud Continuum","D. Rosendo; M. Mattoso; A. Costan; R. Souza; D. Pina; P. Valduriez; G. Antoniu","CNRS, IRISA, University of Rennes, Inria, Rennes, France; Federal University of Rio de Janeiro, Brazil; CNRS, IRISA, University of Rennes, Inria, Rennes, France; Oak Ridge National Laboratory, USA; Federal University of Rio de Janeiro, Brazil; CNRS, LIRMM, University of Montpellier, Inria, Montpellier, France; CNRS, IRISA, University of Rennes, Inria, Rennes, France","2023 IEEE International Conference on Cluster Computing (CLUSTER)","21 Nov 2023","2023","","","221","233","Modern scientific workflows require hybrid infrastructures combining numerous decentralized resources on the IoT/Edge interconnected to Cloud/HPC systems (aka the Computing Continuum) to enable their optimized execution. Understanding and optimizing the performance of such complex Edge-to-Cloud workflows is challenging. Capturing the provenance of key performance indicators, with their related data and processes, may assist in understanding and optimizing workflow executions. However, the capture overhead can be prohibitive, particularly in resource-constrained devices, such as the ones on the IoT/Edge.To address this challenge, based on a performance analysis of existing systems, we propose ProvLight, a tool to enable efficient provenance capture on the IoT/Edge. We leverage simplified data models, data compression and grouping, and lightweight transmission protocols to reduce overheads. We further integrate ProvLight into the E2Clab framework to enable workflow provenance capture across the Edge-to-Cloud Continuum. This integration makes E2Clab a promising platform for the performance optimization of applications through reproducible experiments.We validate ProvLight at a large scale with synthetic workloads on 64 real-life IoT/Edge devices in the FIT IoT LAB testbed. Evaluations show that ProvLight outperforms state-of-the-art systems like ProvLake and DfAnalyzer in resource-constrained devices. ProvLight is 26—37x faster to capture and transmit provenance data; uses 5—7x less CPU; 2x less memory; transmits 2x less data; and consumes 2—2.5x less energy. ProvLight [1] and E2Clab [2] are available as open-source tools.","2168-9253","979-8-3503-0792-4","10.1109/CLUSTER52292.2023.00026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10319957","Provenance;Lineage;Workflows;Edge;IoT;Computing Continuum","Protocols;Memory management;Key performance indicator;Data compression;Cluster computing;Data models;Performance analysis","","","","70","IEEE","21 Nov 2023","","","IEEE","IEEE Conferences"
"BoSMoS: A Blockchain-Based Status Monitoring System for Defending Against Unauthorized Software Updating in Industrial Internet of Things","S. He; W. Ren; T. Zhu; K. -K. R. Choo","School of Computer Science, China University of Geosciences, Wuhan, China; School of Computer Science, China University of Geosciences, Wuhan, China; School of Software, University of Technology Sydney, Sydney, Australia; Department of Information Systems and Cyber Security, University of Texas at San Antonio, San Antonio, USA","IEEE Internet of Things Journal","11 Feb 2020","2020","7","2","948","959","The role of the Industrial Internet of Things (IIoT) in critical infrastructure sectors, such as power, chemistry, and manufacturing, will be increasingly important as we move toward Industry 5.0. For example, IIoT devices are deployed in factories to help the manufacturing companies (e.g., automotive) gain in-depth insight into the various states of production, and thus improving production efficiency and achieving cost reductions. However, malicious code may compromise IIoT devices if either the devices are exposed to outside or unexposed inner devices are updated unauthentically. Due to their limited resources and features, it is challenging to implement strong security solutions for such embedded devices. In this article, we propose a blockchain-based software status monitoring system, called BoSMoS. The system is designed to monitor the software status of IIoT devices to detect and respond to identified malicious behaviors (e.g., intrusions). BoSMoS takes a snapshot of the statue of monitored software and monitors its file system calls. In order to ensure the software integrity information, we use blockchain as the distributed ledger to store a snapshot of software status. The blockchain network of BoSMoS can employ different consensus algorithms. We also evaluate the performance of BoSMoS, in terms of exception response delay, resistance performance to various intrusions, and scalability. The experimental results justify that BoSMoS is practical and sound. In addition, the evaluation of scalability and security demonstrates that the system can carry deployment of large-scale IIoT devices and can guarantee authenticated software updating, as well as detect unauthorized software status.","2327-4662","","10.1109/JIOT.2019.2947339","Major Scientific and Technological Special Project of Guizhou Province(grant numbers:20183001); Open Funding of Guizhou Provincial Key Laboratory of Public Big Data(grant numbers:2018BDKFJJ009,2017BDKFJJ006); Open Funding of Hubei Provincial Key Laboratory of Intelligent Geo-Information Processing(grant numbers:KLIGIP2016A05); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8869742","Blockchain;Industrial Internet of Things (IIoT);software monitoring","Software;Blockchain;Monitoring;Security;Peer-to-peer computing;Internet of Things;Consensus algorithm","","52","","36","IEEE","16 Oct 2019","","","IEEE","IEEE Journals"
"Cyber Warfare Threat Categorization on CPS by Dark Web Terrorist","V. Mahor; R. Rawat; A. Kumar; M. Chouhan; R. N. Shaw; A. Ghosh","Computer Science, SVVV IPS College of Technology and Management, Gwalior, India; Computer Science, SVIIT, Shri Vaishnav Vidyapeeth Vishwavidyalaya, Indore, India; Department of Computer Science and Engineering, Government Engineering College, Bharatpur, Rajasthan, India; Department of Computer Science and Engineering, Government Polytechnic College, Sheopur, MP, India; Department of Electrical, Electronics & Communication Engineering, Galgotias University, India; School of Engineering and Applied Sciences, The Neotia University, West Bengal, India","2021 IEEE 4th International Conference on Computing, Power and Communication Technologies (GUCON)","2 Nov 2021","2021","","","1","6","The Industrial Internet of Things (IIoT) also referred as Cyber Physical Systems (CPS) as critical elements, expected to play a key role in Industry 4.0 and always been vulnerable to cyber-attacks and vulnerabilities. Terrorists use cyber vulnerability as weapons for mass destruction. The dark web's strong transparency and hard-to-track systems offer a safe haven for criminal activity. On the dark web (DW), there is a wide variety of illicit material that is posted regularly. For supervised training, large-scale web pages are used in traditional DW categorization. However, new study is being hampered by the impossibility of gathering sufficiently illicit DW material and the time spent manually tagging web pages. We suggest a system for accurately classifying criminal activity on the DW in this article. Rather than depending on the vast DW training package, we used authorized regulatory to various types of illicit activity for training Machine Learning (ML) classifiers and get appreciable categorization results. Espionage, Sabotage, Electrical power grid, Propaganda and Economic disruption are the cyber warfare motivations and We choose appropriate data from the open source links for supervised Learning and run a categorization experiment on the illicit material obtained from the actual DW. The results shows that in the experimental setting, using TF-IDF function extraction and a AdaBoost classifier, we were able to achieve an accuracy of 0.942. Our method enables the researchers and System authoritarian agency to verify if their DW corpus includes such illicit activity depending on the applicable rules of the illicit categories they are interested in, allowing them to identify and track possible illicit websites in real time. Because broad training set and expert-supplied seed keywords are not required, this categorization approach offers another option for defining illicit activities on the DW.","","978-1-7281-9951-1","10.1109/GUCON50781.2021.9573994","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9573994","Dark web;categorization;TOR;Cyber-physical systems (CPS);terrorism;cyber warfare","Training;Weapons;Supervised learning;Web pages;Cyber warfare;Machine learning;Tagging","","21","","26","IEEE","2 Nov 2021","","","IEEE","IEEE Conferences"
"Evolving Authentication Design Consideration and BaaS Architecture for Internet of Biometric things","P. S. Jangid; V. A. Bharadi","LRTCOE, Thane, MH, India; IT Department, Finolex Academy of Management and Technology, Ratnagiri, MH, India","2020 International Conference on Convergence to Digital World - Quo Vadis (ICCDW)","20 Jan 2021","2020","","","1","7","Cloud computing has opened many possibilities for the design and implementing various models of software for addressing variety of problems. Biometric authentication is an important aspect of security and need for the same is increasing day by day. This has resulted in adaptation of biometric security-based systems by masses. Further, with the portable sensors and computing devices the biometric authentication will become an integral part of Internet of Things. To handle such a large scale of authentication cloud-based implementation is a viable option. In this paper, an evolution of a multimodal biometric authentication system is discussed. Initially the system is proposed as a native multimodal biometric system and further modified to be deployed as Software as a service-based model and a cloud-based model with GPU and NoSQL database. This paper is presenting the improvement in computation time and scalability gained by cloud-based deployment.","","978-1-7281-4635-5","10.1109/ICCDW45521.2020.9318664","NVIDIA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9318664","Cloud Computing;Biometrics;AWS;GPU;BlockChain","Biometrics (access control);Cloud computing;Authentication;Feature extraction;Biological system modeling;Security;Blockchain","","","","18","IEEE","20 Jan 2021","","","IEEE","IEEE Conferences"
"Aperiodic Tasks Scheduling of Energy Harvesting Embedded Systems","H. Xu; B. Zhang; C. Pan","College of Software, Jishou University, Zhangjiajie, China; College of Software, Jishou University, Zhangjiajie, China; Department of Computing Sciences (CSCI), Texas A&M University-Corpus Christi, Corpus Christi, TX","2022 23rd International Symposium on Quality Electronic Design (ISQED)","29 Jun 2022","2022","","","1","6","With the proliferation of the Internet of Things, embedded applications are widely utilized in various fields. Due to the sustainable and environmental friendly features, energy harvesting embedded devices are rapidly expanding in the market. Yet, these energy harvesting embedded systems are usually resource-constrained, which extremely affects the task execution performance of the embedded system. Therefore, this work studies the scheduling problem of aperiodic tasks in energy harvesting systems and designs an energy-constrained scheduling algorithm based on the dynamic voltages frequency scaling (DVFS) technique. For stochastic arrived tasks with multiple levels of Quality of Service (QoS), the execution frequency and service-level are selected according to the available energy and the task deadline, so that the task execution can be completed with a relatively large reward. Experimental results demonstrate that the proposed algorithm significantly improves the system QoS reward compared with the baselines.","1948-3295","978-1-6654-9466-3","10.1109/ISQED54688.2022.9806153","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9806153","energy harvesting;embedded systems;energy-constrained;aperiodic tasks","Performance evaluation;Schedules;Embedded systems;Scheduling algorithms;Simulation;Quality of service;Dynamic scheduling","","","","12","IEEE","29 Jun 2022","","","IEEE","IEEE Conferences"
"Implementation of Blockchain in Healthcare: A Systematic Review","A. K. Noon; O. Aziz; I. Zahra; M. Anwar","Department of Computer Science, NFC Institute of Engineering & Technology, Multan, Pakistan; Department of Computer Science, NFC Institute of Engineering & Technology, Multan, Pakistan; Institute of Computer Science and Information Technology, The Women University Multan, Multan, Pakistan; Department of Information Science, University of Education, Faisalabad, Pakistan","2021 International Conference on Innovative Computing (ICIC)","31 Jan 2022","2021","","","1","10","Blockchain is an emerging technology to ensure the security and trustworthiness for data sharing in different areas such as the economic sector, supply chain management, food industry, energy sector, education, internet of things, and healthcare. In healthcare, balancing patient care with the privacy of information, ease of accessibility and comprehensiveness has been a challenge. Healthcare directly affects humanity and so is one of the first areas where blockchain is implemented because the healthcare system has various problems that should be addressed. Blockchain can solve not only the data management issues between different stakeholders but also saves millions of dollars, reduce forging, and empower the patients. It has contributed to the transparency of insurance claims, management of Electronic Health Record (EHR), and also helps in genome research and so much more. This paper presents a systematic review of the recent research done in the application and major challenges for blockchain technology in the healthcare system. We have reviewed almost 56 papers selected from various search engines. This review focuses on some key areas that are discussed in many pieces of research such as interoperability, security management, fraud prevention, and financial issues. Major challenges and opportunities in the implementation of this technology are also discussed in this review. The basic issue in the healthcare industry is extraordinary costs of the medical facility and subsequent insurance claims. Where the involvement of various parties (hospitals, doctors, insurance companies, and government) makes it very difficult to ensure transparency which casts doubts among stakeholders. It is also observed that despite the favorite area for researchers the technology is not yet implemented on vast levels. Still, a lot of work is required to identify and then resolve the major challenges and issues in the way to transform the health system. The investors need to be convinced about the benefits of blockchain in the healthcare system so that the technology can be implemented on large scale.","","978-1-6654-0091-6","10.1109/ICIC53490.2021.9691510","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9691510","Blockchain;Healthcare;Electronic Health Record(EHR);Transparency.","Privacy;Systematics;Supply chain management;Security management;Insurance;Medical services;Transforms","","","","87","IEEE","31 Jan 2022","","","IEEE","IEEE Conferences"
"PPO2: Location Privacy-Oriented Task Offloading to Edge Computing Using Reinforcement Learning for Intelligent Autonomous Transport Systems","H. Gao; W. Huang; T. Liu; Y. Yin; Y. Li","School of Computer Engineering and Science, Shanghai University, Shanghai, China; School of Computer Science, Zhejiang University, Hangzhou, China; School of Computer Engineering and Science, Shanghai University, Shanghai, China; School of Computer Science, Hangzhou Dianzi University, Hangzhou, China; School of Computer Science, Hangzhou Dianzi University, Hangzhou, China","IEEE Transactions on Intelligent Transportation Systems","7 Jul 2023","2023","24","7","7599","7612","AI-empowered 5G/6G networks play a substantial role in taking full advantage of the Internet of Things (IoT) to perform complex computing by offloading tasks to edge services deployed in intelligent transport systems. However, offloading behavior has a certain regularity, and the real-time location of users can easily be inferred by attackers who have historical user data during the data transmission process. To address this problem, a privacy-oriented task offloading method that can resist attacks from privacy attackers with prior knowledge is proposed. First, the local computing model, channel model, and privacy loss model are defined and used to quantify evaluation indicators, such those related to privacy, time, and energy. Among them, privacy loss is formalized as the probability of a successful attack by an attacker with prior knowledge. Second, the process of solving an optimal task offloading decision problem is formalized into a Markov decision process (MDP). Finally, the deep reinforcement learning (DRL) method PPO2 is proposed to solve the planning problem of task offloading with good generalization and convergence speed, where we focus on the location privacy requirement. Experiments show that our method can handle large-scale task offloading and obtain offloading policies with reduced privacy loss, energy consumption and time delays.","1558-0016","","10.1109/TITS.2022.3169421","National Key Research and Development Program of China(grant numbers:2020YFB2103805); Natural Science Foundation of China(grant numbers:61972358,U20A20173); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9767576","Location privacy;data transmission and tasking offloading;deep reinforcement learning;IoV edge computing;privacy loss","Task analysis;Privacy;Servers;Computational modeling;Edge computing;Data privacy;Real-time systems","","48","","56","IEEE","3 May 2022","","","IEEE","IEEE Journals"
"Distributed and Collaborative Localization for Swarming UAVs","R. Chen; B. Yang; W. Zhang","State Key Laboratory of ISN, Xidian University, Xi’an, China; State Key Laboratory of ISN, Xidian University, Xi’an, China; School of Electrical Engineering and Telecommunications, University of New South Wales, Sydney, NSW, Australia","IEEE Internet of Things Journal","5 Mar 2021","2021","8","6","5062","5074","In recent years, unmanned aerial vehicles (UAVs), especially swarming UAVs are widely deployed in a variety of Internet-of-Things (IoT) scenarios. Since UAVs’ positions are essential for their collaboration, high-precision localization for swarming UAVs has attracted a lot of attention. Although the global positioning system (GPS) receiver has been widely integrated in UAV, it is not accurate enough and is prone to accidental or deliberate interferences. In this article, we propose a distributed and collaborative localization method for swarming UAVs that combines super multidimensional scaling (SMDS) and patch dividing/merging with GPS information. Specifically, the SMDS is first used to get the relative coordinates of the UAVs in each patch, then we merge relative map patches into a global map and transform the relative coordinates of the UAVs to their absolute coordinates. Furthermore, we propose a low-complexity algorithm that greatly reduces the computational complexity of SMDS with a large number of UAVs. Simulation results validate that with accurate enough angle measurements, the proposed SMDS localization algorithm outperforms the other MDS-based collaborative localization algorithms and can greatly improve the localization accuracy and robustness of swarming UAVs.","2327-4662","","10.1109/JIOT.2020.3037192","Foundation of Shaanxi Key Laboratory of Integrated and Intelligent Navigation(grant numbers:SKLIIN-20190103); Shenzhen Science and Innovation Fund(grant numbers:JCYJ20180507182451820,JCYJ20170412104656685); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9253622","Localization;multidimensional scaling (MDS);Nyström approximation;procrustes analysis;unmanned aerial vehicle (UAV)","Collaboration;Global Positioning System;Unmanned aerial vehicles;Internet of Things;Symmetric matrices;Merging;Computational complexity","","40","","32","IEEE","10 Nov 2020","","","IEEE","IEEE Journals"
"DyLoRa: Towards Energy Efficient Dynamic LoRa Transmission Control","Y. Li; J. Yang; J. Wang","School of Software and BNRist, Tsinghua University, P.R. China; School of Software and BNRist, Tsinghua University, P.R. China; School of Software and BNRist, Tsinghua University, P.R. China","IEEE INFOCOM 2020 - IEEE Conference on Computer Communications","4 Aug 2020","2020","","","2312","2320","LoRa has been shown as a promising platform for connecting large scale of Internet of Things (IoT) devices, by providing low-power long-range communication with a low data rate. LoRa has different transmission parameters (e.g., transmission power and spreading factor) to tradeoff noise resilience, transmission range and energy consumption for different environments. Thus, adjusting those parameters is essential for LoRa performance. Existing approaches are mainly threshold based and fail to achieve optimal energy efficiency. We propose DyLoRa, a dynamic LoRa transmission control system to improve energy efficiency. The high level idea of DyLoRa is to adjust parameters to different environments. The main challenge is that LoRa has very limited data rate and sparse data, making it very time- and energy-consuming to obtain physical link properties. We show that symbol error rate is highly related to the Signal- Noise Ratio (SNR) and derive the model to characterize this. We further derive energy efficiency model based on the symbol error model. DyLoRa can adjust parameters for optimal energy efficiency from sparse LoRa packets. We implement DyLoRa based on LoRaWAN 1.0.2 with SX1276 LoRa node and SX1301 LoRa gateway and evaluate its performance in real networks. The evaluation results show that DyLoRa improves the energy efficiency by 41.2% on average compared with the state-of-the- art LoRaWAN ADR.","2641-9874","978-1-7281-6412-0","10.1109/INFOCOM41043.2020.9155407","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155407","","Signal to noise ratio;Chirp;Logic gates;Frequency modulation;Demodulation;Energy consumption;Time-frequency analysis","","39","","30","IEEE","4 Aug 2020","","","IEEE","IEEE Conferences"
"Blockchain-Enabled Authenticated Key Agreement Scheme for Mobile Vehicles-Assisted Precision Agricultural IoT Networks","A. Vangala; A. K. Das; A. Mitra; S. K. Das; Y. Park","Center for Security, Theory and Algorithmic Research, International Institute of Information Technology, Hyderabad, India; Center for Security, Theory and Algorithmic Research, International Institute of Information Technology, Hyderabad, India; Center for Security, Theory and Algorithmic Research, International Institute of Information Technology, Hyderabad, India; Department of Computer Science, Missouri University of Science and Technology, Rolla, MO, USA; School of Electronics Engineering, Kyungpook National University, Daegu, Republic of Korea","IEEE Transactions on Information Forensics and Security","30 Dec 2022","2023","18","","904","919","Precision farming has a positive potential in the agricultural industry regarding water conservation, increased productivity, better development of rural areas, and increased income. Blockchain technology is a better alternative for storing and sharing farm data as it is reliable, transparent, immutable, and decentralized. Remote monitoring of an agricultural field requires security systems to ensure that any sensitive information is exchanged only among authenticated entities in the network. To this end, we design an efficient blockchain-enabled authenticated key agreement scheme for mobile vehicles-assisted precision agricultural Internet of Things (IoT) networks called  $AgroMobiBlock$ . The limited existing work on authentication in agricultural networks shows passive usage of blockchains with very high costs.  $AgroMobiBlock$  proposes a novel idea using the elliptic curve operations on an active hybrid blockchain over mobile farming vehicles with low computation and communication costs. Formal and informal security analysis along with the formal security verification using the Automated Validation of Internet Security Protocols and Applications (AVISPA) software tool have shown the robustness of  $AgroMobiBlock$  against man-in-the-middle, impersonation, replay, physical capture, and ephemeral secret leakage attacks among other potential attacks. The blockchain-based simulation on large-scale nodes shows the computational time for an increase in the network and block sizes. Moreover, the real-time testbed experiments have been performed to show the practical usefulness of the proposed scheme.","1556-6021","","10.1109/TIFS.2022.3231121","National Mission on Interdisciplinary Cyber-Physical Systems (NM-ICPS) for the Technology Innovation Hub (FINTECH) at the Indian Institute of Technology (IIT) Bhilai, Department of Science and Technology, Government of India; Basic Science Research Program through the National Research Foundation of Korea (NRF); Ministry of Education(grant numbers:2020R1I1A3058605); NSF Grants Smart Integrated Farm Network for Rural Agricultural Communities (SIRAC)(grant numbers:1952045); Towards a Unified Robust and Secure Data Driven Approach for Attack Detection in Smart Living (TAURUS)(grant numbers:2030624); Robust Federated Learning for Internet of Things (FLINT)(grant numbers:2008878); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9994772","Intelligent precision agriculture;Internet of Things (IoT);mobile vehicles;blockchain;authentication and key agreement;security;simulation","Blockchains;Authentication;Security;Farming;Smart agriculture;Remote monitoring;Costs","","20","","62","IEEE","20 Dec 2022","","","IEEE","IEEE Journals"
"SateLoc: A Virtual Fingerprinting Approach to Outdoor LoRa Localization using Satellite Images","Y. Lin; W. Dong; Y. Gao; T. Gu","College of Computer Science, Zhejiang University; College of Computer Science, Zhejiang University; College of Computer Science, Zhejiang University; Computer Science and Information Technology, RMIT University","2020 19th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)","9 Jun 2020","2020","","","13","24","With the increasing relevance of the Internet of Things (IoT) and large-scale Location-Based Services (LBS), LoRa localization has been attractive due to its low cost, low power and long range properties. However, existing localization approaches based on Received Signal Strength Indicator (RSSI) are either easily affected by signal fading of different land-cover types or labor-intensive. In this work, we propose SateLoc, a LoRa localization system that utilizes satellite images to generate virtual fingerprints. Specifically, SateLoc first uses high-resolution satellite images to identify land- cover types. With the path loss parameters of each land-cover type, SateLoc can automatically generate a virtual fingerprinting map for each gateway. We then propose a novel multi-gateway combination strategy, which is weighted by the environment interference of each gateway, to produce a joint likelihood distribution for localization. We implement SateLoc with commercial LoRa devices without any hardware modification, and evaluate its performance in a 227,500m2 urban area. Experimental results show that SateLoc achieves a median localization error of 47.1m, improving more than 40% compared to the state-of-the-art model-based approaches. More importantly, compared to the fingerprinting-based approach, SateLoc does not require the labor-intensive fingerprint acquisition process.","","978-1-7281-5497-8","10.1109/IPSN48710.2020.00-50","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9111031","Networks → Wide area networks;Location based services","Location awareness;Training;Radio frequency;Performance evaluation;Satellites;Urban areas;Fingerprint recognition","","17","","41","IEEE","9 Jun 2020","","","IEEE","IEEE Conferences"
"Self-Learning Spatial Distribution-Based Intrusion Detection for Industrial Cyber-Physical Systems","Y. Gao; J. Chen; H. Miao; B. Song; Y. Lu; W. Pan","School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; Information Network Engineering and Research Center, South China University of Technology, Guangzhou, China","IEEE Transactions on Computational Social Systems","30 Nov 2022","2022","9","6","1693","1702","Thanks to the great advancement of cognitive computing, artificial intelligence, big data, and the Internet of Things (IoT) technologies, the fusion of the physical and virtual worlds is changing people’s lifestyles. Although the research and deployment of cyber-physical systems (CPSs) are notably promoted by cognitive computing, the reliability and large-scale application of CPSs are still significantly challenged by some security issues. Therefore, it is meaningful to clarify and address the weaknesses of current intrusion detection methods for CPSs and enhance the ability to identify, analyze, and predict to improve the performance of intrusion detection. In this article, we first propose a novel self-learning spatial distribution algorithm, named Euclidean distance-based between-class learning (EBC learning), which improves between-class learning by calculating the Euclidean distance (ED) among  $k$ -nearest neighbors of different classes. In addition, a cognitive computing-based intrusion detection method named border-line SMOTE and EBC learning based on random forest (BSBC-RF) is also proposed based on the EBC learning for industrial CPSs. The experimental results over a real industrial traffic dataset show that the proposed EBC learning has strong spatial constraint capability and can improve the prediction and recognition performance. Compared with the eight state-of-the-art methods, the proposed method has an ACC exceeding 99.5%, false alarm rate (FAR) less than 0.06%, and  $F1$  close to 0.99, which is still superior to other ones.","2329-924X","","10.1109/TCSS.2021.3135586","Key-Area Research and Development Program of Guangdong Province(grant numbers:2019B010137001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9686054","Between-class learning (BC learning);cognitive computing;cyber-physical systems (CPSs);intrusion detection;machine learning (ML)","Intrusion detection;Feature extraction;Cyber-physical systems;Security;Graphical models;Distribution functions;Hidden Markov models;Machine learning;Learning systems","","11","","39","IEEE","19 Jan 2022","","","IEEE","IEEE Journals"
"Start of Frame Delimiters (SFDs) for Simultaneous Intra-Group One-to-All Dissemination","J. Debadarshini; S. Saha; O. Landsiedel; M. Choon Chan","IIT, Bhubaneswar; IIT, Bhubaneswar; Kiel University, Germany; National University of Singapore","2020 IEEE 45th Conference on Local Computer Networks (LCN)","15 Jan 2021","2020","","","100","111","Intra-group spreading is one of the common and frequent needs in many decentralized communication protocols. Such spreading is useful for quick and local dissemination of information among different clusters in large-scale decentralized systems like the Internet-of-Things (IoT). Complex decentralized protocols can carefully exploit such localized dissemination as a base unit for their efficient implementation. However, due to the inherent broadcast nature of wireless communication, efficient and simultaneous execution of multiple intra-group disseminations is difficult. In this work, we propose a novel and simple way to completely hide a wireless transmission without changing any channel or frequency. Next, we use this for supporting simultaneous intra-group disseminations. Rigorous evaluation of the proposed strategy over testbeds show significant improvement of upto 60% in reliability with similar average latency and radio-on time in comparison to the baseline where no additional mechanism is adopted for separation of intra-group communications.","0742-1303","978-1-7281-7158-6","10.1109/LCN48667.2020.9314842","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9314842","Synchronous transmission;Capture effect;CI;Intragroup dissemination;IoT;WSN;Decentralized systems;Interference;SFD;Start of Frame Delimiter;Glossy","Wireless sensor networks;Interference;Physical layer;Standards;Reliability;Peer-to-peer computing;Time division multiple access","","9","","33","IEEE","15 Jan 2021","","","IEEE","IEEE Conferences"
"How TinyML Can be Leveraged to Solve Environmental Problems: A Survey","H. Bamoumen; A. Temouden; N. Benamar; Y. Chtouki","School of Science and Engineering, Al Akhawayn University in Ifrane, Ifrane, Morocco; School of Science and Engineering, Al Akhawayn University in Ifrane, Ifrane, Morocco; Moulay Ismail University of Meknes School of Science and Engineering, Al Akhawayn University in Ifrane, Ifrane, Morocco; School of Science and Engineering, Al Akhawayn University in Ifrane, Ifrane, Morocco","2022 International Conference on Innovation and Intelligence for Informatics, Computing, and Technologies (3ICT)","30 Dec 2022","2022","","","338","343","Internet of things (IoT) enables the integration of smart and intelligent systems in our lives, subsequently creating an AI-powered society, where the latter is a substantial ingredient in the realization of a variety of tasks, be it industrial, personal, or economic. The emergence of embedded machine learning, or more specifically TinyML, opens a gate for a plethora of new applications that would extend the impact of technology on society. The ability to implement complex machine learning algorithms on low-powered devices can also be exploited to tackle one of the most fearful challenges encountered by the world, which is the environmental challenge. This challenge is currently threatening the entirety of the world on a very large scale, from global warming to climate change, drought, natural resource scarcity, and pollution. In this paper, we underline the contributions of Tiny-ML to the efforts deployed to surmount these challenges; and elaborate on how these tiny devices could be efficiently exploited to protect the natural world. Finally, we point out some challenges that limit Tiny-ML applicability in the environmental domain.","2770-7466","978-1-6654-5193-2","10.1109/3ICT56508.2022.9990661","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9990661","Tiny-ML;Embedded Machine Learning;Environment","Technological innovation;Sensitivity;Pollution;Machine learning algorithms;Atmospheric measurements;Machine learning;Sensors","","7","","38","IEEE","30 Dec 2022","","","IEEE","IEEE Conferences"
"Blockchain-Based Privacy-Preserving Positioning Data Sharing for IoT-Enabled Maritime Transportation Systems","K. Gai; H. Tang; G. Li; T. Xie; S. Wang; L. Zhu; K. -K. R. Choo","School of Cyperspace Science and Technology and the Yangtze Delta Region Academy, Beijing Institute of Technology, Beijing, China; School of Cyperspace Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science, Qufu Normal University, Rizhao, China; School of Cyperspace Science and Technology, Beijing Institute of Technology, Beijing, China; School of Cyperspace Science and Technology, Beijing Institute of Technology, Beijing, China; School of Cyperspace Science and Technology, Beijing Institute of Technology, Beijing, China; Department of Information Systems and Cyber Security, The University of Texas at San Antonio, San Antonio, TX, USA","IEEE Transactions on Intelligent Transportation Systems","8 Feb 2023","2023","24","2","2344","2358","Data-driven applications play an important role in modern-time maritime transportation systems, for instance in facilitating decision-making relating to communication and safety. One example application is position data sharing between vessels within the maritime Internet of Things (IoT)-enabled context. When designing such applications, we need to also consider how to ensure data accuracy as well as privacy in a large scale deployment. In this paper, we demonstrate the potential of using blockchain to facilitate privacy-preserving data sharing. Specifically, we develop a zero-knowledge proof-based scheme to protect vessel identities while allowing data sharing, and a commitment-based approach to ensure relationship-related privacy in data trading between participants. Our security and performance evaluations demonstrate the utility of the proposed approach.","1558-0016","","10.1109/TITS.2022.3190487","Natural Science Foundation of Beijing Municipality(grant numbers:4202068); National Natural Science Foundation of China(grant numbers:61972034); Natural Science Foundation of Shandong Province(grant numbers:ZR2019ZD10,ZR2020ZD01); Defense Industrial Technology Development Program(grant numbers:JCKY2020206C058); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9843902","Blockchain;privacy-preserving;positioning error data sharing;Internet of Things;maritime transportation system","Blockchains;Smart contracts;Sensors;Transportation;Global navigation satellite system;Sensor systems;Privacy","","6","","38","IEEE","27 Jul 2022","","","IEEE","IEEE Journals"
"Digital Implementation of Radial Basis Function Neural Networks Based on Stochastic Computing","A. Morán; L. Parrilla; M. Roca; J. Font-Rossello; E. Isern; V. Canals","Department of Industrial Engineering and Construction, Electronics Engineering Group (GEE), University of the Balearic Islands, Palma de Mallorca, Balearic Islands, Spain; Department of Electronics and Computer Technology, University of Granada, Andalucía, Granada, Spain; Department of Industrial Engineering and Construction, Electronics Engineering Group (GEE), University of the Balearic Islands, Palma de Mallorca, Balearic Islands, Spain; Department of Industrial Engineering and Construction, Electronics Engineering Group (GEE), University of the Balearic Islands, Palma de Mallorca, Balearic Islands, Spain; Department of Industrial Engineering and Construction, Electronics Engineering Group (GEE), University of the Balearic Islands, Palma de Mallorca, Balearic Islands, Spain; Department of Industrial Engineering and Construction, Electronics Engineering Group (GEE), University of the Balearic Islands, Palma de Mallorca, Balearic Islands, Spain","IEEE Journal on Emerging and Selected Topics in Circuits and Systems","22 Mar 2023","2023","13","1","257","269","Nowadays Internet of Things (IoT) and mobile systems use more and more Machine Learning based solutions, which implies a high computation cost with a low energy consumption. This is causing a revival of interest in unconventional hardware computing methods capable of implementing both linear and nonlinear functions with less hardware overhead than conventional fixed point and floating point alternatives. Particularly, this work proposes a novel Radial Basis Function Neural Network (RBF-NN) hardware implementation based on Stochastic Computing (SC), which applies probabilistic laws over conventional digital gates. Several complex functions design to implement RBF-NN are presented and theoretically analyzed, such as the squared Euclidean distance and the stochastic Gaussian kernel similarity function between input samples and prototypes. The efficiency and performance of the methodology is tested over well-known pattern recognition tasks, including the MNIST dataset. The results show a low-cost methodology in terms of logic resources and power, along with an inherent capability to implement complex functions in a simple way. This methodology enables the implementation of massively parallel large scale RBF-NN with relatively low hardware requirements while maintaining 96.20% accuracy, which is nearly the same for the floating point and fixed point models (96.4% and 96.25%, respectively).","2156-3365","","10.1109/JETCAS.2022.3231708","Spanish Ministry of Science and Innovation (MICINN);; Consejería de Economía, Conocimiento, Empresas y Universidad, Junta de Andalucía, Spain; European Regional European Development Founds (ERDF)(grant numbers:PID2020-120075RB-I00,PDC2021-121847-I00,B-TIC-588-UGR20); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9997493","Field programmable gate array (FPGA);K-means;pattern recognition;radial basis function neural networks (RBFNN);stochastic computing (SC)","Hardware;Logic gates;Stochastic processes;Kernel;Encoding;Pattern recognition;Computer architecture","","6","","64","IEEE","22 Dec 2022","","","IEEE","IEEE Journals"
"Prediction and Monitoring of stored food grains health using IoT Enable Nodes","A. Sindwani; A. Kumar; C. Gautam; G. Purohit; P. Tanwar","Dept. of Machnical engineering, Birla Institute of Technology and Science, Pilani, India; Dept. of Electronics Engineering, JCBUST, YMCA, Faridabad, India; Cyber Physical Systems, CSIR-CEERI Delhi Centre, India; Cyber Physical Systems, CSIR-CEERI, Pilani, India; Cyber Physical Systems, CSIR-CEERI, Pilani, India","2020 IEEE International Conference on Computing, Power and Communication Technologies (GUCON)","2 Nov 2020","2020","","","516","522","Accompanying the rapid urbanization, A developing country like India, still monitoring the food grain's health using conventional methods, which detect insects at a very later stage due to which food grain get spoil. The major parameter that should be observed for maintaining the quality of grains are temperature, relative humidity, and carbon dioxide concentration. The observation of these parameters regularly can lead to early detection of the insects in the grains. This paper suggests the state of the art Internet of Things (IoT) based real-time system which observes the warehouse parameter i.e Temperature, Relative Humidity, and Carbon dioxide and predicts the type of insect activity. The hardware Device used in the experiment is designed by keeping in mind the Indian warehouse's conditions and for large scale implementation of this model. The hardware Device contains two sensors (DHT22 and CDM7160), ESP8266, and battery for power supply. DHT22 and CDM7160 sensors are adopted to detect the above parameters i.e temperature, relative humidity, and CO2. The online portal has been created for data analysis and real-time data collection from the sensor nodes. This portal can be easily integrated with the digital portal already present in most of the warehouses. The machine learning algorithm has been deployed on the online server to predict relative humidity on the basis of collected data of relative humidity at a particular temperature. The prediction of relative humidity has been done for the next five days. The predicted relative humidity is used for predicting the type of insect that could attack the stack of the warehouse in the coming future. Based on the predicted results further action will be taken for controlling the food grain quality and prevent the wastage of food grain.","","978-1-7281-5070-3","10.1109/GUCON48875.2020.9231104","CEERI; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9231104","Internet of Things (IoT);Temperature;Relative Humidity;Carbon Dioxide;ESP8266;RNN","Temperature sensors;Insects;Humidity;Sensors;Internet of Things;Portals;Monitoring","","6","","11","IEEE","2 Nov 2020","","","IEEE","IEEE Conferences"
"Performance Analysis of Drone Assisted Multiple Antenna Backscatter IoT Sensor Network","A. M. Hayajneh; H. Al-Obiedollah; H. B. Salameh; M. Merenda; S. M. Hayajneh; S. A. R. Zaidi; D. C. McLernon","Department of Electrical Engineering, The Hashemite University, Zarqa, Jordan; Department of Electrical Engineering, The Hashemite University, Zarqa, Jordan; College of Engineering, Al Ain University, Al Ain, UAE; Delle Infrastrutture e dell’Energia Sostenibile (DIIES), Mediterranea University, Reggio Calabria, Italy; Faculty of Computer Studies, Arab Open University, Jordan; School of Electronic and Electrical Engineering, University of Leeds, Leeds, United Kingdom; NA","2021 8th International Conference on Internet of Things: Systems, Management and Security (IOTSMS)","11 Feb 2022","2021","","","1","7","In this paper, we investigate the idea of drone-assisted multiple antenna ambient backscatter communication (AmBC) based internet of things (IoT) sensor network (SN). We consider a scenario where a drone is used to collect the data from distributed multiple antenna SNs at which the drone is working as an ambient power emitter and a reader. The sensor nodes passively modulate the transmitted pure carrier by implementing load impedance modulation which results in an amplitude shift keying modulation. In order to quantify the performance of the studied network, we aim to find a closed-form expression for the coverage probability for the AmBC double-Rayleigh dyadic fading channel. Our model also incorporates Line of Sight (LoS) and Non-LoS (NLoS) propagation states for accurately modeling large-scale path-loss between drone and SN. We also investigate the use of the method of the moments in finding the probability density function (PDF) for the overall fading channel by matching it to a Log-Normal distribution to ease the mathematical manipulations. Finally, numerical results are compared to Monte-Carlo simulations to verify the effectiveness of the derived system model analysis and to characterize the optimal selection of the network parameters in maximizing the coverage probability.","","978-1-6654-5868-9","10.1109/IOTSMS53705.2021.9704924","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9704924","Drone;Backscatter communication;Dyadic fading;IoT;Coverage probability","Fading channels;Modulation;Probability density function;Mathematical models;Performance analysis;Numerical models;Internet of Things","","3","","33","IEEE","11 Feb 2022","","","IEEE","IEEE Conferences"
"Monostatic Backscatter Communication in Urban Microcellular Environment Using Cellular Networks","M. U. Sheikh; F. Jameel; H. Yiğitler; X. Wang; R. Jäntti","Department of Communications and Networking, Aalto University, Espoo, Finland; Department of Communications and Networking, Aalto University, Espoo, Finland; Department of Communications and Networking, Aalto University, Espoo, Finland; Department of Communications and Networking, Aalto University, Espoo, Finland; Department of Communications and Networking, Aalto University, Espoo, Finland","2020 IEEE Wireless Communications and Networking Conference (WCNC)","19 Jun 2020","2020","","","1","6","Backscatter communication offers a reliable and energy-efficient alternative to conventional radio systems. With the additional capability of wireless power transmission, the backscatter tags can work in a completely battery-less manner. Due to these exciting features, the researchers from academia and industry are extensively investigating its utility as an enabler of massive Internet of Things (IoT) networks. However, before reaping the benefits of ambient backscatter communications, it is necessary to evaluate its feasibility and operability for large scale networks. To do so, this research paper provides an empirical study of the real city wide deployment of monostatic wireless powered backscatter tags in Helsinki region. The coverage and outage performance has been assessed for both indoor and outdoor conditions using a sophisticated 3D ray tracing simulations. Whereby, the indoor scenario consists of several story buildings with low and high loss materials. Moreover, an indepth evaluation of energy shortage at backscatter tags has also been provided which sheds the light on the importance of wireless power transmission for such networks. The results provided here would be helpful in upscaling the practical deployment of backscatter tags.","1558-2612","978-1-7281-3106-1","10.1109/WCNC45663.2020.9120830","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9120830","Backscatter communications;Energy shortage;Internet-of-thing (IoT);Wireless power transmission","Solid modeling;Three-dimensional displays;Urban areas;Buildings;Ray tracing;Probability;Wireless power transmission","","2","","16","IEEE","19 Jun 2020","","","IEEE","IEEE Conferences"
"Taxonomy and Future Threat of Rogue Access Point for Wireless Network","K. C. Patel; A. Patel","Department of Computer Science, Ganpat University, Gujarat, India; A. M. Patel Institute of Computer Studies Ganpat University, Gujarat, India","2022 9th International Conference on Computing for Sustainable Global Development (INDIACom)","2 May 2022","2022","","","679","688","Wireless network communication is an enormous and vast area of research. Many companies and organizations, related to wireless security have struggled due to the narrow, limited, and restricted access to the legitimate network. In a simplistic sense and most common manner, radio frequency (RF) is used for data communication on a network without wires. By its nature and methodology, wireless communication uses an air interface, and hence, it is vulnerable to attackers or hackers who can leverage these things and will compromise the legitimate network, devices, servers, applications, databases, and connected users. Wireless network attacks can be categorised into various types named Distributed Denial of Service (DDoS), Evil-twin, Man-in-the-Middle (MITM), Wireless Fidelity (Wi-Fi) Deauthentication, and Internet of Things (IoT)-based attacks. These types of attacks can compromise and infect the operational technology of large-scale public and private sector organizations' Industrial Control Systems (ICS) and Supervisory Control and Data Acquisition (SCADA). A wireless rogue access point has already done harmful things to businesses of all sizes, not just coffee shops, airport terminals, tube stations, or public gardens. This paper classifies rogue access points (RAPs) in wireless communication as a serious threat to the Wireless Local Area Network (WLAN) 802.11 protocol. The aim is to classify various types of wireless attacks and their various techniques, which are especially performed through RAP successfully. This paper also presents the statistical data and literature survey based on demand of next generation Wi-Fi enabled technologies and related cyber threats, which show that RAP is a serious threat to legitimate networks for wireless network and communication.","","978-93-80544-44-1","10.23919/INDIACom54597.2022.9763150","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9763150","Rogue Access Point;WLAN;Wireless;802.11;Distributed Denial of Service;Security;Threat","Wireless sensor networks;Wireless networks;Weapons;Scalability;Wires;Taxonomy;Communication system security","","2","","97","","2 May 2022","","","IEEE","IEEE Conferences"
"DOVA PRO: A Dynamic Overwriting Voltage Adjustment Technique for STT-MRAM L1 Cache Considering Dielectric Breakdown Effect","J. Chen; C. Lu; J. Ni; X. Guo; P. Girard; Y. Cheng","School of Electrical and Information Engineering, Beihang University, Beijing, China; MIIT Key Laboratory of Spintronics, School of Integrated Circuit Science and Engineering, Beihang University, Beijing, China; MIIT Key Laboratory of Spintronics, School of Integrated Circuit Science and Engineering, Beihang University, Beijing, China; Department of Electrical and Computer Engineering, Lehigh University, Bethlehem, PA, USA; Laboratory of Computer Science, Robotics and Microelectronics of Montpellier (LIRMM), University of Montpellier/CNRS, Montpellier, France; MIIT Key Laboratory of Spintronics, School of Integrated Circuit Science and Engineering, Beihang University, Beijing, China","IEEE Transactions on Very Large Scale Integration (VLSI) Systems","28 Jun 2021","2021","29","7","1325","1334","As device integration density increases exponentially as predicted by Moore's law, power consumption becomes a bottleneck for system scaling where leakage power of on-chip cache occupies a large fraction of the total power budget. Spin transfer torque magnetic random access memory (STT-MRAM) is a promising candidate to replace static random access memory (SRAM) as an on-chip last level cache (LLC) due to its ultralow leakage power, high integration density, and nonvolatility. Moreover, with the prevalence of edge computing and Internet-of-Things (IoT) applications, it can be beneficial to build a total nonvolatile cache hierarchy, including the L1 cache. However, building an L1 cache with STT-MRAM still faces severe challenges particularly because reducing its relatively high write latency by increasing write voltage can accelerate oxide breakdown of the MTJ device and threaten the L1 cache lifetime significantly due to intensive accesses. In our previous work, we proposed a dynamic overwriting voltage adjustment (DOVA) technique to deal with this challenge. In this article, we improve this technique by a DOVA promotion (DOVA PRO) technique for the STT-MRAM L1 cache, considering the cache write endurance and performance simultaneously. A high write voltage is used for performance-critical cache lines, while a low write voltage is used for other cache lines to approach an optimal tradeoff between reliability and performance. Experimental results show that the proposed technique DOVA PRO can improve cache performance by 23.5%, on average, compared to the DOVA technique. In the meantime, the average degradation of cache lifetime remains almost unchanged compared with the DOVA technique on average. Furthermore, DOVA PRO can support flexible configurations to achieve various optimization targets, such as higher performance or a longer lifetime.","1557-9999","","10.1109/TVLSI.2021.3073415","Beijing Natural Science Foundation(grant numbers:4192035); Science, Technology and Innovation Commission of Shenzhen Municipality(grant numbers:JCYJ20180307123657364); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9419672","Performance;reliability;spin transfer torque magnetic random access memory (STT-MRAM);time-dependent dielectric breakdown (TDDB)","Reliability;Magnetic tunneling;Breakdown voltage;Acceleration;Weibull distribution;Stress;Magnetization","","2","","33","IEEE","29 Apr 2021","","","IEEE","IEEE Journals"
"A Large-Scale Dataset of 4G, NB-IoT, and 5G Non-Standalone Network Measurements","K. Kousias; M. Rajiullah; G. Caso; U. Ali; O. Alay; A. Brunstrom; L. D. Nardis; M. Neri; M. -G. D. Benedetto",NA; NA; NA; NA; NA; NA; NA; NA; NA,"IEEE Communications Magazine","","2023","PP","99","1","7","Mobile networks are highly complex systems. Therefore, it is crucial to examine them from an empirical perspective to better understand how network features affect performance, so to suggest additional improvements. To this aim, this paper presents a large-scale dataset of measurements collected over fourth generation (4G) and fifth generation (5G) operational networks, providing Long Term Evolution (LTE), Narrowband Internet of Things (NB-IoT), and 5G New Radio (NR) connectivity. We collected our dataset during seven weeks in Rome, Italy, by performing several tests on the infrastructures of two major mobile network operators (MNOs). The open-sourced dataset has enabled multi-faceted analyses of network deployment, coverage, and end-user performance, and can be further used for designing and testing artificial intelligence (AI) and machine learning (ML) solutions for network optimization.","1558-1896","","10.1109/MCOM.011.2200707","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10239125","","5G mobile communication;Throughput;Long Term Evolution;Frequency measurement;Amplitude modulation;Antenna measurements;Synchronization","","2","","","IEEE","4 Sep 2023","","","IEEE","IEEE Early Access Articles"
"An Efficient Allocation System for Centralized Network Slicing in LoRaWan","F. Z. Mardi; M. Bagaa; Y. Hadjadj-Aoul; N. Benamar","Moulay Ismail University, Meknes, Morocco; Aalto University, CSC, Espoo, Finland; University of Rennes, Inria, IRISA, France; Moulay Ismail University, Meknes, Morocco","2022 International Wireless Communications and Mobile Computing (IWCMC)","19 Jul 2022","2022","","","806","811","The new emerging technologies enable the appearance of the 5G system and beyond that offers a plethora of services and target new verticals. One of these verticals is the large-scale Internet of Things (IoT) that is expected to be used everywhere in our daily lives. The traffic would likely be increased due to these emerging verticals. To overcome such challenges, network slicing and softwarization will play a crucial role in addressing these requirements and ensuring service level agreements (SLAs). Thus, there is a need to provide efficient and flexible network slice management mechanisms to handle the hurdles that come with the emerging industrial verticals. This paper focuses on network slicing in LoRa networks. We suggest a centralized coalition game-based network slicing strategy to manage LoRa nodes efficiently. According to the K-means clustering algorithm, the proposed solution is deployed within clustered players to maximize reliability while ensuring the SLA of the LoRa slices. Simulation results clearly show that our proposed approach improves Packets' Success Rate (PSR), Network Energy Consumption (NEC), and guarantees prioritization between slices.","2376-6506","978-1-6654-6749-0","10.1109/IWCMC55113.2022.9825330","ANR; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9825330","Internet of Things (IoT);LoRa;network slicing","Wireless communication;Energy consumption;Network slicing;Simulation;Quality of service;Internet of Things;Resource management","","2","","16","IEEE","19 Jul 2022","","","IEEE","IEEE Conferences"
"SRCLoc: Synthetic Radio Map Construction Method for Fingerprinting Outdoor Localization in Hybrid Networks","G. B. Tarekegn; R. -T. Juang; H. -P. Lin; L. -C. Tai; Y. Y. Munaye; M. A. Bitew","Department of Electrical Engineering and Computer Science, National Taipei University of Technology, Taipei, Taiwan; Department of Electronic Engineering, Feng Chia University, Taichung, Taiwan; Department of Electronic Engineering, National Taipei University of Technology, Taipei, Taiwan; Department of Electrical and Computer Engineering, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Faculty of Computing, Bahir Dar Institute of Technology, Bahir Dar University, Bahir, Dar, Ethiopia; Faculty of Computing, Bahir Dar Institute of Technology, Bahir Dar University, Bahir, Dar, Ethiopia","IEEE Sensors Journal","1 Aug 2022","2022","22","15","15574","15583","A precise localization system is a key enabling technology for Internet of Things (IoT) applications and location-based services. Fingerprint-based localization methods are well-known and widely used solutions. These methods, however, are time-consuming and laborious for radio map construction during an offline site survey in large-scale applications. In this article, we presented a novel semi-supervised deep convolutional generative adversarial network-based radio map construction method for real-time device localization. The proposed synthetic radio map construction method for fingerprinting outdoor localization (SRCLoc) combined the hybrid support vector machine and deep gated recurrent unit algorithms sequentially. The SRCLoc reduced the workload of site surveying required to build the fingerprint database by up to 85.7%. The results show that the average positioning error of SRCLoc is less than 39 cm, and more than 90% of the errors are less than 82 cm. That is, numerical results proved that, in comparison to traditional methods, the proposed SRCLoc method can significantly improve positioning performance and reduce radio map construction costs.","1558-1748","","10.1109/JSEN.2022.3186469","Ministry of Science and Technology (MOST), Taiwan(grant numbers:110-2221-E-27-033-MY2,109-2222-E-035-003-MY2); Yushan Young Scholar Program(grant numbers:#110B530-9); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9813439","Gated recurrent network;support vector machine;generative adversarial network;radio signal;fingerprint positioning","Fingerprint recognition;Wireless LAN;Location awareness;Support vector machines;Sensors;Logic gates;Feature extraction","","2","","35","IEEE","1 Jul 2022","","","IEEE","IEEE Journals"
"On the Optimality of Data Exchange for Master-Aided Edge Computing Systems","H. Chen; J. Long; S. Ma; M. Tang; Y. Wu","School of Information Science and Technology, ShanghaiTech University, Shanghai, China; School of Information Science and Technology, ShanghaiTech University, Shanghai, China; Peng Cheng Laboratory, Shenzhen, China; Westpac Banking Corporation, Sydney, NSW, Australia; School of Information Science and Technology, ShanghaiTech University, Shanghai, China","IEEE Transactions on Communications","16 Mar 2023","2023","71","3","1364","1376","Edge computing has recently garnered significant interest in many Internet of Things (IoT) applications. However, the excessive overhead during data exchange still remains an open challenge, especially for large-scale data processing tasks. This paper considers a master-aided distributed computing system with multiple edge computing nodes and a master node, where the master node helps edge nodes compute output functions. We propose a coded scheme to reduce the communication latency by exploiting computation and communication capabilities of all nodes and creating coded multicast opportunities. More importantly, we prove that the proposed scheme is always optimal, i.e., achieving the minimum communication latency, for arbitrary computing and storage abilities at the master. This extends the previous optimality results in the extreme cases (either the master could compute all input files or compute nothing) to the general case. Finally, numerical results and TeraSort experiments demonstrate that our schemes can greatly reduce the communication latency compared with the existing schemes.","1558-0857","","10.1109/TCOMM.2023.3238373","National Nature Science Foundation of China (NSFC)(grant numbers:61901267); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10023542","Distributed computing;MapReduce;computation;communication","Computational modeling;Edge computing;Servers;Load modeling;Task analysis;Symbols;Encoding","","1","","40","IEEE","20 Jan 2023","","","IEEE","IEEE Journals"
"Making Internet of Things Robust Through Blockchain Technology: A Quantitative Approachin the World of Technology Advancements","J. Alam; H. S. P; A. Mirza; B. U. Swadia; H. Pallathadka","Department of Humanities & Management Science, Madan Mohan Malaviya University of Technology, Gorakhpur, India; Dept of Electronics Science, SRM Arts and Science College, India; Department of Political Science, Shyama Prasad Mukherji College for Women, University of Delhi, India; Foc GLS University, India; Manipur International University, Imphal, Manipur, India","2022 International Conference on Innovative Computing, Intelligent Communication and Smart Electrical Systems (ICSES)","14 Oct 2022","2022","","","1","7","The domain of connectivity and linkages and new expertise is developed named the Internet of things or IoT.The technology paradigm of the manufacturing age was one of the machinesriseseparateautomated systems, there remainedcorporeal in nature mono purposeful and computerized. It is the biosphere of non-responsive inaccessible technologies, each of which the end-user must manage separately. The technology model of the evidence age is one of the amenities. It is a biosphere where separateconstituentskills are instrumented and associated into large network devices that can interconnect peer to peer to familiarize and self-organize the end-users needs to deliver a seamless service. One of the best artworks of this is the smart city where different organizations no longer exist in storage towers but are inter-connected and prearranged around the end-users need. A sample of 177 respondents was collected from respondents through, a ""standard questionnaire,"" which was created on a five-point interval scale.","","978-1-6654-7413-9","10.1109/ICSES55317.2022.9914014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9914014","Internet of Things;Computerized;Technology;Seamless Service","Temperature sensors;Temperature distribution;Smart cities;Standards organizations;Biosphere;Production facilities;Blockchains","","1","","14","IEEE","14 Oct 2022","","","IEEE","IEEE Conferences"
"Analysis of Load-Altering Attacks Against Power Grids: A Rare-Event Sampling Approach","M. P. Goodridge; S. Lakshminarayana; C. Few","Global Development Initiatives, Queen Mary University of London; School of Engineering, University of Warwick, UK; National Grid, UK","2022 17th International Conference on Probabilistic Methods Applied to Power Systems (PMAPS)","4 Jul 2022","2022","","","1","6","By manipulating tens of thousands of internet-of-things (IoT) enabled high-wattage electrical appliances (e.g., WiFi-controlled air-conditioners), large-scale load-altering attacks (LAAs) can cause severe disruptions to power grid operations. In this work, we present a rare-event sampling approach to identify LAAs that lead to critical network failure events (defined by the activation of a power grid emergency response (ER)). The proposed sampler is designed to ‘skip’ over LAA instances that are of little interest (i.e., those that do not trigger network failure), thus significantly reducing the computational complexity in identifying the impactful LAAs. We perform extensive simulations of LAAs using the Kundur two-area system (KTAS) power network while employing the rare-event sampler. The results help us identify the victim nodes from which the attacker can launch the most impactful attacks and provide insights into how the spatial distribution of LAAs triggers the activation of ERs.","2642-6757","978-1-6654-1211-7","10.1109/PMAPS53380.2022.9810602","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9810602","","Graphical models;Computational modeling;Probabilistic logic;Emergency services;Power grids;Computational complexity;Electrical products","","1","","18","IEEE","4 Jul 2022","","","IEEE","IEEE Conferences"
"Trustworthy Distributed Intelligence for Smart Cities","X. Liu; S. Tamminen; S. Tarkoma; X. Su","University of Helsinki, Helsinki, Finland; University of Oulu, Oulu, Finland; University of Helsinki, Helsinki, Finland; Norwegian University of Science and Technology, Gjøvik, Norway","2022 IEEE 38th International Conference on Data Engineering Workshops (ICDEW)","8 Jul 2022","2022","","","60","65","The future of smart cities has been significantly impacted by Internet of Things (IoT) and distributed intelligence, where a large scale of data are collected from massive amounts of heterogeneous devices and distributed intelligence brings storage, computing, and Artificial Intelligence (AI) functionality close to the end devices where data are generated for providing novel services and applications. However, AI empowered systems face many challenges due to the inscrutability of complex AI models which weakens the trust of users. This paper provides a general understanding of the underlying concepts and challenges in trustworthy distributed intelligence. A use case of district heating network is illustrated to explore the proposed concepts, technologies, and challenges for enabling trustworthy distributed intelligence for smart cities.","2473-3490","978-1-6654-8104-5","10.1109/ICDEW55742.2022.00013","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9814514","Distributed Intelligence;Trustworthy;Smart Cities","Heating systems;Adaptation models;Smart cities;Conferences;Distributed databases;Data models;Robustness","","","","23","IEEE","8 Jul 2022","","","IEEE","IEEE Conferences"
"Risk Model and Defense Strategy for Operation and Maintenance of Remote Terminal Units in Distribution System","G. Wang; Y. Shang; F. Xie; W. Sheng; W. Fan; S. Bai","Department of Distribution System, China Electric Power Research Institute (CEPRI), Beijing, China; Department of Distribution System, China Electric Power Research Institute (CEPRI), Beijing, China; Department of Distribution System, China Electric Power Research Institute (CEPRI), Beijing, China; Department of Distribution System, China Electric Power Research Institute (CEPRI), Beijing, China; Department of Distribution System, China Electric Power Research Institute (CEPRI), Beijing, China; Department of Distribution System, China Electric Power Research Institute (CEPRI), Beijing, China","2023 International Conference on Power System Technology (PowerCon)","6 Dec 2023","2023","","","1","7","In the context of digital transformation, the large-scale Remote Terminal Unit access to distribution system and its operation and maintenance (O&M) process has posed new challenges to the existing information security. Based on the current situation of distribution terminals cyber security, this article first analyzes the security flaws, as well as the risks of information and data leakage in the process of O&M. Then based on the cyber and physical characteristics of distribution Internet of Things (IoT), a risk-based model is constructed. Finally, a dynamic defense strategy for terminal operation and maintenance is proposed to strengthen the communication security of terminal operation and maintenance and resist malicious attacks.","","979-8-3503-0022-2","10.1109/PowerCon58120.2023.10331301","National Key Research and Development Project(grant numbers:2021 YFB2401305); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10331301","Distribution network;Remote terminal unit;Operation and maintenance(O&M) safety;Internet of Things (IoT)","Protocols;Digital transformation;Power system dynamics;Optimization methods;Information security;Resists;Maintenance engineering","","","","21","IEEE","6 Dec 2023","","","IEEE","IEEE Conferences"
"Importance-Aware Data Pre-Processing and Device Scheduling for Multi-Channel Edge Learning","X. Huang; S. Zhou","Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China","Journal of Communications and Information Networks","3 Jan 2023","2022","7","4","394","407","The large-scale deployment of intelligent Internet of things (IoT) devices have brought increasing needs for computation support in wireless access networks. Applying machine learning (ML) algorithms at the network edge, i.e., edge learning, requires efficient training, in order to adapt themselves to the varying environment. However, the transmission of the training data collected by devices requires huge wireless resources. To address this issue, we exploit the fact that data samples have different importance for training, and use an influence function to represent the importance. Based on the importance metric, we propose a data pre-processing scheme combining data filtering that reduces the size of dataset and data compression that removes redundant information. As a result, the number of data samples as well as the size of every data sample to be transmitted can be substantially reduced while keeping the training accuracy. Furthermore, we propose device scheduling policies, including rate-based and Monte-Carlo-based policies, for multi-device multi-channel systems, maximizing the summation of data importance of scheduled devices. Experiments show that the proposed device scheduling policies bring more than 2% improvement in training accuracy.","2509-3312","","10.23919/JCIN.2022.10005217","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10005217","edge computing;ML;data importance;resource allocation","Training;Data models;Servers;Filtering;Wireless communication;Learning systems;Computational modeling","","","","","","3 Jan 2023","","","PTP","PTP Journals"
"A Benchmark of Absolute and Relative Positioning Solutions in GNSS Denied Environments","H. Yao; X. Liang; R. Chen; X. Wang; H. Qi; L. Chen; Y. Wang","State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; Department of Remote Sensing and Photogrammetry, Finnish Geospatial Research Institute, Masala, Finland","IEEE Internet of Things Journal","24 Jan 2024","2024","11","3","4243","4273","Precise positioning is fundamental to the Internet of Things (IoT) that delivers insights into everything from large-scale business to ordinary smart life. Accurate localization and positioning in global navigation satellite system (GNSS) denied environments, such as indoor-, underground-spaces, and forests, is one of the most prosperous research fields because of the great complexity prompted by various challenging application scenarios. Different sensors, algorithms, and combinations of those have been developed in past decades, which provided a great variety of possible solutions that deliver different positioning accuracies. However, a rigorous evaluation of the positioning accuracy of different mainstream solutions is missing, mainly because of the difficulties in acquiring reliable ground truth for referencing and the lack of comparable test/application conditions. A comprehensive benchmarking was carried out in this study based on the comparisons of six solutions that consist of different combinations of five positioning technologies, i.e., 1) ultrawideband (UWB) and inertial measurement unit (IMU); 2) UWB, IMU, and camera; 3) UWB and light detection and ranging (LIDAR); 4) UWB and radio detection and ranging (RADAR); 5) IMU, camera, and LIDAR; and 6) UWB, IMU, camera and LIDAR. The five technologies, i.e., UWB, IMU, camera, RADAR, and LIDAR, were commonly regarded as those that are with high applicability, accuracy, and robustness. New anchors self-positioning algorithm and integrity monitoring algorithm were proposed to further aid the compared solutions and the benchmark. High-precision survey (millimeter)-level ground truth references were acquired at indoor and outdoor test locations and applied in the evaluations, to assist reliable quantitive benchmarks about the positioning accuracies and stabilities of the compared solutions. The strengths, limitations, and potentials of each solution were analyzed. It was revealed that all relative positioning solutions accumulate positioning errors over time. Such accumulation was of the highest significance for RADAR, followed by camera. LIDAR is presented to be the most robust solution for relative positioning. Compared to camera, LIDAR, and RADAR alone, the integration of different technologies clearly improved the performance. The tight coupling (TC) performed slightly superior to loose coupling, and the unscented Kalman filter with TC had a higher positioning accuracy in most cases.","2327-4662","","10.1109/JIOT.2023.3300018","Natural Science Fund of China(grant numbers:32171789); Wuhan University(grant numbers:WHUZZJJ202220); 2023 ISPRS Scientific Initiatives (Benchmarking of Absolute and Relative Positioning Solutions under GNSS Denied Environments for Mobile Geomatics); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10197620","Absolute and relative positioning (ARP);data fusion;global navigation satellite system (GNSS) denied environment;integrity monitoring (IM);Internet of Things (IoT);tight and loose coupling (LC)","Benchmark testing;Laser radar;Global navigation satellite system;Cameras;Ultra wideband radar;Sensors;Monitoring","","","","96","CCBYNCND","31 Jul 2023","","","IEEE","IEEE Journals"
"Multi-Drone Parcel Delivery via Public Vehicles: A Joint Optimization Approach","T. Deng; X. Xu; Z. Zou; W. Liu; D. Wang; M. Hu","School of Electronic Information and Communications, Hubei Key Laboratory of Smart Internet Technology, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Hubei Key Laboratory of Smart Internet Technology, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Hubei Key Laboratory of Smart Internet Technology, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Hubei Key Laboratory of Smart Internet Technology, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Hubei Key Laboratory of Smart Internet Technology, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Hubei Key Laboratory of Smart Internet Technology, Huazhong University of Science and Technology, Wuhan, China","IEEE Internet of Things Journal","","2023","PP","99","1","1","As one of the promising self-powered sensors on Internet of Things (IoT) platforms, unmanned aerial vehicles (UAVs) have attracted much attention for parcel delivery. Their high flexibility and low cost facilitate last-one-mile delivery. However, the limitations of battery capacity and payloads prevent drones from delivering independently over large scales. In this case, it is available to employ vehicles to assist the drones. The vehicles can be private-own trucks and vehicles in public transportation systems (PTSs). Compared to trucks, PTSs such as buses and trains do not require extra operating and fuel costs. Given these advantages, this paper adopts PTSs to assist UAVs in parcel delivery. Nevertheless, the fixed routes and schedules of public vehicles pose new challenges to the Routing and Scheduling problem for PTS-assisted Multi-drone parcel Delivery (RSPMD). To tackle the problem, we propose a novel routing and scheduling algorithm, referred to as the PTS-assisted multi-Drone parcel Delivery (PDD) algorithm. Considering the schedules of the public vehicles, the algorithm jointly optimizes the distance and time cost of drones by iteratively combining parts of existing routes. To the best of our knowledge, we are the first to address RSPMD in which UAVs ride public vehicles to deliver parcels in a wide area. Simulation results are finally presented to demonstrate that PDD outperforms existing solutions in terms of effectiveness and efficiency.","2327-4662","","10.1109/JIOT.2023.3323704","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10286243","Intelligent transportation systems;smart cities;unmanned aerial vehicle;vehicle routing problem","Drones;Autonomous aerial vehicles;Routing;Schedules;Costs;Public transportation;Payloads","","","","","IEEE","16 Oct 2023","","","IEEE","IEEE Early Access Articles"
"Graph Theory-Based Formal Modeling of Forest Fire Management System using IoT and Drone","A. Tehseen; N. A. Zafar; T. Ali","Department of Computer Science, COMSATS University Islamabad, Sahiwal Campus, Pakistan; Department of Computer Science, COMSATS University Islamabad, Sahiwal Campus, Pakistan; Department of Computer Science, COMSATS University Islamabad, Sahiwal Campus, Pakistan","2021 International Conference on Communication Technologies (ComTech)","24 Nov 2021","2021","","","132","137","Forests are a significant aspect of nature and show an important role in the protection of the environment. Humans depend on the forests for their survival which includes intake of air for breathing and wood usage for households. Recently forest fire became the main hazard because it has terrible consequences for nature. Therefore, it is important to detect a fire in the early stages before it spreads over large areas and destroys environmental resources. In this paper, a well-organized internet of things (IoT) and drone-based forest fire detection and counteraction system is presented. Four types of sensors are used in the form of subnets to cover the scaled area of forest. These sensors are equipped with trees and ground to collect the data from fire-affected areas and communicate with gateways. To transmit information subnets are connected with the control room through gateways. Different types of drones with onboard computers are being used for real-time monitoring and perform actions. Graph theory is used to represents the network and transform it into a formal model. To define and prove the formal specification’s correctness the VDM-SL (Vienna Development Method-Specification Language) is used. Various VDM-SL toolkit features are used to ensure model’s verification and validation.","","978-1-6654-1901-7","10.1109/ComTech52583.2021.9616876","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9616876","Forest Fire detection;IoT;Drones;VDM-SL;Formal Methods","Computational modeling;Forestry;Vegetation;Transforms;Logic gates;Real-time systems;Hazards","","","","26","IEEE","24 Nov 2021","","","IEEE","IEEE Conferences"
"Biodiversity Sensor: A Customized and Power Efficient Solution for Biodiversity Surveillance","M. Kaur; K. Singh; S. Kumar","Department of Electrical Engineering, Indian Institute of Technology Ropar, Ropar, India; Department of Electrical Engineering, Indian Institute of Technology Ropar, Ropar, India; Department of Electrical Engineering, Indian Institute of Technology Ropar, Ropar, India","IEEE Sensors Journal","14 Dec 2023","2023","23","24","31159","31170","Pollinators play a vital role in ecosystem conservation, and their extinction would pose a serious threat to our existence. Recent research has revealed that excessive use of pesticides, fertilizers, and changing farming practices has adversely affected pollinator biodiversity. Therefore, continuous farmland monitoring is required to check flying insects for biodiversity conservation. The idea is to develop a digital sensor network across farmlands for the monitoring of biodiversity at a large scale. In this article, a biodiversity sensor (BS) is developed that can track the movement of flying insects in real-time, along with environmental conditions and updates to the cloud server. The developed sensor is a processor-based Internet of Things (IoT) device, powered by a solar photovoltaic (PV)/battery bank and loaded with a customized Linux operating system (OS) (using Yocto-build). An over-the-air (OTA) update feature has been added to the customized OS, allowing remote management and sensor updates that were previously unavailable in the pre-installed multimedia OS. The sensor can also be managed locally using the device manager portal (DMP), which exposes sensor configuration and data download features over a local Wi-Fi hotspot. The developed sensor has been tested in the field, and the result shows that the BS effectively captures the frames of flying insects and performs surveillance appropriately with an accuracy of more than 90%. A comparison of power efficiency and central processing unit (CPU) utilization is also made between the pre-installed multimedia OS from the manufacturer and the customized OS built using Yocto-build. Results demonstrate that the developed BS is power efficient.","1558-1748","","10.1109/JSEN.2023.3328067","Department of Science and Technology (DST), Government of India, at IIT Ropar for bringing Cyber-Physical System- Based Technological Solutions in the Domain of Agriculture and Water Toward Profitable, Resilient and Sustainable Agriculture; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10305520","Biodiversity sensor (BS);embedded Linux;operating system (OS);over-the-air (OTA);processor;sensor;Yocto","Insects;Sensors;Monitoring;Task analysis;Biosensors;Batteries;Cameras;Biodiversity;Linux","","","","22","IEEE","2 Nov 2023","","","IEEE","IEEE Journals"
"Explore Deep Reinforcement Learning to Energy-Efficient Data Synchronism in 5G Self-Powered Sensor Networks","C. Wu; Y. Zhao; S. Xiao; C. Gao","Big Data and Optimization Research Institute, Chongqing College of Electronic Engineering, Chongqing, China; Chongqing No.1 Middle School, Chongqing, China; Big Data and Optimization Research Institute, Chongqing College of Electronic Engineering, Chongqing, China; Big Data and Optimization Research Institute, Chongqing College of Electronic Engineering, Chongqing, China","IEEE Sensors Journal","14 Sep 2023","2023","23","18","20586","20595","Recently, the explosive data traffic growth and large-scale Internet of Things (IoT) equipment connection have brought 5G mobile communication technology many challenges. The communication delay of network services such as augmented reality, smart grid, disaster warning, and emergency communication has been relieved by 5G. However, these services are still confronted with serious challenge of energy conservation. Most of the traditional optimization methods usually need complex operations and iterations to get optimal results, which are not suitable for communication systems with high real-time performance. Based on this argument, this article has focused on green communication in mobile edge computing (MEC)-based self-powered sensor network and proposed a novel approach called mobile intelligent data synchronization [MIDS based on deep reinforcement learning (DLR)]. It exploits deep deterministic policy gradient (DDPG), continuously interacting with the environment and making tryouts to evaluate the feedback from the environment to optimize future decision-making on the path selection scheme for data transmission as well as achieve the energy efficiency and energy consumption balance of mobile devices with self-powered sensors. We provide experiments to show the capability of our approach in reducing the additional energy consumption of mobile devices and the base station (BS) as well as balancing the energy consumption of mobile devices with sensor communication. The superiority of our approach for energy conservation in data synchronization is convincingly demonstrated by comparing it with state-of-the-art methods in MEC-based self-powered sensor network.","1558-1748","","10.1109/JSEN.2022.3221983","Science and Technology Research Program of Chongqing Municipal Education Commission(grant numbers:KJQN202103108,KJQN202203126); General Project of Chongqing Natural Science Foundation(grant numbers:2022NSCQ-MSX5691); Doctoral Initiation Project of Chongqing College of Electronic Engineering(grant numbers:120724); Research and Application of Industrial Internet Remote Sharing Training Technology(grant numbers:cstc2020jscx-msxmX0091); Research and Application of Key Technologies of Middle School Students’ Growth Intelligence Service Based on Cloud-Network Collaboration(grant numbers:cstc2020jscxdxwtBX0015); Key Technology Research on Intelligent Service of Vocational Skill Training in Post-Epidemic Period(grant numbers:cstc2020jscx-msxmX0157); Chongqing University Innovation Research Group Project(grant numbers:CXQT21031); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9967925","Data synchronization;deep reinforcement learning (DRL);emergency communication;energy conservation;mobile edge computing (MEC);self-powered sensor","Sensors;Synchronization;Energy efficiency;Energy consumption;5G mobile communication;Reinforcement learning;Mobile handsets","","","","48","IEEE","1 Dec 2022","","","IEEE","IEEE Journals"
"Security Analysis and Prevention of Attacks on IoT Devices","A. Raghuprasad; S. Padmanabhan; M. Arjun Babu; P. K. Binu","Department of Computer Science, Amrita Vishwa Vidyapeetham, Amritapuri, India; Department of Computer Science, Amrita Vishwa Vidyapeetham, Amritapuri, India; Department of Computer Science, Amrita Vishwa Vidyapeetham, Amritapuri, India; Department of Computer Science, Amrita Vishwa Vidyapeetham, Amritapuri, India","2020 International Conference on Communication and Signal Processing (ICCSP)","1 Sep 2020","2020","","","0876","0880","As the demand for smart devices in homes increases, more and more manufacturers have been launching these devices on a mass scale. But what they are missing out on is taking care of the security part of these IoT devices which results in a more vulnerable system. This paper presents an idea through a small-scale working model and the studies that made the same possible. IoT devices face numerous threats these days with the ease of access to powerful hacking tools such as aircrack-ng which provides services like monitoring, attacking and cracking Wifi networks. The essential thought of the proposed system is to give an idea of how some common attacks are carried out, how these attacks work and to device some form of prevention as an additional security layer for IoT devices in general. The system proposed here prevents most forms of attacks that target the victim IoT device using their MAC addresses. These include DoS and DDoS attacks, both of which are the main focus of this paper. This paper also points out some of the future research work that can be followed up.","","978-1-7281-4988-2","10.1109/ICCSP48568.2020.9182055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9182055","DoS Attack Prevention;IoT Devices;NodeMCU;Arduino IDE;Smart Devices;Home Security;DHT11 Sensor.","Logic gates;Wireless fidelity;Tools;IEEE 802.11 Standard;Pins;Computer crime","","16","","15","IEEE","1 Sep 2020","","","IEEE","IEEE Conferences"
"A Network Infrastructure for Monitoring Coastal Environments and Study Climate Changes in Marine Systems","F. Campagnaro; N. Toffolo; A. Pozzebon; R. Francescon; A. Barausse; L. Airoldi; M. Zorzi","Department of Information Engineering, University of Padova, Italy; Department of Information Engineering, University of Padova, Italy; Department of Information Engineering, University of Padova, Italy; Wireless and More srl, Padova, Italy; Department of Biology, University of Padova, Italy; Department of Biology, University of Padova, Italy; Department of Information Engineering, University of Padova, Italy","OCEANS 2022, Hampton Roads","19 Dec 2022","2022","","","1","8","Climate changes have a tremendous impact on coastal and littoral areas, strongly affected by seaquakes and floods. Moreover, global warming causes a drastic change on the biodiversity of rivers, seas, lakes, including in biodiversity hotspots and protected areas, such as the Venice Lagoon in Italy. A similar impact is caused by pollutants: this called for a large-scale long-term action that aims to monitor aquatic environmental parameters in order to predict, manage and mitigate these effects. Yet, coastal systems are highly heterogeneous in space and variable over short (daily), medium and long (seasonal, inter-annual) timescales, making reliable but affordable monitoring a challenging task. This paper proposes to automate this process with the use of a low-power sustainable integrated underwater and above water Internet of Things sensor network, able to collect water measurements in a cloud database and make them available to researchers to monitor the status of a certain area and develop their predictions models. Simulation results highlight how Low-Power Wide-Area Networks can support the data collection from a dense sensor deployment.","0197-7385","978-1-6654-6809-1","10.1109/OCEANS47191.2022.9977287","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9977287","Underwater networks;underwater internet of things;LoRa;monitoring coastal environment","Simulation;Climate change;Sea measurements;Rivers;Biodiversity;Reliability;Biomedical monitoring;Internet of Things;Underwater equipment","","3","","30","IEEE","19 Dec 2022","","","IEEE","IEEE Conferences"
"A Comparison of Application Layer Communication Protocols in IoT-enabled Smart Grid","L. Šikić; J. Janković; P. Afrić; M. Šilić; Ž. Ilić; H. Pandžić; M. Živić; M. Džanko","Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia; GDi d.o.o., Zagreb, Croatia; GDi d.o.o., Zagreb, Croatia","2020 International Symposium ELMAR","9 Oct 2020","2020","","","83","86","The modern smart grid consists of the classical power grid augmented with a large-scale ICT and renewable energy integration. An indispensable part of the implementation of such grid is IoT, a system built by integrating internet-connectivity into all kinds of plant, equipment and devices in smart grid. It provides a reliable, real-time communication among applications running on different IoT devices and on cloud or edge infrastructures. To this end, it establishes communication channels by using application protocols for IoT devices. However, to provide effective communication between its devices, it is necessary that an IoT-enabled smart grid uses suitable application protocol regards specific terms, such as minimal traffic load and delivery latency. In order to build an IoT-enabled smart grid which will support the most efficient data flow in the above-mentioned terms, we made an experimental analysis of the communication based on the three most commonly used application protocols: HTTP, MQTT and AMQP. The experiment has been conducted using IoT devices, which are a part of a real Microgrid-IoT laboratory.","1334-2630","978-1-7281-5973-7","10.1109/ELMAR49956.2020.9219030","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9219030","smart grid;IoT;application protocols;HTTP;MQTT;AMQP","Renewable energy sources;Protocols;Telecommunication traffic;Communication channels;Real-time systems;Smart grids;Internet of Things","","3","","11","IEEE","9 Oct 2020","","","IEEE","IEEE Conferences"
"Vulnerability Assessment for IoT Nodes Using OpenBTS and Software Defined Radios","J. de Jesus Rugeles Uribe; E. P. Guillen","Applied Sciences PhD program Universidad Militar Nueva Granada, Bogotá, Colombia; Telecommunications Engineering program Universidad Militar Nueva Granada, Bogota, Colombia","2020 3rd International Conference on Signal Processing and Information Security (ICSPIS)","9 Feb 2021","2020","","","1","4","Large-scale cyber attacks using IoT devices have increased in recent years. One of the strategies to deal with this problem is the use of penetration test techniques. The aim of this study was to develop a vulnerability assessment for an IoT M2M node that uses GSM technology. A test scenario was designed consisting of a GMS network created using USRP N210 and OpenBTS radios in a multicell configuration. An IoT-GSM node was designed from a sim8001 radio module, used in several M2M devices. The IoT node stores the measurements of the radio bases operational parameters that make up the GSM network. An algorithm for controlling an attacking base radio was designed using the OpenBTS API, which allows the deployment of a “man in the middle” attack. The entire test deployment can be carried out remotely. Analysis of the results of the measurements obtained lets us understand the attack's behavior in detail and determine the IoT-GSM node's vulnerability. The results obtained show the potential of SDR and OpenBTS technology as penetration test tools to analyze vulnerabilities of IoT systems.","","978-1-7281-8998-7","10.1109/ICSPIS51252.2020.9340151","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9340151","Internet of Things;Software Defined Radio;Pentesting;OpenBTS;Vulnerability;Man-in-the-middle;M2M;GSM","GSM;Machine-to-machine communications;Signal processing algorithms;Tools;Signal processing;Internet of Things;Software radio","","","","13","IEEE","9 Feb 2021","","","IEEE","IEEE Conferences"
"Research and Application of SM9 in the Ubiquitous Electric IoT","H. Liao; D. Wang; J. Wang; L. Li; H. Wang","State Grid Blockchain Technology (Beijing) Co., Ltd., Beijing, China; State Grid Blockchain Technology (Beijing) Co., Ltd., Beijing, China; State Grid Blockchain Technology (Beijing) Co., Ltd., Beijing, China; State Grid Blockchain Technology (Beijing) Co., Ltd., Beijing, China; State Grid Shanxi Electric Power Company, Taiyuan, China","2020 IEEE 5th Information Technology and Mechatronics Engineering Conference (ITOEC)","16 Jul 2020","2020","","","1764","1768","With the continuous advancement of the reform of the power system, relying on new technologies such as big data, cloud computing, artificial intelligence, the IoT, and blockchain, the construction of the ubiquitous electric IoT has promoted data fusion in all aspects of the system and broke the isolation of data island. However, due to the large scale of system access, the complexity of business operations, and the increasing number of system vulnerabilities and vulnerabilities, it is difficult for traditional network security technologies to ensure system security. The certificateless security mechanism based on domestic passwords can effectively solve the security problems brought by massive terminal access and ensure the stable operation of the power system. In order to meet the security requirements of energy Internet information interaction, this article proposes the SM9 cloud service constructed by converged cloud technology for large-scale terminal interconnection scenarios, and integrates the challenge handshake authentication protocol (CHAP) to prevent Identity authentication affected by replay attacks, improving the security management and control capabilities of terminal access, and comprehensively supporting the construction of world-class energy Internet companies with excellent competitiveness.","","978-1-7281-4323-1","10.1109/ITOEC49072.2020.9141583","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9141583","Ubiquitous Electric IoT;Network Security;Identity Authentication;Domestic Cipher","Authentication;Business;Power systems;Cloud computing;Public key;Password","","1","","11","IEEE","16 Jul 2020","","","IEEE","IEEE Conferences"
"Design and Analysis of In-Band Full-Duplex Private 5G Networks Using FR2 Band","H. Luo; A. Bishnu; T. Ratnarajah","Institute for Digital Communications, School of Engineering, The University of Edinburgh, Edinburgh, U.K.; Institute for Digital Communications, School of Engineering, The University of Edinburgh, Edinburgh, U.K.; Institute for Digital Communications, School of Engineering, The University of Edinburgh, Edinburgh, U.K.","IEEE Access","24 Dec 2021","2021","9","","166886","166905","This paper studies a solution for efficient industrial Internet of things (IIoT) communications through an in-band full-duplex (IBFD) enabled private 5G network in frequency range 2 (FR2) band ( $\geq 24.250$  GHz), where ultra-reliable low-latency communications (URLLC) and enhanced mobile broadband (eMBB) devices can be simultaneously served. Large-scale antenna array and RF beamforming are applied, and a self-interference cancellation (SIC) scheme is proposed under such architecture. Particularly, the proposed RF cancellation scheme addressed two key issues of extending current technologies to wideband operations in FR2 band: limited operational bandwidth and the requirement for a large number of cancellers. Then, a frequency domain-based digital canceller is proposed to process with the residual self-interference (RSI) with short processing latency. A game theoretic user allocation algorithm is proposed to minimise co-channel interference (CCI) in a heterogeneous environment. Given a typical IIoT scenario, the performance of such IBFD private 5G network is evaluated in terms of bit error rate (BER) and spectral efficiency (SE) through simulations and analysed based on numerical results and theoretical calculations. It is demonstrated that the latency of uplink eMBB devices can be reduced by 54% through IBFD radios, and the latency of downlink URLLC devices can be reduced to 0.5 ms with the help of flexible numerology, mini-slot, and self-contained sub-frames introduced in 5G NR. IBFD radios can enhance the SE by 92% compared to HD radios with our SIC and user allocation policy. The high SE in conjunction with abundant resources in FR2 band provides multi-Gbps peak data rates, high reliability, and massive connectivity.","2169-3536","","10.1109/ACCESS.2021.3135663","research grant from Huawei Technologies Canada Company Ltd.; Huawei Technologies (Sweden) AB; U.K. Engineering and Physical Sciences Research Council (EPSRC)(grant numbers:EP/P009549/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9650901","Co-channel interference;FR2 band;in-band full-duplex;IIoT;private 5G network;self-interference cancellation","Radio frequency;Antenna arrays;5G mobile communication;Interference cancellation;Industrial Internet of Things;Array signal processing;Ultra reliable low latency communication","","9","","31","CCBY","14 Dec 2021","","","IEEE","IEEE Journals"
"pDPoSt+sPBFT: A High Performance Blockchain-Assisted Parallel Reinforcement Learning in Industrial Edge-Cloud Collaborative Network","F. Yang; F. Xu; T. Feng; C. Qiu; C. Zhao","School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; China National Tendering Center of Mechanical and Electrical Equipment, Ministry of Industry and Information Technology, Beijing, China; College of Intelligence and Computing, Tianjin University, Tianjin, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China","IEEE Transactions on Network and Service Management","9 Oct 2023","2023","20","3","2744","2759","With the increasing demand for resource scheduling efficiency in Industrial Internet of Things (IIoT), parallel reinforcement learning (PRL) based distributed edge-cloud collaborative resource scheduling scheme has attracted enormous attention. However, the computing and communication capacities, the security degree of massive distributed edge computing servers are different. It is difficult to make a large number of edge servers carry out security and efficiency PRL based edge-cloud collaboration resource scheduling scheme. Thus, in this paper, a large-scale distributed edge-cloud collaborative resource scheduling method based on picture delegated proof of state and suspicious practical byzantine fault tolerance (pDPoSt+sPBFT) consensus algorithm is proposed. To be specific, we first propose a collaborative edge-cloud industrial network architecture to support massive industrial intelligence tasks, then a distributed PRL based resource allocation scheme is utilized. Secondly, in order to improve the efficiency and security of distributed PRL training, we propose a server filtering strategy based on pDPoSt algorithm. Finally, a sPBFT algorithm is proposed to further realize security parameter aggregation of distributed PRL. Experimental results show that the proposed method has good efficiency and security performance compared with the traditional distributed edge-cloud collaborative resource scheduling algorithm. The proposed approach has great potential in complex IIoT scenarios.","1932-4537","","10.1109/TNSM.2022.3230208","Natural Science Foundation of China (NSFC), 2020 Industrial Internet Innovation and Development Project “Smart Energy Internet Security Situation Awareness Platform Project,” Beijing Natural Science Foundation-Haidian Frontier Project “Research on Key Technologies of wireless edge intelligent collaboration for industrial Internet scenarios (L202017),” and BUPT Excellent Ph.D. Students Foundation (CX2020214)(grant numbers:U1805262,U61971050); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9991258","Consensus algorithm;blockchain;security parallel reinforcement learning;edge-cloud collaborative resource scheduling","Servers;Training;Security;Task analysis;Job shop scheduling;Computational modeling;Blockchains","","1","","55","IEEE","19 Dec 2022","","","IEEE","IEEE Journals"
"Towards an Architecture for Agricultural Autonomous Robots’ Scheduling","A. Belhassena; P. Battistoni; M. V. Souza; J. Laneurit; R. Moussa; S. Bimonte; R. Wrembel; M. Abouqateb; C. Cariou; G. Chalhoub; G. André; M. Sebillo; B. Bachelet","TSCF, INRAE, Université Clermont Auvergne, France; University Salerno, Italy; LIMOS-CNRS, Université Clermont Auvergne, Clermont-Ferrand, France; TSCF, INRAE, Université Clermont Auvergne, France; University of Carthage, Tunisia; TSCF, INRAE, Université Clermont Auvergne, France; Poznan University of Technology, Poland; TSCF, INRAE, Université Clermont Auvergne, France; TSCF, INRAE, Université Clermont Auvergne, France; LIMOS-CNRS, Université Clermont Auvergne, Clermont-Ferrand, France; TSCF, INRAE, Université Clermont Auvergne, France; University Salerno, Italy; LIMOS-CNRS, Université Clermont Auvergne, Clermont-Ferrand, France","2021 IEEE 25th International Enterprise Distributed Object Computing Workshop (EDOCW)","1 Dec 2021","2021","","","194","203","Smart farming and IoT technologies open up a new research agenda, which relates to different inter-related scopes within a Farm Management Information System, such as robots’ programming, tasks’ scheduling, sensor data capture, management and processing at different layers of the IoT ecosystem. Many research works address these topics, but to the best of our knowledge none has contributed with a fully-featured architecture design of monitoring and scheduling of autonomous agricultural robots. In this paper, we propose the skeleton of architecture for such kind of IoT systems, called LambdAgrIoT. It is designed to support big data and different types of workload (real-time, near real-time, analytic, and transactional). We present the main features of each layer, and the implementation details and its deployment of the Data Source and Speed layers in a real environment. The paper also discusses the open issues related to the other layers and the deployment of the overall architecture at large scale.","2325-6605","978-1-6654-4488-0","10.1109/EDOCW52865.2021.00049","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9626314","Internet of Things;Big data;Smart farming;Agriculture robots","Processor scheduling;Soft sensors;Computer architecture;Management information systems;Programming;Robot sensing systems;Real-time systems","","1","","40","IEEE","1 Dec 2021","","","IEEE","IEEE Conferences"
"A Lightweight and Chip-Level Reconfigurable Architecture for Next-Generation IoT End Devices","C. Zhang; S. Li; Y. Song; Q. Meng; L. Lu; H. Zhu; X. Wang","Computer Science, Southwest Petroleum University (SWPU), Chengdu, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China (UESTC), Chengdu, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China (UESTC), Chengdu, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China (UESTC), Chengdu, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China (UESTC), Chengdu, China; Shanghai Jiao Tong University, Shanghai, China; Computer Science, Southwest Petroleum University (SWPU), Chengdu, China","IEEE Transactions on Computers","9 Feb 2024","2024","73","3","747","763","The rapid development of IoT applications calls for re-configurable IoT devices that can easily extend new functionality on demand. However, in the current architecture, updating chip functions on the end device is highly coupled with the local microprocessor in both hardware and software aspects, leading to inadequate flexibility. In this paper, we propose LEGO, a lightweight architecture with chip-level plug-and-play capabilities for IoT end devices. To achieve this, we first decoupling the control over heterogeneous chips from end devices to the gateway, and design a novel Unified Chip Description Language (UCDL) to access various types of functional chips uniformly. To supporting chips plug-and-play, we design a novel signal converting circuit on end devices to generate all required underlying signals for chip control. We also design a layered instruction orchestrator and hierarchical scheduler to minimize transmission overhead. The results show that our LEGO system can respond to chips plug-and-play within 0.13 seconds, and the lightweight architecture could reduce 49%$\sim$∼61% of power consumption in practical scenarios compared with traditional IoT end devices that are controlled by a microprocessor. The lightweight and easy-to-deploy features of LEGO makes it helpful to reduce deployment cost, thus conducive to accelerating large-scale applications.","1557-9956","","10.1109/TC.2023.3343094","National Natural Science Foundation of China(grant numbers:U21A20462); Natural Science Starting Project of SWPU(grant numbers:2023QHZ002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10360380","Reconfigurable architecture;chip level plug-and-play;description language","Logic gates;Internet of Things;Computer architecture;Hardware;Costs;Standards;Software","","","","38","IEEE","14 Dec 2023","","","IEEE","IEEE Journals"
"Exploiting Unintended Property Leakage in Blockchain-Assisted Federated Learning for Intelligent Edge Computing","M. Shen; H. Wang; B. Zhang; L. Zhu; K. Xu; Q. Li; X. Du","School of Cyberspace Security, Beijing Institute of Technology, Beijing, China; School of Computer Science, Beijing Institute of Technology, Beijing, China; Cyberspace Security Research Center, Peng Cheng Laboratory, Shenzhen, China; School of Cyberspace Security, Beijing Institute of Technology, Beijing, China; Department of Computer Science and Technology and Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, China; Institute for Network Sciences and Cyberspace, Tsinghua University, Beijing, China; Department of Computer and Information Sciences, Temple University, Philadelphia, PA, USA","IEEE Internet of Things Journal","5 Feb 2021","2021","8","4","2265","2275","Federated learning (FL) serves as an enabling technology for intelligent edge computing, where high-quality machine learning (ML) models are collaboratively trained over large amounts of data generated by various Internet of Things devices while preserving data privacy. To further provide data confidentiality, computation auditability, and participant incentives, the blockchain framework has been incorporated into FL. However, it is an open question whether the model updates from participants in blockchain-assisted FL can disclose properties of the private data the participants are unintended to share. In this article, we propose a novel property inference attack that exploits the unintended property leakage in blockchain-assisted FL for intelligent edge computing. More specifically, we present an active attack to learn the property leakage from model updates of participants and to identify a set of participants with a certain property. We also design a dynamic participant selection strategy tailored to the setting of large-scale FL, which accelerates the selection process of target participants and improves attack accuracy. We evaluate the proposed attack through extensive experiments with publicly available data sets. The experimental results demonstrate that the proposed attack is effective and efficient in inferring various properties of training data, while maintaining the high quality of the main tasks in FL.","2327-4662","","10.1109/JIOT.2020.3028110","Beijing Nova Program(grant numbers:Z201100006820006); NSFC Projects(grant numbers:61972039,61932016,61872041); Beijing Natural Science Foundation(grant numbers:4192050); Zhejiang Lab Open Fund(grant numbers:2020AA3AB04); China National Funds for Distinguished Young Scientists(grant numbers:61825204); Beijing Outstanding Young Scientist Program(grant numbers:BJJWZYJH01201910003011); BNRist(grant numbers:BNR2019RC01011); Science and Technology Planning Project of Guangdong Province(grant numbers:LZC0023,LZC0024); PCL Future Greater-Bay Area Network Facilities for Large-Scale Experiments and Applications(grant numbers:LZC0019); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9210531","Blockchain;edge computing;federated learning (FL);Internet of Things (IoT);property inference","Servers;Training;Computational modeling;Collaborative work;Data models;Training data;Blockchain","","37","","39","IEEE","1 Oct 2020","","","IEEE","IEEE Journals"
"Dynamic Power Control for Cell-Free Industrial Internet of Things With Random Data Arrivals","X. Wang; C. Zhai","College of Electrical Engineering, Qingdao University, Qingdao, China; School of Information Science and Engineering, Shandong University, Qingdao, China","IEEE Transactions on Industrial Informatics","21 Feb 2022","2022","18","6","4138","4147","In this article, we propose an uplink cell-free Industrial Internet of Things (IIoT) framework to support a large number of devices with random data arrivals. By adopting nonorthogonal random pilots and the large-scale fading decoding technique, we derive the closed-form expression of the transmission capacity for each terminal. Considering different statistics of random data arrivals, we formulate a long-term stochastic optimization problem to maximize the minimum time average transmission success ratio (TATSR) through jointly determining the power control coefficients and the combining coefficients for each time period. We reformulate the long-term max–min problem into a sequence of subproblems to minimize the Lyapunov drift plus penalty in each time period. We approximate each mixed integer subproblem as a sigmoid optimization problem, and propose an iterative algorithm by the aid of quadratic transform-based fractional programming and the sequential convex programming to solve it. Simulation results show that our proposed scheme can boost the TATSR.","1941-0050","","10.1109/TII.2021.3077892","Natural Science Foundation of Shandong Province(grant numbers:ZR2020QF002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9424993","Cell-free massive MIMO;dynamic power control;fractional programming;industrial IoT;random data arrival;sigmoid optimization","Industrial Internet of Things;Power control;Fading channels;Optimization;Interference;Diversity reception;Channel estimation","","7","","30","IEEE","6 May 2021","","","IEEE","IEEE Journals"
"Spatiotemporal Anomaly Detection for Large-Scale Sensor Data","M. Zhao; H. Takizawa; T. Soma","Graduate School of Information Sciences, Tohoku University, Sendai, Japan; Cyberscience Center, Tohoku University, Sendai, Japan; AI Analytics Division, NEC Corporation, Tokyo, Japan","2021 12th International Symposium on Parallel Architectures, Algorithms and Programming (PAAP)","4 Mar 2022","2021","","","162","168","In the Internet of Things era, thousands of sensors are used to monitor machine health conditions in modern factories. Such sensing data are often analyzed to detect machinery failures and diagnose the suspicious causes to prevent loss. However, failures rarely happen and are highly diverse in the real world, which brings difficulties in collecting abnormal data for supervised models. Furthermore, large numbers of sensors would lead to the problem of high dimensionality that would decrease the accuracy of anomaly detection. To address these issues, this paper proposes the COrrelation-based SpatioTemporal Anomaly Detection (COSTAD) framework to analyze large-scale sensing data. Temporal anomalies are detected in an unsupervised manner using only normal data. Spatial anomalies are analyzed while reducing the dimensions of input features for machine learning models. Our experimental results indicate that the temporal detection approach outperforms some existing methods, and spatial detection can help analyze the suspicious causes of machinery failures.","","978-1-6654-9639-1","10.1109/PAAP54281.2021.9720310","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9720310","Machinery failure detection;Spatiotemporal analysis;Big time series data","Analytical models;Correlation;Scalability;Time series analysis;Production facilities;Spatial databases;Sensors","","1","","17","IEEE","4 Mar 2022","","","IEEE","IEEE Conferences"
"Improvement and Optimization of Vulnerability Detection Methods for Ethernet Smart Contracts","Z. Yang; W. Zhu; M. Yu","Command and Control Engineering College, Army Engineering University of PLA, Nanjing, China; Command and Control Engineering College, Army Engineering University of PLA, Nanjing, China; Command and Control Engineering College, Army Engineering University of PLA, Nanjing, China","IEEE Access","1 Aug 2023","2023","11","","78207","78223","Smart contracts based on blockchain are widely used in finance, management, Internet of Things, healthcare, and other fields. However, with the rapid development of smart contracts, the corresponding security vulnerability attack cases occur frequently. Existing Ethereum smart contract vulnerability detection tools based on static analysis techniques rely too much on expert rules, for this reason, this paper proposes an Ethereum smart contract vulnerability detection method SCSVM based on support vector machine technology. A representation of smart contracts is constructed based on the word-to-vector technique, the features of Ethereum smart contracts are extracted based on the support vector machine technique, and these features are combined to identify vulnerabilities. Experiments on Smartbugs and Smartbugs-wild show that SCSVM is significantly effective. It achieves a detection accuracy of 87.51%, outperforming five typical static analysis vulnerability detection tools in terms of F1-score. To alleviate the problems of deep learning methods over-relying on large-scale data to train models and collecting a large number of smart contract attack samples in a short period, this paper proposes a basic learner-meta-learner framework, SCLMF. solc-based acquisition of the bytecode of Ethereum smart contract Solidity, on which smart contract representations are constructed via Python and the use of SCLMF for vulnerability detection. The experiments on WScrawlD show that SCLMF has a certain detection effect. Also, to further verify the effectiveness of SCLMF, experiments were conducted on Omniglot, and the detection accuracy was 96.7% and 98.5% under 5-way 1-shot and 5-way 5-shot conditions, respectively, which exceeded Memory-Augmented Neural Networks and CONVOLUTIONAL SIAMESE NETS. In summary, the experiments proved the effectiveness of SCSVM and SCLMF in Ethereum smart contract vulnerability detection.","2169-3536","","10.1109/ACCESS.2023.3298672","KYZYJKKCJC23001; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10192903","Base learner-meta-learner;Ethereum;smart contracts;support vector machines;vulnerability detection;word embedding","Smart contracts;Ethernet;Deep learning;Data models;Semantics;Neural networks;Feature extraction;Metalearning;Support vector machines;Network intrusion","","1","","41","CCBYNCND","25 Jul 2023","","","IEEE","IEEE Journals"
"Flow-Level Dynamic Bandwidth Allocation in SDN-Enabled Edge Cloud using Heuristic Reinforcement Learning","A. Qadeer; M. J. Lee; K. Tsukamoto","Department of Electrical Engineering, The City College of New York of CUNY, New York, USA; Department of Electrical Engineering, The City College of New York of CUNY, New York, USA; Department of ECE, Kyutech, Japan","2021 8th International Conference on Future Internet of Things and Cloud (FiCloud)","9 Nov 2021","2021","","","1","10","Edge Cloud (EC) is poised to brace massive machine type communication (mMTC) for 5G and IoT by providing compute and network resources at the edge. Yet, the EC being regionally domestic with a smaller scale, faces the challenges of bandwidth and computational throughput. Resource management techniques are considered necessary to achieve efficient resource allocation objectives. Software Defined Network (SDN) enabled EC architecture is emerging as a potential solution that enables dynamic bandwidth allocation and task scheduling for latency sensitive and diverse mobile applications in the EC environment. This study proposes a novel Heuristic Reinforcement Learning (HRL) based flow-level dynamic bandwidth allocation framework and validates it through end-to-end implementation using OpenFlow meter feature. OpenFlow meter provides granular control and allows demand-based flow management to meet the diverse QoS requirements germane to IoT traffics. The proposed framework is then evaluated by emulating an EC scenario based on real NSF COSMOS testbed topology at The City College of New York. A specific heuristic reinforcement learning with linear-annealing technique and a pruning principle are proposed and compared with the baseline approach. Our proposed strategy performs consistently in both Mininet and hardware OpenFlow switches based environments. The performance evaluation considers key metrics associated with real-time applications: throughput, end-to-end delay, packet loss rate, and overall system cost for bandwidth allocation. Furthermore, our proposed linear annealing method achieves faster convergence rate and better reward in terms of system cost, and the proposed pruning principle remarkably reduces control traffic in the network.","","978-1-6654-2574-2","10.1109/FiCloud49777.2021.00009","NSF(grant numbers:1818884); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9590326","Edge Cloud;Software Defined Networking;Reinforcement Learning;Bandwidth Allocation;Resource Management;OpenFlow","Meters;Cloud computing;Costs;Reinforcement learning;Channel allocation;Dynamic scheduling;Throughput","","8","","30","IEEE","9 Nov 2021","","","IEEE","IEEE Conferences"
"Large-Scale Networks: From Intelligent Robotics to Emergency Response","R. Kozma",University of Memphis,"2022 IEEE 16th International Symposium on Applied Computational Intelligence and Informatics (SACI)","25 Oct 2022","2022","","","000011","000012","Since the turn of the century, the theory of large-scale networks have been studied extensively and lead to a wide range of applications in various disciplines, including computer networks, the www, sensor networks, transportation networks, power systems, the IoT, biological networks, genetic networks, social networks, and many others. We overview the foundation of network theory going back to the pioneering work on Erdos-Renyi on random graphs and phase transitions, followed by small worlds, such as Barabasi-Albert, Strogatz- Watts, scale-free systems with Black Swan statistics, as well as Dragon Kings. Depending on the statistical properties of the structures of these networks, their dynamics may be predictable of essentially unpredictable. Various methods are being developed to control the corresponding network dynamics. The theoretical results lead to novel approaches to autonomous robot control. Another application area includes highly flexible and rapidly reconfigurable distributed sensor networks to support robust decisions. Transitions between various scenarios and corresponding strategies are made rapidly and robustly via phase transitions. The introduced methods are applicable in emergency scenarios during natural or man-made disasters.","","978-1-6654-8125-0","10.1109/SACI55618.2022.9919528","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9919528","","Social networking (online);Power system dynamics;Transportation;Robot sensing systems;Genetics;Emergency services;Computer networks","","","","0","IEEE","25 Oct 2022","","","IEEE","IEEE Conferences"
"A multidimensional human-centric framework for environmental intelligence: Air pollution and noise in smart cities","A. Bardoutsos; G. Filios; I. Katsidimas; T. Krousarlis; S. Nikoletseas; P. Tzamalis","Computer Engineering and Informatics Department, University of Patras, Patras, Greece; Computer Engineering and Informatics Department, University of Patras, Patras, Greece; Computer Engineering and Informatics Department, University of Patras, Patras, Greece; Inlecom Innovation, Athens, Greece; Computer Engineering and Informatics Department, University of Patras, Patras, Greece; Computer Engineering and Informatics Department, University of Patras, Patras, Greece","2020 16th International Conference on Distributed Computing in Sensor Systems (DCOSS)","1 Sep 2020","2020","","","155","164","For the important problem of increasing levels of air pollution and noise in urban and rural areas, we propose a holistic, multi-dimensional approach to gather, monitor and analyze heterogeneous data sources of air pollutants and noise indicators, into an integrated, intelligent computational system. Although several interesting approaches have been developed for monitoring pollution and noise, however the challenge remains for even more detailed, precise, large scale monitoring.To overcome the limitations of current systems, we envision an integrated approach to human-centric environmental intelligence, bringing together modern IoT technology and the human factor. In particular, our approach emphasizes selected behavioural and health aspects, and the complementary use of sensing technology with citizen engagement and crowdsourcing methods. The proposed system will collect diverse data from heterogeneous sources, such as mobile and static wireless sensor networks, crowdsourcing, citizen questionnaires and social media analytics, to continuously combine objective estimations with subjective perception of air quality and noise. With the use of advanced AI and Deep Learning algorithms, our system will be able to estimate air pollutants concentration and noise levels in micro-scale with adequate precision over large urban-scale environments. Furthermore, tracking of behavioral and psychological users' input, as well as personal exposure to pollution, will allow studying the impact of air quality and noise on the users' daily habits and the interplay of ambient conditions with behavioural factors, towards an active engagement of citizens in a hybrid techno-social manner. A reference architecture for the realization of this human-centric environmental intelligence approach is presented. Also, a planned implementation at the city of Patras, Greece is discussed. To the best of our knowledge, this is one of the first holistic, multifaceted approaches to a surveillance system for air quality and noise in urban areas.","2325-2944","978-1-7281-4351-4","10.1109/DCOSS49796.2020.00036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9183628","air quality;noise;system;monitoring;IoT;smart city;crowdsourcing;mobile sensing","Air pollution;Monitoring;Urban areas;Sensors;Wireless sensor networks","","7","","51","IEEE","1 Sep 2020","","","IEEE","IEEE Conferences"
"Scalable On-Chain and Off-Chain Blockchain for Sharing Economy in Large-Scale Wireless Networks","T. Cai; W. Chen; K. E. Psannis; S. K. Goudos; Y. Yu; Z. Zheng; S. Wan","Sun Yat-Sen University, China; Sun Yat-Sen University, China; University of Macedonia, Greece; Aristotle University of Thessaloniki, Greece; Sun Yat-Sen University, China; Sun Yat-Sen University, China; University of Electronic Science and Technology of China, China","IEEE Wireless Communications","16 Aug 2022","2022","29","3","32","38","In the future sharing economy, billions of underutilized IoT devices will be deployed to enable a powerful and large-scale sharing market that produces economic, environmental, and social benefits. Given the fact that communications in numerous IoT devices through wireless links are unreliable, blockchain technology, as a promising solution, has emerged to achieve reliable and secure sharing services in a decentralized manner. However, applying blockchain in large-scale wireless networks confronts scalability challenges. This motivates us to propose a real-time, trusted data interactive, and fine-grained transaction supportable sharing framework, the core of which is a novel two-layer scaling blockchain design. In the on-chain layer, sharing-oriented sharding is employed to enable secure and efficient processing of macro-transactions on the chain. In the off-chain layer, cross-zone off-chain channels are set up to provide real-time sharing transactions with high-frequency micro-trading scenarios. Finally, a proof-of-concept case study of electric vehicle sharing data is implemented with experimental results to demonstrate the feasibility of our framework.","1558-0687","","10.1109/MWC.004.2100616","National Natural Science Foundation of China(grant numbers:62172453,62032025,62172438); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9857806","","Wireless networks;Scalability;Information sharing;Sharing economy;Electric vehicles;Real-time systems;Blockchains","","10","","15","IEEE","16 Aug 2022","","","IEEE","IEEE Magazines"
"IoT Platform for Remote Monitoring and Controlling Small-scale Ventilator for SAR Patient","F. Ullah; M. J. Khan; Q. Arsalan; J. Khattak; U. A. Siddiqui; A. A. Siddiqui","College of Information Technology, UAEU, United Arab Emirates; College of Information Technology, UAEU, United Arab Emirates; Department of Electrical & Engineering, COMSATS University Islamabad-Attock Campus, Attock, Pakistan; Department of Electrical & Engineering, COMSATS University Islamabad-Attock Campus, Attock, Pakistan; Department of Electrical & Engineering, COMSATS University Islamabad-Attock Campus, Attock, Pakistan; Department of Electrical & Engineering, COMSATS University Islamabad-Attock Campus, Attock, Pakistan","2023 15th International Conference on Innovations in Information Technology (IIT)","25 Dec 2023","2023","","","202","207","The Sever Actuatory Respiratory disease termed COVID-19 has triggered worldwide vital ventilator shortages. It necessitates designing a mechanical ventilator based on a microcontroller structure combined with an AMBU Bag (BVM) ventilation mechanism and IoT-enabled remote monitoring and controlling. Mechanical ventilators, called life support systems, are designed for use in the treatment of respiratory insufficiency. The COVID-19 pandemic disease mainly affects the respiratory system and involves mechanical ventilators for breathing control. This article aims to design an intelligent health monitoring and small-scale ventilator system for breathing control using oxygen. The proposed system consists of: (1) Raspberry-pi based platform for interfacing various sensors and actuators required for ventilation; (2) Breathing (O2) control using the proper level of various constituents of air while maintaining the required pressure level; (3) Controlling of inhale and exhale valves based on sensor data; (4) Proper flow control of air mixture; (5) IoT and Web-based platform for remote ventilator patient monitoring. The experimental results show the efficient remote management of the small-scale ventilator system.","2473-2052","979-8-3503-8239-6","10.1109/IIT59782.2023.10366493","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10366493","SAR;CVOID-19;Remote Patient Monitoring;IoT;Web of Things","COVID-19;Ventilators;Technological innovation;Medical services;Ventilation;Valves;Sensor systems","","","","18","IEEE","25 Dec 2023","","","IEEE","IEEE Conferences"
"A Scalable Byzantine Fault Tolerance Algorithm Based on a Tree Topology Network","W. Jiang; X. Wu; M. Song; J. Qin; Z. Jia","College of Information Science and Engineering, Xinjiang University, Ürümqi, China; College of Information Science and Engineering, Xinjiang University, Ürümqi, China; College of Information Science and Engineering, Xinjiang University, Ürümqi, China; College of Information Science and Engineering, Xinjiang University, Ürümqi, China; College of Information Science and Engineering, Xinjiang University, Ürümqi, China","IEEE Access","10 Apr 2023","2023","11","","33509","33519","The consortium chain is the main form of application of blockchain technology in the actual industry, and its consensus mechanism mostly adopts the practical Byzantine fault tolerance (PBFT) algorithm. The traditional PBFT algorithm is only suitable for small-scale local area networks, but in large-scale wide area network environments, its scalability bottleneck has a serious impact on the performance of the system. Therefore, in this paper, a scalable Byzantine fault tolerance algorithm based on a tree topology network is proposed (STBFT), which can take different steps to reach consensus according to the abnormal situation of the system. First, the STBFT algorithm divides the consensus nodes into different layers and groups based on the tree topology network structure, which transforms from global consensus to local consensus and drastically reduces communication consumption. Then, the division method of the group is based on a verifiable random function (VRF), with the purpose of preventing targeted attacks and colluding Byzantine nodes from affecting the normal consensus of the system. Finally, a feedback mechanism is proposed for the first time to reduce the influence of Byzantine failure on hierarchical network systems. The simulation results show that the proposed algorithm reduces the communication complexity and improves the fault tolerance of the system, and the scalability of the tree topology network structure can be better applied in large-scale scenarios such as IoT and health care.","2169-3536","","10.1109/ACCESS.2023.3264011","Major Project of Xinjiang Uygur Autonomous Region(grant numbers:2020A03001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10091103","Tree topology network;PBFT;scalability;communication complexity;high fault tolerance","Heuristic algorithms;Fault tolerant systems;Communications systems;Security;Scalability;Peer-to-peer computing;Consensus algorithm;Topology","","2","","38","CCBYNCND","3 Apr 2023","","","IEEE","IEEE Journals"
"Fairledger: a Fair Proof-of-Sequential-Work based Lightweight Distributed Ledger for IoT Networks","R. Xu; Y. Chen","Department of Electrical and Computer Engineering, Binghamton University, Binghamton, NY, USA; Department of Electrical and Computer Engineering, Binghamton University, Binghamton, NY, USA","2022 IEEE International Conference on Blockchain (Blockchain)","19 Sep 2022","2022","","","348","355","Blockchain has been recognized as a promising solution to construct a tamper-proof and trust-free decentralized framework for Internet of Things (loT) systems. However, directly applying cryptocurrency-oriented blockchains in loT networks still meets tremendous limitations. Proof-of-Work (PoW) consensus protocol enables a blockchain to achieve pseudonymity, scalability and probabilistic finality in an asynchronous and open-access network environment. The compute-intensive PoW favors nodes possessing more computing power, but fairness is an important requirement in highly heterogeneous loT networks. A blockchain designed for loT edge environments must consider devices with various constraints on computation power. This paper proposes Fairledger, a fair Proof-of-Sequential-Work (PoSW) based lightweight distributed ledger for small-scale, permissioned loT networks. By combining efficient verifiable delay function (eVDF) and Proof-of-Credit (PoC) puzzle, PoSW consensus protocol guarantees fairness by requiring all the miners perform a fixed sequential computing steps to represent PoW for block generation despite their hardware resources. Due to the virtual mining manner of PoSW, Fairledger demonstrates computing efficiency compared to traditional PoW blockchains. In addition, Fairledger is less susceptible to “long-range” and “nothing-at-stake” attacks than Proof-of-Stake (PoS) protocols are. A proof-of-concept prototype is implemented, and the experimental results verify the feasibility of running Fairledger in a physical loT network with higher throughput, less computation and communication cost, and better security guarantees.","","978-1-6654-6104-7","10.1109/Blockchain55522.2022.00055","National Science Foundation(grant numbers:CNS-2039342); Air Force Office of Scientific Research(grant numbers:FA9550-21-1-0229); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9881850","Blockchain;Fairness;Security;Proof-of-Sequential-Work (PoSW) Consensus;Verifiable Delay Functions (VDF);Internet-of-Things (loT)","Performance evaluation;Distributed ledger;Scalability;Voting;Prototypes;Throughput;Robustness","","","","30","IEEE","19 Sep 2022","","","IEEE","IEEE Conferences"
"IoT-Enabled Real-Time Management of Smart Grids With Demand Response Aggregators","A. Estebsari; P. R. Mazzarino; L. Bottaccioli; E. Patti","London South Bank University, London, U.K.; Politecnico di Torino, Turin, Italy; Politecnico di Torino, Turin, Italy; Politecnico di Torino, Turin, Italy","IEEE Transactions on Industry Applications","19 Jan 2022","2022","58","1","102","112","Integration of widely distributed small-scale renewable energy sources like rooftop photovoltaic panels and emerging loads like plug-in electric vehicles would cause more volatility in total net demand of distribution networks. Utility-owned storage units and control devices like tap changers and capacitors may not be sufficient to manage the system in real-time. Exploitation of available flexibility in demand side through aggregators is a new measure that distribution system operators are interested in. In this article, we present a developed real-time management schema based on Internet of things solutions which facilitate interactions between system operators and aggregators for ancillary services like power balance at primary substation or voltage regulation at secondary substations. Two algorithms for power balance and voltage regulation are developed based on modified optimal power flow and voltage sensitivity matrix, respectively. To demonstrate the applicability of the schema, we set-up a real-time simulation-based test bed and realized the performance of this approach in a real-like environment using real data of a network with residential buildings.","1939-9367","","10.1109/TIA.2021.3121651","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9582830","Aggregator;demand response;Internet of things (IoT);power flow;real-time simulation","Real-time systems;Smart grids;Substations;Renewable energy sources;Costs;Voltage control;Demand response","","12","","43","IEEE","20 Oct 2021","","","IEEE","IEEE Journals"
"Design of The Ultra-Low-Power Driven VMM Configurations for μW Scale IoT Devices","K. Takano; T. Yajima; S. Kawakami","Kyushu University, Fukuoka, Japan; Kyushu University, Fukuoka, Japan; Kyushu University, Fukuoka, Japan","2023 IEEE 16th International Symposium on Embedded Multicore/Many-core Systems-on-Chip (MCSoC)","17 Jan 2024","2023","","","65","72","Operating IoT devices by supplying power from an energy harvester and installing AI accelerators in IoT devices are required. Nevertheless, conventionally selected architectures for AI processing require a large amount of power, making it difficult to operate in low-power bands such as IoT devices or even impossible to operate in the first place. Therefore, driving AI accelerators with power that energy harvesters can supply is an issue. However, there has been no past exploration of AI accelerators in the driven of the μW scale. In this paper, we analyze the configuration of Vector Matrix Multiplier, mainly used for AI accelerators, and show the effective configuration for μW scale IoT devices. Using 180nm CMOS to synthesize the four architectures of various sizes, we characterize device performance and analyze energy consumption and circuit area. As a result of the analysis, it shows that the configuration in which all calculations are deployed on the circuit can have the lowest energy consumption. In addition, we found that when there is a limit on circuit area, a configuration in which some calculations are performed in the time domain by lowering the voltage is suitable.","2771-3075","979-8-3503-9361-3","10.1109/MCSoC60832.2023.00018","New Energy and Industrial Technology Development Organization; University of Tokyo; Xilinx; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10387933","μW Scale IoT;RTL;Energy Harvesting;Ma-chine Learning","Performance evaluation;Energy consumption;Virtual machine monitors;Power demand;AI accelerators;Computer architecture;Voltage","","","","28","IEEE","17 Jan 2024","","","IEEE","IEEE Conferences"
"A Granular Computing Approach for Multi-Labelled Sequences Classification in IEEE 802.11 Networks","G. Granato; A. Martino; A. Rizzi","Department of Information Engineering, Electronics and Telecommunications, University of Rome “La Sapienza”, Rome, Italy; Department of Business and Management, LUISS University, Rome, Italy; Department of Information Engineering, Electronics and Telecommunications, University of Rome “La Sapienza”, Rome, Italy","2022 International Joint Conference on Neural Networks (IJCNN)","30 Sep 2022","2022","","","1","9","Recent developments in communication networks have made new kind of services possible, which are even more connected due to smart Internet of Things devices and sensor networks. This complex integration of technologies had increased the attack surface on networks that are spread across multiple environments, with different protocols and services, usually based on the wireless medium. Network Intrusion Detection Systems aim to overcome these security issues, analyzing network traffic and applying multiple reconnaissance techniques. For this purpose, state-of-the-art research activities have been focused on Artificial Intelligence and Machine Learning-based approaches in order to scale more efficiently the capabilities of this kind of systems (in terms of both complexity, speed and training data required). Our work further analyzes these security issues, in particular, by introducing a consolidated approach based on the Granular Computing information processing paradigm applied to sequences of WiFi frames. We focused on a subset of attacks collected in the Aegean WiFi Intrusion Detection dataset, that consists in complex multi-step attacks or simpler control frames flooding attacks, not recognizable using a single-frame processing strategy. This kind of structured data heterogeneity implies a non-exclusive labelling strategy, as each frames' sequence could bring information related to different attack classes, making the whole supervised problem more challenging. We show that the proposed solution provides interesting results in terms of classification performances, limited embedding complexity and peculiar white-box trained models.","2161-4407","978-1-7281-8671-9","10.1109/IJCNN55064.2022.9892473","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9892473","Machine Learning;Granular Computing;Knowledge Discovery;Explainable Artificial Intelligence;Intrusion Detection;Communication Networks;WiFi","Wireless communication;Wireless sensor networks;Protocols;Granular computing;Training data;Process control;Telecommunication traffic","","1","","27","IEEE","30 Sep 2022","","","IEEE","IEEE Conferences"
"Design of waiting time Perception System in charging station based on Internet of things","Z. Li; F. Zhou; Y. Yu; H. Zhou; B. Huang","School of Electrical Engineering, Beijing Jiaotong University, Beijing, China; School of Electrical Engineering, Beijing Jiaotong University, Beijing, China; School of Electrical Engineering, Beijing Jiaotong University, Beijing, China; School of Electrical Engineering, Beijing Jiaotong University, Beijing, China; State Grid Shaoyang Power Supply Branch Company, State Grid Hunan Electric Power Co., Ltd., Shaoyang, China","2021 IEEE 4th International Electrical and Energy Conference (CIEEC)","17 Aug 2021","2021","","","1","6","In order to improve the charging service quality of electrical vehicles (shorted as EVs) , it is necessary to provide waiting time information in charging station for EV users, in order to ensure their time schedule better and their time utilization more efficiently. Therefore, based on Internet of things, firstly, from the designated waiting area of the charging station, the information needed to be collected are analyzed, and the appropriate sensing modes are selected; secondly, based on the analysis of waiting time composition, an information perception system is designed to obtain the accurate waiting time in charging stations; finally, according to the charging curves of batteries, capacitor is used as simulated component. The working process of the charging waiting time which is based on MSIC (Medium scale integrated circuit) is simulated by Proteus.The results show that the designed perception system can satisfy the expected requirements.","","978-1-7281-7149-4","10.1109/CIEEC50170.2021.9511007","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9511007","charging station;waiting time;Internet of Things technology;perception system;Proteus","Integrated circuits;Schedules;Conferences;Estimation;Information processing;Charging stations;Predictive models","","","","12","IEEE","17 Aug 2021","","","IEEE","IEEE Conferences"
"μDFL: A Secure Microchained Decentralized Federated Learning Fabric Atop IoT Networks","R. Xu; Y. Chen","Department of Electrical and Computer Engineering, Binghamton University, Binghamton, NY, USA; Department of Electrical and Computer Engineering, Binghamton University, Binghamton, NY, USA","IEEE Transactions on Network and Service Management","12 Oct 2022","2022","19","3","2677","2688","Federated Learning (FL) has been recognized as a privacy-preserving machine learning (ML) technology that enables collaborative training and learning of a global ML model based on the aggregation of distributed local model updates. However, security and privacy guarantees could be compromised due to malicious participants and the centralized aggregation manner. Possessing attractive features like decentralization, immutability and auditability, Blockchain is promising to enable a tamper-proof and trust-free framework to enhance performance and security in IoT based FL systems. However, directly integrating blockchains into the large scale IoT-based FL scenarios still faces many limitations, such as high computation and storage demands, low transactions throughput, poor scalability and challenges in privacy preservation. This paper proposes  $\mu $ DFL, a novel hierarchical IoT network fabric for decentralized federated learning (DFL) atop of a lightweight blockchain called microchain. Following the hierarchical infrastructure of FL, participants in  $\mu $ DFL are fragmented into multiple small scale microchains. Each microchain network relies on a hybrid Proof of Credit (PoC) block generation and Voting-based Chain Finality (VCF) consensus protocol to ensure efficiency and privacy-preservation at the network of edge. Meanwhile, microchains are federated vie a high-level inter-chain network, which adopts an efficient Byzantine Fault Tolerance (BFT) consensus protocol to achieve scalability and security. A proof-of-concept prototype is implemented, and the experimental results verify the feasibility of the proposed  $\mu $ DFL solution in cross-devices FL settings with efficiency, security and privacy guarantees.","1932-4537","","10.1109/TNSM.2022.3179892","U.S. National Science Foundation (NSF) via(grant numbers:CNS-2141468); U.S. Air Force Office of Scientific Research (AFOSR) Dynamic Data and Information Processing Program (DDIP) via(grant numbers:FA9550-21-1-0229); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9786753","Internet of Things (IoT);federated learning;hierarchical blockchain;proof of credit;security;privacy","Training;Data models;Computational modeling;Data privacy;Consensus protocol;Privacy;Collaborative work","","13","","41","IEEE","2 Jun 2022","","","IEEE","IEEE Journals"
"DOLPHIN: Dynamically Optimized and Load Balanced Path for Inter-Domain SDN Communication","Z. Latif; K. Sharif; F. Li; M. M. Karim; S. Biswas; M. Shahzad; S. P. Mohanty","School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; Faridpur Engineering College, University of Dhaka, Dhaka, Bangladesh; School of Sciences, University of Central Lancashire, Pyla, Cyprus; Department of Computer Science and Engineering, University of North Texas, Denton, TX, USA","IEEE Transactions on Network and Service Management","10 Mar 2021","2021","18","1","331","346","Software-Defined Networking has become an integral technology for large scale networks that require dynamic flow management. It separates the control function from data plane devices and centralizes it in a domain controller. However, only a limited number of switches can be managed by a single and centralized controller which introduces challenges such as scalability, reliability, and availability. Distributed controller architecture resolves these issues but also introduces new challenges of uneven load and traffic management across domains. As real-world networks have redundant links, hence a significant challenge is to distribute traffic flows on multiple paths, within a domain, and across multiple independent domains. The selection of ingress and egress switches becomes even more problematic if the intermediate domain is non-cooperative. In this work, we propose a Dynamically Optimized and Load-balanced Path for Inter-domain (DOLPHIN) communication system, a customized solution for different SDN controllers. It provides control beyond the virtual switch elements in intra and inter-domain communication and extends the range of programmability to wireless devices, such as the Internet of Things or vehicular networks. Extensive simulation results show that the traffic load is distributed evenly on multiple links connecting different domains. We model data center communication and 5G vehicular network communication to show that, by load balancing the flow completion times of the different types of network traffic can be significantly improved.","1932-4537","","10.1109/TNSM.2020.3045725","National Natural Science Foundation of China(grant numbers:62072040,61772077); Beijing Natural Science Foundation(grant numbers:4192051); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9298882","Software defined networking;inter-domain communication;vertical programmability;load balancing","Load management;Control systems;Routing;Heuristic algorithms;Optimization;Computer architecture;Scalability","","12","","49","IEEE","18 Dec 2020","","","IEEE","IEEE Journals"
"An Overlapping Self-Organizing Sharding Scheme Based on DRL for Large-Scale IIoT Blockchain","X. Yang; T. Xu; F. Zan; T. Ye; Z. Mao; T. Qiu","College of Intelligence and Computing, and the Tianjin Key Laboratory of Advanced Networking, Tianjin University, Tianjin, China; College of Intelligence and Computing, and the Tianjin Key Laboratory of Advanced Networking, Tianjin University, Tianjin, China; School of Computer, Qinghai Minzu University, Xining, China; School of Computer, Qinghai Minzu University, Xining, China; College of Management and Economics, Tianjin University, Tianjin, China; College of Intelligence and Computing, and the Tianjin Key Laboratory of Advanced Networking, Tianjin University, Tianjin, China","IEEE Internet of Things Journal","5 Feb 2024","2024","11","4","5681","5695","Sharding is widely regarded as a highly promising solution to address the scalability limitations of blockchain. However, the scalability and throughput improved by using sharding are limited by the verification of cross-shard transactions. To reduce cross-shard transaction and improve the throughput of the blockchain, the existing sharding schemes are based on factors such as the edge-end structure of Industrial Internet of Things (IIoT) for sharding. But these schemes are centralized, leading to the problems of low sharding efficiency, poor scalability, and poor security. Moreover, these schemes adopt a nonoverlapping sharding architecture, so the verification cost of cross-shard transactions is significantly higher than that of intrashard transactions. In order to solve the above problems, this article proposes an overlapping self-organizing sharding scheme (deep reinforcement learning (DRL)-OSS) for large-scale IIoT blockchain. Based on local blockchain information, such as nodes’ information and transaction interaction frequency, DRL-OSS uses DRL to achieve self-organizing sharding with the aim to maximize the throughput and security of blockchain. In addition, based on the threat model, this article also designs a block complaint scheme (BCS) to further improve the security of the blockchain, thereby avoiding the reduction in resistance to 1% attack due to the poor anti-predictability of shards and the dilution of computing power. Through experimental verification and analysis, DRL-OSS improves the throughput by 50% when compared to state-of-the-art sharding schemes and has higher system security.","2327-4662","","10.1109/JIOT.2023.3311414","Joint Funds of the National Natural Science Foundation of China(grant numbers:U2001204); National Science Fund for Distinguished Young Scholars of China(grant numbers:62325208); National Natural Science Foundation of China(grant numbers:62272339); National Natural Science Foundation Council of China(grant numbers:92167206); Open Research Project of Zhejiang Laboratory(grant numbers:2021KF0AB02); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10239112","Blockchain;deep reinforcement learning (DRL);Industrial Internet of Things (IIoT);self-organizing sharding","Sharding;Blockchains;Security;Throughput;Industrial Internet of Things;Costs;Scalability","","","","29","IEEE","4 Sep 2023","","","IEEE","IEEE Journals"
"Scalable Transparent Access to 5G Edge Services","J. Hammer; H. Hellwagner","Institute of Information Technology, Alpen-Adria-Universitat Klagenfurt, Austria; Institute of Information Technology, Alpen-Adria-Universitat Klagenfurt, Austria","2023 IEEE 7th International Conference on Fog and Edge Computing (ICFEC)","29 Jan 2024","2023","","","40","48","The challenging demands for the next generation of the Internet of Things have led to a massive increase in edge computing and network virtualization technologies. One significant technology is Multi-access Edge Computing (MEC), a central piece of 5G telecommunication systems. MEC provides a cloud computing platform at the edge of the radio access network and is particularly essential to satisfy the challenging low-latency demands of future applications. Our previous pub-lications argue that edge computing should be transparent to clients. We introduced an efficient solution to implement such a transparent approach, leveraging Software-Defined Networking (SDN) and virtual IP+port addresses for registered edge services. Building on our already efficient approach, in this work, we propose significant improvements to scale our transparent solution to large-scale real-world access networks. First, by improving the modularity of our SDN controller design, we enable various options to distribute both the SDN controller's load and the switches' flows. Second, we introduce the Unique Mask, a solution superior to the Unique Prefix presented in our previous work that considerably reduces the number of required flows in the switches. Our evaluations show that both algorithms perform very well, with the Unique Mask capable of reducing the number of flows by up to 98 %.","","979-8-3503-2288-0","10.1109/ICFEC57925.2023.00014","Austrian Research Promotion Agency(grant numbers:888098); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10402894","Multi-Access Edge Computing;MEC;Fog computing;Software-Defined Networking;SDN;Patricia Trie","5G mobile communication;Scalability;Buildings;Computer architecture;Control systems;Virtualization;Software defined networking","","","","36","IEEE","29 Jan 2024","","","IEEE","IEEE Conferences"
"Mozi IoT Malware and Its Botnets: From Theory To Real-World Observations","J. Sahota; N. Vlajic","Department of Electrical Engineering and Computer Science, Lassonde School of Engineering, York University, Toronto, Canada; Department of Electrical Engineering and Computer Science, Lassonde School of Engineering, York University, Toronto, Canada","2021 International Conference on Computational Science and Computational Intelligence (CSCI)","22 Jun 2022","2021","","","698","703","Mozi IoT malware arrived on the Internet stage in late 2019, and since then has managed to infected over 1.5 million IoT devices, established numerous large-scale botnets, and generate more attack traffic in 2020 and 2021 than any of its IoT-malware counterparts. Even though Mozi code is a blend of three other infamous malware families (Mirai, Gafgyt, and IoTReaper), the main distinguishing feature of Mozi botnets -relative to those of its direct predecessors - is their P2P networking architecture. Notwithstanding Mozi’s significance and prevalence in the real world, there is very little mention of this IoT malware in academic research literature. This paper is one of the first attempts to bring the attention of the research community to the architecture and operation of Mozi and its botnets. The information provided in the paper is in part based on our own experimentation with live monitored instances of Mozi malware.","","978-1-6654-5841-2","10.1109/CSCI54926.2021.00181","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9799037","IoT malware;Mozi;decentralized botnet;peer-to-peer botnet architecture","Scientific computing;Botnet;Computer architecture;Malware;Internet of Things;Security;Computer crime","","","","19","IEEE","22 Jun 2022","","","IEEE","IEEE Conferences"
"Configuration of the Detection Function in a Distributed IDS Using Game Theory","C. Weill; A. Olivereau; D. Zeghlache","CEA, LIST, Palaiseau, France; CEA, LIST, Palaiseau, France; Institut Telécom Telecom SudParis, Evry, France","2020 23rd Conference on Innovation in Clouds, Internet and Networks and Workshops (ICIN)","9 Apr 2020","2020","","","210","215","With the rise of the Internet-of-Things, networks are becoming abundant and diverse in nature. Classical solutions to defend such networks, such as firewalls or access control, cannot scale appropriately. The use of Intrusion Detection Systems, especially networked-based, is widespread as a means to compensate for these shortcomings. Yet, the resources to monitor each network individually, grows considerably with the number of networks and the number of different attacks. To solve this issue, we present a distributed network IDS composed of several probes that monitor the different networks. Each probe of the IDS has access to a large number of detection libraries for signature-based detection, as well as our own anomaly-based detection library. However using these detection mechanisms has a cost on each probe, the choice of network to monitor and of the libraries to use, is a complex one that depends on the attacker's strategies and the goals of the defender. To optimize the detection function at every step, this paper models the choices as a two-player nonzero-sum game between the attackers of the network and the IDS's configuration. There are several papers in the literature that use game theory to find optimal configurations of distributed IDS. Those works have been extended here and through a thorough analysis of our framework, we have established guidelines for IDSs.","2472-8144","978-1-7281-5127-4","10.1109/ICIN48450.2020.9059373","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9059373","Intrusion Detection System (IDS);Network Security;Game Theory;Nash Equilibrium (NE);Repeated Games;Anomaly Detection","Probes;Games;Monitoring;Libraries;Game theory;Intrusion detection","","2","","10","IEEE","9 Apr 2020","","","IEEE","IEEE Conferences"
"HARP: Hierarchical Resource Partitioning in Dynamic Industrial Wireless Networks","J. Wang; T. Zhang; D. Shen; X. S. Hu; S. Han","Dept. of Computer Science and Engineering, University of Connecticut, Storrs, CT; Dept. of Computer Science and Engineering, University of Connecticut, Storrs, CT; School of Computer Science and Engineering, Northeastern University, Shenyang, China; Dept. of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN; Dept. of Computer Science and Engineering, University of Connecticut, Storrs, CT","2022 IEEE 42nd International Conference on Distributed Computing Systems (ICDCS)","13 Oct 2022","2022","","","1029","1039","Industrial wireless networks (IWNs) are being increasingly deployed in the field to serve as the network fabrics for various industrial Internet-of-Things (IIoT) applications. Given that IWNs typically operate in noisy and harsh environments, frequently occurring network dynamics post huge challenges for IWN resource management especially when the network scales up. Existing centralized and distributed network management solutions either suffer from large communication overhead and time delay, or introduce schedule collisions which unnecessarily degrade the system performance. To address these problems, this work proposes a novel HierArchical Resource Partitioning framework (HARP), to provide dynamic resource management in IWNs. By hierarchically partitioning and allocating resources for the links in the network, HARP enables distributed collision-free resource allocation. HARP enables rapid adjustment of the partitions in the presence of network dynamics with modest communication overhead. The effectiveness of HARP is validated and evaluated through both simulation studies and testbed experiments on a 50-node multi-channel multi-hop 6TiSCH network.","2575-8411","978-1-6654-7177-0","10.1109/ICDCS54860.2022.00103","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9912202","Industrial wireless networks;hierarchical resource partitioning and reconfiguration;network dynamics","Schedules;Wireless networks;System performance;Spread spectrum communication;Dynamic scheduling;Fabrics;Resource management","","2","","30","IEEE","13 Oct 2022","","","IEEE","IEEE Conferences"
"A Random Greedy based Design Time Tool for AI Applications Component Placement and Resource Selection in Computing Continua","H. Sedghani; F. Filippini; D. Ardagna","Dipartimento di Elettronica, Informazione e Bioingeneria Politecnico di Milano, Milan, Italy; Dipartimento di Elettronica, Informazione e Bioingeneria Politecnico di Milano, Milan, Italy; Dipartimento di Elettronica, Informazione e Bioingeneria Politecnico di Milano, Milan, Italy","2021 IEEE International Conference on Edge Computing (EDGE)","17 Feb 2022","2021","","","32","40","Artificial Intelligence (AI) and Deep Learning (DL) are pervasive today, with applications spanning from personal assistants to healthcare. Nowadays, the accelerated migration towards mobile computing and Internet of Things, where a huge amount of data is generated by widespread end devices, is determining the rise of the edge computing paradigm, where computing resources are distributed among devices with highly heterogeneous capacities. In this fragmented scenario, efficient component placement and resource allocation algorithms are crucial to orchestrate at best the computing continuum resources. In this paper, we propose a tool to effectively address the component placement problem for AI applications at design time. Through a randomized greedy algorithm, our approach identifies the placement of minimum cost providing performance guar-antees across heterogeneous resources including edge devices, cloud GPU-based Virtual Machines and Function as a Service solutions. Finally, we compare the random greedy method with the HyperOpt framework and demonstrate that our proposed approach converges to a near-optimal solution much faster, especially in large scale systems.","2767-9918","978-1-6654-0062-6","10.1109/EDGE53862.2021.00014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9712094","Component placement;resource selection;AI applications","Performance evaluation;Cloud computing;Medical services;Virtual machining;Large-scale systems;Resource management;Object recognition","","1","","31","IEEE","17 Feb 2022","","","IEEE","IEEE Conferences"
"X-IIoTID: A Connectivity-Agnostic and Device-Agnostic Intrusion Data Set for Industrial Internet of Things","M. Al-Hawawreh; E. Sitnikova; N. Aboutorab","School of Engineering and Information Technology, University of New South Wales–Australian Defence Force Academy, Canberra, ACT, Australia; School of Engineering and Information Technology, University of New South Wales–Australian Defence Force Academy, Canberra, ACT, Australia; School of Engineering and Information Technology, University of New South Wales–Australian Defence Force Academy, Canberra, ACT, Australia","IEEE Internet of Things Journal","21 Feb 2022","2022","9","5","3962","3977","Industrial Internet of Things (IIoT) is a high-value cyber target due to the nature of the devices and connectivity protocols they deploy. They are easy to compromise and, as they are connected on a large scale with high-value data content, the compromise of any single device can extend to the whole system and disrupt critical functions. There are various security solutions that detect and mitigate intrusions. However, as they lack the capability to deal with an IIoT’s co-existing heterogeneity and interoperability, developing new universal security solutions to fit its requirements is critical. This is challenging due to the scarcity of accurate data about IIoT systems’ activities, connectivities, and attack behaviors. In addition, owing to their multiplatform connectivity protocols and multivendor devices, collecting and creating such data are also challenging. To tackle these issues, we propose a holistic approach for generating an appropriate intrusion data set for an IIoT called X-IIoTID, a connectivity-agnostic and device-agnostic intrusion data set for fitting the heterogeneity and interoperability of IIoT systems. It includes the behaviors of new IIoT connectivity protocols, activities of recent devices, diverse attack types and scenarios, and various attack protocols. It defines an attack taxonomy and consists of multiview features, such as network traffic, host resources, logs and alerts. X-IIoTID is evaluated using popular machine and deep learning algorithms and compared with 18 intrusion data sets to verify its novelty.","2327-4662","","10.1109/JIOT.2021.3102056","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9504604","Cybersecurity;data set;Industrial Internet of Things (IIoT);intrusion detection","Industrial Internet of Things;Protocols;Security;Interoperability;Botnet;Feature extraction;Taxonomy","","50","","57","IEEE","3 Aug 2021","","","IEEE","IEEE Journals"
"Follow the Sound of Children’s Heart: A Deep-Learning-Based Computer-Aided Pediatric CHDs Diagnosis System","B. Xiao; Y. Xu; X. Bi; W. Li; Z. Ma; J. Zhang; X. Ma","Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing, China; Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing, China; Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing, China; Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing, China; School of Cybernetics, Xidian University, Xi’an, China; Health Management Center, First Affiliated Hospital of Chongqing Medical University, Chongqing; Human Genetics Resource Center, National Health Commission, Beijing, China","IEEE Internet of Things Journal","12 Mar 2020","2020","7","3","1994","2004","Auscultation of heart sounds is a noninvasive and less costly way for congenital heart disease (CHD) diagnosis, especially for pediatric individuals. The deep-learning-based computer-aided heart sound analysis has been widely studied and developed in recent years. In this article, we develop a deep-learning-based computer-aided system for pediatric CHDs diagnosis using two novel lightweight convolution neural networks (CNNs). One key issue of most existing deep-learning-based systems is the scarcity of large-scale data sets for CNN learning. To this end, we collect heart sounds from newborns and children with physicians’ annotations to construct a pediatric heart sound data set that contains 528 high-quality recordings (nearly 4 h in total) from 137 subjects. With the constructed data set, deep CNN models can be easily trained as classifiers in computer-aided CHDs diagnosis systems. The experimental results demonstrate the superiority of our proposed methods in terms of diagnosis performance and parameter consumption in the application of Internet of Things.","2327-4662","","10.1109/JIOT.2019.2961132","National Key Research and Development Project(grant numbers:2016YFC1000307-3); National Natural Science Foundation of China(grant numbers:61976031); Natural Science Foundation of Chongqing(grant numbers:cstc2018jcyjAX0117); Chongqing Municipal Education Commission(grant numbers:KJZD-K201800601); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8937772","Computer-aided diagnosis;convolution neural networks (CNNs);heart sound;pediatric congenital heart diseases (CHDs)","Heart;Feature extraction;Pediatrics;Hidden Markov models;Computational modeling;Data models;Task analysis","","48","","55","IEEE","20 Dec 2019","","","IEEE","IEEE Journals"
"An Efficient Privacy-Preserving Public Auditing Protocol for Cloud-Based Medical Storage System","X. Li; S. Liu; R. Lu; M. K. Khan; K. Gu; X. Zhang","Institute for Cyber Security, School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Computer Science and Engineering, Hunan University of Science and Technology, Xiangtan, China; Faculty of Computer Science, University of New Brunswick, Fredericton, Canada; College of Computer & Information Sciences, King Saud University, Riyadh, Kingdom of Saudi Arabia; School of Computer & Communication Engineering, Changsha University of Science & Technology, Changsha, China; Institute for Cyber Security, School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China","IEEE Journal of Biomedical and Health Informatics","5 May 2022","2022","26","5","2020","2031","The booming Internet of Things makes smart healthcare a reality, while cloud-based medical storage systems solve the problems of large-scale storage and real-time access of medical data. The integrity of medical data outsourced in cloud-based medical storage systems has become crucial since only complete data can make a correct diagnosis, and public auditing protocol is a key technique to solve this problem. To guarantee the integrity of medical data and reduce the burden of the data owner, we propose an efficient privacy-preserving public auditing protocol for the cloud-based medical storage systems, which supports the functions of batch auditing and dynamic update of data. Detailed security analysis shows that our protocol is secure under the defined security model. In addition, we have conducted extensive performance evaluations, and the results indicate that our protocol not only remarkably reduces the computational costs of both the data owner and the third-party auditor (TPA), but also significantly improves the communication efficiency between the TPA and the cloud server. Specifically, compared with other related work, the computational cost of the TPA in our protocol is negligible and the data owner saves more than $2/3$ of computational cost. In addition, as the number of challenged blocks increases, our protocol saves nearly 90% of communication overhead between the TPA and the cloud server.","2168-2208","","10.1109/JBHI.2022.3140831","National Natural Science Foundation of China(grant numbers:62072078); Sichuan Science and Technology Program(grant numbers:2020JDTD0007); King Saud University(grant numbers:RSP-2021/12); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9672765","Auditing protocol;batch auditing;cloud-based medical storage;integrity;privacy preserving","Protocols;Cloud computing;Medical diagnostic imaging;Security;Computational efficiency;Servers;Medical services","Cloud Computing;Computer Security;Confidentiality;Delivery of Health Care;Humans;Outsourced Services;Privacy","19","","28","IEEE","6 Jan 2022","","","IEEE","IEEE Journals"
"Addressing the Cybersecurity Challenges of Electrical Power Systems of the Future","G. P. de Azevedo; P. César Pellanda; M. B. Campos","Electrical Power Systems Dept., Electric Energy Research Centre, Rio de Janeiro, RJ, Brazil; Electrical Engineering Dept., Military Institute of Engineering, Rio de Janeiro, RJ, Brazil; Strategic Management Dept., Cyber Defence Command, Brasília, DF, Brazil","2020 12th International Conference on Cyber Conflict (CyCon)","2 Jul 2020","2020","1300","","293","308","Electrical Power Systems (EPSs) are among the most prominent critical infrastructures of our digital society. Assets, systems and networks of most other critical infrastructure sectors depend heavily on EPSs and would fail in the event of persistent electricity supply problems. This should make EPSs attractive targets for cyberattacks, so it is somewhat surprising that few large-scale successful cyberattacks on the electricity sector have been reported so far.EPSs structures are undergoing deep changes that will accelerate over the next years. A convergence of environmental concerns and technological evolution is leading to the widespread use of distributed renewable microgeneration, electric vehicles, distributed energy storage, Internet of Things, smart grids and software-defined operating devices. These game-changing innovations are reshaping EPSs. The previously well-ordered computational environment where a limited number of agents interacted in predictable ways will gradually receive new layers of agents, where thousands or even millions of them will buy or sell services in a kind of giant open market. The search for individual advantages or profits rather than overall system welfare will guide the actions of these new participants.This work examines the traditional structure of EPSs from a cybersecurity point of view as well as foreseeable changes. It will also look at associated risks and discuss possible approaches to mitigate them.","2325-5374","9789-949-9904-7-4","10.23919/CyCon49761.2020.9131732","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9131732","critical infrastructure;electrical power systems;soft cybersecurity;industrial control systems;SCADA","Technological innovation;Renewable energy sources;Uncertainty;Low-carbon economy;Power systems;Critical infrastructure;Smart grids","","3","","17","","2 Jul 2020","","","IEEE","IEEE Conferences"
"Scheduling for Minimizing the Age of Information in Multisensor Multiserver Industrial Internet of Things Systems","X. Xie; H. Wang; X. Liu","Key Laboratory of Industrial Internet of Things and Networked Control, Chongqing University of Posts and Telecommunications, Chongqing, China; Key Laboratory of Industrial Internet of Things and Networked Control, Chongqing University of Posts and Telecommunications, Chongqing, China; Key Laboratory of Industrial Internet of Things and Networked Control, Chongqing University of Posts and Telecommunications, Chongqing, China","IEEE Transactions on Industrial Informatics","12 Dec 2023","2024","20","1","573","582","Real-time data delivery is significant for the Industrial Internet of Things (IIoT). Age of information (AoI), a popular real-time metric, is usually used to measure the data freshness of the IIoT systems. If the data most recently received by the destination at time $t$ was generated at time $t_{1}$, then the AoI is $t-t_{1}$. In this article, we consider a multisensor multiserver IIoT system and develop scheduling algorithms to minimize the average AoI. The challenge lies in the strong coupling between link scheduling, server selection, and service preemption. To address this issue, we propose a guided exploration-based deep $Q$-Network (GE-DQN) algorithm utilizing a fixed advantage policy, which has a faster learning speed compared to classical deep $Q$-network. Moreover, we use a shared decision module followed by several network branches to transform the structure of GE-DQN and propose a guided exploration-based branching dueling $Q$-network (GE-BDQN) algorithm. Since the branch structure of GE-BDQN can decompose the high-dimensional action, GE-BDQN can reduce the approximate exponential growth of the number of output neurons with the increase of the number of sensors to linear growth compared to GE-DQN, ensuring the applicability of the algorithm under large-scale systems. From the simulation results, it can be found that the proposed two algorithms can achieve better average AoI compared to the advanced algorithms, and the GE-BDQN algorithm can achieve up to 36% performance gain.","1941-0050","","10.1109/TII.2023.3268749","National Natural Science Foundation of China(grant numbers:92267106,61972061); Fundamental Research and Frontier Exploration Program of Chongqing, China(grant numbers:cstc2021ycjh-bgzxm0017); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10106033","Age of information (AoI);deep reinforcement learning (DRL);industrial Internet of Things (IIoT);scheduling","Servers;Sensors;Industrial Internet of Things;Job shop scheduling;Sensor systems;Optimization;Real-time systems","","1","","38","IEEE","20 Apr 2023","","","IEEE","IEEE Journals"
"Modelling Fog & Cloud Collaboration Methods on Large Scale","K. Al-Zoubi; G. Wainer","Faculty of Computer & Information Technology, Jordan University of Science & Technology, JORDAN; Department of Systems and Computer Engineering, Carleton University, CANADA","2020 Winter Simulation Conference (WSC)","29 Mar 2021","2020","","","2161","2172","Fog Computing is expected to decentralize clouds to improve users quality of service, in technologies like the Internet of Things, by pushing some computing onto mini-clouds (called Fogs) located close to end users. To enhance M&S with this concept, we have developed a complete Fog/Cloud collaboration methods to conduct simulation experiments: Users manipulate their experiments though nearby Fogs servers while M&S resources are dynamically discovered and allocated throughout the Fogs/Cloud. We have already built those methods using privately owned clouds. However, it was difficult in practice to study those methods scalability using real system setups. As a result, we present here the simulation model that we developed to mimic this real system in order to study the proposed collaboration methods on large scale. This model was validated with reference to the real system. The results have clearly shown the scalability of those proposed methods at the structure and coordination levels.","1558-4305","978-1-7281-9499-8","10.1109/WSC48552.2020.9384058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9384058","","Cloud computing;Scalability;Collaboration;Quality of service;Servers;Internet of Things;Edge computing","","1","","13","IEEE","29 Mar 2021","","","IEEE","IEEE Conferences"
"Efficient Simulated Annealing Algorithm for Wireless Sensors Location in Logistics 4.0","S. EL HAMDI; A. ABOUABDELLAH; M. Oudani","MOSIL, TICLab, University of Ibn Tofail, International University of Rabat Kenitra, Rabat, Morocco; Laboratory Engineering Science MOSIL, University of Ibn Tofail, Kenitra, Morocco; TICLab, International University of Rabat, Rabat, Morocco","2020 5th International Conference on Logistics Operations Management (GOL)","13 Jan 2021","2020","","","1","6","Industry 4.0 is a well spread research topic both in academia and industrial areas, the concept afflicts meaningful changes and modifications to known up to day traditional concept of Logistics by adopting Industry 4.0 key technologies such as wireless information transmission, big data and Internet of Things. In the context of fourth industrial revolution, technological innovation has become a necessity asset to production systems and scheduling, thus creating a direct influence on the concept of Logistics, best given examples are the development and the widespread integration of information and communication technologies in applications over the last ten years such transport management systems, warehouse management systems and much more. Continuous variables decision-making processes such as scheduling have gained a huge interest recently especially with increasing shift to smart manufacturing where non linear optimization is not working in practice for large-scale planning and scheduling models. Dynamic scheduling may be considered an enhancer to logistics 4.0 under Industry 4.0 back end layer.","","978-1-7281-6425-0","10.1109/GOL49479.2020.9314747","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9314747","Logistics 4.0;Wireless sensors;Smart Factory;Optimization;Simulated Annealing Algorithm","Internet of Things;Wireless sensor networks;Sensors;Monitoring;Job shop scheduling;Temperature sensors;Intelligent sensors","","1","","17","IEEE","13 Jan 2021","","","IEEE","IEEE Conferences"
"Predictive Control and Communication Co-Design with Fuzzy Logic Based Scheduling for Industrial IoT","J. Zhou; X. Zhu; J. Cao; X. Xiong; Y. Jiang; S. Sun; V. K. N. Lau","School of Electronic and Information Engineering, Harbin Institute of Technology, Shenzhen, China; School of Electronic and Information Engineering, Harbin Institute of Technology, Shenzhen, China; Institute of Infocomm Research, Agency for Science, Technology and Research, Singapore; School of Electronic and Information Engineering, Harbin Institute of Technology, Shenzhen, China; School of Electronic and Information Engineering, Harbin Institute of Technology, Shenzhen, China; Institute of Infocomm Research, Agency for Science, Technology and Research, Singapore; Department of ECE, The Hong Kong University of Science and Technology, Hong Kong","ICC 2023 - IEEE International Conference on Communications","23 Oct 2023","2023","","","1817","1823","Supporting wireless transmission of large-scale control systems is a challenging task due to the scarcity of wireless resources in the industrial internet of things (IIOT). To reduce wireless resource consumption while maintaining control stability, this paper investigates the wireless networked predictive control system, where only part of the control devices is permitted to transmit their state information to the centralized controller in each control cycle. For the rest unscheduled control devices, the centralized controller predicts their state information via the Gaussian process regression method. To evaluate the control performance and the wireless resources consumption, we formulate a joint optimization problem of control device scheduling, power allocation, and bandwidth allocation. The joint predictive control and communication optimization (JPCCO) scheduling algorithm is proposed to minimize both the control cost and communication cost. As for control device scheduling, we proposed a fuzzy logic based scheduling ranking (FL-SR) method, where control devices are ranked in descending order according to the fuzzy output. Numerical results show that the proposed JPCCO scheduling method with FL-SR outperforms the previous scheduling methods without predictive control, enabling a more stable wireless networked control system with less wireless resources.","1938-1883","978-1-5386-7462-8","10.1109/ICC45041.2023.10279586","National Natural Science Foundation of China(grant numbers:62171161); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10279586","predictive control;industrial internet of things;resource allocation;co-design;fuzzy logic","Wireless communication;Performance evaluation;Fuzzy logic;Job shop scheduling;Costs;Channel allocation;Resource management","","","","13","IEEE","23 Oct 2023","","","IEEE","IEEE Conferences"
"DScPA: A Dynamic Subcluster Privacy-Preserving Aggregation Scheme for Mobile Crowdsourcing in Industrial IoT","R. Ma; T. Feng; J. Xiong; Q. Li; Y. Tian","College of Computer and Communication, Lanzhou University of Technology, Lanzhou, China; College of Computer and Communication, Lanzhou University of Technology, Lanzhou, China; Fujian Provincial Key Laboratory of Network Security and Cryptology, College of Computer and Cyber Security, Fujian Normal University, Fuzhou, China; School of Computer Science, Nanjing University of Posts and Telecommunications, Nanjing, China; State Key Laboratory of Public Big Data, College of Computer Science and Technology, Guizhou University, Guiyang, China","IEEE Internet of Things Journal","8 Jan 2024","2024","11","2","1880","1892","Mobile crowdsourcing (MCS) is a promising new paradigm for intelligent data perception in large-scale sensor applications such as the Industrial Internet of Things (IIoT). This approach assigns industrial perception tasks to mobile devices for data collection and sharing, creating a bright outlook for building strong industrial systems and improving industrial services. However, the particular IIoT network environment is vulnerable to a range of malicious attacks, including the manipulation or deletion of data. Moreover, industry-aware nodes, which have limited energy resources, are susceptible to various failures that can result in distorted data and inaccurate trend analysis. To tackle the above issues, we propose a dynamic subcluster privacy-preserving aggregation (DScPA) scheme for the crowdsourced industrial virtual areas, by exploring the equilibrium between privacy security and data benefits for industrial users. Specifically, we propose joining and exiting the virtual area aggregation system protocol, and design low-cost privacy-preserving aggregation algorithm to achieve flexible and dynamic construction of virtual areas. Additionally, we propose a supervised mechanism-based subset aggregation protocol that takes into account the remaining energy of the nodes in the virtual areas aggregation system and their distance from the base station. We employ the relevant characteristics of polynomial functions and binary data to achieve data privacy protection and integrity verification at a lower computational cost. Furthermore, we develop an asymmetric information iterative static noncooperative game model to verify the soundness of DScPA. Finally, security analysis demonstrates that the DScPA scheme meets the security objectives. Simulations show that implementing DScPA in the industrial virtual area can improve the network lifetime by about 16.7% compared to existing solutions, while also increasing the average remaining energy of industry-aware nodes.","2327-4662","","10.1109/JIOT.2023.3318862","National Natural Science Foundation of China(grant numbers:62162039,62272102,62272123); Guangdong Provincial Key Laboratory of Novel Security Intelligence Technologies(grant numbers:2022B1212010005); Natural Science Foundation of Fujian Province(grant numbers:2023J02014); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10285012","Data aggregation;Industrial Internet of Things (IIoT);mobile crowdsourcing (MCS);subcluster","Data privacy;Industrial Internet of Things;Data aggregation;Security;Sensors;Protocols;Data models","","","","33","IEEE","13 Oct 2023","","","IEEE","IEEE Journals"
"Computationally Distributed and Asynchronous Operational Optimization of Droop-Controlled Networked Microgrids","N. Nikmehr; M. A. Bragin; P. Zhang; P. B. Luh","Department of Electrical and Computer Engineering, Stony Brook University, Stony Brook, NY, USA; Department of Electrical and Computer Engineering, University of Connecticut, Storrs, CT, USA; Department of Electrical and Computer Engineering, Stony Brook University, Stony Brook, NY, USA; Department of Electrical and Computer Engineering, University of Connecticut, Storrs, CT, USA","IEEE Open Access Journal of Power and Energy","19 Jul 2022","2022","9","","265","277","Networked microgrids (MGs) with inverter-based and droop-controlled distributed energy resources (DERs) require operational optimization with guaranteed stability performance to ensure the stable energy supply with minimum cost, yet it remains an open challenge. Additionally, the discrete nature of MGs leads to convergence issues to existing optimization methods thereby leading to difficulties obtaining feasible solutions for large-scale networks. This article develops a paradigm for discrete droop control to improve microgrids’ controllability in managing voltage and frequency fluctuations. With the emergence of Internet of Things, the computational tasks are distributed among local resources. The utilized Distributed and Asynchronous Surrogate Lagrangian Relaxation (DA-SLR) method distributes the optimization tasks among the MGs and efficiently coordinates the distributed subsystems. A small-signal model of the operational optimization is then developed to verify the system’s stability. Numerous case studies have proven the DA-SLR’s efficacy in comparison to various variations of the alternating direction of multipliers method (ADMM).","2687-7910","","10.1109/OAJPE.2022.3188733","National Science Foundation(grant numbers:ECCS-2018492,CNS-2006828,OIA-2040599,OIA-2134840,ECCS-1810108); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9815308","Networked microgrids;droop control;distributed optimization;operational optimization;stability analysis","Microgrids;Optimization;Energy management;Stability analysis;Convergence;Voltage control;Convex functions","","4","","45","CCBYNCND","5 Jul 2022","","","IEEE","IEEE Journals"
"Scaling Dense NB-IoT Networks to the Max: Performance Benefits of Early Data Transmission","P. Jörke; T. Gebauer; S. Böcker; C. Wietfeld","Communication Networks Institute, TU Dortmund University, Germany; Communication Networks Institute, TU Dortmund University, Germany; Communication Networks Institute, TU Dortmund University, Germany; Communication Networks Institute, TU Dortmund University, Germany","2022 IEEE 95th Vehicular Technology Conference: (VTC2022-Spring)","25 Aug 2022","2022","","","1","7","The growing number of IoT devices will lead to a massive number of users in communication networks. Therefore, this work analyzes the scalability boundaries of NB-IoT networks with different transmission modes, called standard transmissions, Cellular IoT optimization, and Early Data Transmission, using a novel detailed implementation of NB-IoT in the NS-3 LTE simulation framework LENA. The results show that Early Data Transmission clearly outperforms NB-IoT standard transmissions and Cellular IoT optimization by providing up to 4.1 times less latency and 1.6 times longer battery lifetime, while only using one-fourth of the downlink spectrum. Further, a good scalability for up to 864.000 devices per day in a cell with an area of 4.91km2, or 176.000 devices per day and km2 for all NB-IoT standard transmission, Cellular IoT optimization, and Early Data Transmission scenarios is given. It is shown that the scalability is limited by downlink spectrum capacity for non-Early Data Transmission scenarios and Random Access windows for all scenarios. Doubling the number of Random Access windows improves the performance in highly scaled scenarios in terms of a larger packet delivery rate and fewer Random Access collisions. Still, the number of Random Access collisions for scenarios over 1.000.000 devices per day is very high, which indicates the necessity of a detailed optimization for the radio resource configuration when using new features like Early Data Transmission for optimal cellular performance. Still, the analysis results show a great positive impact of Early Data Transmission on the overall performance and is highly recommended to be used by default.","2577-2465","978-1-6654-8243-1","10.1109/VTC2022-Spring54318.2022.9860611","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9860611","Scalability;NB-IoT;EDT;Early Data Transmission;NS-3;LENA","Performance evaluation;Scalability;Downlink;Batteries;Data communication;Internet of Things;Communication networks","","1","","19","IEEE","25 Aug 2022","","","IEEE","IEEE Conferences"
"Bit2RNG: Leveraging Bad-page Initialized Table with Bit-error Insertion for True Random Number Generation in Commodity Flash Memory","W. Yan; H. Zhu; Z. Yu; F. Tehranipoor; J. Chandy; N. Zhang; X. Zhang","Washington University in St. Louis, St. Louis, Missouri, USA; Washington University in St. Louis, St. Louis, Missouri, USA; Washington University in St. Louis, St. Louis, Missouri, USA; Santa Clara University, Santa Clara, California, USA; University of Connecticut, Storrs, Connecticut, USA; Washington University in St. Louis, St. Louis, Missouri, USA; Washington University in St. Louis, St. Louis, Missouri, USA","2020 IEEE International Symposium on Hardware Oriented Security and Trust (HOST)","25 Dec 2020","2020","","","91","101","Nowadays NAND flash memory is the de-facto storage technology that is widely used from compact commercial off-the-shelf (COTS) embedded devices to large-scale cloud computing facilities. Motivated by the growing demand for mobile and Internet-of-Thing (IoT) applications, researchers have proposed many innovative ways to leverage the physical characteristics of memory devices for different security functionalities. However, many existing solutions lack thorough considerations of practical factors such as device aging, implementation cost, and runtime speed, preventing them from being directly adopted for realworld industrial applications. In this work, we present a novel true random number generation method called Bit2RNG that leverages the intrinsic system resources by combining the bad pages and bit errors in NAND flash as a random source. Our solution requires no hardware modifications to the memory chip, its communication interface, or the flash controller, and consumes no additional system memory space. To demonstrate the capability and benefit of the proposed Bit2RNG technology, we explore several lightweight IoT applications including cryptographic key generation, device identification, and data provenance. The experimental results indicate that Bit2RNG is a practical solution with better system performance trade-off compared with other state-of-the-art TRNG techniques.","","978-1-7281-7405-1","10.1109/HOST45689.2020.9300293","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9300293","NAND flash memory;TRNG;cryptographic key generation;chip identification;image provenance;secure boot","Entropy;Logic gates;Aging;Hardware;Substrates;Software;Random number generation","","","","29","IEEE","25 Dec 2020","","","IEEE","IEEE Conferences"
"Macroscopic Analysis of IoT Botnets","H. A. Almazarqi; M. Woodyard; T. Mursch; D. Pezaros; A. K. Marnerides","School of Computing Science, University of Glasgow, Glasgow, Scotland, UK; Okta, Inc., San Francisco, CA, USA; Bad Packets LLC, Chicago, IL, USA; School of Computing Science, University of Glasgow, Glasgow, Scotland, UK; School of Computing Science, University of Glasgow, Glasgow, Scotland, UK","GLOBECOM 2022 - 2022 IEEE Global Communications Conference","11 Jan 2023","2022","","","2674","2679","The adoption of the IoT by modern sociotechnical systems in synergy with the rapid deployment of insecure IoT devices and services has transformed the cyber-threat landscape. Thus, the vast majority of cyberattacks are underpinned by the orchestration of compromised IoT devices that are globally distributed and controlled through carefully designed IoT botnets. Contrary to conventional belief, cybersecurity vectors instrumented by such botnets are not always uniformly distributed across Internet Autonomous Systems (ASes). By virtue of network structural characteristics imposed by each individual Autonomous System (AS) as well as the diversity in terms of AS-level cybersecurity policies, the spatiotemporal manifestation of IoT botnets differs. In this work, we provide a novel measurement study that empirically quantifies AS tolerance of IoT botnet propagation in the global IPv4 Internet. We assess and correlate measurements gathered by globally distributed honeypots, Internet regional registries and IP blacklists for a 15-month period and observe more than 3.2M malicious events triggered by IoT botnets spanning 9.5K ASes. Our work demonstrates that ASes connected to a low number of providers are prone to embrace a high portion of malicious activities. Hence, we provide evidence on concentrated botnet activities and determine the effectiveness of widely used IP blacklists. In general, this study contributes towards empowering knowledge on large-scale cyber-attacks as being crucial for the composition of next generation data-driven cybersecurity defence applications.","","978-1-6654-3540-6","10.1109/GLOBECOM48099.2022.10001223","UK EPSRC(grant numbers:EP/S035362/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10001223","Autonomous Systems;IoT botnets;cybersecurity;Internet measurements","Sociotechnical systems;Autonomous systems;Botnet;Routing;Malware;Blocklists;Spatiotemporal phenomena","","","","12","IEEE","11 Jan 2023","","","IEEE","IEEE Conferences"
"Communication encryption scheme in multi-embedded systems based on distributed architecture","S. Yingjie; Z. Xihuang","School of Artificial Intelligence and Computer Science, Jiangnan University, Wuxi, China; School of Artificial Intelligence and Computer Science, Jiangnan University, Wuxi, China","2020 19th International Symposium on Distributed Computing and Applications for Business Engineering and Science (DCABES)","9 Dec 2020","2020","","","28","32","With the increasing use of Internet-based embedded devices, multi-embedded systems appear in the form of distributed architectures, forming a large-scale intelligent system. However, this trend inevitably connects the information and infrastructure of a large number of embedded systems to the Internet, so that the data security threats faced by many. In this article, by discussing the requirements for node user access control on embedded devices, the inherent properties of distributed multi-embedded system environment requires support for multi-authority attribute-based encryption (ABE) to achieve access control for each node. Therefore, a secure node access control solution is raised for data transmission in the IoT environment. This solution is a hidden user access control solution. It sustains multi-authority ABE and is highly scalable. In addition, we certificated that the proposed solution provides greater functional characteristics while its performance is comparable to or better than existing cloud computing solutions.","2473-3636","978-1-7281-9724-1","10.1109/DCABES50732.2020.00017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9277828","distributed architecture;attribute encryption;multiple embedded systems;privacy protection","Encryption;Embedded systems;Computer architecture;Authorization;Task analysis;Safety;Privacy","","","","14","IEEE","9 Dec 2020","","","IEEE","IEEE Conferences"
"Modeling of Digital Scale Based on IoT","M. I. Saputra; S. R. Sulistivanti; F. A. Setyawan; U. Murdika; Y. T. Handiko","Jurusan Teknik Elektro, Universitas Lampung, Bandar Lampung, Indonesia; Jurusan Teknik Elektro, Universitas Lampung, Bandar Lampung, Indonesia; Jurusan Teknik Elektro, Universitas Lampung, Bandar Lampung, Indonesia; Jurusan Teknik Elektro, Universitas Lampung, Bandar Lampung, Indonesia; Jurusan Teknik Elektro, Universitas Lampung, Bandar Lampung, Indonesia","2022 FORTEI-International Conference on Electrical Engineering (FORTEI-ICEE)","13 Dec 2022","2022","","","1","4","This system is designed to be able to measure the weight of an item and record IoT-based measurement results by displaying it through a database on a website automatically. Because the livestock sector in Indonesia is still largely unorganized and there is a need for clear supply chain management and support for supply chain performance, even though supply chain management has been made, stock taking still needs to be done. and can result in an imbalance with the number of items in the warehouse and also inefficiency for the company if it wants to see stock. Therefore, the author developed a digital weighing system using 4 IoT-based load cell sensors by recording measurement results through a database and displaying them in real-time on the LCD (Liquid Crystal Digital) and website. The development method used in this research is the prototype method, namely by realizing the system design that has been made. The conclusion of this study is the realization of a digital scale model using four IoT-based load cell sensors, with an instrument accuracy rate of 99.94373%, and the test object is large with a weight of 2-11 Kg.","","979-8-3503-9798-7","10.1109/FORTEI-ICEE57243.2022.9972950","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9972950","Load Cell Sensor;Stock Taking;IOT;Website","Weight measurement;Analytical models;Supply chain management;Databases;Supply chains;Liquid crystal displays;Sensors","","","","9","IEEE","13 Dec 2022","","","IEEE","IEEE Conferences"
"Design of Urban Parking Space Monitoring System Based on LPWAN","X. Meng; H. Wan; T. Qin","School of Computer, Electronic and Information, Guangxi University, Nanning, China; School of Computer, Electronic and Information, Guangxi University, Nanning, China; School of Computer, Electronic and Information, Guangxi University, Nanning, China","2020 IEEE 20th International Conference on Communication Technology (ICCT)","24 Dec 2020","2020","","","1029","1034","Aiming at the problems of poor signal quality, insufficient communication coverage and low intelligence in urban large-scale parking systems, a city parking space monitoring system based on low power wide area network (LPWAN) is proposed. Taking STM32F103C8T6 low power microcontroller as the core, combined with LoRa and NB-IoT wireless communication technology, the low-power and long-distance terminal monitoring nodes and gateway nodes are designed. We also propose a multi-priority mixed time slot allocation algorithm, improving the throughput of the LoRa ad-hoc network, and completing the collected, transmit and display of parking space parameters. This paper focuses on the design of the system including software, hardware and algorithms. We have completed the normal function test of the system, throughput tests, communication distance, and packet loss rate (PLR) tests. The experimental results show that the urban parking space monitoring system has obvious advantages over the traditional wireless network in coverage, throughput and communication quality. LoRa technology and NB-IoT technology provide the possibility of forming a large-scale, low-power wireless sensor network in the future, and have a good promotion value in urban intelligent parking projects.","2576-7828","978-1-7281-8141-7","10.1109/ICCT50939.2020.9295856","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9295856","LoRa;NB-IoT;slot allocation algorithm;wireless sensor network;intelligent parking","Monitoring;Ad hoc networks;Logic gates;Wireless sensor networks;Microcontrollers;Resource management;Conferences","","2","","15","IEEE","24 Dec 2020","","","IEEE","IEEE Conferences"
"Compact Source-Gated Transistor Analog Circuits for Ubiquitous Sensors","E. Bestelink; K. M. Niang; G. Bairaktaris; L. Maiolo; F. Maita; K. Ali; A. J. Flewitt; S. R. P. Silva; R. A. Sporea","Department of Electrical and Electronic Engineering, Advanced Technology Institute, University of Surrey, Guildford, U.K.; Department of Engineering, Electrical Engineering Division, University of Cambridge, Cambridge, U.K.; Department of Electrical and Electronic Engineering, Advanced Technology Institute, University of Surrey, Guildford, U.K.; Istituto per la Microelettronica eMicrosistemi, Consiglio Nazionale delle Ricerche, Rome, Italy; Istituto per la Microelettronica eMicrosistemi, Consiglio Nazionale delle Ricerche, Rome, Italy; Department of Electrical and Electronic Engineering, Advanced Technology Institute, University of Surrey, Guildford, U.K.; Department of Engineering, Electrical Engineering Division, University of Cambridge, Cambridge, U.K.; Department of Electrical and Electronic Engineering, Advanced Technology Institute, University of Surrey, Guildford, U.K.; Department of Electrical and Electronic Engineering, Advanced Technology Institute, University of Surrey, Guildford, U.K.","IEEE Sensors Journal","18 Nov 2020","2020","20","24","14903","14913","Silicon-based digital electronics have evolved over decades through an aggressive scaling process following Moore's law with increasingly complex device structures. Simultaneously, large-area electronics have continued to rely on the same field-effect transistor structure with minimal evolution. This limitation has resulted in less than ideal circuit designs, with increased complexity to account for shortcomings in material properties and process control. At present, this situation is holding back the development of novel systems required for printed and flexible electronic applications beyond the Internet of Things. In this work we demonstrate the opportunity offered by the source-gated transistor's unique properties for low-cost, highly functional large-area applications in two extremely compact circuit blocks. Polysilicon common-source amplifiers show 49 dB gain, the highest reported for a two-transistor unipolar circuit. Current mirrors fabricated in polysilicon and InGaZnO have, in addition to excellent current copying performance, the ability to control the temperature dependence (degrees of positive, neutral or negative) of output current solely by choice of relative transistor geometry, giving further flexibility to the design engineer. Application examples are proposed, including local amplification of sensor output for improved signal integrity, as well as temperature-regulated delay stages and timing circuits for homeostatic operation in future wearables. Numerous applications will benefit from these highly competitive compact circuit designs with robust performance, improved energy efficiency and tolerance to geometrical variations: sensor front-ends, temperature sensors, pixel drivers, bias analog blocks and high-gain amplifiers.","1558-1748","","10.1109/JSEN.2020.3012413","Engineering and Physical Sciences Research Council (EPSRC)(grant numbers:EP/M013650/1); Engineering and Physical Sciences Research Council (EPSRC)(grant numbers:EP/R025304/1); Royal Academy of Engineering of Great Britain through the Research Fellowship(grant numbers:10216/110); Engineering and Physical Sciences Research Council (EPSRC)(grant numbers:EP/R028559/1); Royal Society of Great Britain through project ARES(grant numbers:IES\R3\170059); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9152000","Analog electronics;contact barriers;Schottky barrier;source-gated transistors;thin-film transistors","Thin film transistors;Temperature sensors;Schottky barriers;Analog circuits","","17","","55","CCBY","29 Jul 2020","","","IEEE","IEEE Journals"
"A Fully Integrated Low-Cost HF Multistandard RFID Reader SoC and Module for IoT Applications","D. -M. Wang; J. -G. Hu; J. Wu","School of Physics and Telecommunication Engineering, South China Normal University, Guangzhou, China; School of Microelectronics Science and Technology, Sun Yat-sen University, Zhuhai, China; Research and Development Department, Development Research Institute of Guangzhou Smart City, Guangzhou, China","IEEE Internet of Things Journal","22 Sep 2022","2022","9","19","19201","19213","The deployment and application of large-scale Internet of Things require a large number of 13.56-MHz radio-frequency identification (RFID) reader chips with lower cost. The existing RFID reader module needs to integrate multiple chips, such as microcontroller and high-frequency (HF) RFID reader IC on a single printed circuit board (PCB), which has the bottleneck of cost, power consumption, stability, and reliability. In order to adapt to the development trend of high integration, miniaturization, and low-power consumption of RFID reader, this article proposes a fully integrated low-cost RFID reader System-on-a-Chip (SoC), which integrates RF transceiver and analog circuit, baseband protocol processing, microcontroller, memory, and interface circuit into a single chip. The proposed reader IC supports communication protocols, such as ISO/IEC 14443 Type A and Type B, ISO/IEC 15693, and ISO/IEC 7816. The reader can communicate with contact and contactless IC cards. The modulation depth of the transmitter circuit ranges from 1% to 100%, and the maximum transmitting current is 126 mA. The receiver circuit is composed of I/Q clock generation, switched capacitor sampling circuit, variable gain amplifier (VGA) with filter, comparator, and pulse shaping circuit, which has good anti-noise performance. This 13.56-MHz RFID reader SoC is fabricated in a 180-nm CMOS process and is housed in a 64-pin QFP package. The total area is 8.75 mm2, including 1.47 mm2 for analog and RF circuits.","2327-4662","","10.1109/JIOT.2022.3164919","Key-Area Research and Development Program of Guangdong Province(grant numbers:2019B010142002,2021B1101270004); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2019B1515120025,2020A1515110272); Guangzhou Key Laboratory of IoT Identification IC(grant numbers:202002010002); 2016 Guangzhou Innovation and Entrepreneurship Leader Team(grant numbers:CXLJTD-201608); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9749766","Fully integrated;multistandard;radio-frequency identification (RFID);receiver and transmitter;System-on-a-Chip (SoC)","Radiofrequency identification;Modulation;Integrated circuits;Demodulation;ISO Standards;IEC Standards;Internet of Things","","3","","25","IEEE","5 Apr 2022","","","IEEE","IEEE Journals"
"Joint Waveform Design and Detection in Symbiotic Ambient Backscatter NOMA Systems","C. Wang; M. Pang; G. Cui; X. Chang; F. Jiang; Y. Yao; W. Wang","School of Electronic Engineering and the Key Laboratory of Universal Wireless Communications, Ministry of Education, Beijing University of Posts and Telecommunications, Beijing, China; School of Electronic Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Electronic Engineering and the Key Laboratory of Universal Wireless Communications, Ministry of Education, Beijing University of Posts and Telecommunications, Beijing, China; School of Electronic Engineering, Beijing University of Posts and Telecommunications, Beijing, China; Shaanxi Key Laboratory of Information Communication Network and Security, Xi’an University of Posts and Telecommunications, Xi’an, China; School of Electronic Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Electronic Engineering and the Key Laboratory of Universal Wireless Communications, Ministry of Education, Beijing University of Posts and Telecommunications, Beijing, China","IEEE Internet of Things Journal","30 Oct 2023","2023","10","22","19507","19517","Nonorthogonal multiple access (NOMA) and symbiotic ambient backscatter communications (AmBCs) are both considered promising technologies for beyond 5G mobile communication technology by enabling low-powered and spectrum-efficient access in large-scale Internet of Things. In this article, we investigate the uplink symbiotic communication in AmBC enabled NOMA system. In contrast with existing works, we assume the carrier transmitter (CT) transmits information while providing energy to the backscatter devices (BDs), which improves the energy efficiency. However, the signal power transmitted by the CT to integrated receiver (IR) through the direct link is much larger than the signal reflected by the BD, which can seriously affect the detection of the reflected signal by BD. Therefore, we jointly design the signal waveforms of CT and BDs, and propose a multiuser blind detection algorithm based on interference cancellation at IR. The simulation results demonstrate that the proposed multiuser detection algorithm achieves improved performance even the active BD number is unknown or without direct link.","2327-4662","","10.1109/JIOT.2023.3263967","National Key Research and Development Program of China(grant numbers:2020YFB1807204); National Natural Science Foundation of China(grant numbers:62071377); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10090416","Ambient backscatter communications (AmBCs);multiuser blind detection;nonorthogonal multiple access (NOMA);symbiotic communication;unique word (UW);waveform design","NOMA;Symbiosis;Receivers;Backscatter;Internet of Things;Interference cancellation;Symbols","","2","","49","IEEE","3 Apr 2023","","","IEEE","IEEE Journals"
"Evolutionary Computational Offloading with Autoencoder in Large-scale Edge Computing","H. Yuan; Q. Hu; J. Bi","School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China","2022 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","18 Nov 2022","2022","","","1121","1126","Cloud-edge hybrid systems can support delay-sensitive applications of industrial Internet of Things. Edge nodes (ENs) as service providers, provide users computing/network services in a pay-as-you-go manner, and they also suffer from the high cost brought by providing computing resources. Thus, the problem of profit maximization is highly important to ENs. However, with the development of 5G network technologies, a large number of mobile devices (MDs) are connected to ENs, making the above-mentioned problem a high-dimensional challenge, which is highly difficult to solve. This work formulates a joint optimization problem of task offloading, task partitioning, and associations of large-scale users to ENs to maximize the profit of ENs. This work focuses on applications that can be split into multiple subtasks, each of which can be completed in MDs, ENs and a cloud data center. Specifically, a mixed integer nonlinear program is formulated to maximize ENs’ profit. Then, a novel hybrid algorithm named Genetic Simulated-annealing-based Particle swarm optimizer with a Stacked Autoencoder (GSPSA) is designed to solve it. Real-life data-based experimental results demonstrate that compared with other peer algorithms, GSPSA increases the profit of ENs while strictly meeting latency needs of users’ tasks. The dimension of the problem that can be solved is increased by more than 50% with GSPSA.","2577-1655","978-1-6654-5258-8","10.1109/SMC53654.2022.9945219","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9945219","Computational offloading;autoencoders;PSO;high-dimensional optimization;edge computing","Representation learning;Cloud computing;5G mobile communication;Noise reduction;Simulated annealing;Genetics;Mobile handsets","","1","","19","IEEE","18 Nov 2022","","","IEEE","IEEE Conferences"
"Use Case Example","A. Marcham",NA,"Understanding Infrastructure Edge Computing: Concepts, Technologies, and Considerations","","2021","","","267","273","One of the most promising use cases for infrastructure edge computing is distributed AI, where the key functional components of an AI system are physically spread out across an example area such as a city in order to provide an optimal level of performance, scale and cost to the end user. This type of distributed architecture for AI applications relies on infrastructure edge computing and its ability to deploy and operate a number of infrastructure edge data centre facilities across an area that are interconnected both to each other and to regional points of interest such as any larger data centres.As will be explored in this chapter, there are many use cases for distributed AI which will drive the adoption of both AI and infrastructure edge computing. These use cases include computer vision where distributed AI resources are used to perform visual analysis of still or moving images such as improving the speed and accuracy of patient diagnoses using medical imaging technologies or using automated video security systems to improve threat detection and tracking. They also include many areas that rely on Natural Language Processing (NLP) such as voice‐based AI assistants, and analysing data to extract new actionable insights from sources such as large‐scale IoT networks in a smart city.","","9781119763246","10.1002/9781119763260.ch15","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9821665.pdf&bkn=9820905&pdfType=chapter","","Artificial intelligence;Training;Data centers;Task analysis;Data models;Edge computing;Computer vision","","","","","","12 Jul 2022","","","Wiley","Wiley Data and Cybersecurity eBook Chapters"
"IoT Based electric Vehicle Charging Socket","R. Kumar; S. P. Mahajan","Department of Electronics and Telecommunications, College of Engineering, Pune, Pune, Maharashtra, India; Department of Electronics and Telecommunications, College of Engineering, Pune, Pune, Maharashtra, India","2022 International Conference on Emerging Trends in Engineering and Medical Sciences (ICETEMS)","11 Apr 2023","2022","","","302","304","Interest in electric vehicles is increasing exponentially because of their large advantages over petrol and diesel engine vehicles as Electric vehicles doesn’t emit toxic gases and are eco-friendly as they run on electrically powered batteries and Electric vehicles are more efficient and they require very less maintenance. The only limitation with EV is that they require frequent charging for that we require a large network of EV charging system, so in this model we are developed a low-cost IoT based electric vehicle charging socket, which will be very useful in developing a large network of electric vehicles charging station, and this model can be used as a small-scale business if our home is near roads or highways.","","978-1-6654-6112-2","10.1109/ICETEMS56252.2022.10093681","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10093681","EVs;Internet of Things (IoT);Time of Use (TOU);State of charge (SOC);Battery electric vehicle (BEV);plug-in hybrid EV(PHEV).","Gases;Sockets;Roads;Diesel engines;Charging stations;Maintenance engineering;Market research","","","","5","IEEE","11 Apr 2023","","","IEEE","IEEE Conferences"
"Low Power Clock Generator Design With CMOS Signaling","Y. Fan; I. A. Young","Technology Development, Intel Corporation, Hillsboro, OR, USA; Technology Development, Intel Corporation, Hillsboro, OR, USA","IEEE Open Journal of the Solid-State Circuits Society","8 Nov 2021","2021","1","","162","170","The requirements for computing with higher energy efficiency in the datacenter and for longer battery life in laptop computers, cell phones, and other IoT devices while increasing performance with higher frequency and more cores, drive the needs for more clock generators with increased performance (frequency and jitter) and lower power budgets. The traditional current mode low swing clock generators were used widely in industry about 10 years ago. Although it had the advantage of higher supply noise rejection due to the differential nature of the architectures, however, it had the disadvantages of high-power consumption, large layout area, and not friendly to process scaling. Contrary to current mode low swing design, clock generator architectures with CMOS large swing signaling, which have advantages of low power consumption, small area, and based on circuits friendly to process scaling, have been widely adopted for clocking generation in the industry since 2009. In this paper, phase locked loops, delay locked loops, phase interpolators, high resolution digital to time converter and clock distribution techniques with CMOS large swing signaling will be discussed and reviewed.","2644-1349","","10.1109/OJSSCS.2021.3118339","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9563068","Delay locked loop;phase locked loop;PLL;DLL;phase interpolator;PI;DTC;clock distribution;CMOS;clock generators;inductor peaking","Tracking loops;Clocks;Phase locked loops;Generators;Jitter;Voltage control;Computer architecture","","3","","25","CCBY","7 Oct 2021","","","IEEE","IEEE Journals"
"Enterprise Integration Patterns in SDN: A Reliable, Fault-Tolerant Communication Framework","B. Rauf; H. Abbas; A. M. Sheri; W. Iqbal; A. W. Khan","Department of Information Security, National University of Sciences and Technology, Islamabad, Pakistan; Department of Information Security, National University of Sciences and Technology, Islamabad, Pakistan; Department of Information Security, National University of Sciences and Technology, Islamabad, Pakistan; Department of Information Security, National University of Sciences and Technology, Islamabad, Pakistan; FAST School of Computing, National University of Computer and Emerging Sciences, Islamabad, Pakistan","IEEE Internet of Things Journal","7 Apr 2021","2021","8","8","6359","6371","In today's era, large data centers are drawn toward the two popular technologies, i.e., enterprise integration patterns (EIP) and software defined networking (SDN). The former is the combination of design patterns which integrates the new and existing business applications in an enterprise environment, whereas the latter is a rapidly evolving networking paradigm that has reshaped the large enterprise network management by introducing the programmable planes and centralized control. The promising features of EIP, i.e., asynchronous communication, reliability and that of SDN, namely, robustness, network programmability, agility, and global visibility can be merged in order to cope with growing network demands and security. In this article, we propose a communication framework that incorporates both EIP and SDN in an enterprise environment. The architecture of the propose communication framework consists of adaptive virtual local area network (VLAN) module to install and delete VLANs reactively using EIP. Furthermore, to enable communication between applications from different networks in an enterprise environment, this framework also contains a packet forwarding module where hosts IP addresses are concealed from each other. In the end, we demonstrate through simulations that how the proposed integrated design can be helpful in improving the security, efficiency, and reliability aspects of the enterprise network. As proof of concept, we also discuss the deployment of our proposed framework in IoT-based Smart Cities, which is the extension of EIP on a large scale.","2327-4662","","10.1109/JIOT.2020.3034350","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9241841","ARP;enterprise integration patterns (EIP);network security;reliability;software defined networking (SDN);virtual local area networks (VLANs)","Reliability;Security;Control systems;Business;Software;Smart cities;Routing","","6","","36","IEEE","28 Oct 2020","","","IEEE","IEEE Journals"
"Comparative Analysis of Energy Costs of Asymmetric vs Symmetric Encryption-Based Security Applications","B. Halak; Y. Yilmaz; D. Shiu","School of Electronics and Computer Science, University of Southampton, Southampton, U.K; Department of Computer Engineering, Recep Tayyip Erdogan University, Rize, Turkey; Arqit Ltd., London, U.K","IEEE Access","26 Jul 2022","2022","10","","76707","76719","Public key algorithms are heavily used in many digital applications including key establishment schemes, secure messaging apps, and digital signature schemes in cryptocurrencies. Recent developments in the field of quantum computation have placed these algorithms at risk as they enable the implementation of more effective attacks to derive the secret key. Most notably Shor’s algorithm exponentially speeds up solving the factoring, discrete logarithm (DLP), and elliptic-curve discrete logarithm (ECDLP) problems. To address this challenge, NIST has initiated a process to develop and standardize a new quantum-resistant public-key cryptographic algorithm. However, asymmetric encryption schemes are known to be computationally intensive, hence energy demanding. The proliferation of energy-constrained internet of things devices, combined with the need to adopt higher complexity quantum resilient cryptographic algorithms, makes it more challenging to continue to use public-key algorithms for all applications. One approach to address these challenges is to adopt symmetric key systems, which are known to be more energy-efficient and more resilient to quantum computers-based attacks. This work performs a comprehensive comparison of energy costs between asymmetric and symmetric key schemes. This comparison is performed using two methods. The first approach uses the energy cost of data usage (ECDU) metric to evaluate the global energy costs associated with internet data usage. It was found that the annual energy consumed by applications associated with public-key cryptography globally is sufficient to provide electricity for 1000 UK households for a year. The second method uses an experimental technique based on constructing a small-scale network of wireless embedded devices. This is subsequently used to compare two key establishment schemes, symmetric and asymmetric, which allows for comparing the computation and communication costs of each solution in a controlled environment, and more importantly estimating the energy consumed by each device participating in the protocol. Our results show that a 58% saving in global energy costs of public key-based applications can be achieved by adopting symmetric key systems. It was also found that a 20% reduction of the energy consumed by a wireless device during a key agreement protocol, can be achieved if symmetric key encryption is used.","2169-3536","","10.1109/ACCESS.2022.3192970","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9835713","Symmetric-key encryption;public-key cryptography;key exchange protocols;digital signatures;energy","Costs;Encryption;Servers;Protocols;Public key cryptography;Wireless communication;Sockets","","10","","55","CCBYNCND","21 Jul 2022","","","IEEE","IEEE Journals"
"Robust Optimization in Enabling Optimal Economic Dispatch of IES Based on Information Interaction","Z. Sun; X. Liu; G. Ma; R. Liu; Z. Li","Science and Technology Department, State Grid Hebei Electric Power Co., Ltd., Shijiazhuang, China; Economic Research Institute, State Grid Hebei Electric Power Co., Ltd., Shijiazhuang, China; Economic Research Institute, State Grid Hebei Electric Power Co., Ltd., Shijiazhuang, China; College of Electrical Engineering, Sichuan University, Chengdu, China; College of Electrical Engineering, Sichuan University, Chengdu, China","2021 International Conference on Intelligent Technology and Embedded Systems (ICITES)","20 Dec 2021","2021","","","190","196","At present, The Internet of Things is an important support for the construction of the energy Internet, and it is of great significance to realize the intelligent coordination, promote the transformation of the country's energy structure. On this basis, small-scale wind and solar power are increasingly integrated into modern power system through integrated energy system. Taking into account the uncertainty of wind-solar power, this paper establishes a two-stage robust optimization model to achieve the minimum operating cost. Before the uncertainty is realized, the day-ahead stage as the first stage determines operating strategy that can withstand the worst-case uncertainty. As long as the uncertainty is observed, the operating units will be adjusted in the real-time stage to compensate for errors caused by the operating strategy. Due to the difficulties of solving the model, this paper further adopts the duality theory, Big-M method, and column-and-constraint generation (C&CG) decomposition to transform the model into two tractable mixed integer linear programming problems. In addition, C&CG iterative algorithm is also used to solve MILP, which ultimately provides the optimal economic day-ahead scheduling strategy. The experimental results demonstrate the effectiveness of the proposed method.","","978-1-6654-2755-5","10.1109/ICITES53477.2021.9637087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9637087","Integrated Energy System;Uncertain Optimization;Robust Optimization Model","Uncertainty;Transforms;Production;Real-time systems;Scheduling;Robustness;Power systems","","","","15","IEEE","20 Dec 2021","","","IEEE","IEEE Conferences"
"Towards Smart Farming: Simulation Framework to Exploit Network Connectivity for End-to-End Data Transmission","D. Huo; S. D. Ravana; A. W. Malik; A. U. Rahman; I. Ahmedy","Department of Information Systems, Faculty of Computer Science & Information Technology, University of Malaya, Kuala Lumpur, Malaysia; Department of Information Systems, Faculty of Computer Science & Information Technology, University of Malaya, Kuala Lumpur, Malaysia; Department of Computing, National University of Sciences and Technology (NUST), Islamabad, Pakistan; Department of Computing, National University of Sciences and Technology (NUST), Islamabad, Pakistan; Department of Computer Systems & Technology, Faculty of Computer Science & Information Technology, University of Malaya, Kuala Lumpur, Malaysia","2022 14th International Conference on Software, Knowledge, Information Management and Applications (SKIMA)","6 Feb 2023","2022","","","276","279","Traditional agriculture is highly dependent on human participation and experience. Therefore, it is not possible to guarantee crop yield and quality while expanding the production scale. In recent years, based on the continuous development and innovation of IoT and ICT technologies, the concept of smart farming has started to receive the attention of researchers and farmers. However, many existing smart agriculture applications and research are conducted under controlled environments such as greenhouse farming, vertical farming, and hydroponic farming, etc. Few studies have shifted attention to large-scale arable agriculture, thus neglecting the scalability of the system. This work presents a simulation stack (digital mapping) in which the results of running the simulation model in a large-scale class of real-world scenarios are used to enhance the further performance of the proposed farming system in large-scale scenarios.","2573-3214","978-1-6654-9334-5","10.1109/SKIMA57145.2022.10029463","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10029463","farming system;large-scale;simulation;agent-based","Smart agriculture;Technological innovation;System performance;Scalability;Production;Data models;Software","","1","","18","IEEE","6 Feb 2023","","","IEEE","IEEE Conferences"
"Overhead Study of Telegraf as a Real-Time Monitoring Agent","P. Rattanatamrong; Y. Boonpalit; S. Suwanjinda; A. Mangmeesap; K. Subraties; V. Daneshmand; S. Smallen; J. Haga","Department of Computer Science, Thammasat University, Pathum Thani, Thailand; Department of Computer Science, Thammasat University, Pathum Thani, Thailand; Department of Computer Science, Thammasat University, Pathum Thani, Thailand; Department of Computer Science, Thammasat University, Pathum Thani, Thailand; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA; San Diego Supercomputer Center, University of California, San Diego, La Jolla, CA, USA; Cyber Physical Cloud Research Group, National Institute of Advanced Industrial Science and Technology, Tsukuba, Japan","2020 17th International Joint Conference on Computer Science and Software Engineering (JCSSE)","30 Nov 2020","2020","","","42","46","Large-scale distributed systems have become an essential part of our everyday life. These systems have a large number of hardware and software components, often cooperating in complex and unpredictable ways. Operating these kinds of systems requires centralized monitoring to understand their overall states. While running software to collect metrics in a server is considered common nowadays, it often goes unstudied the impact metric collection software have on the base system. This is especially important in low-power, IoT applications. According to our review, one particular software, Telegraf, has never been formally studied before in terms of how much overhead Telegraf adds to the base system. In this work, we conducted several experiments to study how the base system is affected by Telegraf in two scenarios: a datacenter server and an IoT node. The results show that Telegraf is lightweight and suitable to serve as a real-time monitoring agent in both scenarios.","2642-6579","978-1-7281-6167-9","10.1109/JCSSE49651.2020.9268333","Thammasat University; University of California; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9268333","monitoring;overhead;resource utilization;experimental study;datacenter;IoT","Measurement;Monitoring;Servers;Software;Peer-to-peer computing;Internet of Things;Standards","","1","","20","IEEE","30 Nov 2020","","","IEEE","IEEE Conferences"
"Edge-Based Intrusion Detection using Machine Learning Over the IoT Network","A. J. Wadate; S. P. Deshpande","PG Department of Computer Science, DCPE HVPM, Amravati, Maharashtra, India; PG Department of Computer Science, DCPE HVPM, Amravati, Maharashtra, India","2023 11th International Conference on Emerging Trends in Engineering & Technology - Signal and Information Processing (ICETET - SIP)","19 Jun 2023","2023","","","1","6","Edge systems supported & assisted using IoT at a large scale called edge-assisted IoT. For large computational tasks, the need for edge servers has come into existence. Security of IoT is a difficult task to secure IoT information transmission to the edge. The proposed method shows an attack intrusion detection system (IDS) using back propagation (BP) as well as a basis function Radial (BFR) neural network. Attack intrusion detection function found using BP network and for more attack detection BFR has been used.","2157-0485","979-8-3503-4842-2","10.1109/ICETET-SIP58143.2023.10151535","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10151535","Intrusion Detection System;Internet of Things;Machine Learning;Back Propagation;Basis Function Radial","Image edge detection;Neural networks;Intrusion detection;Training data;Information processing;Machine learning;Electromagnetic compatibility","","","","25","IEEE","19 Jun 2023","","","IEEE","IEEE Conferences"
"Implementation of AES Using Composite Field Arithmetic for IoT Applications","T. B. Singha; R. P. Palathinkal; S. R. Ahamed","Department of EEE, IIT Guwahati, Guwahati, India; Department of EEE, IIT Guwahati, Guwahati, India; Department of EEE, IIT Guwahati, Guwahati, India","2020 Third ISEA Conference on Security and Privacy (ISEA-ISAP)","27 Apr 2020","2020","","","115","121","The presented work carries out a Very Large Scale Integration (VLSI) implementation of the Advanced Encryption Standard (AES) symmetric cipher to investigate for its best-suited architecture for IoT applications. Standard architectures, such as, rolling, unrolling and combinational were examined. S-box, which forms the core of AES was designed using composite field arithmetic and an optimized form was used in each architecture design to improve hardware efficiency. The design, verification and RTL synthesis of the algorithm was done using Xilinx Vivado 2018.3 simulator. Stringent area and power requirements being the prior criteria for IoT devices, the rolled architecture turned out to be the favorite candidate upon analysis of the result.","","978-1-7281-6708-4","10.1109/ISEA-ISAP49340.2020.235009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9079252","Internet of Thing (IoT);AES;S-box;Galois field (GF);polynomial basis","","","1","","12","IEEE","27 Apr 2020","","","IEEE","IEEE Conferences"
"Applicability of RINA in IoT communication for acceptable latency and resiliency against device authentication attacks","B. S. Neelam; B. A. Shimray","Department of Electrical Engineering, National Institute of Technology, Manipur, Imphal, India; Department of Electrical Engineering, National Institute of Technology, Manipur, Imphal, India","2021 6th International Conference for Convergence in Technology (I2CT)","10 May 2021","2021","","","1","7","IoT is revolutionizing the consumer world these days. IoT being an element of ubiquitous networking gathered much interest among industry and academia. Its limitless capability of integrating the cyber world with the physical world made it one of the dominant technologies of the day. But heterogeneous nature of IoT along with its authentication and identity management in large-scale environments present a potential threat to its security. Many new technologies like SDN and Blockchain improved their security but with some limitations. In this context, we present an IoT model based on a secure network architecture called recursive internetworking architecture (RINA) which is fully programmable. The proposed work discusses porting of an IoT-enabled CPS model on to RINA network, verifies the acceptability of latency in remote control and data acquisition according to the IEEE standards, and presented a secure authentication that can be achieved by the RINA password authentication mechanism. Results demonstrate the acceptability of latency as per IEEE standards and resiliency against device authentication threats.","","978-1-7281-8876-8","10.1109/I2CT51068.2021.9417992","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9417992","Future networks;programmable networks;IoT;RINA;CPS","Wireless communication;Wireless LAN;System performance;Data acquisition;Authentication;IEEE Standards;Real-time systems","","3","","30","IEEE","10 May 2021","","","IEEE","IEEE Conferences"
"Design and Construction of a Hybrid Edge-Cloud Smart Surveillance System with Object Detection","G. D. McBride; M. Sumbwanyambe","Department of Electrical and Mining Engineering, College of Science, Engineering and Technology, University of South Africa, Florida, Johannesburg, South Africa; Department of Electrical and Mining Engineering, College of Science, Engineering and Technology, University of South Africa, Florida, Johannesburg, South Africa","2021 International Conference on Computing, Communication, and Intelligent Systems (ICCCIS)","12 Apr 2021","2021","","","642","647","Smart surveillance systems are becoming very popular in personal, business, environmental and government domains as they are more cost effective than legacy CCTV systems. They provide seamless integration with technologies such as smart phones and automation systems. With recent advances in resource constrained hardware and computer vision, smart surveillance systems have the ability to perform advanced object detection while lowering power consumption and costs. In this paper a hybrid edge-cloud smart surveillance system was designed and constructed using a Raspberry Pi, NoIR camera and cloud computing to provide IoT functionality and services while maintaining inference locally at the edge device. The system implemented the mobile-first SSD MobileNetV3 model for object detection, deployed using AWS services such as IoT Greengrass and Lambda allowing the system to easily scale to hundreds of surveillance nodes. The Amazon Simple Notification Service would send email and SMS notifications to the user when a detection occurs with the image of the detection and streamed the video feed to Amazon Kinesis Video Streams allowing the user to immediately view the live feed using a media viewer. Various experiments and tests were then performed in order to validate that the system worked according to the user specifications. Positive detections of both people and animals were achieved in daytime and nighttime conditions with the expected performance indices for the inference time, latency and probability percentage of detected objects. Future iterations of this system will focus on zero touch provisioning and scaling making it easier to deploy over a broad large geographical area. It will also focus on reducing resource utilization even further to cater for even more resource- constrained devices.","","978-1-7281-8529-3","10.1109/ICCCIS51004.2021.9397212","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9397212","smart surveillance;object detection;Amazon Web Services;MobileNetV3;Internet of Things","Cloud computing;Economic indicators;Surveillance;Image edge detection;Object detection;Streaming media;Feeds","","2","","22","IEEE","12 Apr 2021","","","IEEE","IEEE Conferences"
"A Smart IoT-aware Backyard Poultry Farming exploiting low-cost and low-power Technologies","A. T. Shumba; T. Montanaro; I. Sergi; M. de Vittorio; L. Patrono","Department of Innovation Engineering University of Salento, Lecce, Italy; Department of Innovation Engineering University of Salento, Lecce, Italy; Department of Innovation Engineering University of Salento, Lecce, Italy; Department of Innovation Engineering University of Salento, Lecce, Italy; Department of Innovation Engineering University of Salento, Lecce, Italy","2021 6th International Conference on Smart and Sustainable Technologies (SpliTech)","21 Oct 2021","2021","","","1","6","Backyard chicken rearing is very lucrative for low-income families and unemployed individuals because of the high-quality protein in chicken meat and its popularity in many households. It is widespread especially in developing countries in Southern Africa, however, often, farmers can incur losses due to unpredictable weather conditions that can adversely affect the health and growth of the birds and consequently the quality of the produced meat. Chicken rearing is also time-consuming and labor intensive, factors that can cause inefficiency and low productivity. IoT enabling technologies could significantly improve profitability and reduce production cost by minimizing time consumption and manual labor requirements. However, many available on-market technologies enabling smart poultry farming like IoT capable automated environmental monitoring and actuating systems are expensive and therefore not attractive to small scale backyard farmers. This paper describes an innovative modular architecture based on fast prototyping and low-cost components to monitor and control the environmental conditions inside chicken coops as well as keep track of food and water delivery. The proposed architecture consists of a network of sensors, a local gateway, local actuators, a cloud service, and a web application and a mobile app that act as dashboards for data visualization and commands input. With the aim of demonstrating the feasibility of the architecture, an initial prototype was implemented and tested in a real situation within a farm in Southern Africa demonstrating the effectiveness of the system and highlighting the important and useful contribution that fast-prototyping devices, tools and technologies can bring to the sector.","","978-953-290-112-2","10.23919/SpliTech52315.2021.9566396","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9566396","Backyard poultry farming;IoT;MQTT;fast prototyping;low-cost;modular architecture","Proteins;Productivity;Profitability;Prototypes;Africa;Tools;Service-oriented architecture","","4","","47","","21 Oct 2021","","","IEEE","IEEE Conferences"
"EXPRESS 2.0: An Intelligent Service Management Framework for AIoT Systems in the Edge","J. Xu; X. Liu; W. Pan; X. Li; A. Yao; Y. Yang","School of Computer Science and Technology, Anhui University, Hefei, China; School of Information Technology, Deakin University, Geelong, Australia; School of Computer Science and Technology, Anhui University, Hefei, China; School of Computer Science and Technology, Anhui University, Hefei, China; School of Computer Science and Technology, Anhui University, Hefei, China; Department of Computing Technologies, Swinburne University of Technology, Melbourne, Australia","2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)","8 Nov 2023","2023","","","2022","2025","AIoT (Artificial Intelligence of Things) which integrates AI and IoT has received rapidly growing interest from the software engineering community in recent years. It is crucial to design scalable, efficient, and reliable software solutions for large-scale AIoT systems in edge computing environments. However, the lack of effective service management including the support for service collaboration, AI application, and data security in the edge, has seriously limited the development of AIoT systems. To seal this gap, we propose EXPRESS 2.0 which is an intelligent service management framework for AI oT in the edge. Specifically, on top of the existing EXPRESS platform, EXPRESS 2.0 includes the intelligent service collaboration management module, AI application management module, and data security management module. To demonstrate the effectiveness of the framework, we design and implement a last-mile delivery system using both UAVs (Unmanned Aerial Vehicles) and UGVs (Unmanned Ground Vehicles). The EXPRESS 2.0 is open-sourced at https://github.com/ISEC-AHU/EXPRESS2.0. A video demonstration of EXPRESS 2.0 is at https://youtu.be/GHKD_VvJD88.","2643-1572","979-8-3503-2996-4","10.1109/ASE56229.2023.00020","National Natural Science Foundation of China(grant numbers:61972001,62076002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10298474","AIoT System;Edge Computing;Service Collaboration;AI Application;Data Security","Data security;Collaboration;Seals;Reliability engineering;Software;Land vehicles;Software reliability","","","","15","IEEE","8 Nov 2023","","","IEEE","IEEE Conferences"
"A Review of Deep Reinforcement Learning for Smart Building Energy Management","L. Yu; S. Qin; M. Zhang; C. Shen; T. Jiang; X. Guan","College of Automation and College of Artificial Intelligence, Nanjing University of Posts and Telecommunications, Nanjing, China; College of Internet of Things, Nanjing University of Posts and Telecommunications, Nanjing, China; Systems Engineering Institute, Ministry of Education Key Laboratory for Intelligent Networks and Network Security, Xi’an Jiaotong University, Xi’an, China; School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China; Wuhan National Laboratory for Optoelectronics, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Systems Engineering Institute, Ministry of Education Key Laboratory for Intelligent Networks and Network Security, Xi’an Jiaotong University, Xi’an, China","IEEE Internet of Things Journal","26 Jul 2021","2021","8","15","12046","12063","Global buildings account for about 30% of the total energy consumption and carbon emission, raising severe energy and environmental concerns. Therefore, it is significant and urgent to develop novel smart building energy management (SBEM) technologies for the advance of energy efficient and green buildings. However, it is a nontrivial task due to the following challenges. First, it is generally difficult to develop an explicit building thermal dynamics model that is both accurate and efficient enough for building control. Second, there are many uncertain system parameters (e.g., renewable generation output, outdoor temperature, and the number of occupants). Third, there are many spatially and temporally coupled operational constraints. Fourth, building energy optimization problems can not be solved in real time by traditional methods when they have extremely large solution spaces. Fifthly, traditional building energy management methods have respective applicable premises, which means that they have low versatility when confronted with varying building environments. With the rapid development of Internet of Things technology and computation capability, artificial intelligence technology find its significant competence in control and optimization. As a general artificial intelligence technology, deep reinforcement learning (DRL) is promising to address the above challenges. Notably, the recent years have seen the surge of DRL for SBEM. However, there lacks a systematic overview of different DRL methods for SBEM. To fill the gap, this article provides a comprehensive review of DRL for SBEM from the perspective of system scale. In particular, we identify the existing unresolved issues and point out possible future research directions.","2327-4662","","10.1109/JIOT.2021.3078462","National Key Research and Development Program of China(grant numbers:2019YFB1312,2018YFA0702200); National Natural Science Foundation of China(grant numbers:61972214,61822309,61773310); Basic Research Project of Leading Technology of Jiangsu Province(grant numbers:BK20202011); China Postdoctoral Science Foundation(grant numbers:2020M673406); 1311 Talent Project of Nanjing University of Posts and Telecommunications; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9426901","Artificial intelligence;building microgrids;deep reinforcement learning (DRL);energy management;Internet of Things (IoT);smart buildings;uncertainty","Buildings;Optimization;Internet of Things;HVAC;Smart buildings;Reinforcement learning;Microgrids","","124","","130","IEEE","10 May 2021","","","IEEE","IEEE Journals"
"Over-the-Air Computation Systems: Optimization, Analysis and Scaling Laws","W. Liu; X. Zang; Y. Li; B. Vucetic","School of Electrical and Information Engineering, The University of Sydney, Sydney, Australia; School of Electrical and Information Engineering, The University of Sydney, Sydney, Australia; School of Electrical and Information Engineering, The University of Sydney, Sydney, Australia; School of Electrical and Information Engineering, The University of Sydney, Sydney, Australia","IEEE Transactions on Wireless Communications","11 Aug 2020","2020","19","8","5488","5502","For future Internet-of-Things based Big Data applications, data collection from ubiquitous smart sensors with limited spectrum bandwidth is very challenging. On the other hand, to interpret the meaning behind the collected data, it is also challenging for an edge fusion center running computing tasks over large data sets with a limited computation capacity. To tackle these challenges, by exploiting the superposition property of multiple-access channel and the functional decomposition, the recently proposed technique, over-the-air computation (AirComp), enables an effective joint data collection and computation from concurrent sensor transmissions. In this paper, we focus on a single-antenna AirComp system consisting of K sensors and one receiver. We consider an optimization problem to minimize the computation mean-squared error (MSE) of the K sensors' signals at the receiver by optimizing the transmitting-receiving (Tx-Rx) policy, under the peak power constraint of each sensor. Although the problem is not convex, we derive the computation-optimal policy in closed form. Also, we comprehensively investigate the ergodic performance of the AirComp system, and the scaling laws of the average computation MSE (ACM) and the average power consumption (APC) of different Tx-Rx policies with respect to K. For the computation-optimal policy, we show that the policy has a vanishing ACM and a vanishing APC with the increasing K.","1558-2248","","10.1109/TWC.2020.2993703","Australian Research Council’s Australian Laureate Fellowships Scheme(grant numbers:FL160100032); ARC(grant numbers:DP190101988); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9095231","Wireless sensor networks;over-the-air computation;remote estimation;mean-squared error;optimal power allocation;scaling-law analysis","Receivers;Wireless communication;Wireless sensor networks;Estimation;Optimization;Task analysis;Data collection","","111","","26","IEEE","18 May 2020","","","IEEE","IEEE Journals"
"A Resource Allocation Scheme for Joint Optimizing Energy Consumption and Delay in Collaborative Edge Computing-Based Industrial IoT","Z. Jin; C. Zhang; Y. Jin; L. Zhang; J. Su","School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing, China; School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing, China; Department of Mathematics, Yanbian University, Jilin, China; College of Information Engineering, Yangzhou University, Yangzhou, China; School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing, China","IEEE Transactions on Industrial Informatics","14 Jun 2022","2022","18","9","6236","6243","Attributable to the emergence of mobile edge computing (MEC), the hardware-constrained industrial devices have further computational and service capability in industrial Internet of Things (IIoT) systems. Nevertheless, unreliable network environments and unpredictable processing delays are intolerable factors for any service application. Therefore, this article studies the associated constraint problem of how to optimize the offloading decision and resource allocation in collaborative edge computing networks with multiple IIoT devices and MEC servers. In order to attain this purpose, the optimization problem is mathematically derived as a mixed-integer nonlinear programming problem which is a large-scale NP-hard problem. Then, an improved differential evolution algorithm (IDE) is proposed to obtain the optimal solutions in an accessible time complexity. Finally, the performance of the IDE-based resource allocation scheme has been compared with other baseline schemes. Simulation results demonstrate that the IDE-based optimization scheme could significantly reduce the system delay and energy consumption.","1941-0050","","10.1109/TII.2021.3125376","National Natural Science Foundation of China(grant numbers:61802196); Natural Science Foundation of Jilin Province(grant numbers:2020122336JC); Project of Jilin Science and Technology Development for Leading Talent of Science and Technology Innovation; Middle and Young and Team Project(grant numbers:20200301053RQ); Priority Academic Program Development; Jiangsu Higher Education Institution; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9606568","Collaborative edge computing;differential evolution algorithm;Internet of Things (IoT);offloading decision;resource allocation","Task analysis;Delays;Industrial Internet of Things;Servers;Energy consumption;Resource management;Computational modeling","","17","","22","IEEE","8 Nov 2021","","","IEEE","IEEE Journals"
"Edge Intelligence for Smart EL Images Defects Detection of PV Plants in the IoT-Based Inspection System","W. Tang; Q. Yang; X. Hu; W. Yan","College of Electrical Engineering, Zhejiang University, Hangzhou, China; College of Electrical Engineering, Zhejiang University, Hangzhou, China; College of Electrical Engineering, Zhejiang University, Hangzhou, China; College of Electrical Engineering, Zhejiang University, Hangzhou, China","IEEE Internet of Things Journal","6 Feb 2023","2023","10","4","3047","3056","Given the huge installed capacity of photovoltaic (PV) worldwide, the traditional defect detection system for PV plants is infeasible, especially for large-scale plants. In this article, unmanned aerial vehicles (UAVs) mounted with several sensors and a computer in the cloud are used cooperatively to establish an Internet of Things-based cloud-edge computing infrastructure, which can automatically detect defects with low latency, low cost, and high accuracy. The pretrained models trained in the cloud server are embedded into the processor in UAVs to implement online detection. Specifically, given the characteristic of defects in electroluminescence images, a two-stage algorithm is proposed to identify the defects with high performance. In the first stage, cells, the basic unit in the PV module, are extracted using an encoder–decoder network. Then, a vision-based incremental defect classification algorithm is proposed for defect detection that integrates deep learning with prior knowledge to maximize computing efficiency. The performance of the proposed system is evaluated through extensive experiments.","2327-4662","","10.1109/JIOT.2022.3150298","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9709563","Cloud-edge;deep learning;defects detection;Internet of Things (IoT)","Inspection;Cloud computing;Internet of Things;Image edge detection;Servers;Computer architecture;Hardware","","6","","32","IEEE","10 Feb 2022","","","IEEE","IEEE Journals"
"Operational Data-Driven Feedback for Safety Evaluation of Agent-Based Cyber–Physical Systems","I. Lamrani; A. Banerjee; S. K. S. Gupta","iMPACT Laboratory, School of Computing Informatics and Decision Systems Engineering, Computer Science and Engineering, Arizona State University, Tempe, AZ, USA; iMPACT Laboratory, School of Computing Informatics and Decision Systems Engineering, Computer Science and Engineering, Arizona State University, Tempe, AZ, USA; iMPACT Laboratory, School of Computing Informatics and Decision Systems Engineering, Computer Science and Engineering, Arizona State University, Tempe, AZ, USA","IEEE Transactions on Industrial Informatics","23 Feb 2021","2021","17","5","3367","3378","Safety regulation of safety-critical agent-based cyber-physical systems (CPS) which are manufactured in large scale such as next-gen aircrafts, autonomous driving vehicles, and medical devices is a multifaceted problem. CPS deployments can be presented with new safety-critical scenarios and novel inputs. Hence, operational characteristics of the CPS can be quite different from its safety approved design. This article considers a safety assurance solution where operational data from the sensors and actuators in the field of deployment is fed back to the manufacturing process through the Internet of Things infrastructure to assure and improve operational safety. It considers two cases: 1) model-aware, where the safety assured CPS design is fully specified; 2) modelagnostic, where limited specifications exist. For both the cases, it presents a data science based approach, N-HyMn, that learns a hybrid automaton model of the operational characteristics of the CPS from the input/output (I/O) traces of the observable parameters. For the model-aware case, it investigates the presence of inconsistencies between the learned model and the specifications model provided by the manufacturer, thus facilitating the detection of safety problems that may have been overlooked. For the modelagnostic case, it can detect potential safety failures. We show the usage of N-HyMn on the Medtronic Minimed 670 G system. N-HyMn correctly infers the hybrid automaton specifications of the Minimed 670 G and was able to detect a self-adaptation mechanism that is not declared explicitly in the certification documents of the U Food and Drug Administration. N-HyMn has a computational complexity of O(kn2), where k is the number of samples in the I/O trace, and n is the number of continuous variables.","1941-0050","","10.1109/TII.2020.3009985","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9143510","Certification;closed-loop control;Industry 4.0 cyber–physical system (CPS);mining hybrid automata (HA);self-adaptive","Safety;Data models;Time series analysis;Automata;Data mining;Sensors","","6","","41","IEEE","17 Jul 2020","","","IEEE","IEEE Journals"
"Performance Analysis and Power Allocation for Cooperative ISAC Networks","M. Liu; M. Yang; H. Li; K. Zeng; Z. Zhang; A. Nallanathan; G. Wang; L. Hanzo","National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China; State Key Laboratory of Integrated Services Networks, Xidian University, Xi’an, China; Wireless Technology Laboratory, Huawei Technologies Company Ltd., Chengdu, China; National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China; School of Electronic Engineering and Computer Science, Queen Mary University of London, London, U.K.; Wireless Technology Laboratory, Huawei Technologies Company Ltd., Chengdu, China; School of Electronics and Computer Science, University of Southampton, Southampton, U.K.","IEEE Internet of Things Journal","23 Mar 2023","2023","10","7","6336","6351","To mitigate the overlapping of the radar and communication frequency bands caused by large-scale devices access, we propose a novel integrated sensing and communication (ISAC) system, where a micro base station (MiBS) simultaneously carries out both target sensing and cooperative communication. Concretely, the MiBS, acting as the sensing equipment, can also serve as a full-duplex decode-and-forward relay to assist end-to-end communication. Moreover, nonorthogonal downlink transmission (NO-DLT) is adopted between the macro base station and the Internet of Things devices, so that the spectrum utilization can be further improved. To facilitate the performance evaluation, both the exact and asymptotic outage probabilities, the ergodic rates associated communication, and the probability of successful sensing detection are characterized. Subsequently, a pair of problems of maximizing the receive signal-to-interference-plus-noise ratio of the sensing signal and maximizing the sum rate of communication are formulated that are solved by the classic Lagrangian method while exploiting the associated function monotonicity. Our simulation results demonstrate that: 1) The proposed ISAC NO-DLT system improves both the communication and sensing performance under the same power consumption as noncooperative NO-DLT and 2) the proposed power allocation (PA) schemes are superior to the random PA scheme.","2327-4662","","10.1109/JIOT.2022.3225281","National Natural Science Foundation of China(grant numbers:62231020); Higher Education Discipline Innovation Project; Higher Education Discipline Innovation Project; National Natural Science Foundation of Shaanxi Province(grant numbers:2017CGZH-RGXQ-02); Huawei Technologies Company Ltd.(grant numbers:YBN2019085064); Engineering and Physical Sciences Research Council(grant numbers:EP/W016605/1,EP/P003990/1 (COALESCE)); European Research Council’s Advanced Fellow Grant QuantCom(grant numbers:789028); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9965407","Cooperative communication;full-duplex (FD);integrated sensing and communication (ISAC);nonorthogonal downlink transmission (NO-DLT)","Sensors;Internet of Things;Signal to noise ratio;Resource management;Relays;Downlink;System performance","","4","","51","IEEE","28 Nov 2022","","","IEEE","IEEE Journals"
"A Novel Management Model for Dynamic Sensor Networks Using Diffusion Sets","E. Tuyishimire; B. A. Bagula","Computer Science department, University of Cape Town, Cape Town, South Africa; Computer Science department, University of the Western Cape, Cape Town, South Africa","2020 Conference on Information Communications Technology and Society (ICTAS)","30 Apr 2020","2020","","","1","6","The internet of things is predicted to be a complex communication infrastructure embedding millions of devices built around different technologies. It will be using different protocols and operating systems while providing services in different fields. The management of information diffusion in such a complex communication infrastructure is a challenging issue that needs to be addressed efficiently to avoid local disturbances evolve to a large scale disaster by spreading out to the whole infrastructure.This paper revisits the issue of wireless sensor network management to evaluate the performance of information diffusion on connected systems. We propose a novel wireless sensor network partition into sets called ""diffusion sets"", which depends not only to sensors affinity but also to the mechanisms of the dynamic interactions and the underlying persistent communication model. After proving the partition property, we present the diffusion set computation algorithm and show through experimental results how it can be used by a collection tree algorithm to support efficient network engineering and predictions. Results show that the number of diffusion sets of a network is less correlated with existing network metrics which mater.","","978-1-7281-3770-4","10.1109/ICTAS47918.2020.233985","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9082465","","","","2","","32","IEEE","30 Apr 2020","","","IEEE","IEEE Conferences"
"ULP Receivers in Self-Powered Industrial loT Applications: Challenges and Prospects","K. -K. Huang; J. K. Brown; R. K. Sawyer; C. J. Lukas; F. B. Yahya; A. Wang; N. E. Roberts; B. H. Calhoun; D. D. Wentzloff","Everactive, Ann Arbor, MI; Everactive, Ann Arbor, MI; Everactive, Ann Arbor, MI; Everactive, Ann Arbor, MI; Everactive, Ann Arbor, MI; Everactive, Ann Arbor, MI; Everactive, Ann Arbor, MI; Everactive, Ann Arbor, MI; Everactive, Ann Arbor, MI","2022 IEEE Custom Integrated Circuits Conference (CICC)","18 May 2022","2022","","","1","8","Self-powered systems (SPSs) that harvest energy from the ambient environment, eliminating the battery, are gaining traction due to the increasing need for large-scale data collection in the Industrial Internet of Things (IIoT) space. The ultra-low-power receiver (ULP RX) is one promising solution for this application space that provides benefits from its energy-efficient operation. This paper discusses the requirements of self-powered wireless systems for IIoT applications and the challenges of designing ULP RXs for real-world deployments. Circuit design techniques to address the issues are summarized, and an ULP RX design with a proprietary protocol that is being adopted by commercialized SPSs is presented. Finally, the prospects and future trends for ULP receivers are summarized.","2152-3630","978-1-6654-0756-4","10.1109/CICC53496.2022.9772793","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9772793","","Wireless communication;Protocols;Conferences;Receivers;Data collection;Market research;Energy efficiency","","1","","39","IEEE","18 May 2022","","","IEEE","IEEE Conferences"
"2 Modern Agriculture Farming: Rack and Pinion Mechanism-based Remote Controlled Seed Sowing Robot","",,"Advanced Technologies for Smart Agriculture","","2023","","","31","54","This book brings new smart farming methodologies to the forefront, sparked by pervasive applications with automated farming technology. New indigenous expertise on smart agricultural technologies is presented along with conceptual prototypes showing how the Internet of Things, cloud computing, machine learning, deep learning, precision farming, crop management systems, etc., will be used in large-scale production in the future. The necessity of available welfare systems for farmers’ well-being is also discussed in the book. It draws the conclusion that there is a greater need and demand today for smart farming methodologies driven by technology than ever before.","","9788770228831","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10286350.pdf&bkn=10286317&pdfType=chapter","","","","","","","","16 Oct 2023","","","River Publishers","River eBook Chapters"
"14 Crop Welfare and Security to Farmers","",,"Advanced Technologies for Smart Agriculture","","2023","","","301","320","This book brings new smart farming methodologies to the forefront, sparked by pervasive applications with automated farming technology. New indigenous expertise on smart agricultural technologies is presented along with conceptual prototypes showing how the Internet of Things, cloud computing, machine learning, deep learning, precision farming, crop management systems, etc., will be used in large-scale production in the future. The necessity of available welfare systems for farmers’ well-being is also discussed in the book. It draws the conclusion that there is a greater need and demand today for smart farming methodologies driven by technology than ever before.","","9788770228831","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10286348.pdf&bkn=10286317&pdfType=chapter","","","","","","","","16 Oct 2023","","","River Publishers","River eBook Chapters"
"Advanced Technologies for Smart Agriculture","A. J. Anand; P. Tanwar; H. Raza",NA; NA; NA,"Advanced Technologies for Smart Agriculture","","2023","","","i","xxxii","This book brings new smart farming methodologies to the forefront, sparked by pervasive applications with automated farming technology. New indigenous expertise on smart agricultural technologies is presented along with conceptual prototypes showing how the Internet of Things, cloud computing, machine learning, deep learning, precision farming, crop management systems, etc., will be used in large-scale production in the future. The necessity of available welfare systems for farmers’ well-being is also discussed in the book. It draws the conclusion that there is a greater need and demand today for smart farming methodologies driven by technology than ever before.","","9788770228831","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10286321.pdf&bkn=10286317&pdfType=chapter","","","","","","","","16 Oct 2023","","","River Publishers","River eBook Chapters"
"Artificial Intelligence - Enabled Smart Grids: Enhancing Efficiency and Sustainability","A. J. M. Rani; A. Srinivasan; S. A. Shiney; B. Kalpana; S. Subramaniam; V. S. Pandi","Department of Computer Science and Engineering, Saveetha Institute of Medical and Technical Sciences, Chennai, Tamil Nadu, India; Department of AI & DS, Dhanalakshmi College of Engineering, Manimangalam, Chennai, Tamilnadu, India; Department of Computer Science and Engineering, S A Engineering College, Thiruverkadu, Chennai, Tamilnadu, India; Department of Chemistry, Prince Shri Venkateshwara Padmavathy Engineering College, Chennai, Tamilnadu, India; MSC Cybersecurity, Information Security professional, Northumbria University, London, United Kingdom; Centre for Advanced Wireless Integrated Technology(CAWIT), Chennai Institute of Technology, Chennai, Tamilnadu, India","2023 7th International Conference on Electronics, Communication and Aerospace Technology (ICECA)","9 Feb 2024","2023","","","175","180","Smart grids powered by artificial intelligence have emerged as a potentially game-changing method for enhancing the dependability and durability of electricity networks. This article examines the incorporation of AI technologies into power infrastructures, with a focus on sophisticated sensing and monitoring systems, data analytics, machine learning algorithms, and decentralized control mechanisms. The benefits of artificial intelligence- enabled smart grids include improved energy management, increased grid reliability, and reduced environmental impact. Data privacy and security concerns, the incorporation of new technologies such as blockchain and the Internet of Things, and the need for standardization are just a few of the hurdles that must be surmounted. Case studies illustrate AI's successful application in optimizing demand response, predictive maintenance, and integrating renewable energy. Integrating artificial intelligence with new technologies, bolstering privacy and security, refining large-scale deployment, and evaluating economic and policy ramifications are all promising avenues for future research. The results emphasize the potential role of intelligent infrastructure facilitated by artificial intelligence in the transition to sustainable power systems.","","979-8-3503-4060-0","10.1109/ICECA58529.2023.10395590","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10395590","Machine Learning;Blockchain;Smart Grids;Decentralized Control;Artificial Intelligence","Renewable energy sources;Smart grids;Sensors;Power system reliability;Security;Reliability;Artificial intelligence","","","","15","IEEE","9 Feb 2024","","","IEEE","IEEE Conferences"
"1 Introduction to Smart Agriculture","",,"Advanced Technologies for Smart Agriculture","","2023","","","1","30","This book brings new smart farming methodologies to the forefront, sparked by pervasive applications with automated farming technology. New indigenous expertise on smart agricultural technologies is presented along with conceptual prototypes showing how the Internet of Things, cloud computing, machine learning, deep learning, precision farming, crop management systems, etc., will be used in large-scale production in the future. The necessity of available welfare systems for farmers’ well-being is also discussed in the book. It draws the conclusion that there is a greater need and demand today for smart farming methodologies driven by technology than ever before.","","9788770228831","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10286356.pdf&bkn=10286317&pdfType=chapter","","","","","","","","16 Oct 2023","","","River Publishers","River eBook Chapters"
"15 Urban Farming: Case Study","",,"Advanced Technologies for Smart Agriculture","","2023","","","321","338","This book brings new smart farming methodologies to the forefront, sparked by pervasive applications with automated farming technology. New indigenous expertise on smart agricultural technologies is presented along with conceptual prototypes showing how the Internet of Things, cloud computing, machine learning, deep learning, precision farming, crop management systems, etc., will be used in large-scale production in the future. The necessity of available welfare systems for farmers’ well-being is also discussed in the book. It draws the conclusion that there is a greater need and demand today for smart farming methodologies driven by technology than ever before.","","9788770228831","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10286319.pdf&bkn=10286317&pdfType=chapter","","","","","","","","16 Oct 2023","","","River Publishers","River eBook Chapters"
"3 Crop Management System","",,"Advanced Technologies for Smart Agriculture","","2023","","","55","80","This book brings new smart farming methodologies to the forefront, sparked by pervasive applications with automated farming technology. New indigenous expertise on smart agricultural technologies is presented along with conceptual prototypes showing how the Internet of Things, cloud computing, machine learning, deep learning, precision farming, crop management systems, etc., will be used in large-scale production in the future. The necessity of available welfare systems for farmers’ well-being is also discussed in the book. It draws the conclusion that there is a greater need and demand today for smart farming methodologies driven by technology than ever before.","","9788770228831","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10286323.pdf&bkn=10286317&pdfType=chapter","","","","","","","","16 Oct 2023","","","River Publishers","River eBook Chapters"
"11 Indigenous Knowledge in Smart Agriculture","",,"Advanced Technologies for Smart Agriculture","","2023","","","241","258","This book brings new smart farming methodologies to the forefront, sparked by pervasive applications with automated farming technology. New indigenous expertise on smart agricultural technologies is presented along with conceptual prototypes showing how the Internet of Things, cloud computing, machine learning, deep learning, precision farming, crop management systems, etc., will be used in large-scale production in the future. The necessity of available welfare systems for farmers’ well-being is also discussed in the book. It draws the conclusion that there is a greater need and demand today for smart farming methodologies driven by technology than ever before.","","9788770228831","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10286325.pdf&bkn=10286317&pdfType=chapter","","","","","","","","16 Oct 2023","","","River Publishers","River eBook Chapters"
"17 Future of Farming","",,"Advanced Technologies for Smart Agriculture","","2023","","","359","382","This book brings new smart farming methodologies to the forefront, sparked by pervasive applications with automated farming technology. New indigenous expertise on smart agricultural technologies is presented along with conceptual prototypes showing how the Internet of Things, cloud computing, machine learning, deep learning, precision farming, crop management systems, etc., will be used in large-scale production in the future. The necessity of available welfare systems for farmers’ well-being is also discussed in the book. It draws the conclusion that there is a greater need and demand today for smart farming methodologies driven by technology than ever before.","","9788770228831","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10286327.pdf&bkn=10286317&pdfType=chapter","","","","","","","","16 Oct 2023","","","River Publishers","River eBook Chapters"
"5 Predictive Analysis in Smart Agriculture","",,"Advanced Technologies for Smart Agriculture","","2023","","","105","128","This book brings new smart farming methodologies to the forefront, sparked by pervasive applications with automated farming technology. New indigenous expertise on smart agricultural technologies is presented along with conceptual prototypes showing how the Internet of Things, cloud computing, machine learning, deep learning, precision farming, crop management systems, etc., will be used in large-scale production in the future. The necessity of available welfare systems for farmers’ well-being is also discussed in the book. It draws the conclusion that there is a greater need and demand today for smart farming methodologies driven by technology than ever before.","","9788770228831","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10286347.pdf&bkn=10286317&pdfType=chapter","","","","","","","","16 Oct 2023","","","River Publishers","River eBook Chapters"
"13 Cropping Pattern in Farming","",,"Advanced Technologies for Smart Agriculture","","2023","","","283","300","This book brings new smart farming methodologies to the forefront, sparked by pervasive applications with automated farming technology. New indigenous expertise on smart agricultural technologies is presented along with conceptual prototypes showing how the Internet of Things, cloud computing, machine learning, deep learning, precision farming, crop management systems, etc., will be used in large-scale production in the future. The necessity of available welfare systems for farmers’ well-being is also discussed in the book. It draws the conclusion that there is a greater need and demand today for smart farming methodologies driven by technology than ever before.","","9788770228831","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10286349.pdf&bkn=10286317&pdfType=chapter","","","","","","","","16 Oct 2023","","","River Publishers","River eBook Chapters"
"10 Decision-Making Support in Smart Farming","",,"Advanced Technologies for Smart Agriculture","","2023","","","219","240","This book brings new smart farming methodologies to the forefront, sparked by pervasive applications with automated farming technology. New indigenous expertise on smart agricultural technologies is presented along with conceptual prototypes showing how the Internet of Things, cloud computing, machine learning, deep learning, precision farming, crop management systems, etc., will be used in large-scale production in the future. The necessity of available welfare systems for farmers’ well-being is also discussed in the book. It draws the conclusion that there is a greater need and demand today for smart farming methodologies driven by technology than ever before.","","9788770228831","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10286353.pdf&bkn=10286317&pdfType=chapter","","","","","","","","16 Oct 2023","","","River Publishers","River eBook Chapters"
"9 Precision Farming for Crop Prediction","",,"Advanced Technologies for Smart Agriculture","","2023","","","195","218","This book brings new smart farming methodologies to the forefront, sparked by pervasive applications with automated farming technology. New indigenous expertise on smart agricultural technologies is presented along with conceptual prototypes showing how the Internet of Things, cloud computing, machine learning, deep learning, precision farming, crop management systems, etc., will be used in large-scale production in the future. The necessity of available welfare systems for farmers’ well-being is also discussed in the book. It draws the conclusion that there is a greater need and demand today for smart farming methodologies driven by technology than ever before.","","9788770228831","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10286320.pdf&bkn=10286317&pdfType=chapter","","","","","","","","16 Oct 2023","","","River Publishers","River eBook Chapters"
"4 Autonomous Devices in Smart Farming","",,"Advanced Technologies for Smart Agriculture","","2023","","","81","104","This book brings new smart farming methodologies to the forefront, sparked by pervasive applications with automated farming technology. New indigenous expertise on smart agricultural technologies is presented along with conceptual prototypes showing how the Internet of Things, cloud computing, machine learning, deep learning, precision farming, crop management systems, etc., will be used in large-scale production in the future. The necessity of available welfare systems for farmers’ well-being is also discussed in the book. It draws the conclusion that there is a greater need and demand today for smart farming methodologies driven by technology than ever before.","","9788770228831","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10286355.pdf&bkn=10286317&pdfType=chapter","","","","","","","","16 Oct 2023","","","River Publishers","River eBook Chapters"
"6 Machine Learning in Smart Agriculture","",,"Advanced Technologies for Smart Agriculture","","2023","","","129","152","This book brings new smart farming methodologies to the forefront, sparked by pervasive applications with automated farming technology. New indigenous expertise on smart agricultural technologies is presented along with conceptual prototypes showing how the Internet of Things, cloud computing, machine learning, deep learning, precision farming, crop management systems, etc., will be used in large-scale production in the future. The necessity of available welfare systems for farmers’ well-being is also discussed in the book. It draws the conclusion that there is a greater need and demand today for smart farming methodologies driven by technology than ever before.","","9788770228831","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10286322.pdf&bkn=10286317&pdfType=chapter","","","","","","","","16 Oct 2023","","","River Publishers","River eBook Chapters"
"12 Climate Change and Its Impact on Agriculture","",,"Advanced Technologies for Smart Agriculture","","2023","","","259","282","This book brings new smart farming methodologies to the forefront, sparked by pervasive applications with automated farming technology. New indigenous expertise on smart agricultural technologies is presented along with conceptual prototypes showing how the Internet of Things, cloud computing, machine learning, deep learning, precision farming, crop management systems, etc., will be used in large-scale production in the future. The necessity of available welfare systems for farmers’ well-being is also discussed in the book. It draws the conclusion that there is a greater need and demand today for smart farming methodologies driven by technology than ever before.","","9788770228831","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10286324.pdf&bkn=10286317&pdfType=chapter","","","","","","","","16 Oct 2023","","","River Publishers","River eBook Chapters"
"7 Deep Learning in Smart Agriculture","",,"Advanced Technologies for Smart Agriculture","","2023","","","153","176","This book brings new smart farming methodologies to the forefront, sparked by pervasive applications with automated farming technology. New indigenous expertise on smart agricultural technologies is presented along with conceptual prototypes showing how the Internet of Things, cloud computing, machine learning, deep learning, precision farming, crop management systems, etc., will be used in large-scale production in the future. The necessity of available welfare systems for farmers’ well-being is also discussed in the book. It draws the conclusion that there is a greater need and demand today for smart farming methodologies driven by technology than ever before.","","9788770228831","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10286326.pdf&bkn=10286317&pdfType=chapter","","","","","","","","16 Oct 2023","","","River Publishers","River eBook Chapters"
"Convergent Access Control to Enable Secure Smart Communities","S. Bhatt; R. Sandhu","Dept. of Computing and Cyber Security, Texas A & M University-San Antonio, San Antonio, Texas, USA; Institute for Cyber Security and Dept. of Computer Science, Univ. of Texas at San Antonio, Texas, USA","2020 Second IEEE International Conference on Trust, Privacy and Security in Intelligent Systems and Applications (TPS-ISA)","19 Jan 2021","2020","","","148","156","With current technological advancements in IoT, Artificial Intelligence, and networking (e.g., 5G/6G) technologies, we are swiftly moving towards enabling future connected smart communities. We envision a smart community (SC) as an inter-connected ecosystem ranging from a small region to a global scale enabled by IoT devices and key technologies for the betterment of its citizens, businesses, and organizations. A critical aspect for enabling such future smart communities is developing a secure and privacy-preserving access control (AC) framework to defend against malicious actors in the system. Traditionally, access control principles have been formulated based on the access control requirements of an enterprise, an application or a system. Smart communities are an evolving and dynamic concept that includes a range of interdisciplinary components. Thus it is appropriate to reevaluate current access control principles for such a diverse and dynamic ecosystem. In this paper, we first discuss access control requirements and then present access control principles for future smart communities. We envision a convergent access control approach towards enabling future smart communities where different access control models synergistically converge at both policy and enforcement layers. Therefore, we propose a Convergent Access Control (CAC) framework that can address the access control requirements of dynamic application domains such as in future smart communities. The main goal of this paper is to present the vision and need for the CAC framework and initiate discussion on the future research agenda.","","978-1-7281-8543-9","10.1109/TPS-ISA50397.2020.00029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9325352","Internet of Things;Smart Communities;Access Control Principles;Convergent Access Control","Access control;Smart cities;Biological system modeling;Computational modeling;Internet of Things;Intelligent sensors;Ecosystems","","6","","33","IEEE","19 Jan 2021","","","IEEE","IEEE Conferences"
"Internet of Things (IoT) Security Requirements: Issues Related to Sensors","H. Alqarni; W. Alnahari; M. T. Quasim","College of Computing and Information Technology, University of Bisha, Bisha, Saudi Arabia; College of Computing and Information Technology, University of Bisha, Bisha, Saudi Arabia; College of Computing and Information Technology, University of Bisha, Bisha, Saudi Arabia","2021 National Computing Colleges Conference (NCCC)","14 May 2021","2021","","","1","6","The last couple of years have seen IoT-enabled sensors continuing to experience massive growth. Sensors have enhanced the possibility of large-scale IoT deployments in grid systems, vehicles, homes, and so forth. A network that incorporates different embedded systems has the underlying capability of transmitting information and receiving instructions through distributed sensor networks. Sensors are especially essential in gathering different pieces of information that relate to different IoT devices. However, security has become a critical concern for sensor networks that are enabled by the IoT. This is partly because of their design limitations like limited memory, weak processing capability, weak processing ability, and exposure to entities that are malicious. Even more, some ad hoc wireless sensor networks that are enabled by IoT are to some extent also prone to frequent changes in topology. This dynamic aspect tends to aggravate the security issues that are associated with sensors, thus enhancing the need to find a lasting solution. This paper sheds light on the IoT security requirements with special attention to issues related to sensors.","","978-1-7281-6719-0","10.1109/NCCC49330.2021.9428857","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9428857","Sensor;Internet of Things;Advanced Encrypted Standard;Quality of Service","Wireless sensor networks;Technological innovation;Prototypes;Sensor systems;Sensors;Security;Internet of Things","","6","","28","IEEE","14 May 2021","","","IEEE","IEEE Conferences"
"Scaling IoT MUD Enforcement using Programmable Data Planes","S. A. Harish; S. Datta; H. Kothapalli; P. Tammana; A. Basuki; K. Kataoka; S. Manickam; U. Venkanna; Y. -W. Chong","IIT, Hyderabad, India; IIIT, Naya Raipur, India; IIT, Hyderabad, India; IIT, Hyderabad, India; Brawijaya University, Indonesia; IIT, Hyderabad, India; Universiti Sains Malaysia, Malaysia; IIIT, Naya Raipur, India; Universiti Sains Malaysia, Malaysia","NOMS 2023-2023 IEEE/IFIP Network Operations and Management Symposium","21 Jun 2023","2023","","","1","9","IoT-based intrusions and network attacks are becoming ever more concerning. As a mitigatory measure, the IETF standardized Manufacturer Usage Description (MUD) which allows IoT device vendors to specify the legitimate communication patterns (as a MUD profile) of an IoT device. A MUD profile allows the validation of the actual communication pattern of an IoT device with the intended behavior at runtime. However, as the number of IoT devices increases, validation at runtime has scalability challenges in terms of the number of switch resources (e.g., TCAM) required to maintain MUD profiles.In this work, we propose a scalable data plane primitive and a system on top of the primitive, which together enforce MUD profiles of thousands of IoT devices in a P4 programmable switch data plane. Our main idea is to avoid inefficiencies because of the repetition of header values while representing MUD profile-based ACL rules. Further, we exploit the characteristics of header values in ACL rules of real IoT devices and carefully partition the rules across multiple hash-based exact match-action tables in the switch data plane. Since hash-based data structures can be implemented using SRAM which is cheap and abundantly available (order of MBs) in commodity programmable switches, our approach scales well for a large IoT network.","2374-9709","978-1-6654-7716-1","10.1109/NOMS56928.2023.10154376","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10154376","","Multiuser detection;Runtime;Systematics;Scalability;Random access memory;Prototypes;Switches","","","","26","IEEE","21 Jun 2023","","","IEEE","IEEE Conferences"
"Novel Cognitive Radio Framework for Optimized Resource Management over IoT Ecosystem","V. B P; R. Sundarguru","Department of Electronics & Communication Engineering, Sir M.VIT, Bengaluru, India; Department of Electronics & Communication Engineering, Sir M.VIT, Bengaluru, India","2021 International Conference on Computer Communication and Informatics (ICCCI)","21 Apr 2021","2021","","","1","6","Adoption of Cognitive Radio Network (CRN) is increasing owing to its potential facilitation towards accessibility of data services in wireless network. It is considered as an integral part of IoT system which demands faster connectivity with better admission control. However, IoT system has massive number of connected users with both home access point and core base station and it is quite resource consuming in order to relay the data communication even using 5G over IoT. Therefore, this paper introduces a very simple and novel mechanism for resource management in CRN particularly targeting to large scale IoT environment. This analytical model is implemented in MATLAB considering a standard simulation parameter, where the outcome shows that proposed system offers better throughput in less time in contrast to existing channel assignment approaches towards resource management in CRN.","2329-7190","978-1-7281-5875-4","10.1109/ICCCI50826.2021.9402361","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9402361","Cognitive Radio Network;Internet of Things;Resource Management;5G;Energy Optimization","Analytical models;5G mobile communication;Data models;Cognitive radio;Resource management;Mathematical model;Data communication","","","","32","IEEE","21 Apr 2021","","","IEEE","IEEE Conferences"
"IoT based Digital Production Counting System","V. Niranjane; U. Shelke; S. Shirke; S. Dafe","Electronics & telecommunication Engineering, Yeshwantrao chavan college of engineering, Nagpur, India; Electronics & telecommunication Engineering, Yeshwantrao chavan college of engineering, Nagpur, India; Electronics & telecommunication Engineering, Yeshwantrao chavan college of engineering, Nagpur, India; Electronics & telecommunication Engineering, Yeshwantrao chavan college of engineering, Nagpur, India","2022 International Conference on Electronics and Renewable Systems (ICEARS)","13 Apr 2022","2022","","","452","455","The Objective of this research is to Design and build a IoT Base Digital Production Counting system. It decreases the likelihood of counting errors and improve counting accuracy, which is used in big enterprises since it outperforms human techniques. Production manufacturing and counting can be a time-consuming process that includes quality control, large-scale analysis, and quantity measurement. The classification especially supports the quantity factor, or production rate which is accomplished by human resource present in industry with having either a max or min rate of production but keeping the exact count throughout the manufacturing process is still impossible. The quantity outcome is an important factor in steadfast the industry's economic growth and financial health. As IoT is quickly growing as the next phase of the Internet's development, it's becoming more necessary than ever to understand the several prospective domains for IoT operations. Since the previous few decades, technology has played an increasingly important role in our daily lives. As IOT is developed, industries can increase productivity and data collection efficiency. In order to improve production demographics this project aims to count the multiple products which are counted by IR sensor using IR interruption concept and Microcontroller is used here to keep track of a huge number of items and display on a LCD display as well as upload the data on web via Node MCU (IOT Module)","","978-1-6654-8425-1","10.1109/ICEARS53579.2022.9752399","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9752399","Microcontroller At-mega 328 p;Node MCU;IR Sensor;Production object;IOT Module","Productivity;Manufacturing industries;Renewable energy sources;Costs;Manufacturing processes;Microcontrollers;Process control","","1","","12","IEEE","13 Apr 2022","","","IEEE","IEEE Conferences"
"Rogue Access Point: The WLAN Threat","K. C. Patel; A. Patel","Department of Computer Science, Ganpat University, Gujarat, India; A. M. Patel Institute of Computer Studies, Ganpat University, Gujarat, India","2022 International Conference on Computing, Communication, and Intelligent Systems (ICCCIS)","9 Feb 2023","2022","","","943","950","Due to the wireless airspace's limited size and capacity and its restriction to network teams, numerous businesses and organisations involved in wireless security have fought and struggled to obtain it. Briefly stated, data is transmitted through a wireless network using radio signals. Due to the air interface that wireless communication by its very nature provides, it is susceptible to attacks from hackers or attackers who can take down the legitimate network, network equipment, servers, apps, databases, and connected users. According to this report, the WLAN 802.11 technology is seriously threatened by rogue access points. The ultimate objective is to categorise various wireless assaults and their tactics, particularly those that use rogue access points (RAP) and compromised systems. The following terms are frequently used to categorise assaults in the literature: evil-twin, DDoS, MITM, Wi-Fi Deauthentication, IoT-based attacks, attacks on ICS/SCADA, attacks on electric vehicles (EVs) and electric vehicle charging systems (EVCS), and rogue unmanned aerial vehicles (UAVs). Water management, electric generation, distribution, and communication systems, gas and oil systems, production and manufacturing facilities, food production, chemical production, nuclear production, electric vehicle charging stations, and other large-scale public and private sector organisations are all susceptible to compromise and infection from these attacks. Attackers can employ rogue access points to attack cars, unidentified flying objects, and military equipment. Therefore, small, medium, and large-sized enterprises as well as tearooms, coffeehouses, airdromes, railroad or metro stations, football stadiums, public auditoriums, auditoriums, etc. have been infected.","","978-1-6654-6200-6","10.1109/ICCCIS56430.2022.10037591","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10037591","Rogue Access Point;WLAN Threat;DDoS;802.11","Wireless networks;Weapons;Hazards;Electric vehicle charging;Communication system security;Automobiles;Servers","","1","","53","IEEE","9 Feb 2023","","","IEEE","IEEE Conferences"
"A Survey on Mobile Edge Computing Architectures for Deep Learning Models","J. Lee; W. Na","Department of Computer Science and Engineering, Kongju National University, Korea; Department of Software, Kongju National University, Korea","2022 13th International Conference on Information and Communication Technology Convergence (ICTC)","25 Nov 2022","2022","","","2346","2348","With the development of mobile devices and communication technology, the IoT paradigm has recently been gaining attention. Various sensors and high-speed communication technology are equipped by various mobile devices, making it possible to collect a large amount of environmental data. Accordingly, many attempts have been made to process data collected from mobile devices into deep learning models. Since mobile devices have relatively insufficient computing resources and battery constrains to directly execute large-scale deep learning models, these tasks are offloaded to a cloud computing platform instead. In addition, mobile edge computing (MEC) or fog computing architecture has been proposed in order for the heavy tasks to be processed in a nearby computing node, thereby address the latency limits of cloud computing architecture. The deep learning inferencing can be performed with low latency on the surrounding edge computing nodes by applying the MEC paradigm, however, finding the optimal offloading node selection has been challenging problem, which triggered various studies have been conducted. In this paper, communication technologies and edge computing architectures for offloading deep learning models are examined and comparatively analyzed.","2162-1241","978-1-6654-9939-2","10.1109/ICTC55196.2022.9952954","National Research Foundation of Korea (NRF); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9952954","Mobile edge computing;Task offloading;Deep learning","Deep learning;Cloud computing;Multi-access edge computing;Computational modeling;Computer architecture;Mobile handsets;Data models","","1","","9","IEEE","25 Nov 2022","","","IEEE","IEEE Conferences"
"IoT Sensing Platform for e-Agriculture in Africa","A. OLIVEIRA-JR; C. RESENDE; J. GONÇALVES; F. SOARES; W. MOREIRA","Fraunhofer Portugal AICOS, Rua Alfredo Allen 455/461, Porto, Portugal; Fraunhofer Portugal AICOS, Rua Alfredo Allen 455/461, Porto, Portugal; Fraunhofer Portugal AICOS, Rua Alfredo Allen 455/461, Porto, Portugal; Fraunhofer Portugal AICOS, Rua Alfredo Allen 455/461, Porto, Portugal; Fraunhofer Portugal AICOS, Rua Alfredo Allen 455/461, Porto, Portugal","2020 IST-Africa Conference (IST-Africa)","20 Jul 2020","2020","","","1","8","The importance of information and communication technologies (ICT) in small farm agriculture is unquestionable. This paper proposes an IoT Sensing Platform that integrates sensing and wireless communication technologies with soil image acquisition and computer vision to introduce e-agriculture in rural Africa. The proposed IoT sensing platform is part of Project AFRICA that aims at delivering small-scale precision agriculture to smallholder farmers, with special focus on women empowerment. This paper introduces the architecture for the IoT Sensing Platform defined, describes the different prototypes related to the proposed platform, and presents a preliminary validation carried out on a set of the developed prototypes in order to evaluate the viability of the considered sensing elements within the scope of Project AFRICA.","2576-8581","978-1-905824-65-6","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9144060","IoT sensing platform;computer vision;e-agriculture.","Temperature sensors;Soil;Prototypes;Temperature measurement;Cameras;Africa","","","","18","","20 Jul 2020","","","IEEE","IEEE Conferences"
"Eyelid Gesture Control using Wearable Tunnelling Magnetoresistance Sensors","A. Tanwear; H. Heidari; E. Paz; T. Böhnert; R. Ferreira","Microelectronics Lab (meLAB), James Watt School of Engineering, University of Glasgow, Glasgow, UK; Microelectronics Lab (meLAB), James Watt School of Engineering, University of Glasgow, Glasgow, UK; International Iberian Nanotechnology Laboratory (INL), Braga, Portugal; International Iberian Nanotechnology Laboratory (INL), Braga, Portugal; International Iberian Nanotechnology Laboratory (INL), Braga, Portugal","2020 27th IEEE International Conference on Electronics, Circuits and Systems (ICECS)","28 Dec 2020","2020","","","1","4","Everyday technologies are more than ever digitized with the internet of thing's systems and disabled individuals may feel excluded. Handsfree gesture approaches such as eye movements/blinking can enhance interacting with modern technology. This work presents eye blinking for eyelid gesture control using a wearable magnetic system consisting of a flexible magnetic strip on the eyelid and spintronic magnetic sensors with its analogue front-end circuit. To detect eye blinking, tunnelling magnetoresistance (TMR) sensors with a sensitivity of 11mV/V/Oe are embedded into an eyeglass frame. For successful detection of the small magnetic field generated by 6 mm diameter with 1 mm thickness magnetic strip on the eyelid, a sensor readout circuit is designed to amplify the collected signal and cancel the external noise and offset. The circuit is capable of filtering low frequencies <; 0.5 Hz and DC offsets. High frequencies above >28 Hz are filtered for both magnetic field and eyelid movement noise. Each TMR sensor circuit is equipped with a fixed-gain amplifier for detecting low-magnetic field from the mm-sized magnetic strips. The blinks can be repeated within a set time frame and since both eyelids will be detected, multiple command combinations are possible for classification. Based on magnetic field simulation results, the circuit was simulated and has shown high repeatability and stability that can classify eyeblinks based on an amplitude threshold. As a result, the signal can be scaled and classified on a Bluetooth microcontroller capable of connecting to various Bluetooth enabled devices for disabled individuals to communicate with external technology.","","978-1-7281-6044-3","10.1109/ICECS49266.2020.9294878","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9294878","Spintronics;Tunnelling Magnetoresistance Sensor;Eyelid Control;Human-Machine Interface","Strips;Magnetic sensors;Magnetic separation;Eyelids;Tunneling magnetoresistance;Magnetic circuits;Magnetic tunneling","","2","","21","IEEE","28 Dec 2020","","","IEEE","IEEE Conferences"
"Colour Detection And Sorting Of Objects Using IoT","R. Rayala; V. K. Jonnalagadda; V. S. Sriya Vempati; G. S. Tumuluri; J. Tedla","Electrical and Electronics Engineering, V. R. Siddhartha Engineering College, Vijayawada, India; Electrical and Electronics Engineering, V. R. Siddhartha Engineering College, Vijayawada, India; Electrical and Electronics Engineering, V. R. Siddhartha Engineering College, Vijayawada, India; Electrical and Electronics Engineering, V. R. Siddhartha Engineering College, Vijayawada, India; Electrical and Electronics Engineering, V. R. Siddhartha Engineering College, Vijayawada, India","2022 Second International Conference on Next Generation Intelligent Systems (ICNGIS)","30 Mar 2023","2022","","","1","5","Manual sorting is the conventional approach preferred by many medium and small-scale packaging industries. However, considering the visual examination being carried out manually by technicians, the conventional method is laborious, time-consuming, dull, and inconsistent. With the development of society, businesses have become increasingly demanding of businesses for production automation. To address these issues, attempts are being made to develop the design and apply automated techniques, which are desperately needed. As a result, we present a Smart device that uses a TCS3200 colour sensor, NodeMcu, and servo motors that help sort objects based on their colour. This system proposes a method for detecting colour using a colour sensor when an object appears in front of the sensor and after recognition of colour provides a message to the sorter mechanism, which employs a motor to drive the sorting tube towards the appropriate positions and another motor to allow the object to go through the tube. The count of the sorted objects is updated to the ThingSpeak. Hence, a completely automated IoT based detecting and sorting system can be achieved.","","978-1-6654-6792-6","10.1109/ICNGIS54955.2022.10079835","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10079835","Internet of Things Technology;Object Sorting machine;Smart system;ThingSpeak;Automation","Waste management;Automation;Color;Inspection;Electron tubes;Internet of Things;Servomotors","","","","17","IEEE","30 Mar 2023","","","IEEE","IEEE Conferences"
"Deep Learning for Wireless Communications: An Emerging Interdisciplinary Paradigm","L. Dai; R. Jiao; F. Adachi; H. V. Poor; L. Hanzo","Tsinghua University, Beijing, China; Tsinghua University, Beijing, China; Tohoku University, Sendai, Japan; Princeton University, Princeton, NJ, USA; University of Southampton, Southampton, UK","IEEE Wireless Communications","18 Aug 2020","2020","27","4","133","139","Wireless communications are envisioned to bring about dramatic changes in the future, with a variety of emerging applications, such as virtual reality, Internet of Things, and so on, becoming a reality. However, these compelling applications have imposed many new challenges, including unknown channel models, low-latency requirement in large-scale super-dense networks, and so on. The amazing success of deep learning in various fields, particularly in computer science, has recently stimulated increasing interest in applying it to address those challenges. Hence, in this review, a pair of dominant methodologies of using DL for wireless communications are investigated. The first one is DL-based architecture design, which breaks the classical model-based block design rule of wireless communications in the past decades. The second one is DL-based algorithm design, which will be illustrated by several examples in a series of typical techniques conceived for 5G and beyond. Their principles, key features, and performance gains will be discussed. Open problems and future research opportunities will also be pointed out, highlighting the interplay between DL and wireless communications. We expect that this review can stimulate more novel ideas and exciting contributions for intelligent wireless communications.","1558-0687","","10.1109/MWC.001.1900491","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9165550","","Wireless communication;Mathematical model;Receivers;Channel estimation;Channel models;MIMO communication","","68","","15","IEEE","12 Aug 2020","","","IEEE","IEEE Magazines"
"Randomized Algorithms for Computation of Tucker Decomposition and Higher Order SVD (HOSVD)","S. Ahmadi-Asl; S. Abukhovich; M. G. Asante-Mensah; A. Cichocki; A. H. Phan; T. Tanaka; I. Oseledets","CDISE, Skolkovo Institute of Science and Technology (SKOLTECH), Moscow, Russia; CDISE, Skolkovo Institute of Science and Technology (SKOLTECH), Moscow, Russia; CDISE, Skolkovo Institute of Science and Technology (SKOLTECH), Moscow, Russia; CDISE, Skolkovo Institute of Science and Technology (SKOLTECH), Moscow, Russia; CDISE, Skolkovo Institute of Science and Technology (SKOLTECH), Moscow, Russia; Institute of Global Innovation and Research, Tokyo University of Agriculture and Technology, Tokyo, Japan; CDISE, Skolkovo Institute of Science and Technology (SKOLTECH), Moscow, Russia","IEEE Access","19 Feb 2021","2021","9","","28684","28706","Big data analysis has become a crucial part of new emerging technologies such as the internet of things, cyber-physical analysis, deep learning, anomaly detection, etc. Among many other techniques, dimensionality reduction plays a key role in such analyses and facilitates feature selection and feature extraction. Randomized algorithms are efficient tools for handling big data tensors. They accelerate decomposing large-scale data tensors by reducing the computational complexity of deterministic algorithms and the communication among different levels of memory hierarchy, which is the main bottleneck in modern computing environments and architectures. In this article, we review recent advances in randomization for computation of Tucker decomposition and Higher Order SVD (HOSVD). We discuss random projection and sampling approaches, single-pass and multi-pass randomized algorithms and how to utilize them in the computation of the Tucker decomposition and the HOSVD. Simulations on synthetic and real datasets are provided to compare the performance of some of best and most promising algorithms.","2169-3536","","10.1109/ACCESS.2021.3058103","Ministry of Education and Science of the Russian Federation through the Mega Grant Project 14.756.31.0001; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9350569","Randomized algorithm;tensor decomposition;random projection;sampling;unfolding;Tucker decomposition;HOSVD","Tensors;Matrix decomposition;Signal processing algorithms;Approximation algorithms;Memory management;Probability distribution","","31","","140","CCBY","9 Feb 2021","","","IEEE","IEEE Journals"
"Learning-Based Scalable Scheduling and Routing Co-Design With Stream Similarity Partitioning for Time-Sensitive Networking","L. Xu; Q. Xu; J. Tu; J. Zhang; Y. Zhang; C. Chen; X. Guan","Department of Automation, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Shanghai Jiao Tong University, Shanghai, China","IEEE Internet of Things Journal","25 Jul 2022","2022","9","15","13353","13363","The deterministic and real-time communication is the indispensable requirement in Industrial Internet of Things (IIoT) application areas. Time-sensitive networking (TSN) is a promising technology for this kind of communication demands through designing proper scheduling and routing mechanisms. However, it is still challenging to design the mechanisms for large-scale instances due to high computational complexity. In order to guarantee schedulability and scalability, a learning-based scalable scheduling and routing co-design (LSSR) architecture is proposed in this article for TSN. A stream partition method combining classification and graph-based clustering is established to reduce interpartition conflicts to enhance schedulability based on the explored domain knowledge and the characterized stream data set for practical requirements. Integrated with the stream partition method, we construct the constraints of scheduling and routing co-design to guarantee the deterministic and real-time transmission. An iterative scheduling algorithm is proposed to reduce the computational complexity and thus, to enhance scalability. Simulations demonstrate the effectiveness and advantages of the proposed LSSR scheme.","2327-4662","","10.1109/JIOT.2022.3143829","National Key Research and Development Program of China(grant numbers:2018YFB1702100); National Natural Science Foundation of China(grant numbers:62025305,61933009,62103272); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9684566","Industrial Internet of Things (IIoT);iterative scheduling;stream partition;time-sensitive networking (TSN)","Routing;Processor scheduling;Job shop scheduling;Real-time systems;Scalability;Ethernet;Schedules","","24","","36","IEEE","18 Jan 2022","","","IEEE","IEEE Journals"
"Intelligent Blockchain-Enabled Adaptive Collaborative Resource Scheduling in Large-Scale Industrial Internet of Things","K. Lin; J. Gao; G. Han; H. Wang; C. Li","School of Computer Science and Technology, Dalian University of Technology, Dalian, China; School of Computer Science and Technology, Dalian University of Technology, Dalian, China; Department of Information and Communication System, Hohai University, Changzhou, China; School of Computer Science and Technology, Dalian University of Technology, Dalian, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Industrial Informatics","30 Sep 2022","2022","18","12","9196","9205","With the explosive growth of devices and tasks deployed in the industrial Internet of Things (IIoT), the lack of interconnection and collaboration between devices leads to poor timeliness and security in IIoT resource scheduling. This article focuses on the issue of adaptive scheduling of resources in large-scale IIoT. First, a collaborative terminal-edge IIoT architecture is designed, which introduces blockchain and AI technology to support dynamic resource scheduling in untrustworthy environments. Then, a smart contract-based multidimensional resource transaction model is developed to improve the efficiency and security of resource scheduling by establishing a credit-based consensus mechanism. Distributed transaction learning resource scheduling algorithm is further proposed to implement resource-adaptive scheduling between devices in IIoT. Extensive simulation experiments are conducted to evaluate the proposed method with respect to several performance aspects covering the scheduling decision delay, transaction generation ratio, and security. The obtained results demonstrate that the comprehensive scheduling performance of the proposed method outperforms other existing algorithms.","1941-0050","","10.1109/TII.2022.3169457","National Key R&D Program of China(grant numbers:2020YFB1710901); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9763003","Blockchain technology;deep reinforcement learning;industrial Internet of Things (IIoT);resource transaction","Industrial Internet of Things;Job shop scheduling;Blockchains;Dynamic scheduling;Collaboration;Processor scheduling;Security","","5","","23","IEEE","26 Apr 2022","","","IEEE","IEEE Journals"
"Blockchain-Enabled Parallel Learning in Industrial Edge-Cloud Network: a Fuzzy DPoSt-PBFT Approach","F. Yang; J. Tian; T. Feng; F. Xu; C. Qiu; C. Zhao","School of Information and Communication Engineering (SICE), Beijing University of Posts and Telecommunications (BUPT), Beijing, China; State Grid Hunan Electric Power Company Limited; China National Tendering Center of Mach. Elec. Equipment, MIIT; School of Information and Communication Engineering (SICE), Beijing University of Posts and Telecommunications (BUPT), Beijing, China; College of Intelligence and Computing, Tianjin University; School of Information and Communication Engineering (SICE), Beijing University of Posts and Telecommunications (BUPT), Beijing, China","2021 IEEE Globecom Workshops (GC Wkshps)","24 Jan 2022","2021","","","1","6","Recently, parallel reinforcement learning (PRL) based Industrial Internet of Things (IIoT) edge-cloud resource scheduling has elicited escalating attention. However, with the scale of IIoT expands, there are several challenges in the existing researches: 1) large number of parallel servers slows down the convergence rate of PRL; 2) malicious parallel server affects resource allocation efficiency. In order to solve the above efficiency and security problem, blockchain-based approaches are introduced in PRL based resource allocation problem. However, traditional consensus algorithm in blockchain is not suitable for resource allocation and is inefficient. Thus, in this article, based on a novel fuzzy delegated proof of state and practical byzantine fault tolerance (fuzzy DPoSt+PBFT) consensus algorithm, we propose a blockchain-enabled collaborative parallel Q-learning (CPQL) approach to address the above challenges. To be specific, we first construct an edge-cloud collaborative architecture for executing the diversity intelligence IIoT applications. Then, we propose a CPQL algorithm for edge-cloud resource allocation and choosing the optimal number of parallel edge servers to speed up the Q-table training. In the Q-table aggregation process in CPQL, a fuzzy DPoSt+PBFT algorithm is designed for secure CPQL training and efficient consensus. Experimental results show the superior performance of the proposed approach. And the proposed approach has great potential in IIoT resource allocation problem.","","978-1-6654-2390-8","10.1109/GCWkshps52748.2021.9681977","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9681977","Blockchain;consensus protocol;collaborative parallel reinforcement learning;industrial edge-cloud network","Training;Q-learning;Job shop scheduling;Fault tolerant systems;Collaboration;Consensus algorithm;Resource management","","4","","32","IEEE","24 Jan 2022","","","IEEE","IEEE Conferences"
"Incentive Schemes for User‐Provided Fog Infrastructure","G. Iosifidis; L. Gao; J. Huang; L. Tassiulas","School of Computer Science and Statistics, Trinity College Dublin, University of Dublin, Ireland; Department of Electronic and Information Engineering, Harbin Institute of Technology, Shenzhen, China; School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen, China; Department of Electrical Engineering, and Institute for Network Science, Yale University, New Haven, CT, USA","Fog and Fogonomics: Challenges and Practices of Fog Computing, Communication, Networking, Strategy, and Economics","","2020","","","129","150","User‐provided infrastructures (UPIs) are attracting growing interests and are expected to play an important role in realizing the vision of fog computing. This chapter provides an overview of UPIs by focusing on models for network sharing. It discusses the technical issues pertaining to resource allocation for these services and explains the importance of incorporating incentive schemes. The chapter analyzes mobile UPI models that are inspired by Open Garden, where users collaborate in an autonomous fashion, and describes UPI models that are enabled by a central service provider, as in the case of Karma mobile operator. In both cases, the chapter also discusses the challenges in designing incentive mechanisms and presents novel solutions. It also describes a different collaboration mechanism that is fully decentralized and lightweight, with minimum signaling requirements, and hence suitable for large‐scale fog computing architectures as those that expected to arise in Internet of Things.","","9781119501107","10.1002/9781119501121.ch6","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9215563.pdf&bkn=9215548&pdfType=chapter","","Wireless fidelity;Edge computing;Incentive schemes;Internet of Things;Computational modeling;Economics","","1","","","","7 Oct 2020","","","Wiley","Wiley Telecom eBook Chapters"
"Improving Performance of Large-Scale MIMO Detector Via A Proposed Two-Step Deep-Learning Architecture","H. T. Nguyen; D. T. M. Hoang; A. T. Pham","Faculty of Technology Natural Sciences and Maritime Sciences, University of Southeast Norway; Falcuty of Telecomunication, Hanoi University of Science and Technology, Hanoi, Vietnam; Faculty of Telecommunications Posts and Telecommunications, Institute of Technologies, Hanoi, Vietnam","2022 IEEE 33rd Annual International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC)","20 Dec 2022","2022","","","1294","1300","A large-scale multiple-input multiple-out (LS-MIMO) transmission technique with low-resolution analog-to-digital converters (ADCs) has become one of the promising techniques for 5G and future wireless networks. In this paper, we first present the mathematical derivation to fit the high-order 4-ary Amplitude Shift-Keying (ASK) superposition modulation scheme in the conventional deep-learning LS-MIMO signal detector designed previously for the binary phase-shift-keying (BPSK) modulation scheme. Importantly, we also propose a two-step deep-learning detection network that does not require training the network again when changing the modulation order, for example, from BPSK to 4-ary ASK and more, provided that the MIMO configuration is kept unchanged. The two-step model offers a low computing requirement and shorter processing time and still achieves better bit error rate (BER) performance over the one-step architecture. The essential attribute of the proposed two-step detector is that no further training is needed makes it promising for the Internet of Things, where devices with a low computing capacity are embedded. Moreover, the advantages of the two-step deep-learning detector also open up a great possibility to deploy the adaptive modulation transmission scheme to enjoy the channel gain variation of wireless fading channels.","2166-9589","978-1-6654-8053-6","10.1109/PIMRC54779.2022.9977645","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9977645","","Training;Performance evaluation;Fading channels;Wireless networks;Amplitude shift keying;Bit error rate;Detectors","","","","16","IEEE","20 Dec 2022","","","IEEE","IEEE Conferences"
"Dependable Service-Oriented Design of Healthcare IoT","A. Alsaig; V. Alagar","Computer Science and Software Engineering, Concordia University, Montreal, Canada; Computer Science and Software Engineering, Concordia University, Montreal, Canada","2023 IEEE International Conference on Smart Internet of Things (SmartIoT)","1 Nov 2023","2023","","","257","264","Healthcare Internet of Things (HIoT) is transforming healthcare industry by providing large scale connectivity for medical devices, patients, physicians, clinical staff, and nurses who may use them remotely to facilitate real-time monitoring based on the information gathered from the connected medical devices. This network provides both opportunity and challenges for collecting relevant healthcare information and sharing it for innovative research and efficient healthcare provision. Patient-centric information such as their health status and medical devices used by them must be protected to provide safety and offer privacy, while healthcare knowledge should be shared in confidence by experts for healthcare innovation and timely treatment of patients. In this paper a dependable service-oriented 3-tier architecture of HIoT is proposed. Context-aware role-based access control scheme is discussed to ensure services in HIoT are dependable, in the sense that every service provided to any patient in the network, anywhere and at anytime is safe, secure, reliable, and the privacy of patient receiving it is protected.","2770-2677","979-8-3503-1657-5","10.1109/SmartIoT58732.2023.00046","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10296390","Healthcare IoT;Service-oriented IoT;Dependable Services;Context-aware role based access control;Layered Architecture","Privacy;Technological innovation;Medical devices;Semantics;Medical services;Real-time systems;Safety","","","","30","IEEE","1 Nov 2023","","","IEEE","IEEE Conferences"
"EaaS: A Service-Oriented Edge Computing Framework Towards Distributed Intelligence","M. Zhang; J. Cao; Y. Sahni; Q. Chen; S. Jiang; T. Wu","Department of Computing, The Hong Kong Polytechnic University; Department of Computing, The Hong Kong Polytechnic University; Department of Computing, The Hong Kong Polytechnic University; Department of Computing, The Hong Kong Polytechnic University; Department of Computing, The Hong Kong Polytechnic University; Department of Computing, The Hong Kong Polytechnic University","2022 IEEE International Conference on Service-Oriented System Engineering (SOSE)","13 Oct 2022","2022","","","165","175","Edge computing has become a popular paradigm where services and applications are deployed at the network edge closer to the data sources. It provides applications with outstanding benefits, including reduced response latency and enhanced privacy protection. For emerging advanced applications, such as autonomous vehicles, industrial IoT, and metaverse, further research is needed. This is because such applications demand ultra-low latency, hyper-connectivity, and dynamic and reliable service provision, while existing approaches are inadequate to address the new challenges. Hence, we envision that the future edge computing is moving towards distributed intelligence, where heterogeneous edge nodes collaborate to provide services in large-scale and geo-distributed edge infrastructure. We thereby propose Edge-as-a-Service (EaaS) to enable distributed intelligence. EaaS jointly manages large-scale cross-node edge resources and facilitates edge autonomy, edge-to-edge collaboration, and resource elasticity. These features enable flexible deployment of services and ubiquitous computation and intelligence. We first give an overview of existing edge computing studies and discuss their limitations to articulate the motivation for proposing EaaS. Then, we describe the details of EaaS, including the physical architecture, proposed software framework, and benefits of EaaS. Various application scenarios, such as real-time video surveillance, smart building, and metaverse, are presented to illustrate the significance and potential of EaaS. Finally, we discuss several challenging issues of EaaS to inspire more research towards this new edge computing framework.","2642-6587","978-1-6654-7534-1","10.1109/SOSE55356.2022.00026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9912635","Edge computing;edge as a service;service-oriented architecture;edge intelligence;edge-native applications","Smart buildings;Metaverse;Soft sensors;Collaboration;Video surveillance;Ubiquitous computing;Reliability","","7","","71","IEEE","13 Oct 2022","","","IEEE","IEEE Conferences"
"Trustworthy Network Anomaly Detection Based on an Adaptive Learning Rate and Momentum in IIoT","X. Yan; Y. Xu; X. Xing; B. Cui; Z. Guo; T. Guo","Beijing University of Posts and Telecommunications, Beijing, China; Hunan University, Changsha, China; Guangzhou University, Guangzhou, China; Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; Hunan University of Technology and Business, Changsha, China","IEEE Transactions on Industrial Informatics","2 Jun 2020","2020","16","9","6182","6192","While the industrial Internet of Things (IIoT) brings convenience to the industry, it also brings security problems. Due to the massive amount of data generated by the surge of IIoT devices, it is impossible to ensure whether these data contain an attack or untrustworthy data, therefore, how to ensure the security and trustworthiness of IIoT devices has become an urgent problem to solve. In this article, we design a new hinge classification algorithm based on mini-batch gradient descent with an adaptive learning rate and momentum (HCA-MBGDALRM) to minimize the effects of security attacks. The algorithm significantly improves the performance of deep network training compared with traditional neural networks, decision trees and logistic regression in terms of scale and speed. In addition, we have solved the data skew problem in the shuffle phase, and we implement a parallel framework for HCA-MBGDALRM to accelerate the processing speed of very large traffic data sets.","1941-0050","","10.1109/TII.2020.2975227","Fundamental Research Funds for the Central Universities(grant numbers:531118010454); Guangdong Natural Science Foundation of China(grant numbers:2016A030313540); Guangzhou Science and Technology Program(grant numbers:201707010284); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9004556","Anomaly detection;gradient descent;hinge classification algorithm based on mini-batch gradient descent with an adaptive learning rate and momentum (HCA-MBGDALRM);hinge classification;trust management","Training;Fasteners;Servers;Big Data;Adaptive learning;Phishing","","79","","30","IEEE","20 Feb 2020","","","IEEE","IEEE Journals"
"A Big Data-Enabled Consolidated Framework for Energy Efficient Software Defined Data Centers in IoT Setups","K. Kaur; S. Garg; G. Kaddoum; E. Bou-Harb; K. -K. R. Choo","Electrical Engineering Department, École de technologie supérieure, Université du Québec, Montréal, Canada; Electrical Engineering Department, École de technologie supérieure, Université du Québec, Montréal, Canada; Electrical Engineering Department, École de technologie supérieure, Université du Québec, Montréal, Canada; Florida Atlantic University, Boca Raton, USA; Department of Information Systems and Cyber Security and Department of Electrical and Computer Engineering, University of Texas at San Antonio, San Antonio, USA","IEEE Transactions on Industrial Informatics","22 Jan 2020","2020","16","4","2687","2697","The rapidly evolving industry standards and transformative advances in the field of Internet of Things are expected to create a tsunami of Big Data shortly. This, in turn, will demand real-time data analysis and processing from cloud computing platforms. A substantial part of the computing infrastructure is supported by large-scale and geographically distributed data centers (DCs). Nevertheless, these DCs impose a substantial cost in terms of rapidly growing energy consumption, which in turn adversely affects the environment. In this context, efficient resource utilization is seen as a potential candidate to enhance energy efficiency and minimize the load on the power sector. Nevertheless, in the majority of the public clouds, the resources are idle most of the time (i.e., under-utilized) as the load of the servers is unpredictable; thereby leading to a lofty increase in the energy utilization index and wastage of resources. Thus, it is highly essential to devise a precise and efficient resource management technique. Therefore, in this article, we leverage the advantages of software defined data centers (SDDCs) to minimize energy utilization levels. Precisely, SDDC refers to the process of programmatically abstracting the logical computing, network, and storage resources; and configuring them in real-time based on workload demands. In detail, we demonstrate the possibility of 1) designing a consolidated SDDC-based model to jointly optimize the process of virtual machine (VM) deployment and network bandwidth allocation for reduced energy consumption and guaranteed quality of service (QoS), particularly for heterogeneous computing infrastructures; 2) formulating a multiobjective optimization problem to deduce the optimal allocation of resources for both critical and noncritical applications; and 3) designing an efficient scheme based on heuristics to provide suboptimal results for the formulated multiobjective optimization problem. The proposed article presents a suboptimal approach based on first fit decreasing algorithm. Further, our empirical evaluations suggest that the proposed framework leads to almost 27.9% savings in terms of energy consumptions against the existing schemes with negligible QoS violations (approximately 0.33).","1941-0050","","10.1109/TII.2019.2939573","Natural Sciences and Engineering Research Council of Canada; Tier 2 Canada Research Chair on the Next Generations of Wireless IoT Networks; National Science Foundation; Office of Advanced Cyberinfrastructure; Office of Advanced Cyberinfrastructure(grant numbers:1907821); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8825507","Big Data;cloud computing;energy minimization;Internet of Things;multiobjective optimization problem;prioritized scheduling;software defined data centers;and virtual machines","Quality of service;Switches;Data centers;Cloud computing;Software;Virtual machining;Internet of Things","","73","","30","IEEE","5 Sep 2019","","","IEEE","IEEE Journals"
"CeCO: Cost-Efficient Computation Offloading of IoT Applications in Green Industrial Fog Networks","A. Hazra; T. Amgoth","Indian Institute of Technology (Indian School of Mines), Dhanbad, India; Indian Institute of Technology (Indian School of Mines), Dhanbad, India","IEEE Transactions on Industrial Informatics","14 Jun 2022","2022","18","9","6255","6263","Fog computing is one of the promising technology that could reduce the execution cost and energy consumption of smart industrial Internet of Things (IIoT) devices via a strategy called offloading. However, designing an intelligent offloading strategy for large-scale industrial applications becomes challenging. To address this issue, in this article, we design a novel fog federation, a computation offloading framework for industrial networks called cost-efficient computation offloading (CeCO), where a master fog controller regulates the network and distributes the IIoT data among the fog devices. In particular, we design our cost optimization function as the sum of weighted energy-delay cost of IIoT devices while reaching several constraints. To determine this optimization problem, we first design a frequency control mechanism for the IIoT devices. Then, we introduce a controller-based device adaptation strategy and a policy-based reinforcement learning technique for efficiently controlling emergency-based service demands and accordingly route them toward the fog devices following the shortest path. Experimental results demonstrate the effectiveness of the CeCO strategy then the baseline algorithms while maintaining the same and even better cost utilization and performance maximization upto 13%–18% for industrial applications.","1941-0050","","10.1109/TII.2021.3130255","DST (SERB), Government of India(grant numbers:EEQ/2018/000888); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9626588","Computation offloading;cost optimization;energy management;fog controller;industrial Internet of Things (IoT);  $Q$  -learning","Industrial Internet of Things;Task analysis;Costs;Computational modeling;Servers;Informatics;Green products","","21","","20","IEEE","24 Nov 2021","","","IEEE","IEEE Journals"
"Latency Minimization in a Fuzzy-Based Mobile Edge Orchestrator for IoT Applications","V. Nguyen; T. T. Khanh; T. Z. Oo; N. H. Tran; E. -N. Huh; C. S. Hong","Department of Computer Science and Engineering, Kyung Hee University, Yongin, South Korea; Department of Computer Science and Engineering, Kyung Hee University, Yongin, South Korea; Department of Computer Science and Engineering, Kyung Hee University, Yongin, South Korea; School of Computer Science, The University of Sydney, Sydney, NSW, Australia; Department of Computer Science and Engineering, Kyung Hee University, Yongin, South Korea; Department of Computer Science and Engineering, Kyung Hee University, Yongin, South Korea","IEEE Communications Letters","8 Jan 2021","2021","25","1","84","88","Currently, matching the incoming Internet of Things applications to the current state of computing and networking resources of a mobile edge orchestrator (MEO) is critical for providing the high quality of service while temporally and spatially changing the incoming workload. However, MEO needs to scale its capacity concerning a large number of devices to avoid task failure and to reduce service time. To cope with this issue, we propose MEO with fuzzy-based logic that splits tasks from mobile devices and maps them onto the cloud and edge servers to reduce the latency of handling these tasks and task failures. A fuzzy-based MEO handles the multi-criteria decision-making process to decide where the offloaded task should run by considering multiple parameters in the same framework. Our approach selects the appropriate host for task execution and finds the optimal task-splitting strategy. Compared to the existing approaches, the service time using our proposal can achieve up to 7.6%, 22.6%, 38.9%, and 51.8% performance gains for augmented reality, healthcare, compute-intensive, and infotainment applications, respectively.","1558-2558","","10.1109/LCOMM.2020.3024957","MSIT (Ministry of Science and ICT), Korea, under the Grand Information Technology Research Center support program and service mobility support distributed cloud technology(grant numbers:IITP-2020-2015-0-00742,MSIT-2017-0-00294); IITP (Institute for Information & communications Technology Planning & Evaluation); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9201136","Mobile edge orchestrator;edge computing;cloud computing;latency minimization;fuzzy-based approach","Task analysis;Servers;Cloud computing;Mobile handsets;Edge computing;Wide area networks;Delays","","8","","16","IEEE","21 Sep 2020","","","IEEE","IEEE Journals"
"Low-Latency Federated Learning With DNN Partition in Distributed Industrial IoT Networks","X. Deng; J. Li; C. Ma; K. Wei; L. Shi; M. Ding; W. Chen","School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China; Data61, CSIRO, Sydney, NSW, Australia; Department of Electronics Engineering, Shanghai Jiao Tong University, Shanghai, China","IEEE Journal on Selected Areas in Communications","15 Feb 2023","2023","41","3","755","775","Federated Learning (FL) empowers Industrial Internet of Things (IIoT) with distributed intelligence of industrial automation thanks to its capability of distributed machine learning without any raw data exchange. However, it is rather challenging for lightweight IIoT devices to perform computation-intensive local model training over large-scale deep neural networks (DNNs). Driven by this issue, we develop a communication-computation efficient FL framework for resource-limited IIoT networks that integrates DNN partition technique into the standard FL mechanism, wherein IIoT devices perform local model training over the bottom layers of the objective DNN, and offload the top layers to the edge gateway side. Considering imbalanced data distribution, we derive the device-specific participation rate to involve the devices with better data distribution in more communication rounds. Upon deriving the device-specific participation rate, we propose to minimize the training delay under the constraints of device-specific participation rate, energy consumption and memory usage. To this end, we formulate a joint optimization problem of device scheduling and resource allocation (i.e. DNN partition point, channel assignment, transmit power, and computation frequency), and solve the long-term min-max mixed integer non-linear programming based on the Lyapunov technique. In particular, the proposed dynamic device scheduling and resource allocation (DDSRA) algorithm can achieve a trade-off to balance the training delay minimization and FL performance. We also provide the FL convergence bound for the DDSRA algorithm with both convex and non-convex settings. Experimental results demonstrate the derived device-specific participation rate in terms of feasibility, and show that the DDSRA algorithm outperforms baselines in terms of test accuracy and convergence time.","1558-0008","","10.1109/JSAC.2022.3229436","National Key Project(grant numbers:2020YFB1807700,2018YFB1801102); National Natural Science Foundation of China(grant numbers:61872184,62002170,62071296); Fundamental Research Funds for the Central Universities(grant numbers:30921013104); Future Network Grant of Provincial Education Board in Jiangsu; Zhejiang Laboratory Open Research Project(grant numbers:K2022PD0AB02); Jiangsu Specially-Appointed Professor Program 2021; Shanghai Kewei(grant numbers:20JC1416502,22JC1404000); Pudong(grant numbers:PKX2021-D02); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9999679","Federated learning;deep neural network (DNN) partition;device-specific participation rate;dynamic device scheduling and resource allocation","Training;Industrial Internet of Things;Performance evaluation;Resource management;Computational modeling;Logic gates;Data models","","6","","51","IEEE","27 Dec 2022","","","IEEE","IEEE Journals"
"FlowChain: The Playground for Federated Learning in Industrial Internet of Things Environments","P. Bellavista; L. Foschini; R. Montanari; N. Romandini","University of Bologna, Italy; University of Bologna, Italy; University of Bologna, Italy; University of Bologna, Italy","IEEE Internet of Things Magazine","13 Sep 2022","2022","5","2","78","83","The Industrial Internet of Things (IIoI) lays the foundation for a new industrial revolution, the so-called Industry 4.0, in which every element, from machines to processes, is interconnected and fully automated, producing a huge amount of valuable data, crucial for making industrial processes more efficient and profitable. For this reason, it is common to run machine learning algorithms in order to extract useful information from these data. At the same time, due to bandwidth and privacy issues, it is often infeasible to transfer all these large-scale data to a centralized location where these algorithms can be performed. To address these scenarios, federated learning (FL) has been gaining ground in recent years. FL leaves the training data on the devices where they are produced and builds a global model by aggregating locally computed models, preserving user privacy and avoiding overwhelming the network with unnecessary raw data. However, there are still important challenges and limitations to the application of FL in Industry 4.0, mainly due to security issues and the fact that many solutions still suffer from single points of failure and bottlenecks. In this article, we present FlowChain, a framework that integrates FL with blockchain technology and decentralized identifiers (DIDs) to create an infrastructure that offers the possibility to easily exploit FL in Industry 4.0 scenarios. By using smart contract technology to automate the aggregation of partial models, it is possible to make FL fully decentralized. In addition, the fact that the blockchain is immutable and every transaction is verified and traceable makes FL secure. Furthermore, we exploit DIDs to be able to uniquely identify each element participating in industrial processes. This allows finer-grained control of authorizations so that only IIoT devices with a known and authorized identity can actually participate in the FL training process. Finally, we present some preliminary results that demonstrate the feasibility of the proposed approach.","2576-3199","","10.1109/IOTM.001.2100188","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9889268","","Data privacy;Machine learning algorithms;Computational modeling;Training data;Collaborative work;Data models;Industrial Internet of Things;Fourth Industrial Revolution;Smart contracts;Collaborative work","","2","","15","IEEE","13 Sep 2022","","","IEEE","IEEE Magazines"
"Main-Secondary Blockchain Framework: Cross-Domain Trust Management Mechanism Using Trust Ticket","X. Wu; S. Wei; Z. Zhang; P. Lv","School of Information Science and Technology, Hainan Normal University, Haikou, China; School of Computer, Electronics and Information, Guangxi University, Nanning, China; School of Computer, Electronics and Information, Guangxi University, Nanning, China; Guangxi Key Laboratory of Multimedia Communications and Network Technology, Guangxi University, Nanning, China","IEEE Transactions on Network and Service Management","9 Oct 2023","2023","20","3","2830","2844","Industrial Internet of Things (IIoT) can facilitate smart manufacturing and increase productivity through revolutionary techniques. As production processes are getting more sophisticated, an entire production process is usually completed collaboratively by multiple administrative domains (e.g., factories). Trust management is an effective solution to establish trust relationship between the devices from different administrative domains. Recently, many researchers integrate blockchain into trust management mechanisms. However, the existing methods have the shortcoming of low throughput, high delay and storage overhead, so cannot meet scalability requirements of large-scale IIoT multi-domains scenarios. Therefore, this paper proposes a main-secondary chain framework to realize a scalable cross-domain trust management mechanism (MSB-CTrust), where trust tickets are used to resolve the heterogeneity issue of trust evaluation methods in different domains. Besides, MSB-CTrust provides embedded salary distribution rules, which are used to encourage all devices to behave honestly based on a revenue strategy game. Performance evaluations in the experiments show the feasibility and effectiveness of MSB-CTrust.","1932-4537","","10.1109/TNSM.2023.3236673","National Natural Science Foundation of China(grant numbers:62062006,71501156,62062008,62067001); Natural Science Basis Research Plan in Guangxi Province of China(grant numbers:2018JJA170028); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10016666","Main-secondary chain;trust management;industrial Internet of Things","Blockchains;Industrial Internet of Things;Trust management;Reliability;Computer architecture;Throughput;Authentication","","2","","31","IEEE","13 Jan 2023","","","IEEE","IEEE Journals"
"A Lightweight Mobile Temporal Convolution Network for Multi-Location Human Activity Recognition based on Wi-Fi","Z. Li; T. Jiang; J. Yu; X. Ding; Y. Zhong; Y. Liu","Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; Beijing Institute of Technology, Beijing, China; Aisino Co., Ltd","2021 IEEE/CIC International Conference on Communications in China (ICCC Workshops)","23 Sep 2021","2021","","","143","148","Wi-Fi-based human activity recognition has been widely adopted in the field of the Internet of Things. Although recent works have made great progress for human activity recognition at multiple locations, most of them rely on high-resolution data, adequate training samples and large-scale networks to model human activities, which ignores serial floating-point operations on CPU-driven devices and memory consumption limitations. Therefore, to address above issue, this paper proposes a Lightweight Mobile Temporal Convolution Network (LM-TCN). On the one hand, the proposed approach uses the fully 1-D convolution framework to provide time-shift invariant inductive bias. On the other hand, the combination of invert bottleneck and gated mechanism optimizes the computational load of the conventional residual structure to prevent overfitting under few training samples. Experimental results show that the average accuracy of the proposed LM-TCN is 95.2% across all 24 predefined locations, which is 2.9% higher than the baseline TCN while the calculation cost is reduced to 6% of TCN. It is worth noting that only 10 samples and 15 subcarriers for each activity at each location are used for training.","2474-9133","978-1-6654-3944-2","10.1109/ICCCWorkshops52231.2021.9538870","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9538870","Human Activity Recognition;Temporal Convolution Network;Lightweight Depthwise Convolutions;Channel State Information;Internet of Things","Training;Costs;Convolution;Memory management;Activity recognition;Logic gates;Feature extraction","","1","","23","IEEE","23 Sep 2021","","","IEEE","IEEE Conferences"
"A Secure IoT Transmission Scheme Based on Edge Computing","B. Qi","School of Cyber Science and Engineering, Southeast University, Nanjing, China","2021 IEEE 5th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)","5 Apr 2021","2021","","","2499","2504","IoT security is one of the most important challenges for the development of IoT. A large number of resource-constrained nodes in IoT have insufficient storage space, limited computing power, unstable communication links, and cannot adopt internet standard security protocols to guarantee the end-to-end security of communication, which becomes the weakness of IoT. Combining the characteristics and development trend of IoT, this paper proposes an edge computing based IoT security architecture and proposes a novel security transmission scheme. In this scheme, an end-to-end security approach based on proxy datagram transport layer security is adopted. Analysis and experiments show that the scheme can enable resource-constrained devices in the IoT to communicate securely end-to-end using internet-standard security protocols, and has good scale, scalability, and practical feasibility","2689-6621","978-1-7281-8028-1","10.1109/IAEAC50856.2021.9390953","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9390953","IoT transmission;edge computing;end-to-end security;DTLS proxy;constrained resources","Protocols;Computer architecture;Market research;Security;Internet of Things;Standards;Edge computing","","","","16","IEEE","5 Apr 2021","","","IEEE","IEEE Conferences"
"Wavelet Packet Division Multiplexing (WPDM)-Aided Industrial WSNs","I. Dey; N. Marchetti","CONNECT research centre, Electronic Engineering National University of Ireland, Maynooth; CONNECT research centre, School of Engineering, Trinity College Dublin, Ireland","2022 IEEE 33rd Annual International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC)","20 Dec 2022","2022","","","548","553","Industrial Internet-of-Things (IIoT) involve multiple groups of sensors, each group sending its observations on a particular phenomenon to a central computing platform over a multiple access channel (MAC). The central platform incorporates a decision fusion center (DFC) that arrives at global decisions regarding each set of phenomena by combining the received local sensor decisions. Owing to the diverse nature of the sensors and heterogeneous nature of the information they report, it becomes extremely challenging for the DFC to denoise the signals and arrive at multiple reliable global decisions regarding multiple phenomena. The industrial environment represents a specific indoor scenario devoid of windows and filled with different noisy electrical and measuring units. In that case, the MAC is modelled as a large-scale shadowed and slowly-faded channel corrupted with a combination of Gaussian and impulsive noise. The primary contribution of this paper is to propose a flexible, robust and highly noise-resilient multi-signal transmission framework based on Wavelet packet division multiplexing (WPDM). The local sensor observations from each group of sensors are waveform coded onto wavelet packet basis functions before reporting them over the MAC. We assume a multi-antenna DFC where the waveform-coded sensor observations can be separated by a bank of linear filters or a correlator receiver, owing to the orthogonality of the received waveforms. At the DFC we formulate and compare fusion rules for fusing received multiple sensor decisions, to arrive at reliable conclusions regarding multiple phenomena. Simulation results show that WPDM-aided wireless sensor network (WSN) for IIoT environments offer higher immunity to noise by more than 10 times over performance without WPDM in terms of probability of false detection.","2166-9589","978-1-6654-8053-6","10.1109/PIMRC54779.2022.9978103","Science Foundation Ireland (SFI)(grant numbers:13/RC/2077/P2); CHIST-ERA(grant numbers:2017); Irish Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9978103","Wavelet Packet Transform;Denoising;Industrial IoT;Industrial WSNs","Multiplexing;Wireless sensor networks;Simulation;Sensor phenomena and characterization;Sensor fusion;Wavelet packets;Sensors","","","","16","IEEE","20 Dec 2022","","","IEEE","IEEE Conferences"
"FFD: A Full-Stack Federated Distillation method for Heterogeneous Massive IoT Networks","M. -D. Nguyen; H. -S. Luong; Tung-Nguyen; Q. -V. Pham; Q. V. Do; W. -J. Hwang","Department of Information Convergence Engineering, Pusan National University, Busan, Republic of Korea; Department of Autonomous Driving, Vinfast, Hanoi, Vietnam; Department of Information Convergence Engineering, Pusan National University, Busan, Republic of Korea; Korean Southeast Center for the 4th Industrial Revolution Leader Education, Pusan National University, Busan, Republic of Korea; Department of Information Convergence Engineering, Pusan National University, Busan, Republic of Korea; Department of Biomedical Convergence Engineering, Pusan National University, Yangsan, Republic of Korea","2022 International Conference on Advanced Technologies for Communications (ATC)","15 Nov 2022","2022","","","326","331","Data imbalance and complexity are the key challenges of applying federated learning (FL) techniques for wireless networks. In this paper, we propose a novel framework inspired by a divide-and-conquer algorithm. We aim to develop a full-stack federated distillation (FFD) method for federated learning over a massive Internet of Things network. We first divide the network into sub-regions that can be represented by a neural network model. After performing local training, these models are then aggregated into a global model by using a novel knowledge-distillation method. This FFD method allows each local model to be efficiently updated by learning the features of the other models. Furthermore, this method can be easily deployed in new and large-scaled environments without requiring the models to be re-trained from scratch. Finally, we conduct extensive simulations to evaluate the performance of the proposed FFD method. The results show that our solution outperforms many contemporary FL techniques with non-IID (i.e., not independent and identically distributed) and imbalanced data.","2162-1039","978-1-6654-5188-8","10.1109/ATC55345.2022.9943034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9943034","Data Imbalance;Federated Learning;Knowledge Distillation;Internet of Things;Transfer Learning","Training;Federated learning;Wireless networks;Neural networks;Distributed databases;Heterogeneous networks;Data models","","","","24","IEEE","15 Nov 2022","","","IEEE","IEEE Conferences"
"Old Habits Die Hard: A Sober Look at TLS Client Certificates in the Real World","W. Xia; W. Wang; X. He; G. Xiong; G. Gou; Z. Li; Z. Li","Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; National Computer Network Emergency Response Technical Team, Coordination Center of China, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China","2021 IEEE 20th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)","9 Mar 2022","2021","","","83","90","Certificates play a key role in TLS, which is by far the most widely used security protocol for protecting network traffic. Studies have shown that inappropriate usage of certificates may incur security and privacy risks, most of which are focused on the server-side certificates. However, with the rapid development of the Internet of Things that interconnects countless nodes over the world, as well as the Zero Trust philosophy that stresses authentication of every entity, the adoption of client certificates could be a lot more vital. According to our observation, many practical problems and security risks still exist in the deployment and use of client certificates. In this paper, we present a passive measurement of over 24 million client certificates, collected by a framework deployed on the CSTNET, one of the major academic backbone networks in China. By performing a comprehensive analysis of the large scale real-world data, we give a big picture of the client certificates usage in current network, and disclose implementation flaws of these certificates which may possibly harm transport layer security and user privacy. As many as 342,699 defective client certificates are unearthed, which is an important reminder that never should we neglect the correct use of certificates on the client side.","2324-9013","978-1-6654-1658-0","10.1109/TrustCom53373.2021.00029","National Key Research and Development Program of China(grant numbers:2018YFB1800200,2020YFB1006100,2020YFE0200500); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9724395","Client certificate;Connection attribute analysis;Validity Period;Security issues","Privacy;Data privacy;Protocols;Philosophical considerations;Current measurement;Conferences;Telecommunication traffic","","","","22","IEEE","9 Mar 2022","","","IEEE","IEEE Conferences"
"SSH brute force attack mitigation in Internet of Things (IoT) network : An edge device security measure","M. M. Raikar; S. M. Meena","School of Computer Science and Engineering, K L E Technological University, Hubli, India; School of Computer Science and Engineering, K L E Technological University, Hubli, India","2021 2nd International Conference on Secure Cyber Computing and Communications (ICSCCC)","13 Jul 2021","2021","","","72","77","With the explosive growth of IoT applications, billions of things are now connected via edge devices and a colossal volume of data is sent over the internet. Providing security to the user data becomes crucial. The rise in zero-day attacks are a challenge in IoT scenarios. With the large scale of IoT application detection and mitigation of such attacks by the network administrators is cumbersome. The edge device Raspberry pi is remotely logged using Secure Shell (SSH) protocol in 90% of the IoT applications. The case study of SSH brute force attack on the edge device Raspberry pi is demonstrated with experimentation in the IoT networking scenario using Intrusion Detection System (IDS). The IP crawlers available on the internet are used by the attacker to obtain the IP address of the edge device. The proposed system continuously monitors traffic, analysis the log of attack patterns, detects and mitigates SSH brute attack. An attack hijacks and wastes the system resources depriving the authorized users of the resources. With the proposed IDS, we observe 25% CPU conservation, 40% power conservation and 10% memory conservation in resource utilization, as the IDS, mitigates the attack and releases the resources blocked by the attacker.","","978-1-6654-4415-6","10.1109/ICSCCC51823.2021.9478131","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9478131","Raspberry Pi;Intrusion Detection System (IDS);username;password;authentication","Protocols;Force measurement;Image edge detection;Force;Intrusion detection;Internet of Things;Security","","8","","19","IEEE","13 Jul 2021","","","IEEE","IEEE Conferences"
"Design and Development of an Efficient IoT-based Egg Incubation System","K. I. Masud; P. Bhottacharjee; A. Saeid; M. G. Mostofa; M. O. Rahman","Department of CSE, Dhaka University of Engineering & Technology, Gazipur, Gazipur, Bangladesh; Department of CSE, Dhaka University of Engineering & Technology, Gazipur, Gazipur, Bangladesh; Department of CSE, Dhaka University of Engineering & Technology, Gazipur, Gazipur, Bangladesh; Department of CSE, School of Science and Technology Bangladesh Open University, Gazipur, Bangladesh; Department of CSE, Dhaka University of Engineering & Technology, Gazipur, Gazipur, Bangladesh","2023 International Conference on Next-Generation Computing, IoT and Machine Learning (NCIM)","21 Aug 2023","2023","","","1","6","Large-scale production for the successful hatching of eggs is one of the major issues for poultry-industry farmers. Eggs are incubated naturally by hens, but such a natural procedure is not sufficient to produce chicks as per increasing protein (i.e., meat) demands. Therefore, to meet the increasing demand of poultry food protein, an efficient IoT-based egg incubation system is proposed in this paper, which can be a promising solution. It is worth mentioning that few incubation factors (i.e., egg weight loss/gain) dependent mainly on environmental humidity and temperature those need to be monitored constantly and remotely (i.e., by android application, SMS alerting via GSM module, and real-time incubation snaps by the camera) by IoT-based solution to resolve the weight loss effect during incubation period. Moreover, to achieve a successful hatching rate in such IoT-based egg incubation-system ventilation, egg turning, and candling of eggs should be handled carefully as well. This research has focused on the mentioned issues and proposed a new approach for the design and implementation of an IoT-based efficient egg incubator. Furthermore, through experiments, a good amount of statistical data have been generated which has created a scope to apply machine learning-based algorithms for further optimization.","","979-8-3503-1600-1","10.1109/NCIM59001.2023.10212960","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10212960","Internet of Things;Egg Incubation;Weight Loss Effect;Machine Learning","Proteins;Temperature sensors;Temperature measurement;Temperature dependence;Machine learning algorithms;Humidity;Ventilation","","","","15","IEEE","21 Aug 2023","","","IEEE","IEEE Conferences"
"Decentralized Optimal Multi-agent System Tracking Control Using Mean Field Games with Heterogeneous Agent","Z. Zhou; H. Xu","Department of Electrical and Biomedical Engineering, University of Nevada, Reno, NV, USA; Department of Electrical and Biomedical Engineering, University of Nevada, Reno, NV, USA","2021 IEEE Conference on Control Technology and Applications (CCTA)","3 Jan 2022","2021","","","97","102","In this paper, a decentralized optimal tracking control problem has been studied for a large-scale multi-agent system (MAS) with heterogeneous system dynamics. Due to the agent number of large-scale MAS, the notorious “curse of dimensionality” problem has challenged the traditional MAS algorithms for decades. The emerging mean field game (MFG) theory has recently been widely adopted to generate a decentralized control method that tackles those challenges by encoding the large-scale multi-agent systems’ information into a Probability Distribution Function (PDF). However, the traditional MFG methods assume all agents are homogeneous, which is unrealistic in practical industrial applications, e.g., IoTs, etc. Therefore, a novel mean field Stackelberg game (MFSG) is formulated based on the Stackelberg game, where all the agents have been classified as two different categories where one major leader’s decision dominates the other minor agents. Moreover, a hierarchical structure that treats all minor agents as a mean field group is developed to tackle homogeneous agents’ assumptions. Then, the actor-actor-critic-critic-mass $(A^{2}C^{2}M)$ algorithm with five neural networks is designed to learn the optimal policies by solving the MFSG. The Lyapunov theory is utilized to prove the convergence of $A^{2}C^{2}M$ neural networks and the closed-loop system’s stability. Finally, series of numerical simulations are conducted to demonstrate the effectiveness of the developed method.","2768-0770","978-1-6654-3643-4","10.1109/CCTA48906.2021.9659203","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9659203","","System dynamics;Neural networks;Games;Probability density function;Stability analysis;Probability distribution;Trajectory","","","","21","IEEE","3 Jan 2022","","","IEEE","IEEE Conferences"
"Intelligent Outlier Detection for Smart Farming Application using Deep Neural Network","N. Murali; A. S. Kumar; A. Karunamurthy; R. Suseendra; S. Manikandan","Department of Computer Science, E.G.S. Pillay Engineering College, Nagapattinam, Tamil Nadu, India; Department of Cloud Technology and Data Science, Institute of Engineering and Technology, Srinivas University Mukka, Surathkal, Mangalore, India; Department of Computer Science and Engineering, Chirst College of Engineering and Technology, Mulakulam, Pudhucherry, India; Department of Information Technology, Panimalar Engineering College, Chennai, Tamil Nadu, India; Department of Computer Science, E.G.S. Pillay Engineering College, Nagapattinam, Tamil Nadu, India","2022 IEEE 2nd International Conference on Mobile Networks and Wireless Communications (ICMNWC)","7 Feb 2023","2022","","","1","5","Agriculture is backbone of India. In the emerge of human civilization, agriculture has been an essential part of every human society due to the basic fact that the sustenance of any civilization directly depends on agriculture. Agriculture has the great impact on the economy of the country. This paper mainly concentrates on increasing crop production in large scale agricultural area. Due to changing climatic conditions, insufficient water level, insufficient or excessive use of fertilizers etc. the crop production may be affected. Astonishingly, agriculture has not been blessed with the latest advancements in the high-tech space unlike other areas like transport, education, finance, etc. Advancement in agriculture is necessary to balance the demands of people needs as the population grows day by day. The detection of outliers in large-scale area is most challenging tasks. Hence, we explore machine learning methodologies namely Deep Neural Network and Tucker Decomposition is used to detect those anomalies in large scale agriculture area to increase crop production. In this smart farming, the system automatically learns the soil features from IoT sensor data then provides anomaly detection accuracy which helps the farmer to understand the parameters affect the crop growth. This will enhance the crop productivity and economy of farmer. Our system automatically learns the data, analyzes the data and predicts the future.","","978-1-6654-9111-2","10.1109/ICMNWC56175.2022.10031638","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10031638","IoT;Big Sensor Data;Anomaly Detection;Machine Learning;Feature Selection","Support vector machines;Smart agriculture;Productivity;Neural networks;Crops;Soil;Feature extraction","","1","","12","IEEE","7 Feb 2023","","","IEEE","IEEE Conferences"
"Combining Device Behavioral Models and Building Schema for Cybersecurity of Large-Scale IoT Infrastructure","A. Hamza; H. Habibi Gharakheili; T. Pering; V. Sivaraman","School of Electrical Engineering and Telecommunications, University of New South Wales, Sydney, NSW, Australia; School of Electrical Engineering and Telecommunications, University of New South Wales, Sydney, NSW, Australia; Enterprise IoT, Google, Mountain View, CA, USA; School of Electrical Engineering and Telecommunications, University of New South Wales, Sydney, NSW, Australia","IEEE Internet of Things Journal","18 Nov 2022","2022","9","23","24174","24185","Modern buildings are increasingly getting connected by adopting a range of IoT devices and applications from video surveillance and lighting to people counting and access control. It has been shown that rich connectivity can make building networks more exposed to cyberattacks and, hence, difficult to manage. Currently, there is no systematic approach for evaluating or enforcing cybersecurity of building systems with a large number of heterogeneous IoT devices. In this article, we aim to enhance cybersecurity of a large-scale IoT infrastructure by formally capturing the expected behavior of the system using the static profile of devices’ intended usage, buildings information, and network configurations (predeployment) along with dynamic diagnosis (post-deployment) of network activity using machine-learning models. Our contributions are threefold: 1) we develop a tool that automatically generates a formal ontology of network communications for a connected infrastructure by taking a description of buildings (in the form of Brick schema), device network behavior (in the form of manufacturer usage description (MUD) specifications, MUD profile), and network configurations (address, port, and VLAN) as inputs. We contribute our tool as opensource, and apply it to a subset of our university smart campus testbed, covering 20 IoT devices of three types deployed in seven different buildings. We translate the formal model into network flow rules and enforce them to the network at runtime using programmable networking techniques; 2) we, then, measure the network activity of device-specific flow rules and diagnose their health using a set of trained anomaly detection models (one-class classifiers) each corresponding to a particular type of device and specific building location, and demonstrate how our method detects attacks with reasonable accuracy of 92.5%; and (3) finally, we demonstrate three types of location-defined network policies (deployment, administrative, and organizational) that can be verified by this formal model.","2327-4662","","10.1109/JIOT.2022.3189350","CyAmast Pty Ltd; Google Faculty Research Award Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9820757","Anomaly detection;behavioral modeling;building BRICK;IoT system ontology;manufacturer usage description (MUD) profile","Internet of Things;Buildings;Behavioral sciences;Multiuser detection;Security;Ontologies;Sensors","","2","","61","IEEE","8 Jul 2022","","","IEEE","IEEE Journals"
"Load-Altering Attacks Against Power Grids Under COVID-19 Low-Inertia Conditions","S. Lakshminarayana; J. Ospina; C. Konstantinou",Warwick; LANL; KAUST,"2023 IEEE Power & Energy Society General Meeting (PESGM)","25 Sep 2023","2023","","","1","1","The COVID-19 pandemic has impacted our society by forcing shutdowns and shifting the way people interacted worldwide. In relation to the impacts on the electric grid, it created a significant decrease in energy demands across the globe. Recent studies have shown that the low demand conditions caused by COVID-19 lockdowns combined with large renewable generation have resulted in extremely low-inertia grid conditions. In this work, we examine how an attacker could exploit these scenarios to cause unsafe grid operating conditions by executing load-altering attacks (LAAs) targeted at compromising hundreds of thousands of IoT-connected high-wattage loads in low-inertia power systems. Our study focuses on analyzing the impact of the COVID-19 mitigation measures on U.S. regional transmission operators (RTOs), formulating a plausible and realistic least-effort LAA targeted at transmission systems with low-inertia conditions, and evaluating the probability of these large-scale LAAs. Theoretical and simulation results are presented based on the WSCC 9-bus and IEEE 118-bus test systems. Results demonstrate how adversaries could provoke major frequency disturbances by targeting vulnerable load buses in low-inertia systems and offer insights into how the temporal fluctuations of renewable energy sources, considering generation scheduling, impact the grid’s vulnerability to LAAs.","1944-9933","978-1-6654-6441-3","10.1109/PESGM52003.2023.10252465","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10252465","","COVID-19;Renewable energy sources;Fluctuations;Pandemics;Simulation;Power grids","","","","0","IEEE","25 Sep 2023","","","IEEE","IEEE Conferences"
"IoT based Fire Detection and Warning System for Surveillance Applications using Deep Learning Model","S. E C; A. R; E. R","School of Computing, SASTRA Deemed University, Thanjavur, India; School of Computing, SASTRA Deemed University, Thanjavur, India; School of Computing, SASTRA Deemed University, Thanjavur, India","2023 2nd International Conference on Vision Towards Emerging Trends in Communication and Networking Technologies (ViTECoN)","26 Jun 2023","2023","","","1","5","Fire is a natural and destructive phenomenon that can cause significant damage to property and loss of life. Various devices, sensors, and methods have already been proposed and implemented to mitigate the effects of fire by detecting it in its early stages. Early detection helps to stop fire spread, saves lives, and mitigates the destruction of the infrastructure. Traditional sensors such as smoke, heat, flame, infrared, ultraviolet light radiation, and gas have been used for fire detection. These sensors are inefficient and suffer from low sensitivity, difficult deployment in large-scale applications, high false alarms, and detection delays. This paper proposes a Deep Learning model with an IoT system for monitoring, detecting, and Warning of fire in various places like forests, apartments, Industrial buildings, etc. A pre-trained Convolutional Neural Network namely MobileNet is used in Deep Learning as the base model. Transfer learning is used to develop a FireNet architecture for fire detection tasks. Deep Learning on IoT devices provides speed and accuracy in real-time detection.","","979-8-3503-4798-2","10.1109/ViTECoN58111.2023.10157176","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10157176","Internet of Things (IoT);Deep Learning (DL);Convolutional Neural Network (CNN);Active fire Location (AFL);Transfer Learning","Deep learning;Surveillance;Transfer learning;Neural networks;Cameras;Real-time systems;Delays","","","","15","IEEE","26 Jun 2023","","","IEEE","IEEE Conferences"
"Design of Microcontroller based Smart Car Parking System","M. Deepak; N. Kolur; G. S. Pavithra; U. Deeksha; M. B. Chethan","Dept. Of Electronics and Communication Engineering, Sai Vidya Institute of Technology, Bengaluru, Karnataka, India; Dept. Of Electronics and Communication Engineering, Sai Vidya Institute of Technology, Bengaluru, Karnataka, India; Dept. Of Electronics and Communication Engineering, Sai Vidya Institute of Technology, Bengaluru, Karnataka, India; Dept. Of Electronics and Communication Engineering, Sai Vidya Institute of Technology, Bengaluru, Karnataka, India; Dept. Of Electronics and Communication Engineering, Sai Vidya Institute of Technology, Bengaluru, Karnataka, India","2021 International Conference on Recent Trends on Electronics, Information, Communication & Technology (RTEICT)","29 Oct 2021","2021","","","206","210","With the increase in the population in metropolitan cities, vehicle density is also increasing. Due to this, vehicle parking has become a common issue in metro cities. This leads to wastage of time in search for parking. Moreover, large energy consumption, long processing time and also environmental pollution are highly concerned issues. Few introduced systems may lack the ability to detect the empty spots for parking. Many concepts and systems are introduced on IoT and cloud-based technology which is an expensive method for data transmission and are mostly dependable on factors such as climatic conditions and network availability. It requires high investment due to involvement of high-end technologies, which may not justify for small scale implementation. To overcome this issue a novel configuration is introduced which is cost effective, user friendly, less human dependent system which has access to real time data.","","978-1-6654-3559-8","10.1109/RTEICT52294.2021.9573861","Visvesvaraya Technological University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9573861","smart parking;metro cities;infrared sensors;AT mega","Pollution;Smart cities;Microcontrollers;Sociology;Real-time systems;Safety;Reliability","","","","21","IEEE","29 Oct 2021","","","IEEE","IEEE Conferences"
"Scalable IoT architecture for balancing performance and security in mobile crowdsensing systems","T. Nestoridis; C. Oikonomou; A. Temperekidis; F. Gioulekas; P. Katsaros","School of Informatics, Aristotle University of Thessaloniki, 54124 Thessaloniki, Greece; School of Informatics, Aristotle University of Thessaloniki, 54124 Thessaloniki, Greece; School of Informatics, Aristotle University of Thessaloniki, 54124 Thessaloniki, Greece; School of Informatics, Aristotle University of Thessaloniki, 54124 Thessaloniki, Greece; School of Informatics, Aristotle University of Thessaloniki, 54124 Thessaloniki, Greece","2020 7th International Conference on Internet of Things: Systems, Management and Security (IOTSMS)","2 Feb 2021","2020","","","1","8","Crowdsourcing aims to deliver services and content by aggregating contributions from a large user population. For mobile networks and IoT systems, crowdsourcing is used to gather and process sensor data from mobile devices (crowdsensing), in order to deliver real-time, context-aware services and possibly support user collaboration in extended geographic areas. In applications like geonsensitive navigation, location-based activity sharing and recommendations, the challenge of adequate service quality and user experience may be at stake, as the services are provided securely to an ever-growing user population. This happens due to the inherent trade-off between security and real-time performance that ultimately sets in doubt any scalability prospect beyond a certain user-interaction load. This work introduces a publish-subscribe architecture for mobile crowdsensing systems, which can be transparently scaled up to higher usage load, while retaining adequate performance and security by load balancing into multiple MQTT brokers. The security support combines a lightweight TLS implementation with an integrated mechanism for two-level access control: user-device interactions and message topics. We provide proof-of-concept measurements that show how our solution scales to increasing interaction loads through load-balancing the processing cost that includes the overhead of the security mechanisms applied. The system architecture was implemented in a vehicular crowdsensing navigation network that allows to exchange navigation information at real-time, for improved routing of vehicles to their destination.","","978-0-7381-2460-5","10.1109/IOTSMS52051.2020.9340165","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9340165","Internet of Things;crowdsourcing;mobile network;security;load-balancing","Performance evaluation;Crowdsensing;Navigation;Systems architecture;Publish-subscribe;Real-time systems;Statistics","","1","","32","IEEE","2 Feb 2021","","","IEEE","IEEE Conferences"
"Contract-Based Incentive Mechanisms for Honeypot Defense in Advanced Metering Infrastructure","W. Tian; M. Du; X. Ji; G. Liu; Y. Dai; Z. Han","School of Automation, Nanjing University of Science and Technology, Nanjing, China; Key Laboratory of Broadband Wireless Communication and Sensor Network Technology, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Electronic and Information Engineering, Nanjing University of Information Science and Technology, Nanjing, China; School of Electronic and Information Engineering, Nanjing University of Information Science and Technology, Nanjing, China; School of Electronic and Information Engineering, Nanjing University of Information Science and Technology, Nanjing, China; Department of Electrical and Computer Engineering, University of Houston, Houston, TX, USA","IEEE Transactions on Smart Grid","20 Aug 2021","2021","12","5","4259","4268","Honeypot defense deployment is considered as a promising technology to protect the industrial Internet of Things (IIoT), especially Advanced Metering Infrastructure (AMI), threatened by cyber-attacks. AMI defensive effectiveness depends on the honeypot deployment of the small-scale electricity suppliers (SESs) in sharing defense data. However, since the honeypot system is an additional defensive tool deployed by SESs, traditional power retailers (TPRs) cannot confirm in advance that the defense data shared by SES is valid. Therefore, it is necessary to design an incentive mechanism based on the information asymmetry to encourage SES to share defense data honestly. In this paper, we propose a honeypot deployment contract-theoretic model (HDCM) to improve the defensive effectiveness of AMI, where SES will honestly share defense data and the defense cost of TPR will be reduced. We first divide the SESs' contribution into finite types, and model the defense data sharing contract between the TPR and SESs. Then, the contract feasibility of HDCM is derived in necessary and sufficient conditions. At last, we analyze the optimal contract offered by TPR in the continuous case of SESs. Numerical simulations show that the HDCM can incentivize SESs to deploy honeypot and honestly share defense data, and make defensive effectiveness of AMI close to the information symmetry case.","1949-3061","","10.1109/TSG.2021.3071513","NSF(grant numbers:EARS-1839818,CNS1717454,CNS-1731424,CNS-1702850); National Natural Science Foundation of China(grant numbers:U1836104,61602247,61702235,U1636117); Natural Science Foundation of Jiangsu Province(grant numbers:BK20160840); Fundamental Research Funds for the Central Universities(grant numbers:30918012204); Talent Start-Up Fund of Nanjing University of Information Science and Technology(grant numbers:1521082101007); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9397770","Honeypot;contract theory;information asymmetry;industrial Internet of Things;advanced metering infrastructure%","Contracts;Security;Industrial Internet of Things;Smart grids;Tools;Game theory;Databases","","5","","25","IEEE","7 Apr 2021","","","IEEE","IEEE Journals"
"P2P Power Trading between Nanogrid Clusters Exploiting Electric Vehicles and Renewable Energy Sources","S. Lee; H. Jin; S. H. Nengroo; D. Har","Environment ICT Research Section Electronics and Telecommunications Research Institute (ETRI), South Korea, Daejeon; The Cho Chun Shik Graduate School of Green Transportation Korea Advanced Institute of Science and Technology (KAIST), South Korea, Daejeon; The Cho Chun Shik Graduate School of Green Transportation Korea Advanced Institute of Science and Technology (KAIST), South Korea, Daejeon; The Cho Chun Shik Graduate School of Green Transportation Korea Advanced Institute of Science and Technology (KAIST), South Korea, Daejeon","2021 International Conference on Computational Science and Computational Intelligence (CSCI)","22 Jun 2022","2021","","","1849","1855","P2P power trading addresses direct energy exchange between peers, thereby energy from small-scale distributed energy resources in households, workplaces, factories, and other locations is exchanged among neighborhood energy prosumers and consumers. A novel method for real-time P2P power trading between nanogrid clusters based on cooperative game theory is proposed in this paper. Cooperative P2P power trading is used as a powerful aid for a nanogrid cluster's power management involving electric vehicles and renewable energy sources (wind turbine and photovoltaic energy system). For the nanogrid clusters' power management, multi-objective optimization making use of relevant information obtained from the Internet of Things and from the time-varying production of hybrid wind power and PV power is carried out. As a result, cooperative P2P power trading between nanogrid clusters can save the electricity cost and amount of energy supplied from the grid, as compared to the stand-alone nanogrid clusters without P2P power trading.","","978-1-6654-5841-2","10.1109/CSCI54926.2021.00349","Korea Institute of Energy Technology Evaluation and Planning; Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9799005","P2P power trading;power management;nanogrid cluster;renewable energy source;distributed energy resource","Renewable energy sources;Power system management;Wind power generation;Power markets;Real-time systems;Hybrid power systems;Peer-to-peer computing","","3","","34","IEEE","22 Jun 2022","","","IEEE","IEEE Conferences"
"An Intelligent Method for Upper Limb Posture Recognition Based on Limited MEMS Data","Z. Wu; X. Wu; Q. Liu; X. Liu","Ministry of Education, Engineering Research Center of Digital Forensics, Nanjing University of Information Science & Technology, Nanjing, China; Ministry of Education, Engineering Research Center of Digital Forensics, Nanjing University of Information Science & Technology, Nanjing, China; School of Computer and Software, Nanjing University of Information Science & Technology, Nanjing, China; School of Computing, Edinburgh Napier University, Edinburgh, UK","2021 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech)","15 Mar 2022","2021","","","454","459","There are more than 10 million new stroke cases worldwide every year, and stroke has become one of the main causes of death and disability. In recent years, with the rapid development of computer science and technology, through the combination of Internet of things, deep learning, big data and other emerging technologies with traditional medicine, a new field of intelligent medicine has been developed. The scene of this paper is for stroke patients to use functional electrical stimulation equipment for rehabilitation training. By preprocessing the collected training data of MEMS patients, combined with the fully connected neural network (FCNN) model, the patient's upper limb posture can be intelligently recognized, which can make the intervention control of the rehabilitation system more efficient and intelligent. However, due to the damage of the stroke patients' action function, the existing sample data scale is small. In order to solve the problem of over fitting of network model caused by limited sample data in intelligent posture recognition, This paper proposes to expand the sample through data windowing operation to obtain a better performance recognition model.","","978-1-6654-2174-4","10.1109/DASC-PICom-CBDCom-CyberSciTech52372.2021.00082","National Natural Science Foundation of China(grant numbers:41911530242,41975142); Natural Science Foundation of Jiangsu Province(grant numbers:BK20191398,BK20180794); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9730427","Stroke;posture recognition;FCNN;upper limb;MEMS","Micromechanical devices;Training;Neural networks;Fitting;Training data;Stroke (medical condition);Big Data","","","","20","IEEE","15 Mar 2022","","","IEEE","IEEE Conferences"
"Personalized Federated Learning System Based on Permissioned Blockchain","B. Yuan; W. Qiu","School of Computer Science and Engineering, State Key Laboratory of Software Development Environment, Beihang University, Beijing, China; State Key Laboratory of Software Development Environment, Beihang University, Beijing, China","2021 International Conference on Intelligent Computing, Automation and Systems (ICICAS)","7 Mar 2022","2021","","","95","100","Federated learning ensures the privacy of data generated by large-scale IoT devices. Existing federated learning frameworks, based on centralized model coordinators, still face serious security challenges such as single point of failure and lack of privacy. In this paper, we propose a personalized federated learning system based on permissioned blockchain, which is divided into four layers of architecture are IoT device layer, network layer, edge computing layer, blockchain layer, and application layer, using permissioned blockchain as a federated learning server. And a permission blockchain-based personalized federation learning algorithm is proposed, which can achieve privacy protection and resistance to poisoning attacks with high accuracy. The experimental results revealed that the system has high privacy protection and anti-poisoning attack capability and can be deployed in edge computing situations.","","978-1-6654-2810-1","10.1109/ICICAS53977.2021.00026","Technology Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9723722","Individual Federated Learning;IoT;Federal learning;Blockchain;Privacy","Resistance;Privacy;Data privacy;Computer architecture;Collaborative work;Blockchains;Servers","","","","24","IEEE","7 Mar 2022","","","IEEE","IEEE Conferences"
"An Edge Computing Paradigm for Time-Sensitive Applications","A. Jain; D. S. Jat","Computer Science, Namibia University of Science and Technology, Windhoek, Namibia; Computer Science, Namibia University of Science and Technology, Windhoek, Namibia","2020 Fourth World Conference on Smart Trends in Systems, Security and Sustainability (WorldS4)","1 Oct 2020","2020","","","798","803","Edge computing (EC) is a new developing computing technology where data are collected, and analysed nearer to the edge or sources of the data. Cloud to the edge, intelligent applications and analytics are part of the IoT applications and technology. Edge computing technology aims to bring cloud computing features near to edge devices. For time-sensitive applications in cloud computing, architecture massive volume of data is generated at the edge and stored and analysed in the cloud. Cloud infrastructure is a composition of data centres and large-scale networks, which provides reliable services to users. Traditional cloud computing is inefficient due to delay in response, network delay and congestion as simultaneous transactions to the cloud, which is a centralised system. This paper presents a literature review on cloud-based edge computing technologies for delay-sensitive applications and suggests a conceptual model of edge computing architecture. Further, the paper also presents the implementation of QoS support edge computing paradigm in Python for further research to improve the latency and throughput for time-sensitive applications.","","978-1-7281-6823-4","10.1109/WorldS450073.2020.9210325","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9210325","Cloud Computing;Fog Computing;Edge Computing;IOT;QoS","Edge computing;Cloud computing;Computational modeling;Delays;Computer architecture;Quality of service;Sensors","","5","","22","IEEE","1 Oct 2020","","","IEEE","IEEE Conferences"
"Optimizing PhiNet architectures for the detection of urban sounds on low-end devices","A. Brutti; F. Paissan; A. Ancilotto; E. Farella","Digis Center, Fondazione Bruno Kessler, Trento, Italy; Digis Center, Fondazione Bruno Kessler, Trento, Italy; Digis Center, Fondazione Bruno Kessler, Trento, Italy; Digis Center, Fondazione Bruno Kessler, Trento, Italy","2022 30th European Signal Processing Conference (EUSIPCO)","18 Oct 2022","2022","","","1121","1125","Sound Event Detection (SED) pipelines identify and classify relevant events in audio streams. With typical applications in the smart city domain (e.g., crowd counting, alarm triggering), SED is an asset for municipalities and law enforcement agencies. Given the large size of the areas to be monitored and the amount of data generated by the IoT sensors, large models running on centralised servers are not suitable for real-time applications. Conversely, performing SED directly on pervasive embedded devices is very attractive in terms of energy consumption, bandwidth requirements and privacy preservation. In a previous manuscript, we proposed scalable backbones from the PhiNets architectures' family for real-time sound event detection on microcontrollers. In this paper, we extend our analysis investigating how PhiNets' scaling parameters affect the model performance in the SED task while searching for the best configuration given the computational constraints. Experimental analysis on UrbanSound8K shows that while only the total number of parameters matters when training the model from scratch (i.e., it is independent of the scaling parameter configuration), knowledge distillation is more effective with specific scaling configurations.","2076-1465","978-90-827970-9-1","10.23919/EUSIPCO55093.2022.9909572","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9909572","Sound event detection;Neural Networks;PhiNets;tinyML","Performance evaluation;Training;Analytical models;Event detection;Smart cities;Computational modeling;Computer architecture","","3","","24","","18 Oct 2022","","","IEEE","IEEE Conferences"
"ManuChain: Combining Permissioned Blockchain With a Holistic Optimization Model as Bi-Level Intelligence for Smart Manufacturing","J. Leng; D. Yan; Q. Liu; K. Xu; J. L. Zhao; R. Shi; L. Wei; D. Zhang; X. Chen","Guangdong Provincial Key Laboratory of Computer Integrated Manufacturing System, State Key Laboratory of Precision Electronic Manufacturing Technology and Equipment, Guangdong University of Technology, Guangzhou; Guangdong Provincial Key Laboratory of Computer Integrated Manufacturing System, State Key Laboratory of Precision Electronic Manufacturing Technology and Equipment, Guangdong University of Technology, Guangzhou; Guangdong Provincial Key Laboratory of Computer Integrated Manufacturing System, State Key Laboratory of Precision Electronic Manufacturing Technology and Equipment, Guangdong University of Technology, Guangzhou; School of Biomedical and Pharmaceutical Sciences, Guangdong University of Technology, Guangzhou, China; Department of Information Systems, City University of Hong Kong, Hong Kong; Department of Information Systems, City University of Hong Kong, Hong Kong; Guangdong Provincial Key Laboratory of Computer Integrated Manufacturing System, State Key Laboratory of Precision Electronic Manufacturing Technology and Equipment, Guangdong University of Technology, Guangzhou; Guangdong Provincial Key Laboratory of Computer Integrated Manufacturing System, State Key Laboratory of Precision Electronic Manufacturing Technology and Equipment, Guangdong University of Technology, Guangzhou; Guangdong Provincial Key Laboratory of Computer Integrated Manufacturing System, State Key Laboratory of Precision Electronic Manufacturing Technology and Equipment, Guangdong University of Technology, Guangzhou","IEEE Transactions on Systems, Man, and Cybernetics: Systems","30 Dec 2019","2020","50","1","182","192","The growth of individualized product demands drives high flexibility of manufacturing processes, which requires large-scale deployment of Industrial Internet of Things (IIoT). Since centralized control of IIoT suffers from poor flexibility in coping with disturbances and changes, a decentralized organization structure is a better choice, in which a permissioned blockchain-driven IIoT can enable partially decentralized self-organization and thus offload and accelerate the optimization of upper-level manufacturing planning. A novel iterative bi-level hybrid intelligence model named ManuChain is proposed to get rid of unbalance/inconsistency between holistic planning and local execution in individualized manufacturing systems. Lower-level blockchain-driven smart contracts proactively decentralize fine-grained and individualized task execution among machine tools via Raspberry Pi-based smart gateways and make the results available on an upper-level digital twin model for iterative coarse-grained holistic optimization. A prototype ManuChain based on a permissioned blockchain network is presented to realize both lower-level crowd self-organizing intelligence and upper-level holistic optimization intelligence.","2168-2232","","10.1109/TSMC.2019.2930418","National Natural Science Foundation of China(grant numbers:51705091,51675108); Shenzhen Science and Technology Innovation Committee(grant numbers:JCY20170818100156260); Science and Technology Planning Project of Guangdong Province of China(grant numbers:2019A050503010,2019B090916002,2016A010106006); Science and Technology Plan Project of Guangzhou(grant numbers:201804020092); Hong Kong Scholars Program(grant numbers:XJ201817); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8789508","Blockchain;digital twin;individualized manufacturing;Industrial Internet of Things (IIoT);smart contracts","Blockchain;Manufacturing;Smart contracts;Logic gates;Cloud computing;Optimization;Organizations","","167","","64","IEEE","6 Aug 2019","","","IEEE","IEEE Journals"
"A Smart Collaborative Routing Protocol for Delay Sensitive Applications in Industrial IoT","M. Zhu; L. Chang; N. Wang; I. You","School of Electronic and Information Engineering, Beijing Jiaotong University, Beijing, China; Network Technology Research Institute, China Unicom, Beijing, China; Dawning Information Industry (Beijing) Company, Ltd., Beijing, China; Department of Information Security Engineering, Soonchunhyang University, Asan, South Korea","IEEE Access","3 Feb 2020","2020","8","","20413","20427","In the industrial Internet of things (IIoT), there is always a strong demand for real-time information transfer. Especially when deploying wireless/wired hybrid networks in smart factories, the requirement for low delay interaction is more prominent. Although tree routing protocols have been successfully executed in simple networks, more challenges in transmission speed can be observed in the manufacturing broadband communication system. Motivated by the progresses in deep learning, a smart collaborative routing protocol with low delay and high reliability is proposed to accommodate mixed link scenarios. First, we establish a one-hop delay model to investigate the potential affects of Media Access Control (MAC) layer parameters, which supports the subsequent design. Second, forwarding, maintenance, and efficiency strategies are created to construct the basic functionalities for our routing protocol. Relevant procedures and key approaches are highlighted as well. Third, two sub-protocols are generated and the corresponding implementation steps are described. The experimental results demonstrate that the end-to-end delay can be effectively cut down through comprehensive improvements. Even more sensor nodes and larger network scale are involved, our proposed protocol can still illustrate the advantages comparing with existing solutions within IIoT.","2169-3536","","10.1109/ACCESS.2019.2963723","National Natural Science Foundation of China(grant numbers:61872033); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8949516","Industrial IoT;deep learning;routing protocol;tree topology;delay","Routing protocols;Delays;Wireless communication;Wireless sensor networks;Ad hoc networks","","20","","28","CCBY","3 Jan 2020","","","IEEE","IEEE Journals"
"A Novel Spatial–Temporal Specification-Based Monitoring System for Smart Cities","M. Ma; E. Bartocci; E. Lifland; J. A. Stankovic; L. Feng","Department of Computer Science, University of Virginia, Charlottesville, VA, USA; Faculty of Informatics, TU Wien, Vienna, Austria; Department of Computer Science, University of Virginia, Charlottesville, VA, USA; Department of Computer Science, University of Virginia, Charlottesville, VA, USA; Department of Computer Science, University of Virginia, Charlottesville, VA, USA","IEEE Internet of Things Journal","26 Jul 2021","2021","8","15","11793","11806","With the development of the Internet of Things, millions of sensors are being deployed in cities to collect real-time data. This leads to a need for checking city states against city requirements at runtime. In this article, we develop a novel spatial-temporal specification-based monitoring system for smart cities. We first describe a study of over 1000 smart city requirements, some of which cannot be specified using the existing logic, such as the signal temporal logic (STL) and its variants. To tackle this limitation, we develop spatial aggregation STL (SaSTL)-a novel spatial aggregation STL-for the efficient runtime monitoring of safety and performance requirements in smart cities. We develop two new logical operators in SaSTL to augment STL for expressing spatial aggregation and spatial counting characteristics that are commonly found in real city requirements. We define the Boolean and quantitative semantics for SaSTL in support of the analysis of city performance across different periods and locations. We also develop efficient monitoring algorithms that can check the SaSTL requirement in parallel over multiple data streams (e.g., generated by multiple sensors distributed spatially in a city). Additionally, we build an SaSTL-based monitoring tool to support decision making of different stakeholders to specify and runtime monitor their requirements in smart cities. We evaluate our SaSTL monitor by applying it to three case studies with large-scale real city sensing data (e.g., up to 10 000 sensors in one study). The results show that SaSTL has a much higher coverage expressiveness than other spatial-temporal logics, and with a significant reduction of computation time for monitoring requirements. We also demonstrate that the SaSTL monitor improves the safety and performance of smart cities via simulated experiments.","2327-4662","","10.1109/JIOT.2021.3069943","National Science Foundation(grant numbers:CCF-1942836,CNS-1952096); Austrian FFG-Funded IoT4CPS Project at TU Wien; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9391992","Runtime verification;signal temporal logic (STL);smart cities","Monitoring;Smart cities;Safety;Runtime;Intelligent sensors;Tools;Internet of Things","","19","","45","IEEE","31 Mar 2021","","","IEEE","IEEE Journals"
"Visualizing Potential Transportation Demand From ETC Log Analysis Using ELK Stack","C. -K. Tsung; C. -T. Yang; S. -W. Yang","Department of Computer Science and Information Engineering, National Chin-Yi University of Technology, Taichung, Taiwan; Department of Computer Science, Tunghai University, Taichung, Taiwan; Department of Computer Science, Tunghai University, Taichung, Taiwan","IEEE Internet of Things Journal","10 Jul 2020","2020","7","7","6623","6633","Traffic conditions are among the issues most concerned with the general public, and the freeway is a large-scale Internet-of-Things application. In addition to obtaining real-time road usage information, analysis of local road usage habits is crucial in evaluations of government policy implementation. Using road usage data provided by the electronic toll collection (ETC) system, we investigated the data on road usage history on the freeways. The ELK stack was employed to construct a platform for visualizing real-time road usage information and history in this article; the platform is named the local transportation knowledge (LTK) platform. By analyzing more than 500 million pieces of data, the LTK platform proposed in this article efficiently visualized road usage data and facilitated the acquirement of local road usage knowledge. We verified that residents of other counties and cities commuted to Taichung each day. We also discovered that a considerable number of Taichung city residents were employed in Hsinchu Science Park and commuted between the two places. The LTK platform can present real-time freeway traffic conditions, facilitate in-depth analysis of local road usage data, and provide data to verify the relevant information.","2327-4662","","10.1109/JIOT.2020.2974671","Ministry of Science and Technology (MOST), Taiwan(grant numbers:MOST 108-2745-8-029-007,MOST 108-2622-E-029-007-CC3,MOST 108-2221-E-029-010,MOST 108-2221-E-167-022); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9001068","Big data;data visualization;ELK stack;traffic data analysis","Roads;Traffic control;Data visualization;Big Data;Real-time systems;Automobiles","","15","","32","IEEE","18 Feb 2020","","","IEEE","IEEE Journals"
"On Resource Allocation of Cooperative Multiple Access Strategy in Energy-Efficient Industrial Internet of Things","N. Li; M. Xiao; L. K. Rasmussen; X. Hu; V. C. M. Leung","Shenzhen Institutes of Advanced Technology, Chinese Academy of Science, Shenzhen, China; School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden; School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden; Shenzhen Institutes of Advanced Technology, Chinese Academy of Science, Shenzhen, China; Department of Electrical and Computer Engineering, The University of British Columbia, Vancouver, BC, Canada","IEEE Transactions on Industrial Informatics","19 Nov 2020","2021","17","2","1069","1078","In this article, we investigate the jointly optimized resource allocation with hybrid multiple access in energy-efficient industrial Internet of Things (IIoT), where some devices (e.g., those for critical control devices) have higher transmission priority and stable energy supply while some devices (e.g., those for comprehensive sensors) may not. We consider a system model supporting wireless powered IIoT devices, with certain user terminal as a potential relay for the transmission between a hybrid access point and another user terminal. Constrained by the limited energy storage, the user needs to harvest energy before relaying and only the harvested energy is utilized for the following transmission. We propose a collaborative orthogonal and nonorthogonal multiple access protocol where two cooperation schemes with and without decoding the relay message are applied. Jointly considering time sharing in the transmission process, power splitting for simultaneous wireless information and power transfer, and transmit power allocation at the cooperative user, the achievable rate regions under the Rayleigh fading channel model are derived. Based on which, an optimization problem on resource allocation strategies is formulated and discussed. Both analytical and numerical results are provided, illustrating the impact of user geometry on the achievable rates as well as the optimal resource allocation with different cooperative strategies applied in different use cases. Aiming to enhance resource utilization, energy-efficient cooperation enables the combination of various transmission modes and networking classes in large scale networks, as well as a better use of ambient radio frequency signals for wireless powered transmissions.","1941-0050","","10.1109/TII.2020.2988643","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9072642","Energy-efficient cooperation;nonorthogonal multiple access (NOMA);optimal resource allocation;simultaneous wireless information and power transfer (SWIPT)","Resource management;Relays;NOMA;Wireless communication;Wireless sensor networks;Energy harvesting;Protocols","","14","","28","IEEE","20 Apr 2020","","","IEEE","IEEE Journals"
"Over-the-Air Computation With Spatial-and-Temporal Correlated Signals","W. Liu; X. Zang; B. Vucetic; Y. Li","School of Electrical and Information Engineering, The University of Sydney, Sydney, NSW, Australia; School of Electrical and Information Engineering, The University of Sydney, Sydney, NSW, Australia; School of Electrical and Information Engineering, The University of Sydney, Sydney, NSW, Australia; School of Electrical and Information Engineering, The University of Sydney, Sydney, NSW, Australia","IEEE Wireless Communications Letters","8 Jul 2021","2021","10","7","1591","1595","Over-the-air computation (AirComp) leveraging the superposition property of wireless multiple-access channel (MAC), is a promising technique for effective data collection and computation of large-scale wireless sensor measurements in Internet of Things applications. Most existing work on AirComp only considered computation of spatial-and-temporal independent sensor signals, though in practice different sensor measurement signals are usually correlated. In this letter, we propose an AirComp system with spatial-and-temporal correlated sensor signals, and formulate the optimal AirComp policy design problem for achieving the minimum computation mean-squared error (MSE). We develop the optimal AirComp policy with the minimum computation MSE in each time step by utilizing the current and the previously received signals. We also propose and optimize a low-complexity AirComp policy in closed form with the performance approaching to the optimal policy.","2162-2345","","10.1109/LWC.2021.3075029","Australian Research Council’s Australian Laureate Fellowships Scheme(grant numbers:FL160100032); ARC(grant numbers:DP190101988,DP210103410); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9410563","Over-the-air computing;wireless sensor networks;multiple-access channel;spacial-and-temporal correlation","Receivers;Wireless sensor networks;Wireless communication;Covariance matrices;Current measurement;Correlation;Computational modeling","","13","","23","IEEE","22 Apr 2021","","","IEEE","IEEE Journals"
"Multimodal Alignment and Attention-Based Person Search via Natural Language Description","Z. Ji; S. Li","School of Electrical and Information Engineering, Tianjin University, Tianjin, China; School of Electrical and Information Engineering, Tianjin University, Tianjin, China","IEEE Internet of Things Journal","12 Nov 2020","2020","7","11","11147","11156","Visual Internet of Things (VIoT) has been widely deployed in the field of social security. However, how to enable it to be intelligent is an urgent yet challenging task. In this article, we address the task of searching persons with natural language description query in a public safety surveillance system, which is a practical and demanding technique in VIoT. It is a fine-grained many-to-many cross-modal problem and more challenging than those with the image and the attribute as queries. The existing attempts are still weak in bridging the semantic gap between visual modality from different camera sensors and text modality from natural language descriptions. We propose a deep person search approach with a natural language description query by employing the attention mechanism (AM) and multimodal alignment (MA) method to supervise the cross-modal mapping. Particularly, the AM consists of two self-attention modules and one cross-attention module, where the former aims at learning discriminative representations and the latter supervises each other with their own information to offer accurate guidance to a common space. The MA approach contains three alignment processes with a novel cross-ranking loss function to make different matching pairs separable in a common space. Extensive experiments on large-scale CUHK-PEDES demonstrate the superiority of the proposed approach.","2327-4662","","10.1109/JIOT.2020.2995148","Natural Science Foundation of Tianjin(grant numbers:19JCYBJC16000); National Natural Science Foundation of China(grant numbers:61771329); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9094645","Attention mechanism (AM);natural language description;person search;Visual Internet of Things (VIoT)","Task analysis;Natural languages;Visualization;Internet of Things;Cameras;Sensors;Surveillance","","9","","37","IEEE","18 May 2020","","","IEEE","IEEE Journals"
"Enabling Low Latency Edge Intelligence based on Multi-exit DNNs in the Wild","Z. Huang; F. Dong; D. Shen; J. Zhang; H. Wang; G. Cai; Q. He","School of Computer Science and Engineering, Southeast University, Nanjing, China; School of Computer Science and Engineering, Southeast University, Nanjing, China; School of Computer Science and Engineering, Southeast University, Nanjing, China; SING Lab, Hong Kong University of Science and Technology, Hong Kong, China; School of Computer Science and Engineering, Southeast University, Nanjing, China; School of Computer Science and Engineering, Southeast University, Nanjing, China; School of Software and Electrical Engineering, Swinburne University of Technology, Melbourne, Australia","2021 IEEE 41st International Conference on Distributed Computing Systems (ICDCS)","4 Oct 2021","2021","","","729","739","In recent years, deep neural networks (DNNs) have witnessed a booming of artificial intelligence Internet of Things applications with stringent demands across high accuracy and low latency. A widely adopted solution is to process such computation-intensive DNNs inference tasks with edge computing. Nevertheless, existing edge-based DNN processing methods still cannot achieve acceptable performance due to the intensive transmission data and unnecessary computation. To address the above limitations, we take the advantage of Multi-exit DNNs (ME-DNNs) that allows the tasks to exit early at different depths of the DNN during inference, based on the input complexity. However, naively deploying ME-DNNs in edge still fails to deliver fast and consistent inference in the wild environment. Specifically, 1) at the model-level, unsuitable exit settings will increase additional computational overhead and will lead to excessive queuing delay; 2) at the computation-level, it is hard to sustain high performance consistently in the dynamic edge computing environment. In this paper, we present a Low Latency Edge Intelligence Scheme based on Multi-Exit DNNs (LEIME) to tackle the aforementioned problem. At the model-level, we propose an exit setting algorithm to automatically build optimal ME-DNNs with lower time complexity; At the computation-level, we present a distributed offloading mechanism to fine-tune the task dispatching at runtime to sustain high performance in the dynamic environment, which has the property of close-to-optimal performance guarantee. Finally, we implement a prototype system and extensively evaluate it through testbed and large-scale simulation experiments. Experimental results demonstrate that LEIME significantly improves applications' performance, achieving 1.1–18.7 × speedup in different situations.","2575-8411","978-1-6654-4513-9","10.1109/ICDCS51616.2021.00075","National Key R&D Program of China(grant numbers:2018AAA0100500); National Natural Science Foundation of China(grant numbers:61872079,61902065,61632008,61702096,61702097,61972085,61906040); Natural Science Foundation of Jiangsu Province(grant numbers:BK20170689,BK20190345,BK20190335); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9546491","Edge intelligence;Multi-exit setting;Computation offloading;DNN inference","Runtime;Heuristic algorithms;Computational modeling;Prototypes;Dispatching;Task analysis;Low latency communication","","9","","25","IEEE","4 Oct 2021","","","IEEE","IEEE Conferences"
"A Dynamic Pyramid Tilling Method for Traffic Data Stream Based on Flink","L. Hu; F. Zhang; M. Qin; Z. Fu; Z. Chen; Z. Du; R. Liu","School of the Earth Sciences, Zhejiang University, Hangzhou, China; School of the Earth Sciences, Zhejiang University, Hangzhou, China; School of the Earth Sciences, Zhejiang University, Hangzhou, China; School of the Earth Sciences, Zhejiang University, Hangzhou, China; School of the Earth Sciences, Zhejiang University, Hangzhou, China; School of the Earth Sciences, Zhejiang University, Hangzhou, China; School of the Earth Sciences, Zhejiang University, Hangzhou, China","IEEE Transactions on Intelligent Transportation Systems","11 Jul 2022","2022","23","7","6679","6688","Traffic guidance, traffic management and emergency vehicle traffic all require keeping abreast of traffic status. Intelligent Transportation Systems (ITS) is highly expected to provide real-time traffic condition information service. To achieve this, the capability of handling dynamic data stream collected from multi traffic monitoring sources and serving the public with information timely is essential for ITS. With the wide spread of Internet of Things technology, not only the amount, but also the spatial and temporal resolutions of real-time traffic data have explosive growth, thereby enhancing the difficulty of real-time traffic data processing in ITS. Web pyramid map tiles is wide accepted for massive spatial data service, and the latency of tile generation significantly reduces the timeliness of information transmission and the reliability of services. A Flink-based method for dynamic pyramid tile generation and updating is proposed here. Take advantages of combining grid indexes, employing data partition and window selection mechanisms, and applying iterative computational characteristics for resampling, the distributed dynamic pyramid map tile generation algorithm (DPTG), can quickly visualize real-time spatial traffic data with digital map tiles. Taking the national highway road data from China as an example, the experimental results show that the Flink-based DPTG method has high efficiency and scalability in both batch processing and stream processing mode, which highlights the capability of the proposed method to support real-time traffic monitoring data processing for timely large-scale public service in ITS.","1558-0016","","10.1109/TITS.2021.3060576","National Key Research and Development Program of China(grant numbers:2018YFB0505000); National Natural Science Foundation of China(grant numbers:41671391,41922043,41871287); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9370008","Flink;ITS;pyramid tile;real-time traffic data","Real-time systems;Tiles;Monitoring;Data processing;Distributed databases;Spatial databases;Scalability","","6","","43","IEEE","4 Mar 2021","","","IEEE","IEEE Journals"
"PBidm: Privacy-Preserving Blockchain-Based Identity Management System for Industrial Internet of Things","Z. Bao; D. He; M. K. Khan; M. Luo; Q. Xie","Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, China; School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Center of Excellence in Information Assurance, King Saud University, Riyadh, Saudi Arabia; School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Key Laboratory of Cryptography of Zhejiang Province, Hangzhou Normal University, Hangzhou, China","IEEE Transactions on Industrial Informatics","15 Dec 2022","2023","19","2","1524","1534","Industrial Internet of Things (IIoT) is revolutionizing plenty of industrial applications by utilizing large-scale smart devices in manufacturing and industrial processes. However, IIoT is facing the disclosure of identity privacy. The identity information is precious and critical, thereby inspiring a line of follow-up privacy-preserving studies, i.e., anonymous credential protocols, or privacy-preserving identity management schemes. However, they are either too anonymous to be used in the IIoT environment, or the system is highly centralized, which implies the risk of a single point of failure. In this article, we propose PBidm, a privacy-preserving blockchain-based identity management scheme for IIoT. Specifically, by leveraging blockchain and diversified cryptographic tools, PBidm can fully support the desirable properties, i.e., unforgeability, blindness, unlikability, traceability, revocability, and public verifiability. Then, we provide security analysis to ensure reasonable security assurance. Finally, we present a performance evaluation of the proposed scheme to demonstrate the practicability in IIoT applications.","1941-0050","","10.1109/TII.2022.3206798","National Key Research and Development Program of China(grant numbers:2021YFA1000600); National Natural Science Foundation of China(grant numbers:62172307,U21A20466,61972294,61932016); Special Project on Science and Technology Program of Hubei Province(grant numbers:2020AEA013); Natural Science Foundation of Hubei Province(grant numbers:2020CFA052); Wuhan Municipal Science and Technology Project(grant numbers:2020010601012187); King Saud University(grant numbers:RSP-2022/12); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9893355","Anonymous credentials;blockchain;blockchain-based identity;industrial Internet of Things;PBidm","Industrial Internet of Things;Blockchains;Privacy;Cryptography;Protocols;Identity management systems;Encryption","","5","","25","IEEE","15 Sep 2022","","","IEEE","IEEE Journals"
"A Tag-Based PHY-Layer Authentication Scheme Without Key Distribution","Y. An; S. Zhang; Z. Ji","College of Information Engineering, North China University of Science and Technology, Tangshan, China; College of Information Engineering, North China University of Science and Technology, Tangshan, China; College of Information Engineering, North China University of Science and Technology, Tangshan, China","IEEE Access","18 Jun 2021","2021","9","","85947","85955","Authentication is the process of confirming the legal identity of communicating entities, and it is the first line of defense for security communication. Most of the existing tag-based physical layer security authentication (PLSA) requires distributing the shared keys in advance. In the large scale internet of things scenario, nodes frequently join and leave the wireless networks that cause the distribution and management of keys particularly difficult. This paper proposes a tag-based PLSA scheme, which utilizes channel characteristics instead of distributing keys to generate authentication tags. Specifically, based on watermarking mechanism, we design a fault-tolerant hash algorithm to couple the secret sequence and the message signal for authentication tags generation. The shared secret sequence is generated by legitimate nodes through channel probing. And the theories of information theory and composite hypothesis testing is employed to analyze the performance of system. The simulation results show that the agreement ratio of the generating shared secret sequence is as high as 96% in the case of high signal-to-noise ratio and low power tag embedding. In addition, performance analysis demonstrates the scheme can resist against multiple attacks, such as replay, jamming, tampering, and impersonation attack.","2169-3536","","10.1109/ACCESS.2021.3087508","Science and Technology Major Project of the Science and Technology Ministry of China(grant numbers:2017YFE0135700); High Level Talent Support Project of Hebei Province(grant numbers:A201903011); Natural Science Foundation of Hebei Province(grant numbers:F2018209358); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9448211","Authentication;wireless network;tag-based;hash algorithm;channel probing","Authentication;Watermarking;Security;Communication system security;Hash functions;Fault tolerant systems;Fault tolerance","","4","","35","CCBY","8 Jun 2021","","","IEEE","IEEE Journals"
"Haptic Signal Reconstruction in eHealth Internet of Things","A. Li; Y. Chen; S. Ni; J. Chen; L. Zhou","Key Laboratory of Broadband Wireless Communication and Sensor Network Technology (Ministry of Education), Nanjing University of Posts and Telecommunications, Nanjing, China; Key Laboratory of Broadband Wireless Communication and Sensor Network Technology (Ministry of Education), Nanjing University of Posts and Telecommunications, Nanjing, China; Key Laboratory of Broadband Wireless Communication and Sensor Network Technology (Ministry of Education), Nanjing University of Posts and Telecommunications, Nanjing, China; Key Laboratory of Broadband Wireless Communication and Sensor Network Technology (Ministry of Education), Nanjing University of Posts and Telecommunications, Nanjing, China; Key Laboratory of Broadband Wireless Communication and Sensor Network Technology (Ministry of Education), Nanjing University of Posts and Telecommunications, Nanjing, China","IEEE Internet of Things Journal","7 Sep 2022","2022","9","18","17047","17057","With the haptic technology continuously enlarging the eHealth Industry Internet of Things (IIoT) ecosystem, haptic perception service which requires effective haptic signal reconstruction for immersive experience has become an indispensable function. However, the majority of existing haptic signal reconstruction methods are generally inefficient because of undergoing extremely complex operations or inefficient feature representations. To resolve this dilemma, this article proposes a long short-term memory-based force reconstruction network (LSTM-FRN) by designing a novel sparse attention module for low-latency reconstruction and a novel metric learning-based constraint for high-precision reconstruction, yielding an excellent tradeoff between the computational complexity and feature representation. To train our network, we construct a large-scale data set of synchronous needle motion signals and haptic signals in acupuncture needle insertion. Finally, we build an interactive needle insertion training system (HapAR-NITS) by integrating augmented reality (AR), the LSTM-FRN-based haptic reconstruction as well as a skill assessment subsystem. Comprehensive experiments demonstrate that the proposed multiple technologies enable our HapAR-NITS to achieve satisfying immersive experience and manipulation effects.","2327-4662","","10.1109/JIOT.2021.3132771","Priority Academic Program Development of Jiangsu Higher Education Institutions; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9637497","eHealth Industry Internet of Things (IIoT);haptic signal reconstruction;long short-term memory unit (LSTM);needle insertion","Haptic interfaces;Needles;Training;Electronic healthcare;Industrial Internet of Things;Visualization;Force","","4","","41","IEEE","6 Dec 2021","","","IEEE","IEEE Journals"
"Mobile Measurement of Particulate Matter Concentrations on Urban Streets: System Development and Field Verification","Y. -L. Chiang; J. -C. Wang; C. -H. Sun; T. -H. Wen; J. -Y. Juang; J. -A. Jiang","Department of Biomechatronics Engineering, National Taiwan University, Taipei, Taiwan; Department of Biomechatronics Engineering, National Taiwan University, Taipei, Taiwan; Department of Geography, National Taiwan University, Taipei, Taiwan; Department of Geography, National Taiwan University, Taipei, Taiwan; Department of Geography, National Taiwan University, Taipei, Taiwan; Department of Biomechatronics Engineering, National Taiwan University, Taipei, Taiwan","IEEE Access","6 Nov 2020","2020","8","","197617","197629","Concentrations of various particulate matter (PM) in urban areas have attracted great attention, due to the increasing demand on life quality. Many studies have highlighted the spatial variability of PM2.5 in urban areas, and found that there are significant differences between residents' exposure and background levels. Different from the strategy of establishing large-scale Airbox stations or utilizing mobile stations with portable instruments to measure residents' exposures, this study develops an on-vehicle monitoring system (OVMS), which is based on the technology of Internet of Things, to increase the spatial resolution of the monitoring data in an economical way. The parameters measured by the OVMS include PM2.5, time, location, moving speed, ambient temperature, and relative humidity. According to the experimental results, the effects of the moving speed of the OVMS on PM2.5 measurements are negligible (r =0.024), when the moving speed is below 57 km/hr. The correlation between the dynamic measurements provided by the OVMS and a standard instrument is high (r =0.601). These results show that the OVMS can accurately monitor PM2.5 as it moves. The data of PM2.5 obtained by the OVMS also reveal the impacts of traffic and community pollution in urban areas on residents' exposure. In addition, this study proposes a visualized map that shows real-time PM2.5 measurements as the OVMS travels. Map users can choose a less-polluted path to get to their destinations based on the PM2.5 information. In addition, the OVMS measurements can be integrated with the Airbox measurements, so the visualized map can provide detailed spatial interpolation results on PM2.5 exposures. Thus, the OVMS can be a great help in evaluating the PM2.5 levels in certain areas of urban streets where Airbox stations are not installed.","2169-3536","","10.1109/ACCESS.2020.3034489","Ministry of Science and Technology and the Council of Agriculture of the Executive Yuan, Taiwan(grant numbers:MOST 105-2221-E-002-132-MY3,MOST 106-3113-E-002-012,MOST 107-3113-E-002-007,MOST 108-2321-B-002-037,MOST 108-2811-B-002-510,MOST 108-2622-E-002-023-CC2,MOST 108-2221-E-002-090,MOST 109-2321-B-002-043,MOST 109-2811-B-002-521,MOST 109-2221-E-002-060-MY3,MOST 110-2811-E-002-500-MY3,108AS-13.2.11-ST-a5,108AS-16.2.1-FD-Z2,109AS-11.3.2-ST-a2,109 AS-14.2.1-FD-Z2,109AS-11.3.2-ST-a8); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9241769","Internet of Things;on-vehicle monitoring system;PM₂.₅;residents’ exposure","Monitoring;Atmospheric measurements;Pollution measurement;Air quality;Urban areas;Sensors;Temperature measurement","","3","","42","CCBYNCND","28 Oct 2020","","","IEEE","IEEE Journals"
"Sparse CNN and Deep Reinforcement Learning-Based D2D Scheduling in UAV-Assisted Industrial IoT Networks","V. D. Tuong; W. Noh; S. Cho","School of Computer Science and Engineering, Chung-Ang University, Seoul, Republic of Korea; School of Software, Hallym University, Chuncheon, Republic of Korea; School of Computer Science and Engineering, Chung-Ang University, Seoul, Republic of Korea","IEEE Transactions on Industrial Informatics","12 Dec 2023","2024","20","1","213","223","Unmanned aerial vehicles (UAVs) have been widely applied in wireless communications because of its high flexibility and line-of-sight transmission. In this study, we develop low-complexity and robust device-to-device (D2D) link scheduling in UAV-assisted industrial-Internet-of-Things (IIoT) networks. First, we propose a sparse convolutional neural network (SCNN) model that uses the geographical map of transmission links as input. The model consists of three main blocks: 1) generic feature filtering, 2) speed–accuracy balancing, and 3) deep feature processing. Unlike other state-of-the-art methods, the proposed SCNN directly processes the geographical map collected using a connected UAV. Second, we propose a deep deterministic policy gradient-based reinforcement learning model that processes the output feature map from the SCNN to optimize the D2D scheduling decision and maximize the achievable system rate in the long run. Extensive simulations revealed that the proposed scheme significantly improved the achievable rate over other benchmark comparison schemes, such as transmitters and receivers density-based deep learning (DL), ResNet-based DL, VGGNet-based DL, random scheduling, and all-active schemes, respectively. The simulations also demonstrated that the proposed scheme reduces computational complexity. With reduced complexity and nearly optimal performance, the proposed solution can be more efficiently applied to large-scale and dense IIoT networks.","1941-0050","","10.1109/TII.2023.3254651","Ministry of Science and ICT, Korea(grant numbers:IITP-2023-RS-2022-00156353); Institute for Information Communications; National Research Foundation of Korea(grant numbers:NRF-2020R1F1A1069119); Chung-Ang University Young Scientist Scholarship in 2021; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10075466","Deep deterministic policy gradient (DDPG)-based reinforcement learning;geographical map;sparse convolutional neural network (SCNN);UAV-assisted industrial-Internet-of-Things (IIoT) networks;unmanned aerial vehicle (UAV)-assisted device-to-device (D2D) scheduling","Device-to-device communication;Industrial Internet of Things;Job shop scheduling;Interference;Neural networks;Deep learning;Computational complexity","","2","","36","IEEE","17 Mar 2023","","","IEEE","IEEE Journals"
"Vulnerability Analysis and Security Compliance Testing for Networked Surveillance Cameras","D. He; Y. Zhang; T. Li; S. Chan; Y. Cheng; N. Guizani","East China Normal University, Shanghai, China; East China Normal University, Shanghai, China; East China Normal University, Shanghai, China; City University of Hong Kong, Hong Kong, China; Institute for Infocomm Research, Singapore, Singapore; Purdue University, West Lafayette, IN, USA","IEEE Network","18 Sep 2020","2020","34","5","315","321","The development of Internet of Things technology and the decline of hardware costs have made large-scale camera interconnection possible. Security vendors have cooperated with governments to develop various security standards to achieve interconnection and unified management among cameras of different brands and models. However, there are still some security issues in some standards and their specific implementations. This article takes an existing camera security standard as an example, analyzes these issues in detail and proposes corresponding enhancements. We propose a camera security compliance testing system to test various security capabilities including the one-way authentication capability, the two-way authentication capability and the signaling authentication capability.","1558-156X","","10.1109/MNET.001.1900666","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9076120","","Cameras;Servers;Authentication;Internet of Things;Protocols;Digital signatures","","1","","15","IEEE","22 Apr 2020","","","IEEE","IEEE Magazines"
"Single-Server Public-Key Authenticated Encryption With Keyword Search and Its Application in IIoT","X. Zhou; D. He; J. Ning; M. Luo; X. Huang","School of Cyber Science and Engineering, Wuhan University, Wuhan, China; School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Fujian Provincial Key Laboratory of Network Security and Cryptology, College of Computer and Cyber Security, Fujian Normal University, Fuzhou, China; School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Artificial Intelligence Thrust, Information Hub, Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China","IEEE Transactions on Network Science and Engineering","5 Jan 2024","2024","11","1","404","415","Cloud-assisted Industrial Internet of Things (IIoT) gathers and analyzes multiple types of data (such as ambient and mechanical data) from physical devices to improve intelligent manufacturing. However, the heavy requirements for data storage and sharing have led to increased demands for efficiency and security in the IIoT system. Public-key Encryption with Keyword Search (PEKS) is an encryption method that provides both data confidentiality and efficient retrieval. Unfortunately, inside keyword guessing attacks (IKGA) have been a persistent issue in PEKS. To resist this attack, Public-key Authenticated Encryption with Keyword Search (PAEKS) has been developed. However, the existing PAEKS schemes are generally proven under intractability assumptions, such as Decisional Bilinear Diffie-Hellman (DBDH) and modified Decision Linear (mDLIN) assumptions, or they involve costly bilinear pairing operations, or rely on two non-colluded cloud servers, which are not suitable for large-scale IIoT applications. In this article, we propose a secure and efficient PAEKS scheme with only one server for cloud-assisted IIoT. Our proposal achieves the IKGA-secure property (i.e., it satisfies the trapdoor privacy and multi-ciphertext indistinguishability) and sidesteps the bilinear pairing operation. Our performance analysis demonstrates the feasibility of our scheme in IIoT by significantly improving computation efficiency (at least 21.97 times) with similar communication overhead.","2327-4697","","10.1109/TNSE.2023.3300716","National Natural Science Foundation of China(grant numbers:62172307,U21A20466,62032005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10198221","Public-key authenticated encryption with keyword search;inside keyword guessing attacks;Internet of Thing","Servers;Industrial Internet of Things;Security;Encryption;Cryptography;Public key;Proposals","","1","","45","IEEE","1 Aug 2023","","","IEEE","IEEE Journals"
"Recorp: Receiver-Oriented Policies for Industrial Wireless Networks","R. Brummet; O. Chipara; T. Herman",University of Iowa; University of Iowa; University of Iowa,"2020 IEEE/ACM Fifth International Conference on Internet-of-Things Design and Implementation (IoTDI)","21 May 2020","2020","","","135","141","The next generation of Industrial Internet-of-Things (IIoT) systems will require wireless solutions to connect sensors, actuators, and controllers as part of feedback-control loops over real-time flows. A key challenge in such networks is to provide predictable performance and adaptability to variations in link quality. We address this challenge by developing Receiver Oriented Policies (RECORP), which leverages the stability of IIoT workloads to build a solution that combines offline policy synthesis and run-time adaptation. Compared to schedules that service a single flow in a slot, RECORP policies share slots among multiple flows by assigning a coordinator and a set of candidate flows in the same slot. At run-time, the coordinator will dynamically execute one of the flows depending on what flows the coordinator has already received. The net effect of this strategy is that a node can dynamically repurpose the retransmissions remaining after receiving the data of an incoming flow to service other incoming flows opportunistically. Therefore, the flows that are executed in a slot can be adapted in response to the variable link conditions observed at run-time. Furthermore, RECORP also provides predictable performance: a policy meets the end-to-end reliability and deadline constraints of flows given probabilistic link qualities. When RECORP policies and schedules are configured to meet the same end-to-end reliability target of 99%, larger-scale multihop simulations show that across typical IIoT workloads, policies provided a median improvement of 1.63 to 2.44 times in real-time capacity as well as a median reduction of 1.45 to 2.43 times in worst-case latency.","","978-1-7281-6602-5","10.1109/IoTDI49375.2020.00020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9097591","wireless communication;real time communication;transmission scheduling;WirelessHART","Schedules;Real-time systems;Reliability;Wireless communication;Wireless sensor networks;Routing;Topology","","1","","8","IEEE","21 May 2020","","","IEEE","IEEE Conferences"
"Are You Diligent, Inefficient, or Malicious? A Self-Safeguarding Incentive Mechanism for Large Scale-Federated Industrial Maintenance Based On Double Layer Reinforcement Learning","H. Zhao; M. Sui; M. Liu; C. Zhu; W. Xun; B. Xu; H. Zhu","School of Internet of Things, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Communications and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Communications and Information Engineering, China; School of Communications and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Communications and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Communications and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Communications and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China","IEEE Internet of Things Journal","","2024","PP","99","1","1","Fault prediction is an important application in the Industrial Internet of Things (IIoT) to ensure the safety of industrial systems and factories. Currently, deep learning-based fault prediction models are more popular, and multi-factory co-operation is required to improve the accuracy and generality of fault prediction models. Federated learning can coordinate multiple clients to train models together while protecting client privacy, and thus is widely used for training fault prediction models. How to incentivise more factories to participate in model training is crucial, however, most of the existing incentive mechanisms focus on the problem of fair measurement of client contributions and ignore the problem of incentive allocation in scenarios with limited incentive budgets. In this paper, we design a self-safeguarding incentive mechanism for large scale-federated industrial maintenance based on double layer reinforcement learning, known as Dual Layer Incentive (DLI). The method enables the central server to achieve higher model training accuracy within a limited incentive budget through rational allocation of incentives, which ultimately reduces the overall cost of model training. In addition, we categorise participating clients into “diligent clients”“, inefficient clients” and “malicious clients” based on their contributions and design tailor-made incentives for each client type, which saves training costs and enhances the safety of the model training process. Finally, the proposed approach is evaluated through experiments using various datasets. The results show that the method significantly improves the accuracy and safety of industrial fault prediction model compared to other existing methods.","2327-4662","","10.1109/JIOT.2024.3367875","National Key Research and Development Program of China(grant numbers:No. 2021ZD0113003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10440403","Fault Prediction;Industrial Internet of things;Federated Learning;Incentive Mechanism;Deep Reinforcement Learning","Predictive models;Training;Federated learning;Production facilities;Data models;Servers;Industrial Internet of Things","","","","","IEEE","20 Feb 2024","","","IEEE","IEEE Early Access Articles"
"Adaptive Learning With Extreme Verification Latency in Non-Stationary Environments","M. M. Idrees; F. Stahl; A. Badii","Department of Computer Science, University of Reading, Reading, U.K.; German Research Center for Artificial Intelligence GmbH (DFKI), Marine Perception, Oldenburg, Germany; Department of Computer Science, University of Reading, Reading, U.K.","IEEE Access","9 Dec 2022","2022","10","","127345","127364","Existing Data Stream Mining algorithms assume the availability of labelled and balanced data streams. However, in many real-world applications such as Robotics, Weather Monitoring, Fraud-Detection systems, Cyber Security, and Human Activity Recognition, a vast amount of high-speed data is generated by Internet of Things sensors and real-time data on the Internet are unlabelled. Furthermore, the prediction models need to learn in Non-Stationary Environments due to evolving concepts. Manual labelling of these data streams is not practical due to the need for domain expertise and the time-resource-prohibitive nature of the required effort. To deal with such scenarios, existing approaches are self-Learning or Cluster-Guided Classification (CGC) which predict the pseudo-labels, which further update the prediction models. Previous studies have yet to establish a clear and conclusive view as to when, and why one pseudo-labelling approach should be preferable to another and what causes an approach to fail. In this research, we propose a novel approach, “Predictor for Streaming Data with Scarce Labels” (PSDSL), which is capable of intelligently switching between self-learning, CGC and micro-clustering strategies, based on the problem it is applied to, i.e., the different characteristics of the data streams. In PSDSL a novel approach called Envelope-Clustering has been introduced to resolve the conflict during the cluster labelling which suggested a confidence measure approach to ensure the quality and correctness of labels assigned to the clusters. The auto parameter tuning mechanism of PSDSL eliminates the human dependency and determines the best value of number of centroids from initial labelled data. The predictive performance of the PSDSL is evaluated on non-stationary datasets, synthetic data-streams, and real-world datasets. The approach has shown promising results on randomised datasets as well as on synthetic data-streams, as compared with state-of-the-art approaches. This is the first large-scale study on an adaptive extreme verification approach that supports automatic parameter tuning and intelligent switching of pseudo-labelling strategy, thus reducing the dependency of machine learning on human input.","2169-3536","","10.1109/ACCESS.2022.3225225","Ministry for Science and Culture, Lower Saxony, Germany, through Funds from the Niedersachsische Vorab(grant numbers:ZN3683,ZN3480); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9964239","Concept drift;data stream mining;extreme verification latency;non-stationary environment;semi-supervised learning","Data mining;Classification algorithms;Predictive models;Prediction algorithms;Training;Labeling;Benchmark testing","","","","80","CCBY","28 Nov 2022","","","IEEE","IEEE Journals"
"Intelligent Sharding Decision for Blockchain-Enabled Industrial IoT Based on A3C Approach","X. Xiong; M. Li; P. Si; R. Yang; C. Yang; Z. Wang","Faculty of Information Technology, Beijing University of Technology, Beijing, P.R. China; Faculty of Information Technology, Beijing University of Technology, Beijing, P.R. China; Faculty of Information Technology, Beijing University of Technology, Beijing, P.R. China; Faculty of Information Technology, Beijing University of Technology, Beijing, P.R. China; Faculty of Information Technology, Beijing University of Technology, Beijing, P.R. China; Faculty of Information Technology, Beijing University of Technology, Beijing, P.R. China","2023 IEEE International Symposium on Product Compliance Engineering - Asia (ISPCE-ASIA)","28 Dec 2023","2023","","","1","6","As an essential concept and technology, the Industrial Internet of Things (IIoT) is a feasible way for the advancement of industrial digitization, networking and intelligence. However, it brings serious security and privacy risks to industrial data. Blockchain technology can address security and privacy risks into the IIoT effectively, but there are a few nonnegligible questions in the current researches: 1) The scalability of the conventional blockchain system is extremely limited, making it unable to handle the rapid uploading of massive data in the IIoT. 2) The large-scale nature of IIoT and complex consensus procedure of blockchain result in excessive computational overhead. 3) The balance between security and computational efficiency is often ignored. To address these problems, we propose the concept of sharding decision blockchain innovatively and formulate the optimization problem as a Markov decision process (MDP). Besides, the combining of mobile edge computing (MEC) and cloud computing is empowered the computational efficiency in the proposed scheme. An asynchronous advantage actor-critic (A3C) approach is taken into account and used to solve the optimization problem. Experimental results indicate that our proposed scheme provides a significant improvement on the IIoT versus other solutions.","2831-3410","979-8-3503-6120-9","10.1109/ISPCE-ASIA60405.2023.10365903","Beijing Municipal Commission of Education; National Key Research and Development Program of China; China State Construction Engineering Corporation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10365903","Industrial Internet of Things (IIoT);sharding decision blockchain;mobile edge computing (MEC);asynchronous advantage actor-critic (A3C)","Sharding;Data privacy;Multi-access edge computing;Scalability;Markov processes;Blockchains;Computational efficiency","","","","18","IEEE","28 Dec 2023","","","IEEE","IEEE Conferences"
"Decentralized Control of Large-Scale Nonlinear Systems: Optimal Robust Tracking","J. Hammer","Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA","2021 29th Mediterranean Conference on Control and Automation (MED)","15 Jul 2021","2021","","","1287","1292","The design and implementation of decentralized controllers for large-scale nonlinear systems is considered. The objective is to track a specified target state over the infinite time horizon. Simple optimal robust decentralized controllers that comply with specified constraints are developed. Potential applications include electrical power distribution networks and the internet of things.","2473-3504","978-1-6654-2258-1","10.1109/MED51440.2021.9480290","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9480290","","Electric potential;Target tracking;Systematics;Automation;Design methodology;Decentralized control;Power systems","","","","21","IEEE","15 Jul 2021","","","IEEE","IEEE Conferences"
"Design of Intelligent Sericulture Management System Based on Artificial Intelligence","X. Sun; W. Zhou; Q. Zhu; J. Shi; S. Xu","Yancheng bioengineering branch of Jiangsu Union Technical Institute, Yancheng, China; Yandu District silkworm egg farm, Yancheng, China; Yancheng bioengineering branch of Jiangsu Union Technical Institute, Yancheng, China; Yancheng Siyuan Network Technology Co., Ltd, Yancheng, China; Yancheng Institute of Technology, Yancheng, China","2023 International Seminar on Computer Science and Engineering Technology (SCSET)","3 Oct 2023","2023","","","348","354","At present, intelligent and equipped sericulture has become an inevitable trend for the high-quality development of modern sericulture. However, sericulture in the past is still facing practical problems such as labor shortage, outdated equipment, complicated control, low standards, and lax regulations. It is urgent to change the way of sericulture. Based on the research on intelligent monitoring of sericulture environment, the development of intelligent sericulture management system based on intelligent perception and processing is discussed. Combining intelligent and large-scale sericulture real scenes, relying on the intelligent perception technology of the Internet of Things, the environmental elements of sericulture and the developmental status of silkworms are intelligently sensed, identified, transmitted, and processed, and the development process and environmental conditions of sericulture are accurately grasped. Using the deep residual neural network algorithm (DRCNN), multi-feature data extraction and hierarchical fusion processing, timely correction of sericulture data standards, real-time monitoring of sericulture production process, output technical solutions, and provide automated sericulture decision-making. It provides a reference for building an intelligent and equipped compatible platform for sericulture.","","979-8-3503-0147-2","10.1109/SCSET58950.2023.00083","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10266553","intelligent perception;deep learning;sericulture management system;design","Seminars;Decision making;Production;Market research;Regulation;Real-time systems;Internet of Things","","","","23","IEEE","3 Oct 2023","","","IEEE","IEEE Conferences"
"Priority-Aware Access Strategy for GF-NOMA System in IIoT: The Device-Specific Allocation Approach","D. Wu; Z. Zhang; Y. Huang; X. Qin","State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; Academy of Military Sciences of PLA, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China","IEEE Internet of Things Journal","8 Jan 2024","2024","11","2","2152","2165","To support large-scale connectivity of massive machine-type communication (mMTC) devices in Industrial Internet of Things (IIoT) scenario, a grant-free (GF) transmission aided nonorthogonal multiple access (NOMA) system is considered in this article, where the devices with diverse behavior characteristics coexist. In order to reflect the diversity of IIoT scenario, multiple types of MTC devices are taken into account, and the network environment is divided into stationary mode and overload mode based on the differences in behavior characteristics of devices. Further, the successful access probability maximization problem is established to obtain the priority-aware access strategy. To solve this problem, we propose a novel distributed  $Q$ -learning algorithm and an adaptive update (AdaUpdate) aided priority-aware deep  $Q$  network (PA-DQN) algorithm for the stationary mode and the overload mode, respectively. Simulation results demonstrate that the proposed algorithms achieve better performance than that of traditional reinforcement learning algorithms and the random access algorithm in terms of overall access efficiency and satisfying the access requirements of emergency devices preferentially.","2327-4662","","10.1109/JIOT.2023.3292894","National Key Research and Development Program of China(grant numbers:2020YFB1807204); Young Elite Scientists Sponsorship Program by CAST(grant numbers:2021QNRC001); National Natural Science Foundation of China(grant numbers:61971474); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10175515","Grant-free (GF) transmission;nonorthogonal multiple access (NOMA);reinforcement learning (RL)","Industrial Internet of Things;Uplink;Internet of Things;Resource management;NOMA;Q-learning;Behavioral sciences","","","","38","IEEE","7 Jul 2023","","","IEEE","IEEE Journals"
"Integration of MEC and Blockchain","B. Cao; W. Liu; M. Peng","State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing,, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing,, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing,, China","Wireless Blockchain: Principles, Technologies and Applications","","2022","","","161","177","Mobile edge computing (MEC) sinks computing power to the edge of networks and integrates mobile access networks and Internet services in 5G and beyond. With the continuous development of services, heterogeneous MEC systems were proposed to carry out the massive and complex computing services. However, when it comes to multiserver collaboration, trust and security issues would come to the fore. With large‐scale access support capability, public blockchain network (PBN) has been widely adapted to provide the trust and security enhancement for various services because of its key characteristics of decentralization, distributed consistency, consensus, etc., which can effectively resolve the problems mentioned in heterogeneous MEC. As for PBN, the adopted proof‐of‐work consensus mechanism is computationally intensive, posing an obstacle to the application in wireless mobile networks, because most Internet of Things/mobile devices (IMDs) are resource limited. In contrast, however, by allowing resource‐limited IMDs to offload their computation tasks to the edge servers, MEC, in turn, can solve the resource‐intensive problems faced by PBN.","","9781119790815","10.1002/9781119790839.ch7","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9598499.pdf&bkn=9598346&pdfType=chapter","","Task analysis;Servers;Blockchains;Mobile handsets;Privacy;Base stations;Wireless communication","","","","","","2 Nov 2021","","","IEEE","Wiley-IEEE Press eBook Chapters"
"V-IoT: A Smart Hydraulic Distribution System Using Volumetric Route-Genetic Algorithm","K. C. Okafor; O. M. Longe","Mechatronics Engineering, Federal University of Technology, Owerri, Nigeria; Electrical and Electronic Engineering Science, University of Johannesburg, South Africa","2021 IEEE 6th International Forum on Research and Technology for Society and Industry (RTSI)","15 Nov 2021","2021","","","412","417","Hydraulic distribution systems (HDS) are widely used in the Mechatronics industry to drive manufacturing machines, heavy-duty vehicles, equipment, and distribute fluids automatically with control valves and pipelines/horses. The absence of smart sensors, valves, and cylinders hinder the reporting of real-time state information about hydraulic motion controllers and pipeline networks. Legacy HD lacks active and structured communication protocols like Ethernet-IP. Unfortunately, these hydraulic flow systems are poorly designed during large-scale deployment at both residential and industrial areas. Cases of leakages and failures still abound. In some cases, there are no reference standards for IoT integration with fluid flow systems. In this paper, Volumetric IoT (V-IoT) sensors are introduced to monitor hydraulic flow systems leveraging route genetic algorithm. A state diagram for leakage amplitude monitoring is presented. Considering its node-to-node connectivity for steady-state monitoring, the enhanced V-IoT, with Genetic and Fibonacci algorithms offered leakage amplitude of 23.07%, 30.77%, and 46.16% respectively.","2687-6817","978-1-6654-4135-3","10.1109/RTSI50628.2021.9597258","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9597258","Distributed Intelligence;Volumetric Internet of Things (V-IoT);Genetic Algorithm;Automation","Industries;Pumps;Hydraulic systems;Valves;Sensor systems;Steady-state;Monitoring","","","","21","IEEE","15 Nov 2021","","","IEEE","IEEE Conferences"
"Waste Management of Residential Society using Machine Learning and IoT Approach","S. Dubey; M. K. Singh; P. Singh; S. Aggarwal","ECE.IEC College of Engineering & Technology, Gr. Noida, India; CSE.IEC College of Engineering & Technology, Gr. Noida, India; CSE.IEC College of Engineering & Technology, Gr. Noida, India; CSE.IEC College of Engineering & Technology, Gr. Noida, India","2020 International Conference on Emerging Smart Computing and Informatics (ESCI)","17 Aug 2020","2020","","","293","297","Due to the increasing population and industrialization of nations, waste management has become a challenging issue for all of us. A small scale waste management is also adding same potential as large scale waste management. IoT and machine learning based waste management system for residential society are aimed to enhance the same concern as the waste management of smart city. This paper employs on monitoring of various dustbins located at different residential societies. Dustbin is equipped with sensors which monitors for dustbin capacity, metal level and poisonous gas level. The machine learning classification technique such as SVM, NB, RF, DT and KNN are used to test their ability to predict the accuracy of sending alert messages to third party in order to manage the waste of the society. In addition, results suggest that RF algorithm produced the most accurate forecasts of the alert message. The accuracy of RF algorithm is 85.29 %. The overall impact of this research is in the upliftment of the green technologies by reducing pollution of the smart city.","","978-1-7281-5263-9","10.1109/ESCI48226.2020.9167526","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9167526","Machine Learning;Waste Management;Random Forest;Decision Tree;IoT","Waste management;Machine learning;Monitoring;Smart cities;Forestry;Gas detectors","","14","","18","IEEE","17 Aug 2020","","","IEEE","IEEE Conferences"
"Research and Application of Operation and Maintenance Simulation Technology of Provincial Intelligent Distribution Network Based on Data Mining","J. Wang","Grid Operation Training Department, State Grid of China Technology College, Jinan, China","2021 IEEE 5th Information Technology,Networking,Electronic and Automation Control Conference (ITNEC)","4 Nov 2021","2021","5","","1247","1251","Based on the actual production in the power industry, this achievement researches the key technologies of operation and maintenance simulation such as horizontal data fusion of multi-service systems of intelligent distribution network, vertical data penetration of provincial multi-level (provincial, city and county), large-scale operation state analysis of intelligent distribution network, data mining, etc., develops a full panoramic simulation environment of intelligent distribution network, builds dynamic real-time monitoring of distribution network multi-service, monitoring and analysis of distribution network equipment, and functional modules of distribution network operation optimization, and thus realizes a panoramic display, multi-dimensional analysis and operation control of intelligent distribution network. This will enable the panoramic display, multi-dimensional analysis and operation control of the operation status of intelligent distribution networks, filling the gap in the field of practical training and assessment of intelligent distribution network operation and maintenance and management in China. It supports the construction of a small-scale energy interconnection research platform with flexible access to all elements of source, network, load and storage, and is compatible with various smart meters, sensors and other IoT devices, collecting all kinds of massive data and supporting relevant scientific research, simulation testing and functional verification.","2693-3128","978-1-6654-1599-6","10.1109/ITNEC52019.2021.9586938","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9586938","Big Data Mining;Operation and Maintenance Simulation;Distribution Network;Data Fusion","Training;Analytical models;Urban areas;Distribution networks;Maintenance engineering;Data models;Smart meters","","1","","16","IEEE","4 Nov 2021","","","IEEE","IEEE Conferences"
"Sensor Based Smart Agriculture with IoT Technologies: A Review","M. Pyingkodi; K. Thenmozhi; K. Nanthini; M. Karthikeyan; S. Palarimath; V. Erajavignesh; G. B. A. Kumar","Department of Computer Applications, Kongu Engineering College, Erode, Inida; Department of Computer Science, Kristu Jayanthi College, Bengaluru, India; Department of Computer Applications, Kongu Engineering College, Erode, Inida; Department of Computer Applications, Kongu Engineering College, Erode, Inida; Department of IT, University of Technology and Applied Sciences, Salalah, Oman; Department of Computer Applications, Kongu Engineering College, Erode, Inida; Department of Computer Applications, Kongu Engineering College, Erode, Inida","2022 International Conference on Computer Communication and Informatics (ICCCI)","31 Mar 2022","2022","","","1","7","The IoT is a new technology trend used in almost every area thing, when connected to the internet and to each other, when you connect to the internet or interconnect, your entire system will be smarter. We have used IoT in all areas of our lives, including smart cities, smart homes, and smart retail. Much more. From 9.6 billion by 2050, agriculture needs to deliver even faster to meet this type of demand. This is possible with the latest technology, especially the IoT. The IoT enables labour free farms. Not only can it be used for large-scale agriculture, but it can also be used for livestock, greenhouse management, and agricultural land management. The most significant tool for the IoT is the sensor. A sensor is a device that collects important data that is interpreted to obtain the required analysis. The important objective of sensors are used to determine the soil's physical qualities and the environment. The main applications of sensors are control and supervise, safety, alarm, diagnostics, and analytics. Sensors make innovative agriculture more effective and trouble-free. In agriculture, the sensor is mainly used for measuring, measuring NPK (Nitrogen, Phosphorus, Potassium) levels, and detecting disease and soil moisture content. The main solution to this problem is smart farming, which modernizes traditional farming practices. This paper narrates the role of IoT application in smart agriculture. Smart farming is also known as precision farming hence it uses accurate information to draw outcomes. It demonstrates the different sensors, applications, challenges, strengths and weaknesses that support the IoT and agriculture.","2329-7190","978-1-6654-8035-2","10.1109/ICCCI54379.2022.9741001","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9741001","IoT Sensors;Smart farming;Agriculture Sensor;Smart Agriculture;Precision Agriculture","Soil measurements;Moisture measurement;Smart cities;Green products;Soil moisture;Smart homes;Safety","","21","","35","IEEE","31 Mar 2022","","","IEEE","IEEE Conferences"
"Subscription Freedom: Automatic Industrial Data Subscription Based on Recommendation System","Y. Wu; B. Yang","Shanghai Jiao Tong University, Shanghai, CN; Shanghai Jiao Tong University, Shanghai, CN","2022 China Automation Congress (CAC)","13 Mar 2023","2022","","","3614","3619","In smart factory, the number of sensors and industrial applications is increasing exponentially. The data transfer relationship between sensor data and applications has also become intricate. Message queuing telemetry transport (MQTT) has become the de-facto standard in the IoT field due to its decoupling of data transfer in time and space. However, even though existing MQTT message servers have been able to reach 100 million connections, the way data is subscribed still relies entirely on manual work. Based on a recommender system, this work proposes an innovative automated industrial data subscription approach to improve the level of automation to better cope with the large-scale dynamic scenarios of smart factory data transfer. This work deploys MQTT broker to the cloud for larger datasets and computing power, and combines OPC UA semantic model to make MQTT publish/subscribe more standardized and automatic. The architecture and algorithm for auto-subscription are proposed, and the corresponding datasets are constructed and obtained on the MQTT broker. The similarity between different subscribers are mined through natural language processing (NLP) model and user-based collaborative filtering. Then the usefulness of the topics is calculated to generate the auto-subscription list. The simulation proves that this work can realize automatic industrial data subscription effectively.","2688-0938","978-1-6654-6533-5","10.1109/CAC57257.2022.10055861","National Key Research and Development Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10055861","industrial internet of things (IIoT);recommendation system;natural language processing(NLP);message queuing telemetry transport (MQTT);auto-subscription","Automation;Computational modeling;Data transfer;Natural language processing;Telemetry;Servers;Recommender systems","","","","12","IEEE","13 Mar 2023","","","IEEE","IEEE Conferences"
"A proposal on the control mechanism among distributed MQTT brokers over wide area networks","Y. Noda; K. Ishibashi; T. Yokotani","Graduate School Kanazawa Institute of Technology Ohgigaoka 7-1, Nonoichi, Ishikawa, Japan; College of Engineering Kanazawa Institute of Technology Ohgigaoka 7-1, Nonoichi, Ishikawa, Japan; College of Engineering Kanazawa Institute of Technology Ohgigaoka 7-1, Nonoichi, Ishikawa, Japan","2022 IEEE International Conference on Internet of Things and Intelligence Systems (IoTaIS)","13 Dec 2022","2022","","","70","75","MQTT for IoT communication requires the deployment of multiple brokers to aggregate traffic from localized areas. However, the routing mechanisms among these brokers in a large-scale environment have yet to be specified. In this paper, a routing suitable for up-scaling based on the distribute MQTT broker by data link look up for traffic reduction (DMLT) is proposed. In this study, several up-scaling methods are proposed and compared in terms of traffic volume, scalability, and resilience. As a result, we chose an improved version of DMLT. A prototype of a wide-area DMLT system was constructed and verified by combining the DMLT method with an approach that the authors judged to be the most suitable for large-scale deployment.","2832-1383","979-8-3503-9645-4","10.1109/IoTaIS56727.2022.9976024","Ministry of Economy; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9976024","IoT;MQTT;multiple brokers;routing protocol;VPN","Wide area networks;Scalability;Aggregates;Prototypes;Wavelength division multiplexing;Routing;Virtual private networks","","1","","15","IEEE","13 Dec 2022","","","IEEE","IEEE Conferences"
"Development and In-situ Teaching of Disaster-resistant Monitoring System on Slopeland with Micro-weather Stations and Microcontrollers","L. -S. Kuo; I. -H. Chen; S. -H. Peng","Department of Water Resources, Changhua County Government, Changhua City, Taiwan; Department of Civil Engineering, National Chung Hsing University, Taichung City, Taiwan; Department of Spatial Design, Chienkuo Technology University, Changhua City, Taiwan","2022 IEEE 5th Eurasian Conference on Educational Innovation (ECEI)","20 Jul 2022","2022","","","51","54","By applying new microcontrollers and microcomputers, a monitoring system of disaster prevention is prepared for disaster-resistant communities and environmental safety on the slope. The display of the monitoring system consists of disaster-prevention education and interactive instrument operations. It is a simple and easy-to-understand system including a micro:bit micro-weather station and Raspberry Pi IoT microcomputer. The micro:bit micro-weather station is energy-saving, real-time, and automatic device that is installed outdoor for rainfall and environmental monitoring. The system communicates wirelessly through two micro:bit devices to connect to indoor IoT microcomputers in real-time. Meanwhile, the micro-weather station only needs 10 W solar power. Thus, there is no need for electric wires and network cables. It is practical to apply the new devices for the monitoring of disaster prevention and environmental safety. Furthermore, the system is economical and simple-installed so that all disaster-resistant communities set up the micro-weather station to enhance the disasters resilience in the debris or large-scale landslide areas.","","978-1-6654-3318-1","10.1109/ECEI53102.2022.9829433","Soil and Water Conservation Bureau; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9829433","disaster-resistant community;microcontroller monitoring;debris disaster prevention;large-scale landslide","Microcontrollers;Education;Wires;Microcomputers;Terrain factors;Real-time systems;Safety","","","","9","IEEE","20 Jul 2022","","","IEEE","IEEE Conferences"
"WIP: Sysnif: Constructing Workflow from Interleaved Logs in Intelligent IoT System","Z. Jin; X. Xie; Y. Fang; Z. Jian; Y. Lu; G. Li","College of Cyber Science, Nankai University, Tianjin, China; College of Cyber Science, Nankai University, Tianjin, China; College of Cyber Science, Nankai University, Tianjin, China; College of Cyber Science, Nankai University, Tianjin, China; College of Cyber Science, Nankai University, Tianjin, China; Cyberspace Administration of Tianjin, China","2021 IEEE 22nd International Symposium on a World of Wireless, Mobile and Multimedia Networks (WoWMoM)","5 Jul 2021","2021","","","264","267","The massive smart devices in intelligent IoT can be broken due to malicious attacks and system failures. As a nonintrusive method, workflows mined from system logs facilitate administrators to quickly locate and diagnose anomalies in time. System logs are usually interleaved since there are lots of concurrent and asynchronous operations and executions on large scale IoT devices. Consequently, it is so challenging to construct an adaptive workflow from these logs and realize the real-time anomaly detection. To meet this challenge, in this paper, we propose a two-stage workflow construction approach named Sysnif, which includes offline construction and online adjustment. First, the window-based dependence computing method is employed to obtain the context of execution paths. Second, a weight-greedy algorithm is designed to denoise the interleaved system logs effectively. Third, in order to match system mechanism variation, the online micro-iteration adjusting algorithm is presented to update the workflow model. Experiment results highlight that Sysnif can outperform state-of-the-art methods, such as Logsed, on dataset of OpenStack logs by 22.4% on recall, meanwhile maintaining the same precision roughly. Sysnif can achieve an average precision and recall of 93.8% and 94.7%, respectively.","","978-1-6654-2263-5","10.1109/WoWMoM51794.2021.00049","National Key Research and Development Program of China; CERN; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9469470","Workflow;Interleaved Logs;Dependence computing;Micro-iteration adjusting","Multimedia systems;Computational modeling;Real-time systems;Smart devices;Anomaly detection","","","","9","IEEE","5 Jul 2021","","","IEEE","IEEE Conferences"
"A LoRaWAN Based Solar PV Condition Monitoring System","Q. Ziyuan; D. R. Thinesh; V. Ayyalusamy; B. Sivaneasan; K. T. Tan; K. J. Tseng","Singapore Institute of Technology (SIT), Singapore; Singapore Institute of Technology (SIT), Singapore; Singapore Institute of Technology (SIT), Singapore; Singapore Institute of Technology (SIT), Singapore; Singapore Institute of Technology (SIT), Singapore; Singapore Institute of Technology (SIT), Singapore","2022 IEEE International Conference on Power Electronics, Drives and Energy Systems (PEDES)","30 Mar 2023","2022","","","1","6","This paper presents the design and performance of a low-cost, low-power remote condition monitoring (CM) solution for large-scale solar photovoltaic (PV) systems. The developed CM solution utilises ESP-NOW and Long Range Wide Area Network (LoRaWAN) wireless communication protocols for data exchanges. The developed solution operates in self-power mode, with each IoT node capable of monitoring up to 16 channels of voltage, current, and temperature of the PV panels. The 2.4GHz ESP-NOW wireless communication protocol is used for data transfer between the IoT nodes in a many-to-one configuration. The transceiver node stores messages from all IoT nodes and broadcasts them via the LoRaWAN network to the server. The developed hardware and software solutions were tested to measure the accuracy and reliability of the CM system. As a result, a fully-functioning low-cost solar PV CM system is developed, with an overall sensor measurement error of less than 3%, with an average Received Signal Strength Indicator (RSSI) of -105dBm in non-line-of-sight conditions.","","978-1-6654-5566-4","10.1109/PEDES56012.2022.10080221","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10080221","IoT;LoRaWAN;ESP-NOW;Renewable Energy;Solar PV;Microgrid;Condition Monitoring","Wireless communication;Deep learning;Condition monitoring;Wide area networks;Measurement errors;Wireless sensor networks;Protocols","","1","","12","IEEE","30 Mar 2023","","","IEEE","IEEE Conferences"
"Anomaly Detection on IoT Network Intrusion Using Machine Learning","Z. Liu; N. Thapa; A. Shaver; K. Roy; X. Yuan; S. Khorsandroo","Department of Computer Science, North Carolina Agricultural and Technology State University, Greensboro, USA; Department of Computer Science, North Carolina Agricultural and Technology State University, Greensboro, USA; Department of Computer Science, North Carolina Agricultural and Technology State University, Greensboro, USA; Department of Computer Science, North Carolina Agricultural and Technology State University, Greensboro, USA; Department of Computer Science, North Carolina Agricultural and Technology State University, Greensboro, USA; Department of Computer Science, North Carolina Agricultural and Technology State University, Greensboro, USA","2020 International Conference on Artificial Intelligence, Big Data, Computing and Data Communication Systems (icABCD)","1 Sep 2020","2020","","","1","5","Enhancing the security of IoT networks is trending as one of the most crucial issues the information technology community faces. With large scales of IoT devices being developed and deployed, the ability for these devices to communicate securely without compromising performance is challenging. The challenges exist because most of IoT devices are limited by power hence constrained to less computational ability. Subsequently, encryption and authentication are difficult to be applied to fence off malicious cyber-attacks. Intrusion Detection System (IDS) logically becomes the forefront security solution. Anomaly-based network intrusion detection plays a major role in safeguarding networks against different malicious activities. In this paper, we apply different machine learning algorithms to efficiently detect anomalies on the IoT Network Intrusion Dataset. The results show promise as we were able to achieve 99%-100% accuracy while having high efficiency.","","978-1-7281-6770-1","10.1109/icABCD49160.2020.9183842","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9183842","IoT security;anomaly detection;intrusion detection system;machine learning","Anomaly detection;Machine learning;Performance evaluation;Intrusion detection;Botnet;Testing","","26","","21","IEEE","1 Sep 2020","","","IEEE","IEEE Conferences"
"Programming (and Learning) Self-Adaptive & Self-Organising Behaviour with ScaFi: for Swarms, Edge-Cloud Ecosystems, and More","R. Casadei; G. Aguzzi; D. Pianini; M. Viroli","University of Bologna, Cesena, Italy; University of Bologna, Cesena, Italy; University of Bologna, Cesena, Italy; University of Bologna, Cesena, Italy","2023 IEEE International Conference on Autonomic Computing and Self-Organizing Systems Companion (ACSOS-C)","11 Dec 2023","2023","","","33","34","Large-scale and fully distributed cyber-physical systems (CPS), such as swarm robotics or IoT systems, pose significant challenges for programming and design. These challenges include promoting the desired (emergent) collective and self-organising behaviour, dealing with failures, enacting decentralised coordination, and deploying efficient executions. Aggregate computing is a promising approach that aims to simplify the design of such systems by providing a high-level abstraction for describing collective and self-organising behaviours. In this tutorial, we introduce a toolchain that supports the development of aggregate computing applications, based on ScaFi (a Scala-based language and toolkit for aggregate computing) and Alchemist (a simulator for CPS scenarios). We will showcase the toolchain by means of a series of examples, ranging from simple collective behaviours to more complex self-adaptive and self-organising ones. Finally, we provide several pointers to research opportunities (e.g., related to learning collective behaviours and adaptive large-scale deployments) and applications (e.g., in swarm robotics, edge-cloud ecosystems, and more).","","979-8-3503-3746-4","10.1109/ACSOS-C58168.2023.00032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10336236","self-organisation;macro-programming;aggregate computing;collective adaptive systems;swarm intelligence;edge-cloud ecosystems","Adaptive systems;Aggregates;Ecosystems;Swarm robotics;Tutorials;Programming;Cyber-physical systems","","","","16","IEEE","11 Dec 2023","","","IEEE","IEEE Conferences"
"A Large-Scale Simulator for NB-IoT","V. Therrien; H. Mellah; V. Boutin; B. Sansò","Department of Electrical Engineering, Polytechnique Montréal, Montréal, QC, Canada; Department of Electrical Engineering, Polytechnique Montréal, Montréal, QC, Canada; Department of Electrical Engineering, Polytechnique Montréal, Montréal, QC, Canada; Department of Electrical Engineering, Polytechnique Montréal, Montréal, QC, Canada","IEEE Access","4 Jul 2022","2022","10","","68231","68239","This paper presents a large-scale comprehensive machine-to-machine NB-IoT (narrowband IoT) traffic simulator designed to study IoT application performance in large-scale environments, such as smart cities. The simulation system uses real geographical data to define a wide range of devices characterized by location, packet generation pattern, and network access properties. Key performance indicator metrics are collected during simulations to evaluate the way that various factors affect the “machine quality of experience.”","2169-3536","","10.1109/ACCESS.2022.3186365","Natural Sciences and Engineering Research Council of Canada (NSERC) and Ericsson(grant numbers:CRDPJ 520642); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9807286","KPIs;verticals;simulation;NB-IoT;performance assessment;IoT","Urban areas;Internet of Things;Base stations;Databases;Telecommunications;Performance evaluation;Smart cities","","6","","29","CCBY","27 Jun 2022","","","IEEE","IEEE Journals"
"Optimizing Packet Transmission for Ledger-Based Points Transfer System in LPWAN: Solutions, Evaluation and Standardization","X. Qi; K. Yu; T. Sato; K. Shibata; E. Brigham; T. Tokutake; R. Eguchi; Y. Maruyama; Z. Wen; K. Tamesue; Y. Katsuyama; K. Sako; T. Sato","Waseda University, Global Information and Telecommunication Institute, Tokyo, Japan; Waseda University, Global Information and Telecommunication Institute, Tokyo, Japan; Waseda University, Global Information and Telecommunication Institute, Tokyo, Japan; Skeed Co., Ltd, Tokyo, Japan; School of Fundamental Science and Engineering, Waseda University, Tokyo, Japan; School of Fundamental Science and Engineering, Waseda University, Tokyo, Japan; School of Fundamental Science and Engineering, Waseda University, Tokyo, Japan; School of Fundamental Science and Engineering, Waseda University, Tokyo, Japan; School of Fundamental Science and Engineering, Waseda University, Tokyo, Japan; Waseda University, Global Information and Telecommunication Institute, Tokyo, Japan; Waseda University, Global Information and Telecommunication Institute, Tokyo, Japan; School of Fundamental Science and Engineering, Waseda University, Tokyo, Japan; Research Institute for Science and Engineering, Waseda University, Tokyo, Japan","2021 ITU Kaleidoscope: Connecting Physical and Virtual Worlds (ITU K)","6 Jan 2022","2021","","","1","8","Low Power Wide Area Network (LPWAN) is a long-range low-power wireless communication network. Its features, such as wide network coverage and low power consumption of terminals, make it suitable for large-scale deployment of IoT applications. The points transfer system, especially points transfer system in LPWAN, as a typical third-party payment application, is being closely attended by both industry and academia. Recent studies have shown that distributed ledger technology, because ofits characteristics such as high confidentiality, non-tampering, and decentralization, is a good solution to problems such as low-security performance due to centralized storage for a points transfer system. However, the distributed ledger will generate a large amount of data traffic in recording the transactions of network participants, which is a challenge for resource-constrained IoT devices. To address these issues, we propose an optimized packet transmission mechanism for a ledger-based points transfer system in LPWAN. Simulation results show that our proposed mechanism can well reduce the packet transmission ofthe whole system and meet the requirements of LPWAN. Moreover, we update the reader with information about distributed ledger and standardization-related activities in this paper.","","978-92-61-33881-7","10.23919/ITUK53220.2021.9662101","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9662101","Distributed ledger;LPWAN;points transfer system;standardization","Wireless communication;Performance evaluation;Power demand;Distributed ledger;Simulation;Standardization;ITU","","1","","16","","6 Jan 2022","","","IEEE","IEEE Conferences"
"Enabling On-Demand Crowdsourced Federated Learning Over IoT","M. Tahir; M. I. Ali","SFI Centre for Research Training in Machine Learning, Dublin CIty University, Dublin, Ireland; School of Electronic and Computer Engineering, Dublin City University, Dublin, Ireland","2023 Eighth International Conference on Fog and Mobile Edge Computing (FMEC)","8 Nov 2023","2023","","","128","134","Federated learning (FL) is attributed to training a machine learning (ML) model over a large number of distributed devices. Under these settings, the edge devices perform computations on their local data before sending the required updates to the central server to improve the global model. This approach has shown great potential since hundreds of devices can collectively contribute to learning a single task without sharing their local data. However, IoT devices often have only small data samples, and collaboration among a large number of devices is required to collectively provide the extensive training data needed to train a high-performing model. Despite the success in many domains, FL is facing challenges when it comes to audit and scaling the clients to increase the performance of the federated network. In this paper, we argue that there's a need for a dynamic learning platform where IoT devices could volunteer to collaboratively learn a task through FL. Building on that, we propose a dynamic marketplace for on-demand, crowd-sourced FL namely FedOnDemand, to train high-performing ML models over IoT devices. The proposed system coordinates client selection, task assignment, and model training to allow computationally efficient FL while maintaining communication efficiency. To drive FedOnDemand, we use the data valuation mechanism based on the Shapley Value to incentivize participants and ensure a fair reward distribution.","","979-8-3503-1697-1","10.1109/FMEC59375.2023.10306078","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10306078","Federated Learning;Crowdsourcing;Crowdsourced Federated Learning;Internet of Things;IoT;Market-place","Training;Performance evaluation;Multi-access edge computing;Federated learning;Computational modeling;Training data;Data models","","","","24","IEEE","8 Nov 2023","","","IEEE","IEEE Conferences"
"Scalable Spatial Queries in Big Data Systems","L. Abdelhafeez",Department of Computer Science and Engineering,"2022 23rd IEEE International Conference on Mobile Data Management (MDM)","25 Aug 2022","2022","","","328","330","The amount of data in the world is increasing exponentially, a large portion of this data comes from the interactions over mobile devices and the ubiquitous IoT applications. Improving our ability to extract information and insights from these large and complex datasets is crucial to a variety of applications. Our research focuses on scaling spatial queries in the context of big data systems, to be able to apply complex algorithms on large-scale spatial datasets in a timely manner. In particular, this paper studies two spatial queries: (a) spatial group-by polygon query which groups input data points by a given complex polygon set (e.g. world countries), and (b) polygonization query which polygonizes an input set of line strings (e.g. USA road network).","2375-0324","978-1-6654-5176-5","10.1109/MDM55031.2022.00073","National Science Foundation, USA(grant numbers:IIS-1849971,IIS-190137,SES-1831615); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9861194","spatial;big data;group by;join;polygon;query processing;scalable;aggregation;polygonization;doubly-connected edge list;distributed systems","Roads;Big Data;Spatial databases;Mobile handsets;Internet of Things;Data mining","","","","10","IEEE","25 Aug 2022","","","IEEE","IEEE Conferences"
"embServe: Embedded Services for Constrained Devices","J. Oliveira; F. Sousa; L. Almeida","Fraunhofer Portugal AICOS, Porto, Portugal; Fraunhofer Portugal AICOS, Porto, Portugal; CISTER / FEUP - University of Porto, Porto, Portugal","2023 IEEE 19th International Conference on Factory Communication Systems (WFCS)","7 Jun 2023","2023","","","1","8","Implementing, managing and updating large-scale complex IoT applications is still a non-trivial challenge. Service Oriented Architectures (SOA) are increasingly used for this purpose, given their well-defined communication interfaces and configurable service-to-service links that ease the implementation of complex data flows. However, these architectures usually stop at the edge, not supporting far-edge resource-constrained devices. This paper proposes embServe, a new service-oriented framework that enables SOA on networks of constrained devices. It allows users to deploy services compiled independently of the base application and configure their connections using standard IoT protocols and data models. We compared a reference implementation against traditional approaches. Results show that embServe reduces resource overhead with a subtle impact on computing performance while improving application response time and uptime.","2835-8414","978-1-6654-6432-1","10.1109/WFCS57264.2023.10144123","Portuguese Foundation for Science and Technology(grant numbers:UIDB/04234/2020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10144123","Internet of Things;Constrained Devices;Software-Oriented Architecture;Edge Computing;Far-Edge","Performance evaluation;Protocols;Codes;Runtime;Quality of service;Service-oriented architecture;Time factors","","","","17","IEEE","7 Jun 2023","","","IEEE","IEEE Conferences"
"FORESEEN: Towards Differentially Private Deep Inference for Intelligent Internet of Things","L. Lyu; J. C. Bezdek; J. Jin; Y. Yang","Department of Computer Science, National University of Singapore, Singapore; Department of Computing and Information Systems, The University of Melbourne, Parkville, Australia; School of Software and Electrical Engineering, Swinburne University of Technology, Melbourne, Australia; Shanghai Institute of Fog Computing Technology (SHIFT), SCA and SIST, ShanghaiTech University, Shanghai, China","IEEE Journal on Selected Areas in Communications","15 Sep 2020","2020","38","10","2418","2429","In state-of-the-art deep learning, centralized deep learning forces end devices to pool their data in the cloud in order to train a global model on the joint data, while distributed deep learning requires a parameter server to mediate the training process among multiple end devices. However, none of these architectures scale gracefully to large-scale privacy and time-sensitive IoT applications. Therefore, we are motivated to propose a FOg-based pRivacy prEServing dEep lEarNing framework named FORESEEN, so as to achieve scalable, accurate yet private analytics. In FORESEEN, the intermediate fog nodes and the cloud collaboratively perform noisy training of deep neural networks (DNNs), while each end device and its connected fog node collaboratively perform fast, private yet accurate inference. To enhance robustness and ensure privacy, we put forward a collaborative noisy training algorithm and develop a novel representation perturber to perturb the extracted features by combining random projection, random noise addition and data nullification. To meet the required constraints of accuracy, memory and energy in IoT end devices, we build deep models with mixed-precision. Through these sophisticated designs, FORESEEN is able to not only preserve privacy but also maintain comparable inference performance. Extensive experimental results under different datasets, different inference schemes and different noise addition strategies validate the effectiveness of FORESEEN. Moreover, FORESEEN is capable of reducing the communication cost and providing inherent support for robustness and scalability.","1558-0008","","10.1109/JSAC.2020.3000374","National Basic Research Program of China (973 Program)(grant numbers:YFB0102104); National Natural Science Foundation of China (NSFC) Key Project Program(grant numbers:61932014); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9110605","Privacy-preserving;deep learning;fog computing;differential privacy","Deep learning;Computational modeling;Privacy;Training;Data privacy;Cloud computing;Feature extraction","","15","","31","IEEE","8 Jun 2020","","","IEEE","IEEE Journals"
"Small Object Detection in Complex Large Scale Spatial Image by Concatenating SRGAN and Multi-Task WGAN","Y. Fu; C. Zheng; L. Yuan; H. Chen; J. Nie","College of Information Science and Engineering, Ocean University of China, Qingdao, China; College of Information Science and Engineering, Ocean University of China, Qingdao, China; College of Information Science and Engineering, Ocean University of China, Qingdao, China; College of Information Science and Engineering, Ocean University of China, Qingdao, China; College of Information Science and Engineering, Ocean University of China, Qingdao, China","2021 7th International Conference on Big Data Computing and Communications (BigCom)","1 Oct 2021","2021","","","196","203","With rapid development of IOT, especially in the field of geological exploration, areal images obtained through optical sensors with large spatial coverage are becoming an effective material for earth understanding. As such that research on object detection among large scale spatial image is of great significance for resource exploration, natural disaster assessment, and military target detection and recognition. Compared with common images, object detection in spatial image is still a big challenge because of the spatial heterogeneity, scale dependency and with complex context. In order to solve this problem, we propose a novel framework by concatenating a super resolution GAN (SRGAN) and a multitask Wasserstein GAN (WGAN) to increase the performance of a backbone detection model, like RetinaNet. Here, SRGAN and WGAN act as image restoration module attempt to increase global and local resolution respectively. To be exactly, the SRGAN is applied to the global image before detection, while the WGAN is applied to the anchor regions after detection. Unlike previous method with unique generative task, our WGAN is designed to complete generation, classification and regression tasks, with which can increase the detection performance comprehensively by back propagating classification loss and regression loss to the generator to remove false positive anchors and regulate the region box. In order to verify the effectiveness of the proposed model, we conducted a large number of ablation and comparative experiments on the public areal image dataset DOTA, and obtained superior average precision for small object detection.","","978-1-6654-4252-7","10.1109/BigCom53800.2021.00017","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9546851","Small Object Detection;RetinaNet;SRGAN;WGAN;super-resolution","Training;Target recognition;Superresolution;Object detection;Propagation losses;Generators;Image restoration","","","","17","IEEE","1 Oct 2021","","","IEEE","IEEE Conferences"
"A Vertical 2T NOR (V2T) Architecture to Enable Scaling and Low-Power Solutions for NOR Flash Technology","H. -T. Lue; T. -H. Hsu; T. -H. Yeh; W. -C. Chen; C. R. Lo; C. -T. Huang; G. -R. Lee; C. -J. Chiu; K. -C. Wang; C. -Y. Lu",NA; NA; NA; NA; NA; NA; NA; NA; NA; NA,"2020 IEEE Symposium on VLSI Technology","2 Dec 2020","2020","","","1","2","NOR Flash has stopped scaling for many years. However, recently there are increasingly new demands of NOR Flash in various 5G and IoT applications or wearable devices that strongly require new technology advancement of NOR. In this work, we developed a new vertical 2T (V2T) NOR Flash architecture that provides not only scaling capability but also low-power solutions. We leveraged the process of standard 3D NAND to develop a vertical 2T NOR that produces even smaller cell size than conventional planar 1T NOR. Advanced high-K metal-gate (HK/MG) integration is developed to provide high-performance BE-MANOS charge-trapping device with excellent 1M endurance and retention reliability. The 2T NOR architecture provides low-voltage read (~1V) that is compatible with advanced CMOS circuits without charge pumping to save power. We also suggest future technology extensions of the V2T NOR by adopting the ferroelectric memory devices (FeFET) and the 3DIC chiplets integration to broaden the applications fields of NOR technology in embedded Flash and computing in memory (CIM).","2158-9682","978-1-7281-6460-1","10.1109/VLSITechnology18217.2020.9265037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9265037","","Logic gates;Erbium;Computer architecture;Three-dimensional displays;Low voltage;Microprocessors;Very large scale integration","","10","","5","IEEE","2 Dec 2020","","","IEEE","IEEE Conferences"
"When Directory Design Meets Data Explosion: Rethinking Query Performance for IoT","L. Hao; H. Schulzrinne","Department of Computer Science, Columbia University, New York, NY, USA; Department of Computer Science, Columbia University, New York, NY, USA","2020 International Symposium on Networks, Computers and Communications (ISNCC)","25 Dec 2020","2020","","","1","6","As IoT services scale up from single homes to smart cities, directories and mapping services are needed to manage potentially millions of devices. However, directory service providers will likely struggle to accommodate the increasing number of IoT devices, made more challenging by their heterogeneous metadata and the large volume of queries. One of the critical challenges, the high heterogeneity of IoT, is being addressed by a working standard of W3C, which formalizes a physical or virtual device as a formatted Thing Description (TD).We propose a local directory service architecture with a series of design requirements. With a focus on query performance, we build a proof-of-concept system to store metadata of IoT devices as TDs in terms of the working standard. A Raspberry Pi is configured to investigate the query performance of relational database and non-relational database as the classic choices for internal directories. Evaluation results demonstrate that compared with relational database, non-relational database can achieve 2.9 times higher resilience on property query and 2.35 times faster processing on spatial query, with mild loss on aggregation query.","","978-1-7281-5628-6","10.1109/ISNCC49221.2020.9297269","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9297269","","Databases;Internet of Things;Metadata;Performance evaluation;Standards;Servers;Resource description framework","","2","","18","IEEE","25 Dec 2020","","","IEEE","IEEE Conferences"
"Real-Time Jamming Detection in Wireless IoT Networks","F. T. Zahra; Y. S. Bostanci; M. Soyturk","Vehicular Networking and Intelligent Transportation Systems Research Laboratory, Marmara University, İstanbul, Turkey; Vehicular Networking and Intelligent Transportation Systems Research Laboratory, Marmara University, İstanbul, Turkey; Vehicular Networking and Intelligent Transportation Systems Research Laboratory, Marmara University, İstanbul, Turkey","IEEE Access","25 Jul 2023","2023","11","","70425","70442","IoT-based networks are vulnerable to jamming attacks due to their large-scale deployment and shared communication environment. Resource constraints and the low computational power of IoT devices make it harder to implement high-performance ML-based architectures for jamming detection. In this work, the effects of jamming attacks on a Wi-Fi network are presented and a novel real-time jamming detection mechanism is devised which can identify attacks on multiple channels in 2.4 GHz bandwidth simultaneously. The experiments are conducted in the lab environment by generating the jamming attacks with a Software Defined Radio. Certain QoS parameters in an end-to-end wireless IoT system are collected during normal operating conditions and during jamming attacks. The detection mechanism is implemented on IoT devices by employing the effects of jamming on wireless communication. The proposed real-time jamming detection method has an accuracy of 99% with zero false alarms. It benefits from the communication profile of a wireless network to detect jamming and requires minimal computational resources regarding memory and CPU usage which makes it a low-cost and easily deployable solution for IoT devices.","2169-3536","","10.1109/ACCESS.2023.3293404","InSecTT and BEYOND5 projects; Electronic Component Systems for European Leadership Joint Undertaking (ECSEL JU) and TUBITAK(grant numbers:876038,876124); respectively; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10175509","IoT;jamming detection;wireless communication;WiFi;SDR;real-time","Jamming;Internet of Things;Wireless fidelity;Real-time systems;Communication system security;Wireless networks;Throughput","","1","","43","CCBYNCND","7 Jul 2023","","","IEEE","IEEE Journals"
"UAV Trajectory Planning for Data Collection from Time-Constrained IoT Devices","M. Samir; S. Sharafeddine; C. M. Assi; T. M. Nguyen; A. Ghrayeb","Concordia Institute for Information Systems Engineering, Concordia University, Montreal, Canada; Department of Computer Science and Mathematics, Lebanese American University, Beirut, Lebanon; Concordia Institute for Information Systems Engineering, Concordia University, Montreal, Canada; École de Technologie Supérieure, Montreal, Canada; Electrical and Computer Engineering Department, Texas A&M University at Qatar, Doha, Qatar","IEEE Transactions on Wireless Communications","8 Jan 2020","2020","19","1","34","46","The global evolution of wireless technologies and intelligent sensing devices are transforming the realization of smart cities. Among the myriad of use cases, there is a need to support applications whereby low-resource IoT devices need to upload their sensor data to a remote control centre by target hard deadlines; otherwise, the data becomes outdated and loses its value, for example, in emergency or industrial control scenarios. In addition, the IoT devices can be either located in remote areas with limited wireless coverage or in dense areas with relatively low quality of service. This motivates the utilization of UAVs to offload traffic from existing wireless networks by collecting data from time-constrained IoT devices with performance guarantees. To this end, we jointly optimize the trajectory of a UAV and the radio resource allocation to maximize the number of served IoT devices, where each device has its own target data upload deadline. The formulated optimization problem is shown to be mixed integer non-convex and generally NP-hard. To solve it, we first propose the high-complexity branch, reduce and bound (BRB) algorithm to find the global optimal solution for relatively small scale scenarios. Then, we develop an effective sub-optimal algorithm based on successive convex approximation in order to obtain results for larger networks. Next, we propose an extension algorithm to further minimize the UAV's flight distance for cases where the initial and final UAV locations are known a priori. We demonstrate the favourable characteristics of the algorithms via extensive simulations and analysis as a function of various system parameters, with benchmarking against two greedy algorithms based on distance and deadline metrics.","1558-2248","","10.1109/TWC.2019.2940447","Concordia University; Fonds Québécois de la Recherche sur la Nature et les Technologies; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8842600","Unmanned aerial vehicle (UAV);IoT devices;timely data collection;resource allocation","Trajectory;Data collection;Internet of Things;Unmanned aerial vehicles;Resource management;Wireless communication;Smart cities","","238","","39","IEEE","17 Sep 2019","","","IEEE","IEEE Journals"
"Research on Optimal Management and Flexible Control Method of Reactive Power Voltage for Distributed PV Users in Distribution Station Area","B. Zhang; J. Lei; X. Feng; Y. Xu; L. Xu","Wuxi Power Supply Company of State Grid Jiangsu Electric Power Co., Ltd, Wuxi, China; State Grid Shanghai Energy Interconnection Research Institute Co. Ltd, Nanjing, China; State Grid Shanghai Energy Interconnection Research Institute Co. Ltd, Nanjing, China; Wuxi Power Supply Company of State Grid Jiangsu Electric Power Co., Ltd, Wuxi, China; Wuxi Power Supply Company of State Grid Jiangsu Electric Power Co., Ltd, Wuxi, China","2023 3rd International Conference on Energy, Power and Electrical Engineering (EPEE)","25 Dec 2023","2023","","","1325","1332","With the large-scale grid-connection of distributed PV, the distributed PV users at the end of the low-voltage distribution station area have the problem of voltage exceeding the limit, and even the situation of burning the photovoltaic inverter and the distribution transformer, which seriously affects the operation safety of the distribution network. Aiming at the problems such as high cost and difficult implementation of existing control methods, a reactive power and voltage optimal management and flexible control method and system of distributed photovoltaic inverters based on distribution transformer supervisory terminal unit (TTU) of the station are proposed. Based on the EC-IoT technology architecture, the method and system make full use of the residual reactive power capacity of photovoltaic inverters and combine with the reactive power compensation equipment in the station area to propose a unified and coordinated control strategy for voltage control in the station area. Finally, the actual output and load data of distributed PV users in a distribution area of China are used for simulation analysis, field tests and applications. The application results show that the distributed resource coordination control APP embedded in TTU proposed in this paper can realize real-time and accurate adjustment of the reactive power output of photovoltaic inverters, without transforming the distribution network lines or restricting the distributed photovoltaic active power output, effectively improve the voltage quality of the station area, and avoid the problems such as frequent start and stop of the inverter caused by grid-connected overvoltage of photovoltaic users, and voltage fluctuations or even oscillations caused by the self-regulation of multiple inverters and other problems. The method proposed in this paper provides a good reference case for solving the problem of end-user voltage over-limit caused by large-scale distributed PV grid-connection.","","979-8-3503-1818-0","10.1109/EPEE59859.2023.10351833","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10351833","Voltage over limit;photovoltaic inverter;reactive power optimization;distribution area;comprehensive management and flexible control","Photovoltaic systems;Wireless communication;Reactive power;Costs;Voltage fluctuations;Distribution networks;Transformers","","","","11","IEEE","25 Dec 2023","","","IEEE","IEEE Conferences"
"Design and Fabrication of IoT based Agricultural Automation system","S. Rode; R. Saraf; J. Veigas; N. Shetty; S. Shardul","Department of Mechanical Engineering, Fr. C. Rodrigues Institute of Technology, Navi Mumbai, India; Department of Mechanical Engineering, Fr. C. Rodrigues Institute of Technology, Navi Mumbai, India; Department of Mechanical Engineering, Fr. C. Rodrigues Institute of Technology, Navi Mumbai, India; Department of Mechanical Engineering, Fr. C. Rodrigues Institute of Technology, Navi Mumbai, India; Department of Mechanical Engineering, Fr. C. Rodrigues Institute of Technology, Navi Mumbai, India","2023 5th Biennial International Conference on Nascent Technologies in Engineering (ICNTE)","12 Jun 2023","2023","","","1","6","The paper illustrates the use of smart devices and digitization to achieve agricultural process automation and increased yield of crops. Crops need fertilizers in the form of NP-K and water in a specific quantity and time. Current process of watering and adding fertilizers to specific plants is closely studied and correlated data on growth rates and fertilizer requirement is collected. This data is integrated into the smart Fertigation system which uses multiple sensors and smart devices. This system is then used to carry out controlled drip irrigation-based fertilization and irrigation of crops. An experimental setup for the same is deployed in a lab like environment using sensors to monitor parameters such as pH level of the soil, TDS values, temperature, humidity at a given time of the day, Arduino based actuator circuit is deployed for remote operations and control systems and additionally the remote data collection/control is enabled using Python and Google APIs. This fully functional IoT fertigation system collected data as illustrated in the paper. A correlation is drawn between the sensor actual data and control parameters of fertilizer and water supplied to the soil. This paper evaluates the viability of such a system in a controlled environment and further scaling of this system for farmers benefit to autonomously manage large land parcels based on weather data and soil characteristics.","","978-1-6654-6504-5","10.1109/ICNTE56631.2023.10146721","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10146721","Agriculture;automation;IoT;fertigation","Temperature sensors;Automation;Crops;Soil;Sensor phenomena and characterization;Control systems;Sensor systems","","","","9","IEEE","12 Jun 2023","","","IEEE","IEEE Conferences"
"Smart Irrigation Systems: Soil Monitoring and Disease Detection for Precision Agriculture","P. Peddi; A. Dasgupta; V. H. Gaidhane","Department Electrical and Electronics Engineering, Birla Institute of Technology and Science Pilani, Dubai Campus, Dubai, UAE; Department Electrical and Electronics Engineering, Birla Institute of Technology and Science Pilani, Dubai Campus, Dubai, UAE; Department Electrical and Electronics Engineering and APPCAIR, Birla Institute of Technology and Science Pilani, Dubai Campus, Dubai, UAE","2022 IEEE International IOT, Electronics and Mechatronics Conference (IEMTRONICS)","20 Jun 2022","2022","","","1","7","Smart farming is an evolving concept in the field of information and communications technology. In this, the IoT sensors and image processing is used to establish transparent mechanisms of feedback about the growth and productivity of crops and the environmental surrounding conditions. In this paper, the solution of the aforementioned problem statement in the form of an accountable live information system of the cultivated crops to yield efficiency has been presented. The feedback mechanism consists of monitoring parameters like temperature, humidity, weather, soil and crop moisture, crop health, etc. It provides the information between the planting phase and the harvesting phase to facilitate soil management and climate forecasting in real time. The proposed paper suggests the use of an open data platform, namely Adafruit IO, for visualizing and analyzing real-time in the IoT integrated system. Further, image processing approach has been used for crop remotely health monitoring for 2 widespread diseases namely, Glomeralla Cingulata and Phaeoisariopsis Bataticola. Owing to the economical nature and the ergonomic design of the proposed system, it has the feasibility of being implemented on a large scale in water scarce economies aiming to build a sustainable smart farming infrastructure by automating existing irrigation systems.","","978-1-6654-8684-2","10.1109/IEMTRONICS55184.2022.9795747","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9795747","","Training;Irrigation;Webcams;Image processing;Crops;Soil;Real-time systems","","2","","18","IEEE","20 Jun 2022","","","IEEE","IEEE Conferences"
"IoT-based Office Buildings Energy Management with Distributed Edge Computing Capability","M. N. Moghadam; M. Abapour","Greater Tehran Electricity Distribution Company, Tehran, Iran; Faculty of Electrical and Computer Engineering, University of Tabriz, Tabriz, Iran","2023 8th International Conference on Technology and Energy Management (ICTEM)","4 Apr 2023","2023","","","1","5","Building Energy Management systems (BEMS) are becoming very popular, for providing net Zero Energy Buildings (nZEBs). Attachment of these systems through IoT technologies, enables the building owners as well as utility companies to control energy's usage, generation, and storage in a more smart and real time manner, which is the foundational concept for Internet of Energy (IoE). High number of buildings especially in metropolitan areas imposes high amount of computation resources and increased communication and computation delays to the central cloud servers. In this paper, we first describe the details of a real IoT-based large scale deployment of office buildings energy management system in Greater Tehran Electricity Distribution Company (GTEDC), and then we propose an edge computing solution to reduce the complexity and delay of data dissemination in the system expansion phase.","","978-1-6654-5285-4","10.1109/ICTEM56862.2023.10083681","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10083681","Building Energy Management;Internet of Things;Internet of Energy;Edge Computing;Cloud Computing","Cloud computing;Urban areas;Companies;Control systems;Real-time systems;Delays;Servers","","1","","13","IEEE","4 Apr 2023","","","IEEE","IEEE Conferences"
"AoI-Constrained Energy Efficiency Optimization in Random-Access Poisson Networks","F. Zhao; X. Sun; W. Zhan; B. Zhou; X. Huang","School of Electronics and Communication Engineering, Shenzhen Campus of Sun Yat-sen University; School of Electronics and Communication Engineering, Shenzhen Campus of Sun Yat-sen University; School of Electronics and Communication Engineering, Shenzhen Campus of Sun Yat-sen University; School of Electronics and Communication Engineering, Shenzhen Campus of Sun Yat-sen University; School of Electronics and Communication Engineering, Shenzhen Campus of Sun Yat-sen University","2022 IEEE Wireless Communications and Networking Conference (WCNC)","16 May 2022","2022","","","1123","1128","For battery-limited IoT networks, the energy efficiency and Age of Information (AoI) are two key performance metrics. Yet the tradeoff between energy efficiency and AoI remains unclear for large-scale networks since the analysis becomes challenging due to the couple queue problem. This paper aims to address this issue by studying the performance limit of energy efficiency under AoI constraint.Specifically, we evaluate the energy efficiency via the expected number of successfully transmitted packets during each transmitter’s life time for which the explicit expression is derived based on the spatio-temporal analytical framework in [1]. By further taking the AoI constraint into consideration, explicit expressions of the Maximum Expected Number of Successfully Transmitted Packets (MENSTP) and the corresponding channel access probability are obtained. The analysis reveals that if the Power Ratio of the Transmission state and the Waiting state (PRTW) equals one, i.e., the energy consumption per time slot of the transmission state equals to that of the waiting state, then the expected number of successfully transmitted packets during each transmitter’s life time and the peak AoI can be optimized simultaneously; otherwise, the MENSTP declines with a stringent AoI constraint. Moreover, the performance gap enlarges when the PRTW or the node distribution density increases which reveals a crucial tradeoff between the energy efficiency and AoI. It is therefore of importance to properly tuning the channel access probability to strike an optimal energy-age tradeoff in battery-limited large-scale IoT networks.","1558-2612","978-1-6654-4266-4","10.1109/WCNC51071.2022.9771861","National Natural Science Foundation of China; National Natural Science Foundation of China; Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9771861","Energy efficiency;age of information;random access","Measurement;Energy consumption;Conferences;Information age;Energy efficiency;Tuning;Queueing analysis","","1","","13","IEEE","16 May 2022","","","IEEE","IEEE Conferences"
"Experimentally Analyzing Diverse Antenna Placements and Orientations for UAV Communications","M. Badi; J. Wensowitch; D. Rajan; J. Camp","Department of Electrical and Computer Engineering, Southern Methodist University, Dallas, TX, USA; Department of Electrical and Computer Engineering, Southern Methodist University, Dallas, TX, USA; Department of Electrical and Computer Engineering, Southern Methodist University, Dallas, TX, USA; Department of Electrical and Computer Engineering, Southern Methodist University, Dallas, TX, USA","IEEE Transactions on Vehicular Technology","22 Jan 2021","2020","69","12","14989","15004","A vast array of potential applications is emerging for drones and other devices to collaborate from disaster relief and search and rescue missions to smart agriculture and IoT systems. As drones move across multiple altitudes, they must have the ability to communicate across any direction in a three-dimensional (3D) space. However, due to the heterogeneous nature of the drone body and its interaction with the mounted antennas, different antenna positions on the drone can result in variations in the radiation pattern. While there have been a fair number of airborne communication works, few consider the role that antenna positioning has on the resulting transmission along the azimuth and elevation planes. In this work, we study the effects of the drone body and various antenna placements on the radiation pattern and fading of drone-based channels. Through systematic anechoic chamber and in-field measurements, we show that the drone body alters the radiation pattern of the mounted antennas, rendering the common assumption of a constant azimuth radiation pattern invalid. In addition, the body increases polarization mixing of drone-based channels, resulting in significant degradation of the cross-polarization discrimination (XPD). Hence, we propose using effective radiation pattern and XPD values instead of relying on measurements and/or assumptions that disregard drone-antenna interaction. We then analyze the shadowing and losses associated with the drone body for many antenna setups at various elevation angles and show that when mounted on the opposite side from the ground transmitter, shadowing increases with relatively-higher drone elevations. To account for these body-induced effects, we introduce rotational loss that results in better prediction results of the large-scale fading behavior compared to conventional models that neglect these body effects. Then, we analyze the small-scale fading for various antenna setups and show that the Rician K-factor is strongly dependent on elevation for polarization-matched vertical links, while it is approximately flat for cross-polarized links. To do so, we conduct a set of drone-to-drone (DtD) experiments at high altitudes with no surrounding reflectors and compare results to those obtained by our ground-to-drone (GtD) measurements. We find that, while at low elevations the ground can reduce the K-factor by 10 dB, at higher elevations, small-scale fading is dominated by the antennas, not the ground.","1939-9359","","10.1109/TVT.2020.3031872","NSF(grant numbers:CNS-1823304); Air Force Office of Scientific Research(grant numbers:FA9550-19-1-0375); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9229122","MIMO;cross-polarization discrimination;drone-to-drone channels;UAV body effects;3D communications","Drones;Antenna radiation patterns;Antenna measurements;Fading channels;MIMO communication;Azimuth","","16","","59","IEEE","19 Oct 2020","","","IEEE","IEEE Journals"
"Indoor Navigation System for Evacuation Route in case of Fire by using Environment and Location Data","S. Lee; S. Park; S. Kim; S. H. Lee; S. Lee; S. Park","Chung-Ang University, Seoul, Korea; Chung-Ang University, Seoul, Korea; Chung-Ang University, Seoul, Korea; Chung-Ang University, Seoul, Korea; Chung-Ang University, Seoul, Korea; Chung-Ang University, Seoul, Korea","2020 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-Taiwan)","23 Nov 2020","2020","","","1","2","In the case of high-rise buildings with more than five floors, there is a greater risk of a large number of casualties due to the spread of large-scale fires when a fire occurs. To overcome this problem, the indoor navigation system was implemented using the IoT devices installed in the building and AR technology to guide the evacuation route reflecting the fire situation. It describes the member and function of the system and mentions the parts that need to be supplemented and how to solve them.","2575-8284","978-1-7281-7399-3","10.1109/ICCE-Taiwan49838.2020.9258143","Korea Institute of Energy Technology Evaluation and Planning(grant numbers:20184030202070); MOTIE(grant numbers:20192710100151); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9258143","","Buildings;Servers;Mobile applications;Indoor navigation;Augmented reality;Clouds;Logic gates","","","","4","IEEE","23 Nov 2020","","","IEEE","IEEE Conferences"
"Lung Cancer Detection using Deep Learning Approach CNN","M. Praveena; A. Ravi; T. Srikanth; B. H. Praveen; B. S. Krishna; A. S. Mallik","Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation, Guntur, AP, India; Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation, Guntur, AP, India; Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation, Guntur, AP, India; Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation, Guntur, AP, India; Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation, Guntur, AP, India; Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation, Guntur, AP, India","2022 7th International Conference on Communication and Electronics Systems (ICCES)","29 Jul 2022","2022","","","1418","1423","Thoracic radiography (chest X-ray) is a low-cost scientific imaging approach that is quite successful. However, because to a scarcity of skilled radiologists, the technique’s utility is severely limited. Even recent Deep Learning-based solutions sometimes require a lot of supervision to educate such systems, such as annotated bounding boxes, which is difficult to harvest on a large scale. This study recommends that frontal thoracic X-rays be classified and forecasted using a modified model called MobileNet V2. Every year, Computed Tomography (CT) should save a huge number of lives by finding most tumors early on. However, radiologists confront a significant task in analyzing many these images, and they frequently suffer from observer fatigue, which can affect their performance. As a result, it is necessary to read, identify, and consider CT images quickly. Using the NIH Chest-Xray-14 database, the overall performance of this technique is compared to the current modern-day pathology classification algorithms. Inconsistencies in classifiers were originally investigated using the Area Under the receiver operating characteristic Curve (AUC) data. Overall, the obtained result has a wide range, with an AUC of 0.811 and an accuracy of more than 90%. It is concluded that resampling the dataset improves the model’s performance significantly. The goal is to design a model that could be taught, as well as modified units that used less computational energy and could be used in smaller IoT devices.","","978-1-6654-9634-6","10.1109/ICCES54183.2022.9835794","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9835794","Thoracic radiography;computed tomography;chest CT scans;CNN (Convolutional Neural Network);Deep Learning;ConvNets;pulmonary disorders;MobileNet V2;ROC curve","Solid modeling;Three-dimensional displays;Computed tomography;Computational modeling;X-rays;Mathematical models;Convolutional neural networks","","6","","17","IEEE","29 Jul 2022","","","IEEE","IEEE Conferences"
"Installation of Automated Sericulture Functional Unit in Rural Area","K. L. Joshitha; K. V. Rithwik","Dept of ECE, Sri Sai Ram Engineering College, Chennai-44; System Engineer Tata Consultancy services, Chennai","2021 4th International Conference on Computing and Communications Technologies (ICCCT)","18 Feb 2022","2021","","","43","45","Out of the major small scale cottage industrial sectors that fetches good revenue for our country the most fascinating one is the sericulture industry. The specialty of this sector is due to the large usage and craze of the Indian women using silk wardrobes. The tradition and culture of most of the south Indians make it a pride in the usage of silk materials on special occasions. The rearing of the silkworm demands a time constrained monitoring task which involves lot of human intervention. The business involves less investment but requires much of human skill to earn the returns. The proposed work tries to automate the silkworm rearing system by implementing an IoT based functional unit with sensors for continuous monitoring of the essential parameters and controlling operation. The objective of the work is to provide a congenial environment for rearing of cocoons and to improve the cocoon shell percentage and the reel ability parameter of the developed cocoons.","","978-1-6654-1447-0","10.1109/ICCCT53315.2021.9711911","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9711911","Sericulture;rearing;automation;monitoring;IoT;sensors","Industries;Sensor systems;Communications technology;Sensors;Time factors;Task analysis;Monitoring","","1","","10","IEEE","18 Feb 2022","","","IEEE","IEEE Conferences"
"Autonomous Robotic Arm for Object Sorting and Motion Compensation using Kalman Filter","M. A. Ndambani; T. Fang; J. Saniie","Department of Electrical and Computer Engineering, Embedded Computing and Signal Processing (ECASP) Research Laboratory, Illinois Institute of Technology, Chicago, Illinois, U.S.A; Department of Electrical and Computer Engineering, Embedded Computing and Signal Processing (ECASP) Research Laboratory, Illinois Institute of Technology, Chicago, Illinois, U.S.A; Department of Electrical and Computer Engineering, Embedded Computing and Signal Processing (ECASP) Research Laboratory, Illinois Institute of Technology, Chicago, Illinois, U.S.A","2022 IEEE International Conference on Electro Information Technology (eIT)","7 Jul 2022","2022","","","488","491","Robotic arm has played a key role in the industry for more than a half-century. Although robotic arms have superior accuracy and efficiency, they are not always cost-effective, especially for small-scale applications. This paper proposes an autonomous robotic arm system that can identify, sort, and interact with different objects, using IoT devices. For precision robotic arm movement, we have developed a Kalman filter-based motion compensation system. The embedded computing system is used for real-time object recognition and motion compensation. Experimental results show that the proposed high precision autonomous robotic arm system can recognize objects with 95% accuracy, and locate and sort the moving objects with a mean error of 1.1mm.","2154-0373","978-1-6654-8009-3","10.1109/eIT53891.2022.9814075","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9814075","Robotic arm;Computer vision;Kalman filter;Electromagnets","Computer vision;Service robots;Neural networks;Manipulators;Prediction algorithms;Motion compensation;Real-time systems","","1","","10","IEEE","7 Jul 2022","","","IEEE","IEEE Conferences"
"Recent Progress and Performance Analysis on Durability Evaluation and rRemaining useful life Prediction Technology Development for the Life Extension of Wind Turbines in Korea","S. -J. Lee; C. Kim; I. -K. Yu; M. -T. Ngo; M. -C. Dinh; M. Park","Institute of Mechatronics, Changwon National University, Changwon City, Korea; Institute of Mechatronics, Changwon National University, Changwon City, Korea; Institute of Mechatronics, Changwon National University, Changwon City, Korea; Institute of Mechatronics, Changwon National University, Changwon City, Korea; Institute of Mechatronics, Changwon National University, Changwon City, Korea; Department of Electrical Engineering, Changwon National University, Changwon City, Korea","2023 12th International Conference on Renewable Energy Research and Applications (ICRERA)","6 Oct 2023","2023","","","339","343","The digitalization of wind power generation is rapidly progressing with the development of ICT technologies such as big data, IoT, and artificial intelligence, along with the trend of large-scale wind power generation and the expansion of offshore wind power generation. As the number of wind turbines installed in power generation complexes decreases due to the increasing size of turbines, the availability, reliability, efficiency, and lifespan of each wind turbine are becoming increasingly important. In particular, digital twin technology for high-efficiency operation is expected to accelerate due to the large-scale expansion of offshore wind power and the increase in operation and maintenance (O&M) costs resulting from the scale and aging of turbines. In this paper, we intend to establish a foundation for extending the lifespan of wind turbines through performance analysis and durability evaluation of Korean wind turbines, as well as the development of remaining life prediction technology. To predict the remaining life of a wind turbine, we selected crucial components based on failure rates and downtime, focusing on identifying the core parts of the turbine. Actual SCADA and CMS operational data for key components were acquired, and system performance was analyzed using artificial intelligence and knowledge-based condition diagnosis algorithms. The remaining life prediction program will be enhanced using real-time sensor data obtained from the following performance analysis. The final outcome will be applied to real wind turbines in Korea for a long-term demonstration.","2572-6013","979-8-3503-3793-8","10.1109/ICRERA59003.2023.10269432","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10269432","Wind turbine system;Remaining useful life prediction;condition diagnosis","Renewable energy sources;System performance;Wind power generation;Maintenance engineering;Prediction algorithms;Market research;Real-time systems","","","","16","IEEE","6 Oct 2023","","","IEEE","IEEE Conferences"
"Monitoring and Control of PV Microgrid using IoT","V. Tiwari; S. Kumari; P. P. Sahoo","M. Tech- Electrical Power Systems NIT, Jamshedpur, Jharkhand, India; M. Tech- Electrical Power Systems NIT, Jamshedpur, Jharkhand, India; M. Tech- Electrical Power Systems NIT, Jamshedpur, Jharkhand, India","2021 7th International Conference on Electrical Energy Systems (ICEES)","26 Mar 2021","2021","","","292","298","A Microgrid (MG) is a small-scale power grid that can operate independently or collaboratively with other power grids. The practice of using MGs is known as distributed energy production (DER). Microgrid refers to the distributed energy sources which in turn can be connected to the main grid network or can be made standalone. IoT presents a solution for improving the performance of power generation in a distributed energy resources (DER) in MG. For multiple MG systems, IoT provides a method to interconnect all the system such that all the MG systems combines together and can be connected to grid simultaneously to support the load demand in peak time, which reduces the overall load on the power generation plant.","","978-1-7281-7612-3","10.1109/ICEES51510.2021.9383724","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9383724","Microgrid;IoT;Distributed Energy Resources (DER);Protocols;Real time monitoring","Portable computers;Microgrids;Production;Mobile handsets;Batteries;Monitoring;Load modeling","","","","14","IEEE","26 Mar 2021","","","IEEE","IEEE Conferences"
"Research on Smart Agriculture IoT System Based Heterogeneous Networking Technology","Y. Lu; J. An; S. Shi","Changchun University of Finance and Economics, Changchun, Jilin, China; Changchun University of Finance and Economics, Changchun, Jilin, China; Changchun University of Finance and Economics, Changchun, Jilin, China","2021 IEEE 4th International Conference on Information Systems and Computer Aided Education (ICISCAE)","11 Nov 2021","2021","","","485","488","Agriculture is the source of food and clothing for human society, the foundation of survival, the foundation of supporting the whole national economy, and the guarantee of continuous development and progress of society. Although China is a big agricultural country, China's agricultural competitiveness is still at a disadvantage compared with developed countries such as Europe and America. The main reason is that most areas of China are still in the mode of intensive farming and small-scale farming, relying mainly on abundant natural resources and low labor costs to gain international advantages. Information technology is used as a channel to connect all links of modern agriculture. Accurate, timely and effective acquisition, dissemination and application of information can greatly improve the level of agricultural management and promote the rapid development of agricultural economy. The emergence of the IoT provides a very favorable technical support for the development of smart agriculture. Under the background of big data era, this paper discusses how to effectively combine intelligent agriculture with IoT technology in China, and puts forward the construction method of intelligent agriculture IoT system based on heterogeneous networking technology, which is of positive significance to the development of agriculture.","","978-1-6654-4124-7","10.1109/ICISCAE52414.2021.9590756","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9590756","Big data;Smart agriculture;IoT","Wireless sensor networks;Technological innovation;Costs;Wireless networks;Production;Big Data;Agriculture","","5","","14","IEEE","11 Nov 2021","","","IEEE","IEEE Conferences"
"A General-Purpose CNN Accelerator Based on Improved Systolic Array for FPGAs","C. Yang; Y. Yang; W. Yang; L. Huang; Y. Li","College of Automation and Information Engineering, Xi’an University of Technology, Xi’an, China; College of Automation and Information Engineering, Xi’an University of Technology, Xi’an, China; College of Automation and Information Engineering, Xi’an University of Technology, Xi’an, China; College of Automation and Information Engineering, Xi’an University of Technology, Xi’an, China; College of Automation and Information Engineering, Xi’an University of Technology, Xi’an, China","2022 7th International Conference on Integrated Circuits and Microsystems (ICICM)","16 Jan 2023","2022","","","529","533","In recent years, convolutional neural networks have been increasingly used for processing image tasks, such as target recognition, image enhancement, and other areas. In the embedded and IoT fields, the small size and low-power application characteristics make it impractical to deploy high-performance computing devices on hardware platforms in this field. In this paper, a general neural network accelerator is designed that can be scaled to any size, which can be adapted to hardware platforms in different application areas including data centers and IoT according to power consumption and arithmetic power requirements. The accelerator is based on the improved systolic array, which improves the utilization and throughput of data and reduces the system power consumption. This paper uses int8 data type to match embedded and IoT low-power requirements. In this paper, the accelerator is deployed on the XC7Z020 hardware platform, compared with CPU and GPU platforms, and evaluate the performance of handwritten digit recognition neural network based on the Minist dataset. The experimental results show that the energy consumption ratio of the design in this paper is 10 times better compared to current advanced CPUs and GPUs, and more than 300 times better compared to current CPUs in the embedded domain.","","978-1-6654-6043-9","10.1109/ICICM56102.2022.10011386","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10011386","convolutional neural network;field programmable gate array;hardware acceleration;systolic array","Energy consumption;Power demand;Quantization (signal);Neural networks;Throughput;Systolic arrays;Hardware","","","","9","IEEE","16 Jan 2023","","","IEEE","IEEE Conferences"
"Towards Developing an IoT-Based Aquaculture Monitoring System","M. A. Arif; M. R. Reza; A. B. Mandal; M. A. Mahmud Akib; F. M. Shuma; S. S. M. Fehir","Dept. of CSE, University of Scholars, Dhaka, Bangladesh; Dept. of CSE, University of Scholars, Dhaka, Bangladesh; Dept. of CSE, Military Institute of Science and Technology, Dhaka, Bangladesh; Dept. of CSE, Asian University of Bangladesh, Dhaka, Bangladesh; Dept. of CSE, Asian University of Bangladesh, Dhaka, Bangladesh; Dept. of CSE, Asian University of Bangladesh, Dhaka, Bangladesh","2023 International Conference on Information and Communication Technology for Sustainable Development (ICICT4SD)","6 Nov 2023","2023","","","134","138","Aquaculture is one of the most important sectors for the economic development of a country. Although fish is the most common aquatic organism, the production of fish is greatly hampered every year because of inadequate monitoring of water contamination. Maintaining many factors, including temperature, pH, and turbidity, is crucial to prevent the contamination and proliferation of aquatic organisms. The conventional monitoring system exhibits intrinsic flaws, characterized by a lengthy and occasionally imprecise manual procedure that often fails to provide timely assistance to fish farmers. To mitigate this issue, an automated tool is much needed. Therefore, this study proposed an IoT-based system to monitor water quality in real-time. To determine whether the water is suitable for fish production, this system gathers data using different sensors. Moreover, an algorithm is developed to classify water quality by comparing real-time samples with the standard value. Thus, the system will set off an alarm and use IoT technology to notify the user of any irregularities in water quality. The system will remain immersed in the aquatic environment for 24 hours and will monitor any sudden change in water parameters. If critical conditions occur, an alert SMS will be sent to the user. Finally, this system is tested in ponds and bioflocs, followed by a functional accuracy test for its usability. The system is designed to be affordable, especially for small-scale farmers. It can be an aiding tool for farmers and will help boost their business as well as the economy of the country.","","979-8-3503-5866-7","10.1109/ICICT4SD59951.2023.10303402","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10303402","IoT;smart aquaculture;water pollution;water monitoring;fish production","Temperature sensors;Temperature measurement;Production;Fish;Real-time systems;Water pollution;Biomedical monitoring","","","","20","IEEE","6 Nov 2023","","","IEEE","IEEE Conferences"
"Decentralized Federated Learning Over Slotted ALOHA Wireless Mesh Networking","A. Salama; A. Stergioulis; A. M. Hayajneh; S. A. R. Zaidi; D. McLernon; I. Robertson","Department of Electrical and Electronic Engineering, University of Leeds, Leeds, U.K.; Department of Electrical and Electronic Engineering, University of Leeds, Leeds, U.K.; Department of Electrical Engineering, Faculty of Engineering, The Hashemite University, Zarqa, Jordan; Department of Electrical and Electronic Engineering, University of Leeds, Leeds, U.K.; Department of Electrical and Electronic Engineering, University of Leeds, Leeds, U.K.; Department of Electrical and Electronic Engineering, University of Leeds, Leeds, U.K.","IEEE Access","28 Feb 2023","2023","11","","18326","18342","Federated Learning (FL) presents a mechanism to allow decentralized training for machine learning (ML) models inherently enabling privacy preservation. The classical FL is implemented as a client-server system, which is known as Centralised Federated Learning (CFL). There are challenges inherent in CFL since all participants need to interact with a central server resulting in a potential communication bottleneck and a single point of failure. In addition, it is difficult to have a central server in some scenarios due to the implementation cost and complexity. This study aims to use Decentralized Federated learning (DFL) without a central server through one-hop neighbours. Such collaboration depends on the dynamics of communication networks, e.g., the topology of the network, the MAC protocol, and both large-scale and small-scale fading on links. In this paper, we employ stochastic geometry to model these dynamics explicitly, allowing us to quantify the performance of the DFL. The core objective is to achieve better classification without sacrificing privacy while accommodating for networking dynamics. In this paper, we are interested in how such topologies impact the performance of ML when deployed in practice. The proposed system is trained on a well-known MINST dataset for benchmarking, which contains labelled data samples of 60K images each with a size  $28\times 28$  pixels, and 1000 random samples of this MNIST dataset are assigned for each participant’ device. The participants’ devices implement a CNN model as a classifier model. To evaluate the performance of the model, a number of participants are randomly selected from the network. Due to randomness in the communication process, these participants interact with the random number of nodes in the neighbourhood to exchange model parameters which are subsequently used to update the participants’ individual models. These participants connected successfully with a varying number of neighbours to exchange parameters and update their global models. The results show that the classification prediction system was able to achieve higher than 95% accuracy using the three different model optimizers in the training settings (i.e., SGD, ADAM, and RMSprop optimizers). Consequently, the DFL over mesh networking shows more flexibility in IoT systems, which reduces the communication cost and increases the convergence speed which can outperform CFL.","2169-3536","","10.1109/ACCESS.2023.3246924","Engineering and Physical Sciences Research Council (EPSRC), U.K.(grant numbers:EP/S016813/1,EP/N010523/1); Royal Academy of Engineering, U.K.(grant numbers:122040); Transforming Systems through Partnership(grant numbers:TSP1040); Royal Academy through the Distinguished International Associates(grant numbers:DIA-2021-18); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10049061","Simplicity;privacy;federated learning;decentralization learning","Servers;Data models;Internet of Things;Performance evaluation;Federated learning;Data privacy;Learning systems","","6","","53","CCBY","20 Feb 2023","","","IEEE","IEEE Journals"
"Multi-UAV-Assisted Federated Learning for Energy-Aware Distributed Edge Training","J. Tang; J. Nie; Y. Zhang; Z. Xiong; W. Jiang; M. Guizani","State Key Laboratory of Public Big Data, Guizhou University, Guiyang, China; School of Computer Science and Engineering, Nanyang Technological University, Nanyang Ave, Singapore; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; Pillar of Information Systems Technology and Design, Singapore University of Technology and Design, Tampines, Singapore; Pillar of Information Systems Technology and Design, Singapore University of Technology and Design, Tampines, Singapore; Machine Learning Department, Mohamed Bin Zayedm University of Artificial Intelligence, Abu Dhabi, UAE","IEEE Transactions on Network and Service Management","7 Feb 2024","2024","21","1","280","294","Unmanned aerial vehicle (UAV)-assisted mobile edge computing (MEC) has largely extended the border and capacity of artificial intelligence of things (AIoT) by providing a key element for enabling flexible distributed data inputs, computing capacity, and high mobility. To enhance data privacy for AIoT applications, federated learning (FL) is becoming a potential solution to perform training tasks locally on distributed IoT devices. However, with the limited onboard resources and battery capacity of each UAV node, optimization is required to achieve a large-scale and high-precision FL scheme. In this work, an optimized multi-UAV-assisted FL framework is designed, where regular IoT devices are in charge of performing training tasks, and multiple UAVs are leveraged to execute local and global aggregation tasks. An online resource allocation (ORA) algorithm is proposed to minimize the training latency by jointly deciding the selection decisions of clients and a global aggregation server. By leveraging the Lyapunov optimization technique, virtual energy queues are studied to depict the energy deficit. With the help of the actor-critic learning framework, a deep reinforcement learning (DRL) scheme is designed to improve per-round training performance. A deep neural network (DNN)-based actor module is designed to derive client selection decisions, and a critic module is proposed through a conventional optimization method to evaluate the obtained selection decisions. Moreover, a greedy scheme is developed to find the optimal global aggregation server. Finally, extensive simulation results demonstrate that the proposed ORA algorithm can achieve optimal training latency and energy consumption under various system settings.","1932-4537","","10.1109/TNSM.2023.3298220","National Natural Science Foundation of China(grant numbers:62071343); National Research Foundation, Singapore, and Infocomm Media Development Authority under its Future Communications Research & Development Programme(grant numbers:SUTD SRG-ISTD-2021- 165); SUTD-ZJU IDEA(grant numbers:(SUTD-ZJU (VP) 202102)); Ministry of Education, Singapore, under its SUTD Kickstarter Initiative(grant numbers:(SKI 20210204)); National Science Foundation of China(grant numbers:62202118); Top Technology Talent Project from Guizhou Education Department(grant numbers:(Qianjiao Ji [2022]073)); Natural Science Foundation of Hebei Province(grant numbers:F2022203026); Science and Technology Project of Hebei Education Department(grant numbers:BJK2022029); Foundation of State Key Laboratory of Public Big Data(grant numbers:PBD2023-12); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10190740","UAV;federated learning;resource allocation;client selection;DRL","Training;Internet of Things;Autonomous aerial vehicles;Servers;Resource management;Task analysis;Performance evaluation","","1","","51","IEEE","24 Jul 2023","","","IEEE","IEEE Journals"
"A Review of Confidentiality Threats Against Embedded Neural Network Models","R. Joud; P. -A. Moëllic; R. Bernhard; J. -B. Rigaud","CEA Tech, Centre CMP, Equipe Commune CEA Tech - Mines Saint-Etienne, Gardanne, France; CEA Tech, Centre CMP, Equipe Commune CEA Tech - Mines Saint-Etienne, Gardanne, France; CEA Tech, Centre CMP, Equipe Commune CEA Tech - Mines Saint-Etienne, Gardanne, France; Mines Saint-Etienne, CEA Tech, SAS, Centre CMP, Gardanne, France","2021 IEEE 7th World Forum on Internet of Things (WF-IoT)","9 Nov 2021","2021","","","610","615","Utilization of Machine Learning (ML) algorithms, especially Deep Neural Network (DNN) models, becomes a widely accepted standard in many domains more particularly IoT-based systems. DNN models reach impressive performances in several sensitive fields such as medical diagnosis, smart transport or security threat detection, and represent a valuable piece of Intellectual Property. Over the last few years, a major trend is the large-scale deployment of models in a wide variety of devices. However, this migration to embedded systems is slowed down because of the broad spectrum of attacks threatening the integrity, confidentiality and availability of embedded models. In this review, we cover the landscape of attacks targeting the confidentiality of embedded DNN models that may have a major impact on critical IoT systems, with a particular focus on model extraction and data leakage. We highlight the fact that Side-Channel Analysis (SCA) is a relatively unexplored bias by which model’s confidentiality can be compromised. Input data, architecture or parameters of a model can be extracted from power or electromagnetic observations, testifying a real need from a security point of view.","","978-1-6654-4431-6","10.1109/WF-IoT51360.2021.9595434","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9595434","Machine Learning;Deep Neural Networks;Security;Attacks;Side-Channel Analysis","Performance evaluation;Analytical models;Microcontrollers;Neural networks;Training data;Data models;Data mining","","1","","31","IEEE","9 Nov 2021","","","IEEE","IEEE Conferences"
"Scalable and Fast Algorithm for Constructing Phylogenetic Trees With Application to IoT Malware Clustering","T. He; C. Han; R. Isawa; T. Takahashi; S. Kijima; J. Takeuchi","Graduate School and Faculty of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japan; National Institute of Information and Communications Technology, Koganei, Japan; National Institute of Information and Communications Technology, Koganei, Japan; National Institute of Information and Communications Technology, Koganei, Japan; Graduate School and Faculty of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japan; Graduate School and Faculty of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japan","IEEE Access","27 Jan 2023","2023","11","","8240","8253","With the development of IoT devices, there is a rapid increase in new types of IoT malware and variants, causing social problems. The malware’s phylogenetic tree has been used in many studies for malware clustering or better understanding of malware evolution. However, when dealing with a large-scale malware set, conventional methods for constructing a phylogenetic tree is very time-consuming or even cannot be done in a realistic time. To solve this problem, we propose a high-speed, scalable phylogenetic tree construction algorithm with a clustering algorithm to cluster it. The proposed method involves the following steps: (1) Calculating the similarity of the specimen pairs using the normalized compression distance. (2) Creating a phylogenetic tree containing all specimens, instead of calculating the similarity of all pairs of a specimen, our algorithm only calculates a small part of the similarity matrix. (3) Dividing the phylogenetic tree into clusters by applying the minimum description length criterion. In addition, we propose a new online processing algorithm to add new malware specimens into the existing phylogenetic tree sequentially. Our goal is to reduce the computational cost of constructing the phylogenetic tree and improve the clustering accuracy of our previous research. We evaluated our method’s clustering accuracy and scalability with 65,494 IoT malware specimens. The results showed that our algorithm reduced the computation by 97.52% compared with the conventional method. Our clustering algorithm achieved accuracies of 95.5% and 99.3% for clustering family name and architecture name, respectively.","2169-3536","","10.1109/ACCESS.2023.3238711","Ministry of Internal Affairs and Communications, Japan, through the “MITIGATE” among “Research and Development for Expansion of Radio Wave Resources”(grant numbers:JPJ000254); JST SPRING(grant numbers:JPMJSP2136); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10024280","Clustering;IoT malware;MDL criterion;phylogenetic tree","Malware;Phylogeny;Clustering algorithms;Static analysis;Feature extraction;Computational efficiency;Clustering methods","","1","","35","CCBY","23 Jan 2023","","","IEEE","IEEE Journals"
"Automation of the IoT-Based COVID-19 Isolation Room Temperature and Humidity Control System at Telkom University","T. R. Raditya; H. H. Nuha; Y. A. S. Yudo","School of Computing, Telkom University, Bandung, Indonesia; School of Computing, Telkom University, Bandung, Indonesia; School of Computing, Telkom University, Bandung, Indonesia","2022 1st International Conference on Software Engineering and Information Technology (ICoSEIT)","3 Feb 2023","2022","","","79","84","During the current COVID-19 pandemic, the large number of positive cases of infection has resulted in medical institutions lacking personnel to treat patients who continue to arrive. As a result of these problems, supervision and monitoring of room conditions is still lacking or even non-existent, so that the recovery process can be hampered or can facilitate the transmission of the virus to other people. It takes a device or tool that can monitor conditions and regulate the isolation room so that the temperature and humidity remain in the optimal zone so that recovery can be optimal and also reduce the risk of virus transmission. Based on this description, the author applies the concept of IoT by utilizing the IoT platform system and designing a system and tool that can monitor and regulate the COVID-19 isolation room and convey this information quickly and concisely. In addition, this study also examines how well and easily understood the system is when used by end-users by using the System Usability Scale or SUS as its usability testing method. The results obtained from this study are that the system and equipment function properly, the automation system and the method used are able to mitigate changes in temperature and humidity in the isolation room, and through the SUS method, the level of usability for end-users is deemed quite sufficient.","","978-1-6654-7303-3","10.1109/ICoSEIT55604.2022.10030064","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10030064","IoT;COVID-19;DHT11;NodeMCU;System Usability Scale (SUS)","Temperature sensors;Temperature measurement;COVID-19;Visualization;Automation;Humidity;Temperature control","","2","","26","IEEE","3 Feb 2023","","","IEEE","IEEE Conferences"
"An Improved Large Scale Data Analytics for Smart Cities with Multimodal Data Fusion","A. T. Raj; B. Lal; N. Chinthamu; A. Komuraiah; M. K. Kirubakaran","Department of Information Technology, Sri Venkateswara College of Engineering, Chennai, Tamilnadu, India; Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation (KLEF), KL University, Vaddeswaram, Andhra Pradesh, India; MIT (Massachusetts Institute of Technology) CTO Candidate, Dallas, Texas, USA; Department of Mechanical Engineering, Kamala Institute of Technology and Science, Karimnagar, Telangana, India; Department of Information Technology, St. Joseph’s Institute of Technology, Chennai, India","2023 Second International Conference on Augmented Intelligence and Sustainable Systems (ICAISS)","22 Sep 2023","2023","","","1128","1133","Massive amounts of data are produced by smart cities from a variety of sources, including sensors, social media, and IoT devices. The data analysis can offer insightful information for raising the quality of life and improving urban services. However, data fusion and analysis are made more difficult by the large-scale nature of smart city data. An improved method for big data analytics for smart cities is presented in this abstract, with a particular emphasis on the fusion and analysis of multimodal data. Integrating heterogeneous data from several sources, such as text, photos, videos, and sensor measurements, is known as multimodal data fusion. A more complete understanding of the city can be attained by merging these many data modalities. To establish a single representation for analysis, the fusion process uses feature extraction, data preprocessing, and integration techniques. There are several opportunities created by the analysis of multimodal data in smart cities. It makes it possible to find intricate patterns like social behavior, environmental pollution, and traffic congestion. Predictive models that foretell future occurrences and optimize resource allocation can be constructed by utilizing cutting-edge machine learning and deep learning techniques. Additionally, data analytics may support decision-making by giving city officials and urban planners up-to-the-minute information and practical advice. To create strong data analytics frameworks and integrate them into the architecture of smart cities, interdisciplinary collaboration between data scientists, urban designers, subject matter experts, and policymakers is necessary. In conclusion, large-scale data analytics for smart cities that combine and analyze multimodal data have significant promise for enhancing urban services and building sustainable, livable communities.","","979-8-3503-2579-9","10.1109/ICAISS58487.2023.10250451","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10250451","smart cities;data analysis;multimodal data;artificial intelligence;internet of things","Data analysis;Recurrent neural networks;Smart cities;Social networking (online);Soft sensors;Data integration;Sensor fusion","","","","24","IEEE","22 Sep 2023","","","IEEE","IEEE Conferences"
"MCRaft: synergistic collaboration of multi leaders for IoT cluster stability optimization","Z. Xu; Y. Lei; H. Han; X. Dong; X. Chen; Z. Zhu","School of Computer science, Hubei University of Technology, Wuhan, China; School of Computer science, Hubei University of Technology, Wuhan, China; School of Computer science, Hubei University of Technology, Wuhan, China; School of Computer science, Hubei University of Technology, Wuhan, China; School of Computer science, Hubei University of Technology, Wuhan, China; School of Computer science, Hubei University of Technology, Wuhan, China","2022 IEEE Smartworld, Ubiquitous Intelligence & Computing, Scalable Computing & Communications, Digital Twin, Privacy Computing, Metaverse, Autonomous & Trusted Vehicles (SmartWorld/UIC/ScalCom/DigitalTwin/PriComp/Meta)","27 Jul 2023","2022","","","1702","1709","Raft is a consensus algorithm to coordinate the proper execution of protocols and rules within the system. Owing to its security and simplicity, it can be applied to the field of IoT with blockchains. When IoT device clusters run under the Raft consensus algorithm, as the number of devices increases, split voting is prone to arise, therefore the Raft algorithm cannot run efficiently under large-scale nodes. To improve the problem of split voting and delay in system recovery after a leader collapse (DISR), this paper proposes a high-fault-tolerant consensus algorithm based on synergistic collaboration of multi leaders within the IoT clusters—MCRaft. The concept of super node cluster is introduced. MCRaft elects three leaders to form a super node cluster mapping single Raft leader. The election of the MCRaft node is verified through the log hash stored by the node, and the voting overhead of the cluster is born by the node’s own computing power instead of relying on the voting mechanism, making the election of leaders more efficient and secure. According to the experiments, the synergistic collaboration of the super node clusters effectively prevents DISR issue hence achieve efficient transmission, improving the fault tolerance of the IoT cluster. MCRaft algorithm improves the election efficiency by about 84% compared with that of common Raft algorithm within 100 nodes. 200 crash experiments indicates that the MCRaft algorithm improves its stability by about 24% on average compared with that of common Raft.","","979-8-3503-4655-8","10.1109/SmartWorld-UIC-ATC-ScalCom-DigitalTwin-PriComp-Metaverse56740.2022.00257","National Natural Science Foundation of China; Research and Development; Research and Development; Hubei University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10189688","Raft;ZooKeeper;Hash verification;Collaboration;IoT cluster","Fault tolerance;Voting;Fault tolerant systems;Collaboration;Clustering algorithms;Consensus algorithm;Blockchains","","","","25","IEEE","27 Jul 2023","","","IEEE","IEEE Conferences"
"Evaluation of Learners' Visual Attention in Online English Guiding System Based on Large-scale 5G and Information Mining","S. Zhang","Wuhu Institute of Technology, Wuhu, Anhui, China","2020 Second International Conference on Inventive Research in Computing Applications (ICIRCA)","1 Sep 2020","2020","","","299","302","Evaluation of learners' visual attention in online English guiding system based on large-scale 5G and information mining is studied in this paper. In the ultra-dense heterogeneous network, the distance between each node and the terminal is shortened, and the system capacity and flexibility will be then greatly improved. Inspired by this, the paper proposes the evaluation model. Wireless transmission technology can connect all sensors throughout the IoT. The requirements of IoT for wireless transmission technology are mainly reflected in the distance range, data rate, bandwidth, security, and cost. Hence, the sparse model is integrated to construct an efficient system. The performance is evaluated through comparison testing. The results are satisfactory, and in the future, applying the model will be considered in more scenarios.","","978-1-7281-5374-2","10.1109/ICIRCA48905.2020.9183302","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9183302","Information Mining;Visual Attention;Large-scale 5G;Performance Evaluation;Online Systems","5G mobile communication;Education;Feature extraction;Communication system security;Biological system modeling;Wireless networks","","1","","18","IEEE","1 Sep 2020","","","IEEE","IEEE Conferences"
"Evaluation of Path States of Large IoT Networks Using Locally and Remotely Controlled Measurements","A. Chodorek; R. R. Chodorek","Faculty of Electrical Engineering, Automatic Control and Computer Science, Kielce University of Technology, Kielce, Poland; Department of Telecommunications, The AGH University of Science and Technology, Kraków, Poland","2020 IFIP Networking Conference (Networking)","17 Jul 2020","2020","","","683","684","The state of network paths is of great importance for the quality and reliability of the transmission of information coming from the IoT devices. Changing network conditions cause the state of a single path to be highly unpredictable, especially when large-scale IoT networks, connecting thousands of specialized devices, are in use. The solution to this problem is to perform trials in a real environment, with the use of real hardware. The rationalization of the design, the implementation and the exploitation of the process will be the main benefit of this approach. In this demonstration, a testbed infrastructure for the estimation of the state of path parameters in wired and wireless networks is presented. The estimation is based mainly on active measurements performed with the use of the Probing Packet Trains method. The key elements of the testbed infrastructure are locally and remotely controlled energy-efficient single-board computers, working under the control of the Linux operating system, which are equipped with software able to track (in manual or automatic mode) changing conditions of a given transmission path.","","978-3-903176-28-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9142778","congestion control;Internet of Things;measurements;Probing Packet Trains","Estimation;Internet of Things;Monitoring;Performance evaluation;Servers;Manuals;Bandwidth","","","","5","","17 Jul 2020","","","IEEE","IEEE Conferences"
"Synthesis of Large-Scale Instant IoT Networks","P. Ghosh; J. Bunton; D. Pylorof; M. A. M. Vieira; K. Chan; R. Govindan; G. S. Sukhatme; P. Tabuada; G. Verma","Department of Computer Science, University of Southern California, Los Angeles, CA, USA; Department of Electrical and Computer Engineering, University of California, Los Angeles, Los Angeles, CA, USA; Systems Science and Engineering Department at U.S. DOE Idaho National Laboratory, Washington, DC, USA; Computer Science Department, Universidade Federal de Minas Gerais, Belo Horizonte, Brazil; US Army Research Laboratory, Adelphi, MD, USA; Department of Computer Science, University of Southern California, Los Angeles, CA, USA; Department of Computer Science, University of Southern California, Los Angeles, CA, USA; Department of Electrical and Computer Engineering, University of California, Los Angeles, Los Angeles, CA, USA; US Army Research Laboratory, Adelphi, MD, USA","IEEE Transactions on Mobile Computing","6 Feb 2023","2023","22","3","1810","1824","While most networks have long lifetimes, temporary network infrastructure is often useful for special events, pop-up retail, or disaster response. An instant IoT network is one that is rapidly constructed, used for a few days, then dismantled. We consider the synthesis of instant IoT networks in urban settings. This synthesis problem must satisfy complex and competing constraints: sensor coverage, line-of-sight visibility, and network connectivity. The central challenge in our synthesis problem is quickly scaling to large regions while producing cost-effective solutions. We explore two qualitatively different representations of the synthesis problems using satisfiability modulo convex optimization (SMC), and mixed-integer linear programming (MILP). The former is more expressive, for our problem, than the latter, but is less well-suited for solving optimization problems like ours. We show how to express our network synthesis in these frameworks. To scale to problem sizes beyond what these frameworks are capable of, we develop a hierarchical synthesis technique that independently synthesizes networks in sub-regions of the deployment area, then combines these. We find that, while MILP outperforms SMC in some settings for smaller problem sizes, the fact that SMC's expressivity matches our problem ensures that it uniformly generates better quality solutions at larger problem sizes.","1558-0660","","10.1109/TMC.2021.3099005","Army Research Laboratory(grant numbers:W911NF-17-2-0196. T); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9495234","Network topology;wireless sensor networks;wireless networks;topology synthesis;optimization","Optimization;Ad hoc networks;Wireless sensor networks;Redundancy;Planning;Network topology;Network synthesis","","2","","57","IEEE","26 Jul 2021","","","IEEE","IEEE Journals"
"Multi-level Bluetooth Intrusion Detection System","S. Satam; P. Satam; S. Hariri","NSF Center for Cloud and Autonomic Computing, University of Arizona, Tucson, USA; NSF Center for Cloud and Autonomic Computing, University of Arizona, Tucson, USA; NSF Center for Cloud and Autonomic Computing, University of Arizona, Tucson, USA","2020 IEEE/ACS 17th International Conference on Computer Systems and Applications (AICCSA)","13 Jan 2021","2020","","","1","8","Large scale deployment of IoT devices has made Bluetooth Protocol (IEEE 802.15.1) the wireless protocol of choice for close-range communications. Devices such as keyboards, smartwatches, headphones, computer mouse, and various wearable connecting devices use Bluetooth network for communication. Moreover, Bluetooth networks are widely used in medical devices like heart monitors, blood glucose monitors, asthma inhalers, and pulse oximeters. Also, Bluetooth has replaced cables for wire-free equipment in a surgical environment. In hospitals, devices communicate with one another, sharing sensitive and critical information over Bluetooth scatter-networks. Thus, it is imperative to secure the Bluetooth networks against attacks like Man in the Middle attack (MITM), eavesdropping attacks, and Denial of Service (DoS) attacks. This paper presents a Multi-Level Bluetooth Intrusion Detection System (ML-BIDS) to detect malicious attacks against Bluetooth devices. In the ML-IDS framework, we perform continuous device identification and authorization in Bluetooth networks following the zero-trust principle [ref]. The ML-BIDS framework includes an anomaly-based intrusion detection system (ABIDS) to detect attacks on the Bluetooth protocol. The ABIDS tracks the normal behavior of the Bluetooth protocol by comparing it with the Bluetooth protocol state machine. Bluetooth frame flows consisting of Bluetooth frames received over 10 seconds are split into n-grams to track the current state of the protocol in the state machine. We evaluated the performance of several machine learning algorithms like C4.5, Adaboost, SVM, Naive Bayes, Jrip, and Bagging to classify normal Bluetooth protocol flows from abnormal Bluetooth protocol flows. The ABIDS detects attacks on Bluetooth protocols with a precision of up to 99.6% and recall up to 99.6%. The ML-BIDS framework also performs whitelisting of the devices on the Bluetooth network to prevent unauthorized devices from connecting to the network. ML-BIDS uses a combination of the Bluetooth Address, mac address, and IP address to uniquely identify a Bluetooth device connecting to the network, and hence ensuring only authorized devices can connect to the Bluetooth network.","2161-5330","978-1-7281-8577-4","10.1109/AICCSA50499.2020.9316514","Air Force Office of Scientific Research (AFOSR); National Science Foundation (NSF)(grant numbers:NSF-1624668,NSF-1849113); National Institute of Standards and Technology (NIST)(grant numbers:70NANB18H263); Department of Energy; National Nuclear Security Administration(grant numbers:DE-NA0003946); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9316514","Bluetooth Security;Whitelisting;Internet of Things (IoT);Anomaly based Intrusion Detection;IEEE 802.15.1","Bluetooth;Protocols;Intrusion detection;Biomedical monitoring;Monitoring;Security;Performance evaluation","","3","","31","IEEE","13 Jan 2021","","","IEEE","IEEE Conferences"
"Toward Scalable and Robust AIoT via Decentralized Federated Learning","P. Pinyoanuntapong; W. H. Huff; M. Lee; C. Chen; P. Wang","University of North Carolina at Charlotte, USA; University of North Carolina at Charlotte, USA; University of North Carolina at Charlotte, USA; University of Central Florida, USA; University of North Carolina at Charlotte, USA","IEEE Internet of Things Magazine","11 May 2022","2022","5","1","30","35","As Artificial Intelligence of Things (AIoT) has become increasingly important for modern AI applications, federated learning (FL) is envisioned to be the enabling technology for AIoT, especially for large-scale, data privacy-preserving scenarios. However, most existing FL is managed in a centralized manner (CFL), which confronts the limitations of scalability given the AioT device explosion. The key challenge faced by CFL is the communication bottleneck at the central model aggregation server, which leads to a high server-to-worker communication delay and thus severely slows down the model convergence. To address this challenge, this article introduces a generic decentralized FL (DFL) framework that can operate in either synchronous (Sync-DFL) mode or asynchronous (Async-DFL) mode to alleviate the high communication congestion around the central server. Moreover, Async-DFL is the first DFL in the literature to provide a generic FL framework that is fully asynchronous and able to completely avoid worker waiting, which leads to robust distributed model training in the inherently heterogeneous IoT environments, where stragglers (i.e., slow devices) are very common due to the largely varying computing/networking speeds of IoT devices. Our DFL framework is implemented, deployed, and experimented with in both simulation and physical testbeds. The results show that Async-DFL can accelerate the convergence speed of model training twice as fast as CFL, while maintaining convergence accuracy and effectively combating the impact of the stragglers.","2576-3199","","10.1109/IOTM.006.2100216","NSF(grant numbers:2008447); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9773089","","Training data;Computational modeling;Scalability;Collaborative work;Artificial intelligence;Collaborative work;Internet of Things","","5","","15","IEEE","11 May 2022","","","IEEE","IEEE Magazines"
"Optimal Load Scheduling Based on Mobile Edge Computing Technology in 5G Dense Networking","L. Xia; D. Guo; Y. Wang; D. Sun; W. Zhen; C. Jing","Director of the Institute Science and Technology Innovation Research Academy (Hebei) of CAICT Institute Co.,ltd Baoding, Hebei Province, China; Technology R&D Department Science and Technology, Innovation Research Academy (Hebei) of CAICT Institute Co.,ltd Baoding, Hebei Province, China; Technology R&D Department Science and Technology, Innovation Research Academy (Hebei) of CAICT Institute Co.,ltd Baoding, Hebei Province, China; Technology R&D Department Science and Technology, Innovation Research Academy (Hebei) of CAICT Institute Co.,ltd Baoding, Hebei Province, China; Technology R&D Department Science and Technology, Innovation Research Academy (Hebei) of CAICT Institute Co.,ltd Baoding, Hebei Province, China; Technology R&D Department Science and Technology, Innovation Research Academy (Hebei) of CAICT Institute Co.,ltd Baoding, Hebei Province, China","2022 3rd Asia Conference on Computers and Communications (ACCC)","22 Mar 2023","2022","","","137","142","Mobile Edge Computing (MEC) technology enables offloading of network tasks at the edge, combining edge IoT devices to provide proximity services for devices or terminals, solving the pressure and shortage of data storage, performance computing and decision analysis in the cloud platform. However, in the scenario of large-scale dense networking, the terminal deployment order is large and the tasks are large. Therefore, the system model based on mobile edge computing needs to be further optimized to meet the service requirements. In addition, the computing and storage resources of the edge computing nodes are limited, and there is a possibility of backlog of intensive task processing. Therefore, the mobile edge computing in the 5G intensive networking scenario still faces the task scheduling problem. Based on the above analysis, this paper proposes a task load balancing algorithm based on game theory. The algorithm can prove the upper limit of system cost by establishing a mathematical model for multi-terminal task processing and combining with the game mathematics theory to solve the optimal solution. he simulation results show that the algorithm proposed in this paper can reasonably utilize the edge resources and ensure the maximum benefit of the terminal equipment.","","979-8-3503-3295-7","10.1109/ACCC58361.2022.00030","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10071575","mobile edge computing;5G intensive networking;load balancing;game theory;limited Resources","Performance evaluation;Multi-access edge computing;5G mobile communication;Processor scheduling;Computational modeling;Simulation;Games","","","","17","IEEE","22 Mar 2023","","","IEEE","IEEE Conferences"
"IoT (Internet of Things) based Solution Trend Identification and Analysis Research","D. Choi","Department of Software Engineering, Joongbu Univ., Seoul, South Korea","2022 IEEE/ACIS 7th International Conference on Big Data, Cloud Computing, and Data Science (BCD)","29 Sep 2022","2022","","","252","258","IoT shares data with other things, such as applications, networked devices, or industrial equipment. With a large-scale complex architecture de-sign composed of numerous ‘things’, the scalability and reliability of various models stand out. When these advantages are vulnerable to security, constant problems occur continuously. Since IoT devices are provided with services closely to users, it can be seen that there are many users with various hacking methods and environments vulnerable to hacking.","","978-1-6654-6582-3","10.1109/BCD54882.2022.9900777","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9900777","Internet of Things (IoT);Security;IoT Solution","Cloud computing;Scalability;Information sharing;Computer architecture;Data science;Market research;Internet of Things","","","","5","IEEE","29 Sep 2022","","","IEEE","IEEE Conferences"
"On Resident Strategy for White-Hat Botnet in Botnet Defense System","S. Yamaguchi; D. Makihara","Graduate School of Sciences and Technology for Innovation, Yamaguchi University, Ube, Japan; Graduate School of Sciences and Technology for Innovation, Yamaguchi University, Ube, Japan","2022 IEEE International Conference on Consumer Electronics - Taiwan","1 Sep 2022","2022","","","189","190","This paper proposes a new strategy, named resident strategy, for defending IoT networks from repeated infection of malicious botnets in the Botnet Defense System (BDS). The resident strategy aims to make a small-scale white-hat botnet resident in the network respond immediately to invading malicious botnets. The BDS controls the resident white-hat botnet with two parameters: upper and lower number of its bots. The lower limit prevents the white-hat botnet from disappearing, while the upper limit prevents it from filling up the network. The BDS with the strategy was modeled with agent-oriented Petri nets and was evaluated through the simulation. The result showed that the proposed strategy was able to deal with repeatedly invading malicious botnets with about half the scale of the conventional white-hat botnet.","2575-8284","978-1-6654-7050-6","10.1109/ICCE-Taiwan55306.2022.9869218","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869218","Botnet Defense System;botnet;resident strategy;multi-agent;Petri net","Botnet;Petri nets;Filling;Consumer electronics","","1","","2","IEEE","1 Sep 2022","","","IEEE","IEEE Conferences"
"ELOFS: An Extensible Low-Overhead Flash File System for Resource-Scarce Embedded Devices","R. Zhang; D. Liu; X. Chen; X. She; C. Yang; Y. Tan; Z. Shen; Z. Shao; L. Qiao","Key Laboratory of Dependable Service Computing in Cyber Physical Society (Chongqing University), Ministry of Education, Chongqing, China; Key Laboratory of Dependable Service Computing in Cyber Physical Society (Chongqing University), Ministry of Education, Chongqing, China; Key Laboratory of Dependable Service Computing in Cyber Physical Society (Chongqing University), Ministry of Education, Chongqing, China; Key Laboratory of Dependable Service Computing in Cyber Physical Society (Chongqing University), Ministry of Education, Chongqing, China; Key Laboratory of Dependable Service Computing in Cyber Physical Society (Chongqing University), Ministry of Education, Chongqing, China; Key Laboratory of Dependable Service Computing in Cyber Physical Society (Chongqing University), Ministry of Education, Chongqing, China; School of Computer Science and Technology, Shandong University, Qingdao, China; Department of Computer Science and Engineering, The Chinese University of Hong Kong, NT, China; Beijing Institute of Control Engineering, Beijing, China","IEEE Transactions on Computers","8 Aug 2022","2022","71","9","2327","2340","Emerging applications like machine learning in embedded devices (e.g., satellites and vehicles) require huge storage space, which recently stimulates the widespread deployment of large-scale flash memory in IoT devices. However, existing embedded file systems fall short in managing large-capacity storage efficiently for two reasons. First, prior arts store data structures of file systems either in flash or in main memory, which severely magnifies the scarcity of computing and memory resources. Moreover, the fine-grained metadata management in the existing embedded file systems induces significant energy consumption for large-capacity storage. In this paper, we propose a novel embedded file system, ELOFS, to tackle the above issues and manage large-capacity NAND flash on resource-scarce devices. ELOFS is made efficient through three novel techniques. First, we redefine the space management granularity and streamline the metadata to speed up the mounting performance. In addition, we design hybrid file structures to adapt dissimilar access patterns of embedded devices. Furthermore, ELOFS provides opportunities for in-depth cooperation with application-specific systems. We implement ELOFS with Memory Technology Device (MTD) interfaces, and the experimental results show that ELOFS outperforms YAFFS and UBIFS in terms of write, read, and deletions with orders of magnitude reductions on memory footprint and mounting time.","1557-9956","","10.1109/TC.2022.3152079","National Natural Science Foundation of China(grant numbers:61672116,61802038,62162011); Chongqing High-Tech Research Key Program(grant numbers:cstc2019jscx-mbdx0063); Fundamental Research Funds for the Central Universities(grant numbers:0214005207005,2019CDJGFJSJ001); Chongqing Youth Talent Support Program(grant numbers:cstc2021ycjh-bgzxm0331); Chongqing Science Foundation for Distinguished Young Scholars(grant numbers:cstc2020jcyj-jqX0012); Chongqing Technology Innovation and Application Development Key Project(grant numbers:cstc2019jscx-mbdxX0022); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9715229","Embedded file systems;memory efficient;NAND flash","Ash;Performance evaluation;Random access memory;Metadata;Hardware;Memory management;Sensors","","","","46","IEEE","17 Feb 2022","","","IEEE","IEEE Journals"
"SMART IRRIGATION SYSTEM","M. D. Josephine; S. Gurunathan; V. Krishna; G. Nath; S. Ramasamy","Dept of Electronics and Communication Engineering, Coimbatore Institute of Technology, Coimbatore, India; Dept of Electronics and Communication Engineering, Coimbatore Institute of Technology, Coimbatore, India; Dept of Electronics and Communication Engineering, Coimbatore Institute of Technology, Coimbatore, India; Dept of Electronics and Communication Engineering, Coimbatore Institute of Technology, Coimbatore, India; Dept of Electronics and Communication Engineering, Coimbatore Institute of Technology, Coimbatore, India","2021 10th International Conference on Internet of Everything, Microwave Engineering, Communication and Networks (IEMECON)","4 Feb 2022","2021","","","1","4","Agriculture in India is livelihood for a majority of the population and can never be underestimated. This project mainly focuses on IoT based smart irrigation system which helps to reduce the manual work and save the time of farmers. Monitoring environmental conditions is the key factor to improve the yield of crops and to grow seasonal crops. It involves automated checking of moisture, humidity, water level and temperature of the land under cultivation. Automatic irrigation facility is provided for irrigation if and when required. The smart irrigation system comes with different sensors that monitors the environmental conditions and gives the sensed outputs to Arduino board. The farmers can get the required information from the developed mobile application through Wi-Fi module. This system can be used even in small scale terrace gardening. The system is carefully deployed in such a way that everyone can easily follow the steps and procedures and feasible to everyone.","","978-1-6654-2686-2","10.1109/IEMECON53809.2021.9689158","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9689158","IoT;Arduino;Mobile Application;temperature sensor;soil moisture sensor","Temperature sensors;Temperature measurement;Irrigation;Temperature;Moisture;Crops;Statistics","","4","","11","IEEE","4 Feb 2022","","","IEEE","IEEE Conferences"
"An aquaculture monitoring system based on NB-IoT","L. Shu; X. Wen","Wuhan Institute of Technology, Wuhan, China; Wuhan Institute of Technology, Wuhan, China","2021 33rd Chinese Control and Decision Conference (CCDC)","30 Nov 2021","2021","","","5620","5624","In the traditional small-scale pond aquaculture field, the vast majority of individual farmers can only carry out the pond aquaculture based on experience and the breeding environment is hard to be accurately monitored, so the lower cost and high profit are unable to be achieved in this paper, an aquaculture monitoring system based on the narrow-band IoT is designed. The system is composed of acquisition and control module, wireless transmission module and user monitoring module. With the STM32L151RCT6 microcontroller as the core, the acquisition and control module are used to collect water quality parameter information and control the actuator to realize the adjustment of water quality parameters. In addition, after the water quality parameter information is transmitted to the STM32F103C8T6 through ZigBee wireless network, it is displayed on the LCD screen in real time and uploaded to the cloud platform. Users can monitor the aquaculture environment through the Web and mobile phone. The experimental results showed that the designed aquaculture monitoring system can realize the collection, monitoring and control of water quality parameters such as dissolved oxygen, PH and temperature.","1948-9447","978-1-6654-4089-9","10.1109/CCDC52312.2021.9601877","Wuhan institute of technology(grant numbers:CX2020085); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9601877","Aquaculture;Relay;NB-IoT;Cloud platform;ZigBee","Temperature sensors;Temperature measurement;Wireless sensor networks;Clouds;Wireless networks;Zigbee;Water quality","","","","10","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"X-on-interposer ecosystem to migrate IoT1.0 to value-added IoT2.0","C. -m. Fu; Y. -C. Wang","Biomedical Incubation Center D110; No.2, Shengyi 2nd Rd, Yuan Consulting Ltd., Zhubei City, Hsinchu County, Taiwan (R.O.C.); Department of Civil Engineering, NCKU, National Cheng Kung University, Tainan City, Taiwan (R.O.C.)","2020 15th International Microsystems, Packaging, Assembly and Circuits Technology Conference (IMPACT)","30 Nov 2020","2020","","","121","124","IoT applications normally involve heterogeneous integration of MCU, RF, sensor chips and discrete components, with the diversity but smaller quantity. PCB prototype is the first practical and cheap proof-of-concept (from 0 to 1) assembly using available package-ICs, components for initial functions test, software development and market trials, although with lower entry-barrier without much differentiation. SiP (system-in-package) is the next rationale revision option (from 1 to 2) for not only decent structural scaling, but also for system-level PPA$ (performance, power, formfactor and total cost) co-optimization, especially for the value-added sensor fusion, edge IoT2.0 applications or so called AIoT transformation. Such attempt of PCB migration to SiP options is not trivial to-be LEGO-like flows or simple ROI justification, if without deeper domain knowledges and chiplet design flow insights. Traditional SOC mindsets may be not sufficient, due to lacking system-level PPA(performance, power, area) considerations and more, such as thermal, stress management, decent what-if analysis and meaningful design-technology co-optimization among various structural stacking options. Some heterogenous cases are discussed in this article about IP/chip/package strategy, and potentially are developed for decent application-driven interposer platform technology proposals.","2150-5942","978-1-7281-9851-4","10.1109/IMPACT50485.2020.9268589","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9268589","SiP;structural scaling;chiplet design flow;AIoT transformation;design-technology co-optimization;X-on-interposer.","Sensors;Radio frequency;Integrated circuits;Stress;Layout;Bills of materials;Universal Serial Bus","","","","7","IEEE","30 Nov 2020","","","IEEE","IEEE Conferences"
"MBOX: Designing a Flexible IoT Multimodal Learning Analytics System","H. Ouhaichi; D. Spikol; B. Vogel","Department of Computer, Science and Media Technology Malmö University, Sweden; Department of Science Education, University of Copenhagen, Copenhagen, Denmark; Department of Computer, Science and Media Technology Malmö University, Sweden","2021 International Conference on Advanced Learning Technologies (ICALT)","2 Aug 2021","2021","","","122","126","Multimodal Learning Analytics (MMLA) provides opportunities for understanding and supporting collaborative problem-solving. However, the implementation of MMLA systems is challenging due to the lack of scalable technologies and limited solutions for collecting data from group work. This paper proposes the Multimodal Box (MBOX), an IoT-based system for MMLA, allowing the collection and processing of multimodal data from collaborative learning tasks. MBOX investigates the development and design for an IoT focusing on small group work in real-world settings. Moreover, MBOX promotes adaptation to different learning environments and enables a better scaling of computational resources used within the learning context.","2161-377X","978-1-6654-4106-3","10.1109/ICALT52272.2021.00044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9499820","Multimodal Learning Analytics;CSCL;IoT;Interaction Design;Human Social Signal Processing","Focusing;Collaboration;Signal processing;Collaborative work;Problem-solving;Task analysis","","1","","31","IEEE","2 Aug 2021","","","IEEE","IEEE Conferences"
"A new MBFF merging strategy for post-placement power optimization of IoT devices","Y. Attaoui; M. Chentouf; Z. E. Abidine Alaoui Ismaili; A. El Mourabit","Siemens EDA/CSD Calypto - Synthesis Solutions, Rabat, Morocco; Siemens EDA/CSD Calypto - Synthesis Solutions, Rabat, Morocco; Information, Communication and Embedded Systems (ICES) Team, Mohammed V University, Rabat, Morocco; System & Data Engineering Team. ENSA of Tangier, Abdelmalek Essaâdi University, Morocco","2021 IEEE/ACS 18th International Conference on Computer Systems and Applications (AICCSA)","25 Jan 2022","2021","","","1","6","Recently power has become the most important factor in VLSI design. As clock network is the largest design element in terms of power consumption in modern low-power Very Large Scale Integration (VLSI) Designs and IoT applications, several studies have been made in order to reduce the power leaks and unnecessary switching of the clock network. The clock gating, as well as the use of Multibit Flip Flops (MBFFs), are some of the widely used low-power technics.In this paper, we presented a novel approach for power consumption reduction in IoT systems by applying an iterative MBFF insertion. we will make several trials on the use of multi-bit Flip-Flops during each phase of logic Synthesis, Placement, and Optimization. In the first trial, we have measured the impact of MBFF merging on power and circuit performance in several development stages using 2-bits and 4-bits MBFFs. In the second trial, we have combined 2-bits and 4-bits MBFFs and measured the power numbers and circuit’s performance. Finally, we have applied an iterative MBFF merging algorithm and measure the PPA (Power, Performance, and Area) impact versus traditional MBFF implementation.The result of this experiment achieved a better total MBFF merging coverage of 76.6%, a good routability maintenance with less congestion, less wire-length by 3.8% leading to a switching power improvement of around 3.3% with no timing and area degradation.","2161-5330","978-1-6654-0969-8","10.1109/AICCSA53542.2021.9686857","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9686857","ASIC;Logic Synthesis;Low-Power;Clock Tree;Multibit Flip-Flop;IoT","Degradation;Power measurement;Power demand;Merging;Switches;Very large scale integration;Timing","","1","","18","IEEE","25 Jan 2022","","","IEEE","IEEE Conferences"
"Using Software-Defined Networking Technology for Delivering Software Updates to Wireless Sensor Networks","S. Buzura; V. Lazar; B. Iancu; A. Peculea; V. Dadarlat","Computer Science Department, Technical University of Cluj-Napoca, Cluj-Napoca, Romania; Computer Science Department, Technical University of Cluj-Napoca, Cluj-Napoca, Romania; Computer Science Department, Technical University of Cluj-Napoca, Cluj-Napoca, Romania; Computer Science Department, Technical University of Cluj-Napoca, Cluj-Napoca, Romania; Computer Science Department, Technical University of Cluj-Napoca, Cluj-Napoca, Romania","2021 20th RoEduNet Conference: Networking in Education and Research (RoEduNet)","10 Dec 2021","2021","","","1","6","The current paper proposes a system architecture where a distributed environment of wireless sensor networks (WSNs) can selectively receive software updates when enhanced with a Software-Defined Network (SDN) control environment. In the context of IoT, the current work aims to facilitate the deployment of software updates on WSNs in an automated fashion and also proposes the usage of this architecture in large scale business networks, where different areas of the same network may change their purpose at different times during the network lifecycle. A central component oversees the coordination of each WSN, but each WSN is responsible for retrieving its updates from the storage location. For security, the software updates are stored in a remote peer-2-peer storage location. A simulation environment is also presented which uses Mininet-Wifi as a WSN emulator with Pox controller as SDN enabler and uses the IPFS network as a remote peer-2-peer storage. The Pox controller’s host_tracker module is enhanced with features to retrieve the updates from the IPFS network and to deliver the retrieved information to each station on the network. The simulations show that information can be delivered with relatively small network overhead and changes to the Pox controller, making this a viable solution for delivering updates to WSNs.","2247-5443","978-1-6654-1351-0","10.1109/RoEduNet54112.2021.9637720","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9637720","SDN;WSN;Delivering software updates;IoT;Repurposing WSN","Wireless sensor networks;Education;Systems architecture;Computer architecture;Software;Security;Business","","1","","23","IEEE","10 Dec 2021","","","IEEE","IEEE Conferences"
"6G Connected Vehicle Framework to Support Intelligent Road Maintenance Using Deep Learning Data Fusion","M. Hijji; R. Iqbal; A. Kumar Pandey; F. Doctor; C. Karyotis; W. Rajeh; A. Alshehri; F. Aradah","Faculty of Computers and Information Technology, University of Tabuk, Tabuk, Saudi Arabia; College of Engineering and IT, University of Dubai, Dubai, United Arab Emirates; Interactive Coventry Ltd., Coventry, U.K; Centre for Computational Intelligence, School of Computer Science and Electronic Engineering, University of Essex, Colchester, U.K.; Interactive Coventry Ltd., Coventry, U.K; Faculty of Computers and Information Technology, University of Tabuk, Tabuk, Saudi Arabia; Department of Computer Science, Applied College, University of Tabuk, Tabuk, Saudi Arabia; Centre for Computational Intelligence, School of Computer Science and Electronic Engineering, University of Essex, Colchester, U.K.","IEEE Transactions on Intelligent Transportation Systems","7 Jul 2023","2023","24","7","7726","7735","The growth of IoT, edge and mobile Artificial Intelligence (AI) is supporting urban authorities exploit the wealth of information collected by Connected and Autonomous Vehicles (CAV), to drive the development of transformative intelligent transport applications for addressing smart city challenges. A critical challenge is timely and efficient road infrastructure maintenance. This paper proposes an intelligent hierarchical framework for road infrastructure maintenance that exploits the latest developments in 6G communication technologies, deep learning techniques, and mobile edge AI training approaches. The proposed framework abides with the stringent requirements of training efficient machine learning applications for CAV, and is able to exploit the vast numbers of CAVs forecasted to be present on future road networks. At the core of our framework is a novel Convolution Neural Networks (CNN) model which fuses imagery and sensory data to perform pothole detection. Experiments show the proposed model can achieve state of the art performance in comparison to existing approaches while being simple, cost-effective and computationally efficient to deploy. The proposed system can form part of a federated learning framework for facilitating large scale real-time road surface condition monitoring and support adaptive resource allocation for road infrastructure maintenance.","1558-0016","","10.1109/TITS.2023.3235151","Deanship of Scientific Research at the University of Tabuk(grant numbers:0195-1442-S); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10021225","6G;deep learning;mobile edge intelligence;pothole detection;federated learning;intelligent transportation systems","Roads;Maintenance engineering;Data models;Computational modeling;6G mobile communication;Training;Smart phones","","13","","60","IEEE","18 Jan 2023","","","IEEE","IEEE Journals"
"Distributed Fractionalized Data Networks For Data Integrity","A. Majumdar; G. Mohan","Virgil Systems, Toronto; Virgil Systems, Toronto","2020 IEEE International Conference on Blockchain and Cryptocurrency (ICBC)","17 Aug 2020","2020","","","1","3","The world is being transformed by the onset of new high speed 5G Technologies that open the possibility of IoT networks at scale. This demands delivery guarantees and coordinated distributed communications that are resistant to damage and can self-heal under adversity. The speed of change is increasing with increased automation, artificial intelligence, information from multiple sources, integrated systems of systems and emerging quantum technologies. Current distributed consensus checking mechanisms are computationally intensive and fail to scale along with these changes because of the complexity of proof of work calculations or the unnecessary need to bind in domain specific elements such as cryptocurrencies. Furthermore, these mechanisms are brittle in that small changes in messages can cause restarts or failure of integrity checks, or they introduce domain specific elements (e.g. monetary design that has little to do with integrity). We propose distributed ledgers as a pure technology coupled with a strong proof protocol for exchanges, called ""Proof of Integrity"" without any need for cryptocurrencies or other domain specific elements. Proof of Integrity provides distributed data guarantees and operational continuity through adversity or breakdowns while creating a reliable and trustworthy layer for the application specificity of domain specific elements.","","978-1-7281-6680-3","10.1109/ICBC48266.2020.9169392","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9169392","","Peer-to-peer computing;Distributed databases;Data integrity;Resistance;Cryptography","","","","5","IEEE","17 Aug 2020","","","IEEE","IEEE Conferences"
"Efficient Edge Server Computing on a Scaled IoT Based Sensory Network","S. A. Amin; M. R. Ghoto; U. S. Khan; H. Jabbar","Department of Mechatronics Engineering College of E&ME, National University of Science and Technology, Pakistan; Department of Mechatronics Engineering College of E&ME, National University of Science and Technology, Pakistan; Department of Mechatronics Engineering College of E&ME, National University of Science and Technology, Pakistan; Department of Mechatronics Engineering College of E&ME, National University of Science and Technology, Pakistan","2021 International Conference on Robotics and Automation in Industry (ICRAI)","28 Dec 2021","2021","","","1","5","Edge server-based computing is one the most effective way of approaching and dealing with the problem of a wide or scaled sensory network where we have an excessive amount of data to deal with. The approach to implementing such a system used here offers not just a singular set of sensor networks but allows users to control, add and/or maintain the entire daisy chain of the sensory network on a local scale controlled by IoT cloud access and local computing potential using Raspberry Pi as the main edge computing resource. In this method, the ESP32 sensor node will do a small computation on the sensed data. It can be read in any form either analog or digital. After computation, it will send these data packets by publishing them to the locally connected edge node created by using Edge X Foundry service, management tools, and Mosquitto as the main broker. This edge node gathers the data from all the sensors and then publishes them accordingly to the cloud server based on subscriptions configured by the cloud host. The main objective of this project is to achieve a high level of control that allows users to manipulate a local system that is capable of locally administering and governing the data and release them upon requests with minimal possible power draw, having a potential of scalability as well as portability as compared to the solutions currently available and used. This method has the potential to be applied on any kind of application ranging from consumer, industrial or infrastructural levels.","","978-1-6654-2343-4","10.1109/ICRAI54018.2021.9651429","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9651429","Data acquisition;Edge Computing;Edge X Foundry;IIoT;cloud;Mosquitto;Northbound / Southbound data flow","Cloud computing;Automation;Publishing;Scalability;Organizations;Robot sensing systems;Servers","","","","7","IEEE","28 Dec 2021","","","IEEE","IEEE Conferences"
"Q-Learning Algorithm Enabled Topology Control Scheme in Power Line Communication Networks","L. Liu; L. Zheng; Y. Wang","State Grid Dalian Electric Power Supply Company, Liaoning, China; State Grid Dalian Electric Power Supply Company, Liaoning, China; State Grid Dalian Electric Power Supply Company, Liaoning, China","2022 4th International Conference on Smart Power & Internet Energy Systems (SPIES)","3 Apr 2023","2022","","","2229","2232","The topology control technology is of great importance in the Power Line Communications (PLC) networks for smart power grid. Due to the weak topology controlling ability of current large-scale PLC networks, the throughput of current PLC networks is limited seriously and fail to support more real-time services. To deal with this problem, this paper proposes a Q-Learning algorithm enabled topology control scheme of PLC networks. This robust topology control scheme introduces the Q-learning algorithm into the CSMA/CA protocol and adopts the Markov process to build the networking model of PLC system. Through period on-line learning by proposed algorithm, the robust topology can be established in PLC networks. Test results show that the proposed approach can improve topology control ability for real-time services by smart grid IoT (SG-IoT) systems, in terms of both packet loss rate and time delay performance with great feasibility and efficiency.","","978-1-6654-8957-7","10.1109/SPIES55999.2022.10082615","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10082615","Topology control scheme;Q-learning algorithm;power line communications;smart grid IoT","Q-learning;Multicast algorithms;Protocols;Network topology;Power line communications;Packet loss;Markov processes","","","","15","IEEE","3 Apr 2023","","","IEEE","IEEE Conferences"
"A Secured IoT Scheme for Microgrids Monitoring","J. Martínez-Martínez; C. Carvajal-Jiménez; D. A. Aponte-Roa","Electrical and Computer Engineering Department, Universidad Ana G. Méndez, Gurabo Campus, Gurabo, Puerto Rico; Computer Science Department, Universidad Ana G. Méndez, Cupey Campus, Cupey, Puerto Rico; Electrical and Computer Engineering Department, Universidad Ana G. Méndez, Gurabo Campus, Gurabo, Puerto Rico","2020 10th Annual Computing and Communication Workshop and Conference (CCWC)","12 Mar 2020","2020","","","0986","0990","A microgrid is a small-scale grid for electricity generation and distribution to small communities using different energy sources such as the sun and the wind. This paper presents a secured IoT scheme to monitor a DC microgrid components for improving its performance. The key idea is to set up a Wireless Sensor Network in which the sensor nodes are connected to a network using the Zigbee protocol and allow external communication through a sink node. A mobile application allows the user to monitor and control the system via the Internet to minimize the waste of energy. For security purposes, data are authenticated, encrypted, and decrypted for avoiding malicious attacks. In addition, the sink node has an encrypted key-based protocol for establishing a secured remote login with the authorized users. Also, a firewall and network intrusion detection & prevention system was implemented to protect the devices and their local data. Our results demonstrate the feasibility of this proposed scheme in a real microgrid.","","978-1-7281-3783-4","10.1109/CCWC47524.2020.9031280","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9031280","IoT;Microgrid;Security;Privacy;Network;Pen-Test;DoS;Stress-Test","Cryptography;Microgrids;Cloud computing;Protocols;Monitoring;Firewalls (computing)","","","","15","IEEE","12 Mar 2020","","","IEEE","IEEE Conferences"
"Efficient and Distributed Temporal Pattern Mining","N. Ho; V. L. Ho; T. Bach Pedersen; M. Vu","Department of Computer Science, Aalborg University, Denmark; Department of Computer Science, Aalborg University, Denmark; Department of Computer Science, Aalborg University, Denmark; Department of Electrical & Computer Engineering, Tufts University, Medford, MA, USA","2021 IEEE International Conference on Big Data (Big Data)","13 Jan 2022","2021","","","335","343","The widespread deployment of IoT systems in the real world today has enabled the generation and collection of an enormous amount of sensor times series. One of the important mining techniques to extract patterns from time series is temporal pattern mining (TPM). Unlike the sequential pattern mining, TPM adds an additional temporal dimension, i.e., time intervals, into extracted patterns, making them more informative. However, adding the extra temporal dimension into patterns results in an additional exponential factor to the growth of the search space, and thus, significantly increases the mining complexity. Current TPM approaches work sequentially, therefore, cannot scale to large datasets. In this paper, we propose Distributed Hierarchical Pattern Graph TPM (DHPG-TPM), the first distributed solution that supports large-scale TPM using the leading distributed platform Apache Spark. Moreover, DHPG-TPM employs efficient data structures, distributed bitmap and distributed Hierarchical Pattern Graph that are carefully designed to work efficiently in a distributed environment to enable fast computations of support and confidence. To address the exponential search space of TPM, we design effective distributed pruning techniques based on the Apriori principle and the transitivity property of temporal relations to reduce the search space while minimizing the communication overhead between the cluster nodes. We conduct extensive experiments on real-world and synthetic datasets, showing that DHPG-TPM outperforms the sequential baselines and scales to very large datasets.","","978-1-6654-3902-2","10.1109/BigData52589.2021.9671753","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671753","","Conferences;Time series analysis;Cluster computing;Big Data;Data structures;Computational efficiency;Complexity theory","","3","","26","IEEE","13 Jan 2022","","","IEEE","IEEE Conferences"
"Wide-area Synchronous Sampling Technique for Terminal Devices of Distribution IoT","S. Haoyang; W. Peng; G. Shen; Z. Jichuan; L. Jiaying","China Electric Power Research Institute, Beijing, China; China Electric Power Research Institute, Beijing, China; China Electric Power Research Institute, Beijing, China; China Electric Power Research Institute, Beijing, China; China Electric Power Research Institute, Beijing, China","2021 IEEE 4th International Electrical and Energy Conference (CIEEC)","17 Aug 2021","2021","","","1","6","With the rapid development of the scale of the power grid, problems such as the changing operation mode of the distribution network and a large amount of monitoring data have become increasingly prominent. At present, the centralized sensing system based on synchronous phasor measurement has been researched, but there are still problems such as synchronization data delay mismatch in the implementation process, and the sampling data caused by clock differences are not timely and asynchronous, which is a problem in the construction of the power distribution IoT. The emergence of Beidou satellite timing, voltage-controlled crystal oscillator and other technologies provide new solutions to the above problems. This paper proposes a wide-area synchronous sampling technology for power distribution IoT terminal equipment that combines Beidou satellite timing with automatic frequency control. This technology can effectively solve the problems of too long time delay and too large synchronization error, and is an important technology to improve the real-time performance of synchronization data in the distribution network. The paper firstly compares various clock synchronization technologies, and then focuses on analyzing the causes of crystal oscillator errors, and then supplements the error control algorithm. Finally, the Beidou satellite timing and automatic frequency control combination of sampling synchronization software and hardware design methods are proposed, and the experimental data is analyzed. Experimental verification shows that the above method can control the clock synchronization error within one hundred nanoseconds, and realize the wide-area high-precision synchronous sampling of the power distribution IoT terminal equipment.","","978-1-7281-7149-4","10.1109/CIEEC50170.2021.9510371","State Grid Corporation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9510371","clock synchronization;Beidou;frequency control;crystal oscillator;IoT","Automatic frequency control;Satellites;Software algorithms;Power distribution;Distribution networks;Crystals;Error correction","","","","12","IEEE","17 Aug 2021","","","IEEE","IEEE Conferences"
"Car parking detection in a typical village core street using public camera feeds","A. Coleiro; D. Scerri; I. Briffa","Institute of ICT Malta College of Arts, Science & Technology, Paola, Malta; Institute of ICT Malta College of Arts, Science & Technology, Paola, Malta; Institute of ICT Malta College of Arts, Science & Technology, Paola, Malta","2020 IEEE 10th International Conference on Consumer Electronics (ICCE-Berlin)","17 Feb 2021","2020","","","1","6","Malta is a small island with a highly dense car population. In many towns and villages parking is a serious problem leading to time waste and pollution. This study proposes a solution to accurately detect any available parking spaces in a typical village street. Solutions making use of IoT sensors beneath the top layer of asphalt in each parking space are expensive to scale and were only employed on the island in two pilot studies. Our solution proposes a two-phase approach to provide a dynamic low-cost solution by using public camera feeds. Phase 1 makes use of a Convolutional Neural Network (Mask R-CNN) to detect cars. Cars behavior over time is then exported and used to generate a heatmap which is then processed through a series of thresholding, morphological and contour detection operations to automatically annotate parking slots. In phase 2 the annotated street is fed into a second algorithm to determine parking space occupancy. We found that although our system automatically annotates parking spaces, results were very similar to other systems that require manually annotated parking boxes. Moreover, our system enables re-learning of annotations at desired intervals, thus creating a solution which adapts itself to street changes.","2166-6822","978-1-7281-5885-3","10.1109/ICCE-Berlin50680.2020.9352169","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9352169","Smart Parking Systems;Image Processing;Automated Parking Space Annotation;Computer Vision;Artificial Intelligence;Mask R-CNN","Space vehicles;Annotations;Aerospace electronics;Cameras;Automobiles;Feeds;Space heating","","3","","15","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"A Load-Independent ZVS Class-E2 Wireless Power Transfer with Receiver-side Constant-Frequency PWM Power Control","T. Mishima; S. Shimizu; C. -M. Lai","Dept. Marine Engineering, Kobe University, Kobe, Japan; Dept. Marine Engineering, Kobe University, Kobe, Japan; Dept. Electrical Engineering, National Chung Hsing University, Taichung, Taiwan","2023 11th International Conference on Power Electronics and ECCE Asia (ICPE 2023 - ECCE Asia)","22 Aug 2023","2023","","","1038","1043","A compact and low-profile high frequency (HF) power converter is essential for a magnetically resonant wireless power transfer (WPT) system suitable for a small-scale electric load such as IoT equipments and medical implantable devices. This paper presents a new prototype of a class E HF inverter/active rectifier-based WPT system, where the load power control achieves only in the receiver (Rx) side while maintaining zero voltage soft-switching (ZVS) on the transmitter (Tx) side with the fixed frequency and duty cycle. The modeling-based analysis and design of PWM-controlled Rx-side class-E rectifier are originally presented in accordance with load-independent ZVS in the Transmitter (Tx)-side class-E inverter. The effectiveness of the modeling and design of the class-E2 WPT system are verified by experiment of 1MHz-8W prototype, after whereby the load-independent ZVS performance of class-E inverter is demonstrated with the relevant steady-state characteristics.","2150-6086","978-89-5708-350-5","10.23919/ICPE2023-ECCEAsia54778.2023.10213964","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10213964","Class-E inverter/rectifier;load independence;magnetic resonance;wireless power transfer;zero voltage soft switching (ZVS)","Transmitters;Soft switching;Power control;Rectifiers;Prototypes;Wireless power transfer;Zero voltage switching","","","","4","","22 Aug 2023","","","IEEE","IEEE Conferences"
"Analysis, Design and Verifications on Receiver-side Pulse-Width-Modulation Load-Independent ZVS Class-E2 Wireless Power Transfer","T. Mishima; S. Shimizu; T. Yang; C. -M. Lai","Dept. Marine Engineering, Kobe University, Kobe, Japan; Dept. Marine Engineering, Kobe University, Kobe, Japan; Dept. Marine Engineering, Kobe University, Kobe, Japan; Dept. Electrical Engineering, National Chung Hsing University, Taichung, Taiwan","2023 IEEE Energy Conversion Congress and Exposition (ECCE)","29 Dec 2023","2023","","","6462","6469","A compact and low-profile high frequency(HF) power converter is essential for a magnetically resonant wireless power transfer(WPT) system suitable for a small-scale electric load such as IoT equipments and medical implantable devices. This paper presents a new prototype of a class-E HF inverter/active rectifier-based WPT system, where the load power control achieves only in the receiver(Rx) side while maintaining zero voltage soft switching(ZVS) on the transmitter(Tx)-side with the fixed frequency and duty cycle. The modeling-based analysis and design of PWM-controlled Rx-side class-E rectifier are originally presented in accordance with load-independent ZVS in the Tx-side class-E inverter. The effectiveness of the modeling and design of the class-E2 WPT system is verified by experiment of 1MHz-8W prototype, after whereby the load-independent ZVS performance of class-E inverter is demonstrated with the relevant steady-state characteristics.","2329-3748","979-8-3503-1644-5","10.1109/ECCE53617.2023.10362701","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10362701","Class-E inverter/rectifier;load-independence;magnetic resonance;pulse-width-modulation(PWM);wireless power transfer(WPT);zero voltage soft switching(ZVS)","Power control;Prototypes;Rectifiers;Switches;DC-DC power converters;Zero voltage switching;Pulse width modulation","","","","23","IEEE","29 Dec 2023","","","IEEE","IEEE Conferences"
"A 94.1 dB DR 4.1 nW/Hz Bandwidth/Power Scalable DTDSM for IoT Sensing Applications Based on Swing-Enhanced Floating Inverter Amplifiers","Y. Zhao; H. Zhang; Y. Hu; Y. Bao; L. Ye; W. Qu; M. Zhao; Z. Tan","Zhejiang University, Hangzhou, China; Delft University of Technology, Delft, The Netherlands; Zhejiang University, Hangzhou, China; Peking University, Beijing, China; Peking University, Beijing, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China","2021 IEEE Custom Integrated Circuits Conference (CICC)","17 May 2021","2021","","","1","2","IoT sensing applications operating from batteries or harvested energy require microwatt data converters. To accurately measure small signals, they often need to achieve a high DR (>90dB) and better linearity than the transducers themselves (>14b) with a BW in the kHz range. IoT systems also often consist of multiple sensing modalities with different BW requirements and are often heavily duty-cycled to reduce power consumption. This paper presents a fully dynamic discrete-time delta-sigma modulator (DTDSM) that supports 4x bandwidth/power scaling without any programming overhead except for changing fs, using a capacitively biased swing-enhanced floating inverter amplifier (SEFIA). The prototype, fabricated in 180nm CMOS, consumes only 4μW at 800Hz BW and achieves >87dB SNDR over 2 octaves of fs, between 100 kHz and 400 kHz, and a DR of 94.1 dB while operating with an OSR of 125.","2152-3630","978-1-7281-7581-2","10.1109/CICC51472.2021.9431415","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9431415","","Transducers;Power demand;Conferences;Prototypes;Modulation;Linearity;Programming","","11","","6","IEEE","17 May 2021","","","IEEE","IEEE Conferences"
"Developing a Feasible Firewall System with Parallel Rule Allocation Optimization for High Service Availability under Large-Scale Network Attacks","C. -S. Chao","Department of Communications Engineering, Feng Chia University, Taichung, Taiwan","2023 IEEE 5th Eurasia Conference on IOT, Communication and Engineering (ECICE)","12 Jan 2024","2023","","","56","60","Firewalls are essential in the front line of protected networks to safeguard them against network attacks. With the massive and increasing deployment of IoT and 5G devices on the Internet, large-scale network attacks are easily launched but the structure of current firewalls can no longer protect the managed network from being paralyzed by such large attacks. In this study, a novel firewall system with parallel rule allocation optimization was developed to offer overall packet filtering with rule anomalies and high availability of the protected network. As a result, the developed system was implemented and evaluated for packet-filtering rates. The results showed excellence and feasible performance.","","979-8-3503-1469-4","10.1109/ECICE59523.2023.10383082","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10383082","optimization of parallel allocation for IPv6 firewall rules;independent function-parallel firewall;IoT service availability under large-scale network attacks;correlation of firewall rules","Firewalls (computing);Filtering;5G mobile communication;Resource management;Internet of Things;Optimization","","","","15","IEEE","12 Jan 2024","","","IEEE","IEEE Conferences"
"Eris: An Online Auction for Scheduling Unbiased Distributed Learning Over Edge Networks","J. Pang; Z. Han; R. Zhou; R. Zhang; J. C. S. Lui; H. Chen","Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, China; School of Computer Science and Engineering, Southeast University, Nanjing, China; Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong; Huawei Technologies Co., Ltd., China","IEEE Transactions on Mobile Computing","","2023","PP","99","1","13","The emergence of edge intelligence has made smart IoT services (e.g., video/audio surveillance, autonomous driving and smart city) a reality. To ensure the quality of service, edge service providers train unbiased models of distributed machine learning jobs over the local datasets collected by edge networks, and usually adopt the parameter server (PS) architecture. However, the training of unbiased distributed learning (UDL) depends on geo-distributed data and edge resources, bringing a new challenge for service providers: how to effectively schedule and price UDL jobs such that the long-term system utility (i.e., social welfare) can be maximized. In this paper, we propose an online auction-based scheduling algorithm Eris, which determines the data workload, the number and the placement of concurrent workers and PSs for each arriving UDL job, and dynamically prices limited edge resources based on current resource consumption. Eris applies a primal-dual framework which calls an efficient dual subroutine to schedule UDL jobs, achieving a good competitive ratio and pseudo-polynomial time complexity. To evaluate the effectiveness of Eris, we implement both a testbed and a large-scaled simulator. The results demonstrate that Eris outperforms and achieves up to 44% more social welfare compared to state-of-the-art algorithms in today's cloud system.","1558-0660","","10.1109/TMC.2023.3333368","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10334489","Auction;distributed machine learning;online scheduling","Cloud computing;Training;Pricing;Training data;Servers;Bandwidth;Task analysis","","","","","IEEE","29 Nov 2023","","","IEEE","IEEE Early Access Articles"
"A Tracing Based Model to Identify Bottlenecks in Physically Distributed Applications","C. Cassé; P. Berthou; P. Owezarski; S. Josset","LAAS - CNRS, Université de Toulouse, CNRS, UPS, Toulouse, France; LAAS - CNRS, Université de Toulouse, CNRS, UPS, Toulouse, France; LAAS - CNRS, Université de Toulouse, CNRS, UPS, Toulouse, France; Orange Labs, Blagnac, France","2022 International Conference on Information Networking (ICOIN)","26 Jan 2022","2022","","","226","231","The Cloud computing paradigm has become the new industry standard way of designing large scale applications. Over the past years, we observe an increased adoption of this technology on numerous IoT- Edge applications. And while this technology comes with its promises and benefits, considering almost infinite scalability, it also comes along with its drawbacks and challenges. Detecting partial failures or bottlenecks are new obstacles that arose with the adoption of Cloud Applications. Distributed Tracing now allows developers to gain insight on the composition of services within a distributed Application. Today we observe an increased adoption of this technology on numerous cloud-native architectures. The project OpenTelemetry proposes a specification for traces that normalizes this new monitoring data format. In this publication we present an approach that leverages these traces to identify bottlenecks at the scale of a physically distributed application. We propose an extension of our model that builds a hierarchical property graph to exhibit bottlenecks in an application that follows the layered Cloud - IoT network model. Based on OpenTelemetry traces we can maintain a model at runtime of the whole application and compute bottlenecks. Their identification relies on the scores provided by centrality algorithms.","1976-7684","978-1-6654-1332-9","10.1109/ICOIN53446.2022.9687217","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9687217","Distributed Tracing;Multi-zones Cloud;Edge-IoT;Property Graph;Graph Rewriting;Hierarchical Model","Industries;Cloud computing;Runtime;Computational modeling;Scalability;Image edge detection;Computer architecture","","6","","20","IEEE","26 Jan 2022","","","IEEE","IEEE Conferences"
"SC-Chain: An Efficient Blockchain Framework for Smart City","K. Fan; H. Lu; Y. Bai; Y. Luo; Y. Yang; K. Zhang; H. Li","State Key Laboratory of Integrated Service Networks, School of Cyber Engineering, Xidian University, Xi’an, China; State Key Laboratory of Integrated Service Networks, School of Cyber Engineering, Xidian University, Xi’an, China; State Key Laboratory of Integrated Service Networks, School of Cyber Engineering, Xidian University, Xi’an, China; State Key Laboratory of Integrated Service Networks, School of Cyber Engineering, Xidian University, Xi’an, China; Key Laboratory of the Ministry of Education for Wide Band Gap Semiconductor Materials and Devices, Xidian University, Xi’an, China; Department of Electronical and Computer Engineering, University of Nebraska–Lincoln, Lincoln, NE, USA; State Key Laboratory of Integrated Service Networks, School of Cyber Engineering, Xidian University, Xi’an, China","IEEE Internet of Things Journal","21 Feb 2024","2024","11","5","7863","7877","To overcome the challenges of urbanization and population growth, smart cities use cutting-edge technologies, such as IoT and AI to offer improved public services. Although these advancements have brought convenience, they have raised security and privacy concerns. Blockchain technology has the potential to address these concerns, but existing blockchain frameworks have issues of scalability and efficiency that hinder their ability to meet the smart city demands. In this article, we propose a novel blockchain framework for smart cities, named SC-Chain. Specifically, SC-Chain incorporates a decentralized access mechanism that leverages threshold signatures and BFT-like consensus for efficient node registration and authentication in decentralized systems. Furthermore, we propose a consensus mechanism that utilizes the verifiable random function (VRF) to achieve efficient miner node election, ensuring efficiency, fairness, and security in large-scale smart city systems. We demonstrate the effectiveness and feasibility of the SC-Chain through theoretical analysis and simulations, showcasing its potential to enable the development of secure and efficient smart city infrastructure.","2327-4662","","10.1109/JIOT.2023.3317451","“Pioneer” and “Leading Goose” Research and Development Program of Zhejiang(grant numbers:2022C03174); National Natural Science Foundation of China(grant numbers:92067103,62002276); Key Research and Development Projects of Shaanxi Province(grant numbers:2021ZDLGY06-02); Natural Science Foundation of Shaanxi Province(grant numbers:2019ZDLGY1202); Shaanxi Innovation Team Project(grant numbers:2018TD-007); Xi’an Science and Technology Innovation Plan(grant numbers:20189168CX9JC10); Fundamental Research Funds for the Central Universities(grant numbers:YJS2212); National 111 Program of China(grant numbers:B16037); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10256090","Blockchain;consensus;Internet of Things (IoT);smart city","Blockchains;Smart cities;Internet of Things;Security;Consensus algorithm;Smart contracts;Data privacy","","","","49","IEEE","20 Sep 2023","","","IEEE","IEEE Journals"
"A Self-adaptive QoS-management Framework for Highly Dynamic IoT Networks","A. Bassene; B. Gueye","Université Cheikh Anta Diop de Dakar, Senegal; Université Cheikh Anta Diop de Dakar, Senegal","2022 IEEE Multi-conference on Natural and Engineering Sciences for Sahel's Sustainable Development (MNE3SD)","3 Mar 2022","2022","","","1","8","IoT infrastructure makes great demands on network control methods for dynamic and efficient management of massive amounts of nodes. Software-Defined Networking (SDN) enables to handle dynamically network traffic as well as flexible traffic control in real-time. However, while providing flexibility and scalability, SDN-based architecture still remains ineffective to self-adapt with respect to network topologies with more or less switches in the data plane (highly dynamic topology). Having a centralized control plane is not an acceptable situation because that would represent a single point of failure in the network. Using multiple controllers that ensure flexibility and high availability would be a solution; meaning that if one controller has problems and fails, the other would be ready to take over and control the network. Thus, having a single controller raises the problem of scalability while multiple controllers call for a distributed states management problem. To overcome such issues, we propose EFQM++, a selfadaptive framework for highly dynamic network topology changes. By leveraging SDN controller topology discovery mechanism, EFQM++ improves flow end-to-end transmission delay. It tackles flexibility and scalability related to a single point of failure problem and gives distributed states management solutions in large scale IoT networks. EFQM++ reduces up to 6% and 13% the average delay in contrast to previous works like EFQM and AQRA, respectively.","","978-1-6654-2152-2","10.1109/MNE3SD53781.2022.9723303","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9723303","Software-Defined Networking;Internet of Things;Performance;Quality of Service;Clustering.","Network topology;Scalability;Quality of service;Telecommunication traffic;Switches;Traffic control;Delays","","","","24","IEEE","3 Mar 2022","","","IEEE","IEEE Conferences"
"A Smart Wireless System to Automate Production of Crops and Stop Intrusion Using Deep Learning","M. Shrihari","Department of Computer Science, Amrita School of Arts and Sciences, Mysore, India","2020 Third International Conference on Smart Systems and Inventive Technology (ICSSIT)","6 Oct 2020","2020","","","1038","1045","The idea of automating the production of crops has existed since the early 90s and one of the major issues both scientists and farmers face, is the question of irrigation. An irrigation system is a dynamic system that is predominantly dependent on external covariant. This paper provides a methodology by utilizing a custom-built mathematical model which includes wireless sensors as a data source that is processed on Google Cloud there by providing a smart IoT enabled architecture that can be scaled even on large farms. Based on Holistic Agricultural surveys, around 35% of crops get destroyed due to animals and humans. This intelligent system is enabled with deep learning neural networks implemented with Tensorflow to identify animals based on its threat level and human intruders who are not authorized on the farm, and immediately report the intrusion to the farmer. The system is equipped with an android application that provides remote access to the system and surveillance through live video streaming.","","978-1-7281-5821-1","10.1109/ICSSIT48917.2020.9214303","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9214303","Raspberry pi;CNN;ZigBee;GCP;Beam I/O;Tensor flow;BigQuery;Dataflow","Sensors;Irrigation;Cloud computing;Animals;Mathematical model;Tensile stress","","2","","15","IEEE","6 Oct 2020","","","IEEE","IEEE Conferences"
"Smart Shopping Carts Based on Mobile Computing and Deep Learning Cloud Services","M. A. Sarwar; Y. -A. Daraghmi; K. -W. Liu; H. -C. Chi; T. . -U. İk; Y. -L. Li","Department of Computer Science, College of Computer Science, National Chiao Tung University 1001 University Road, Hsinchu City, Taiwan; Department of Computer Systems Engineering, Palestine Technical University Kadoorie, Tulkarem, Palestine; Department of Computer Science, College of Computer Science, National Chiao Tung University 1001 University Road, Hsinchu City, Taiwan; Department of Computer Science, College of Computer Science, National Chiao Tung University 1001 University Road, Hsinchu City, Taiwan; Department of Computer Science, College of Computer Science, National Chiao Tung University 1001 University Road, Hsinchu City, Taiwan; Department of Computer Science, College of Computer Science, National Chiao Tung University 1001 University Road, Hsinchu City, Taiwan","2020 IEEE Wireless Communications and Networking Conference (WCNC)","19 Jun 2020","2020","","","1","6","Self-checkout systems enable retailers to reduce costs and customers to process their purchases quickly without waiting in queues. However, existing self-checkout systems suffer from design problems as they require large hardware consisting of a camera, sensors, RFID and other IoT technologies which increases the cost of such systems. Therefore, we propose a smart shopping cart with self-checkout, called iCart, to improve customer’s experience at retail stores by enabling just walk out checkout and overcome the aforementioned problems. iCart is based on mobile cloud computing and deep learning cloud services. In iCart, a checkout event video is captured and sent to the cloud server for classification and segmentation where an item is identified and added to the shopping list. The Linux based cloud server contained the yolov2 deep learning network. iCart is a lightweight system of low cost solution which is suitable for the small-scale retail stores. The system is evaluated using real-world checkout video, and the accuracy of the shopping event detection and item recognition is about 97%. iCart demo can be found at URL: http://nol.cs.nctu.edu.tw/iCart/index.html.","1558-2612","978-1-7281-3106-1","10.1109/WCNC45663.2020.9120574","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9120574","smart shopping cart;iCart;just walk out technology;YOLOv2;frame classification;action segmentation;shopping event detection;self-checkout","Deep learning;Training;Cloud computing;Costs;Event detection;Streaming media;Sensor systems","","13","","30","IEEE","19 Jun 2020","","","IEEE","IEEE Conferences"
"Fuzzing attacks for vulnerability discovery within MQTT protocol","G. Casteur; A. Aubaret; B. Blondeau; V. Clouet; A. Quemat; V. Pical; R. Zitouni","ECE Paris Research Lab, 37 Quai de Grenelle, Paris, France; ECE Paris Research Lab, 37 Quai de Grenelle, Paris, France; ECE Paris Research Lab, 37 Quai de Grenelle, Paris, France; ECE Paris Research Lab, 37 Quai de Grenelle, Paris, France; ECE Paris Research Lab, 37 Quai de Grenelle, Paris, France; ECE Paris Research Lab, 37 Quai de Grenelle, Paris, France; ECE Paris Research Lab, 37 Quai de Grenelle, Paris, France","2020 International Wireless Communications and Mobile Computing (IWCMC)","27 Jul 2020","2020","","","420","425","This paper deals with the security issues of IoT networks and particularly with vulnerabilities of Message Queuing Telemetry Transport (MQTT) protocol. We proposed Fuzzing attack techniques to detect new security breaches in MQTT. Fuzz involves the random data generation and transmission to the input of MQTT brokers or clients in order to identify breaches by analyzing their responses. We focus on the development of a containerized test architecture as well as on the generation of scenarios using the Fuzzing. We chose Docker as a container of applications based on a single virtual machine. Through our empirical tests, we found Docker lighter and better efficient than traditional Virtual Machines. We demonstrated that the implementation of a fuzzing technique on Docker within small-scale is efficient to detect a number of MQTT security flaws.","2376-6506","978-1-7281-3129-0","10.1109/IWCMC48107.2020.9148320","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9148320","MQTT Protocol;IoT Security;Fuzzing;Docker;Containerization","Protocols;Fuzzing;Containers;Security;Payloads;Computer architecture;Servers","","7","","14","IEEE","27 Jul 2020","","","IEEE","IEEE Conferences"
"An 81.5dB-DR 1.25MHz-BW VCO-Based CT ΔΣ ADC with Double-PFD Quantizer","Y. Zhong; X. Tang; J. Liu; W. Zhao; S. Li; N. Sun",Tsinghua University; Univ. of Texas Austin; Tsinghua University; Univ. of Texas Austin; Georgia Institute of Technology; Tsinghua University,"2021 IEEE Custom Integrated Circuits Conference (CICC)","17 May 2021","2021","","","1","2","In the IoT era, VCO-based ΔΣ ADCs are showing growing popularity due to its highly digital architecture, thus allowing analog circuits to harness process scaling for low power, high speed, and high precision [1 ]-[6]. In such ADCs, the VCO integrates the voltage input into phase output, followed by the phase quantizer for digitization. To boost VCO-based ADC's energy efficiency, the high resolution and wide detection range phase quantizers are highly desired. However, current implementations still have limitations. For an N-stage dual VCO, the conventional XOR-based phase quantizer only detects the phase difference between 0 and π without the lead-lag information, leading to a small detecting range and low resolution of N [1]. A phase-extended quantizer (PEQ) [2],[4] extracts the lead-lag information, thus expanding the detection range from -ιτ to π and improving resolution to 2N. However, its lead-lag extraction requires accessing all output nodes of the VCO, largely increasing the circuit complexity and power. By detecting the rising edge of the dual VCO's outputs in each oscillation cycle, the PFD-based phase quantizer naturally extracts the lead-lag status and ensures full range (-2π to 2π) detection of the VCO phase information [3]. However, due to its single-edge detection, its phase resolution is limited to 2N. Additionally, the prior PFD-based quantizer suffers from 2X gain reduction.","2152-3630","978-1-7281-7581-2","10.1109/CICC51472.2021.9431499","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9431499","","Application specific integrated circuits;Voltage-controlled oscillators;Image edge detection;Conferences;Energy resolution;Lead;Analog circuits","","5","","6","IEEE","17 May 2021","","","IEEE","IEEE Conferences"
"Remote State Estimation With Asynchronous Mission-Critical IoT Sensors","M. Tang; S. Cai; V. K. N. Lau","Department of ECE, The Hong Kong University of Science and Technology, Hong Kong; Department of ECE, The Hong Kong University of Science and Technology, Hong Kong; Department of ECE, The Hong Kong University of Science and Technology, Hong Kong","IEEE Journal on Selected Areas in Communications","18 Feb 2021","2021","39","3","835","850","In this paper, we consider a mission-critical remote state estimation system with asynchronous massive access of the IoT sensors. We focus on remote state estimation stability of the system in the presence of asynchronous access of the sensors. Exploiting the sparsity in the observation matrix induced by the asynchronous access, we propose a low complexity 2-D message passing state estimation algorithm, where the cyclic loops in the 2-D factor graphs are removed based on the Gaussian-elimination-based quasi-diagonalization of the oversampled aggregated channel matrix of the IoT sensors. As a result, the proposed state estimation scheme is of low complexity and can achieve exact MAP estimation. Using Lyapunov drift analysis, we derive closed-form necessary and sufficient conditions for stability of the mission-critical remote state estimation system. We show that our proposed scheme can achieve significant performance gain over various state-of-the-art baselines for the large-scale system under asynchronous massive access.","1558-0008","","10.1109/JSAC.2020.3018800","Guangdong Basic and Applied Basic Research Foundation(grant numbers:2019A1515110781); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9174850","Mission-critical remote state estimation systems;asynchronous massive access;Lyapunov analysis;large scale system analysis;message passing algorithm","State estimation;Sensor systems;Wireless sensor networks;Wireless communication;Timing","","9","","34","IEEE","24 Aug 2020","","","IEEE","IEEE Journals"
"An Improved Genetic Algorithm for Safety and Availability Checking in Cyber-Physical Systems","Z. Wang; Y. Jin; S. Yang; J. Han; J. Lu","Faculty of Science and Engineering, The Open University of China, Beijing, China; School of Information Management and Statistics, Hubei University of Economics, Wuhan, China; Xingzhi College, Zhejiang Normal University, Jinhua, China; Department of Computer Science and Engineering, Zhejiang Normal University, Jinhua, China; Department of Computer Science and Engineering, Zhejiang Normal University, Jinhua, China","IEEE Access","16 Apr 2021","2021","9","","56869","56880","Cross-IoT infrastructure access frequently occurs when performing tasks in a distributed computing infrastructure of a cyber-physical system (CPS). The access control technology that ensure secure access cross-IoT infrastructure usually automatically establish relationships between user-attribute/role-permission. How to efficiently determine whether an automatic authorization access control state satisfies the safety and availability requirements of a system is a huge challenge. Existing work often focuses on a single aspect of safety or availability, while ignoring the differences between permissions and the differences between users. In this paper, we first propose a fine-grained personalization policy that takes into account the specificity of permissions/users and describes the safety, availability and efficiency requirements of an access control system in CPS. Second, we define a Personalization Policy Checking (PPC) Problem to determine whether a given personalization policy is satisfied in an access control state. We give the computational complexity of the PPC problem in different subcases, and show that it is NP-complete in general. Third, we design a binary genetic search algorithm, whose improvements mainly include continuous update and selection of the best chromosomes in the population for iteration, and exploring and determining the optimal crossover and mutation probabilities, thereby improving the convergence efficiency of the algorithm. Finally, simulation results show the effectiveness of our proposed algorithm, which is especially fit for the case that the computational overhead is even more important than the accuracy in a large-scale CPS system.","2169-3536","","10.1109/ACCESS.2021.3072635","National Natural Science Foundation of China(grant numbers:62072411,61872323); Zhejiang Provincial Natural Science Foundation of China(grant numbers:LR21F020001); Department of Education of Zhejiang Province(grant numbers:Y202043497); Social Development Project of Zhejiang Provincial Public Technology Research(grant numbers:2017C33054); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9400839","Access control;personalization policy;genetic algorithm;cyber-physical system","Access control;Safety;Task analysis;Genetic algorithms;Computational complexity;Authorization;Decision making","","1","","32","CCBY","12 Apr 2021","","","IEEE","IEEE Journals"
"Implementation of User Access Control based on Resource Hopping Multiple Access Scheme in mMTC Scenario","B. Feng; G. Ma; Y. Ma; D. Fei; J. Liao; X. Ou; B. Ai","State Key Laboratory of Advanced Rail Autonomous Operation, Beijing Jiaotong University; State Key Laboratory of Advanced Rail Autonomous Operation, Beijing Jiaotong University; State Key Laboratory of Advanced Rail Autonomous Operation, Beijing Jiaotong University; State Key Laboratory of Advanced Rail Autonomous Operation, Beijing Jiaotong University; Wuhan Maritime Communication Research Institute, Wuhan, China; Wuhan Maritime Communication Research Institute, Wuhan, China; State Key Laboratory of Advanced Rail Autonomous Operation, Beijing Jiaotong University","2023 IEEE 34th Annual International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC)","31 Oct 2023","2023","","","1","6","With the emergence of various IoT applications, a large-scale IoT system is set to revolutionize the various industry. Massive machine type communication will play a crucial role in providing robust support to this system. However, in mMTC, implementing user access control to block malicious users remains a critical issue that needs to be addressed. To this end, this paper proposes a user access control scheme based on resource hopping multiple access (RHMA). This scheme utilizes the unique resource hopping patterns of different users to control user access. The controllability of these resource hopping patterns effectively prevents malicious users from intruding into the system. Moreover, the proposed user access control scheme is implemented in practice with USRP platform. The experimental results confirm the reliability and effectiveness of the proposed access control system.","2166-9589","978-1-6654-6483-3","10.1109/PIMRC56721.2023.10293798","Fundamental Research Funds for the Central Universities; Fundamental Research Funds for the Central Universities; National Natural Science Foundation of China; Research and Development; Royal Society; Natural Science Foundation of Jiangsu Province; China Scholarship Council; Shenzhen Research Institute of Big Data; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10293798","mMTC;TSMA;frequency hopping;access control","Access control;Industries;Radio transmitters;Massive machine type communications;Controllability;Internet of Things;Reliability","","","","13","IEEE","31 Oct 2023","","","IEEE","IEEE Conferences"
"A Scheme on Pedestrian Detection using Multi-Sensor Data Fusion for Smart Roads","H. Wang; C. Li; Y. Zhang; Z. Liu; Y. Hui; G. Mao","State Key Laboratory of Integrated Services Networks, Xidian University, Xi’an, China; State Key Laboratory of Integrated Services Networks, Xidian University, Xi’an, China; State Key Laboratory of Integrated Services Networks, Xidian University, Xi’an, China; State Key Laboratory of Integrated Services Networks, Xidian University, Xi’an, China; State Key Laboratory of Integrated Services Networks, Xidian University, Xi’an, China; State Key Laboratory of Integrated Services Networks, Xidian University, Xi’an, China","2020 IEEE 91st Vehicular Technology Conference (VTC2020-Spring)","30 Jun 2020","2020","","","1","5","Transforming our roads into smart roads is an indispensable step towards future self-driving systems, and therefore has drawn increasing attention from both academia and industry. To this end, this paper develops a novel cost-effective IoT-based target detection system utilizing the multi-sensor data fusion technology with a particular focus on pedestrian detection, as an important component of smart road system. Particularly, the developed intelligent pedestrian detection module (${i}$PDM) consists of three major sensors, i.e., Doppler microwave radar sensor, passive infrared (PIR), and geomagnetic sensor. A multi-sensor data fusion algorithm is developed to fuse the sensor data and achieves reliable target detection. After that, ${i}$PDM sends the relevant warning signal wirelessly to nearby base station and vehicles. Experiments are conducted on real traffic environment to evaluate the performance of ${i}$PDM. The results validate the high reliability of ${i}$PDM with an average 91.7% detection accuracy. Moreover, to our best knowledge, ${i}$PDM is the first IoT-based implementation for pedestrian detection of smart roads. It is necessary to highlight that ${i}$PDM is a low-cost, low-power, wide-coverage pedestrian detection system where the cost of a single ${i}$PDM is only US $ 30, which makes it suitable to large-scale deployment.","2577-2465","978-1-7281-5207-3","10.1109/VTC2020-Spring48590.2020.9128855","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9128855","","Roads;Temperature sensors;Doppler effect;Intelligent sensors;Doppler radar","","","","12","IEEE","30 Jun 2020","","","IEEE","IEEE Conferences"
"Predicting Different Types of Imbalanced Intrusion Activities Based on a Multi-Stage Deep Learning Approach","R. Qaddoura; A. M. Al-Zoubi; I. Almomani; H. Faris","Faculty of Information Technology, Philadelphia University, Amman, Jordan; School of Science, Technology, and Engineering, University of Granada, Granada, Spain; Computer Science Department, Prince Sultan University, Riyadh, Saudi Arabia; King Abdullah II School for Information Technology, The University of Jordan, Amman, Jordan","2021 International Conference on Information Technology (ICIT)","26 Jul 2021","2021","","","858","863","Intrusion Detection Systems for IoT networks have emerged to solve the vulnerabilities caused by the extensive utilization of IoT devices for different applications. Intrusion Detection Systems are not only limited to predicting the existence of intrusion activities apart from the normal ones but it is also extended to identify different types of intrusion activities that allow for a larger scale of recovery actions toward solving this security breach. This study proposes a deep learning approach to detect different types of intrusion activities using a multistage mechanism and an oversampling process which solves the problem of the imbalanced data produced by the IoT devices. This work confirms that the selected classification techniques are not able to detect all types of intrusion for imbalanced data if not combined with the oversampling process. It also compares the proposed approach with other classification and deep learning techniques which consider the oversampling process as part of their pre-processing phase. The results presented in this work show that the proposed approach outperforms the other techniques in terms of Accuracy and G-mean and has an advantage over the other techniques in predicting the different types of intrusion in terms of Precision and Recall.","","978-1-6654-2870-5","10.1109/ICIT52682.2021.9491634","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9491634","intrusion detection;classification;deep learning;oversampling;SMOTE;imbalanced;IoTID20","Deep learning;Intrusion detection;Security;Information technology","","5","","34","IEEE","26 Jul 2021","","","IEEE","IEEE Conferences"
"CAROL: Confidence-Aware Resilience Model for Edge Federations","S. Tuli; G. Casale; N. R. Jennings","Department of Computing, Imperial College London, UK; Department of Computing, Imperial College London, UK; Loughborough University","2022 52nd Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN)","25 Jul 2022","2022","","","28","40","In recent years, the deployment of large-scale Inter-net of Things (IoT) applications has given rise to edge federations that seamlessly interconnect and leverage resources from multiple edge service providers. The requirement of supporting both latency-sensitive and compute-intensive IoT tasks necessitates service resilience, especially for the broker nodes in typical broker-worker deployment designs. Existing fault-tolerance or resilience schemes often lack robustness and generalization capability in non-stationary workload settings. This is typically due to the expensive periodic fine-tuning of models required to adapt them in dynamic scenarios. To address this, we present a confidence aware resilience model, CAROL, that utilizes a memory-efficient generative neural network to predict the Quality of Service (QoS) for a future state and a confidence score for each prediction. Thus, whenever a broker fails, we quickly recover the system by executing a local-search over the broker-worker topology space and optimize future QoS. The confidence score enables us to keep track of the prediction performance and run parsimonious neural network fine-tuning to avoid excessive overheads, further improving the QoS of the system. Experiments on a Raspberry-Pi based edge testbed with IoT benchmark applications show that CAROL outperforms state-of-the-art resilience schemes by reducing the energy consumption, deadline violation rates and resilience overheads by up to 16, 17 and 36 percent, respectively.","2158-3927","978-1-6654-1693-1","10.1109/DSN53405.2022.00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9833585","Edge Federations;Service Resilience;Confidence-Aware;Generative Models;Deep Learning","Adaptation models;Network topology;Neural networks;Quality of service;Predictive models;Robustness;Topology","","1","","53","IEEE","25 Jul 2022","","","IEEE","IEEE Conferences"
"A Situation Calculus based approach to Cognitive Modelling for Responding to IoT Cyberattacks","P. K. Chouhan; L. Chen; T. Hussain; A. Beard","School of Computing, Ulster Universit, Jordanstown, UK; School of Computing, Ulster Universit, Jordanstown, UK; School of Computing, Ulster Universit, Jordanstown, UK; Applied Research BT Labs, Ipswich, UK","2021 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/IOP/SCI)","18 Nov 2021","2021","","","219","225","Both the sophistication and scale of cyberattacks are increasing, revealing the extent of risks at which critical infrastructure and other information and communication systems are exposed. Furthermore, the introduction of IoT devices in a number of different applications, ranging from home automation to the monitoring of critical infrastructure, has created an even more complicated cybersecurity landscape. A large amount of research has been done on detecting these attacks in real time, however mitigation is left to security experts, which is time consuming and may have economic consequences. In addition, there is no public data available for action selection that could enable the use of the latest techniques in machine learning or deep learning for this area. Currently, most systems deploy a rule-based response selection methodology for mitigating detected attacks. In this paper, we introduce a situation calculus-based approach to automated response for IoT cyberattacks. The approach offers explicit semantic-rich cognitive modeling of attacks, effects and actions and supports situation inference for timely and accurate responses. We demonstrate the effectiveness of our approach for modelling and responding to cyberattacks by implementing a use case in a real-world IoT scenario.","","978-1-6654-1236-0","10.1109/SWC50871.2021.00038","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9604399","Cognitive Model;Intrusion response;Cybersecurity;Cyberattacks;Internet of Things;Situation Calculus;Epistemic Logic;Dynamic Logic","Economics;Technological innovation;Home automation;Smart cities;Biological system modeling;Real-time systems;Critical infrastructure","","","","15","IEEE","18 Nov 2021","","","IEEE","IEEE Conferences"
"SHAKE: SHared Acceleration Key Establishment for Resource-Constrained IoT Devices","E. Bejder; A. K. Mathiasen; M. De Donno; N. Dragoni; X. Fafoutis","DTU Compute, Technical University of Denmark, Denmark; DTU Compute, Technical University of Denmark, Denmark; DTU Compute, Technical University of Denmark, Denmark; DTU Compute, Technical University of Denmark, Denmark; DTU Compute, Technical University of Denmark, Denmark","2020 IEEE 6th World Forum on Internet of Things (WF-IoT)","13 Oct 2020","2020","","","1","6","IoT security for resource-constrained devices is largely based on symmetric block ciphers, such as AES. In such resource-constrained contexts, and particularly in the case of large-scale IoT deployments with multiple devices, the installation of encryption keys can pose a significant challenge. This paper presents SHAKE (SHared Acceleration Key Establishment): a convenient means to generate and install secret keys in IoT devices during deployment. Using SHAKE, an IoT deployment technician can generate and install a shared encryption key on two devices by holding them together and shaking them. SHAKE, operating on each of the devices, captures these movements from an on-board accelerometer and generates a secret key based on the shared acceleration profile. We provide a proof-of-concept implementation of SHAKE for the Contiki-NG operating system and assess its security against mimic attacks, that is the scenario whereby an eavesdropper with a clear line of sight to the deployment technician tries to mimic the random movements to generate the same key. Finally, we assess the energy requirements for generating a 128-bit key with SHAKE and we compare it against state-of-the-art methods for key generation.","","978-1-7281-5503-6","10.1109/WF-IoT48130.2020.9221263","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9221263","Secret key generation;IoT security;IoT deployments;Resource-constrained devices;Internet of Things","Accelerometers;Ciphers;Operating systems;Encryption;Security;Internet of Things","","6","","33","IEEE","13 Oct 2020","","","IEEE","IEEE Conferences"
"IoT Device Fingerprinting on Commodity Switches","C. Kuzniar; M. Neves; V. Gurevich; I. Haque",Dalhousie University; Dalhousie University; Intel BXD; Dalhousie University,"NOMS 2022-2022 IEEE/IFIP Network Operations and Management Symposium","9 Jun 2022","2022","","","1","9","IoT devices such as wearables, voice assistants and home appliances are becoming an integral part of our lives. However, these devices still represent a security and privacy risk with large-scale coordinated attacks often populating the news. The ability to tell which IoT devices are where in a network (i.e., to fingerprint them) can help administrators to mitigate such attacks at the earliest stages. While fingerprinting solutions exist, they often work offline, depend on sampled data or rely on payload information to work. In this paper, we propose PoirIoT, a high-speed in-network system for fingerprinting IoT devices. PoirIoT is based only on packet metadata (e.g., length and direction) and can detect a device as soon as it exchanges its first packets. We implement a prototype of PoirIoT on a Tofino-based programmable switch and show it can detect all possible IoT devices on a publicly available dataset. Moreover, PoirIoT runs at line rate and incurs minimal resource overhead on the programmable switch ASIC.","2374-9709","978-1-6654-0601-7","10.1109/NOMS54207.2022.9789865","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9789865","","Privacy;Wearable computers;Prototypes;Switches;Fingerprint recognition;Metadata;Internet of Things","","1","","35","IEEE","9 Jun 2022","","","IEEE","IEEE Conferences"
"IoT based Real Time Health Monitoring","V. Yeri; D. C. Shubhangi","Dept. of VLSI Design & Embedded System, VTU Centre for PG Studies, Kalaburagi, India; VTU Centre for PG Studies, Kalaburagi, India","2020 Second International Conference on Inventive Research in Computing Applications (ICIRCA)","1 Sep 2020","2020","","","980","984","Conventional sensor based diagnosis in medial field requires more number of sensors and human efforts if it is processed in a large scale. It is a difficult task due to the shortage of medical professionals and system setup. To overcome this issue an IoT based health care application is proposed in the research work. The proposed system consists of the web and mobile application based on continuous wireless monitoring of patients. The objective is paper is to implement a low-cost system and transmit the patient vital signs in emergency situations. Sensors are being used for measuring the patient vital signs by using the wireless network. The sensors data are collected and transmitted to the cloud for storage via Wi-Fi module connected with the controller. The data is processed in the cloud and feedback steps are taken on the analysed data which can be further analysed by a doctor remotely. Remote viewing reduces burden to doctors and provides the exact health status of patients. If the patient needs urgent attention then a message is sent to the doctor.","","978-1-7281-5374-2","10.1109/ICIRCA48905.2020.9183194","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9183194","Arduino;Health;monitoring;patient;IoT;sensor;wireless","Monitoring;Temperature measurement;Medical services;Temperature sensors;Cloud computing;Wireless sensor networks;Wireless communication","","43","","20","IEEE","1 Sep 2020","","","IEEE","IEEE Conferences"
"Wearable smart multimeter equipped with AR glasses based on IoT platform","K. Xia; T. Tang; Z. Mao; Z. Zhang; H. Qu; H. Li","College of Innovation and Entrepreneurship, University of Shanghai for Science and Technology, Shanghai, China; Electrical Engineering Department, University of Shanghai for Science and Technology, Shanghai, China; Electrical Engineering Department, University of Shanghai for Science and Technology, Shanghai, China; Electrical Engineering Department, University of Shanghai for Science and Technology, Shanghai, China; Electrical Engineering Department, University of Shanghai for Science and Technology, Shanghai, China; Electrical Engineering Department, University of Shanghai for Science and Technology, Shanghai, China","IEEE Instrumentation & Measurement Magazine","22 Oct 2020","2020","23","7","40","45","A new digital measurement system is presented in this manuscript. A wearable smart measurement system equipped with monocular augmented reality (AR) glasses and Wi-Fi and Bluetooth modules is designed, which is more suitable for high-altitude measurement occasions than traditional digital multimeters (DMM). The measurement data could be displayed on AR glasses supported by Bluetooth module in real time. Also, the effective management of large-scale industrial measurement data could be implemented through the IoT data interaction platform with high speed communication by employing a Wi-Fi module. In addition, the wire-receiving device is introduced into the system, which effectively solves the problem that occurs when the traditional DMM harness is tangled. Hall sensors are adopted to measure the current and solves the problem that the traditional DMM needs to be connected into an electronic circuit in series.","1941-0123","","10.1109/MIM.2020.9234764","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9234764","","Current measurement;Frequency measurement;Semiconductor device measurement;Glass;Augmented reality;Time measurement;Bluetooth;Sensors;Real-time systems;Smart devices;Wearable computers","","6","","12","IEEE","22 Oct 2020","","","IEEE","IEEE Magazines"
"Renewable Energy Generation and Grid Synchronization using IOT","S. Sivaranjani; S. Logashri; C. K. Pavithra; T. Pavithra; S. Puviarasi","Sri Krishna College of Engineering and Technology, Coimbatore, India; Sri Krishna College of Engineering and Technology, Coimbatore, India; Sri Krishna College of Engineering and Technology, Coimbatore, India; Sri Krishna College of Engineering and Technology, Coimbatore, India; Sri Krishna College of Engineering and Technology, Coimbatore, India","2022 IEEE World Conference on Applied Intelligence and Computing (AIC)","18 Aug 2022","2022","","","492","496","Since the fossil fuel are reducing there is a need to switch on to an alternative renewable source in order to produce Energy, because energy in present days play a vital role in our Life for which renewable energy sources such as solar, wind, tidal, biomass, geothermal are considered as most promising alternatives to reduce fossil-fuel-based consumption. But still, depend on large scale Energy Generation plants for energy which here used every day. But in this proposed system an efficient system for Energy Production is done using renewable energy such as wind and solar through which here can produce energy in our private lands or households which it can use it for ourselves and transfer it through grids so that others can also get benefitted and can make easy profit through our grid synchronization and monitoring system through IOT. Even in the case of efficient use of renewable energy, the data analysis has greater value, for better the analysis, better the efficient and effective use. Data logging of Wind turbine or Solar Panel is done by collecting and communicating the data to the cloud server. This way ourselves can produce the energy for our consumption and can also be efficiently transferred to Grids and make Profit.","","978-1-6654-7988-2","10.1109/AIC55036.2022.9848846","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9848846","Renewable Energy;Fossil fuel;Profit Generation Plants;Private lands;Households;Grid Synchronization;Monitoring system;IOT (Internet of Things).","Renewable energy sources;Wind energy;Switches;Production;Wind turbines;Synchronization;Internet of Things","","3","","13","IEEE","18 Aug 2022","","","IEEE","IEEE Conferences"
"Big Data Analytics and Visualization of Residential Electricity Consumption Behavior based on Smart Meter Data","R. Mathumitha; P. Rathika; K. Manimala","Anna University, Chennai, India; Dept. of ECE, PSN clg of Engg., Tirunelveli, India; Dept. of EEE, Dr.Sivanthi Aditanar clg of Engg., Tiruchendur, India","2022 International Conference on Breakthrough in Heuristics And Reciprocation of Advanced Technologies (BHARAT)","17 Oct 2022","2022","","","166","171","Detecting unusual electricity usage behavior has grown increasingly crucial in recent years. It is now possible for homeowners to collaborate with utilities in the electricity consumption of their appliances due to the lively growth of IoT-based home appliances and smart meter system. As a result, the proposed work permits homeowners to regulate their home appliances' energy use and compare it to the total consumption of their local community. To increase the stability of the grid and efficiency of the energy, smart meter system is implemented and also to improve customer service. Its goal is to assist utilities and consumers in gaining a better understanding of power usage patterns. Existing research, on the other hand, frequently concentrates on algorithm enhancement while ignoring the process of getting features. In this paper, with an optimal big data mathematical technique, we use a computational cluster which is based on Hadoop Distributed File System (HDFS). To gain access to individual homes, more smart meter data are simulated. For managing energy big data, utility companies can use a computing cluster and distributed storage to undertake customer load analysis and visualization on a larger scale.","","978-1-6654-3625-0","10.1109/BHARAT53139.2022.00043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9914913","Smart meter data;electricity consumption and visualization;Big data analytics and IoT","Home appliances;Data visualization;Big Data;Power system stability;Smart meters;Stability analysis;Real-time systems","","2","","15","IEEE","17 Oct 2022","","","IEEE","IEEE Conferences"
"Implementation of Complete Glaucoma Diagnostic System Using Machine Learning and Retinal Fundus Image Processing","D. Doan; P. T. T. Ho; T. T. Nguyen; T. N. Ngo; T. T. T. Pham; M. S. Nguyen","University of Information Technology, Ho Chi Minh City, Vietnam; Ho Chi Minh City Eye Hospital, Ho Chi Minh City, Vietnam; University of Information Technology, Ho Chi Minh City, Vietnam; University of Information Technology, Ho Chi Minh City, Vietnam; Ho Chi Minh City Eye Hospital, Ho Chi Minh City, Vietnam; University of Information Technology, Ho Chi Minh City, Vietnam","2022 International Conference on Advanced Computing and Analytics (ACOMPA)","9 Jan 2023","2022","","","66","71","Glaucoma is one of the leading diseases causing irreversible blindness worldwide. Nearly 70 million individuals suffer from glaucoma globally in 2020 and by 2040 this number is expected to rise to 111.8 million. Moreover, half of the patients affected by glaucoma remain undiagnosed until a relatively late stage due to the slow and asymptomatic nature of the disease in its earlier stages. Early detection of glaucoma based on quality images is highly needed. Examining retinal fundus image is one of the popular screening approach for glaucoma. However, this approach is laborious with specific technological devices and requires eye specialists. It is therefore difficult to conduct in large scale of a country, especially with provincial medicine centers. In this paper, we introduce a complete real-time system for glaucoma classification, which can support eye doctors to diagnose the disease potential efficiently. Applying latest technologies, we build a complete system including IoT device for retinal funus image processing, machine learning on cloud for glaucoma classification, and an desktop application for glaucoma diagnostic. According to our review, this is the first complete system in this field with the classification accuracy of 85%.","","978-1-6654-6171-9","10.1109/ACOMPA57018.2022.00017","Technology Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10005592","Glaucoma screening;image processing;machine learning;IoT application","Image processing;Machine learning;Medical services;Blindness;Retina;Real-time systems;Internet of Things","","2","","19","IEEE","9 Jan 2023","","","IEEE","IEEE Conferences"
"A Sensor System for Non-Destructive Monitoring of Food Ripening Processes","A. Zompanti; S. Grasso; M. Santonico; G. Pennazza","Department of Engineering, Unit Of Electronics For Sensor Systems, Campus Bio-Medico University of Rome, Rome, Italy; Department of Engineering, Unit Of Electronics For Sensor Systems, Campus Bio-Medico University of Rome, Rome, Italy; Department of Science and Technology for humans and the environment, Unit Of Electronics For Sensor Systems, Campus Bio-Medico University of Rome, Rome, Italy; Department of Engineering, Unit Of Electronics For Sensor Systems, Campus Bio-Medico University of Rome, Rome, Italy","2020 IEEE International Workshop on Metrology for Industry 4.0 & IoT","10 Jul 2020","2020","","","80","83","Food quality, processing and preservation are nodal points in the block chain of food industry. In this context the key points are: non-destructive approach and a design oriented to IoT applications. In this work dry cured ham has been selected as food product for a pilot study checking for feasibility in a large-scale food industry scenario. A measure chain including a non-destructive sampling device and a gas sensor array have been designed and fabricated. The sampler, named FLUTE (Food Life Upkeep Tester), has been patented. It has shown to be effective in a minimal invasive capture of ham aroma during the curing process. The aroma sampled has been analysed with a gas sensor array (named BIONOTE) based on quartz microbalances functionalized with anthocyanins. The dry-cured ham samples were obtained from the ham factory “Prosciuttificio di Bassiano srl” (Bassiano, Italy). A total number of 168 legs of ham were characterized through the BIONOTE system. The ripening stage was correctly classified in the 88.09% of the cases, with an error of 17 days in the worst case. The sensor system was also able to identify meat origin and place of ripening. This system could be developed for automated control of food quality along the block chain by uploading the classification model in cloud and moving the sensors inside the FLUTE.","","978-1-7281-4892-2","10.1109/MetroInd4.0IoT48571.2020.9138308","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138308","Gas Sensors;Anthocyanins;ripening;dry-cured ham;artificial sensorial system;Food quality control","Food industry;Process control;Quality control;Sensor systems;Production facilities;Blockchains;Internet of Things","","1","","14","IEEE","10 Jul 2020","","","IEEE","IEEE Conferences"
"Development of Wireless Emulator for Large-Scale IoT Applications","H. Harada; H. Masaki","Graduate School of Informatics, Kyoto University, Kyoto, Japan; Graduate School of Informatics, Kyoto University, Kyoto, Japan","2022 IEEE 33rd Annual International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC)","20 Dec 2022","2022","","","01","06","In this study, to evaluate large-scale IoT applications comprising numerous radio devices, we developed a wireless emulator that can evaluate various radio communication systems in cyberspace, without requiring actual radio devices, in addition to verifying transmission performance in an operation similar to actual operations. Because the wireless emulator can separately and independently operate each radio node by porting software that realizes protocols other than the physical layer on the actual radio device to the emulator, the software can be implemented in the actual radio device as it is after completing the emulation. Furthermore, in the emulator, the topology of the network can be altered freely in cyberspace. Moreover, because the simulation of the physical layer is analyzed independently in the emulator, various applications can be evaluated, regardless of mobile and fixed communications. In this study, the Wi-SUN FAN system was adopted as the evaluation example of the wireless communication system using this emulator, star and tree topologies with Wi-SUN FAN nodes were formed in cyberspace, and transmission characteristics, such as average packet transmission success rate and average delay time, were evaluated. The characteristics were compared with the computer simulation results without actual operations and were consistent.","2166-9589","978-1-6654-8053-6","10.1109/PIMRC54779.2022.9977775","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9977775","wireless emulator;IoT;Wi-SUN FAN;multi-hop","Wireless communication;Fans;Protocols;Emulation;Cyberspace;Physical layer;Software","","1","","9","IEEE","20 Dec 2022","","","IEEE","IEEE Conferences"
"Advances in Deterministic Wireless Channel Characterization for IoT Applications","F. Falcone","Public University of Navarra, Pamplona, Spain","2020 Global Congress on Electrical Engineering (GC-ElecEng)","10 Dec 2020","2020","","","XXI","XXI","Summary form only given. There has been a steady growth in the implementation and adoption of context aware environments, with particular focus in Smart Cities and Smart regions. Large scale massive deployments, with flexible location and mobile links are leading to the use of multiple wireless communication systems in order to enable end to end connectivity. The deployment and operation of these wireless systems is challenging, owing to complex configuration of structural elements within the scenarios of operation, highly dynamic channels owing to mobility, interference handling or the constraints in the use of wearable devices. In this presentation we will analyze the challenges in wireless channel characterization to enable IoT applications. Different channel analysis techniques will be desribed, as well as application to different case studies within the scope of Smart Cities and Smart Regions.","","978-1-938302-00-8","10.23919/GC-ElecEng48342.2020.9286277","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9286277","","Wireless communication;Smart cities;Internet of Things;Electromagnetics;Context-aware services;Wearable computers;Technological innovation","","","","","","10 Dec 2020","","","IEEE","IEEE Conferences"
"A Tale of Two C’s: Convergence and Composability","İ. Altintaş",San Diego Supercomputer Center,"2021 IEEE International Parallel and Distributed Processing Symposium (IPDPS)","28 Jun 2021","2021","","","1","1","Summary form only given, as follows. The complete presentation was not made available for publication as part of the conference proceedings. Cyberinfrastructure is everywhere in diverse forms in service of applications in science, business and society. From IoT to extreme-scale computing data and computing have never been so distributed with the potential for real-time integration into these applications. The common theme to these applications, mostly composed of (big) data-integrated workloads, is their need to run in specialized environments for reasons such as on-demand or 24x7 nature of the tasks they are performing, and difficulties regarding their portability, latency, privacy, and performance optimization. Moreover, in many data-driven scientific applications, there is a need for heterogeneous integration of tasks requiring specialized computing capabilities with traditional high-throughput computing or high-performance computing tasks. Although some key middleware technologies enabled demonstration of standalone heterogeneous applications, such integration requires expertise convergence from a large group of people in very specialized settings. There are still many challenges for streamlined, scalable, repeatable, responsible, and explainable integration of data-integrated applications. Key opportunities for further innovations include intelligent systems and automated workflow management software that can compose and steer dynamic applications that can adapt to changing conditions in a data-driven fashion while integrating many tools to explore, analyze and utilize data. This talk will discuss some examples for data-integrated applications, describe emerging systems that enabled these applications, and overview our recent research to enable composable applications including a convergence application development methodology, intelligent middleware, and workflow composition.","1530-2075","978-1-6654-4066-0","10.1109/IPDPS49936.2021.00001","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9458990","","Data science;Task analysis;Convergence;Supercomputers;Middleware;Distributed processing;Workflow management software","","","","","IEEE","28 Jun 2021","","","IEEE","IEEE Conferences"
"Cryptography model to secure IoT device endpoints, based on polymorphic cipher OTP","C. Bran; D. Flores; C. Hernández","IIIE, Universidad Don Bosco El Salvador; IIIE, Universidad Don Bosco El Salvador; IIIE, Universidad Don Bosco El Salvador","2022 IEEE 40th Central America and Panama Convention (CONCAPAN)","29 Dec 2022","2022","","","1","5","The security of data exchange between IoT components is of vital importance to avoid integrity breaches in M2M relationships.The main reason for incorporating complex encryption strategies is the processing and memory limitations of embedded systems. This paper proposes an efficient alternative for encrypting messages between two IoT components with processes that make use of keys that change with each new communication making it difficult for brute force attacks to gain access to the exchanged content. Additionally, the method adds a mutation of the encryption functions that adds another additional difficulty to decrypt the message since it depends not only on the key but also on the sequence of application of the decryption functions. The algorithm can be scaled up to end nodes with larger resources, so that the number of bits of the keys and the complexity of the encryption functions can be further increased, and since it is applied directly on the payload, it is independent of any other security method used in higher layers.","","978-1-7281-6715-2","10.1109/CONCAPAN48024.2022.9997589","TED; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9997589","Cryptography;Internet of Thing;One Time password;polymorphic cipher","Wireless communication;Ciphers;Protocols;Memory management;Force;Zigbee;Hardware","","","","25","IEEE","29 Dec 2022","","","IEEE","IEEE Conferences"
"Implementation and Evaluation of the Control Mechanism Among Distributed MQTT Brokers","K. Kosaka; Y. Noda; T. Yokotani; K. Ishibashi","Graduate School of Electrical Engineering and Electronics, Kanazawa Institute of Technology, Nonoichi, Japan; Mitsubishi Electric Information Network Corporation, Tokyo, Japan; Department of Electrical and Electronic Engineering, College of Engineering, Kanazawa Institute of Technology, Nonoichi, Japan; Department of Information and Computer Science, College of Engineering, Kanazawa Institute of Technology, Hakusan-shi, Japan","IEEE Access","1 Dec 2023","2023","11","","134211","134216","MQTT for IoT communication requires multiple brokers to aggregate traffic from localized areas. However, routing mechanisms among these brokers have yet to be specified. In this paper, the Distributed MQTT broker by data Link look-up for Traffic reduction (DMLT) is proposed as a new routing mechanism. This mechanism is aimed at layer-2 based control. It provides cooperation with MQTT and the Spanning Tree Protocol and invokes a traffic reduction and simplified transfer by an independent flow. We evaluate the performance of the DMLT method and compare the DMLT method and the conventional method in terms of traffic volume. According to the experimental results, a reduction in traffic volume is confirmed. We also build and verify a prototype of a wide-area DMLT (WDMLT) system, which is a method suitable for large-scale deployment of DMLT. Finally, the IoT DEP registered as an international standardization and its application to the proposed method is explained.","2169-3536","","10.1109/ACCESS.2023.3335273","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10329916","IoT;MQTT;multiple brokers;routing protocol;VPN","Routing;Switches;IP networks;Internet of Things;Virtual private networks;Wavelength division multiplexing;Linux","","","","20","CCBYNCND","28 Nov 2023","","","IEEE","IEEE Journals"
"Fog Computing: A Comprehensive Architectural Survey","P. Habibi; M. Farhoudi; S. Kazemian; S. Khorsandi; A. Leon-Garcia","Department of Electrical and Computer Engineering, University of Toronto, Toronto, Canada; Department of Computer Engineering and Information Technology, Amirkabir University of Technology, Tehran, Iran; Department of Computer Engineering and Information Technology, Amirkabir University of Technology, Tehran, Iran; Department of Computer Engineering and Information Technology, Amirkabir University of Technology, Tehran, Iran; Department of Electrical and Computer Engineering, University of Toronto, Toronto, Canada","IEEE Access","22 Apr 2020","2020","8","","69105","69133","Fog computing is an emerging technology to address computing and networking bottlenecks in large scale deployment of IoT applications. It is a promising complementary computing paradigm to cloud computing where computational, networking, storage and acceleration elements are deployed at the edge and network layers in a multi-tier, distributed and possibly cooperative manner. These elements may be virtualized computing functions placed at edge devices or network elements on demand, realizing the “computing everywhere” concept. To put the current research in perspective, this paper provides an inclusive taxonomy for architectural, algorithmic and technologic aspects of fog computing. The computing paradigms and their architectural distinctions, including cloud, edge, mobile edge and fog computing are subsequently reviewed. Practical deployment of fog computing includes a number of different aspects such as system design, application design, software implementation, security, computing resource management and networking. A comprehensive survey of all these aspects from the architectural point of view is covered. Current reference architectures and major application-specific architectures describing their salient features and distinctions in the context of fog computing are explored. Base architectures for application, software, security, computing resource management and networking are presented and are evaluated using a proposed maturity model.","2169-3536","","10.1109/ACCESS.2020.2983253","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9046806","Cloud Computing;edge computing;fog computing;Internet of Things (IoT);advanced internet architecture","Edge computing;Cloud computing;Computer architecture;Resource management;Security;Taxonomy;Software","","96","","191","CCBY","25 Mar 2020","","","IEEE","IEEE Journals"
"Collaboration of Network Operators and Cloud Providers in Software-Controlled Networks","J. Kwak; L. B. Le; G. Iosifidis; K. Lee; D. I. Kim","Daegu Gyeongbuk Institute of Science and Technology, Daegu, South Korea; University of Quebec, Quebec City, QC, Canada; Trinity College Dublin, Dublin, Ireland; Seoul National University, Seoul, South Korea; Sungkyunkwan University, Seoul, South Korea","IEEE Network","18 Sep 2020","2020","34","5","98","105","The next generation of networks will need to support massive requests for services that have very stringent performance requirements, and their delivery involves significant computing and storage resources. Prominent examples are the mobile augmented and virtual reality services, processing of large-scale IoT data, and mobile data analytics. In order to address these arising challenges, mobile network operators need innovative solutions, and one such is the close collaboration with the cloud service providers. In this article, we propose a novel system architecture that integrates the infrastructure of Mobile Network Operator (MNO) and Cloud Service Provider (CSP), leveraging recent developments in network softwarization that allows the unified control of the network, computing, and storage resources. We envision a multi-tier architecture where the CSP and MNO exchange real-time information about their resource availability and the users' needs, and jointly devise the servicing policy. We present a blueprint of the architecture, several application examples, and a numerical case study that focuses on distributed computing.","1558-156X","","10.1109/MNET.001.1800329","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9165549","","Collaboration;Computer architecture;Cloud computing;Data analysis;Servers;Delays;Integrated circuits","","7","","14","IEEE","12 Aug 2020","","","IEEE","IEEE Magazines"
"Towards Highly Scalable Runtime Models with History","L. Sakizloglou; S. Ghahremani; T. Brand; M. Barkowsky; H. Giese","Hasso Plattner Institute, University of Potsdam, Germany; Hasso Plattner Institute, University of Potsdam, Germany; Hasso Plattner Institute, University of Potsdam, Germany; Hasso Plattner Institute, University of Potsdam, Germany; Hasso Plattner Institute, University of Potsdam, Germany","2020 IEEE/ACM 15th International Symposium on Software Engineering for Adaptive and Self-Managing Systems (SEAMS)","19 Jun 2023","2020","","","188","194","Advanced systems such as IoT comprise many heterogeneous, interconnected, and autonomous entities operating in often highly dynamic environments. Due to their large scale and complexity, large volumes of monitoring data are generated and need to be stored, retrieved, and mined in a time- and resource-efficient manner. Architectural self-adaptation automates the control, orchestration, and operation of such systems. This can only be achieved via sophisticated decision-making schemes supported by monitoring data that fully captures the system behavior and its history. Employing model-driven engineering techniques we propose a highly scalable, history-aware approach to store and retrieve monitoring data in form of enriched runtime models. We take advantage of rule-based adaptation where change events in the system trigger adaptation rules. We first present a scheme to incrementally check model queries in the form of temporal logic formulas which represent the conditions of adaptation rules against a runtime model with history. Then we equip the model with the capability to retain only information that is relevant to queries. Finally, we demonstrate the scalability of our approach via experiments on a simulated smart healthcare system employing a real-world medical guideline.","2157-2321","978-1-4503-7962-5","10.1145/3387939.3388614","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10148713","runtime models;architectural self-adaptation;IoT;temporal graph conditions;memory efficiency;history-awareness;scalability","Adaptation models;Runtime;Scalability;Decision making;Medical services;Model driven engineering;Data models","","2","","40","","19 Jun 2023","","","IEEE","IEEE Conferences"
"Cloud-Edge Architecture With Virtualized Hardware Functionality for Real-Time Diagnosis of Transients in Smart Grids","N. Tzanis; E. Mylonas; P. Papaioannou; M. Birbas; A. Birbas; C. Tranoris; S. Denazis; A. Papalexopoulos","Department of Electrical and Computer Engineering, University of Patras, Patras, Greece; Department of Electrical and Computer Engineering, University of Patras, Patras, Greece; Department of Electrical and Computer Engineering, University of Patras, Patras, Greece; Department of Electrical and Computer Engineering, University of Patras, Patras, Greece; Department of Electrical and Computer Engineering, University of Patras, Patras, Greece; Department of Electrical and Computer Engineering, University of Patras, Patras, Greece; Department of Electrical and Computer Engineering, University of Patras, Patras, Greece; ECCO International Inc., San Francisco, CA, USA","IEEE Transactions on Cloud Computing","6 Jun 2023","2023","11","2","1230","1241","Edge Cloud is providing unprecedented opportunities for IoT and WAMS (Wide Area Monitoring Systems) in electrical grid operation. It is an orchestrated environment able to address low latency events through appropriate edge-cloud computing configurations. Transient State Estimation (TSE) is a key monitoring tool for capturing a reliable knowledge of the Smart Grid status in real-time, given the impediments introduced by the increasing penetration of Distributed Energy Resources in the energy mix. Frequency response anomalies, large scale transients, and voltage swings can be captured by TSE for real time or post failure data analytics. This work presents a cloud edge framework for the efficient calculation of TSE which, albeit its benefits, demands high computational resources at the edge (close to the measurement units) along with ultra low latency communications. The framework enables TSE as a service through the coordination of Virtual Machines (VMs) running on virtualized infrastructure and other non-virtualized physical nodes. In order to support the stringent time requirements, part of the TSE is offloaded to dedicated hardware acceleration units (FPGA). The proposed TSE framework is validated using an IEEE 30-bus, and the results show a significant superiority in terms of total latency compared to conventional cloud and edge deployments.","2168-7161","","10.1109/TCC.2023.3241698","H2020 European Project 5G-VICTORI(grant numbers:857201); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10035428","Cloud-Edge architecture;real-time transient state estimation;reconfigurable hardware;virtualization","Cloud computing;Computer architecture;Transient analysis;Real-time systems;State estimation;Monitoring;History","","","","27","IEEE","2 Feb 2023","","","IEEE","IEEE Journals"
"A Compact Wideband Joint Bidirectional Class-G Digital Doherty Switched-Capacitor Transmitter and N-Path Quadrature Receiver through Capacitor Bank Sharing","J. Lee; D. Jung; D. Munzer; H. Wang","Georgia Institute of Technology, Atlanta, GA; Georgia Institute of Technology, Atlanta, GA; Georgia Institute of Technology, Atlanta, GA; Georgia Institute of Technology, Atlanta, GA","2022 IEEE Custom Integrated Circuits Conference (CICC)","18 May 2022","2022","","","1","2","Spectrally efficient complex modulation schemes are widely employed to support the exponential growth in data traffic. However, this places stringent requirements on the RF electronic frontends, including stringent linearity, high Peak-to-Average-Power-Ratio (PAPR), large modulation bandwidth, and energy efficiency, which poses major challenges in traditional analog RF design. On the other hand, continuous device scaling enables energy-efficient device switching at RF frequencies, which has opened the door to growing research efforts towards digital transmitter (Tx) and receiver (Rx) frontends. Notably, the past few years have witnessed the demonstration of a wide variety of digital power amplifiers with multi-mode operations and back-off efficiency/linearity enhancement [1]–[3]. N-path mixer-first digital receivers remain a popular topic due to their inherent capabilities of high linearity, tunable frontend filtering, and wideband operations [4]. While digital RF frontends naturally offer excellent RF performance and extensive reconfigurability, they commonly rely on architectures based on binary and/or unary arrays of sliced active and passive devices, which inevitably results in substantial area overhead compared to their analog RF counterparts. In particular, capacitor banks are widely used in various digital RF frontends, i.e., switched-capacitor PAs and N-path receivers, which often occupy a majority of the chip area. However, numerous commercial applications, e.g., IOT devices, require extremely compact RF frontends to fit within the application formfactor and cost budget.","2152-3630","978-1-6654-0756-4","10.1109/CICC53496.2022.9772864","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9772864","","Radio frequency;Transmitters;Capacitors;Linearity;Power amplifiers;Receivers;Switches","","2","","6","IEEE","18 May 2022","","","IEEE","IEEE Conferences"
"GNN for Wireless Link Anomaly Detection","B. Bertalanič; M. Mohorčič; C. Fortuna","Department of Communication Systems, Jožef Stefan Institute, Slovenia; Department of Communication Systems, Jožef Stefan Institute, Slovenia; Department of Communication Systems, Jožef Stefan Institute, Slovenia","IEEE INFOCOM 2023 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)","29 Aug 2023","2023","","","1","2","In this paper, we present a new approach for detecting wireless link layer anomalies in large-scale IoT networks based on graph neural networks (GNN). We propose a method that transforms time series data into graphs with Markov Transition Field representation. The transformed data is then used to train a new GNN architecture that can successfully distinguish between 4 different link-layer anomalies and outperforms state-of-the-art shallow and deep learning methods.","2833-0587","978-1-6654-9427-4","10.1109/INFOCOMWKSHPS57453.2023.10225904","Slovenian Research Agency(grant numbers:P2-0016); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10225904","anomaly detection;wireless link;machine learning;graph neural network;graph transformation;time series","Wireless communication;Deep learning;Conferences;Time series analysis;Transforms;Computer architecture;Markov processes","","","","7","IEEE","29 Aug 2023","","","IEEE","IEEE Conferences"
"FPGA-ENABLED REAL-TIME POWER GRID SIMULATION USING GRID PARTITIONING","S. Stavropoulos; N. Tzanis; E. Mylonas; M. Birbas; A. Birbas; A. Papalexopoulos","Electrical and Computer Engineering Department, University of Patras, 26504 Patras, Greece; Electrical and Computer Engineering Department, University of Patras, 26504 Patras, Greece; Electrical and Computer Engineering Department, University of Patras, 26504 Patras, Greece; Electrical and Computer Engineering Department, University of Patras, 26504 Patras, Greece; Electrical and Computer Engineering Department, University of Patras, 26504 Patras, Greece; Ecco International Inc. San Francisco, CA 94104, USA","The 12th Mediterranean Conference on Power Generation, Transmission, Distribution and Energy Conversion (MEDPOWER 2020)","22 Sep 2021","2020","2020","","177","182","The high penetration of Distributed Energy Resources (DERs) and the IoT devices in the grid, as a result of policy regulations and economic considerations, physically located everywhere, in all shapes and sizes, both in front (FTM) and behind the meter (BTM) are fundamentally transforming the grid into a decentralized network of new grid assets that participate in multiple hierarchical energy markets. This transformation, however, creates challenges that needs to be managed. In order to adequately capture the transient behavior of the various grid components, detailed component models and Real-Time (RT) simulations are required. Leveraging their inherent parallelism capabilities, FPGA platforms help to achieve high-speed simulation execution, becoming a useful validation and planning tool for power grid management. However, the hardware utilization in these solutions is directly proportional to the size of the network under test, leading to expensive and hardly scalable architectures unsuitable for the simulation of large scale power networks. In this paper, a novel technique is presented, which aims to reduce the FPGA's resources utilization in distribution power grids. There are cases where part of the network under test can be partitioned in a number of identical subnetworks, whose output can be calculated by the same hardware module and thus lead to hardware utilization reduction. As proof of concept of the proposed approach, the implementations of a microgrid with and without applying the partitioning technique are demonstrated and compared in terms of accuracy, simulation speed and FPGA resources utilization.","","","10.1049/icp.2021.1273","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9543789","","","","","","","","22 Sep 2021","","","IET","IET Conferences"
"Easy-Turb: Light-weight cost-effective turbidity sensors for distributed underwater sensing systems","P. Wilmoth; P. Sundaravadivel","Department of Electrical Engineering, The University of Texas at Tyler, Tyler, Texas, USA; Department of Electrical Engineering, The University of Texas at Tyler, Tyler, Texas, USA","OCEANS 2022, Hampton Roads","19 Dec 2022","2022","","","1","4","The cleanliness of a water body can provide important insight on the health of the ecosystem. Turbidity is a measure of the relative clarity of a liquid; the less light that can pass through, the more turbid the liquid is. This is also how the turbidity sensor works, it measures the amount of infrared light which makes it through the liquid. Most turbidity sensors on the market are several thousand dollars. Our proposed sensor is low cost, low power, and has a wide range. This lower price allows users to deploy a swarm of sensors to collect data on a large scale. By integrating our sensor into an IoT framework of interconnected devices, we can track the turbidity of vast areas of water in real-time.","0197-7385","978-1-6654-6809-1","10.1109/OCEANS47191.2022.9977148","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9977148","Turbidity sensors;real-time quality estimation;underwater sensor","Temperature measurement;Temperature sensors;Liquids;Rain;Current measurement;Roads;Sea measurements","","","","10","IEEE","19 Dec 2022","","","IEEE","IEEE Conferences"
"A Privacy and Security Preservation Framework for D2D Communication Based Smart Grid Services","L. P. Bopape; B. Nleya; P. Khumalo","Department of Electronic & Computer Engineering, Faculty of Engineering, DUT, Durban, RSA; Department of Electronic & Computer Engineering, Faculty of Engineering, DUT, Durban, RSA; Department of Electronic & Computer Engineering, Faculty of Engineering, DUT, Durban, RSA","2020 Conference on Information Communications Technology and Society (ICTAS)","30 Apr 2020","2020","","","1","6","Long-Term-Evolution (LTE) based Device-to-Device (D2D) communication in future generation networks are envisaged to become the basis for deployment of various applications and services in Smart Grids (SGs). However related privacy and security aspects are also under serious consideration especially when dealing with large-scale deployment of services and applications related D2D groups. Current and legacy related algorithms cannot be applied directly to this new paradigm shift (i.e D2D communication and group formations). Using the IoT as the pillar communication subsystem for SGs, the service providers can deploy several applications and services some of which may include the acquisition and storage of personal information of individual SG users. However, the challenge will always be in the strict preservation of privacy and security of their personal data and thus a necessity in eliminating such concerns. In this paper we propose a general framework that employs a Group Key Management (GKM) mechanism to ensure enhanced privacy and security especially during the discovery and communication phases. We further mitigate on the impact of enhanced privacy and security in SG services and applications.","","978-1-7281-3770-4","10.1109/ICTAS47918.2020.233995","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9082450","IoT (Internet of Things);privacy;security;group authentication;D2D communications","","","","","18","IEEE","30 Apr 2020","","","IEEE","IEEE Conferences"
"Karonte: Detecting Insecure Multi-binary Interactions in Embedded Firmware","N. Redini; A. Machiry; R. Wang; C. Spensky; A. Continella; Y. Shoshitaishvili; C. Kruegel; G. Vigna",UC Santa Barbara; UC Santa Barbara; Arizona State University; UC Santa Barbara; UC Santa Barbara; Arizona State University; UC Santa Barbara; UC Santa Barbara,"2020 IEEE Symposium on Security and Privacy (SP)","30 Jul 2020","2020","","","1544","1561","Low-power, single-purpose embedded devices (e.g., routers and IoT devices) have become ubiquitous. While they automate and simplify many aspects of users' lives, recent large-scale attacks have shown that their sheer number poses a severe threat to the Internet infrastructure. Unfortunately, the software on these systems is hardware-dependent, and typically executes in unique, minimal environments with non-standard configurations, making security analysis particularly challenging. Many of the existing devices implement their functionality through the use of multiple binaries. This multi-binary service implementation renders current static and dynamic analysis techniques either ineffective or inefficient, as they are unable to identify and adequately model the communication between the various executables. In this paper, we present Karonte, a static analysis approach capable of analyzing embedded-device firmware by modeling and tracking multi-binary interactions. Our approach propagates taint information between binaries to detect insecure interactions and identify vulnerabilities. We first evaluated Karonte on 53 firmware samples from various vendors, showing that our prototype tool can successfully track and constrain multi-binary interactions. This led to the discovery of 46 zero-day bugs. Then, we performed a large-scale experiment on 899 different samples, showing that Karonte scales well with firmware samples of different size and complexity.","2375-1207","978-1-7281-3497-0","10.1109/SP40000.2020.00036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9152796","","Computer bugs;Web servers;Static analysis;Security;Tools;Prototypes;Microprogramming","","36","","55","IEEE","30 Jul 2020","","","IEEE","IEEE Conferences"
"On the Observability and Controllability of Large-Scale IoT Networks: Reducing Number of Unmatched Nodes via Link Addition","M. Doostmohammadian; H. R. Rabiee","Faculty of Mechanical Engineering, Semnan University, Semnan, Iran; Computer Engineering Department, ICT Innovation Center for Advanced Information and Communication Technology, Sharif University of Technology, Tehran, Iran","IEEE Control Systems Letters","5 Jan 2021","2021","5","5","1747","1752","In this letter, we study large-scale networks in terms of observability and controllability. In particular, we compare the number of unmatched nodes in two main types of Scale-Free (SF) networks: the Barabási-Albert (BA) model and the Holme-Kim (HK) model. Comparing the two models based on theory and simulation, we discuss the possible relation between clustering coefficient and the number of unmatched nodes. In this direction, we propose a new algorithm to reduce the number of unmatched nodes via link addition. The results are significant as one can reduce the number of unmatched nodes and therefore number of embedded sensors/actuators in, for example, an IoT network. This may significantly reduce the cost of controlling devices or monitoring cost in large-scale systems.","2475-1456","","10.1109/LCSYS.2020.3043637","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288728","Observability;controllability;clustering;unmatched nodes;scale-free network","Controllability;Observability;Observers;Clustering algorithms;Mathematical model;Tuning;Perturbation methods","","11","","40","IEEE","9 Dec 2020","","","IEEE","IEEE Journals"
"Agri Warehouse Management System","S. J. Kumaresan; M. Vikneswaran; P. Surai; S. Vignesh","Dept. of ECE, R.M.K. Engineering College, Kavaraipettai, Tamil Nadu, India; Dept. of ECE, R.M.K. Engineering College, Kavaraipettai, Tamil Nadu, India; Dept. of ECE, R.M.K. Engineering College, Kavaraipettai, Tamil Nadu, India; Dept. of ECE, R.M.K. Engineering College, Kavaraipettai, Tamil Nadu, India","2022 International Interdisciplinary Humanitarian Conference for Sustainability (IIHC)","17 Mar 2023","2022","","","705","709","Agricultural method has proved to be India's most vital source of wealth, with agricultural products accounting for 80 percent of rural communities' income. India's overall grain output is expected to rise by 2% to 303 million tons in the 2020–2021 harvest season, setting a new high. In comparison to other countries, this is a substantial amount of grain. Every year, the country wastes 67 million tons of food, valued approximately 92,000 crores. This is the same as feeding everyone in the state. Food waste must be reduced urgently, which demands the deployment of appropriate storage strategies to protect agricultural goods. Food safety is impacted from food waste, hence proper food storage is critical. They can cut down on losses while also increasing the amount of food accessible. In this project, we proposed a system that includes an embedded and IoT-enabled system that can be deployed in remote areas for small-scale farmers with very low accessibility. It includes OCP (monitoring, control, prevention) for storage parameters such as temperature, humidity, movement, theft detection, and smoke. There are two microcontrollers and various sensors to perform the operation. Multiple sensor nodes installed elsewhere in the warehouse. Provides farmers with information about the warehouse environment via mobile SMS and cloud websites.","","978-1-6654-5687-6","10.1109/IIHC55949.2022.10059944","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10059944","","Food waste;Temperature sensors;Microcontrollers;Humidity;Sensors;Safety;Temperature control","","","","7","IEEE","17 Mar 2023","","","IEEE","IEEE Conferences"
"Air Cleaning System Based On The Internet Of Things (IoT)","M. Sarosa; R. I. Hapsari; S. Adhisuwignjo; D. Moentamaria; B. Irawan; R. I. Putri; S. Wirayoga","Department of Electrical Engineering, State Polytechnic of Malang, Indonesia; Department of Civil Engineering, State Polytechnic of Malang, Indonesia; Department of Electrical Engineering, State Polytechnic of Malang, Indonesia; Dept. of Chemical Engineering, State Polytechnic of Malang, Indonesia; Dept. of Mechanical Engineering, State Polytechnic of Malang, Indonesia; Dept. of Electrical Engineering, State Polytechnic of Malang, Indonesia; Dept. of Electrical Engineering, State Polytechnic of Malang, Indonesia","2023 International Conference on Electrical and Information Technology (IEIT)","6 Dec 2023","2023","","","367","371","The problem of air pollution is one of the most crucial environmental problems and requires serious attention from all parties. One of the significant sources of air pollution is the burning of waste, especially in densely populated urban areas. Burning waste produces various harmful emissions, such as particles, gases, and toxic chemicals, that can endanger human health and the surrounding environment. To overcome this, the cleaning team hopes for increasingly advanced technological developments. An air purifier technology for burning waste has been developed, which can help reduce the adverse effects of air pollution. The air curtain method is quite effective in cleaning the air from burning waste, but its use is limited to a limited burning area and on a small scale. In a room that has been separated for gas with high carbon, it will be doused with water with a tool that has been made. As a result of these findings, water is used to clean up the pollutants in the burning waste. With the method of spraying water to remove some of the molecules of the pollutant. After that, the polluted air is cleaned, and a pump is used to return the water to the ceiling pipe. This is a method of eliminating air pollution, as shown by the water curtain device. For control, an IoT system will be used that is integrated with the application so that it can be monitored remotely. The system created is capable of reducing the carbon by around 10% to 15%.","","979-8-3503-2729-8","10.1109/IEIT59852.2023.10335547","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10335547","garbage;CO2 levels;burning;Air Curtain;IoT","Urban areas;Toxic chemicals;Spraying;Carbon dioxide;Air pollution;Water pollution;Cleaning","","","","10","IEEE","6 Dec 2023","","","IEEE","IEEE Conferences"
"PoRCH: A Novel Consensus Mechanism for Blockchain-Enabled Future SCADA Systems in Smart Grids and Industry 4.0","M. T. Hossain; S. Badsha; H. Shen","University of Nevada, Reno, NV, USA; University of Nevada, Reno, NV, USA; University of Nevada, Reno, NV, USA","2020 IEEE International IOT, Electronics and Mechatronics Conference (IEMTRONICS)","8 Oct 2020","2020","","","1","7","Smart Grids and Industry 4.0 (I4.0) are neither a dream nor a near-future thing anymore, rather it is happening now. The integration of more and more embedded systems and IoT devices is pushing smart grids and I4.0 forward at a breakneck speed. To cope up with this, the modification of age-old SCADA (Supervisory Control and Data Acquisition) systems in terms of decentralization, near-real-time operation, security, and privacy is necessary. In this context, blockchain technology has the potential of providing not only these essential features of the data acquisition process of future SCADA systems but also many other useful add-ons. On the other side, it is evident that various type of security breach tends to take place more during any economic turmoil. These can cause even more serious devastation to the global economy and human life. Thus, it is necessary to make our industries robust, automated, and resilient with secured and immutable data acquiring systems. This paper deals with the implementation scopes of blockchain in the data acquisition part of SCADA systems in the area of the smart grid and I4.0. There are several consensus mechanisms to support blockchain integration in the field cryptocurrencies, vehicular networks, healthcare systems, e-commerce, etc. But little attention has been paid for developing efficient and easy to implement consensus mechanisms in the field of blockchain-enabled SCADA systems. From this perspective, a novel consensus mechanism, which we call PoRCH (Proof of Random Count in Hashes), with a customized mining node selection scheme has been proposed in this paper. Also, a small-scale prototype of a blockchain-enabled data acquisition system has been developed. The performance evaluation of the implemented prototype shows the benefits of blockchain technology.","","978-1-7281-9615-2","10.1109/IEMTRONICS51293.2020.9216438","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9216438","Smart Grid;Industry 4.0;IoT;SCADA;Security;Blockchain;PoRCH","Data mining;Data acquisition;Servers;Protocols;Relays;Smart grids","","13","","20","IEEE","8 Oct 2020","","","IEEE","IEEE Conferences"
"An Extensive Study on Precision Farming Based on Crop Yield Using Integrated Approaches to Learning","K. Geetha; B. V. Vidhya; A. Kiran","Department of Computer Science, SRM University, Chennai, Tamil Nādu, India; Department of Computer Science, SRM University, Chennai, Tamil Nādu, India; Department of Computer Science and Engineering, MLR Institute of Technology, Hyderabad","2023 International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)","3 Jan 2024","2023","","","1","8","Precision agriculture aims to optimize the use of resources by tailoring them to specific field conditions. Previous research has investigated the use of IoT devices, remote sensing techniques, and machine learning algorithms to develop variable rate technology systems. Smart agriculture has been a topic of extensive research and development, with numerous studies focusing on different aspects of its implementation. Existing approaches use remote sensing techniques to predict the yield, but remote sensing imagery is typically acquired at a certain spatial resolution, which may need to be finer to capture small-scale variations within a field or distinguish individual plants or crops. This can limit the accuracy and precision of crop yield predictions, particularly when dealing with heterogeneous fields or small plot sizes. Traditional statistical models often assume linear relationships between input variables and crop yield. However, machine learning algorithms can identify and capture nonlinear relationships, interactions, and complex patterns in the data. This ability to model nonlinearities is particularly advantageous in agriculture, where multiple factors influence crop growth and yield and exhibit nonlinear behaviour. IoT sensors and imaging technologies can collect data on crop health indicators. Machine learning algorithms can analyze this data to identify patterns and detect early signs of crop diseases, nutrient deficiencies, or pest infestations. Early detection enables prompt action and targeted interventions, minimizing the spread of diseases and reducing the need for excessive pesticide use. This paper focuses on the comparative study of crop yield prediction and recommendation using different mechanisms.","","979-8-3503-0570-8","10.1109/RMKMATE59243.2023.10369738","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10369738","Precision Farming;Remote Sensing;IoT Sensors;Machine Learning;Statistical Models","Machine learning algorithms;Soft sensors;Soil properties;Vegetation mapping;Machine learning;Yield estimation;Internet of Things","","","","33","IEEE","3 Jan 2024","","","IEEE","IEEE Conferences"
"Throughput Enhancement in UAV-aided Wireless Sensor Networks via Wake-Up Radio Technology and Priority-based MAC Scheme","A. Trotta; M. D. Felice; L. Bononi; L. Perilli; E. F. Scarselli; T. S. Cinotti","Department of Computer Science and Engineering, University of Bologna, Italy; Department of Computer Science and Engineering, University of Bologna, Italy; Department of Computer Science and Engineering, University of Bologna, Italy; Department of Electrical, Electronic, and Information Engineering, University of Bologna, Italy; Department of Electrical, Electronic, and Information Engineering, University of Bologna, Italy; Department of Computer Science and Engineering, University of Bologna, Italy","2020 IEEE 6th World Forum on Internet of Things (WF-IoT)","13 Oct 2020","2020","","","1","6","UAV-aided Wireless Sensor Networks (WSNs) constitute an energy- and cost-effective solution for the deployment of large-scale IoT monitoring systems. At the same time, the integration of UAVs into IoT scenarios poses some practical challenges which are far to be addressed, like the synchronization issue (how can the Wireless Ground Sensors (WGSs) be aware of the presence of the UAV?) and the channel contention in high-dense scenarios (how can the WGSs cope with the limited transmission opportunity?). In this paper, we address both the issues above by proposing a novel Energy Load Aware Sensor To aIr Communication (ELASTIC) platform, supporting the deployment of scalable and energy-efficient UAV-aided WSNs. The proposal includes two main components, working in synergy at the PHY and MAC layers. First, the paper describes the design and implementation of Active Wake-up Radio mechanisms through which the WGSs can be notified of the UAV’s presence and hence of the transmission opportunity; the proposed architecture supports two operative modes (Switch and Low-Power) that can be properly orchestrated so that the energy consumption of the WGSs in standby phase is minimized. Second, since multiple WGSs can be activated from a wake-up signal and access the channel at the same time, a novel priority-based MAC scheme has been designed: the proposed solution performs distributed contention control among the WGSs, by taking into account the length of the transmission opportunity for each WGS and the actual channel load. The simulation results demonstrate that the proposed ELASTIC MAC protocol guarantees a +50% throughput improvement when compared to the legacy CSMA/CA MAC in high-dense WSNs, and show its ability to adapt to different traffic loads and UAV speeds.","","978-1-7281-5503-6","10.1109/WF-IoT48130.2020.9221487","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9221487","","Wireless communication;Wireless sensor networks;Simulation;Telecommunication traffic;Switches;Throughput;Media Access Protocol","","2","","18","IEEE","13 Oct 2020","","","IEEE","IEEE Conferences"
"Efficient and Secure Multi-User Multi-Task Computation Offloading for Mobile-Edge Computing in Mobile IoT Networks","I. A. Elgendy; W. -Z. Zhang; Y. Zeng; H. He; Y. -C. Tian; Y. Yang","School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; Department of Electrical and Computer Engineering, Stony Brook University, Stony Brook, NY, USA; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; School of Computer Science, QUT, Brisbane, QLD, Australia; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China","IEEE Transactions on Network and Service Management","9 Dec 2020","2020","17","4","2410","2422","Mobile edge computing (MEC) is a new paradigm to alleviate resource limitations of mobile IoT networks through computation offloading with low latency. This article presents an efficient and secure multi-user multi-task computation offloading model with guaranteed performance in latency, energy, and security for mobile-edge computing. It does not only investigate offloading strategy but also considers resource allocation, compression and security issues. Firstly, to guarantee efficient utilization of the shared resource in multi-user scenarios, radio and computation resources are jointly addressed. In addition, JPEG and MPEG4 compression algorithms are used to reduce the transfer overhead. To fulfill security requirements, a security layer is introduced to protect the transmitted data from cyber-attacks. Furthermore, an integrated model of resource allocation, compression, and security is formulated as an integer nonlinear problem with the objective of minimizing the weighted sum of energy under a latency constraint. As this problem is considered as NP-hard, linearization and relaxation approaches are applied to transform the problem into a convex one. Finally, an efficient offloading algorithm is designed with detailed processes to make the computation offloading decision for computation tasks of mobile users. Simulation results show that our model not only saves about 46% of system overhead consumption in comparison with local execution but also scale well for large-scale IoT networks.","1932-4537","","10.1109/TNSM.2020.3020249","Key Research and Development Program for Guangdong Province(grant numbers:2019B010136001); National Key Research and Development Plan(grant numbers:2017YFB0801801); National Natural Science Foundation of China (NSFC)(grant numbers:61672186,61872110); Shenzhen Science and Technology Research and Development Fundation(grant numbers:JCYJ20190806143418198); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9179773","Computation offloading;compression;Internet of Things (IoT);mobile-edge computing;optimization;security","Computational modeling;Cloud computing;Security;Task analysis;Energy consumption;Mobile handsets;Resource management","","97","","51","IEEE","28 Aug 2020","","","IEEE","IEEE Journals"
"IoT Enabled Real-Time Availability and Condition Monitoring of CNC Machines","B. Siddhartha; A. P. Chavan; G. K. HD; K. N. Subramanya","Department of Electronics and Communication Engineering, R. V. College of Engineering, Bangalore, India; Department of Electronics and Communication Engineering, R. V. College of Engineering, Bangalore, India; Mechanical Engineering Department, R. V. College of Engineering, Bangalore, India; Department of Industrial Engineering and Management, R. V. College of Engineering, Bangalore, India","2020 IEEE International Conference on Internet of Things and Intelligence System (IoTaIS)","23 Feb 2021","2021","","","78","84","One of the biggest challenges faced by the manufacturing industry is to improve productivity and process efficiency. Achieving zero downtime has been the goal of manufacturers since a long time, with the advancement in IoT making sensors inexpensive and compact with Industry 4.0 revolutionizing the complete manufacturing process, real-time monitoring and collection of data from all necessary perspectives can be done remotely. Industries manufacturing at large scale often find it difficult to monitor the condition of the machines and manufacturing process. Downtime due to machine faults and operator negligence contributes to machine inefficiency. This paper presents a multiple sensor-based condition and availability monitoring system deployed on a CNC machine. The major steps for preventive maintenance are daily checking of lubricant level, inspecting of vibration levels, and temperature of the motor. The IoT system uses sensors measuring Vibration, Current, temperature, and coolant levels of CNC machines. A cloud-based platform is created for displaying of real-time graphs of important parameters and Overall Equipment Effectiveness. The data collected from the machine can be used to quickly diagnose the problem and Availability monitoring can help to pinpoint the cause of downtime in the process. The proposed system is useful for remote condition monitoring and data-based decision-making process.","","978-1-7281-9448-6","10.1109/IoTaIS50849.2021.9359698","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9359698","IoT;CNC Machine;Condition Monitoring;Availability Monitoring","Temperature sensors;Temperature measurement;Vibrations;Real-time systems;Software;Sensors;Monitoring","","4","","12","IEEE","23 Feb 2021","","","IEEE","IEEE Conferences"
"A New IDS for Smart Home based on Machine Learning","T. Gazdar","Cybersecurity Department, University of Jeddah, Jeddah, Saudi Arabia","2022 14th International Conference on Computational Intelligence and Communication Networks (CICN)","13 Jan 2023","2022","","","393","400","IoT environments are highly diverse with regard to devices, applications, and communications protocols. Consequently, they are highly vulnerable to many new attacks specific to this particular network. Existing Intrusion detection systems have shown their inefficiency in loT and this is for many reasons related basically to the limited computation capability of the devices, their mobility, the inherent Internet connectivity, and the large scale of the IoT network. Thus, a lightweight and efficient intrusion detection system designed for loT is required. Inspired by the success of Machine Learning in many fields and its potential in attack detection, we propose in this paper an intrusion detection system for Smart Home. The main goal is to design a model that detects different attacks on different Smart Home devices. We aim to enhance the detection capabilities of our IDS by exploring different features allowing us to classify the input traffic as benign or malicious. More importantly, we seek to develop specific models to predict the type of attacks per device. To this end, we trained two ML and two DL models using an loT dataset named 10T/IIoT. The obtained results show that the ML algorithms trained after applying a feature selection technique outperforms the model where all features are used in the training. Besides, the ML models allow reaching accuracy values competing with the accuracy of DL models, further, they outperform DL models for some devices/attacks.","2472-7555","978-1-6654-8771-9","10.1109/CICN56167.2022.10008310","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10008310","Smart Home;Intrusion detection;Machine Learning;Deep Learning;feature selection","Training;Protocols;Computational modeling;Intrusion detection;Smart homes;Machine learning;Predictive models","","2","","24","IEEE","13 Jan 2023","","","IEEE","IEEE Conferences"
"PimCity: A Compute in Memory Substrate featuring both Row and Column Parallel Computing","S. Resch; H. Cılasun; M. Zabihi; Z. Chowdhury; Z. Zhao; J. -P. Wang; S. S. Sapatnekar; U. Karpuzcu","University of Minnesota, Twin Cities; University of Minnesota, Twin Cities; University of Minnesota, Twin Cities; University of Minnesota, Twin Cities; University of Minnesota, Twin Cities; University of Minnesota, Twin Cities; University of Minnesota, Twin Cities; University of Minnesota, Twin Cities","2023 IEEE International Conference on Rebooting Computing (ICRC)","15 Jan 2024","2023","","","1","10","Processing-in-memory (PIM) substrates can perform parallel computation directly within the memory array. As a result, throughput performance and energy efficiency can reach unprecedented levels, however, there are limitations. Typical PIM architectures only support parallel computing in one dimension of the memory array: Computation is performed along either multiple rows or multiple columns (but not both). This restricts data layout and makes intra-array intermediate data transfers during computation inevitable - which require reads and writes, even for short-distance data movement. Inter-array data transfers, on the other hand, become a problem for larger scale algorithms which use more than one PIM array. Such data transfers incur large communication overheads and increase the complexity of the peripheral circuitry and interconnection network between arrays. Intermediate data transfers of any form limit scalability and efficiency. To overcome this limitation, we introduce PimCity, a new PIM substrate which can compute in both the rows and the columns of the memory array. PimCity replaces intraarray data transfer (memory) operations with lower overhead logic operations inside the memory array. Further, PimCity can perform logic operations directly across neighboring memory arrays, which in turn enables low-cost inter-array data transfers. PimCity hence represents a scalable PIM architecture suitable for both HPC and embedded IoT style applications.","","979-8-3503-8204-4","10.1109/ICRC60800.2023.10386151","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10386151","","Multiprocessor interconnection;Scalability;Layout;Parallel processing;Data transfer;Throughput;Energy efficiency","","","","43","IEEE","15 Jan 2024","","","IEEE","IEEE Conferences"
"A Priority-Based Tag Identification Protocol for the Large-Scale RFID System","K. Guo; X. Xie; H. Qi; K. Li","School of Computer Science and Technology, Dalian University of Technology, Dalian, China; Department of Computing, The Hong Kong Polytechnic University, Hong Kong; School of Computer Science and Technology, Dalian University of Technology, Dalian, China; School of Computer Science and Technology, Dalian University of Technology, Dalian, China","IEEE Wireless Communications Letters","8 Dec 2021","2021","10","12","2772","2775","Radio Frequency Identification (RFID) technology has been widely deployed in IoT-enabled applications because of its cheapness, simultaneous multi-item-identification, and strong information storage capability. In a large-scale RFID system, all tags belong to different groups according to the item-associated brand, value, or danger class. However, the existing works assume that groups equally share the maximum identification efficiency 36.8% under the optimal parameter settings. This letter proposes a Priority-based Tag Identification (PTI) protocol for RFID systems. In PTI, the high priority group enjoys a higher identification efficiency than the low priority groups. This is achieved by using the priority queue technique, which enables the reader to detect the tags with the highest priority and only allows them to respond to the reader. Our experiments show that due to the benefit of priority queues, the maximum slot efficiency of the PTI protocol can be improved to 78.9%.","2162-2345","","10.1109/LWC.2021.3116949","Science Innovation Foundation of Dalian(grant numbers:2019J12GX037); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9555834","RFID;anti-collision;priority;tag identification","Protocols;Radiofrequency identification;Standards;Statistics;Sociology;Throughput;Estimation","","4","","13","IEEE","1 Oct 2021","","","IEEE","IEEE Journals"
"Developing a Scalable Network of High-Interaction Threat Intelligence Sensors for IoT Security","T. Zimmermann; E. Lanfer; N. Aschenbruck","Institute of Computer Science, Osnabrück University; Institute of Computer Science, Osnabrück University; Institute of Computer Science, Osnabrück University","2022 IEEE 47th Conference on Local Computer Networks (LCN)","26 Aug 2022","2022","","","251","253","In the last decade, numerous Industrial IoT systems have been deployed. Attack vectors and security solutions for these are an active area of research. However, to the best of our knowledge, only very limited insight in the applicability and real-world comparability of attacks exists. To overcome this widespread problem, we have developed and realized an approach to collect attack traces at a larger scale. An easily deployable system integrates well into existing networks and enables the investigation of attacks on unmodified commercial devices.","0742-1303","978-1-6654-8001-7","10.1109/LCN53696.2022.9843744","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9843744","Threat Intelligence Sensor;IoT;IIoT;Honeypots;Network Measurements;Network Security","Computer networks;Security;Intelligent sensors;Industrial Internet of Things","","","","9","IEEE","26 Aug 2022","","","IEEE","IEEE Conferences"
"Reservoir-Based Distributed Machine Learning for Edge Operation of Emitter Identification","S. Kokalj-Filipovic; P. Toliver; W. Johnson; R. Miller",Peraton Labs; Peraton Labs; Peraton Labs; Peraton Labs,"MILCOM 2021 - 2021 IEEE Military Communications Conference (MILCOM)","30 Dec 2021","2021","","","96","101","This paper has several contributions, all motivated by the operational aspects of in-situ retrainable Specific Emitter Identification (SEI) for authentication of mobile emitters at the Edge, tactical or IoT. The paper first provides a review of the prior work (DLR) that uses our design of reservoir delay loops (DL) to implement low-power, high accuracy and high-reliability classifiers of signals represented as time series of samples, capable of in-situ training at the Edge. We analyze those DLR properties that enable seamless authentication of mobile emitters on a larger scale using radio frequency (RF) fingerprints. Delay loops project the SEI inputs into a space where different input classes are linearly separable, allowing the use of a linear classifier for emitter identification. Moreover, the architecture of split loops enables a more effective linear separation, constraining the number of weight coefficients, which is important for efficient integration of locally trained DLRs into a global SEI model (D-DLR). D-DLR enables mobile edge platforms to authenticate and then track emitters. To authenticate mobile devices across large regions, D-DLR is trained in a distributed fashion with very little additional processing and a small communication cost, all while maintaining accuracy. We illustrate how to merge locally trained DLR SEI classifiers, and how to reliably detect unseen emitters using a simple multi-layer perceptron to which the DLR weights have been transferred.","2155-7586","978-1-6654-3956-5","10.1109/MILCOM52596.2021.9653098","DARPA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9653098","","Training;Image edge detection;Time series analysis;Neural networks;Transfer learning;Authentication;Reservoirs","","3","","11","IEEE","30 Dec 2021","","","IEEE","IEEE Conferences"
"Load-Altering Attacks Against Power Grids Under COVID-19 Low-Inertia Conditions","S. Lakshminarayana; J. Ospina; C. Konstantinou","School of Engineering, University of Warwick, Coventry, U.K; Los Alamos National Laboratory, Los Alamos, NM, USA; Computer, Electrical and Mathematical Sciences and Engineering (CEMSE) Division, King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia","IEEE Open Access Journal of Power and Energy","10 Jun 2022","2022","9","","226","240","The COVID-19 pandemic has impacted our society by forcing shutdowns and shifting the way people interacted worldwide. In relation to the impacts on the electric grid, it created a significant decrease in energy demands across the globe. Recent studies have shown that the low demand conditions caused by COVID-19 lockdowns combined with large renewable generation have resulted in extremely low-inertia grid conditions. In this work, we examine how an attacker could exploit these scenarios to cause unsafe grid operating conditions by executing load-altering attacks (LAAs) targeted at compromising hundreds of thousands of IoT-connected high-wattage loads in low-inertia power systems. Our study focuses on analyzing the impact of the COVID-19 mitigation measures on U.S. regional transmission operators (RTOs), formulating a plausible and realistic least-effort LAA targeted at transmission systems with low-inertia conditions, and evaluating the probability of these large-scale LAAs. Theoretical and simulation results are presented based on the WSCC 9-bus and IEEE 118-bus test systems. Results demonstrate how adversaries could provoke major frequency disturbances by targeting vulnerable load buses in low-inertia systems and offer insights into how the temporal fluctuations of renewable energy sources, considering generation scheduling, impact the grid’s vulnerability to LAAs.","2687-7910","","10.1109/OAJPE.2022.3155973","PETRAS National Centre of Excellence for IoT Systems Cybersecurity through the U.K. EPSRC(grant numbers:EP/S035362/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9726888","Load-altering attacks (LAAs);cybersecurity;low-inertia conditions;COVID-19;IoT-based attack vectors","COVID-19;Power grids;Renewable energy sources;Power system stability;Stability analysis;Pandemics;Open Access","","12","","49","CCBY","3 Mar 2022","","","IEEE","IEEE Journals"
"MQT-TZ: Hardening IoT Brokers Using ARM TrustZone : (Practical Experience Report)","C. Segarra; R. Delgado-Gonzalo; V. Schiavoni","Université de Neuchatel, Switzerland; CSEM; Université de Neuchatel, Switzerland","2020 International Symposium on Reliable Distributed Systems (SRDS)","12 Nov 2020","2020","","","256","265","The publish-subscribe paradigm is an efficient communication scheme with strong decoupling between the nodes, that is especially fit for large-scale deployments. It adapts natively to very dynamic settings and it is used in a diversity of real-world scenarios, including finance, smart cities, medical environments, or IoT sensors. Several of the mentioned application scenarios require increasingly stringent security guarantees due to the sensitive nature of the exchanged messages as well as the privacy demands of the clients/stakeholders/receivers. MQTT is a lightweight topic-based publish-subscribe protocol popular in edge and IoT settings, a de-facto standard widely adopted nowadays by the industry and researchers. However, MQTT brokers must process data in clear, hence exposing a large attack surface. This paper presents MQT-TZ, a secure MQTT broker leveraging ARM TRUSTZONE, a trusted execution environment (TEE) commonly found even on inexpensive devices largely available on the market (such as Raspberry Pi units). We define a mutual TLS-based handshake and a two-layer encryption for end-to-end security using the TEE as a trusted proxy. The experimental evaluation of our fully implemented prototype with micro-, macro-benchmarks, as well as with real-world industrial workloads from a MedTech use-case, highlights several tradeoffs using TRUSTZONE TEE. We report several lessons learned while building and evaluating our system. We release MQT-TZ as open-source.","2575-8462","978-1-7281-7626-0","10.1109/SRDS51746.2020.00033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9252059","trustzone, mqtt, arm, publish subscribe, iot, sensors","Smart cities;Prototypes;Publish-subscribe;Security;Reliability;Surface treatment;Standards","","4","","60","IEEE","12 Nov 2020","","","IEEE","IEEE Conferences"
"Age-Energy Tradeoff in Random-Access Poisson Networks","F. Zhao; X. Sun; W. Zhan; X. Wang; J. Gong; X. Chen","School of Electronics and Communication Engineering, Sun Yat-sen University (Shenzhen Campus), Shenzhen, China; School of Electronics and Communication Engineering, Sun Yat-sen University (Shenzhen Campus), Shenzhen, China; School of Electronics and Communication Engineering, Sun Yat-sen University (Shenzhen Campus), Shenzhen, China; School of Electronics and Information Technology, Sun Yat-sen University, Guangzhou, China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; School of Electronics and Information Technology, Sun Yat-sen University, Guangzhou, China","IEEE Transactions on Green Communications and Networking","23 Nov 2022","2022","6","4","2055","2072","Energy efficiency and Age of Information (AoI) are two key performance metrics for many emerging battery-limited fresh-aware IoT networks, where random access protocols, such as Aloha, are usually adopted. Yet, in large-scale random access scenarios, the energy efficiency and AoI performance would degrade severely if the network is not configured properly. This paper aims to address this issue by studying the performance limit of energy efficiency under AoI constraint and how to achieve such limit in a slotted Aloha-based Poisson bipolar network. Specifically, we evaluate the energy efficiency via the lifetime throughput, which is defined as the number of update packets successfully decoded by the receiver during the lifetime of each transmitter. The explicit expression of the lifetime throughput is derived, based on which the maximum lifetime throughput with or without AoI constraint and the corresponding optimal channel access probability and packet arrival rate are characterized. The analysis reveals that both the maximum lifetime throughput and AoI-optimal lifetime throughput decline as the node density increases, while the gap between them would be non-negligible if the power ratio of the transmission state and the waiting state is large. Further with AoI constraint, it is shown that the AoI-constrained maximum lifetime throughput has to be sacrificed if the constraint is stringent. The effects of key system parameters on the optimal network configurations and age-energy tradeoff are also discussed, which provide important insights on practical battery-limited fresh-aware IoT network design.","2473-2400","","10.1109/TGCN.2022.3210138","Key-Area Research and Development Program of Guangdong Province(grant numbers:2019B010158001); National Natural Science Foundation of China(grant numbers:62001524,62271513,62171481); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2021A1515012631); Shenzhen Science and Technology Program(grant numbers:RCBS20210706092408010,2021A04); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9904522","Energy efficiency;age of information;random access;lifetime throughput;Aloha","Throughput;Interference;Transmitters;Optimization;Internet of Things;Signal to noise ratio;Information age","","3","","49","IEEE","27 Sep 2022","","","IEEE","IEEE Journals"
"FerroElectronics for Edge Intelligence","A. Keshavarzi; K. Ni; W. Van Den Hoek; S. Datta; A. Raychowdhury",Stanford University; Rochester Institute of Technology; Leading Edge Research; University of Notre Dame; Georgia Institute of Technology,"IEEE Micro","20 Oct 2020","2020","40","6","33","48","The future data-centric world demands edge intelligence (EI) - the ability to analyze data locally and to decide on a course of action autonomously. Challenges with Moore's Law scaling and limitations of von Neumann computing architectures are limiting the performance and energy efficiency of conventional electronics. Promising new discoveries of advanced CMOS-compatible HfO2-based ferroelectric devices open the door for FerroElectronics; electronics based on ferroelectric building blocks integrated on advanced CMOS technology nodes. It will enable much needed improvement in computing capabilities making EI a reality. In-memory computing in data-flow architectures is at the core of FerroElectronics. This approach will enable building 1000X more compute-energy-efficient small-system AI engines needed for EI. Smart edge intelligent IoT devices enable new applications, for example, micro Drones(uDrones), that demand higher performance to support local embedded intelligence, real-time learning, and autonomy. They will drive the next phase of growth in the semiconductor industry.","1937-4143","","10.1109/MM.2020.3026667","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9207822","","Artificial intelligence;Energy efficiency;Engines;Memory management;Performance evaluation;Neural networks","","45","","14","IEEE","28 Sep 2020","","","IEEE","IEEE Magazines"
"Enhancing Agricultural Support for Small Scale Farmers in Kenya: An IoT-based Mini Weather Station as a Machine Learning Data Collector","S. Itotia; B. Muriithi; S. Gitahi; P. Korir; M. Murigi; R. Kimutai; J. Olukuru; J. Sevilla","@iLabAfrica, Strathmore University, Nairobi, Kenya; @iLabAfrica, Strathmore University, Nairobi, Kenya; @iLabAfrica, Strathmore University, Nairobi, Kenya; @iLabAfrica, Strathmore University, Nairobi, Kenya; @iLabAfrica, Strathmore University, Nairobi, Kenya; @iLabAfrica, Strathmore University, Nairobi, Kenya; @iLabAfrica, Strathmore University, Nairobi, Kenya; @iLabAfrica, Strathmore University, Nairobi, Kenya","2023 IEEE Global Conference on Artificial Intelligence and Internet of Things (GCAIoT)","15 Jan 2024","2023","","","66","71","This paper presents a mini weather station device as a data collector for a machine learning model, aiming to support the Kenyan agricultural sector through small-scale farmers. Most farmers in Kenya practice small-scale farming and often face challenges in accessing timely and accurate weather information, which deters them from making informed decisions on what kind of crops to grow and the type of resources to allocate to their farms. We propose designing and deploying an affordable IoT mini weather station that collects real-time weather data to address this issue. The device has sensors that collect meteorological parameters such as humidity, temperature, light intensity, and atmospheric pressure. The collected data is transmitted to a cloud server and can be used as input for AI-powered machine learning models for forecasting and advisory systems to personalize recommendations to farmers, such as optimal planting time, irrigation schedules, and pest management strategies based on the prevailing weather.","","979-8-3503-8202-0","10.1109/GCAIoT61060.2023.10385094","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10385094","IoT;AI;weather and climate information;Smart Agriculture","Temperature sensors;Atmospheric modeling;Crops;Machine learning;Solids;Data models;Sensors","","","","14","IEEE","15 Jan 2024","","","IEEE","IEEE Conferences"
"Self Regulated Solar Powered IoT Based Egg Incubator","J. Siby; A. Tomy; A. Shaji; R. Chacko; V. Sankar","Electrical and Electronics Engineering, Amal Jyothi College of Engineering, Kottayam, Kerala, India; Electrical and Electronics Engineering, Amal Jyothi College of Engineering, Kottayam, Kerala, India; Electrical and Electronics Engineering, Amal Jyothi College of Engineering, Kottayam, Kerala, India; Electrical and Electronics Engineering, Amal Jyothi College of Engineering, Kottayam, Kerala, India; Electrical and Electronics Engineering, Amal Jyothi College of Engineering, Kottayam, Kerala, India","2022 IEEE 19th India Council International Conference (INDICON)","16 Feb 2023","2022","","","1","6","Incubators can provide a safe, controlled environment for eggs to hatch. Before the invention of incubators, people relied on various methods like heating an egg with a candle or using lukewarm water for hatching eggs. A key characteristic of an incubator is that the temperature inside the incubator is regulated so as to maintain a constant embryo development. The main challenges faced by the poultry industry are low productivity, high costs, and low egg quality due to a lack of sufficient conditions for egg hatching. Newer incubators are electric and generally more expensive due to high initial and operating costs, it is not affordable for small-scale poultry farmers. In this project, a new IoT-based solar-powered egg incubator with an automatic egg turning mechanism, effective ventilation, closed-loop temperature, and humidity control is introduced. The system is also equipped with real-time monitoring which allows close monitoring of the incubator. The data collected by the sensors inside the egg incubator is stored in a database and is displayed in a web app for easy monitoring and analysis. Even though the initial cost for this incubator is high, in long run it is more profitable than electric egg incubators. Since the main power source for this incubator is solar energy, the cost for electricity can be minimized.","2325-9418","978-1-6654-7350-7","10.1109/INDICON56171.2022.10039910","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10039910","Egg incubator;Internet of Things;Microcontroller;Database;Webapp","Temperature sensors;Temperature distribution;Costs;Water heating;Humidity;Solar energy;Turning","","","","20","IEEE","16 Feb 2023","","","IEEE","IEEE Conferences"
"Secrecy in an IoT System with Correlated and Non-identical Eavesdroppers","X. Liu","Department of Systems Engineering, University of Arkansas at Little Rock, Little Rock, USA","2021 IEEE Latin-American Conference on Communications (LATINCOM)","23 Dec 2021","2021","","","1","6","In this paper, we investigate the secrecy of a generic IoT system in the small-scale fading environment. The present work extends several existing works. In particular, we consider the correlated and non-identical eavesdroppers, and derive the closed-form formula of the probability of strictly positive secrecy capacity. Numerical examples are presented and analyzed.","2330-989X","978-1-6654-4035-6","10.1109/LATINCOM53176.2021.9647835","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9647835","Correlation;information-theoretic secrecy;Internet of Things;Rayleigh fading;secrecy capacity","Correlation;Conferences;Computational modeling;Rayleigh channels;Complexity theory;Shadow mapping;Capacity planning","","","","17","IEEE","23 Dec 2021","","","IEEE","IEEE Conferences"
"ARGUS – An Adaptive Smart Home Security Solution","R. M. Ruwin R. Ratnayake; G. D. N. D. K. Abeysiriwardhena; G. A. J. Perera; A. Senarathne; R. Ponnamperuma; B. A. Ganegoda","Department of Computer Systems Engineering, Sri Lanka Institute of Information Technology, Malabe, Sri Lanka; Department of Computer Systems Engineering, Sri Lanka Institute of Information Technology, Malabe, Sri Lanka; Department of Computer Systems Engineering, Sri Lanka Institute of Information Technology, Malabe, Sri Lanka; Department of Computer Systems Engineering, Sri Lanka Institute of Information Technology, Malabe, Sri Lanka; Department of Computer Systems Engineering, Sri Lanka Institute of Information Technology, Malabe, Sri Lanka; Department of Computer Systems Engineering, Sri Lanka Institute of Information Technology, Malabe, Sri Lanka","2022 4th International Conference on Advancements in Computing (ICAC)","31 Jan 2023","2022","","","459","464","Smart Security Solutions are in high demand with the ever-increasing vulnerabilities within the IT domain. Adjusting to a Work-From-Home (WFH) culture has become mandatory by maintaining required core security principles. Therefore, implementing and maintaining a secure Smart Home System has become even more challenging. ARGUS provides an overall network security coverage for both incoming and outgoing traffic, a firewall and an adaptive bandwidth management system and a sophisticated CCTV surveillance capability. ARGUS is such a system that is implemented into an existing router incorporating cloud and Machine Learning (ML) technology to ensure seamless connectivity across multiple devices, including IoT devices at a low migration cost for the customer. The aggregation of the above features makes ARGUS an ideal solution for existing Smart Home System service providers and users where hardware and infrastructure is also allocated. ARGUS was tested on a small-scale smart home environment with a Raspberry Pi 4 Model B controller. Its intrusion detection system identified an intrusion with 96% accuracy while the physical surveillance system predicts the user with 81% accuracy.","","979-8-3503-9809-0","10.1109/ICAC57685.2022.10025331","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10025331","Smart Home System;Intrusion Detection;Activity Monitoring;Surveillance;Firewall;Bandwidth Management;IoT;Cyber Security","Cloud computing;Surveillance;Systems architecture;Smart homes;Machine learning;Bandwidth;Traffic control","","1","","17","IEEE","31 Jan 2023","","","IEEE","IEEE Conferences"
"Blue Danube: A Large-Scale, End-to-End Synchronous, Distributed Data Stream Processing Architecture for Time-Sensitive Applications","P. A. Michael; P. D. Tsanakas; D. S. Parker","University of California Los Angeles, National Technical University of Athens, Athens, Greece; Electrical Engineering/Computer Engineering Department, National Technical University of Athens, Athens, Greece; Computer Science Department, University of California Los Angeles, Los Angeles, California","2022 IEEE/ACM 26th International Symposium on Distributed Simulation and Real Time Applications (DS-RT)","1 Nov 2022","2022","","","39","48","An extensive list of time-sensitive applications requiring ultra-low latency ranging from a few microseconds to a few milliseconds are presented in recent publications and IEEE standards. Time-sensitive applications, include industrial, critical healthcare and transportation applications as also applications for Smart Grids and the Internet of Vehicles – one of the most active research fields of Intelligent Transportation Systems of Smart Cities. In this work, we mainly set our focus on the suite of safety applications which attracts strong interest from the research community, as it aims to avoid road accidents and save lives. The IEEE Time-Sensitive Networking (TSN) set of standards specifies fundamental real-time characteristics. Nevertheless, as TSN works on Data Link layer (Layer 2 of the OSI model) the benefits of these characteristics fade away when other layers are crossed from the Application layer (Layer 7). Indicatively, recent research works report latencies on the order of tens of seconds when benchmarking Data Stream Processing and IoT platforms, and thus they are not suited for time-critical applications. Such platforms mainly use loosely coupled components with asynchronous communication. On Application layer, we propose a novel End-to-End Synchronous, Distributed Architecture for Large-Scale, High-Bandwidth, Ultra-Low Latency Data Stream Processing. Through our Big Data Stream analysis experiments (4.7 Gbit/s total average aggregated throughput, 1 Terabyte in-memory distributed database, 4 milliseconds average query latency) we have demonstrated the suitability of our architecture for time-sensitive applications such as accident avoidance for the Internet of Vehicles.","1550-6525","978-1-6654-9799-2","10.1109/DS-RT55542.2022.9932034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9932034","synchronous;data stream processing;end-to-end synchronous;time-sensitive applications;time-critical applications;ultra-low latency;Internet-of-Things;Intelligent Transportation Systems;Internet of Vehicles;Smart Cities","Distributed databases;Transportation;Open systems;Big Data;Throughput;Real-time systems;Data models","","","","49","IEEE","1 Nov 2022","","","IEEE","IEEE Conferences"
"A Decentralized Data Sharing Model using Blockchain with Fine Grained Access Control","A. Singh; G. Rathee","CSE department, Netaji Subhas University of Technology, New Delhi, India; CSE department, Netaji Subhas University of Technology, New Delhi, India","2023 International Conference on Computational Intelligence and Sustainable Engineering Solutions (CISES)","21 Jul 2023","2023","","","13","18","In recent years, the use of cloud services for data sharing poses a severe threat to the security and privacy of the data being shared over a public communication channel. The owners not only lose complete ownership of the data being uploaded to the cloud but the security and privacy of the data are also at stake. The interplanetary file system, IPFS has introduced a decentralized way to store data on a large scale, thereby overcoming the issue of a single point of failure and unavailability of data at all times. For added security, the use of attribute-based encryption before uploading the data on the IPFS provides an extra layer of security and confidentiality. ABE enables data owners to encrypt their data under a list of attributes with only the user possessing those attributes can decrypt the said file. The use of ABE provides fine-grained access control on the data being shared and provides the facility for easy updations of access rights. In this paper, we analyzed various data-sharing schemes based on Ethereum and IPFS and presented a scheme incorporating ciphertext policy, attribute-based encryption, CP-ABE along with Ethereum and smart contracts for enabling data storage and data sharing in the Internet of Medical Things, IoMT. The use of partial decryption also reduces the load on the resource-constrained IoT devices of a user. To further make the framework efficient and always available, the ability to access the file using a keyword search is also added to the framework. Experimental results prove that the proposed scheme uses less storage overhead as compared to some of the existing schemes thus reducing the computation time and cost too.","","979-8-3503-2391-7","10.1109/CISES58720.2023.10183531","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10183531","decentralized;data sharing;blockchain;IPFS;ABE;Internet of Things","Access control;Data privacy;Cloud computing;Smart contracts;Keyword search;Redundancy;Computer architecture","","","","25","IEEE","21 Jul 2023","","","IEEE","IEEE Conferences"
"MAESTRO: Orchestrating Computational Offloading to Multiple FemtoClouds in Various Communication Environments","H. Gedawy; A. Elgazar; K. A. Harras","Computer Science Department, Carnegie Mellon University Qatar, Doha, Qatar; Computer Science Department, Carnegie Mellon University Qatar, Doha, Qatar; Computer Science Department, Carnegie Mellon University Qatar, Doha, Qatar","IEEE Access","15 Mar 2022","2022","10","","27096","27112","Many novel IoT-based applications demand low latency, large compute resources, and high privacy. These requirements have motivated the emergence of fog and edge computing to complement the low-privacy and high-latency cloud. The intention behind Fog computing is to place computational servers closer to the user, typically within the city’s vicinity, to reduce latency. However, because of the high deployment cost of these servers at scale, and unreliable network infrastructures in many countries or areas, edge computing was proposed. Edge computing advocates leveraging compute resources, typically 0-hops away, on distributed ensembles of colocated devices called FemtoClouds. In this paper, we propose MAESTRO, a system that enables users to offload computational jobs to multiple FemtoClouds in their immediate vicinity. For MAESTRO, we build an integrated architecture that includes two new scheduling algorithms for assigning computing workloads to FemtoClouds. Each of our scheduling algorithms is designed to allow the system to operate more efficiently given poor or strong network infrastructures. We implement a full prototype of our system to assess its performance on our experimental testbed. The results indicate that in communication-challenged environments, our specialized scheduler outperforms state-of-the-art schedulers by up to 55%, while in communication-friendly environments our other specialized scheduler outperforms state-of-the-art schedulers by up to 67%.","2169-3536","","10.1109/ACCESS.2022.3152075","Qatar National Research Fund (a member of Qatar Foundation)(grant numbers:PDRA 6-0624-20020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9714351","Edge computing;FemtoClouds;Internet of Things;IoT cloud;mobile computing","Task analysis;Scheduling;Edge computing;Cloud computing;Scheduling algorithms;Servers;Prototypes","","1","","42","CCBY","15 Feb 2022","","","IEEE","IEEE Journals"
"A Load Balancing and Routing Strategy in Fog Computing using Deep Reinforcement Learning","N. E. Belkout; K. Zeraoulia; M. N. Shahzad; L. Liu; B. Yuan","Department of Computer Science, University of Science and Technology Houari Boumediene, Algiers, Algeria; Department of Computer Science, University of Science and Technology Houari Boumediene, Algiers, Algeria; Department of Informatics, University of Leicester, Leicester, United Kingdom; Department of Informatics, University of Leicester, Leicester, United Kingdom; Department of Informatics, University of Leicester, Leicester, United Kingdom","2022 International Conference on Electrical, Computer and Energy Technologies (ICECET)","9 Sep 2022","2022","","","1","8","Fog computing is proposed to overcome cloud computing limitations by extending its services close to the network edge. However, fog systems are still facing many challenges due to their large-scale distributed architecture and small resource power. We investigate in this paper resource management in fog computing and propose a load balancing strategy using Deep Reinforcement Learning (DRL) combined with a link-state routing protocol based on the Dijkstra algorithm. The objective of the strategy is to simultaneously minimize the tasks’ processing and communication delay. The proposed solution involves designing a Load Balancer Smart Controller (LBSC) which engages a smart DRL agent in a fog environment. The LBSC examines the nodes and links’ states in order to make the optimal decision by selecting the most suitable node and path to process each task. The performance of the proposed approach is tested in a dynamic IoT environment with a high-rate workload generation scenario. Simulation results show that the average total latency including processing and communication delays of the proposed method is reduced by around 50% in comparison to the classic load balancing algorithms.","","978-1-6654-7087-2","10.1109/ICECET55527.2022.9872763","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9872763","Fog computing;Resources management;Load balancing;Routing;Deep Reinforcement Learning;Dijkstra","Energy consumption;System performance;Simulation;Reinforcement learning;Load management;Routing;Routing protocols","","2","","22","IEEE","9 Sep 2022","","","IEEE","IEEE Conferences"
"FPGA-based implementation of 2D Normalized Cross-Correlation for Large Scale Signals","M. Salaris; A. Damiani; E. Putti; L. Stornaiuolo","Dipartimento di Elettronica Informazione e Bioingegneria (DEIB), Politecnico di Milano, Milan, Italy; Dipartimento di Elettronica Informazione e Bioingegneria (DEIB), Politecnico di Milano, Milan, Italy; Dipartimento di Elettronica Informazione e Bioingegneria (DEIB), Politecnico di Milano, Milan, Italy; Dipartimento di Elettronica Informazione e Bioingegneria (DEIB), Politecnico di Milano, Milan, Italy","2021 IEEE 6th International Forum on Research and Technology for Society and Industry (RTSI)","15 Nov 2021","2021","","","300","305","About every three years, the high-end image resolution quadruples: what we called high-resolution in 2018 is turning standard now. Even simpler embedded devices can shoot videos at 4K resolution. The combination of this rush to wider frames with the blooming era of Computer Vision (CV) constantly pushes the performance requirements of the underlying processing. Template matching is one of the CV's foundations as it enables the localization of objects inside images. It exploits similarity functions such as the 2D Cross-Correlation and its variants Normalized Cross-Correlation (NCC) and Zero-mean NCC (ZNCC). However, these computations do not scale gracefully with resolution. We propose two novel FPGA-based implementations with low hardware resource consumption for the 2D NCC and ZNCC for large-scale images. We succeeded in fitting our accelerator on the 3CG class of Xilinx Zynq UltraScale+ ARM-based MPSoCs, among the smallest embedded-grade classes that do not even include dedicated CV hardware, which adds a 14% cost overhead, thus enabling accelerated template matching for local preprocessing in IoT applications. We achieve this while attaining a $\boldsymbol{3.52}\times$ speedup over non-embedded systems and remaining $\mathbf{43.2}\times$ more power efficient for NCC. Finally, to fully exploit the heterogeneous nature of our target hardware, we provide a runtime hardware selection algorithm to automatically target the proper hardware/software implementation for best performance.","2687-6817","978-1-6654-4135-3","10.1109/RTSI50628.2021.9597359","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9597359","Normalized Cross-Correlation;Zero-mean Normalized Cross-Correlation;Zynq;SoC;PYNQ;SciPy;FPGA","Performance evaluation;Runtime;Image resolution;Heuristic algorithms;Reconfigurable logic;Turning;Hardware","","","","20","IEEE","15 Nov 2021","","","IEEE","IEEE Conferences"
"The design and implementation of an IOT-based real-time air purification system for outdoor environment","H. M. R. G. Herath; K. K. W. S. P. K. Jayasundara; Y. K. A. Yadhasighe; S. D. A. Sanjeewa","Department of Electrical & Electronics Technology, University of Vocational Technology, Ratmalana, Sri Lanka; Department of Electrical & Electronics Technology, University of Vocational Technology, Ratmalana, Sri Lanka; Department of Electrical & Electronics Technology, University of Vocational Technology, Ratmalana, Sri Lanka; Department of Electrical & Electronics Technology, University of Vocational Technology, Ratmalana, Sri Lanka","2022 2nd International Conference on Advanced Research in Computing (ICARC)","14 Apr 2022","2022","","","314","319","Even though air pollution is a fact, it is also a harsh reality that causes serious health issues for people around the world, such as premature death. It is imperative that immediate action is taken to improve air quality in some regions of the world. In order to address this issue on a large scale, this research project aims to provide real-time data monitoring and air purification for the city. A lack of precision, low sensitivity, and the need for laboratory analysis mean that current monitoring systems are ineffective. Thus, new and improved monitoring systems are required. This system uses filtering technology and a real-time dashboard to solve the shortcomings of current solutions. An IoT system is an interconnected network of smart devices that can sense and communicate with each other and other systems. Arduino Integrated Development Environment(Arduino IDE), a Wi-Fi module from Arduino, and sensors for gas, dust, pressure, and temperature were used to build the data-gathering hardware. Instruments that measure air pollution and fresh air might be installed in the purification system. The Arduino IDE receives data from the gas sensors, which collect data from the surrounding environment. The Wi-Fi module of the Arduino IDE delivers the data to the cloud. Users can get important air quality data from the cloud via the web page ""Wayu.live,"" built by our team. Air quality indicator levels can also be used by the government for negotiations and forecasting.","","978-1-6654-0741-0","10.1109/ICARC54489.2022.9754097","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9754097","Real time monitoring;Air Purify;HEPA;Smart City;Wireless Sensor Network","Temperature sensors;Temperature measurement;Cloud computing;Purification;Web pages;Air pollution;Real-time systems","","","","7","IEEE","14 Apr 2022","","","IEEE","IEEE Conferences"
"Intrusion Detection System Using Machine Learning for Vehicular Ad Hoc Networks Based on ToN-IoT Dataset","A. R. Gad; A. A. Nashat; T. M. Barkat","Department of Communication and Electronics Engineering, October High Institute for Engineering and Technology, 6th of October City, Egypt; Department of Electrical Engineering, Faculty of Engineering, Fayoum University, Faiyum, Egypt; Department of Electrical Engineering, Faculty of Engineering, Fayoum University, Faiyum, Egypt","IEEE Access","25 Oct 2021","2021","9","","142206","142217","Vehicular ad hoc networks (VANETs) are a subsystem of the proposed intelligent transportation system (ITS) that enables vehicles to communicate over the wireless communication infrastructure. VANETs are used in multiple applications, such as improving traffic safety and collision prevention. The use of VANETs makes the network vulnerable to various types of attacks, such as denial of service (DoS) and distributed denial of service (DDoS). Many researchers are now interested in adding a high level of security to VANETs. Machine learning (ML) methods were used for constructing a high level of security capabilities based on intrusion detection systems (IDSs). Furthermore, the vast majority of existing research is based on NSL-KDD or KDD-CUP99 datasets. Recent attacks are not present in these datasets. As a result, we employed a realistic dataset called ToN-IoT that derived from a large-scale, heterogeneous IoT network. This work tested various ML methods in both binary and multi-class classification problems. We used the Chi-square (Chi2) technique was used for feature selection and the Synthetic minority oversampling technique (SMOTE) for class balancing. According to the results, the XGBoost method outperformed other ML methods.","2169-3536","","10.1109/ACCESS.2021.3120626","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9576115","Intrusion detection system (IDS);Internet of Things (IoT);ToN-IoT dataset;machine learning (ML);vehicular ad hoc networks (VANETs)","Support vector machines;Vehicular ad hoc networks;Radio frequency;Computer crime;Security;Industrial Internet of Things;Password","","96","","44","CCBYNCND","15 Oct 2021","","","IEEE","IEEE Journals"
"QoS and Resource-Aware Security Orchestration and Life Cycle Management","M. Bagaa; T. Taleb; J. B. Bernabe; A. Skarmeta","Aalto University, Espoo, Finland; Aalto University, Espoo, Finland; Department of Communications and Information Engineering, University of Murcia, Murcia, Spain; Department of Communications and Information Engineering, University of Murcia, Murcia, Spain","IEEE Transactions on Mobile Computing","1 Jul 2022","2022","21","8","2978","2993","Zero-touch network and service management (ZSM) exploits network function virtualization (NFV) and software-defined networking (SDN) to efficiently and dynamically orchestrate different service function chaining (SFC), whereby reducing capital expenditure and operation expenses. The SFC is an optimization problem that shall consider different constraints, such as Quality of Service (QoS), and actual resources, to achieve cost-efficient scheduling and allocation of the service functions. However, the large-scale, complexity and security issues brought by virtualized IoT networks, which embrace different network segments, e.g., Fog, Edge, Core, Cloud, that can also exploit proximity (computation offloading of virtualized IoT functions to the Edge), imposes new challenges for ZSM orchestrators intended to optimize the SFC, thereby achieving seamless user-experience, minimal end-to-end delay at a minimal cost. To cope with these challenges, this paper proposes a cost-efficient optimized orchestration system that addresses the whole life-cycle management of different SFCs, that considers QoS (including end-to-end delay, bandwidth, jitters), actual capacities of Virtual Network Functions (VNFs), potentially deployed across multiple Clouds-Edges, in terms of resources (CPU, RAM, storage) and current network security levels to ensure trusted deployments. The proposed orchestration system has been implemented and evaluated in the scope of H2020 Anastacia EU project,1 showing its feasibility and performance to efficiently manage SFC, optimizing deployment costs, reducing overall end-to-end delay and optimizing VNF instances distribution.","1558-0660","","10.1109/TMC.2020.3046968","European research project H2020 ANASTACIA GA(grant numbers:731558,MonB5G GA 871780,INSPIRE-5Gplus GA 871808); AXA Postdoctoral Scholarship; AXA Research Fund; Academy of Finland(grant numbers:318927); Academy of Finland CSN project(grant numbers:311654); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9305277","","Security;Optimization;Delays;Quality of service;Cloud computing;Resource management;Hardware","","11","","23","IEEE","23 Dec 2020","","","IEEE","IEEE Journals"
"Fine-grained Frequencies for Simultaneous Intra-Group One-to-All Dissemination","J. Debadarshini; C. Shekhar; S. Saha",IIT Bhubaneswar; IIT Bhubaneswar; IIT Bhubaneswar,"2020 IEEE 17th International Conference on Mobile Ad Hoc and Sensor Systems (MASS)","23 Feb 2021","2020","","","473","481","Simultaneous intra-group communication is one of the possible ways to handle the scaling issues in large decentralized systems. FDMA is an elegant strategy to carry out intra-group activities in parallel. However, due to increasing congestion in the licence free ISM bands, especially in the urban area, its hard to get enough number of good standard channels for multi-group setting in decentralized systems like IoT/WSN. In this work, we leverage concurrent transmission for efficient simultaneous intra-group one-to-all dissemination. Concurrent transmissions based strategies schedule the packet-transmissions in a special way so that the overlapping packets, instead of colliding with each other, result in constructive-interference or capture-effect. We propose a simple strategy to exploit this feature under concurrent transmission to achieve fruitful simultaneous intra-group communication in overlapping channels. Through extensive evaluation in testbeds for WSN/IoT under 2.4 GHz ISM band we show that, the proposed strategy can efficiently support simultaneous intra-group one-to-all dissemination even with allocation of channels having Center Frequency Distance (CFD) 1 MHz in most of the common group divisions. Experiments with a wide variety of group divisions also reveal that under concurrent transmission a CFD of 3 MHz and above can tolerate strong inter-group interference when the groups are quite mixed with each other which can be quite common specially when the nodes are mobile.","2155-6814","978-1-7281-9866-8","10.1109/MASS50613.2020.00064","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9356064","WSN;IoT;Concurrent transmission;Capture-effect;Continuous frequency allocation;overlapping channels","Wireless sensor networks;Time-frequency analysis;Schedules;Urban areas;Sensor systems;Standards;Radio spectrum management","","10","","28","IEEE","23 Feb 2021","","","IEEE","IEEE Conferences"
"A Stack4Things-based Web of Things Architecture","Z. Benomar; F. Longo; G. Merlino; A. Puliafito","Dipartimento di Ingegneria, Università di Messina, Italy; Dipartimento di Ingegneria, Università di Messina, Italy; Dipartimento di Ingegneria, Università di Messina, Italy; CINI: National Interuniversity Consortium for Informatics, Rome, Italy","2020 International Conferences on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData) and IEEE Congress on Cybermatics (Cybermatics)","28 Dec 2020","2020","","","113","120","With the great impact of the advancement in the hardware field, major efforts have been made to create large-scale networks of IoT devices (e.g., embedded systems, sensors, and actuators) that can interact with each other as well as their surrounding environments. However, most of the deployments are based on proprietary and tightly-coupled systems. To overwhelm the application layer interoperability issues, the Web of Things (WoT) paradigm aims at making smart things an integral part of the Web and thus, enabling them to communicate through Web standards/protocols. Therefore, applications/services making use of smart things become easier to conceive by means of Web standards/protocols (e.g., HTTP, Websockets). This paper proposes an approach enabling the smart devices to join the Web using features provided by the Stack4Things (S4T) OpenStack-based middleware. Thereby, user agents, typically, Web browsers and/or smart devices can make use of the resources of (other) IoT devices using globally resolvable Uniform Resource Locators (URLs) regardless of their underlying used protocol stacks.","","978-1-7281-7647-5","10.1109/iThings-GreenCom-CPSCom-SmartData-Cybermatics50389.2020.00036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9291689","Cloud computing;Internet of Things;Web of Things;OpenStack;REST","Internet of Things;Protocols;Cloud computing;Internet;Standards;Web servers;Hardware","","9","","14","IEEE","28 Dec 2020","","","IEEE","IEEE Conferences"
"Improving Security in Edge Computing by using Cognitive Trust Management Model","D. Ganesh; K. Suresh; M. S. Kumar; K. Balaji; S. Burada","Sree Vidyanikethan Engineering College(Autonomous), Tirupati, Andhra Pradesh, India; Sree Vidyanikethan Engineering College(Autonomous), Tirupati, Andhra Pradesh, India; Sree Vidyanikethan Engineering College(Autonomous), Tirupati, Andhra Pradesh, India; B V Raju Institute of Technology, Narsapur, Telangana State, India; Department of Computer Science and Engineering, Koneru Lakshmaiah Educational Foundation, Vaddeswaram, Guntur, Andhra Pradesh, India","2022 International Conference on Edge Computing and Applications (ICECAA)","8 Nov 2022","2022","","","524","531","As a result of this new computer design, edge computing can process data rapidly and effectively near to the source, avoiding network resource and latency constraints. By shifting computing power to the network edge, edge computing decreases the load on cloud services centers while also reducing the time required for users to input data. Edge computing advantages for data-intensive services, in particular, could be obscured if access latency becomes a bottleneck. Edge computing raises a number of challenges, such as security concerns, data incompleteness, and a hefty up-front and ongoing expense. There is now a shift in the worldwide mobile communications sector toward 5G technology. This unprecedented attention to edge computing has come about because 5G is one of the primary entry technologies for large-scale deployment. Edge computing privacy has been a major concern since the technology’s inception, limiting its adoption and advancement. As the capabilities of edge computing have evolved, so have the security issues that have arisen as a result of these developments, as well as the increasing public demand for privacy protection. The lack of trust amongst IoT devices is exacerbated by the inherent security concerns and assaults that plague IoT edge devices. A cognitive trust management system is proposed to reduce this malicious activity by maintaining the confidence of an appliance & managing the service level belief & Quality of Service (QoS). Improved packet delivery ratio and jitter in cognitive trust management systems based on QoS parameters show promise for spotting potentially harmful edge nodes in computing networks at the edge.","","978-1-6654-8232-5","10.1109/ICECAA55415.2022.9936568","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9936568","Edge Computing;Internet of Things (IoT);security;Resource Management","Privacy;Cloud computing;Image edge detection;Computational modeling;Quality of service;Delays;Security","","3","","31","IEEE","8 Nov 2022","","","IEEE","IEEE Conferences"
"A Blockchain Dynamic Sharding Scheme Based on Hidden Markov Model in Collaborative IoT","J. Xi; G. Xu; S. Zou; Y. Lu; G. Li; J. Xu; R. Wang","National Engineering Laboratory of Mobile Network Security, the School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China; National Engineering Laboratory of Mobile Network Security, the School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China; National Engineering Laboratory of Mobile Network Security, the School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China; School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China; Institutes of Science and Development, Chinese Academy of Sciences, Beijing, China; College of Computer Science and Technology, China University of Petroleum (Eastern China), Qingdao, China; Beijing University of Posts and Telecommunications, Beijing, China","IEEE Internet of Things Journal","7 Aug 2023","2023","10","16","14896","14907","Sharded blockchain offers scalability, decentralization, immutability, and linear improvement, making it a promising solution for addressing the trust problem in large-scale collaborative IoT. However, a high proportion of cross-shard transactions (CSTs) can severely limit the performance of decentralized blockchain. Furthermore, the dynamic assemblage characteristic of collaborative sensing in sharded blockchain is often ignored. To overcome these limitations, we propose HMMDShard, a dynamic blockchain sharding scheme based on the hidden Markov model (HMM). HMMDShard leverages fine-grained blockchain sharding and fully embraces the dynamic assemblage characteristic of IoT collaborative sensing. By integrating the HMM, we achieve adaptive dynamic incremental updating of blockchain shards, effectively reducing CSTs across all shards. We conduct a comprehensive analysis of the security issues and properties of HMMDShard, and evaluate its performance through the implementation of a system prototype. The results demonstrate that HMMDShard significantly reduces the proportion of CSTs and outperforms other baselines in terms of system throughput and transaction confirmation latency.","2327-4662","","10.1109/JIOT.2023.3294234","National Key Research and Development Program of China(grant numbers:2021YFB3101500); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10177929","Blockchain sharding;dynamic incremental updating;hidden Markov model (HMM);IoT collaborative sensing","Blockchains;Sharding;Hidden Markov models;Internet of Things;Collaboration;Sensors;Throughput","","2","","31","CCBYNCND","11 Jul 2023","","","IEEE","IEEE Journals"
"Tiny Machine Learning: Progress and Futures [Feature]","J. Lin; L. Zhu; W. -M. Chen; W. -C. Wang; S. Han","Massachusetts Institute of Technology, Cambridge, MA, USA; Massachusetts Institute of Technology, Cambridge, MA, USA; Massachusetts Institute of Technology, Cambridge, MA, USA; Massachusetts Institute of Technology, Cambridge, MA, USA; Massachusetts Institute of Technology, Cambridge, MA, USA","IEEE Circuits and Systems Magazine","13 Oct 2023","2023","23","3","8","34","Tiny machine learning (TinyML) is a new frontier of machine learning. By squeezing deep learning models into billions of IoT devices and microcontrollers (MCUs), we expand the scope of applications and enable ubiquitous intelligence. However, TinyML is challenging due to the hardware constraints: the tiny memory resource is difficult hold deep learning models designed for cloud and mobile platforms. There is also limited compiler and inference engine support for bare-metal devices. Therefore, we need to co-design the algorithm and system stack to enable TinyML. In this review, we will first discuss the definition, challenges, and applications of TinyML. We then survey the recent progress in TinyML and deep learning on MCUs. Next, we will introduce MCUNet, showing how we can achieve ImageNet-scale AI applications on IoT devices with system-algorithm co-design. We will further extend the solution from inference to training and introduce tiny on-device training techniques. Finally, we present future directions in this area. Today’s “large” model might be tomorrow’s “tiny” model. The scope of TinyML should evolve and adapt over time.","1558-0830","","10.1109/MCAS.2023.3302182","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10284551","TinyML;efficient deep learning;on-device training;learning on the edge","Deep learning;Training;Adaptation models;Microcontrollers;Memory management;Inference algorithms;Tiny machine learning;Microcontrollers;Machine learning","","1","","154","IEEE","13 Oct 2023","","","IEEE","IEEE Magazines"
"MTdt:Enabling Meta-Transactions for Data Tracking of Industrial Workflow","J. Yu; M. Tang; S. Li","Shenyang Institute of Computing Technology, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Shenyang, China; Shenyang Institute of Computing Technology, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Shenyang, China; School of Institute of Equipment Engineering, Shenyang Ligong University, Shenyang, China","2021 7th International Conference on Computer and Communications (ICCC)","17 Jan 2022","2021","","","1532","1538","The decentralization and traceability of blockchain technology can realize the supervision of industrial Internet industry processes. As a jointly maintained distributed ledger, blockchain can provide an open, transparent and tamper proof information publicity platform. However, due to the huge amount of data and complex data interface of IOT equipment, blockchain cannot become a platform for direct access of IOT system. Nowadays, more and more decentralized applications are born. Building such services using emerging blockchain technology is a promising direction. We attempt to use the latest blockchain proxy strategy to solve data management problems in the system. We propose a blockchain sub-proxy model that traces workflows. Host data links to proxies, blockchain only store necessary information to ensure that subsequent transactions can be traced back to previous operations. Multiple tasks are represented by distributed agents to form a complete industry chain. In this model, industrial processes can be recorded asynchronously and on a large scale. Unlike centralized management processes, agents and blocks work together to ensure data storage efficiency and security.","","978-1-6654-0950-6","10.1109/ICCC54389.2021.9674458","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9674458","blockchain;meta-transaction;decentralization;agent","Industries;Distributed ledger;Memory;Decentralized applications;Data models;Blockchains;Internet","","","","16","IEEE","17 Jan 2022","","","IEEE","IEEE Conferences"
"A Reliable Data Compression Scheme in Sensor-Cloud Systems Based on Edge Computing","S. Lu; Q. Xia; X. Tang; X. Zhang; Y. Lu; J. She","College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; Quantum Corporation, Mendota Heights, MN, USA; College of Computer Science and Electronic Engineering, Hunan University, Changsha, China","IEEE Access","1 Apr 2021","2021","9","","49007","49015","The rapid development of the IoT and cloud computing has spawned a new network structure — sensor-cloud system (SCS) where sensors, sensor networks, and cloud computing are integrated to perform data sensing, collection, transmission, and decision making. The large-scale deployment of sensors creates a massive amount of data, posing new challenges in data transmission and storage. As an intermediate platform between IoT and cloud platforms, edge computing provides IoT with data collection, processing, and scheduling services. This paper proposes a hybrid data compression scheme that incorporates lossy and lossless compression in SCS based on edge computing to address the increasing challenges. Moreover, we propose a new reliable lossy compression algorithm DFan, based on the simplified Fan algorithm with a high compression ratio (CR). By introducing the data tolerable deviation, DFan transforms single-factor decision-making into multi-factor decision-making, reducing the error of lossy compression. Through experiments on IntelLab and MIT-BIH datasets, the proposed hybrid data compression scheme achieves an overall CR of  $4.21\times $  and  $3.88\times $ , respectively. The lossy CR of DFan is  $6.42\times $  and  $5.1\times $ , respectively, and the Percentage RMS Difference (PRD) caused by lossy compression is 0.27% and 0.56%, respectively. The hybrid compression scheme, high compression ratio, and reliable data restoration make this scheme attractive to the data processing of sensors in SCS.","2169-3536","","10.1109/ACCESS.2021.3068753","Industrial Internet Innovation and Development Project of China(grant numbers:TC19084DY); Special Funds for Construction of Innovative Provinces in Hunan Province of China(grant numbers:2020SK2066,2020GK2016); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9386062","Sensor-cloud system (SCS);data compression;edge computing;Internet of Things (IoT)","Sensors;Data compression;Cloud computing;Compression algorithms;Reliability;Edge computing;Wireless sensor networks","","20","","29","CCBY","24 Mar 2021","","","IEEE","IEEE Journals"
"Collaborative Edge Network Research and Design Based on Ant Colony Algorithm for IoT","H. Fu; G. Xiong; Y. Liu; B. Hu; S. Liu; S. Chen","School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; The State Key Laboratory for Management and Control of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; The State Key Laboratory for Management and Control of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; The State Key Laboratory for Management and Control of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; The State Key Laboratory for Management and Control of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; The State Key Laboratory for Management and Control of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China","2021 IEEE 16th Conference on Industrial Electronics and Applications (ICIEA)","30 Aug 2021","2021","","","1334","1339","IoT connections emerge exponential growth trend, which poses a serious challenge to cloud computing due to the limit of network bandwidth. Edge computing provides a promising solution. However, the computing power of edge side isn't enough to complete large scale tasks. Hence, to solve computing power shortage, a collaborative edge network (CEN) model is proposed, including system model and network communication model. Further, to estimate the performance of CEN, we design and implement ant colony algorithm to schedule tasks for IoT scenarios. The simulation results show, as the mobile devices increase to 1500, the CEN reduces significantly average task complete time by 90% and task failure rate (TFR) by 10% compared with OnlyEdge. And the CEN reduces sharply TFR by 70% compared with OnlyCloud. As a consequence, the comprehensive performance of CEN is leading, which has more powerful access ability to serve enormous IoT devices.","2158-2297","978-1-6654-2248-2","10.1109/ICIEA51954.2021.9516050","National Key Research and Development Program of China(grant numbers:2018YFB1702701); National Natural Science Foundation of China(grant numbers:61773381,61773382,61872365); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9516050","IoT;cloud;edge computing;collaborative edge network;ant colony algorithm","Performance evaluation;Industrial electronics;Schedules;Computational modeling;Simulation;Collaboration;Market research","","1","","21","IEEE","30 Aug 2021","","","IEEE","IEEE Conferences"
"A Comprehensive Review: Shunt Active Power Filter For Nonlinear IoT Applications","A. Sharma; G. Goswami; P. K. Goswami; R. Mahajan","Department of Electrical and Electronics Engineering, R.B.S.E.T.C., Agra, India; Department of Electronics Engineering, Teerthanker Mahaveer University, Moradabad, India; Department of Electronics Engineering, Teerthanker Mahaveer University, Moradabad, India; Department of Electronics Engineering, HCST, Mathura, India","2021 10th International Conference on System Modeling & Advancement in Research Trends (SMART)","18 Jan 2022","2021","","","595","600","The increasing use of smart sensors in IoT applications enhances the scale of smart automation. The applications area of smart industries constitutes nonlinear load sensors at large level. The nonlinear characteristics of such components causes insertion of severe harmonic current and this result in performance deviation and system failure. It is clear that a wider area is IoT and improvement in power quality is challenge. This paper presents comprehensive review on power quality control and shunt active filters. Articles belong to the category of IoT, Active Power Filter and different types of improvement in power quality methods and were mainly published in a decade. The review of literature has been carried out by making category-based sections of papers issue wise or under sub-area. This comprehensive review will absolutely help to researchers for problem identification and research gap findings in most smart technologies.","2767-7362","978-1-6654-3970-1","10.1109/SMART52563.2021.9676207","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9676207","IoT;SAPF;PQ;Harmonics;Smart Devices","Power quality;Quality control;Sensor phenomena and characterization;Active filters;Minimization;Market research;Internet of Things","","","","30","IEEE","18 Jan 2022","","","IEEE","IEEE Conferences"
"Intelligent Lighting Control and Energy Management System","G. Bhartiya; P. Pathak","Dept of CEA, GLA University, Mathura, India; Dept of Mathematics, GLA University, Mathura, India","2020 International Conference on Power Electronics & IoT Applications in Renewable Energy and its Control (PARC)","7 May 2020","2020","","","86","89","Public lighting in streets, city centers, squares and other public places etc. can account about 30% of the urban energy consumption. We intend to design an efficient energy saving mechanism using microcontroller and sensors which turn on/off street lights automatically. The aim of this work is to reduce the ill effects of energy consumption of the current lighting system, and find a method to save power. We use distance sensors to switch on the light when the object is sensed in a nearby area otherwise it is kept off. Implementation reveals the prototype works with accuracy and if implemented on a large scale, it will prove to be very useful. Additionally, a person can switch on/off light using his Bluetooth on mobile phone. Also, an IOT enabled DHT-11 sensor kept over light pole will raise an alarm in case of fire or accidents.","","978-1-7281-6575-2","10.1109/PARC49193.2020.236563","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9087112","lighting control;sensor;street light control;energy management","","","6","","13","IEEE","7 May 2020","","","IEEE","IEEE Conferences"
"Cloud Password Shield: A Secure Cloud-based Firewall against DDoS on Authentication Servers","Y. Fu; M. H. Au; R. Du; H. Hu; D. Li","School of ECE, Shenzhen Graduate School, Peking University, China; Department of Computer Science, The University of Hong Kong, Hong Kong; School of ECE, Shenzhen Graduate School, Peking University, China; Department of Electronic and Information Engineering, The Hong Kong Polytechnic University, Hong Kong; International Institute of Next Generation Internet, Macau University of Science and Technology, Macau SAR","2020 IEEE 40th International Conference on Distributed Computing Systems (ICDCS)","23 Feb 2021","2020","","","1209","1210","Password-based authentication is essential to any online service. It is normally powered by a database of user credentials, for example a RADIUS server. However, even with various indexing techniques (e.g., B+-tree), password-based authentication can still be resource-consuming on large-scale systems (e.g., Internet and IoT), and is thus vulnerable to distributed denial-of-service (DDoS) attacks.In this paper, we propose a cloud-based firewall that uses Bloom filters to pre-screen and reject suspicious requests with wrong password before they reach the authentication server. The main challenge is the security of the firewall because it can be operated by a third party, so the Bloom filters might be accessed by adversaries to assist their brute-force password guessing.To ensure security, we start with the assumption of trusted cloud server and design a key-based semantic secure Bloom filter (KSSBF) for the best efficiency. We then design a generically secure Bloom filter (GSBF) for non-trusted cloud servers, which is key-independent and with strictly provable security. Through theoretical and empirical analysis, we show both of them can mitigate malicious requests without compromising the security of passwords.","2575-8411","978-1-7281-7002-2","10.1109/ICDCS47774.2020.00154","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9355714","Security;DDoS;Bloom filter;Firewall","Cloud computing;Firewalls (computing);Authentication;Denial-of-service attack;Servers;Security;Password","","4","","3","IEEE","23 Feb 2021","","","IEEE","IEEE Conferences"
"Internet of Things Software Defined Radio Technology for LoRaWAN Wireless Communication: A survey","A. Lavric; A. I. Petrariu; L. Anchidin","Electronics and Automation Department, Computers, Stefan cel Mare University of Suceava, Romania; Electronics and Automation Department, Computers, Stefan cel Mare University of Suceava, Romania; Electronics and Automation Department, Computers, Stefan cel Mare University of Suceava, Romania","2021 12th International Symposium on Advanced Topics in Electrical Engineering (ATEE)","12 May 2021","2021","","","1","4","The past few years we have witnessed an increase in the development of IoT concept. This concept entails the connection of objects that surround us in our everyday life to Internet. This paradigm where the human users are replaced by objects determines the appearance of different problems that are related to: scalability of the systems and sensors, power supply management techniques that must allow the sensor to operate for years and even decades and longer communication range suitable for urban non-LoS. LoRa modulation among the LoRaWAN communication protocol is regarded as a problem solver. In this paper, we present the development and the design of a LoRa traffic generator that has the ability of generating a high volume of traffic. This approach allows for the emulation of large scale LoRaWAN networks without the need of additional costs. Thus, the scalability and the reliability of LoRa networks can be researched and studied in detail. From the obtained results the LoRa traffic generator ensures a high level of performance and can be used for future improvements of LoRa communication.","2159-3604","978-1-6654-1878-2","10.1109/ATEE52255.2021.9425135","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9425135","Internet of Things;LoRaWAN;LoRa;sensors;wireless communication","Wireless communication;Wireless sensor networks;Protocols;Scalability;Tools;Generators;Sensor systems","","3","","15","IEEE","12 May 2021","","","IEEE","IEEE Conferences"
"Challenge of Anomaly Detection in IoT Analytics","H. -T. Pai; S. -H. Wang; T. -S. Chang; J. -X. Wu","National Yunlin University of Science and Technology, Douliou, Taiwan (ROC); National Yunlin University of Science and Technology, Douliou, Taiwan (ROC); Da-Yeh University, Dacun, Taiwan (ROC); National Chin-Yi University of Technology, Taichung, Taiwan (ROC)","2020 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-Taiwan)","23 Nov 2020","2020","","","1","2","Many studies applied anomaly detection technology to varied areas such as fraud detection for finance activities, fault detection in industrial systems, and so on. However, big data rises to the challenge of performing a large scale of anomaly analytics in IoT. In this paper, we adopt several methods to analyze a realworld dataset on anomalous events in paper and pulp industry. By experiments, we discuss the findings and illustrate the difficulty in identifying anomalies, which provide useful information for further study.","2575-8284","978-1-7281-7399-3","10.1109/ICCE-Taiwan49838.2020.9258075","MOST-Taiwan(grant numbers:108-2218-E-224-005-MY3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9258075","","Anomaly detection;Dimensionality reduction;Big Data;Switches;Standards;Process control;Heuristic algorithms","","2","","11","IEEE","23 Nov 2020","","","IEEE","IEEE Conferences"
"AI Driven IoT Web-Based Application for Automatic Segmentation and Reconstruction of Abdominal Organs from Medical Images","B. Villarini; H. A. Asaturyan","School of Computer Science and Engineering, University of Westminster, London, United Kingdom; School of Computer Science and Engineering, University of Westminster, London, United Kingdom","2022 18th International Conference on Distributed Computing in Sensor Systems (DCOSS)","12 Sep 2022","2022","","","215","221","Medical imaging technology has rapidly advanced in the last few decades, providing detailed images of the human body. The accurate analysis of these images and the segmentation of anatomical structures can produce significant morphological information, provide additional guidance toward subject stratification after diagnosis or before a clinical trial, and help predict a medical condition. Usually, medical scans are manually segmented by expert operators, such as radiologists and radiographers, which is complex, time-consuming and prone to inter-observer variability. A system that generates automatic, accurate quantitative organ segmentation on a large scale could deliver a clinical impact, supporting current investigations in subjects with medical conditions and aiding early diagnosis and treatment planning. This paper proposes a web-based application that automatically segments multiple abdominal organs and muscle, produces respective 3D reconstructions and extracts valuable biomarkers using a deep learning backend engine. Furthermore, it is possible to upload image data and access the medical image segmentation tool without installation using any device connected to the Internet. The final aim is to deliver a web-based image-processing service that clinical experts, researchers and users can seamlessly access through IoT devices without requiring knowledge of the underpinning technology.","2325-2944","978-1-6654-9512-7","10.1109/DCOSS54816.2022.00045","Royal Academy of Engineering; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9881625","IoT Web Application;Deep Learning;3D Reconstruction;Web Technology;Medical Image Computing;Organ Segmentation","Image segmentation;Three-dimensional displays;Magnetic resonance imaging;Biological systems;Anatomical structure;Muscles;Metadata","","","","16","IEEE","12 Sep 2022","","","IEEE","IEEE Conferences"
"Priority-Aware Task Offloading and Resource Allocation in Satellite and HAP Assisted Edge-Cloud Collaborative Networks","X. Dai; X. Chen; L. Jiao; Y. Wang; S. Du; G. Min","School of Computer Science, Beijing Information Science & Technology University, Beijing, China; School of Computer Science, Beijing Information Science & Technology University, Beijing, China; School of Computer Science, Beijing Information Science & Technology University, Beijing, China; School of Computer Science, Beijing Information Science & Technology University, Beijing, China; School of Computer Science, Beijing Information Science & Technology University, Beijing, China; College of Engineering, Mathematics and Physical Sciences, University of Exeter, Exeter, UK","2023 15th International Conference on Communication Software and Networks (ICCSN)","6 Nov 2023","2023","","","166","171","Mobile edge computing (MEC) has been regarded as an effective technique to handle computing intensive tasks of IoT devices (IoTDs). In this paper, we present a priority-aware edge computing model for space-air-ground integrated networks (SAGIN), which contain a satellite, a high altitude platform (HAP) and numerous IoTDs. In such networks, the HAP provides edge computing services close to the IoTDs and the cloud servers connected to satellite provide cloud computing services. The network considers different services for IoTDs with various Quality-of-Service (QoS) requirements. First, we design a media access control MAC protocol named priority-aware time division multiple access (PTDMA) for controlling the large-scale access of IoTDs. Second, for tasks with different priorities, we propose a priority-aware deep deterministic policy gradient (DDPG) based task offloading and resource allocation scheme (PDOA). Simulation experimental results validate the performance of the PTDMA and PDOA scheme, which can effectively improve the average system utility in a stochastic time-varying environment.","2472-8489","979-8-3503-2936-0","10.1109/ICCSN57992.2023.10297374","National Natural Science Foundation of China(grant numbers:62202059); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10297374","Mobile edge computing;task offloading;resource allocation;high altitude platform;satellite","Cloud computing;Time division multiple access;Satellites;Stochastic processes;Quality of service;Space-air-ground integrated networks;Media Access Protocol","","","","11","IEEE","6 Nov 2023","","","IEEE","IEEE Conferences"
"Development of RF Energy Harvesting Circuit by Multistage and Multiple Connections","S. Torigoe; R. Hosaka; M. M. Mansour; O. Takiguchi; M. Murakami; H. Kanaya","Graduate School of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japan; Graduate School of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japan; Graduate School of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japan; ALSENS Inc., Sagamihara-shi, Kanagawa, JAPAN; SEIKO ELECTRIC CO., LTD., Fukuoka-shi, Fukuoka, JAPAN; Graduate School of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japan","2022 IEEE 24th Electronics Packaging Technology Conference (EPTC)","18 Jan 2023","2022","","","01","04","In recent years, there has been an increase in environmental awareness and the development of IoT. One technology that has been attracting attention is energy harvesting (EH). EH is a technology that harvests unused energy in our surroundings and converts it into electric energy. Although it cannot generate electricity on a large scale, it is being considered for use in devices that can be driven by low power, such as sensors and communication modules like Bluetooth Low Energy (BLE). The high-frequency radio wireless energy focused on in this research is emitted into airspace by many wireless devices and propagates everywhere, but this energy is very weak. In this study, we focused on the electromagnetic waves emitted from UHF-band radio frequency identification (RFID) systems and developed a rectifier circuit that performs RF-DC conversion and boosts the output DC voltage. We also experimented with the proposed circuit to supply power to the sensors and BLE data transmission module.","","979-8-3503-9885-4","10.1109/EPTC56328.2022.10013115","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10013115","","Wireless communication;Radio frequency;Wireless sensor networks;Rectennas;Radio transmitters;Rectifiers;Voltage","","","","13","IEEE","18 Jan 2023","","","IEEE","IEEE Conferences"
"Application of Smart Site Construction Technology in Civil Airport Airfield Area","L. Xiao","China Airport Construction Group Co., Ltd, Beijing, China","2021 7th International Conference on Hydraulic and Civil Engineering & Smart Water Conservancy and Intelligent Disaster Reduction Forum (ICHCE & SWIDR)","29 Dec 2021","2021","","","411","414","The civil airport airfield area project has the characteristics of large construction scale, long construction period, involving many professionals, and high construction quality requirements. The traditional airport airfield area construction management method is difficult to effectively manage the quality, safety, equipment, information, and environment during the construction process, and there are problems such as low management efficiency, poor informationization, and difficulty in adapting to environmental protection requirements. With the rapid development of IoT technology, big data technology, BIM technology and cloud computing technology, smart construction sites have emerged. This article introduces the smart site construction technology in civil airport airfield area from the aspect of key technologies and airport airfield area smart construction site management platform. The intelligent construction site management platform of the civil airport airfield area is the core of the intelligent construction site. The intelligent construction site platform system of the airport airfield area realizes the scientific and precise management of engineering projects through the use of information technology. It has the functions of quality management, safety management, equipment management, information management, environmental management and video monitoring during the construction process. The use of the smart construction site platform can guarantee the construction quality of the airport airfield area, improve the efficiency of construction management, and bring great social and economic benefits.","","978-1-6654-0865-3","10.1109/ICHCESWIDR54323.2021.9656321","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9656321","airport airfield area;construction management;smart site construction","Safety management;Airports;Turning;Information management;Personnel;Internet of Things;Information technology","","","","10","IEEE","29 Dec 2021","","","IEEE","IEEE Conferences"
"Scalable and Upgradable AI for Detected Beat-By-Beat ECG Signals in Smart Health","I. H. Tsai; B. I. Morshed","Department of Computer Science, Texas Tech University, Lubbock, TX, USA; Department of Computer Science, Texas Tech University, Lubbock, TX, USA","2023 IEEE World AI IoT Congress (AIIoT)","13 Jul 2023","2023","","","0409","0414","The accurate and efficient classification of electrocardiogram (ECG) signals is crucial in identifying cardiac conditions for effective remote heart monitoring and telemedicine systems. However, the large-scale data from various ECG databases presents a challenge to traditional artificial intelligence (AI) algorithms. To address this issue, we use multi-stage classification as a promising method in sHealth. In this study, we aim to evaluate the performance and power consumption of various machine learning and deep learning algorithms in single-stage and multi-stage classification. Specifically, we analyzed beats combined from three different ECG databases and trained decision tree (DT), artificial neural network (ANN), support vector machine (SVM), Naïve Bayes, K-nearest neighbors (KNN), bagged tree, recurrent neural network (RNN), convolutional neural network (CNN), and long short-term memory (LSTM) algorithms using time series feature extraction library (TSFEL). By dividing the data into training and testing sets, we were able to obtain the best accuracy for each algorithm and evaluate their memory usage, CPU usage, and running time. Our study highlights the advantages of multi-stage classification with DT and ANN in accurately detecting cardiovascular diseases while also consuming less power, making it a scalable and upgradable approach. The algorithm developed through this research can be implemented in wearable devices as a pre-trained model to efficiently monitor heart health and detect potential cardiac issues. The use of such IoT devices for remote heart monitoring can significantly improve access to healthcare for patients in remote or underserved areas, allowing for early detection and treatment of cardiovascular diseases.","","979-8-3503-3761-7","10.1109/AIIoT58121.2023.10174482","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10174482","Multi-stage classification;Single-stage classification;Cardiac episodes;Unsupervised monitoring;Machine learning","Heart;Support vector machines;Recurrent neural networks;Machine learning algorithms;Databases;Electrocardiography;Classification algorithms","","","","17","IEEE","13 Jul 2023","","","IEEE","IEEE Conferences"
"Leveraging the Decentralised Open IoT Security Protocol ((d)OISP)™: Facilitating Edge-Based Artificial Intelligence in Large-Scale Network Infrastructures","C. P. Autry; W. Henderson; M. Magal; A. W. Roscoe","Iothic, Ltd., The University of Oxford, Florence, Italy; Iothic, Ltd., Oxford, The United Kingdom; Iothic, Ltd, Toronto, Canada; The University of Oxford, Oxford, The United Kingdom","2023 International Conference on Electrical, Computer and Energy Technologies (ICECET)","22 Jan 2024","2023","","","1","8","There is an increasing demand for integrating edge-based Artificial Intelligence (AI) into complex large-scale network infrastructures. This need is driven by the requirement for faster data processing, reduced latency, minimized cyberattack surfaces, and the preservation of bandwidth and lowered energy consumption. Yet, one significant hurdle has consistently stood out: ensuring a secure, authenticated seamless point-to point exchange of information in decentralized systems across heterogeneous devices and platforms without the use of central authority. This paper presents a novel approach to this challenge by leveraging the decentralized Open IoT Security Protocol ((d)OISP). We delve into the architectural design, operational dynamics, and merits of (d)OISP, with its decentralized nature, promises to enhance quantum-safe security measures by utilizing quantum safe standardized cryptosystems and offering a unified protocol that caters to diverse devices without necessitating a central point of control. By incorporating (d)OISP into networks, not only is data exchange made more secure, but the efficiency of edge-based AI operations is notably enhanced, especially in large-scale settings.","","979-8-3503-2781-6","10.1109/ICECET58911.2023.10389601","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10389601","Decentralized;Interoperable;Authentication;Security Protocol;(d)OISP;Edge AI;Quantum Safe;Critical Network Infrastructure;Decentralized Security;Real-Time Processing","Energy consumption;Protocols;Shape;Ecosystems;Bandwidth;Data processing;Security","","","","24","IEEE","22 Jan 2024","","","IEEE","IEEE Conferences"
"FLARE: Detection and Mitigation of Concept Drift for Federated Learning based IoT Deployments","T. Chow; U. Raza; I. Mavromatis; A. Khan","Toshiba Europe Ltd., Bristol Research & Innovation Laboratory, Bristol, UK; Waymap Limited, London, UK; Toshiba Europe Ltd., Bristol Research & Innovation Laboratory, Bristol, UK; Toshiba Europe Ltd., Bristol Research & Innovation Laboratory, Bristol, UK","2023 International Wireless Communications and Mobile Computing (IWCMC)","21 Jul 2023","2023","","","989","995","Intelligent, large-scale IoT ecosystems have become possible due to recent advancements in sensing technologies, distributed learning, and low-power inference in embedded devices. In traditional cloud-centric approaches, raw data is transmitted to a central server for training and inference purposes. On the other hand, Federated Learning migrates both tasks closer to the edge nodes and endpoints. This allows for a significant reduction in data exchange while preserving the privacy of users. Trained models, though, may under-perform in dynamic environments due to changes in the data distribution, affecting the model’s ability to infer accurately; this is referred to as concept drift. Such drift may also be adversarial in nature. Therefore, it is of paramount importance to detect such behaviours promptly. In order to simultaneously reduce communication traffic and maintain the integrity of inference models, we introduce FLARE, a novel lightweight dual-scheduler FL framework that conditionally transfers training data, and deploys models between edge and sensor endpoints based on observing the model’s training behaviour and inference statistics, respectively. We show that FLARE can significantly reduce the amount of data exchanged between edge and sensor nodes compared to fixed-interval scheduling methods (over 5x reduction), is easily scalable to larger systems, and can successfully detect concept drift reactively with at least a 16x reduction in latency.","2376-6506","979-8-3503-3339-8","10.1109/IWCMC58020.2023.10182870","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10182870","Federated Learning;Distributed deployment;Concept Drift;Model Robustness;Scalable IoT Inference","Training;Wireless communication;Computer aided instruction;Federated learning;Distance learning;Biological system modeling;Image edge detection","","","","22","IEEE","21 Jul 2023","","","IEEE","IEEE Conferences"
"Smart Infrastructure: Solutions to Improve Privacy and Security","P. Kardos; B. Suter; D. Mullican; J. Nicol; M. Kline; E. York; A. Salman","School of Integrated Sciences, James Madison University, Harrisonburg, VA; School of Integrated Sciences, James Madison University, Harrisonburg, VA; School of Integrated Sciences, James Madison University, Harrisonburg, VA; School of Integrated Sciences, James Madison University, Harrisonburg, VA; School of Integrated Sciences, James Madison University, Harrisonburg, VA; School of Integrated Sciences, James Madison University, Harrisonburg, VA; School of Integrated Sciences, James Madison University, Harrisonburg, VA","2020 Systems and Information Engineering Design Symposium (SIEDS)","2 Jun 2020","2020","","","1","6","The development and implementation of smart infrastructure raises legitimate security and privacy concerns for both the specific users of these systems as well as the public at large. The consolidation of big data through smart applications within smart infrastructure systems allows large tech companies and government entities to gather and potentially exploit the personal information of consumers. These powerful organizations collect consumer data in order to perform analysis on it, trade or sell it, or simply store it for later use. The gathering of big data or metadata, data about data, provides an opportunity for the collector to observe or predict the behaviors of specific individuals or groups. Those holding this information could use it to promote their own agendas or to otherwise exploit those from whom it has been collected without their knowledge or consent. Additionally, the current lack of legislation and policies concerning the security of smart applications or IoT devices makes the possibility of security and privacy breaches more prevalent. A breach would allow access to sensitive information which would be a threat to security and privacy at an individual and/or national scale. Due to the dynamic nature of smart infrastructure, we employed a systems analysis of this problem as a methodological approach leading to three solutions. We recommend a three-part solution-based analysis, consisting of 1.) Financial Backing 2.) Creation of Policies and Regulations and 3.) Technical Integration. This solution addresses market mitigation, data privacy for consumers, and data authentication between smart technologies and critical infrastructure. Preliminary results of this research suggest that these components are necessary for a sustainable smart infrastructure.","","978-1-7281-7145-6","10.1109/SIEDS49339.2020.9106650","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9106650","Smart Infrastructure;Security;Privacy;Big Data;Funding;Regulation;Integration;Critical;Policy;Technology;Government;Private Industry;Sustainable","Data privacy;Legislation;Companies;Big Data;Metadata;Privacy breach;Regulation","","1","","13","IEEE","2 Jun 2020","","","IEEE","IEEE Conferences"
"mmSpy: Spying Phone Calls using mmWave Radars","S. Basak; M. Gowda","The Pennsylvania State University, University Park, PA; The Pennsylvania State University, University Park, PA","2022 IEEE Symposium on Security and Privacy (SP)","27 Jul 2022","2022","","","1211","1228","This paper presents a system mmSpy that shows the feasibility of eavesdropping phone calls remotely. Towards this end, mmSpy performs sensing of earpiece vibrations using an off-the-shelf radar device that operates in the mmWave spectrum (77GHz, and 60GHz). Given that mmWave radars are becoming popular in a number of autonomous driving, remote sensing, and other IoT applications, we believe this is a critical privacy concern. In contrast to prior works that show the feasibility of detecting loudspeaker vibrations with larger amplitudes, mmSpy exploits smaller wavelengths of mmWave radar signals to detect subtle vibrations in the earpiece devices used in phonecalls. Towards designing this attack, mmSpy solves a number of challenges related to non-availability of large scale radar datasets, systematic correction of various sources of noises, as well as domain adaptation problems in harvesting training data. Extensive measurement-based validation achieves an endto-end accuracy of 83-44% in classifying digits and keywords over a range of 1-6ft, thereby compromising the privacy in applications such as exchange of credit card information. In addition, mmSpy shows the feasibility of reconstruction of the audio signals from the radar data, using which more sensitive information can be potentially leaked.","2375-1207","978-1-6654-1316-9","10.1109/SP46214.2022.9833568","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9833568","side channel attacks;mmWave radars;speech privacy","Vibrations;Training;Radar remote sensing;Adaptation models;Radar detection;Training data;Radar","","7","","103","IEEE","27 Jul 2022","","","IEEE","IEEE Conferences"
"FastTrack: Minimizing Stalls for CDN-Based Over-the-Top Video Streaming Systems","A. O. Al-Abbasi; V. Aggarwal; T. Lan; Y. Xiang; M. -R. Ra; Y. -F. Chen","School of Industrial Engineering, Purdue University, West Lafayette, IN, USA; School of Industrial Engineering & the School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA; Department of Electrical and Computer Engineering, George Washington University, Washington, DC, USA; AT&T Research Labs, Bedminster, NJ, USA; AT&T Research Labs, Bedminster, NJ, USA; AT&T Research Labs, Bedminster, NJ, USA","IEEE Transactions on Cloud Computing","3 Dec 2021","2021","9","4","1453","1466","Traffic for internet video streaming has been rapidly increasing and is further expected to increase with the higher definition videos and IoT applications, such as 360 degree videos and augmented virtual reality applications. While efficient management of heterogeneous cloud resources to optimize the quality of experience is important, existing work in this problem space often left out important factors. In this paper, we present a model for describing a today’s representative system architecture for video streaming applications, typically composed of a centralized origin server and several CDN sites. Our model comprehensively considers the following factors: limited caching spaces at the CDN sites, allocation of CDN for a video request, choice of different ports from the CDN, and the central storage and bandwidth allocation. With the model, we focus on minimizing a performance metric, stall duration tail probability (SDTP), and present a novel, yet efficient, algorithm to solve the formulated optimization problem. The theoretical bounds with respect to the SDTP metric are also analyzed and presented. Our extensive simulation results demonstrate that the proposed algorithms can significantly improve the SDTP metric, compared to the baseline strategies. Small-scale video streaming system implementation in a real cloud environment further validates our results.","2168-7161","","10.1109/TCC.2019.2920979","National Science Foundation(grant numbers:CNS-1618335); Cisco; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8731757","Video streaming;distributed storage systems;content distribution network;caching;two-stage probabilistic scheduling;bandwidth allocation","Streaming media;Streming media;Measurement;Optimization;Quality of experience;Cloud computing;Probabilistic logic;Distribution networks","","8","","41","IEEE","5 Jun 2019","","","IEEE","IEEE Journals"
"From One to Many FemtoClouds","H. Gedawy; A. Elgazar; K. A. Harras",Hamad Bin Khalifa University; Carnegie Mellon University; Carnegie Mellon University,"GLOBECOM 2020 - 2020 IEEE Global Communications Conference","15 Feb 2021","2020","","","1","6","Many novel IoT-based applications now require large compute resources, high-privacy, and low-latency. This demand has triggered the rise of fog and edge computing to complement the high-latency and low-privacy cloud. Fog computing provides lower latency by bringing computational servers closer to the user, typically within the city's vicinity. However, due to the high cost of deploying such fog servers at scale, and poor network infrastructures in many countries and areas, edge computing has been introduced. Edge computing argues for leveraging compute resources, typically within a user's immediate environment, on distributed ensembles of devices called FemtoClouds. In this paper, we propose Maestro, a system that aids users by offloading computational jobs from them to multiple FemtoClouds in their immediate vicinity. We propose an integrated architecture for Maestro, which incorporates a new scheduling algorithm that assigns compute tasks to FemtoClouds. We implement a full prototype of Maestro, and evaluate its performance on our experimental testbed, as well as through emulation. Our results show that our system and scheduler outperforms state-of-the-art by up to 55%.","2576-6813","978-1-7281-8298-8","10.1109/GLOBECOM42002.2020.9348083","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9348083","","Scheduling algorithms;Urban areas;Prototypes;Servers;Global communication;Task analysis;Edge computing","","1","","29","IEEE","15 Feb 2021","","","IEEE","IEEE Conferences"
"DMACN: A Dynamic Multi-Attribute Caching Mechanism for NDN-Based Remote Health Monitoring System","P. Kar; K. Chen; J. Shi","School of Computer Science, University of Nottingham Ningbo China, Ningbo, Zhejiang, China; Department of Electrical and Electronic Engineering, University of Nottingham Ningbo China, Ningbo, Zhejiang, China; Department of Mathematical Science, University of Nottingham Ningbo China, Ningbo, Zhejiang, China","IEEE Transactions on Computers","6 Apr 2023","2023","72","5","1301","1313","Named Data Network (NDN) advocates the philosophy of accessing IoT data owing to its location independence feature. This enables routers to pre-cache content and serves the future requests for the same content on a local basis. Such architecture demonstrates huge application potential in the E-health field. In order to achieve efficient healthcare treatment and administration for both patients and medical professions, the optimization of storing patients’ real-time, large-scale physical data is of necessity. We propose a Dynamic Multi-Attribute Caching mechanism for NDN-Based remote health monitoring system (DMACN). In our model, we adopted a predictable consumer-driven freshness mechanism with low computation cost to satisfy the freshness-sensitive nature of health data. A novel content popularity model based on Analytic Hierarchy Process (AHP) and medical-grade parameters are proposed to handle the doctor-decision-making-coupled Interest sending mechanism of a remote health monitoring system. The final simulation results show DMACN has strong robustness against intensive requesting and complex contents. It is also shown that its performance surpasses existing mechanisms. The Cache Hit Ratio exceeds 37.5% to FIFO and LRU, 220% compared with CPFC, and 55% for CTDICR for both consumer and producer tests. On the other hand, the Latency is about 23.8% lower than FIFO and LRU, 46.6% lower compared with CPFC, and 35.4% for CTDICR.","1557-9956","","10.1109/TC.2022.3197955","Ningbo Municipal Bureau of Science and Technology(grant numbers:202002N3135); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9854159","Named data network;NDN caching mechanism;remote health monitoring system","Monitoring;Internet of Things;Medical services;Computational modeling;Data models;Costs;Computer architecture","","1","","25","IEEE","10 Aug 2022","","","IEEE","IEEE Journals"
"Design and Implementation of Smart Inertial Profilometer System for Road Quality Assessment","M. A. Khan; M. H. Tariq; A. Ali; Y. A. Bakhtiar; T. Kamal","Electrical and Computer Engineering, DSSE, Habib University, Karachi, Pakistan; Electrical and Computer Engineering, DSSE, Habib University, Karachi, Pakistan; Electrical and Computer Engineering, DSSE, Habib University, Karachi, Pakistan; Electrical and Computer Engineering, DSSE, Habib University, Karachi, Pakistan; Electrical and Computer Engineering, DSSE, Habib University, Karachi, Pakistan","IECON 2023- 49th Annual Conference of the IEEE Industrial Electronics Society","16 Nov 2023","2023","","","1","6","Roads are one of the most essential element in maintaining the socioeconomic backbone of any region due to their facilitation of mobility, connectivity, social integration, and regional development. For growing urban cities like Karachi, Pakistan, accurate and precise monitoring of road health is vital for economic and infrastructural growth. This paper presents the design of a highly cost-effective, power-efficient, IoT-enabled Road Health Monitoring System (RHMS) for real-time quantification of the International Roughness Index (IRI). The study details the node architecture, including essential modules, sensors, and BMS, as well as their integration and deployment in the field. Results of the conducted experiment are presented for IRI calculation, power consumption, and device reliability. The developed system can be deployed on a large scale in dense urban regions with intricate transportation networks to realistically analyze road conditions, identify efficient routes, and address repair demands, thereby enabling the construction of sustainable socio-political policies for urban planning.","2577-1647","979-8-3503-3182-0","10.1109/IECON51785.2023.10312603","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10312603","Urban Road Health;Sensor Integration;IoT-enabled Systems","Roads;Urban planning;Transportation;Rough surfaces;Quality assessment;Sensors;Indexes","","","","12","IEEE","16 Nov 2023","","","IEEE","IEEE Conferences"
"CHERIoT: Complete Memory Safety for Embedded Devices","S. Amar; D. Chisnall; T. Chen; N. W. Filardo; B. Laurie; K. Liu; R. Norton; S. W. Moore; Y. Tao; R. N. M. Watson; H. Xia","Microsoft Tel Aviv, Israel; Microsoft Cambridge, UK; Microsoft Redmond, Washington, USA; Microsoft Cambridge, UK; Google London, UK; Microsoft San Diego, California, USA; Microsoft Cambridge, UK; University of Cambridge, Cambridge, UK; Microsoft Mountain View, California, USA; University of Cambridge, Cambridge, UK; Arm Ltd, Cambridge, UK","2023 56th IEEE/ACM International Symposium on Microarchitecture (MICRO)","6 Feb 2024","2023","","","641","653","The ubiquity of embedded devices is apparent. The desire for increased functionality and connectivity drives ever larger software stacks, with components from multiple vendors and entities. These stacks should be replete with isolation and memory safety technologies, but existing solutions impinge upon development, unit cost, power, scalability, and/or real-time constraints, limiting their adoption and production-grade deployments. As memory safety vulnerabilities mount, the situation is clearly not tenable and a new approach is needed.To slake this need, we present a novel adaptation of the CHERI capability architecture, co-designed with a green-field, security-centric RTOS. It is scaled for embedded systems, is capable of fine-grained software compartmentalization, and provides affordances for full inter-compartment memory safety. We highlight central design decisions and offloads and summarize how our prototype RTOS uses these to enable memory-safe, compartmentalized applications. Unlike many state-of-the-art schemes, our solution deterministically (not probabilistically) eliminates memory safety vulnerabilities while maintaining source-level compatibility. We characterize the power, performance, and area microarchitectural impacts, run microbenchmarks of key facilities, and exhibit the practicality of an end-to-end IoT application. The implementation shows that full memory safety for compartmentalized embedded systems is achievable without violating resource constraints or real-time guarantees, and that hardware assists need not be expensive, intrusive, or power-hungry.","","979-8-3503-3056-4","","Innovate UK; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10411387","","Microarchitecture;Embedded systems;Costs;Hardware;Real-time systems;Safety;Security","","","","31","","6 Feb 2024","","","IEEE","IEEE Conferences"
"Adaptive Uplink Data Compression in Spectrum Crowdsensing Systems","Y. Zeng; R. Calvo-Palomino; D. Giustiniano; G. Bovet; S. Banerjee",UW-Madison; Universidad Rey Juan Carlos; IMDEA Networks; armasuisse; UW-Madison,"2021 IEEE International Symposium on Dynamic Spectrum Access Networks (DySPAN)","20 Jan 2022","2021","","","114","122","Understanding spectrum activity is challenging when attempted at scale. The wireless community has recently risen to this challenge in designing spectrum monitoring systems that utilize many low-cost spectrum sensors to gather large volumes of sampled data across space, time, and frequencies. These crowdsensing systems are limited by the uplink bandwidth available for transmitting to the backhaul network raw in-phase and quadrature (IQ) samples and power spectrum density (PSD) measurements needed to run a variety of applications. This paper presents FlexSpec, a framework based on the Walsh-Hadamard transform to compress spectrum data collected from distributed and low-cost sensors for real-time applications. We show that this transformation allows sensors to greatly save uplink bandwidth thanks to its inherent properties both when it is applied to IQ and PSD measurements. Additionally, by leveraging a feedback loop between an edge device and the sensor, FlexSpec carefully adapts the compression ratio over time, such that data size, application’s performance, and spectrum variations are all considered. We experimentally evaluate FlexSpec in several applications. Our results show that FlexSpec is particularly suitable for IoT transmissions and for signals close to the noise floor. Compared with prior work, FlexSpec provides up to 7× more reduction of uplink data size for signal detection based on PSD data, and reduces up to 6× to 8× the number of undecodable messages for IQ sample decoding.","2334-3125","978-1-6654-1339-8","10.1109/DySPAN53946.2021.9677075","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9677075","","Wireless communication;Wireless sensor networks;Time-frequency analysis;Crowdsensing;Bandwidth;Transforms;Sensor systems","","2","","18","IEEE","20 Jan 2022","","","IEEE","IEEE Conferences"
"Hybrid Workflow Provisioning and Scheduling on Cooperative Edge Cloud Computing","R. Alsurdeh; R. N. Calheiros; K. M. Matawie; B. Javadi","School of Computer, Data and Mathematical Sciences, Western Sydney University, Sydney, Australia; School of Computer, Data and Mathematical Sciences, Western Sydney University, Sydney, Australia; School of Computer, Data and Mathematical Sciences, Western Sydney University, Sydney, Australia; School of Computer, Data and Mathematical Sciences, Western Sydney University, Sydney, Australia","2021 IEEE/ACM 21st International Symposium on Cluster, Cloud and Internet Computing (CCGrid)","2 Aug 2021","2021","","","445","454","The dramatic growth of IoT-based applications in many domains such as real-time monitoring, interactive reporting, and smart manufacturing brings challenges for adoption of cloud-based solutions for integration of latency-sensitive and resource-intensive applications. We refer to this integration as a hybrid-workflow. This paper provides a resource estimation and task scheduling framework to run hybrid workflows on edge and cloud computing systems. We propose an adaptive resource estimation technique with an online gradient descent approximation to handle the complexity of hybrid workflows. In addition, a scheduling technique to execute workflow tasks on a cooperative edge cloud system to resolve the issues of latency-sensitive application as well as to improve resource utilization at the edge layer is proposed. Experimental results show the capability of the cooperative model in reducing the time and cost of running complex and large scale hybrid workflows.","","978-1-7281-9586-5","10.1109/CCGrid51090.2021.00054","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9499354","Hybrid workflow scheduling;Stream processing;Cooperative edge;Edge cloud computing;Resource provisioning","Cloud computing;Job shop scheduling;Processor scheduling;Computational modeling;Estimation;Real-time systems;Complexity theory","","1","","40","IEEE","2 Aug 2021","","","IEEE","IEEE Conferences"
"Adaptive Uplink Data Compression in Spectrum Crowdsensing Systems","Y. Zeng; R. Calvo-Palomino; D. Giustiniano; G. Bovet; S. Banerjee","Department of Computer Sciences, University of Wisconsin–Madison, Madison, WI, USA; Department of Signal Theory and Communications and Telematic Systems and Computing, Universidad Rey Juan Carlos, Madrid, Spain; IMDEA Networks Institute, Leganés, Spain; Armasuisse, Bern, Switzerland; Department of Computer Sciences, University of Wisconsin–Madison, Madison, WI, USA","IEEE/ACM Transactions on Networking","16 Oct 2023","2023","31","5","2207","2221","Understanding spectrum activity is challenging when attempted at scale. The wireless community has recently risen to this challenge in designing spectrum monitoring systems that utilize many low-cost spectrum sensors to gather large volumes of sampled data across space, time, and frequencies. These crowdsensing systems are limited by the uplink bandwidth available to backhaul the raw in-phase and quadrature (IQ) samples and power spectrum density (PSD) data needed to run various applications. This paper presents FlexSpec, a framework based on the Walsh-Hadamard transform to compress spectrum data collected from distributed and low-cost sensors for real-time applications. This transformation allows sensors to significantly save uplink bandwidth thanks to its inherent properties both when it is applied to IQ and PSD data. Additionally, by leveraging a feedback loop between the sensor and the edge device it connects to, FlexSpec carefully adapts the compression ratio over time to changes in the spectrum and different applications, jointly considering data size, application performance, and spectrum variations. We experimentally evaluate FlexSpec in several applications. Our results show that FlexSpec is particularly suitable for IoT transmissions and signals close to the noise floor. Compared with prior work, FlexSpec provides up to  $7\times $  more reduction of uplink data size for signal detection based on PSD data, and reduces up to  $6\times $  to  $8\times $  the number of undecodable messages for IQ sample decoding.","1558-2566","","10.1109/TNET.2023.3239378","Fundación IMDEA Networks (IMDEA) through the Madrid Regional Government Técnicas Avanzadas para Potenciar la Inteligencia de las Redes “(TAPIR-CM) Project”(grant numbers:2018/TCS-4496); Ministry of Economic Affairs and Digital Transformation through the Project Machine Learning-based Privacy Preserving Analytics for 6G Mobile Networks (MAP-6G)(grant numbers:TSI-063000-2021-63); U.S. National Science Foundation(grant numbers:CNS-2112562,CNS-2107060,CNS-2003129,CNS-1838733,CNS-1647152); U.S. Department of Commerce(grant numbers:70NANB21H043); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10032115","Spectrum crowdsensing;adaptive data compression;fast Walsh-Hadamard transform;feedback loop","Sensors;Uplink;Crowdsensing;Decoding;Data compression;Wireless communication;Backhaul networks","","1","","51","IEEE","30 Jan 2023","","","IEEE","IEEE Journals"
"GitFL: Uncertainty-Aware Real-Time Asynchronous Federated Learning Using Version Control","M. Hu; Z. Xia; D. Yan; Z. Yue; J. Xia; Y. Huang; Y. Liu; M. Chen","School of Computer Science and Engineering, Nanyang Technological University, Singapore; MoE Engineering Research Center of SW/HW Co-Design Tech. and App., East China Normal University, China; MoE Engineering Research Center of SW/HW Co-Design Tech. and App., East China Normal University, China; MoE Engineering Research Center of SW/HW Co-Design Tech. and App., East China Normal University, China; MoE Engineering Research Center of SW/HW Co-Design Tech. and App., East China Normal University, China; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; MoE Engineering Research Center of SW/HW Co-Design Tech. and App., East China Normal University, China","2023 IEEE Real-Time Systems Symposium (RTSS)","6 Feb 2024","2023","","","145","157","As a promising distributed machine learning paradigm that enables collaborative training without compromising data privacy, Federated Learning (FL) has been increasingly used in large-scale A IoT (Artificial Intelligence of Things) system design. However, due to the lack of efficient management of straggling devices, existing FL methods greatly suffer from the problems of long response time (e.g., training and communication latency) and low inference accuracy. Things become even worse when taking various uncertain factors (e.g., network delays, performance variances caused by process variation) existing in AIoT scenarios into account. To address this issue, this paper proposes a novel asynchronous FL framework named GitFL, whose implementation is inspired by the famous version control system Git. Unlike traditional FL, the cloud server of GitFL maintains a master model (i.e., the global model) together with a set of branch models indicating the trained local models committed by selected devices, where the master model is updated based on both all the pushed branch models and their version information, and only the branch models after the pull operation are dispatched to devices. By using our proposed Reinforcement Learning (RL)-based device selection mechanism, a pulled branch model with an older version will be more likely to be dispatched to a faster and less frequently selected device for the next round of local training. In this way, GitFL enables both effective controls of model staleness and adaptive load balance of versioned models among straggling devices, thus avoiding performance deterioration while ensuring real-time performance. Comprehensive experimental results on well-known models and datasets show that, compared with state-of-the-art asynchronous and synchronous FL methods, GitFL can achieve up to 2.64X training acceleration and 7.88 % inference accuracy improvements in various uncertain scenarios.","2576-3172","979-8-3503-2857-8","10.1109/RTSS59052.2023.00022","National Research Foundation Singapore(grant numbers:AISG2-RP-2020-019); DSO National Laboratories under the AI Singapore Programme(grant numbers:AISG2-RP-2020-019); Natural Science Foundation of China(grant numbers:62272170); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10406061","AIoT;Asynchronous Federated Learning;Uncertainty;Reinforcement Learning;Version Control","Training;Performance evaluation;Adaptation models;Real-time systems;Time factors;Internet of Things;Load modeling","","","","40","IEEE","6 Feb 2024","","","IEEE","IEEE Conferences"
"PPGC: A Path Planning System by Grid Caching based on Cloud-Edge Collaboration for Unmanned Surface Vehicle in IoT Systems","L. Yan; H. Chen; Y. Tu; X. Zhou; S. Drew","Faculty of Electrical Engineering and Computer Science, Ningbo University, Zhejiang, China; Faculty of Electrical Engineering and Computer Science, Ningbo University, Zhejiang, China; Faculty of Electrical Engineering and Computer Science, Ningbo University, Zhejiang, China; Faculty of Electrical Engineering and Computer Science, Ningbo University, Zhejiang, China; Department of Electrical and Software Engineering, University of Calgary, AB, Canada","2022 IEEE 19th International Conference on Mobile Ad Hoc and Smart Systems (MASS)","19 Dec 2022","2022","","","74","80","Unmanned Surface Vehicle (USV), as an important terminal device in IoT systems, is widely used in various fields. Path planning is one of the common problems to be solved in different USV applications. Most of the current path planning systems are deployed in the cloud, resulting in fluctuating trans-mission delay, considerable computational delay and queuing delay when processing path planning requests from multiple USVs. Furthermore, in large-scale path planning systems, the computational time spent in planning the optimal path grows exponentially with the increasing distance between the source and target location. To address these path planning problems in the cloud, we propose a Path Planning algorithm by Grid Caching (PPGC) based on Cloud-Edge collaboration. PPGC only processes path requests at the current edge servers in the areas of the USVs, and optimizes path sharing cache and the grid-based path matching algorithm to improve the promptness of the path planning response. Experimental results show that the average response latency of the proposed path planning system is reduced by 73% compared with the cloud-based path planning system.","2155-6814","978-1-6654-7180-0","10.1109/MASS56207.2022.00018","National Natural Science Foundation of China NSFC(grant numbers:62002183); Ningbo Natural Science Foundation(grant numbers:2021J090,202003N4087); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9973644","USV;path planning;cloud-edge collaboration;grid;caching","Collaboration;Computer architecture;Path planning;Cache storage;Delays;Planning;Servers","","","","14","IEEE","19 Dec 2022","","","IEEE","IEEE Conferences"
"A ZigBee – based Lightweight Wireless Sensor System for measuring action potential bio signals in Agriculture IoT Applications","A. Gotsinas; K. Kalovrektis; A. Xenakis; G. Stamoulis","Computer Science, University of Piraeus, Pireus, Greece; Computer Science and Telecommunications, University of Thessaly, Lamia, Greece; Computer Science and Telecommunications, University of Thessaly, Lamia, Greece; Computer Science and Telecommunications, University of Thessaly, Lamia, Greece","2020 11th International Conference on Information, Intelligence, Systems and Applications (IISA","11 Dec 2020","2020","","","1","7","The deployment and integration of a low power pervasive wireless sensor system, for measuring and processing action potentials bio signals for plants, is an interesting and challenging technical task. In our experiments, we focus on measuring electrical potentials for Chrysanthemum and Sansevieria plants. We note that the wireless pervasive sensor system, for real time data collection, should be optimally designed in terms of energy and communication costs. Therefore, in our work, we design and propose an optimized ZigBee - based lightweight end to end system to measure and evaluate plant action potentials. Our system's design functionality response results, demonstrated a significant reduction in the firmware code length, to be loaded in the microcontroller unit, potential use of 8 - bit microcontrollers with low memory capacity and reduced development costs for hundreds of measuring plant points and reduced processing and communication costs. All these results makes the system suitable for large scale use in agricultural IoT applications.","","978-1-6654-2228-4","10.1109/IISA50023.2020.9284340","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284340","Wireless Sensor Networks;ZigBee;Bio signals;Ag/AgCL sensors;IoT agriculture applications","Wireless communication;Wireless sensor networks;Zigbee;Agriculture;Sensor systems;Real-time systems;Monitoring","","","","23","IEEE","11 Dec 2020","","","IEEE","IEEE Conferences"
"Accelerate Deep Learning in IoT: Human-Interaction Co-Inference Networking System for Edge","C. Zhang; M. Dong; K. Ota","Advanced Institute of Industrial Technology, Tokyo Metropolitan Public University Corporation, Tokyo, Japan; Department of Information and Electronic Engineering, Muroran Institute of Technology, Muroran, Japan; Department of Information and Electronic Engineering, Muroran Institute of Technology, Muroran, Japan","2020 13th International Conference on Human System Interaction (HSI)","17 Jul 2020","2020","","","1","6","As the core technology of the artificial intelligence in the new era, AI technology applied in health care devices has received significant attention. However, due to the limitation of the power supply and computation resource, it is difficult to implement a stable and large AI based human interaction task processing system from the remote edge devices to the centered clouds. In this paper, we propose a holistic network solution that focuses on solving the potential problems of network congestion with the explosive growth of IoT health care devices supported AI inference tasks. First, we propose a multi-hop maximum weight network to describe a DNN inference network based on edge computing. Then, we propose a Maximum Weight Wave propulsion Algorithm (MWWP) algorithm to reduce the overall network latency. Finally, we build up a prototype of a distributed AI inference system and test the computation and transmission performance. Besides, through large-scale experiments, we prove the optimality of our holistic solution.","2158-2254","978-1-7281-7392-4","10.1109/HSI49210.2020.9142631","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9142631","","Cloud computing;Routing;Feature extraction;Computational modeling;Machine learning;Task analysis","","3","","18","IEEE","17 Jul 2020","","","IEEE","IEEE Conferences"
"Temporal based Network Packet Anomaly Detection using Machine Learning","V. K. B. P; S. DV; S. Hegde; C. Pankaj; S. Suresh; P. Ramakrishna","Department of Information Science and Engineering, M S Ramaiah Institute of Technology, Bangalore, INDIA; Department of Information Science and Engineering, M S Ramaiah Institute of Technology, Bangalore, INDIA; Department of Information Science and Engineering, M S Ramaiah Institute of Technology, Bangalore, INDIA; Department of Information Science and Engineering, M S Ramaiah Institute of Technology, Bangalore, INDIA; Department of Information Science and Engineering, M S Ramaiah Institute of Technology, Bangalore, INDIA; Department of Information Science and Engineering, M S Ramaiah Institute of Technology, Bangalore, INDIA","2021 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT)","7 Dec 2021","2021","","","1","6","In the present computer networking scenario, due to increase in the amount of ubiquitous network usage with computers, mobile computing, sensing systems and IoT applications, there is a tendency for large-scale cyber-attacks to occur. With the enormous rise in cyber-attacks in today's world, it becomes imperative to monitor the network packet flow in order to identify attacks by intruders, which otherwise can lead to disruptions and losses in computing resources. These large dimensional and voluminous network packets have to be carefully examined and investigated for network anomalies, and will be a tedious and complicated task. Hence, to make this process simpler, a network anomaly detection model that considers the temporal variations in packet transmissions to identify the threats and to protect these networks against malicious activities is proposed. In this model, we propose a machine learning based anomaly detection system (ADS) that is capable of classifying malicious and benign traffic. At the same time, identifies the time varying patterns by using unsupervised learning that provides the patterns and hidden features in the captured packets. Kohonen's self-organizing map neural network (KSOM-NN) is used as an unsupervised learning method to classify the pre-processed packet features into clusters and thereafter the classification methods are used and verified with the labelled dataset. Similarly, a statistical analysis and a threshold value of packet loss, jitter, and other parameters for normal and anomalous packets are observed for further investigations. Above models were trained and tested with the UNSW-NB15 dataset. Totally the patterns are thoroughly analyzed for anomalies with the help of supervised and unsupervised machine learning algorithms. Improved performance with respect to anomaly detection rate and accuracy is observed.","2766-2101","978-1-6654-2849-1","10.1109/CONECCT52877.2021.9622556","All India Council for Technical Education (AICTE) RPS(grant numbers:8-224/RIFD/ RPS(Policy-1)/2018-19); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9622556","Machine Learning;Supervised Learning;Computer Networks;Intrusion Detections;Network Anomaly","Self-organizing feature maps;Statistical analysis;Neural networks;Packet loss;Machine learning;Sensors;Task analysis","","","","10","IEEE","7 Dec 2021","","","IEEE","IEEE Conferences"
"New Vision for 5G Backbone Network Architecture","S. C. Gupta; G. Gupta; H. Saran","Dept of CSE, Indian Institute of Technology, Delhi, India; Software Engineer, Seattle, USA; Dept of CSE, Indian Institute of Technology, Delhi, India","2020 IEEE 3rd 5G World Forum (5GWF)","13 Oct 2020","2020","","","330","336","Today’s routing infrastructure uses BGP for interdomain routing, which suffers from several well-known issues - slow convergence, lack of transparency, limited control in routing, and limited scalability for handling the massive IPv6 address space. As a result, it cannot meet the stringent requirements 5G ultra-reliable low-latency communication (URLLC), which has been designed for latency-critical real-time applications such as tele robotics and augmented reality, and must scale up to support millions of IoT devices. To address these shortcomings of today’s routing infrastructure, we propose a four layer hierarchical network architecture, that associates a real (geographical) address with each IP address. The real address has four parts - country, state, district, and AS - that correspond to the four layers of routing hierarchy, and is used for inter-domain routing; the IP address is used for routing only within an AS. The hierarchical routing using geographical addresses enables quick convergence, fewer number of routing hops, and a very small number of forwarding rules in each router. Each network layer can further be sliced for the three broad categories of 5G users i.e mBBC, MTC and uRLLC. As deploying a new architecture across the globe is challenging, we discuss how it can be incrementally deployed one country at a time, exploiting existing infrastructure for international routing.","","978-1-7281-7299-6","10.1109/5GWF49715.2020.9221152","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9221152","5G;uRLLC;Internet Architecture;Innovation;Inter-domain routing;BGP;DNS;IPv6","5G mobile communication;Scalability;Ultra reliable low latency communication;Network architecture;Routing;Real-time systems;IP networks","","2","","25","IEEE","13 Oct 2020","","","IEEE","IEEE Conferences"
"Joint Modulation and Beamforming for MIMO Systems With 1-b DACs","Y. Han; J. Lee; R. Zakaria; D. Le Ruyet","Department of Electrical and Computer Engineering, INMAC, Seoul National University, Seoul, South Korea; Department of Electrical and Computer Engineering, INMAC, Seoul National University, Seoul, South Korea; CEDRIC laboratory, Conservatoire National des Arts et Métiers, Paris, France; CEDRIC laboratory, Conservatoire National des Arts et Métiers, Paris, France","IEEE Transactions on Vehicular Technology","16 Jan 2020","2020","69","1","1075","1079","To realize multiple-input multiple-output (MIMO) with low cost and low power consumption, the use of low-resolution digital-to-analog converters (DAC) is drawing significant interest. While previous studies on low-resolution DAC MIMO have focused on optimizing precoding for massive MIMO, this approach faces the limitation that the coarse resolution at the transmitter makes it difficult to construct a transmit signal close enough to the desired one when a small scale MIMO transmitter is considered as in IoT networks. To address this problem, we propose a new transmission framework that jointly performs modulation and beamforming. With the proposed scheme, a message symbol is directly mapped into a feasible transmit vector. We also develop a channel-adaptive mapping function within the proposed framework that minimizes error probability. Simulation results show that the proposed scheme can significantly improve the error performance.","1939-9359","","10.1109/TVT.2019.2950308","Korean-French Science and Technology Amicable Relationship (STAR)(grant numbers:2016K1A3A1A21005707,36670SC); Basic Science Research Programs(grant numbers:2017R1A2B2007102); MSIP; BK21-PLUS; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8886524","Low-resolution DAC;precoding;joint modulation and beamforming","MIMO communication;Precoding;Modulation;Transmitters;Array signal processing;Receivers","","1","","15","IEEE","30 Oct 2019","","","IEEE","IEEE Journals"
"On the Role of Smart Vision Sensors in Energy-Efficient Computer Vision at the Edge","A. Ancilotto; F. Paissan; E. Farella","E3DA Unit, Digital Society Center, Fondazione Bruno Kessler (FBK), Trento, Italy; E3DA Unit, Digital Society Center, Fondazione Bruno Kessler (FBK), Trento, Italy; E3DA Unit, Digital Society Center, Fondazione Bruno Kessler (FBK), Trento, Italy","2022 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops)","6 May 2022","2022","","","497","502","The increasing focus of the research community towards lightweight and small footprint neural network models is closing the gap between inference performance in cluster-scale models and tiny devices. In the recent past, researchers have shown how it is possible to achieve state-of-the-art performance in different domains (e.g. sound event detection, object detection, image classification) with small footprints and low computational cost architectures. However, these studies lack a comprehensive analysis of the input space used (e.g. for images) and present the results on standard RGB benchmarks. In this manuscript, we investigate the role of smart vision sensors (SVSs) in deep learning-based object detection pipelines. In particular, we combine the motion bitmaps with standard color spaces representations (namely, RGB, YUV, and grayscale) and show how SVSs can be used optimally for an IoT end-node. In conclusion, we report that, overall, the best-performing input space is grayscale augmented with the motion bitmap. These results are promising for real-world applications since many SVSs provide both image formats at low power consumption.","","978-1-6654-1647-4","10.1109/PerComWorkshops53856.2022.9767380","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9767380","smart vision sensors;edge computing;tinyML;embedded computer vision","Performance evaluation;Computer vision;Conferences;Computational modeling;Pipelines;Object detection;Vision sensors","","1","","31","IEEE","6 May 2022","","","IEEE","IEEE Conferences"
"Resistive Neural Hardware Accelerators","K. Smagulova; M. E. Fouda; F. Kurdahi; K. N. Salama; A. Eltawil","Division of Computer, Electrical and Mathematical Sciences and Engineering (CEMSE), King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; Center for Embedded and Cyber-Physical Systems, University of California at Irvine, Irvine, CA, USA; Center for Embedded and Cyber-Physical Systems, University of California at Irvine, Irvine, CA, USA; Division of Computer, Electrical and Mathematical Sciences and Engineering (CEMSE), King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; Division of Computer, Electrical and Mathematical Sciences and Engineering (CEMSE), King Abdullah University of Science and Technology, Thuwal, Saudi Arabia","Proceedings of the IEEE","16 May 2023","2023","111","5","500","527","Deep neural networks (DNNs), as a subset of machine learning (ML) techniques, entail that real-world data can be learned, and decisions can be made in real time. However, their wide adoption is hindered by a number of software and hardware limitations. The existing general-purpose hardware platforms used to accelerate DNNs are facing new challenges associated with the growing amount of data and are exponentially increasing the complexity of computations. Emerging nonvolatile memory (NVM) devices and the compute-in-memory (CIM) paradigm are creating a new hardware architecture generation with increased computing and storage capabilities. In particular, the shift toward resistive random access memory (ReRAM)-based in-memory computing has great potential in the implementation of area- and power-efficient inference and in training large-scale neural network architectures. These can accelerate the process of IoT-enabled AI technologies entering our daily lives. In this survey, we review the state-of-the-art ReRAM-based DNN many-core accelerators, and their superiority compared to CMOS counterparts was shown. The review covers different aspects of hardware and software realization of DNN accelerators, their present limitations, and prospects. In particular, a comparison of the accelerators shows the need for the introduction of new performance metrics and benchmarking standards. In addition, the major concerns regarding the efficient design of accelerators include a lack of accuracy in simulation tools for software and hardware codesign.","1558-2256","","10.1109/JPROC.2023.3268092","King Abdullah University of Science and Technology through the Competitive Research Grant (CRG)(grant numbers:URF/1/4704-01-01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10127587","Compute-in-memory (CIM);deep neural networks (DNNs);hardware acceleration;in-memory computing;processing-in-memory;resistive random access memory (ReRAM)","Deep learning;Neural networks;Random access memory;Hardware acceleration;Memory management;Resistive RAM","","2","","163","IEEE","16 May 2023","","","IEEE","IEEE Journals"
"CYBRIA - Pioneering Federated Learning for Privacy-Aware Cybersecurity with Brilliance","P. Thantharate; A. T",NA; NA,"2023 IEEE 20th International Conference on Smart Communities: Improving Quality of Life using AI, Robotics and IoT (HONET)","1 Jan 2024","2023","","","56","61","Centralized machine learning approaches for cyber-security raise significant privacy and security concerns due to raw data aggregation from distributed sources. This paper presents Cybria, a federated learning framework for collaborative cyber threat detection without compromising confidential data. The decentralized approach trains models on local data distributed across clients and shares only intermediate model updates to generate an integrated global model. We develop a federated learning architecture tailored for privacy-preserving intrusion detection. Comparative evaluations on the Bot-IoT dataset demonstrate that Cybria's federated model achieves 89.6% accuracy compared to 81.4% for a centralized deep neural network. The ~10% improvement highlights the benefits of collective learning from decentralized data for cyber defense applications. However, real-world deployment faces challenges like statistical heterogeneity, systemic bias, and data poisoning attacks. Advances in secure aggregation, differential privacy, and adversarial defenses are crucial to robust large-scale adoption. With thoughtful human-centric design, federated intelligence paves the path for an ecosystem approach to security where organizations collectively build threat awareness without centralizing data.","1949-4106","979-8-3503-3111-0","10.1109/HONET59747.2023.10374608","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10374608","Cybersecurity;Federated Learning;IoT;Privacy-Aware;Decentralized Learning","Production systems;Federated learning;Smart cities;Biological system modeling;Ecosystems;Intrusion detection;Organizations","","1","","16","IEEE","1 Jan 2024","","","IEEE","IEEE Conferences"
"Flexible Parallel Learning in Edge Scenarios: Communication, Computational and Energy Cost","F. Malandrino; C. F. Chiasserini","CNR-IEIIT and CNIT, Torino, Italy; Politecnico di Torino, CNR-IEIIT and CNIT, Torino, Italy","2022 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops)","6 May 2022","2022","","","509","514","Traditionally, distributed machine learning takes the guise of (i) different nodes training the same model (as in federated learning), or (ii) one model being split among multiple nodes (as in distributed stochastic gradient descent). In this work, we highlight how fog- and IoT-based scenarios often require combining both approaches, and we present a framework for flexible parallel learning (FPL), achieving both data and model parallelism. Further, we investigate how different ways of distributing and parallelizing learning tasks across the participating nodes result in different computation, communication, and energy costs. Our experiments, carried out using state-of-the-art deep-network architectures and large-scale datasets, confirm that FPL allows for an excellent trade-off among computational (hence energy) cost, communication overhead, and learning performance.","","978-1-6654-1647-4","10.1109/PerComWorkshops53856.2022.9767275","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9767275","Edge computing;distributed machine learning","Training;Costs;Conferences;Machine learning;Computer architecture;Parallel processing;Collaborative work","","1","","21","IEEE","6 May 2022","","","IEEE","IEEE Conferences"
"Multipath TCP Meets Transfer Learning: A Novel Edge-Based Learning for Industrial IoT","S. R. Pokhrel; L. Pan; N. Kumar; R. Doss; H. L. Vu","School of Information Technology, Deakin University, Geelong, VIC, Australia; School of Information Technology, Deakin University, Geelong, VIC, Australia; Department of Computer Science and Information Engineering, Thapar Institute of Engineering, Patiala, India; School of Information Technology, Deakin University, Geelong, VIC, Australia; Institute of Transport Studies, Monash University, Melbourne, VIC, Australia","IEEE Internet of Things Journal","22 Jun 2021","2021","8","13","10299","10307","We consider a fifth-generation (5G)-empowered future Industrial IoT (IIoT) networking problem where IIoT machines are capable of communicating and sharing their data networking knowledge gained (and experiences) with other neighboring devices/tools. For such an IIoT setting, deep-learning (DL)-based communication protocols are known to be highly efficient but having a computationally complex training procedure in terms of both time/space and volume of data sets. One solution for such training is to be completed offline for each equipment and machines of IIoT before deployment. A better approach would be to replicate the model from the expert existing machine and implant it into new machines. Such training for the transfer of knowledge can be done by manufacturers using high computational power, even for large-scale DL models. After sufficient training and the desired level of accuracy, the trained machines can be deployed in the smart factory equipment to perform life-long collaborative learning. We design a novel distributed transfer learning (TL) framework to maximize multipath communication networking performance for Industry 4.0 environment. To conduct seamless sharing of knowledge gain by the multipath TCP (MPTCP) agents and tackle retraining issues of DL-based approaches, we investigate TL for MPTCP from the IIoT networking perspective. With relevant insights from transfer and collaborative learning, we develop a distributed TL-MPTCP framework to accelerate the learning efficiency and enhance the performance of newly deployed machines. Our approach is validated with numerical and emulated NS-3 experiments in comparison with the state-of-the-art schemes.","2327-4662","","10.1109/JIOT.2021.3056466","School of IT internal fund, Deakin University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9344582","Industrial Internet of Things (IIoT);Industry 4.0;multipath communication model;smart manufacturing;transfer learning (TL)","Wireless fidelity;Analytical models;Throughput;Cellular networks;Couplings;Wireless networks;Propagation losses","","23","","35","IEEE","2 Feb 2021","","","IEEE","IEEE Journals"
"Early Detection of Heart Disease Using Advances of Machine Learning for Large-Scale Patient Datasets","S. A. A. Shah; A. H. Saleh; M. Ebrahimian; R. Kashef","Department of Electrical and Computer Engineering, Toronto Metropolitan University, Toronto, Canada; Department of Electrical and Computer Engineering, Toronto Metropolitan University, Toronto, Canada; Department of Electrical and Computer Engineering, Toronto Metropolitan University, Toronto, Canada; Department of Electrical and Computer Engineering, Toronto Metropolitan University, Toronto, Canada","2022 IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)","17 Oct 2022","2022","","","274","280","Heart disease is one of the significant causes of death all over the world. The Healthcare industry produces a large amount of data; thus, heart disease prediction is becoming a challenging task in IoT-based healthcare systems. Machine learning plays a vital role in predicting the disease accurately. Many studies have been conducted in this area; however, they do not use large-size datasets to explore the real power of machine learning techniques in predicting heart disease. In this paper, we used four large-scale multi-dimensionality heart disease datasets collected from different sources. We applied various traditional machine learning techniques, namely Decision Tree (DT), Naïve Bayes (NB), K-Nearest Neighbor (KNN), Random Forest (RF), Support Vector Machine (SVM), and Multilayer Perceptron (MLP) to predict heart disease. The results are compared to an ensemble model for the diagnosis of the heart disease.","2576-7046","978-1-6654-8432-9","10.1109/CCECE49351.2022.9918215","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9918215","heart disease;machine learning;ensemble modeling","Heart;Support vector machines;Radio frequency;Industries;Computational modeling;Medical services;Multilayer perceptrons","","","","26","IEEE","17 Oct 2022","","","IEEE","IEEE Conferences"
"Toward Scalable and Robust Indoor Tracking: Design, Implementation, and Evaluation","F. Jin; K. Liu; H. Zhang; J. K. -Y. Ng; S. Guo; V. C. S. Lee; S. H. Son","Key Laboratory of Dependable Service Computing in Cyber Physical Society, Ministry of Education, Chongqing University, Chongqing, China; Key Laboratory of Dependable Service Computing in Cyber Physical Society, Ministry of Education, Chongqing University, Chongqing, China; Key Laboratory of Dependable Service Computing in Cyber Physical Society, Ministry of Education, Chongqing University, Chongqing, China; Department of Computer Science, Hong Kong Baptist University, Hong Kong; Key Laboratory of Dependable Service Computing in Cyber Physical Society, Ministry of Education, Chongqing University, Chongqing, China; Department of Computer Science, City University of Hong Kong, Hong Kong; Department of Information and Communication Engineering, Daegu Gyeongbuk Institute of Science and Technology, Daegu, South Korea","IEEE Internet of Things Journal","11 Feb 2020","2020","7","2","1192","1204","Although indoor localization has been studied over a decade, it is still challenging to enable many IoT applications, such as activity tracking and monitoring in smart home and customer navigation and trajectory mining in smart shopping mall, which typically require meter-level localization accuracy in a highly dynamic and large-scale indoor environment. Therefore, this article aims at designing and implementing an adaptive and scalable indoor tracking system in a cost-effective way. First, we propose a zero site-survey overhead (ZSSO) algorithm to enhance the system scalability. It integrates the step information and map constraints to infer user's positions based on the particle filter and supports the auto labeling of scanned Wi-Fi signal for constructing the fingerprint database without the extra site-survey overhead. Further, we propose an iterative-weight-update (IWU) strategy for ZSSO to enhance system robustness and make it more adaptive to the dynamic changing of environments. Specifically, a two-step clustering mechanism is proposed to delete outliers in the fingerprint database and alleviate the mismatch between the auto-tagged coordinates and the corresponding signal features. Then, an iterative fingerprint update mechanism is designed to continuously evaluate the Wi-Fi fingerprint localization results during online tracking, which will further refine the fingerprint database. Finally, we implement the indoor tracking system in real-world environments and conduct a comprehensive performance evaluation. The field testing results conclusively demonstrate the scalability and effectiveness of the proposed algorithms.","2327-4662","","10.1109/JIOT.2019.2953376","National Natural Science Foundation of China(grant numbers:61872049,61572088); Fundamental Research Funds for the Central Universities(grant numbers:2018CDQYJSJ0034); Hong Kong Baptist University; Innovation and Technology Commission(grant numbers:ITP/048/14LP); Global Research Laboratory Program under through NRF(grant numbers:2013K1A1A2A02078326); ICT Research and development Program of MSIP/IITP (Resilient Cyber-Physical Systems Research)(grant numbers:2014-0-00065); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8897653","Algorithm design;indoor localization;performance evaluation;trajectory tracking;Wi-Fi fingerprint","Wireless fidelity;Databases;Indoor environment;Scalability;Internet of Things;Trajectory;Adaptive systems","","12","","30","IEEE","13 Nov 2019","","","IEEE","IEEE Journals"
"Understanding and Mitigating the Impact of Wi-Fi 6E Interference on Ultra-Wideband Communications and Ranging","H. Brunner; M. Stocker; M. Schuh; M. Schuß; C. A. Boano; K. Römer","Institute of Technical Informatics, Graz University of Technology, Austria; Institute of Technical Informatics, Graz University of Technology, Austria; Institute of Technical Informatics, Graz University of Technology, Austria; Institute of Technical Informatics, Graz University of Technology, Austria; Institute of Technical Informatics, Graz University of Technology, Austria; Institute of Technical Informatics, Graz University of Technology, Austria","2022 21st ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)","18 Jul 2022","2022","","","92","104","The introduction of the Wi-Fi 6E standard operating in the 6 GHz frequency band is a serious threat for IoT systems based on ultra-wideband technology, as they share portions of the same spectrum. Wi-Fi 6E devices can in fact support channel bandwidths up to 160 MHz and operate at a much higher transmission power compared to ultra-wideband devices, which may lead to severe coexitence issues and degraded performance. However, whether and to which extent the performance of ultra-wide band systems worsens due to Wi-Fi 6E interference has not been investigated in detail yet. In this paper, we fill this gap and study how Wi-Fi 6E traffic affects ultra-wideband performance. Our experiments on a large-scale testbed demonstrate that Wi-Fi 6E transmissions may largely disrupt ultra-wideband communications and decrease the accuracy as well as the precision of ranging measurements, with significant consequences on the efficiency of localization systems. We investigate in detail the root causes for the degraded performance and derive empirical observations that can be used to design countermeasures mitigating the impact of Wi-Fi 6E interference. These include, among others, an optimal selection of physical layer settings, as well as the use of a tight synchronization to prevent a false detection of Wi-Fi 6E traffic as ultra-wide band frames and an overshooting of the radio's automatic gain control. We further devise a technique to detect the presence of Wi-Fi 6E traffic and postpone ultra-wideband transmissions accordingly. Our experiments demonstrate that these countermeasures effectively mitigate the impact of Wi-Fi 6E interference on the performance of ultra-wide band systems.","","978-1-6654-9624-7","10.1109/IPSN54338.2022.00015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9826115","Coexistence;Communication;DW1000;Interference;Localization;Performance;Reliability;Testbeds;UWB;Wi-Fi;Wireless","Performance evaluation;Wireless communication;Wireless sensor networks;Interference;Physical layer;Distance measurement;Synchronization","","9","","70","IEEE","18 Jul 2022","","","IEEE","IEEE Conferences"
"Aggressive Design Reuse for Ubiquitous Zero-Trust Edge Security—From Physical Design to Machine-Learning-Based Hardware Patching","M. Alioto","ECE Department, National University of Singapore, Queenstown, Singapore","IEEE Open Journal of the Solid-State Circuits Society","7 Apr 2023","2023","3","","1","16","This work presents an overview of challenges and solid pathways toward ubiquitous and sustainable hardware security in next-generation silicon chips at the edge of distributed and connected systems (e.g., IoT and AIoT). As the first challenge, the increasingly connected nature and the exponential proliferation of edge devices are unabatingly increasing the overall attack surface, making attacks easier and mandating ubiquitous security down to each edge node. At the same time, the necessity to incorporate zero-trust policies in large-scale distributed systems requires a complete set of security primitives for hardware-backed authentication, and a higher degree of physical context awareness (including primitives detecting the onset of physical attacks). Thus, making the inclusion of such security primitives economically sustainable even in low-end devices is a second key challenge. As third challenge, the ever-changing vulnerability landscape and the need for increased chip longevity in distributed systems require security assurance methods that are sustainable and adaptive across the entire chip lifecycle. In this work, design principles and promising directions to enable ubiquitous and sustainable security capabilities along with physical awareness are discussed. Such achievements require a fundamental rethinking of design methodologies to enable aggressive design and resource reuse (e.g., area, power, and design effort), along with low-cost on-chip sensorization and intelligence for physical attack detection. Such rethinking inevitably crosses over the traditional design abstractions, and requires innovation from the physical to the algorithmic level. At the physical and circuit levels, design and resource reuse is enabled by immersed-in-logic and in-memory security approaches. At the algorithm level, “hardware patching” is introduced and exemplified to show that runtime intelligence (machine learning) allows security capabilities to adapt and improve over time, as typical of security patching in software. Sensing techniques to detect attacks in situ from noninvasive to invasive are illustrated while still preserving fully automated design approaches. Overall, the above design principles are expected to push security capabilities in distributed systems to a new level, ultimately making the edge more intelligent and self-reliant, and security measures more distributed.","2644-1349","","10.1109/OJSSCS.2022.3223274","Singapore National Research Foundation and the Cyber Security Agency through the “SOCure” Project(grant numbers:NRF2018NCR-NCR002-0001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9955388","Hardware patching;hardware security;in-memory security;laser attacks;machine learning;physically unclonable functions (PUFs);sensors;side-channel attacks;true random number generators (TRNGs);ubiquitous and sustainable security","Security;Costs;System-on-chip;Silicon;Image edge detection;Market research;Hardware security;Lasers;Physical unclonable function;Side-channel attacks;Random number generation;Sustainable development","","2","","117","CCBY","18 Nov 2022","","","IEEE","IEEE Journals"
"Toward Distributed, Global, Deep Learning Using IoT Devices","B. Sudharsan; P. Patel; J. Breslin; M. I. Ali; K. Mitra; S. Dustdar; O. Rana; P. P. Jayaraman; R. Ranjan","National University of Ireland Galway, Galway, Ireland; National University of Ireland Galway, Galway, Ireland; National University of Ireland Galway, Galway, Ireland; Dublin City University, Dublin 9, Ireland; Luleå University of Technology, Luleå, Sweden; TU Wien, Vienna, Austria; Cardiff University, Cardiff, U.K.; Swinburne University of Technology, Hawthorn, Australia; Newcastle University, Newcastle upon Tyne, U.K.","IEEE Internet Computing","20 Jul 2021","2021","25","3","6","12","Deep learning (DL) using large scale, high-quality IoT datasets can be computationally expensive. Utilizing such datasets to produce a problem-solving model within a reasonable time frame requires a scalable distributed training platform/system. We present a novel approach where to train one DL model on the hardware of thousands of mid-sized IoT devices across the world, rather than the use of GPU cluster available within a data center. We analyze the scalability and model convergence of the subsequently generated model, identify three bottlenecks that are: high computational operations, time consuming dataset loading I/O, and the slow exchange of model gradients. To highlight research challenges for globally distributed DL training and classification, we consider a case study from the video data processing domain. A need for a two-step deep compression method, which increases the training speed and scalability of DL training processing, is also outlined. Our initial experimental validation shows that the proposed method is able to improve the tolerance of the distributed training process to varying internet bandwidth, latency, and Quality of Service metrics.","1941-0131","","10.1109/MIC.2021.3053711","European Union's Horizon 2020 research and innovation program(grant numbers:847577); Science Foundation Ireland(grant numbers:SFI/16/RC/3918,SFI/12/RC/2289_P2); European Regional Development Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9491849","","Training data;Deep learning;Analytical models;Computational modeling;Scalability;Graphics processing units;Collaborative work;Internet of Things","","9","","14","CCBY","20 Jul 2021","","","IEEE","IEEE Magazines"
"VetIoT: On Vetting IoT Defenses Enforcing Policies at Runtime","A. J. Nafis; O. Chowdhury; E. Hoque","Syracuse University, NY, USA; Stony Brook University, NY, USA; Syracuse University, NY, USA","2023 IEEE Conference on Communications and Network Security (CNS)","27 Oct 2023","2023","","","1","9","Smart homes are powered by numerous programmable IoT platforms. Despite tremendous innovations, these platforms often suffer from safety and security issues. One class of defense solutions dynamically enforces safety and security policies, which essentially capture the expected behavior of the IoT system. While many proposed works were built on this runtime approach, they all are under-vetted. The primary reason lies in their evaluation approach. They are mostly self-evaluated in isolation using a virtual testbed combined with manually orchestrated test scenarios that rely on user interactions with the platform’s UI. Such hand-crafted and non-uniform evaluation setups are limiting not only the reproducibility but also a comparative analysis of their efficacy results. Closing this gap in the traditional way requires a huge upfront manual effort, which causes the researchers turn away from any large-scale comparative empirical evaluation. Therefore, in this paper, we propose a highly-automated uniform evaluation platform, dubbed VetIoT, to vet the defense solutions that hinge on runtime policy enforcement. Given a defense solution, VetIoT easily instantiates a virtual testbed inside which the solution is empirically evaluated. VetIoT replaces manual UI-based interactions with an automated event simulator and manual inspection of test outcomes with an automated comparator. We developed a fully-functional prototype of VetIoT and applied it on three runtime policy enforcement solutions: Expat, Patriot, and IoTguard. VetIoT reproduced their individual prior results and assessed their efficacy results via stress testing and differential testing. We believe VetIoT can foster future research/evaluation.","","979-8-3503-3945-1","10.1109/CNS59707.2023.10288667","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10288667","IoT Security;Testbed;Evaluation","Technological innovation;Runtime;Prototypes;Manuals;Smart homes;Network security;Reproducibility of results","","1","","33","IEEE","27 Oct 2023","","","IEEE","IEEE Conferences"
"SOChain: A Privacy-Preserving DDoS Data Exchange Service Over SOC Consortium Blockchain","L. -Y. Yeh; P. J. Lu; S. -H. Huang; J. -L. Huang","Department of Information Management, National Chi Nan University, Nantou, Taiwan; Information Technology Division, National Center for High-Performance Computing, Hsinchu City, Taiwan; Department of Computer Science, National Chiao Tung University, Hsinchu, Taiwan; Information Technology Division, National Center for High-Performance Computing, Hsinchu City, Taiwan","IEEE Transactions on Engineering Management","16 Oct 2020","2020","67","4","1487","1500","IoT devices provide a significant medium for distributed denial-of-service (DDoS) attacks. In 2016, a large-scale DDoS attack, named Dyn, caused massive damage to several well-known companies. One effective countermeasure is observing previous network traffic information or abnormal behavior determined by the host machines and determining the latest DDoS-attack IP addresses. Because of the lack of a fair exchange mechanism, most security operation centers (SOCs) are unwilling to share their real-time DDoS data. In this article, we propose a decentralized DDoS data exchange platform, namely SOChain, using blockchain technology to overcome the trust and fairness issues. The platform incentivizes SOCs through the DDoS_coin token. The more DDoS information an SOC contributes, the more coins it earns. To confirm the validity of uploaded information, we enlist a content verifier to examine uploaded abnormal IP addresses. Moreover, the verifier is incentivized by the DDoS_coin. To decrease the management effort, the entire flow is automatically executed in smart contract deployed onto the blockchain system. To address the issue of privacy in smart contracts, we devise a novel dual-level Bloom filter to enable efficient searches with privacy protection. Herein, a verifiable method is designed without revealing the information to public.","1558-0040","","10.1109/TEM.2020.2976113","National Science Council(grant numbers:108-2221-E-492-007-MY3,108-2218-E-009-049,108-2218-E-001-001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9040569","Blockchain;bloom filter;Diffie–Hellman key exchange;distributed denial of service (DDoS);incentive coin","Blockchain;Computer crime;Smart contracts;Denial-of-service attack;IP networks;Collaboration","","25","","32","IEEE","18 Mar 2020","","","IEEE","IEEE Journals"
"Impact Analysis of Data Clustering Techniques for Data-Based Topological Formation in WSNs","M. Lino; C. Montez; E. Leão; R. Lira","Automation and Systems Department (DAS), Federal University of Santa Catarina (UFSC), Florianópolis, Brazil; Automation and Systems Department (DAS), Federal University of Santa Catarina (UFSC), Florianópolis, Brazil; Department of Computing (DC), Federal University of Piaui (UFPI), Teresina, Brazil; Department of Computing (DC), Federal University of Piaui (UFPI), Teresina, Brazil","2022 IEEE 20th International Conference on Industrial Informatics (INDIN)","15 Dec 2022","2022","","","636","641","Leveraged by IoT and Industry 4.0 solutions, Wireless Sensor Networks (WSNs) have been proposed as an important alternative for large-scale monitoring applications. Such technology provides sensor nodes with the intelligent and autonomous ability to monitor large areas, create self-organizing structures, detect events and process massive data. In this context, data-driven schemes are increasingly needed. For this, some data clustering techniques (DCTs) are used to tackle common problems in WSNs; however, the vast majority of techniques do not consider the data monitored by the sensors to perform topological changes and provide better network structures. This work addresses an architecture for this type of application and evaluates the impact of different DCTs on network performance and the creation of priority node groups.","","978-1-7281-7568-3","10.1109/INDIN51773.2022.9976088","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9976088","cluster-tree;data-based WSNs;clustering","Measurement;Wireless sensor networks;Clustering algorithms;Quality of service;Topology;Fourth Industrial Revolution;Delays","","","","14","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"Reinforcement Learning Framework for Server Placement and Workload Allocation in Multiaccess Edge Computing","A. Mazloomi; H. Sami; J. Bentahar; H. Otrok; A. Mourad","Concordia Institute for Information Systems Engineering, Concordia University, Montreal, QC, Canada; Concordia Institute for Information Systems Engineering, Concordia University, Montreal, QC, Canada; Concordia Institute for Information Systems Engineering, Concordia University, Montreal, QC, Canada; Department of Electrical Engineering and Computer Science, Center of Cyber-Physical Systems, Khalifa University, Abu Dhabi, UAE; Department of CSM, Cyber Security Systems and Applied AI Research Center, Lebanese American University Division of Science, Lebanese American University, Beirut, Lebanon","IEEE Internet of Things Journal","5 Jan 2023","2023","10","2","1376","1390","Cloud computing is a reliable solution to provide distributed computation power. However, real-time response is still challenging regarding the enormous amount of data generated by the IoT devices in 5G and 6G networks. Thus, multiaccess edge computing (MEC), which consists of distributing the edge servers in the proximity of end users to have low latency besides the higher processing power, is increasingly becoming a vital factor for the success of modern applications. This article addresses the problem of minimizing both, the network delay, which is the main objective of MEC, and the number of edge servers to provide a MEC design with minimum cost. This MEC design consists of edge servers placement and base stations allocation, which makes it a joint combinatorial optimization problem (COP). Recently, reinforcement learning (RL) has shown promising results for COPs. However, modeling real-world problems using RL when the state and action spaces are large still needs investigation. We propose a novel RL framework with an efficient representation and modeling of the state space, action space, and the penalty function in the design of the underlying Markov decision process (MDP) for solving our problem. This modeling makes the temporal difference (TD) learning applicable for a large-scale real-world problem while minimizing the cost of network design. We introduce the TD $(\lambda)$  with eligibility traces for minimizing the cost (TDMC) algorithm, in addition to  $Q$ -learning for the same problem (QMC) when  $\lambda =0$ . Furthermore, we discuss the impact of state representation, action space, and penalty function on the convergence of each model. Extensive experiments using real-world data sets from Shanghai Telecommunication and Citywide Public Computer Centers demonstrate that in the light of an efficient model, TDMC/QMC are able to find the actions that are the source of lower delayed penalty. The reported results show that our algorithm outperforms the other benchmarks by creating a tradeoff among multiple objectives.","2327-4662","","10.1109/JIOT.2022.3205051","FRQNT, Quebec; NSERC and DnD, Canada; FRQNT, Quebec; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9881565","Base station allocation;edge server placement;multiaccess edge computing (MEC);Q-learning;reinforcement learning (RL);TD(λ)","Servers;Delays;Q-learning;Cloud computing;Base stations;Resource management;Internet of Things","","11","","44","IEEE","8 Sep 2022","","","IEEE","IEEE Journals"
"Towards precision agriculture in Morocco: A machine learning approach for recommending crops and forecasting weather","C. El Hachimi; S. Belaqziz; S. Khabba; A. Chehbouni","Center for Remote Sensing Applications (CRSA), Mohammed VI Polytechnic University (UM6P), Benguerir, Morocco; Department of Computer Science, LabSIV Laboratory, Faculty of Science, UIZ University, Agadir, Morocco; Department of Physics, LMFE, Faculty of Sciences Semlalia, Cadi Ayyad University, Marrakesh, Morocco; Center for Remote Sensing Applications (CRSA), Mohammed VI Polytechnic University (UM6P), Benguerir, Morocco","2021 International Conference on Digital Age & Technological Advances for Sustainable Development (ICDATA)","9 Nov 2021","2021","","","88","95","Statistical models predict that the world's population will reach 8.5 billion by the end of 2030. This represents a real threat to our food security and puts the current food production system under pressure. Efficient use of Earth's natural resources is the only solution to facing future challenges such as global hunger. The implementation of precision agriculture using new technologies such as artificial intelligence, big data, IoT and remote sensing is the first step towards this goal. In this paper, we investigated several machine learning models to create two services: one for recommending the best crop to grow based on soil and the region's weather characteristics, and another for the forecasting of the hourly average air temperature. Performance evaluation results for the first service show that Random Forest has the best metrics as a classifier (accuracy = 100%, precision = 100%, recall = 100%) compared to K-Nearest Neighbors (KNN), Decision Tree, Naive Bayes, Logistic Regression, Convolutional Neural Network, and Feed Forward Neural Network. This is a confirmation that classic machine learning algorithms perform better on small-size datasets. In our case, we used a dataset of 2200 instances available online. On the other hand, Facebook Prophet was more accurate (R2 = 0.81, RMSE = 3.74) than our proposed LSTM architecture in time series forecasting at hourly scale using historical weather data provided by the weather station of our study area. These two optimal models are then integrated as the first building blocks in our decision support platform, intended for both farmers and policymakers with the aim of making agriculture in Morocco more efficient and more sustainable.","","978-1-6654-2901-6","10.1109/ICDATA52997.2021.00026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9588245","Precision Agriculture;Smart Agriculture;Agricultural Decision Support Systems;Machine Learning;Deep Learning;Weather forecasting;LSTM;Facebook Prophet","Social networking (online);Time series analysis;Crops;Weather forecasting;Predictive models;Soil;Agriculture","","9","","28","IEEE","9 Nov 2021","","","IEEE","IEEE Conferences"
"Decentralized Wireless Federated Learning With Differential Privacy","S. Chen; D. Yu; Y. Zou; J. Yu; X. Cheng","School of Computer Science and Technology, Shandong University, Qingdao, China; School of Computer Science and Technology, Shandong University, Qingdao, China; School of Computer Science and Technology, Shandong University, Qingdao, China; School of Computer Science and Technology, Qilu University of Technology (Shandong Academy of Science), Jinan, China; School of Computer Science and Technology, Shandong University, Qingdao, China","IEEE Transactions on Industrial Informatics","14 Jun 2022","2022","18","9","6273","6282","This article studies decentralized federated learning algorithms in wireless IoT networks. The traditional parameter server architecture for federated learning faces some problems such as low fault tolerance, large communication overhead and inaccessibility of private data. To solve these problems, we propose a decentralized wireless federated learning algorithm called DWFL. The algorithm works in a system where the workers are organized in a peer-to-peer and server-less manner, and the workers exchange their privacy preserving data with the analog transmission scheme over wireless channels in parallel. With rigorous analysis, we show that DWFL satisfies $(\epsilon,\delta)$-differential privacy and the privacy budget per worker scales as $\mathcal {O}(\frac{1}{\sqrt{N}})$, in contrast with the constant budget in the orthogonal transmission approach. Furthermore, DWFL converges at the same rate of $\mathcal {O}(\sqrt{\frac{1}{TN}})$ as the best known centralized algorithm with a central parameter server. Extensive experiments demonstrate that our algorithm DWFL also performs well in real settings.","1941-0050","","10.1109/TII.2022.3145010","National Key R&D Program of China(grant numbers:2019YFB2102600); National Natural Science Foundation of China(grant numbers:62122042,61832012); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9693141","Decentralized learning;differential privacy;federated learning (FL);IoT system","Wireless communication;Collaborative work;Privacy;Differential privacy;Wireless sensor networks;Communication system security;Bandwidth","","20","","26","IEEE","25 Jan 2022","","","IEEE","IEEE Journals"
"The Frontiers of Deep Reinforcement Learning for Resource Management in Future Wireless HetNets: Techniques, Challenges, and Research Directions","A. Alwarafy; M. Abdallah; B. S. Çiftler; A. Al-Fuqaha; M. Hamdi","Division of Information and Computing Technology, College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar; Division of Information and Computing Technology, College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar; Division of Information and Computing Technology, College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar; Division of Information and Computing Technology, College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar; Division of Information and Computing Technology, College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar","IEEE Open Journal of the Communications Society","3 Mar 2022","2022","3","","322","365","Next generation wireless networks are expected to be extremely complex due to their massive heterogeneity in terms of the types of network architectures they incorporate, the types and numbers of smart IoT devices they serve, and the types of emerging applications they support. In such large-scale and heterogeneous networks (HetNets), radio resource allocation and management (RRAM) becomes one of the major challenges encountered during system design and deployment. In this context, emerging Deep Reinforcement Learning (DRL) techniques are expected to be one of the main enabling technologies to address the RRAM in future wireless HetNets. In this paper, we conduct a systematic in-depth, and comprehensive survey of the applications of DRL techniques in RRAM for next generation wireless networks. Towards this, we first overview the existing traditional RRAM methods and identify their limitations that motivate the use of DRL techniques in RRAM. Then, we provide a comprehensive review of the most widely used DRL algorithms to address RRAM problems, including the value- and policy-based algorithms. The advantages, limitations, and use-cases for each algorithm are provided. We then conduct a comprehensive and in-depth literature review and classify existing related works based on both the radio resources they are addressing and the type of wireless networks they are investigating. To this end, we carefully identify the types of DRL algorithms utilized in each related work, the elements of these algorithms, and the main findings of each related work. Finally, we highlight important open challenges and provide insights into several future research directions in the context of DRL-based RRAM. This survey is intentionally designed to guide and stimulate more research endeavors towards building efficient and fine-grained DRL-based RRAM schemes for future wireless networks.","2644-125X","","10.1109/OJCOMS.2022.3153226","NPRP-Standard (NPRP-S) Thirteen (13th) Cycle from the Qatar National Research Fund (a member of Qatar Foundation)(grant numbers:NPRP13S-0201-200219); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9718516","Radio resource allocation and management;deep reinforcement learning;next generation wireless networks;HetNets;power;bandwidth;rate;access control","Wireless communication;Wireless networks;Optimization;Resource management;Quality of service;Next generation networking;Reinforcement learning","","19","","223","CCBY","23 Feb 2022","","","IEEE","IEEE Journals"
"Using the Compute Continuum for Data Analysis: Edge-cloud Integration for Urban Mobility","L. Belcastro; F. Marozzo; A. Orsino; D. Talia; P. Trunfio","University of Calabria, Rende, Italy; University of Calabria, Rende, Italy; University of Calabria, Rende, Italy; University of Calabria, Rende, Italy; University of Calabria, Rende, Italy","2023 31st Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP)","1 Jun 2023","2023","","","338","344","More and more in recent years, IT companies have adopted edge-cloud continuum solutions to efficiently perform analysis tasks on data generated by IoT devices. As an example, in the context of urban mobility, the use of edge solutions can be extremely effective in managing tasks that require real-time analysis and low response times, such as driver assistance, collision avoidance and traffic sign recognition. On the other hand, the integration with cloud systems can be convenient for tasks that require a lot of computing resources for accessing and analyzing big data collections, such as route calculations and targeted advertising. Designing and testing such hybrid edge-cloud architectures are still open issues due to their novelty, large scale, heterogeneity, and complexity. In this paper, we analyze how the compute continuum can be exploited for efficiently managing urban mobility tasks. In particular, we focus on a case study related to taxi fleets that need to find locations where they are more likely to find new passengers. Through a simulation-based approach, we demonstrate that these solutions turn out to be effective for this class of problems, especially as the number of connected vehicles increases.","2377-5750","979-8-3503-3763-1","10.1109/PDP59025.2023.00058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10136967","Edge-cloud architecture;IoT infrastructure;Edge computing;Urban computing;Smart cities;Urban mobility","Processor scheduling;Computer architecture;Reinforcement learning;Software;Real-time systems;Internet of Things;Time factors","","","","31","IEEE","1 Jun 2023","","","IEEE","IEEE Conferences"
"A Behavioral Model of Digital Resistive Switching for Systems Level DNN Acceleration","J. K. Eshraghian; Q. Lin; X. Wang; H. H. C. Iu; Q. Hu; H. Tong","Department of Electrical Engineering and Computer Science, University of Michigan at Ann Arbor, Ann Arbor, USA; School of Optical and Electronic Information, Wuhan National Laboratory for Optoelectronics, Huazhong University of Science and Technology, Wuhan, China; School of Electronics and Information, Hangzhou Dianzi University, Hangzhou, China; School of Electrical, Electronic and Computer Engineering, University of Western Australia, Perth, Australia; School of Optical and Electronic Information, Wuhan National Laboratory for Optoelectronics, Huazhong University of Science and Technology, Wuhan, China; School of Optical and Electronic Information, Wuhan National Laboratory for Optoelectronics, Huazhong University of Science and Technology, Wuhan, China","IEEE Transactions on Circuits and Systems II: Express Briefs","30 Apr 2020","2020","67","5","956","960","The deployment of IoT has brought on the generation of massive amounts of data in need of analysis. In recent times, resistive switching-based crossbar arrays have been presented as a viable candidate for the acceleration of neural network inference, in pushing beyond the limit of CMOS process scaling so as to keep pace with the ever-growing complexity of computation. While plenty of empirical and physically descriptive models exist, their simulation run times become inconvenient for users when used in large scale crossbar arrays. In this brief, we first present a behavioral model of digital resistive switching devices, demonstrated on experimental PCM data to exhibit generality which can see useful implementation in circuit analysis methods for compute-in-memory applications. This model is based on a pair of nonlinear ordinary differential equations that request switching time and threshold voltage inputs from the user, which are the most important concerns for binarized weights in crossbar arrays. By stripping the model of detailed physical characteristics that is not required at the systems level, we demonstrate an improvement of computational run time of up to 20-fold over state-of-the-art physics-based models, and 1.3 times over the most commonly used empirically driven models.","1558-3791","","10.1109/TCSII.2020.2979847","iDataMap Corporation; Endeavour Research Leadership Award from the Australian Government; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9031725","Behavioral model;crossbar;neural network;memristor;RRAM","Computational modeling;Switches;Mathematical model;Integrated circuit modeling;Phase change materials;Data models;Switching circuits","","11","","25","IEEE","10 Mar 2020","","","IEEE","IEEE Journals"
"A Communication-Efficient Federated Learning Scheme for IoT-Based Traffic Forecasting","C. Zhang; L. Cui; S. Yu; J. J. Q. Yu","Department of Computer Science and Engineering, Guangdong Provincial Key Laboratory of Brain-inspired Intelligent Computation, Southern University of Science and Technology, Shenzhen, China; Faculty of Engineering and Information Technology, University of Technology Sydney, Sydney, NSW, Australia; Faculty of Engineering and Information Technology, University of Technology Sydney, Sydney, NSW, Australia; Department of Computer Science and Engineering, Guangdong Provincial Key Laboratory of Brain-inspired Intelligent Computation, Southern University of Science and Technology, Shenzhen, China","IEEE Internet of Things Journal","6 Jul 2022","2022","9","14","11918","11931","Federated learning (FL) is widely adopted in traffic forecasting tasks involving large-scale IoT-enabled sensor data since its decentralization nature enables data providers’ privacy to be preserved. When employing state-of-the-art deep learning-based traffic predictors in FL systems, the existing FL frameworks confront overlarge communication overhead when transmitting these models’ parameter updates since the modeling depth and breadth renders them incorporating an enormous number of parameters. In this article, we propose a practical FL scheme, namely, Clustering-based hierarchical and Two-step-optimized FL (CTFed), to tackle this issue. The proposed scheme follows a divide et impera strategy that clusters the clients into multiple groups based on the similarity between their local models’ parameters. We integrate the particle swarm optimization algorithm and devises a two-step approach for local model optimization. This scheme enables only one but representative local model update from each cluster to be uploaded to the central server, thus reduces the communication overhead of the model updates transmission in FL. CTFed is orthogonal to the gradient compression- or sparsification-based approaches so that they can orchestrate to optimize the communication overhead. Extensive case studies on three real-world data sets and three state-of-the-art models demonstrate the outstanding training efficiency, accurate prediction performance, and robustness to unstable network environments of the proposed scheme.","2327-4662","","10.1109/JIOT.2021.3132363","Stable Support Plan Program of Shenzhen Natural Science Fund(grant numbers:20200925155105002); General Program of Guangdong Basic and Applied Basic Research Foundation(grant numbers:2019A1515011032); Guangdong Provincial Key Laboratory of Brain-inspired Intelligent Computation(grant numbers:2020B121201001); Australia ARC(grant numbers:DP200101374,LP190100676); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9634121","Communication efficiency;federated learning (FL);graph neural networks (GNNs);industrial IoT;traffic forecasting","Forecasting;Predictive models;Training;Servers;Data models;Organizations;Convolutional neural networks","","12","","53","IEEE","3 Dec 2021","","","IEEE","IEEE Journals"
"Optimal RUL Estimation: A State-of-Art Digital Twin Application","M. D. Anis; S. Taghipour; C. -G. Lee",University of Toronto; Ryerson University; University of Toronto,"2020 Annual Reliability and Maintainability Symposium (RAMS)","31 Jul 2020","2020","","","1","7","A real world Industrial IoT set up has paved way for simultaneous monitoring of several sensors at their unique sampling rates. This has realized the need for artificial intelligence tools for robust data processing. However, the large size of input data requires real time monitoring and synchronization for online analysis. As the star concept behind the Industry 4.0 wave, a digital twin is a virtual, multi-scale and probabilistic simulation to mirror the performance of its physical counterpart and serve the product lifecycle in a virtual space. Evidently, a digital twin can proactively identify potential issues with its corresponding real twin. Thus, it is best suited for enabling a physics-based and data-driven model fusion to estimate the remaining useful life (RUL) of the components. Traditional RUL prediction approaches have assumed either an exponential or linear degradation trend with a fixed curve shape to build a Health Index (HI) model. Such an assumption may not be useful for multi-sensor systems or cases where sensor data is available intermittently. A common constraint in the industry is irregular sensor data collection. The resulting asynchronous time series of the sporadic data needs to be an accurate representation of the component's HI when constructing a degradation model. In this paper, we extend the Long-Short Term Memory (LSTM) Recurrent Neural Network (RNN) technique to generate RUL prediction within a digital twin framework as a means of synchronization with changing operational states. More specifically, we first use LSTM encoder-decoder (LSTM-ED) to train a multilayered neural network and reconstruct the sensor data time series corresponding to a healthy state. The resulting reconstruction error can be used to capture patterns in input data time series and estimate HI of training and testing sets. Using a time lag to record similarity between the HI curves, a weighted average of the final RUL estimation is obtained. The described empirical approach is evaluated on publicly available engine degradation dataset with run-to-failure information. Results indicate a high RUL estimation accuracy with greater error reduction rate. This demonstrates wide applicability of the discussed methodology to various industries where event data is scarce for the application of only data-driven techniques.","2577-0993","978-1-7281-3690-5","10.1109/RAMS48030.2020.9153669","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9153669","Prognostics;RUL Estimation;Deep Learning;Long-short Term Memory;IIoT;Autoencoder","Time series analysis;Computer architecture;Microprocessors;Sensors;Mathematical model;Degradation;Logic gates","","5","","11","IEEE","31 Jul 2020","","","IEEE","IEEE Conferences"
"HGO: Hierarchical Graph Optimization for Accurate, Efficient, and Robust Network Localization","H. Ping; Y. Wang; D. Li","Department of Computer Sciences, Renmin University of China, Beijing, P.R.China; Department of Computer Sciences, Renmin University of China, Beijing, P.R.China; Department of Computer Sciences, Renmin University of China, Beijing, P.R.China","2020 29th International Conference on Computer Communications and Networks (ICCCN)","30 Sep 2020","2020","","","1","9","Inferring nodes' locations by inter-node measurements is a crucial problem in the IoT era. Despite the various approaches to this problem, obtaining accurate results is still challenging when the measurements are noisy, sparse, or uneven. Such unsatisfactory measurements are, however, inevitable for the general consideration of the deployment cost and the limited sensing scope.This paper proposes a Hierarchical Graph Optimization (HGO) framework to address the network localization problem when the measurements are sparse and noisy. It firstly efficiently extracts the dense sub-graphs and realizes their local structures in local coordinate systems. The local structures of dense components are rather accurate for the local sufficiency of the measurements. Then, the noises of the inter-edges that sparsely connect the dense sub-graphs are found as the main course of the network localization errors. A close-loop condition is derived and two denoising algorithms are proposed to set up linear equation arrays to correct the noises of these critical edges. After that, a projection algorithm is proposed to realize a smoothed backbone graph using the corrected critical edges, and finally, a hierarchical registration method is proposed to register the realized backbone and the dense sub-components to produce the global network structure. A parallel implementation is further developed, which speeds up HGO in large scale networks. Extensive simulations verify that HGO consistently outperforms existing network localization algorithms in terms of accuracy, efficiency, and reliability under various measurement settings.","2637-9430","978-1-7281-6607-0","10.1109/ICCCN49398.2020.9209620","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9209620","Hierarchical Graph Optimization;Structure Aware;Component Stitching;Sparse and Noise Networks;Close-loop Condition;Critical Edges","Optimization;Noise measurement;Image edge detection;Robustness;Distance measurement;Estimation;Smoothing methods","","3","","42","IEEE","30 Sep 2020","","","IEEE","IEEE Conferences"
"Edge-Cloud Offloading: Knapsack Potential Game in 5G Multi-Access Edge Computing","C. -Y. Hsieh; Y. Ren; J. -C. Chen","Department of Computer Science, National Yang Ming Chiao Tung University (NYCU), Hsinchu, Taiwan; School of Computing Science, University of East Anglia (UEA), Norwich, U.K; Department of Computer Science, National Yang Ming Chiao Tung University (NYCU), Hsinchu, Taiwan","IEEE Transactions on Wireless Communications","10 Nov 2023","2023","22","11","7158","7171","In 5G, multi-access edge computing enables the applications to be offloaded to near-end edge servers for faster response. According to the 3GPP standards, users in 5G are separated into many types, e.g., vehicles, AR/VR, IoT devices, etc. Specifically, the high-priority traffic can preempt edge resources to guarantee the service quality. However, even if a traffic is transmitted with low priority, its latency requirement in 5G is much lower than that in 4G. Too strict latency requirement and priority-based service make resource configuration difficult on the edge side. Therefore, we propose the edge-cloud offloading mechanism, in which each edge server can offload tasks to back-end cloud server to ensure service quality of both high- and low-priority traffic. In this paper, we establish a priority-based queuing system to model the edge-cloud offloading behaviors. Based on the formulation of our system model, we propose Knapsack Potential Game (KPG) to derive an optimal offloading ratio for each edge server to balance the cost-effectiveness of the overall system. We demonstrate that KPG has low computational complexity and outperforms two baseline algorithms. The results indicate that KPG’s performance is optimal and provides a theoretical guideline to operators while designing their edge-cloud offloading strategies without large-scale implementation.","1558-2248","","10.1109/TWC.2023.3248270","Engineering and Physical Sciences Research Council (EPSRC)(grant numbers:EP/T022566/1,EP/T024593/1); Royal Society(grant numbers:IEC\R3\213100); National Science and Technology Council(grant numbers:111-2221-E-A49-093-MY3,111-2218-E-A49-023,111-3114-E-A49-001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10057219","Multi-access edge computing;QoS;5G;performance analysis;3GPP standards","Quality of service;Servers;5G mobile communication;Wireless communication;Resource management;Costs;Time factors","","2","","36","IEEE","1 Mar 2023","","","IEEE","IEEE Journals"
"A Comprehensive Plant Health Monitoring System with IoT and Deep Learning","S. Bhattacharya; A. S. Bagmar; K. E","School of Electronics Engineering, Vellore Institute of Technology, Vellore, India; School of Electronics Engineering, Vellore Institute of Technology, Vellore, India; School of Electronics Engineering, Vellore Institute of Technology, Vellore, India","2023 International Conference on Next Generation Electronics (NEleX)","16 Feb 2024","2023","","","1","6","Ensuring optimal crop yield and quality relies heavily on the efficient monitoring of plant health. To address the challenges associated with physically monitoring plant well-being, we introduce a system designed to compute an overall plant health score and present it visually. This system leverages an IoT cloud platform to relay the plant's health parameters to users. Should the plant's health deteriorate, users will receive email notifications regarding its current condition. Furthermore, we intend to incorporate a deep learning algorithm capable of predicting plant diseases. This algorithm will undergo training on extensive publicly available datasets, enabling it to detect plant diseases on a larger scale. Our proposed system presents a holistic solution for streamlined plant health monitoring, disease detection, and user communication. It holds the potential to transform the approach to plant health monitoring, leading to enhancements in crop yield and quality.","","979-8-3503-1908-8","10.1109/NEleX59773.2023.10421592","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10421592","Plant Health Monitoring;IoT Cloud Platform;Crop Yield Enhancement;Disease Detection;Deep Learning Algorithm;Agricultural Innovation","Deep learning;Training;Plant diseases;Communication systems;Transforms;Prediction algorithms;Monitoring","","","","19","IEEE","16 Feb 2024","","","IEEE","IEEE Conferences"
"Smart Fiber-Optic Distributed Acoustic Sensing (sDAS) With Multitask Learning for Time-Efficient Ground Listening Applications","H. Wu; Y. Wang; X. Liu; Y. Sun; G. Yan; Y. Wu; Y. Rao","Key Laboratory of Optical Fiber Sensing and Communications (Ministry of Education), School of Information and Communication Engineering,, University of Electronic Science and Technology of China, Chengdu, China; Key Laboratory of Optical Fiber Sensing and Communications (Ministry of Education), School of Information and Communication Engineering,, University of Electronic Science and Technology of China, Chengdu, China; Key Laboratory of Optical Fiber Sensing and Communications (Ministry of Education), School of Information and Communication Engineering,, University of Electronic Science and Technology of China, Chengdu, China; Key Laboratory of Optical Fiber Sensing and Communications (Ministry of Education), School of Information and Communication Engineering,, University of Electronic Science and Technology of China, Chengdu, China; Fiber Optic Sensing Research Center, Zhejiang Laboratory, Hangzhou, China; Key Laboratory of Optical Fiber Sensing and Communications (Ministry of Education), School of Information and Communication Engineering,, University of Electronic Science and Technology of China, Chengdu, China; Key Laboratory of Optical Fiber Sensing and Communications (Ministry of Education), School of Information and Communication Engineering,, University of Electronic Science and Technology of China, Chengdu, China","IEEE Internet of Things Journal","21 Feb 2024","2024","11","5","8511","8525","In recent years, fiber-optical distributed acoustic sensing (DAS) has been applied to various large-scale infrastructure monitoring areas in smart cities, leading to a new generation of fiber-optic IoT for ground listening. However, its single-task-focused postprocessing methods cannot achieve real-time efficient ground event recognition and localization concurrently. In this article, a two-level multitask learning (MTL) enhanced smart fiber-optical DAS (sDAS) system is proposed, for the first time, to simultaneously realize ground event recognition and localization. Performances and efficiency of both tasks are significantly improved by sharing knowledge across them. Besides, the imbalanced incremental learning ability for new events is also enhanced in the proposed MTL network. The total computation time for the two tasks is greatly shortened to 0.3 ms for a spatial-temporal sample with 129-m fiber length and 5-s time frame, which equals to a processing time of 0.04 s over a total fiber length of 18.7-km with a spatial sampling interval of 1.29 m, and is even better than the fastest single recognition reported to date. In the field test, such an MTL-enhanced sDAS system indicates excellent feature extraction performance with classification accuracy of up to 99.46% for five events and location error of ±1 m for two core-events at 8/16 different radial distances, which are much better than the DAS systems with multiclassifier and the combined single-task learning methods. Also, the MTL-enhanced sDAS shows strong robustness against environmental noises. Hence, it provides a breakthrough technology for time-efficient multitask processing in smart distributed sensors.","2327-4662","","10.1109/JIOT.2023.3320149","Natural Science Foundation of China(grant numbers:U21A20453,41527805,61290312); Natural Science Foundation of Sichuan Province(grant numbers:2023NSFSC0382); Program for Changjiang Scholars and Innovative Research Team in University (PCSIRT)(grant numbers:IRT1218); 111 Project(grant numbers:B14039); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10266693","Fiber-optic Internet of Things (IoT);real-time multitask processing;smart fiber-optic distributed acoustic sensing (sDAS);synchronous event recognition and localization","Optical fiber networks;Task analysis;Sensors;Optical fiber sensors;Optical fiber cables;Multitasking;Location awareness","","","","59","IEEE","28 Sep 2023","","","IEEE","IEEE Journals"
"The Last Mile of M-Connected-Healthcare in the Covid Age: Data Sharing at Large Scale","A. Faro; D. Giordano; M. Venticinque","Innovative Start-up DeepSensing srl, Catania, Italy; Dept. of Electrical, Electronics and Computer Eng., Univ. of. Catania, Italy; Ist. per i Sistemi Agricoli e FOrestali del Mediterraneo (ISAFOM) CNR, Catania, Italy","2020 IEEE International Conference on Internet of Things and Intelligence System (IoTaIS)","23 Feb 2021","2021","","","149","154","Aim of the paper is to illustrate a platform for that supports the link between the patient and doctors, family members, clinical laboratories and hospitals, that is a platform that supports the last mile between patients and the entire healthcare network so that the personal data collected by edge devices don't remain confined locally at the patient side but are shared at large scale to aid the patients anywhere and anytime. In particular the paper illustrates from the engineering point of view how implementing the last mile for Covid monitoring and control in practice by means of available Cyber Physical Systems (CPSs), i.e., edge IoT devices provided with communication and computational functions, freeware home control systems and low cost relevant web services available on the market. The key element of our proposal is the one of using a portable BLE/MQTT gateway or to develop DIY MQTT sensors to allow health measurements taken by edge devices to be sent to a remote automated control system supervised by a doctor. A detailed analysis is carried out on the contact and contactless sensors that can be integrated in our platform from the more and more diffused smart bands and ibeacons until the IR thermal cameras. For each considered sensor, the paper discusses its integration it in the platform and the global scenario in which it may be used effectively.","","978-1-7281-9448-6","10.1109/IoTaIS50849.2021.9359706","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9359706","Cyber Physical Systems;M-Connected-Healthcare;Covid-19;Ubiquitous and Pervasive Systems","COVID-19;Web services;Thermal sensors;Control systems;Sensor systems;Thermal analysis;Intelligent sensors","","","","18","IEEE","23 Feb 2021","","","IEEE","IEEE Conferences"
"Automatic Operator Performance Tumng in a Machine Learning System on Edge","P. Xu; X. Chang; J. Zhao; C. H. Liu","School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China","2022 IEEE 28th International Conference on Parallel and Distributed Systems (ICPADS)","27 Mar 2023","2023","","","802","809","With the current large scale deployment of machine learning technologies, such as those on cloud servers and edge and IoT hardwares, machine learning systems have been widely prevalence. Practical requirement has driven their performance increase in both academia and industry. However, the application requirement varies greatly across different applications, and directly using off-the-shelf systems might not be sufficient in many cases. In this work, we first propose to implement a series of techniques to optimize performance of convolution operation, one of the most important operations, in constructing deep learning networks. Besides, we also propose to apply the automated empirical optimisation of software approach to improve the performance of operators in machine learning system, most notably across various hardware platforms. Evaluation compared to existing libraries on different hardware devices has proved the efficiency of our proposed method.","2690-5965","978-1-6654-7315-6","10.1109/ICPADS56603.2022.00109","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10078003","optimization;automatic tuning;convolution;machine learning system","Performance evaluation;Deep learning;Convolution;Memory management;Libraries;Hardware;Software","","","","33","IEEE","27 Mar 2023","","","IEEE","IEEE Conferences"
"Fast Prototyping of Distributed Stream Processing Applications with stream2gym","M. M. Amin Ifath; M. Neves; I. Haque",Dalhousie University; Dalhousie University; Dalhousie University,"2023 IEEE 43rd International Conference on Distributed Computing Systems (ICDCS)","11 Oct 2023","2023","","","395","405","Stream processing applications have been widely adopted due to real-time data analytics demands, e.g., fraud detection, video analytics, IoT applications. Unfortunately, prototyping and testing these applications is still a cumbersome process for developers that usually requires an expensive testbed and deep multi-disciplinary expertise, including in areas such as networking, distributed systems, and data engineering. As a result, it takes a long time to deploy stream processing applications into production and yet users face several correctness and performance issues. In this paper, we present stream2gym, a tool for the fast prototyping of large-scale distributed stream processing applications. stream2gym builds on Mininet, a widely adopted network emulation platform, and provides a high-level interface to enable developers to easily test their applications under various operating conditions. We demonstrate the benefits of stream2gym by prototyping and testing several applications as well as reproducing key findings from prior research work in video analytics and network traffic monitoring. Moreover, we show stream2gym presents accurate results compared to a hardware testbed while consuming a small amount of resources (enough to be supported in a single commodity laptop even when emulating a dozen of processing nodes).","2575-8411","979-8-3503-3986-4","10.1109/ICDCS57875.2023.00034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10272479","","Portable computers;Visual analytics;Emulation;Telecommunication traffic;Production;Hardware;Reproducibility of results","","","","61","IEEE","11 Oct 2023","","","IEEE","IEEE Conferences"
"Blockchain Technology in Current Agricultural Systems: From Techniques to Applications","W. Lin; X. Huang; H. Fang; V. Wang; Y. Hua; J. Wang; H. Yin; D. Yi; L. Yau","Institute of Agricultural Economics and Rural Development, Guangzhou, China; Institute of Agricultural Economics and Rural Development, Guangzhou, China; Computer Science Department, Loughborough University, Loughborough, U.K; Institute for Criminal Justice Studies, University of Portsmouth, Portsmouth, U.K; Computer Science Department, Loughborough University, Loughborough, U.K; Institute of Agricultural Economics and Rural Development, Guangzhou, China; SAP China, Shanghai, China; Department of Computing Science, University of Aberdeen, Aberdeen, U.K; Asia Pacific Applied Nano Technology Research Centre, Hong Kong","IEEE Access","13 Aug 2020","2020","8","","143920","143937","Increasingly, blockchain technology is attracting significant attentions in various agricultural applications. These applications could satisfy the diverse needs in the ecosystem of agricultural products, e.g., increasing transparency of food safety and IoT based food quality control, provenance traceability, improvement of contract exchanges, and transactions efficiency. As multiple untrusted parties, including small-scale farmers, food processors, logistic companies, distributors and retailers, are involved into the complex farm-to-fork pipeline, it becomes vital to achieve optimal trade-off between efficiency and integrity of the agricultural management systems as required in contexts. In this paper, we provide a survey to study both techniques and applications of blockchain technology used in the agricultural sector. First, the technical elements, including data structure, cryptographic methods, and consensus mechanisms are explained in detail. Secondly, the existing agricultural blockchain applications are categorized and reviewed to demonstrate the use of the blockchain techniques. In addition, the popular platforms and smart contract are provided to show how practitioners use them to develop these agricultural applications. Thirdly, we identify the key challenges in many prospective agricultural systems, and discuss the efforts and potential solutions to tackle these problems. Further, we conduct an improved food supply chain in the post COVID-19 pandemic economy as an illustration to demonstrate an effective use of blockchain technology.","2169-3536","","10.1109/ACCESS.2020.3014522","Science and Technology Planning Project of Guangdong, China(grant numbers:201903010105); Philosophy and Social Science 13th Five-Year Planning Project of Guangzhou, China(grant numbers:2018GZZK23); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9159588","Blockchain technology;agricultural applications;food supply chains management;data integrity;traceability","Cryptography;Data integrity;Supply chains;Memory;Ecosystems;Agriculture","","96","","115","CCBY","5 Aug 2020","","","IEEE","IEEE Journals"
"Ultra-Compact Fourier Transform Near-Infrared MEMS Spectral Sensor for Smart Industry and IoT","B. Mortada; M. Medhat; Y. M. Sabry; M. Sadek; A. Shebl; K. Hassan; M. El-Masry; Y. Nada; M. Anwar; M. Gad; M. H. A. Haron; B. Saadany; D. Khalil; T. Bourouina","Si-Ware Systems, Cairo, Egypt; Si-Ware Systems, Cairo, Egypt; Si-Ware Systems, Cairo, Egypt; Si-Ware Systems, Cairo, Egypt; Si-Ware Systems, Cairo, Egypt; Si-Ware Systems, Cairo, Egypt; Si-Ware Systems, Cairo, Egypt; Si-Ware Systems, Cairo, Egypt; Si-Ware Systems, Cairo, Egypt; Si-Ware Systems, Cairo, Egypt; Si-Ware Systems, Cairo, Egypt; Si-Ware Systems, Cairo, Egypt; Faculty of Engineering, Ain Shams University, Cairo, Egypt; ESIEE, Paris, France","IEEE Journal of Selected Topics in Quantum Electronics","13 Jul 2021","2021","27","6","1","9","Miniaturized spectrometers are being developed in the recent few years leveraging the rapidly-progressing technology and triggering new markets in the field of on-site and mobile spectroscopic analysis. Although some devices were commercialized for the near-infrared spectroscopy (NIRS), their size and cost still don't meet the requirements for the ubiquitous deployment of the spectrometer as a spectral sensor needed for the smart industry and IoT applications. In this work we report an integrated microelectromechanical system (MEMS)-based Fourier Transform Infrared (FT-IR) spectral sensor. A monolithic scanning Michelson interferometer MEMS chip and an extended InGaAs photodetector chip are integrated with a micro-optical system in a tiny package with a footprint of 18 mm, presenting the smallest reported FT-IR solution to date. A compact light source head is designed and implemented targeting diffuse-reflection applications. The reported sensor's spectral resolution is about 66.6 cm-1 across the spectral range of 1350-2550 nm. The signal-to-noise ratio (SNR) achieved is 8000:1 at 2400 nm in 2 seconds, with an order of magnitude improvement with respect to previously reported fiber-coupled solution. The presented solution provides a low cost, low power, wide wavelength range NIR spectral sensor that can be manufactured with high volumes leveraging economies of scale.","1558-4542","","10.1109/JSTQE.2021.3091375","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9462357","Fourier transform spectrometer;MEMS optical bench technology;Michelson interferometer;spectroscopy;smart industry","Micromechanical devices;Optical interferometry;Optical fiber sensors;Actuators;Optical reflection;Optical fiber amplifiers;Mirrors","","8","","37","IEEE","22 Jun 2021","","","IEEE","IEEE Journals"
"Platform Generation for Edge AI Devices with Custom Hardware Accelerators","L. Hielscher; A. Bloeck; A. Viehl; S. Reiter; M. Staiger; O. Bringmann","FZI Research Center for Information Technology, Karlsruhe, Germany; FZI Research Center for Information Technology, Karlsruhe, Germany; FZI Research Center for Information Technology, Karlsruhe, Germany; FZI Research Center for Information Technology, Karlsruhe, Germany; Staiger GmbH & Co. KG, Erligheim, Germany; Chair for Embedded Systems, University of Tuebingen, Tuebingen, Germany","2021 IEEE 19th International Conference on Industrial Informatics (INDIN)","11 Oct 2021","2021","","","1","8","In recent years artificial neural networks (NNs) have been at the center of research on data processing. However, their high computational demand often prohibits deployment on resource-constrained Industrial IoT Systems. Custom hardware accelerators can enable real-time NN processing on small-scale edge devices but are generally hard to develop and integrate. In this paper we present a hardware generation approach to rapidly create, test, and deploy entire SoC platforms with application-specific NN hardware accelerators. The feasibility of the approach is demonstrated by the generation of a condition monitoring system for high-speed valves.","","978-1-7281-4395-8","10.1109/INDIN45523.2021.9557519","Ministry of Economic Affairs; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9557519","Hardware Acceleration;Hardware Generation;Neural Networks;Edge Devices","Condition monitoring;Conferences;Artificial neural networks;Valves;Data processing;Real-time systems;Informatics","","1","","16","IEEE","11 Oct 2021","","","IEEE","IEEE Conferences"
"An Efficient and Scalable Sparse Polynomial Multiplication Accelerator for LAC on FPGA","J. Zhang; Z. Liu; H. Yang; J. Huang; W. Wu","Nanjing University of Aeronautics and Astronautics, Jiangsu, China; State Key Laboratory of Cryptology, Beijing, China; Nanjing University of Aeronautics and Astronautics, Jiangsu, China; Nanjing University of Aeronautics and Astronautics, Jiangsu, China; Nanjing University of Aeronautics and Astronautics, Jiangsu, China","2020 IEEE 26th International Conference on Parallel and Distributed Systems (ICPADS)","25 Feb 2021","2020","","","390","397","LAC, a Ring-LWE based scheme, has shortlisted for the second round evaluation of the National Institute of Standards and Technology Post-Quantum Cryptography (NIST-PQC) Standardization. FPGAs are widely used to design accelerators for cryptographic schemes, especially in resource-constrained scenarios, such as IoT. Sparse Polynomial Multiplication (SPM) is the most compute-intensive routine in LAC. Designing an accelerator for SPM on FPGA can significantly improve the performance of LAC. However, as far as we know, there are currently no works related to the hardware implementation of SPM for LAC. In this paper, the proposed efficient and scalable SPM accelerator fills this gap. More concretely, we firstly develop the Dual-For-Loop-Parallel (DFLP) technique to optimize the accelerator's parallel design. This technique can achieve 2x performance improvement compared with the previous works. Secondly, we design a hardware-friendly modular reduction algorithm for the modulus 251. Our method not only saves hardware resources but also improves performance. Then, we launch a detailed analysis and optimization of the pipeline design, achieving a frequency improvement of up to 34%. Finally, our design is scalable, and we can achieve various performance-area trade-offs through parameter $p$. Our results demonstrate that the proposed design can achieve a very considerable performance improvement with moderate hardware area costs. For example, our medium-scale architecture for LAC-128 takes only 783 LUTs, 432 FFs, 5BRAMs, and no DSP on an Artix-7 FPGA and can complete LAC's polynomial multiplication in 8512 cycles at a frequency of 202MHz.","2690-5965","978-1-7281-9074-7","10.1109/ICPADS51040.2020.00059","National Natural Science Foundation of China(grant numbers:61802180); Natural Science Foundation of Jiangsu Province(grant numbers:BK20180421); Fundamental Research Funds for the Central Universities(grant numbers:NE2018106); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9359143","lattice-based cryptography;Ring-LWE;sparse polynomial multiplication;hardware accelerator;LAC;FPGA","Pipelines;Hardware;Table lookup;Cryptography;Acceleration;Optimization;Field programmable gate arrays","","1","","22","IEEE","25 Feb 2021","","","IEEE","IEEE Conferences"
"Voice Spoofing Countermeasure for Logical Access Attacks Detection","T. Arif; A. Javed; M. Alhameed; F. Jeribi; A. Tahir","Department of Software Engineering, University of Engineering and Technology, Taxila, Taxila, Pakistan; Department of Computer Science, University of Engineering and Technology, Taxila, Taxila, Pakistan; College of Computer Science and Information Technology, Jazan University, Jazan, Saudi Arabia; College of Computer Science and Information Technology, Jazan University, Jazan, Saudi Arabia; College of Computer Science and Information Technology, Jazan University, Jazan, Saudi Arabia","IEEE Access","17 Dec 2021","2021","9","","162857","162868","Voice-driven devices (VDDs) like Google Home and Amazon Alexa, which are well-known connected devices in consumer IoT, have applications in various domains i.e., home appliances automation, next-generation vehicles, voice banking, and so on. However, these VDDs that are based on automatic speaker verification systems (ASVs) are vulnerable to voice based logical access (LA) attacks like Text-to-Speech (TTS) synthesis and converted voice signals. Intruders can exploit these attacks to bypass the security of such systems and gain access of victim’s bank account or home control. Thus, there exists a need to develop an effective voice spoofing countermeasure that can reliably be used to protect these VDDs against such malicious attacks. This work presents a novel audio features descriptor named as extended local ternary pattern (ELTP) to capture the vocal tract dynamically induced attributes of bonafide speech and algorithmic artifacts in synthetic and converted speeches. We fused our novel ELTP features with the linear frequency cepstral coefficients (LFCC) to further strengthen the capability of our features for capturing the traits of bonafide and spoofed signals. We employ the proposed ELTP-LFCC features to train the deep bidirectional Long Short-Term Memory (DBiLSTM) network for classification of the bonafide and spoof signal (i.e., TTS synthesis, converted speech). Performance of our spoofing countermeasure is measured on the large-scale and diverse ASVspoof 2019 logical access dataset. Experimental results demonstrate that the proposed audio spoofing countermeasure can reliably be used to detect the LA spoofing attacks.","2169-3536","","10.1109/ACCESS.2021.3133134","Grant of Punjab Higher Education Commission (PHEC) of Pakistan(grant numbers:PHEC/ARA/PIRCA/20527/21); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9638512","Extended local ternary pattern;logical access attacks;text-to-speech synthesis;voice spoofing countermeasure;voice conversion","Feature extraction;Speech synthesis;Reliability;Cepstral analysis;Biometrics (access control);Internet;Heuristic algorithms","","12","","43","CCBY","6 Dec 2021","","","IEEE","IEEE Journals"
"MAIC: Metalearning-Based Adaptive In-Field Calibration for IoT Air Quality Monitoring System","N. Liu; Z. Wu; G. Li; X. Liu; Y. Wang; L. Zhang","Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Tsinghua-Berkeley Shenzhen Institute, Tsinghua University, Shenzhen, China; DSIT Research Center, Tsinghua-Berkeley Shenzhen Institute, Tsinghua University, Shenzhen, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Tsinghua-Berkeley Shenzhen Institute, Tsinghua University, Shenzhen, China","IEEE Internet of Things Journal","24 Aug 2022","2022","9","17","15928","15941","Air pollution has become a global threat to human health. Fine-grained air quality monitoring has attracted much attention in recent years. Low-cost calibrated sensors make it possible for the large-scale deployment of IoT air quality monitoring systems. In practice, the calibration performance degrades after deployment due to the dynamic and diversity of system conditions. However, it is infeasible to collect sufficient in-field reference data to train calibration models for these new conditions. To address the multicondition and few-data challenge, we proposed metalearning-based adaptive in-field calibration (MAIC), a metalearning-based adaptive in-field calibration algorithm. Specifically, MAIC adopts metalearning to learn how to adapt to new conditions quickly. To effectively leverage historical data, we first develop task generation strategies for sensor calibration under this scheme. Then, task-oriented optimization is introduced to train a model with superior adaptability in the offline training phase. Furthermore, an adaptation method is presented to learn the task-specific data distribution without forgetting the metaknowledge, enabling continual learning to utilize the temporal dependencies between multiple conditions. Our evaluations on synthetic and real-world data sets show that MAIC has high robustness and adaptability under multiple complicated conditions. Our proposed method outperforms the state-of-the-art calibration algorithms by 4.23%–29.46% in the real-world deployment data set, but with fewer requirements for the available in-field reference data.","2327-4662","","10.1109/JIOT.2022.3150849","Shenzhen Science and Technology Program(grant numbers:KQTD20170810150821146); Tsinghua-Toyota Joint Research Institute Cross-Discipline Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9711568","Air quality monitoring;low-cost sensor calibration;metalearning","Calibration;Sensors;Monitoring;Adaptation models;Pollution measurement;Data models;Task analysis","","5","","48","IEEE","11 Feb 2022","","","IEEE","IEEE Journals"
"Joint Relaying and Spatial Sharing Multicast Scheduling for mmWave Networks","G. H. Sim; M. Mousavi; L. Wang; A. Klein; M. Hollick","Secure Mobile Networking Lab., Technical University of Darmstadt, Darmstadt, Germany; Communication Engineering Lab, TU Darmstadt, Germany; VU Amsterdam, The Netherlands; Communication Engineering Lab, TU Darmstadt, Germany; Secure Mobile Networking Lab, TU Darmstadt, Germany","2020 IEEE 21st International Symposium on "A World of Wireless, Mobile and Multimedia Networks" (WoWMoM)","9 Oct 2020","2020","","","127","136","Millimeter-wave (mmWave) communication plays a vital role in disseminating large volumes of data in beyond-5G networks efficiently. Unfortunately, the directionality of mmWave communication significantly complicates efficient data dissemination, particularly in multicasting, which is gaining more and more importance in emerging applications (e.g., V2X, public safety, massive IoT). While multicasting for systems operating at lower frequencies (i.e., sub-6GHz) has been extensively studied, they are sub-optimal for mmWave systems as mmWave has significantly different propagation characteristics, i.e., using the directional transmission to compensate for the high path loss and thus promoting spectrum sharing. In this paper, we propose novel multicast scheduling algorithms by jointly exploiting relaying and spatial sharing gains while aiming to minimize the multicast completion time. We first characterize the problem with a comprehensive model and formulate it with an integer linear program (ILP). We further design a practical and scalable semi-distributed algorithm named mmDiMu, based on gradually maximizing the transmission throughput over time. Finally, we carry out validation through extensive simulations in different scales, and the results show that mmDiMu significantly outperforms conventional algorithms with around 95% reduction on multicast completion time.","","978-1-7281-7374-0","10.1109/WoWMoM49955.2020.00033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9217741","Millimeter-wave (mmWave) networks;multicasting;relay;spatial sharing;scheduling","Multicast communication;Relays;Throughput;Array signal processing;Signal to noise ratio;Unicast;Complexity theory","","4","","27","IEEE","9 Oct 2020","","","IEEE","IEEE Conferences"
"Predictable Efficiency for Reconfiguration of Service-Oriented Systems with Concerto","M. Chardet; H. Coullon; C. Perez","Inria, LS2N, UBL, IMT Atlantique, Nantes, France; Inria, LS2N, UBL, IMT Atlantique, Nantes, France; Inria, CNRS, ENS de Lyon, UCBL LIP, Univ. Lyon, Lyon Cedex 07, France","2020 20th IEEE/ACM International Symposium on Cluster, Cloud and Internet Computing (CCGRID)","14 Jul 2020","2020","","","340","349","Dynamic reconfiguration of distributed software systems is nowadays gaining interest because of the emergence of dynamic IoT and smart applications as well as large scale dynamic infrastructures (e.g., Fog and Edge computing). When quality of service and experience is of prime importance, efficient reconfiguration is necessary, as well as performance predictability to decide when a reconfiguration should occur. This paper tackles the problem of efficient execution of a reconfiguration plan and its predictability with Concerto, a reconfiguration model supporting a high level of parallelism. Evaluation performed on synthetic cases and on two real production scenarios show that Concerto provides better performance than state-of- the-art systems with accurate time estimation.","","978-1-7281-6095-5","10.1109/CCGrid49817.2020.00-59","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9139637","distributed systems;reconfiguration;component model;performance","Parallel processing;Tools;Servers;Software systems;Estimation;Planning","","3","","22","IEEE","14 Jul 2020","","","IEEE","IEEE Conferences"
"A Multi-band Solution for Interacting with Energy-Neutral Devices","C. Buyle; B. Cox; L. V. der Perre; L. De Strycker","Department of Electrical Engineering, KU, Leuven, Belgium; Department of Electrical Engineering, KU, Leuven, Belgium; Department of Electrical Engineering, KU, Leuven, Belgium; Department of Electrical Engineering, KU, Leuven, Belgium","2021 55th Asilomar Conference on Signals, Systems, and Computers","4 Mar 2022","2021","","","329","333","RF Wireless Power Transfer (WPT) emerges as a technology for charging autonomous devices, enabling simultaneous power and information transfer. However, with increasing distance, single-input, single-channel rectenna systems are not able to meet the power requirements of large scale IoT applications. In this paper, we tackle this problem on two levels. First, we minimize the energy consumption at the energy-constrained device on three levels. Second, we evolve to a dual-band solution increasing RF WPT. One frequency band is used to provide a base charge to many nodes in a shared transmission. Beam steering, on the other hand, allows for more power hungry operations while introducing as minimal interference as possible. We showcase this method for a hybrid RF-acoustic positioning system. Practical measurements conducted in a multi-antenna indoor testbed (Techtile) show the additional power gain and positioning rate.","2576-2303","978-1-6654-5828-3","10.1109/IEEECONF53345.2021.9723184","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9723184","Acoustic Sensors;Hybrid Signaling;Low-Power Electronics;Beam steering","Semiconductor device measurement;Beam steering;Three-dimensional displays;Power measurement;Rectennas;Wireless power transfer;Time measurement","","2","","19","EU","4 Mar 2022","","","IEEE","IEEE Conferences"
"Evaluation of Load Prediction Techniques for Distributed Stream Processing","K. Gontarska; M. Geldenhuys; D. Scheinert; P. Wiesner; A. Polze; L. Thamsen","Hasso Plattner Institute, University of Potsdam, Germany; Technische Universität, Berlin, Germany; Technische Universität, Berlin, Germany; Technische Universität, Berlin, Germany; Hasso Plattner Institute, University of Potsdam, Germany; Technische Universität, Berlin, Germany","2021 IEEE International Conference on Cloud Engineering (IC2E)","22 Nov 2021","2021","","","91","98","Distributed Stream Processing (DSP) systems enable processing large streams of continuous data to produce results in near to real time. They are an essential part of many data-intensive applications and analytics platforms. The rate at which events arrive at DSP systems can vary considerably over time, which may be due to trends, cyclic, and seasonal patterns within the data streams. A priori knowledge of incoming workloads enables proactive approaches to resource management and optimization tasks such as dynamic scaling, live migration of resources, and the tuning of configuration parameters during run-times, thus leading to a potentially better Quality of Service. In this paper we conduct a comprehensive evaluation of different load prediction techniques for DSP jobs. We identify three use-cases and formulate requirements for making load predictions specific to DSP jobs. Automatically optimized classical and Deep Learning methods are being evaluated on nine different datasets from typical DSP domains, i.e. the IoT, Web 2.0, and cluster monitoring. We compare model performance with respect to overall accuracy and training duration. Our results show that the Deep Learning methods provide the most accurate load predictions for the majority of the evaluated datasets.","","978-1-6654-4970-0","10.1109/IC2E52221.2021.00023","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9610459","Distributed Stream Processing;Resource Management and Optimization;Load Prediction;Time Series Forecasting;Machine Learning","Training;Deep learning;Web 2.0;Training data;Real-time systems;Resource management;Task analysis","","2","","38","IEEE","22 Nov 2021","","","IEEE","IEEE Conferences"
"Evaluating Off-chain Transaction Queueing Delay to Ensure Data Integrity by Blockchain","H. Seike; Y. Aoki; N. Koshizuka","Center for the Promotion of Social Data Science Education and Research, Hitotsubashi University, Tokyo, Japan; Picolab Co., LTD, Tokyo, Japan; Interfaculty Initiative in Information Studies, The University of Tokyo, Tokyo, Japan","2023 8th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA)","26 Jun 2023","2023","","","68","75","In recent years, society has been promoting the use of big data to improve our daily lives. At the same time, there is a demand to verify the legitimacy of data. For this reason, there have been many proposals to ensure data integrity by a blockchain consensus. However, the blockchain-based system cannot process a lot of transactions in a short period. Therefore, the blockchain technology cannot be simply applied into systems where large amounts of data are added and updated.Off-chain protocols have been proposed to scale blockchains. They guarantee the integrity of data outside the blockchain and reduce the on-chain replication cost by not directly storing data in the blockchain storage. Meanwhile, an off-chain queueing delay is newly introduced since off-chain transactions (OTXs) are processed in a batch manner by periodically posting the OTX summary data on the underlying blockchain. This delay cannot be ignored, especially in the case of frequently updated data, such as IoT data.In this paper, we propose and analyze a queueing model that considers OTX processing time in order to estimate the mean OTX queueing delay. This analytical values help us to previously determine whether the adopted off-chain approach is effective to ensure the integrity of the given data. In numerical examples, we show how the parameters, such as the OTX batch size and the OTX rate, affect the OTX queueing delay.","2832-3734","978-1-6654-5533-6","10.1109/ICCCBDA56900.2023.10154727","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10154727","blockchain scalability;queueing model;processing time;high frequency data","Analytical models;Time-frequency analysis;Costs;Data integrity;Big Data;Data models;Blockchains","","1","","28","IEEE","26 Jun 2023","","","IEEE","IEEE Conferences"
"Compressed Cluster Sensing in Multiagent IoT Control","D. Uzhva; O. Granichin; O. Granichina","Laboratory ""Control of Complex Systems"", Institute for Problems in Mechanical Engineering, Saint Petersburg; Laboratory ""Control of Complex Systems"", Institute for Problems in Mechanical Engineering, Saint Petersburg; Herzen State Pedagogical University, Saint Petersburg","2022 IEEE 61st Conference on Decision and Control (CDC)","10 Jan 2023","2022","","","3580","3585","Traditional multiagent system control relies primarily on inter-agent local communications. In large-scale IoT systems it may appear hard to synthesize local control actions in a simple manner. Cluster control possibilities are thus thoroughly discussed, with possible control goals stated. The relation between multiagent state sparsity and cluster patterns is illustrated, for further utilization of sparsity for cluster control. Consequently, the problem of cluster identification is stated, and a possible solution is proposed in the form of the compressed cluster sensing algorithm. The algorithm utilizes compressed sensing methodology for a compact representation of agent states, which is then used to synthesize compact control actions in a low-dimensional space, without requiring to specify cluster locations.","2576-2370","978-1-6654-6761-2","10.1109/CDC51059.2022.9992703","Russian Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9992703","","Wireless sensor networks;Heuristic algorithms;Clustering algorithms;Sensors;Numerical models;Nonlinear dynamical systems;Synchronization","","","","37","IEEE","10 Jan 2023","","","IEEE","IEEE Conferences"
"On Securing the Global Economical Dispatch in DC Microgrid Clusters: An Event-Driven Approach","S. Jena; N. P. Padhy; A. K. Srivastava","Department of Electrical Engineering, Indian Institute of Technology Roorkee, Haridwar, Uttarakhand, India; Department of Electrical Engineering, Indian Institute of Technology Roorkee, Haridwar, Uttarakhand, India; LCSEE, West Virginia University, Morgantown, WV, USA","IEEE Transactions on Automation Science and Engineering","","2023","PP","99","1","16","This article investigates the effects of cyber attacks on the global economical dispatch of vicinity interconnected DC MG clusters. First, it articulates an analytical detection and mitigation strategy integrated with logical operation aided event generators for retaining the feasible operation region of the economic dispatch problem in multiple MG clusters. Second, separate defense actions are designed for leader and follower nodes in a MG, unlike common mitigation action for all nodes in previous works. Third, a variable averaging gain for processing the neighbor’s information at every node is proposed. It aids in distinguishing an actual instance of power generation unit saturation from a cyber attack. The entire system is modelled in a real time digital simulator and the results obtained demonstrate the efficacy of the proposed algorithm for attaining a secure global economic dispatch. It also exhibits an important feature of prioritising resiliency over economics by transitioning from economic dispatch mode to supplying to critical loads under adverse events. Finally, for testing the application of the proposed algorithm to a large-scale system, it is extended to five interconnected MG clusters containing 20 DC-DC power electronic converters. Note to Practitioners—Cybersecurity becomes a critical concern for vicinity connected microgrids as an increasing amount of IoT devices are adopted for communication, monitoring, and operation support purposes. This cyber-physical structure provides an attack surface because adversaries can compromise the physical structure by attacking its dependent cyberspace. For mitigation of the attacks, twining the efforts of securing from both the cyber and the physical testbed is required. As such, this paper provides the owners and operators with in-depth knowledge about the requirement of different control strategies for the leader and follower nodes in the interconnected network of microgrids. It also emphasizes the need for prioritising resilience under adverse events. The technique is simple and user-friendly for implementation in the already existing control strategies. The real-time simulation results prove its effectiveness so that it can be put into practice.","1558-3783","","10.1109/TASE.2023.3330928","Department of Science & Technology (DST)/Department of Energy (DOE) US-India collAborative for smart diStribution System wIth STorage (UI-ASSIST)(grant numbers:IUS-1132-EED/DE-IA0000025); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10315077","Direct current (DC);event generator;global economical dispatch (GED);reconfigurable and real-time simulator","Cyberattack;Security;Microgrids;Clustering algorithms;Resilience;Costs;Internet of Things","","","","","IEEE","10 Nov 2023","","","IEEE","IEEE Early Access Articles"
"FRAVaR: A Fast Failure Recovery Framework for Inter-DC Network","H. Huang; Y. ZhangB; R. Wang; Q. Xiang; W. Wang; X. Que; K. Xu","Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; School of Informatics, Xiamen University, China; Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; Department of Computer Science and Technology, Tsinghua University, China","2023 IEEE Wireless Communications and Networking Conference (WCNC)","12 May 2023","2023","","","1","6","Along with the development of 5G and IoT technologies in recent years, Inter Data Center (Inter-DC) network is facing an explosive growth of geographically distributed user data, which needs to be duplicated among DCs in a real-time manner. Transmission-based applications require high availability that is going beyond 99.99%. However, with the expansion of Inter-DC network scale, link failures are also growing, which seriously affects data transmission efficiency, so fast link failure recovery is then urgently needed. Many previous works have been done to achieve fast failure recovery, but most of them ignore two key points, 1) the cost of deploying recovery strategies, and 2) the side-effect of re-transmission to network availability. These two factors make the existing failure recovery process too slow to be practical in real-time online industrial environments. To achieve realistic fast recovery from Inter-DC network failures, we propose a failure recovery framework FRAVaR, which achieves high network availability with very little deployment overhead. Particularly, FRAVaR reduces the deployment overhead by a novel incremental routing strategy to isolate link failures. In other words, it only needs to shuffle a tiny amount of traffic within a small failure isolation domain. On this base, FRAVaR further adopts a risk assessment theory named Value-at-Risk (VaR) to control flow re-transmission. We implement a prototype of FRAVaR and conduct a series of experiments on 4 real InterDC network topologies (ATT North America, IBM, GlobalCenter, AGIS). Experiment results show that FRAVaR outperforms state-of-the-art solutions on the recovery speed by 70.2%.1","1558-2612","978-1-6654-9122-8","10.1109/WCNC55385.2023.10119088","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10119088","Inter data center network;Failure recovery;Value at Risk","Data centers;Reactive power;Network topology;Prototypes;Throughput;Routing;Real-time systems","","","","20","IEEE","12 May 2023","","","IEEE","IEEE Conferences"
"A Review on Emerging Spintronic Devices: CMOS Counterparts","P. Jangra; M. Duhan","Department of Electronics and Communication Engineering, DCRUST, INDIA; Department of Electronics and Communication Engineering, DCRUST, INDIA","2022 7th International Conference on Communication and Electronics Systems (ICCES)","29 Jul 2022","2022","","","90","99","As the scaling and integration limits of conventional devices in the semiconductor industry are approaching, spintronics devices have attracted an enormous amount of attraction. Spintronic devices can provide a solution for traditional charge-based implementation problems, such as large power consumption, high operating voltage, process issues, etc. The basic principle in spintronic field is the use of spin degree of freedom of electrons. What makes spintronics devices trending in research is their almost zero power leakage, high endurance, effective read and write capabilities than CMOS counterparts, nonvolatility nature, and ease of integration and support for high-end technologies such as Big data and IoT. These devices’ advantages have propelled the industry to use them in-memory applications and remodel the process in-memory architecture for future use. The paper reviews the advancements and achievements in the field of spintronics and its principles. Also, many spintronics devices such as spin logic devices, spin valves, etc., and magnetic phenomena such as tunnel magnetoresistance, spin hall effect, etc., are covered. In this paper, the advancements done in past 20 years, current position, and next growth aspects of spintronic technology have been discussed.","","978-1-6654-9634-6","10.1109/ICCES54183.2022.9835778","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9835778","All spin logic (ASL);Anti Parallel (AP);Domain Wall (DW);Dynamic Random Access Memory (DRAM);Free Layer (FL);Ferromagnetic (FM);Ferroelectric Random Access Memory (FeRAM);Hard Disk Drive (HDD);Logic in memory (LIM);Magnetic Tunnel Junction (MTJ);Magnetoresistance random access memory (MRAM);Non-Volatile Memories (NVM);Pinned Layer (PL);Resistive random access memory (ReRAM);Racetrack Memory (RM);Spin-Orbit Torque Magnetic Random-Access Memory (SOT-MRAM);Spin Hall Effect (SHE);Spin-Transfer Torque Magnetic Random-Access Memory (STT-MRAM);Static Random Access Memory (SRAM);Thermal Assisted Switching (TAS);Tunnel Magnetoresistance (TMR)","Industries;Torque;Memory management;Random access memory;Magnetic domains;Writing;Hall effect","","2","","62","IEEE","29 Jul 2022","","","IEEE","IEEE Conferences"
"Graph Coordinates and Conventional Neural Networks - An Alternative for Graph Neural Networks","Z. Qin; R. Paffenroth; A. P. Jayasumana","Electrical and Computer Engineering, Colorado State University, Fort Collins, USA; Department of Data Science Program, Worcester Polytechnic Institute, Worcester, MA, USA; Electrical and Computer Engineering, Colorado State University, Fort Collins, USA","2023 IEEE International Conference on Big Data (BigData)","22 Jan 2024","2023","","","4456","4465","Graph-based data present unique challenges and opportunities for machine learning. Graph Neural Networks (GNNs), and especially those algorithms that capture graph topology through message passing for neighborhood aggregation, have been a leading solution. However, these networks often require substantial computational resources and may not optimally leverage the information contained in the graph’s topology, particularly for large-scale or complex graphs.We propose Topology Coordinate Neural Network (TCNN) and Directional Virtual Coordinate Neural Network (DVCNN) as novel and efficient alternatives to message passing GNNs, that directly leverage the graph’s topology, sidestepping the computational challenges presented by competing algorithms. Our proposed methods can be viewed as a reprise of classic techniques for graph embedding for neural network feature engineering, but they are novel in that our embedding techniques leverage ideas in Graph Coordinates (GC) that are lacking in current practice.Experimental results, benchmarked against the Open Graph Benchmark Leaderboard, demonstrate that TCNN and DVCNN achieve competitive or superior performance to message passing GNNs. For similar levels of accuracy and ROC-AUC, TCNN and DVCNN need far fewer trainable parameters than contenders of the OGBN Leaderboard. The proposed TCNN architecture requires fewer parameters than any neural network method currently listed in the OGBN Leaderboard for both OGBN-Proteins and OGBN-Products datasets. Conversely, our methods achieve higher performance for a similar number of trainable parameters. These results hold across diverse datasets and edge features, underscoring the robustness and generalizability of our methods. By providing an efficient and effective alternative to message passing GNNs, our work expands the toolbox of techniques for graph-based machine learning. A significantly lower number of tunable parameters for a given evaluation metric makes TCNN and DVCNN especially attractive for resource limited IoT/mobile devices and for reducing power consumption of ML models.","","979-8-3503-2445-7","10.1109/BigData59044.2023.10386792","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10386792","graph embedding;graph coordinate;green AI;graph analytics;network embedding","Performance evaluation;Training;Network topology;Message passing;Machine learning;Benchmark testing;Robustness","","","","42","IEEE","22 Jan 2024","","","IEEE","IEEE Conferences"
"An Anomaly Comprehension Neural Network for Surveillance Videos on Terminal Devices","Y. Cheng; G. Huang; P. Zhen; B. Liu; H. -B. Chen; N. Wong; H. Yu","Department of Micro/Nano Electronics, Shanghai Jiao Tong University, Shanghai, China; Department of Electrical and Electronic Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Micro/Nano Electronics, Shanghai Jiao Tong University, Shanghai, China; Department of Electrical and Electronic Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Micro/Nano Electronics, Shanghai Jiao Tong University, Shanghai, China; Department of Electrical and Electronic Engineering, The University of Hong Kong, Hong Kong; Department of Electrical and Electronic Engineering, Southern University of Science and Technology, Shenzhen, China","2020 Design, Automation & Test in Europe Conference & Exhibition (DATE)","15 Jun 2020","2020","","","1396","1401","Anomaly comprehension in surveillance videos is more challenging than detection. This work introduces the design of a lightweight and fast anomaly comprehension neural network. For comprehension, a spatio-temporal LSTM model is developed based on the structured, tensorized time-series features extracted from surveillance videos. Deep compression of network size is achieved by tensorization and quantization for the implementation on terminal devices. Experiments on large-scale video anomaly dataset UCF-Crime demonstrate that the proposed network can achieve an impressive inference speed of 266 FPS on a GTX-1080Ti GPU, which is 4.29 faster than ConvLSTM-based method; a 3.34% AUC improvement with 5.55% accuracy niche versus the 3D-CNN based approach; and at least 15k× parameter reduction and 228× storage compression over the RNN-based approaches. Moreover, the proposed framework has been realized on an ARM-core based IOT board with only 2.4W power consumption.","1558-1101","978-3-9819263-4-7","10.23919/DATE48585.2020.9116533","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9116533","anomaly comprehension;surveillance videos;AI on IOT","Feature extraction;Tensors;Videos;Quantization (signal);Surveillance;Hardware;Neural networks","","7","","21","","15 Jun 2020","","","IEEE","IEEE Conferences"
"DQC2O: Distributed Quantum Computing for Collaborative Optimization in Future Networks","N. Ngoenriang; M. Xu; J. Kang; D. Niyato; H. Yu; X. Shen","Vidyasirimedhi Institute of Science and Technology, Thailand; School of Computer Science and Engineering, Nanyang Technological University, Singapore; Guangdong University of Technology, China; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; University of Waterloo, Waterloo, Canada","IEEE Communications Magazine","18 May 2023","2023","61","5","188","194","With the advantages of high-speed parallel processing, quantum computers can efficiently solve large-scale complex optimization problems in future networks. However, due to the uncertain qubit fidelity and quantum channel noise, distributed quantum computing, which relies on quantum networks connected through entanglement, faces many challenges in exchanging information across quantum computers. In this article, we propose an adaptive distributed quantum computing approach, called DQC2O, to manage quantum computers and quantum networks for solving optimization tasks in future networks. Firstly, we describe the fundamentals of quantum computing and its distributed concept in quantum networks. Secondly, to address the uncertainty of future demands of collaborative optimization tasks and instability over quantum networks, we propose a quantum resource allocation scheme based on stochastic programming for minimizing quantum resource consumption. Finally, based on the proposed approach, we discuss the potential military applications of collaborative optimization in future networks, such as smart grid management, IoT cooperation, and semantic communications. Promising research directions that can lead to the design and implementation of future distributed quantum computing frameworks are also highlighted.","1558-1896","","10.1109/MCOM.003.2200573","NSFC(grant numbers:62102099,U22A2054); National Research Foundation (NRF)(grant numbers:AISG2-RP-2020-019); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10032075","","Quantum computing;Logic gates;Teleportation;Task analysis;Smart grids;Military computing;Internet of Things","","5","","15","IEEE","30 Jan 2023","","","IEEE","IEEE Magazines"
"Channel-Resilient Deep-Learning-Driven Device Fingerprinting Through Multiple Data Streams","N. Basha; B. Hamdaoui; K. Sivanesan; M. Guizani","EECS, Oregon State University, Corvallis, OR, USA; EECS, Oregon State University, Corvallis, OR, USA; Intel Labs, Intel Corporation, Hillsboro, OR, USA; Machine Learning Department, Mohamed Bin Zayed University of Artificial Intelligence, Abu Dhabi, UAE","IEEE Open Journal of the Communications Society","13 Jan 2023","2023","4","","118","133","Enabling accurate and automated identification of wireless devices is critical for allowing network access monitoring and ensuring data authentication for large-scale IoT networks. RF fingerprinting has emerged as a solution for device identification by leveraging the transmitters’ inevitable hardware impairments that occur during manufacturing. Although deep learning is proven efficient in classifying devices based on hardware impairments, the performance of deep learning models suffers greatly from variations of the wireless channel conditions, across time and space. To the best of our knowledge, we are the first to propose leveraging MIMO capabilities to mitigate the channel effect and provide a channel-resilient device classification framework. We begin by showing that for AWGN channels, combining multiple received signals improves the testing accuracy by up to 30%. We then show that for more realistic Rayleigh channels, blind channel estimation enabled by MIMO increases the testing accuracy by up to 50% when the models are trained and tested over the same channel, and by up to 69% when the models are tested on a channel that is different from that used for training.","2644-125X","","10.1109/OJCOMS.2022.3233372","U.S. National Science Foundation through NSF(grant numbers:1923884); NSF/Intel(grant numbers:2003273); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10004717","Automated network access;deep learning;IoT device fingerprinting;multiple-input multiple-out (MIMO)","Fingerprint recognition;MIMO communication;Signal to noise ratio;Diversity reception;Training;Radio frequency;Wireless communication","","4","","39","CCBY","2 Jan 2023","","","IEEE","IEEE Journals"
"Cost-Effective Space Partitioning Approach for IoT Data Indexing and Retrieval","I. Kemouguette; Z. Kouahla; A. -E. Benrazek; B. Farou; H. Seridi","Computer Science Department, LabSTIC Laboratory, 8 May 1945 University, P.O. Box 401, Guelma, Algeria; Computer Science Department, LabSTIC Laboratory, 8 May 1945 University, P.O. Box 401, Guelma, Algeria; Computer Science Department, LabSTIC Laboratory, 8 May 1945 University, P.O. Box 401, Guelma, Algeria; Computer Science Department, LabSTIC Laboratory, 8 May 1945 University, P.O. Box 401, Guelma, Algeria; Computer Science Department, LabSTIC Laboratory, 8 May 1945 University, P.O. Box 401, Guelma, Algeria","2021 International Conference on Networking and Advanced Systems (ICNAS)","6 Dec 2021","2021","","","1","6","IoT technology implies a huge group of connected devices to capture a tremendous quantity of information. Computing and storing this huge amount of data requires scalable and efficient indexing solutions. Among the latest indexing structures in the BCCF-tree metric space, one framework is focused on providing recursive clustering of the space using the k-means algorithm. This solution suffers from data overlap between space partitioning at large scale. This study aims to optimize the structure of the BCCF. We propose to replace the k-means algorithm with an algorithm for estimating the overlap rate between the partitions of the space. Experimental results show good performance of the construction and search algorithms on several types of datasets.","","978-1-6654-2821-7","10.1109/ICNAS53565.2021.9628904","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9628904","Indexing;IoT;Optimization;K nn search;Similarity","Measurement;Clustering algorithms;Artificial neural networks;Parallel processing;Partitioning algorithms;Indexing","","1","","34","IEEE","6 Dec 2021","","","IEEE","IEEE Conferences"
"LibDI: A Direction Identification Framework for Detecting Complex Reuse Relationships in Binaries","S. Li; C. Dong; Y. Wang; W. Liu; W. Wang; H. Li; H. Zhu; L. Sun","Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; School of Software, Henan University, Kaifeng, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China","MILCOM 2023 - 2023 IEEE Military Communications Conference (MILCOM)","25 Dec 2023","2023","","","741","746","With the continuous evolution of software development, the increasing reuse and complexity of programs have become prominent. Detecting and analyzing reuse relationships in binary programs are crucial for software maintenance, performance optimization, and security enhancement. However, existing methods only identify whether binaries have reuse relationships without distinguishing the source binary of the reused code. This limitation hinders the detection of complex reuse relationships, such as nested reuse and pseudo-propagation reuse, and adversely affects the detection of 1-day vulnerability propagation relationships. To address this challenge, we propose LibDI, a Direction Identification framework specifically designed for detecting complex reuse relationships in C/C++ binaries. LibDI utilizes the Multi-level direction identification technique to accurately determine the direction of reuse between binaries, enabling the identification of complex reuse relationships. Experimental results demonstrate that LibDI achieves a recognition accuracy of 0.976 on public datasets, significantly outperforming existing methods. Moreover, LibDI successfully identifies complex reuse relationships in large-scale IoT firmware and effectively detects the propagation paths of vulnerabilities.","2155-7586","979-8-3503-2181-4","10.1109/MILCOM58377.2023.10356328","National Key Research and Development Program of China; Youth Foundation; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10356328","Third-party Library Detection;Software Component Analysis;Complex Reuse Relationship Identification","Military communication;Software maintenance;Codes;Libraries;Complexity theory;Security;Optimization","","","","14","IEEE","25 Dec 2023","","","IEEE","IEEE Conferences"
"Performance evaluation of the AquaTag, a prototype near-field RF-based soil moisture sensor","J. Balendonck; İ. H. Tüzel; U. Tunali; G. B. Oztekin; Y. Tüzel","Greenhouse Horticulture, Wageningen University and Research, Wageningen, The Netherlands; Faculty of Agriculture, Ege University, Bornova-Izmir, Turkey; Faculty of Agriculture, Ege University, Bornova-Izmir, Turkey; Faculty of Agriculture, Ege University, Bornova-Izmir, Turkey; Greenhouse Horticulture, Wageningen University and Research, Wageningen, The Netherlands","2021 13th International Conference on Electromagnetic Wave Interaction with Water and Moist Substances (ISEMA)","10 Aug 2021","2021","","","1","6","Soil sensor activated irrigation scheduling is used in agriculture to optimally dose water and improve water use efficiency. Soil moisture sensors give point-related information and due to heterogeneities in soil hydraulic properties, use of a limited number of sensors may lead to errors in the average soil moisture content obtained for a field. As prices for individual IoT-based soil moisture sensors are still high, there is a need for low-cost soil moisture sensors. The AquaTag prototype is a passive, impedance-based sensor tag and a hand-held readout device for measuring soil water content. It operates contactless using a near-field, narrow-band RF-technology at 27 MHz. The tag has a lower accuracy than regular FD or TDR sensors, but it has the potential to be produced at very low-cost. Growers with small-scale, low-tech soil-grown crop production systems could use it to save water at acceptable cost. The aim of this work was to evaluate performance of prototypes, especially for the effects of production variability, reader-sensor positioning, temperature and soil type calibration. Sensor repeatability was ±0.62% and the overall accuracy tested with well-saturated glass beads was ±10.4%, taking effects of functional calibration, reader positioning and temperature into account. Production variability was improved by functional testing, selection and optimizing the reader signal analysis. Measurements for dry and wet sandy soils are possible at sensor-reader distances up to 10 cm. The reader angular position influences readings only marginally, if measurements are taken with care. Soil temperature affects sensor readings considerably, but the effect of the tag temperature is only marginally. A single calibration curve for two loamy-clay sandy soils was obtained. The AquaTag seems suitable to determine soil moisture content, but in order to reach an accuracy of below ±10%, sensors must be tuned individually, for temperature a compensation is required and in-situ calibration for well-saturated soils is advised. Sensors with a longer shaft are required to use the tag for measurements at common crop rooting depths.","","978-1-7281-8738-9","10.1109/ISEMA49699.2021.9508292","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9508292","wireless;contactless;battery-less;RF tag;soil water content;electrical conductivity;horticulture;irrigation","Temperature measurement;Temperature sensors;Shafts;Temperature distribution;Production systems;Soil measurements;Soil moisture","","1","","16","IEEE","10 Aug 2021","","","IEEE","IEEE Conferences"
"An IoT Based Secure Smart Farming","J. S. Philip; J. A. Mathew; J. Johnson; J. Jose; K. Sanal; M. K. Saji; M. J. K","Computer Science & Engineering, Mar Baselios College of Engineering & Technology, Kerala, India; Computer Science & Engineering, Mar Baselios College of Engineering & Technology, Kerala, India; Computer Science & Engineering, Mar Baselios College of Engineering & Technology, Kerala, India; Computer Science & Engineering, Mar Baselios College of Engineering & Technology, Kerala, India; Computer Science & Engineering, Mar Baselios College of Engineering & Technology, Kerala, India; Computer Science & Engineering, Mar Baselios College of Engineering & Technology, Kerala, India; Computer Science & Engineering, Mar Baselios College of Engineering & Technology, Kerala, India","2023 International Conference on Circuit Power and Computing Technologies (ICCPCT)","22 Sep 2023","2023","","","788","793","Agrotechnology takes into account the soil and climatic conditions in order to guarantee a high crop production with the best possible labour investment. The progress of farming as a whole has been greatly influenced by advancements in plant physiology. Use of organic and mineral fertilizers has been rationalized. A scientific rationale for the necessity of irrigation has been developed via studies of the soil and plant water requirements. When the right conditions, such as the right temperature, humidity, sunlight, moisture, nutrients, etc. were present, these developments led to an increase in the soil's effective fertility, which in turn contributed to boost crop output. Crops are chosen based on the quality of the soil and the climate. The suggested agro method helps farmers identify the type of soil with the aid of sensors that can measure the soil's moisture content, pH level, and nutrient content (NPK). The farmer will be able to choose the right crops to plant with the aid of these values. Crop selection should be based on a number of parameters, including the kind of soil, its texture, and its nutrient content. The major goal is to increase plant health while simultaneously lowering excessive water use. It must guarantee that the crops are not over-or under-irrigated. Building a water supply system that will consider the soil's moisture content and disperse water as the soil requires can solve this issue, without harming the crop and without using excessive amounts of water. We can continuously check the amount of water in the soil by utilising inexpensive sensors. When the water level drops and crosses a certain threshold, the sensors will trigger a sprinkler or a pump that is connected to it, providing water to the crops. This arrangement will assist small-scale farmers in increasing crop yields, which will boost the Indian economy. The IoT module has sensors for soil moisture, temperature, pH, and NPK that collect data in real time and upload it to a cloud storage. Then, pre-trained models created using machine learning methods will be compared with the real-time sensed data. The Sensor Information Unit, which is connected to the secure cloud storage, receives data from the deployed sensors. A machine learning algorithm will be utilised to anticipate the appropriate crops that can be produced in that particular soil utilising the data obtained by the cloud for data analysis. The machine learning module will additionally predict when fertilisers will need to be applied and how precise monitoring will result in a high crop yield.","","979-8-3503-3324-4","10.1109/ICCPCT58313.2023.10245248","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10245248","","Temperature sensors;Smart agriculture;Cloud computing;Machine learning algorithms;Soil moisture;Crops;Machine learning","","","","7","IEEE","22 Sep 2023","","","IEEE","IEEE Conferences"
"DROPS: Dynamic Radio Protocol Selection for Energy-Constrained Wearable IoT Healthcare","S. Misra; A. Roy; C. Roy; A. Mukherjee","Department of Computer Science and Engineering, IIT Kharagpur, Kharagpur, India; Advanced Technology Development Centre, IIT Kharagpur, Kharagpur, India; Department of Industrial and Systems Engineering, IIT Kharagpur, Kharagpur, India; Department of Computer Science and Engineering, IIT Kharagpur, Kharagpur, India","IEEE Journal on Selected Areas in Communications","14 Jan 2021","2021","39","2","338","345","We propose “DROPS”, a scheme which dynamically selects radio protocols in an energy-constrained wearable IoT healthcare system. We consider the use of multiple radio protocols, which are capable of transmitting a patient's sensed physiological parameters to the server through Local Processing Units (LPUs). As the health parameters are non-stationary and temporally fluctuating, especially for critical patients, the selection of an appropriate radio protocol is essential to maintain the accuracy and timely delivery of data from the patient to the server. Additionally, the mobility of patients through various locations within the hospital mandates the selection of the best radio protocol among the multiple available ones for each location, to enable data to offload to the remote server. We use single-leader-multiple-follower Stackelberg non-cooperative game to map the strategic interactions between a patient's LPU and the hospital's server. “DROPS” dynamically selects the appropriate radio protocol, based on the criticality index of a patient, the reputation of the radio, the Euclidean distance between the radios and the LPU, and the load on the protocol. Results on real-life data and their large-scale emulation show that the data rate increases by almost 78% and throughput by approximately 7%, as compared to existing schemes.","1558-0008","","10.1109/JSAC.2020.3020678","Indian National Academy of Engineering (INAE) through national funds(grant numbers:INAE/121/AKF); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9181524","Wireless body area networks (WBAN);IoT;next generation networks;health criticality","Protocols;Servers;Medical services;Biomedical monitoring;Physiology;Wireless communication;Body area networks","","33","","20","IEEE","31 Aug 2020","","","IEEE","IEEE Journals"
"Towards Dense and Scalable Soil Sensing Through Low-Cost WiFi Sensing Networks","S. M. Hernandez; D. Erdag; E. Bulut","Department of Computer Science, Virginia Commonwealth University, Richmond, VA, USA; Department of Computer Science, Virginia Commonwealth University, Richmond, VA, USA; Department of Computer Science, Virginia Commonwealth University, Richmond, VA, USA","2021 IEEE 46th Conference on Local Computer Networks (LCN)","7 Sep 2021","2021","","","549","556","Precision agriculture uses precise sensor data collected throughout farmland to give farmers better insight into their land, allowing for greater crop yields and reduced resource usage. However, existing solutions require high hardware costs thus limiting large scale deployments. To address that, we propose a low-cost and scalable solution for sensing physical attributes of soil using IoT based WiFi sensing devices. By understanding variations in WiFi radio signals with channel state information (CSI) and machine learning models, we evaluate the proposed soil sensing system through experiments on physical soil traits such as soil moisture content, soil texture and position. Moreover, we also demonstrate how a mesh network of WiFi sensing devices allows us to predict the physical traits of the soil in the area between each pair of sensors, allowing for an increase in sensing area coverage as nodes are added.","0742-1303","978-1-6654-1886-7","10.1109/LCN52139.2021.9525003","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9525003","WiFi sensing;sensor networks;soil sensing;soil moisture;precision agriculture","Costs;Soil moisture;Crops;Moisture;Soil texture;Agriculture;Transceivers","","7","","16","IEEE","7 Sep 2021","","","IEEE","IEEE Conferences"
"Learning-Aided Multi-RAT Operation for Battery Lifetime Extension in LPWAN Systems","M. Stusek; D. Moltchanov; P. Masek; J. Hosek; S. Andreev; Y. Koucheryavy","Department of Telecommunications, Brno University of Technology, Brno, Czech Republic; Unit of Electrical Engineering, Tampere University, Finland; Department of Telecommunications, Brno University of Technology, Brno, Czech Republic; Department of Telecommunications, Brno University of Technology, Brno, Czech Republic; Unit of Electrical Engineering, Tampere University, Finland; Unit of Electrical Engineering, Tampere University, Finland","2020 12th International Congress on Ultra Modern Telecommunications and Control Systems and Workshops (ICUMT)","14 Oct 2020","2020","","","26","32","End-device (ED) lifetime is considered to be a crucial design factor in radio systems for massive machine-type communications. This parameter is heavily impacted by the continuously changing propagation conditions between the ED and the base station. In this paper, to extend the ED lifetime, we consider equipping a single ED with multiple low-power wide-area network (LPWAN) technologies to dynamically select the one with lower energy consumption. To facilitate this process, we propose to employ reinforcement learning (RL) algorithms. Assessing the resultant performance, we conduct two large-scale measurement campaigns that characterize the ED power consumption and the time-dependent propagation conditions for NB-IoT, Sigfox, and LoRaWAN technologies. Our numerical results demonstrate that the designed schemes effectively reduce ED power consumption by timely reacting to the varying radio conditions. Consequently, the ED lifetime expectancy is prolonged by around 10%. For instance, the Thompson sampling technique delivers the most consistent results by outperforming its counterparts and allowing to exploit up to 99% of the theoretical gains while converging over only 25-50 samples.","2157-023X","978-1-7281-9281-9","10.1109/ICUMT51630.2020.9222440","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222440","End-device lifetime;Energy consumption optimization;LPWAN;Multi-armed bandit;Multi-RAT;Reinforcement learning","Energy consumption;Power demand;Power measurement;Heuristic algorithms;Switches;Reinforcement learning;Control systems","","5","","18","IEEE","14 Oct 2020","","","IEEE","IEEE Conferences"
"Intelligent Fabric Enabled 6G Semantic Communication System for In-Cabin Scenarios","Y. Tang; N. Zhou; Q. Yu; D. Wu; C. Hou; G. Tao; M. Chen","School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; Tongji Medical College, Huazhong University of Science and Technology, Wuhan, Hubei, China; School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; Sport and Health Initiative, Optical Valley Laboratory, the Wuhan National Laboratory for Optoelectronics, and the School of Optics and Electronic Information, Huazhong University of Science and Technology, Wuhan, Hubei, China; Sport and Health Initiative, Optical Valley Laboratory, the Wuhan National Laboratory for Optoelectronics, and the State Key Laboratory of Material Processing and Die & Mould Technology, School of Materials Science and Engineering, Huazhong University of Science and Technology, Wuhan, Hubei, China; School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, Hubei, China","IEEE Transactions on Intelligent Transportation Systems","26 Jan 2023","2023","24","1","1153","1162","With the large-scale commercialization of 5G, the global industry has started the exploration of the next generation mobile communication technology (6G). From mobile Internet, to IoT, and then to the smart connection of everything, 6G will transform from 5G’s service objects of people and things to the intelligent networking of agent that supports human–machine–object. 6G networks should have the characteristics of ubiquitous intelligence and ubiquitous perception, which poses challenges for 6G network construction. Therefore, we propose a 6G Semantic Communication Scheme based on Intelligent Fabrics for transportation in-cabin scenarios (6GSCS-IF), which can provide senseless intelligent interaction in transportation in-cabin environment through widely and flexibly deployed intelligent fabrics, demonstrating the superiority of intelligent fabrics in realizing human–machine–object intelligent sensory interaction. Then, we propose a Deep Learning-based Semantic Communication Model for Time-series data (DL-SCMT), and use deep learning for semantic sensing and information extraction to build an end-to-end semantic communication system. The experimental results show that the semantic communication services provided by this model can achieve better signal reconstruction and higher-order intelligent services compared with traditional communication methods.","1558-0016","","10.1109/TITS.2022.3174704","China National Natural Science Foundation(grant numbers:62176101); Science and Technology Planning Project of Guangdong Province(grant numbers:2021A0505110008); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9788561","Semantic communication;intelligent fabric;6G;deep learning","Semantics;6G mobile communication;Fabrics;5G mobile communication;Codes;Transportation;Radio transmitters","","4","","22","IEEE","3 Jun 2022","","","IEEE","IEEE Journals"
"Reinforcement Learning assisted Routing for Time Sensitive Networks","N. S. Bülbül; M. Fischer","University of Hamburg, Germany; University of Hamburg, Germany","GLOBECOM 2022 - 2022 IEEE Global Communications Conference","11 Jan 2023","2022","","","3863","3868","Recent developments in real-time critical systems pave the way for different application scenarios such as Industrial IoT with various quality-of-service (QoS) requirements. The most critical common feature of such applications is that they are sensitive to latency and jitter. Thus, it is desired to perform flow placements strategically considering application requirements due to limited resource availability. In this paper, path computation for time-sensitive networks is investigated while satisfying individual end-to-end delay requirements of critical traffic. The problem is formulated as a mixed-integer linear program (MILP) which is NP-hard with exponentially increasing computational complexity as the network size expands. To solve the MILP with high efficiency, we propose a reinforcement learning (RL) algorithm that learns the best routing policy by continuously interacting with the network environment. The proposed learning algorithm determines the variable action set at each decision-making state and captures different execution times of the actions. The reward function in the proposed algorithm is carefully designed for meeting individual flow deadlines. Simulation results indicate that the proposed reinforcement learning algorithm can produce near-optimal flow allocations (close by ~1.5 %) and scales well even with large topology sizes.","","978-1-6654-3540-6","10.1109/GLOBECOM48099.2022.10001630","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10001630","delay aware routing;TSN;reinforcement learning;resource allocation;routing optimization","Training;Network topology;Supervised learning;Reinforcement learning;Quality of service;Routing;Topology","","2","","14","IEEE","11 Jan 2023","","","IEEE","IEEE Conferences"
"Light Pollution Monitoring Using A Modular IoT Sensor Platform","R. N. Dizon-Paradis; O. Ferrigno; I. Reid; S. Bhunia","Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL","2022 IEEE International Conference on Smart Internet of Things (SmartIoT)","8 Sep 2022","2022","","","28","35","Light pollution, caused by indiscriminate use of artificial lighting at night, is a growing threat to astronomy, the environment, and other fields. Monitoring light pollution can help inform local communities on its impact on their environment, especially nocturnal plants and animals, such as sea turtles. However, existing systems for light pollution monitoring are expensive, non-scalable, and uni-directional, while others are inaccurate and cannot be deployed at a large scale. In this paper, we propose a modular IoT sensor platform called Pasteables with reconfigurable and easily replaceable components. We tailor this sensor platform to use many of the sensors related to monitoring light pollution. It builds upon our previous work that shares the idea of a generic modular sensing platform [1]. Unlike the previous work, we created new designs for the Components for Uniform Interface (CUI) with sensors, including light sensor, temperature/pressure sensor, and GPS. We fabricated PCB proto-types of this Pasteables platform using FR-4 material and surface mount components. Each CUI connects to the base pad using edge connectors to make the CUIs reconfigurable during installation. With these prototypes, we evaluated its responsiveness and sensitivity at two different locations of varying heights for the light source against the least expensive existing solution.","2770-2677","978-1-6654-7952-3","10.1109/SmartIoT55134.2022.00014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9874602","light pollution;light sensing;hatching sea turtle;modular IoT sensor platform","Temperature sensors;Temperature measurement;Pollution;Sensitivity;Prototypes;Surface mount technology;Sensors","","1","","19","IEEE","8 Sep 2022","","","IEEE","IEEE Conferences"
"Enhancing Education in Underserved Schools: The Internet Backpack as Cyber-physical Infrastructure","L. W. McKnight; D. Taana Smith; W. J. Ronelus; R. Ondocin; P. K. Ghosh","School of Information Studies, Syracuse University, Syracuse, USA; College of Arts and Sciences, Syracuse University, Syracuse, USA; Timothy Dwight Elementary School, New York, USA; School of Information Studies, Syracuse University, Syracuse, USA; College of Engineering & Computer Science, Syracuse University, Syracuse, USA","2021 IEEE Conference on Cognitive and Computational Aspects of Situation Management (CogSIMA)","9 Jul 2021","2021","","","32","38","This paper assesses the results of a STEM education pilot project bringing cyber-physical infrastructure for broadband connectivity, trusted devices, and secure cloud and privacy and rights-protecting edge cognitive computing and wireless services, to underserved New York City school children at Timothy Dwight PS 33X in the South Bronx, PS 91 Albany Avenue School and PS 316 Elijah Stroud Elementary School, both in Brooklyn, New York, USA. This pilot study, initiated in 2017, demonstrated how the innovative Internet Backpack could bring immediate connectivity and digital and physical (cyber-physical) resource-sharing including cognitive wireless networks to many school children simultaneously, much faster than previously thought possible, or affordable. Projecting from this successful pilot, in this paper we explain how we anticipate that the results will serve to focus further action by all stakeholders on the broadband underserved wherever they may be. We suggest utilizing the Internet Backpack to develop a gap-filling last few hundred feet road map of where broadband connectivity is otherwise lacking and hence hindering school children’s education performance and opportunities to explore STEM learning topics. This model can guide future buildouts of broadband Internet and cyber-physical infrastructure to help address both the Covid-19 pandemic emergency and the ongoing, longstanding systemic societal emergencies exacerbated by limited Internet access in resource-constrained communities. Our initial pilot data shows improvement in both student scientific reasoning and science mastery when uninterrupted Internet connectivity is provided, allowing students to engage in both curricular and extracurricular science projects unimpeded by digital divides. Larger-scale studies, if replicating these results, could guide educators and policymakers towards utilizing cognitive systems such as the Internet Backpacks, and Science/IoT curricula, for efficient cloud to edge connectivity and innovative educational content, changing the equation for greater digital inclusion in urban and rural communities, quickly.","2379-1675","978-1-7281-7698-7","10.1109/CogSIMA51574.2021.9475946","Syracuse University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9475946","Internet Backpack;Broadband Connectivity;Digital Inclusion;Science Education;Cyber-physical Infrastructure","Performance evaluation;Cloud computing;Wireless networks;Urban areas;Education;Bandwidth;Cognition","","1","","27","IEEE","9 Jul 2021","","","IEEE","IEEE Conferences"
"Leveraging IoT solutions as a base for development of the agriculture advisory services","S. Mueller; M. Plociennik; M. Zacharczuk; A. Fojud; M. Blaszczak; A. Laskowska; R. Palma; M. Jakubowska; A. Wojtowicz","PSNC, Institue of Bioorganic Chemistry PAS, Poznan, Poland; PSNC, Institue of Bioorganic Chemistry PAS, Poznan, Poland; Wielkopolski Osrodek Doradztwa Rolniczego w Poznaniu, Poznan, Poland; Wielkopolski Osrodek Doradztwa Rolniczego w Poznaniu, Poznan, Poland; PSNC, Institue of Bioorganic Chemistry PAS, Poznan, Poland; PSNC, Institue of Bioorganic Chemistry PAS, Poznan, Poland; PSNC, Institue of Bioorganic Chemistry PAS, Poznan, Poland; Department of Monitoring and Signalling of Agrophages, Institute of Plant Protection-NRI, Poznan, Poland; Department of Mycology, Institute of Plant Protection-NRI, Poznan, Poland","2022 IEEE International Conference on Omni-layer Intelligent Systems (COINS)","18 Aug 2022","2022","","","1","6","Plant protection is one of the key factors determining the quality of agricultural production. In this paper, we present the results regarding the implementation and deployment of the Polish decision support system (DSS) for integrated plant protection, as part of the large scale national project called eDwin. At the core of the DSS is an IoT network of agro-meteorological stations deployed across the whole Poland. Additionally, the DSS leverages a set of automatic phenological observation stations that are deployed in selected experimental fields. After the deployment and validation of several pest prediction models, the DSS currently allows Polish farmers and advisors to access and use 20 models related to the main cultivations in Poland. Moreover, a digital platform for the farmers and advisors has been designed and developed, providing four e-services, complemented with interoperable mechanisms and APIs.","","978-1-6654-8356-8","10.1109/COINS54846.2022.9854950","European Commission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9854950","decision support system;IoT;integrated plant protection;apiary management;smart agriculture;interoperability","Decision support systems;Plants (biology);Production;Predictive models;Agriculture;Intelligent systems","","1","","15","IEEE","18 Aug 2022","","","IEEE","IEEE Conferences"
"CONETSI: On Demand Distributed Network State Information Collection using Opportunistic Exploration for Resource Constrained Networks","S. Nair; A. Sahu; S. Mantravadi; S. V. R. Anand; M. Hegde","Department of Electrical Communication Engineering, Indian Institute of Science; Department of Electrical Communication Engineering, Indian Institute of Science; Department of Electrical Communication Engineering, Indian Institute of Science; Department of Electrical Communication Engineering, Indian Institute of Science; Department of Electrical Communication Engineering, Indian Institute of Science","2020 International Conference on COMmunication Systems & NETworkS (COMSNETS)","9 Mar 2020","2020","","","491","498","Large scale IoT deployments for industrial, smart-city and many other applications require efficient mechanisms to monitor node health, and various performance influencing parameters of the underlying resource constrained network. Efficient and timely collection of such Network State Information (NSI) and its analytics help network operators ensure continuous operation, maintain end application QoS, and optimize the overall network performance through efficient network resource management. Considering the power and bandwidth constraints in these networks, it is imperative that the overheads inherently associated with NSI collection are minimized in transporting the monitored data comprising of different levels of demands and time criticality. We present CONETSI, a distributed algorithm and protocol for collecting NSI by forming node chains. Briefly, a node having NSI to be sent to a remote monitoring station opportunistically advertises for other potential sources of NSI. One of the neighboring nodes, chosen based on a distributed contention resolution logic running on the nodes, joins the chain. The exploration is then repeated by the joined nodes forming the NSI chain rooted at the originating node. The farthest node then collects NSI serially along the chain towards the originating node. CONETSI provides differential QoS to the NSI transfers by considering demand level and time criticality of the NSI data possessed by the network nodes. We evaluate theoretical bounds, backed by experimental results showing the performance gains that amortize the overheads associated with the exploration process. We also describe our software implementation in Contiki-NG operating system running the 6LoWPAN/RPL stack.","2155-2509","978-1-7281-3187-0","10.1109/COMSNETS48256.2020.9027403","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9027403","network management;IoT;Fairness;distributed algorithm;network resource optimization;NSI","Wireless sensor networks;Routing protocols;Monitoring;Bandwidth;Wireless communication;Routing","","","","13","IEEE","9 Mar 2020","","","IEEE","IEEE Conferences"
"Qualitative Analysis on Implementation of Security Aspects for Web 3.0","S. Padave; N. A. Natraj; G. G. Hallur","Symbiosis Institute of Digital and Telecom Management, Symbiosis International (Deemed University), Lavale, Pune; Symbiosis Institute of Digital and Telecom Management, Symbiosis International (Deemed University), Lavale, Pune; Symbiosis Institute of Digital and Telecom Management, Symbiosis International (Deemed University), Lavale, Pune","2023 7th International Conference on Intelligent Computing and Control Systems (ICICCS)","8 Jun 2023","2023","","","1352","1356","Social Media Analytics and its real-time people sentiments play a pivotal role in shaping the use of emerging technologies. They will act as a critical use case with Web 3.0. Organizations have used this data to plan campaigns and design advertisements to entice their target audience & with web 3.0, social media platforms like Facebook, Instagram, and Twitter are integrated with evolving computing models, such as IoT. Consumers can thus expect additional interaction, integration, and seamless movement between physical spaces due to these platforms coming together in Web 3.0. However, ensuring data privacy across such systems could be challenging. This is where the emergence of blockchain technology could potentially improve and help evolve the online landscape. Thus, the research aims to narrow down methods to enhance security protocols in web 3.0 by leveraging available technology. This article employs a bibliographical study based on an extensive literature study. The analysis has found numerous web 3.0 use cases and parallel security loopholes, thus offering scope for research. This article will have large-scale implications for achieving control over data leading to digital privacy.","2768-5330","979-8-3503-9725-3","10.1109/ICICCS56967.2023.10142635","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10142635","Web 3.0;Blockchain;cyber security;digital privacy;social media 3.0","Semantic Web;Data privacy;Protocols;Social networking (online);Web services;Organizations;Search engines","","","","22","IEEE","8 Jun 2023","","","IEEE","IEEE Conferences"
"Internet of Things and Sensor Networks","S. Andreev; N. D. Dao; P. Misra","Tampere University, Finland; NA; TCS Research and Innovation, Bangalore, India","IEEE Communications Magazine","6 Oct 2020","2020","58","9","12","12","The articles in this special section focus on the application of Internet of Things to sensor networks. The number of Internet of Things (IoT) technology applications has been growing steadily. IoT devices can perform basic functionalities for sensor data collection and machine control. Furthermore, advancements in chip design have enabled sophisticated system-on-chip applications over small-sized IoT devices that perform complex data processing at the network edge. Unlike human-operated devices, such as smart phones, the operation of IoT devices is often expected to be autonomous. However, the massive numbers of IoT nodes in large-scale communication networks pose new challenges for IoT system design and management. Presents selected novel applications, highlights essential security and privacy aspects, and evaluates the performance of the emerging cellular technology that supports IoT connectivity. ","1558-1896","","10.1109/MCOM.2020.9214380","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9214380","","Special issues and sections;Internet of Things;Security;Sensors;Privacy;Data analysis;Malware","","1","","0","IEEE","6 Oct 2020","","","IEEE","IEEE Magazines"
"Introduction to the Special Section on Network Science for Internet of Things (IoT)","H. Wang; S. Yu; S. Zeadally; D. B. Rawat; Y. Gao",NA; NA; NA; NA; NA,"IEEE Transactions on Network Science and Engineering","5 Mar 2020","2020","7","1","237","238","The papers in this special section examine network science for the Internet of Things (IoT). IoT applications have been growing significantly in recent years and the so-called IoT ecosystem enables seamless connectivity that is paving the way for many applications such as smart home, smart health, connected vehicle, smart grid and others. The network infrastructure, connectivity, and dynamics in the IoT ecosystem are becoming increasingly complex, scalable and heterogeneous, opening up many challenges for network sciences and system engineering including architectural, operational, service and security challenges. In addition, since IoT applications generate huge amounts of network traffic over networks, network issues such complexity, efficiency, dynamics, interferences and interaction and robustness need to be re-examined on a large scale. We aim to leverage them in order to better understand network performance bound, user demands and experience and capacity of the IoT network infrastructure which will enable the network to seamlessly connect to IoT devices and support the emerging applications of IoT users. In summary, research on network sciences and engineering for inter-disciplinary IoT applications is still in its infancy.","2327-4697","","10.1109/TNSE.2019.2959676","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9025279","","Special issues and sections;Internet of Things;Network security;Optimization;Ecosystems;Data processing;Network architecture","","4","","0","IEEE","5 Mar 2020","","","IEEE","IEEE Journals"
"Novel Cybersecurity Paradigms for Consumer Technology","F. Pescador; S. P. Mohanty",Universidad Politécnica de Madrid; University of North Texas,"IEEE Consumer Electronics Magazine","4 Dec 2020","2021","10","1","72","73","Almost all the current generation consumer electronics (CE) and consumer technology (CT) have the feature of Internet connectivity. This connectivity comes with the major challenge of cybersecurity. Cybersecurity threats in for CE devices and systems have multiple forms including software, hardware, and communications networks. The cybersecurity attacks can come from remote locations through Internet. The cybersecurity threats can be local as built-in as trojans, which can be remotely exploited. In general, a variety of consumer devices are integrated in the Internet-of-Things (IoT) and cyber–physical systems (CPS) making large smart components. For example, healthcare CPS making smart healthcare, agriculture CPS making smart agriculture, and transportation CPS making smart transportation, and energy CPS making smart energy. Similarly, at a smaller scale, smart homes and autonomous vehicles can have serious cybersecurity issues. With the previous thoughts, we invited perspective authors to contribute to the current special section that presents state-of-the-art of cybersecurity solutions for CE and CT. We briefly present the accepted papers in the following paragraphs.","2162-2256","","10.1109/MCE.2020.3032206","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9281378","","","","2","","0","IEEE","4 Dec 2020","","","IEEE","IEEE Magazines"
"Special Issue on Cool Chips and Hot Interconnects","L. K. John","The University of Texas at Austin, Austin, TX, USA","IEEE Micro","28 Mar 2022","2022","42","2","4","5","This special issue brings to IEEE Micro’s readership the best from two interesting conferences - Cool Chips 2021 and Hot Interconnects 2021. Cool Chips is a conference that focuses on the research on state-of-the-art low-power, high-speed chips and challenges facing researchers to simultaneously achieve low power consumption and high chip performance. The past couple of years have seen a flurry of research in low-power high-speed chips in artificial intelligence (AI), Internet of Things (IoT), consumer electronics, etc., and several of these were presented at the Cool Chips conference. Three selected papers from Cool Chips are presented in this issue. This special issue also presents a collection of articles on interconnect technologies based on the Hot Interconnect Conference of August 2021. Hot Interconnects is a conference that brings to light state of the art in interconnect technology. In modern systems on chip and large-scale computer systems, many processing components are being interconnected and the larger system’s performance and energy consumption significantly depends on the interconnect. Five selected articles from Hot Interconnects are presented in this issue. These are briefly summarized here.","1937-4143","","10.1109/MM.2022.3155994","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9743812","","","","","","0","IEEE","28 Mar 2022","","","IEEE","IEEE Magazines"
"Guest Editorial: Introduction to Special Section on Smart Systems and Intelligent Networking Powered With Big Data Analytics","",,"IEEE Transactions on Network Science and Engineering","31 Dec 2020","2020","7","4","2526","2527","The papers in this special section focus on smart systems and intelligent networking that is powered with Big Data analytics. Smart systems, including Internet of Things (IoT), have emerged to address contemporary economic, societal, and environmental challenges, such as business and production automation, urban sustainability, climate change, healthcare, and globalization. They encompass different autonomous or collaborative systems with functions of sensing, actuation, and control for describing and analyzing a situation, and make decisions based on the available data in a predictive or adaptive manner. Intelligent networking enables these functions of smart systems by offering a global infrastructure for networked physical devices and everyday objects, which generates a gigantic amount of data, or big data. In addition, big data analytics is also employed in analyzing the big data so as to enable the networking to be intelligent and allow smart systems to perform astute, autonomous or collaborative actions. Nevertheless, the efficient and effective big data management and knowledge discovery of large-scale smart systems, big data analytics for intelligent networking, and networking technologies for big data (e.g., collection, processing, analysis and visualization) need more explorations. ","2327-4697","","10.1109/TNSE.2020.3037986","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9311498","","Special issues and sections;Smart devices;Big Data;Cloud computing;Blockchain;Smart devices;Heuristic algorithms;Intelligent networks;Data analysis","","1","","0","IEEE","31 Dec 2020","","","IEEE","IEEE Journals"
"Guest Editorial Special Issue on Edge-Cloud Interplay Based on SDN and NFV for Next-Generation IoT Applications","S. Garg; S. Guo; V. Piuri; K. -K. Raymond Choo; B. Raman","École de Technologie Supérieure, Montreal, Canada; Hong Kong Polytechnic University, Hong Kong; Università degli Studi di Milano, Milan, Italy; University of Texas at San Antonio, San Antonio, USA; Indian Institute of Technology Roorkee, Roorkee, India","IEEE Internet of Things Journal","10 Jul 2020","2020","7","7","5690","5694","With significant and continuing advances in information and communication technologies, the Internet of Things (IoT) will play an increasingly important role in domains, such as healthcare, transportation, finance, and energy. In an IoT system, billions of devices (e.g., sensors, wearables, and smart appliances) are connected to the global network infrastructure, and one associated phenomenon is the generation of a large volume of data. Apart from data volume, the velocity, variety, and veracity of these data will pose a significant burden on conventional networking infrastructures. However, as sensor and fifth-generation (5G) cellular technologies advance, so will the pervasiveness of IoT deployment. Parallel to this trend, cloud computing has been integrated with IoT in order to address limitations in existing IoT networks (e.g., storage and computing resources), and examples include Google cloud dataflow and Amazon IoT. However, cloud-centric IoT solutions may not be suited for delay-sensitive and computationally intensive applications, for example, due to resource availability, end-to-end latency, bandwidth, etc. Increasingly, large-scale IoT deployments demand high connectivity, interoperability, and orchestration which are necessary for minimizing latency and maximizing throughput. This highlights the importance of a distributed computing platform that can support the interactions between IoT and cloud computing systems.","2327-4662","","10.1109/JIOT.2020.2999798","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138556","","Special issues and sections;Cloud computing;Edge computing;Intelligent sensors;Wearable sensors;Wearable computers","","11","","0","IEEE","10 Jul 2020","","","IEEE","IEEE Journals"
"Guest Editorial Special Issue on Internet of Things for Smart Health and Emotion Care","M. Chen; K. Hwang; H. Wang; V. C. M. Leung; I. Humar","School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; School of Data Science, Chinese University of Hong Kong, Shenzhen, China; Department of Computer Science, University of Minnesota at Duluth, Duluth, MN, USA; School of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; School of Financial Engineering, University of Ljubljana, Ljubljana, Slovenia","IEEE Internet of Things Journal","19 Nov 2021","2021","8","23","16718","16722","As an information carrier, the Internet of Things (IoT) based on the Internet and sensing equipment makes all physical objects form an interconnected network. The 5th generation mobile networks (5G) technology has many advantages, such as high data rates, reduced latency, energy savings, reduced costs, increased system capacity and large-scale device connectivity, realize the real-time data collection, transmission, analysis, management, and application in the era of global Internet of Everything. In order to quickly respond to people’s daily requirements and provide the smart application based on artificial intelligence technology in various scenarios, the number of IoT devices will further increase. The integration of mobile-edge computing (MEC) and IoT is imperative, especially in industries needing real-time data computing, such as smart home, public security, automobile transportation, smart health, emotion care, etc. As a new form of IoT terminal combining 5G and MEC, wearable device based on intelligent fabrics plays an important role in smart health and emotion care, which is one of the potential development directions of the next generation of intelligent medical and rehabilitation systems.","2327-4662","","10.1109/JIOT.2021.3116407","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9620204","","Special issues and sections;Smart healthcare;Intelligent sensors;Medical services;5G mobile communication;6G mobile communication","","3","","0","IEEE","19 Nov 2021","","","IEEE","IEEE Journals"
"Guest Editorial: Special Section on Advanced Deep Learning Algorithms for Industrial Internet of Things","",,"IEEE Transactions on Industrial Informatics","15 Jan 2021","2021","17","4","2764","2766","The articles in this special section focus on deep learning algorithms for the Industrial Internet of Things (IIoT). Currently, the industrial Internet of Things (IIoT) has been widely utilized in various fields (e.g., smart transportation, smart home, smart manufacturing). However, there are still some challenges, which hinder the further large-scale application of IIoT. Specifically, the data in IIoT are with a certain redundancy, while transmitting and processing these redundant data consume energy unnecessarily. Therefore, these redundant data should be compressed or removed. Conventionally, machine learning algorithms are used to process these redundant data in IIoT. However, with the growing diversity of IIoT and complexity of mobile network architectures, as well as increasing volume of data with increased dimensions and dynamics, they have made monitoring and managing a multitude of IIoT elements extremely difficult using machine learning algorithms. As we all know, deep learning algorithms can solve more complicated problems, unsolvable by machine learning algorithms, and produce high accurate results. Thus, machine learning algorithms are being replaced by advanced deep learning algorithms in various fields of IIoT. Incorporating advanced deep learning algorithms into IIoT can provide radical innovations in data analysis and pathbreaking industry applications.","1941-0050","","10.1109/TII.2020.3026551","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9325711","","Special issues and sections;Industrial Internet of Things;Deep learning;Machine learning;Streaming media;Adaptation models","","10","","0","IEEE","15 Jan 2021","","","IEEE","IEEE Journals"
"Guest Editorial: Introduction to Special Issue on “Cloud-Edge-End Orchestrated Computing for Smart Grid”","R. Deng; C. -W. Ten; C. Li; D. Niyato; F. Teng","Zhejiang University, Hangzhou, Zhejiang, China; Michigan Technological University, Houghton, MI, USA; University of New South Wales, Sydney, NSW, Australia; Nanyang Technological University, Singapore; Imperial College London, London, U.K.","IEEE Transactions on Cloud Computing","6 Jun 2023","2023","11","2","1107","1110","The integration of distributed energy resources (DER) into the smart grid through digitalization has transformed the power grid into a more decentralized system, enhancing energy efficiency and resilience during significant catastrophes. However, the integration of a large number of DERs into the transmission and distribution networks poses reliability challenges due to the intermittent nature of renewable energy sources. To tackle this, smart grids have been using advanced metering infrastructure (AMI) and Internet of Things (IoT) devices for over two decades to improve grid observability and enable near-real-time forecasting of continent-wide anomalies. Cloud-edge-end orchestrated computing can achieve hierarchical management and innovative operational strategies, such as multi-level control and optimization of all-grid-level DERs, voltage and frequency regulation using phasor measurement units (PMU), and special protection schemes (SPS) to detect and prevent potential faults or large-scale cyber-attacks.","2168-7161","","10.1109/TCC.2023.3271489","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10144931","","Special issues and sections;Smart grids;Distributed power generation;Energy management;Energy efficiency;Security","","","","0","IEEE","6 Jun 2023","","","IEEE","IEEE Journals"
"Guest Editorial Special Issue on IoT for Power Grids","L. Yang; W. Huang; V. G. Agelidis; D. Duan; Y. Cao","Internet of Things Thrust, Hong Kong University of Science and Technology, Guangzhou, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Electrical Engineering, Technical University of Denmark, Kgs. Lyngby, Denmark; Department of Electrical Engineering and Computer Science, University of Wyoming, Laramie, WY, USA; Power Dispatching and Control Center, China Southern Power Grid, Guangzhou, China","IEEE Internet of Things Journal","21 Apr 2023","2023","10","9","7426","7428","Recent years have witnessed the exciting developments for the power grid. For instance, many traditional mechanical components are being replaced by modern electronics devices that can operate intelligently; new elements, such as renewable energy resources and various large-scale energy storage, are introduced into the grid to bring a new outlook on the system operation and control; smart appliances are produced to facilitate more customized and efficient energy usage; and advanced sensors, such as the phasor measurement units (PMUs) and the advanced metering infrastructure (AMI), are designed and implemented for real-time wide-area monitoring of the system conditions. In general, the power grid is increasingly organized and managed as an interconnected network of many different individual components that operate intelligently in a distributed but connected manner, as opposed to the traditional centralized fashion. In other words, the power grid is evolving into a big Internet of Things (IoT).","2327-4662","","10.1109/JIOT.2023.3244637","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10106539","","Special issues and sections;Power grids;Internet of Things;Phasor measurement units;Systems operation;Renewable energy sources;Real-time systems;Energy storage;Sensor systems","","","","0","IEEE","21 Apr 2023","","","IEEE","IEEE Journals"
"Ieee Access Special Section Editorial: Human-Driven Edge Computing","R. Zhu; L. Liu; A. Anjum; M. Ma; S. Mao","College of Informatics, Huazhong Agricultural University, Wuhan, China; School of Informatics, University of Leicester, Leicester, U.K.; School of Informatics, University of Leicester, Leicester, U.K.; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Department of Electrical and Computer Engineering, Auburn University, Auburn, AL, USA","IEEE Access","7 Jul 2021","2021","9","","93948","93953","The advent of Fifth Generation (5G) and the Internet of Things (IoT) is expected not only to make it possible to collect and disseminate information for various crowd-sensing services in densely populated environments but also to put forward a higher request on these services with the rapid evolution of artificial intelligence and edge computing, which provides cloud computing and cache capabilities to reduce the computational load of cellular networks, displacing it at the edges of such networks. However, the costs for deployment and maintenance of mobile edge computing (MEC) are still high. Human-driven edge computing (HEC) is a novel model which integrates the elements of human, devices, internet and information, and combines the power of MEC architecture and the large-scale sensing ability of mobile crowd-sensing (MCS). Realizing better data spreading and environmental coverage in smart cities based on HEC has aroused a great deal of research interest from academia and industry. Although the studies of human-driven edge computing for 5G and the IoT are attractive, there are many open research problems, such as fusion analysis, efficient resource usage, low latency communication, large-scale search, and data security and privacy.","2169-3536","","10.1109/ACCESS.2021.3092476","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9475884","","","","1","","0","CCBY","7 Jul 2021","","","IEEE","IEEE Journals"
"Guest Editorial: Computational Intelligence for Human-in-the-Loop Cyber Physical Systems","A. Jolfaei; M. Usman; M. Roveri; M. Sheng; M. Palaniswami; K. Kant","Department of Computing, Macquarie University, Sydney, NSW, Australia; Faculty of Computing, Engineering and Science, University of South Wales, Newport, U.K.; Dipartimento di Elettronica e Informazione, Politecnico di Milano, Milano, Italy; Department of Computing, Macquarie University, Sydney, NSW, Australia; Department of Electrical and Electronic Engineering, The University of Melbourne, Parkville, VIC, Australia; Department of Computer and Information Sciences, Temple University, Philadelphia, PA, USA","IEEE Transactions on Emerging Topics in Computational Intelligence","21 Jan 2022","2022","6","1","2","5","The papers in this special section focus on human-in-the-loop cyber-physical systems. Recent advances in computational intelligence, real-time computing and control, have given momentum to Humanin-the-Loop Cyber Physical Systems (HitLCPS) to enable gamechanging communication and collaboration paradigms that operate in connection with humans’ natural behaviour patterns. Despite the ongoing advancement of computational intelligence techniques for analyzing the interactions between the cognitive and cyber domains, there are growing concerns regarding the security, privacy, and safety of humans when they interact with smart cyber physical environments (IoT ecosystems). The large-scale integration of heterogeneous IoT devices to manage and control a wide variety of sensors and settings will hugely increase the attack surface and the scope for misconfigurations. These could lead to unsafe or conflicting behaviour of various devices and subsystems, which in turn, can place the human in unsafe and hazardous situations, both mentally and physically. It is still unclear how to design optimized collaborative systems between people and machines in a scalable manner, how to design triggers for pro-active engagement and disengagement, and how to handle the consequences of implied actions. For example, when the system misbehaves as a result of erroneous data, it is important to have real-time rules that can guarantee a fail-safe state for the HitLCPS. The verification of operations in a large HitLCPS can be very complex due to the evolving nature of human-in-the-loop networks both in terms of physical aspects and the operational environment. Therefore, understanding the semantics of HitLCPS and the context of control behaviour is critical to detect or entirely avoid incorrect configurations and build a proactive resilience and a reactive defence against evolving threats. ","2471-285X","","10.1109/TETCI.2021.3139998","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9687852","","Special issues and sections;Computational intelligence;Cyber-physical systems;Collaboration;Human factors;Predictive models;Real-time systems;Semantics","","4","","0","IEEE","21 Jan 2022","","","IEEE","IEEE Journals"
"Guest Editorial Software Defined Internet of Vehicles","Z. Lv; J. Lloret; H. Song","College of Computer Science and Technology, Qingdao University, Qingdao, China; Department of Communications, Universitat Politecnica de Valencia, Valencia, Spain; Department of Electrical Engineering and Computer Science, Embry–Riddle Aeronautical University, Daytona Beach, FL, USA","IEEE Transactions on Intelligent Transportation Systems","31 May 2021","2021","22","6","3504","3510","Internet of Vehicles (IoV) is a large interactive network composed of information such as vehicle location, speed and route. Vehicles can collect their own environment and state information through GPS, RFID, sensors, camera image processing, and other devices. They can transmit their various information to the central processing unit through Internet technology. These large amounts of vehicle information can be analyzed and processed through computer technology to calculate the optimal route for different vehicles, and report road conditions in time and schedule signal light cycles. Internet of Vehicles (IoV) is a large-scale system network for wireless communication and information exchange between vehicles and people, vehicles and roads, vehicles and the Internet, which is based on intra-vehicle network, inter-vehicle network and vehicle mobile Internet, in accordance with the agreed communication protocols and data interaction standards. The system realizes the integrated network of intelligent traffic management, intelligent dynamic information service, and intelligent vehicle control by “filtering and cleaning” massive data and processing data on the platform. Internet of Vehicles (IoV) system utilizes advanced IoT technology, cloud computing, and big data to make the system fully aware of roads and traffic. It enables all vehicles to collect information through their own environment and state, and upload all kinds of information to the Internet big data platform. The central processing unit collects, analyzes, and processes a large amount of uploaded information. The system will control every vehicle involved in the traffic and control every road in real time to provide users with traffic efficiency and safety.","1558-0016","","10.1109/TITS.2021.3080875","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9444574","","Special issues and sections;Software defined networking;Internet of Vehicles;Wireless communication;Real-time systems","","7","","0","IEEE","31 May 2021","","","IEEE","IEEE Journals"
"A Tale of Two C’s: Convergence and Composability","İ. Altintaş",San Diego Supercomputer Center,"2021 IEEE International Parallel and Distributed Processing Symposium (IPDPS)","28 Jun 2021","2021","","","1","1","Cyberinfrastructure is everywhere in diverse forms in service of applications in science, business and society. From IoT to extreme-scale computing data and computing have never been so distributed with the potential for real-time integration into these applications. The common theme to these applications, mostly composed of (big) data-integrated workloads, is their need to run in specialized environments for reasons such as on-demand or 24x7 nature of the tasks they are performing, and difficulties regarding their portability, latency, privacy, and performance optimization. Moreover, in many data-driven scientific applications, there is a need for heterogeneous integration of tasks requiring specialized computing capabilities with traditional high-throughput computing or high-performance computing tasks. Although some key middleware technologies enabled demonstration of standalone heterogeneous applications, such integration requires expertise convergence from a large group of people in very specialized settings. There are still many challenges for streamlined, scalable, repeatable, responsible, and explainable integration of data-integrated applications. Key opportunities for further innovations include intelligent systems and automated workflow management software that can compose and steer dynamic applications that can adapt to changing conditions in a data-driven fashion while integrating many tools to explore, analyze and utilize data. This talk will discuss some examples for data-integrated applications, describe emerging systems that enabled these applications, and overview our recent research to enable composable applications including a convergence application development methodology, intelligent middleware, and workflow composition.","1530-2075","978-1-6654-4066-0","10.1109/IPDPS49936.2021.00009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9460393","","","","","","","IEEE","28 Jun 2021","","","IEEE","IEEE Conferences"
"Guest Editorial: Network Applications Software for Vertical IoT Industry","B. Sayadi; C. -Y. Chang; C. Tranoris; Q. Wang; A. Gosain; A. Nakao; Y. Wang",NA; NA; NA; NA; NA; NA; NA,"IEEE Internet of Things Magazine","9 Jan 2023","2022","5","4","112","114","Network Applications is defined as a set of services that provide certain functionalities to the verticals and their associated use cases. In practice, this software piece consumes the exposed Application Programmable Interfaces (APIs) from the network, e.g., northbound APIs of 5G core network and RAN Intelligent Controller (RIC), and edge computing APIs. Considering the levels of interaction and trust, Network Applications can either be integrated with (a part of) vertical application or exposes its APIs (e.g., service APIs) to be further consumed by vertical applications. In short, Network Applications could be viewed as a separate middleware layer, which is contributed by both network operators and third parties, to simplify the vertical system deployments on a large scale and extend to vertical IoT industries.","2576-3199","","10.1109/MIOT.2022.10012471","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10012471","","Special issues and sections;Internet of Things;Edge computing;Intelligent systems;Computer applications;Fourth Industrial Revolution;Wireless networks;5G mobile communications;Vertical markets","","","","6","IEEE","9 Jan 2023","","","IEEE","IEEE Magazines"
"Workshop: Converge of Edge Intelligence in IoT (EdgeA-IoT 2022)","C. Anagnostopoulos; F. Deligiani; K. Kolomvatsos; J. M. Fornés","School of Computing Science, University of Glasgow, Glasgow, UK; School of Computing Science, University of Glasgow, Glasgow, UK; Department of Computer Science & Telecommunications, University of Thessaly, Lamia, Greece; Department of Computer Science, University of Lleida, Lleida, Spain","2022 IEEE 8th World Forum on Internet of Things (WF-IoT)","22 Jun 2023","2022","","","1","2","Edge Intelligence is a synergy that seems to be imperative to conclude the convergence of the Edge Computing and Internet of Things to support intelligent application very close to end users. IoT has pervaded our daily life by making things, interconnected through the Internet, smarter, distributed and more autonomous. The emerging development of intelligent applications in IoT has now started to gain significant attention. Cloud provides many benefits to IoT devices, including high-performance computing, a storage infrastructure, processing and analysis of large-scale data giving to IoT the opportunity to be robust, smart and self-configuring. The forthcoming emergence of Edge AI will extend the capabilities of the ‘legacy’ IoT, its potentials, the number of devices and the volumes of data. However, Cloud technologies face some accessibility challenges when providing services to end-users. For instance, mobile clients can move among different places, yet require Cloud services with minimum cost and short response time. The unstable connection between Cloud and mobile devices is expected to prevent providers from achieving the optimal performance. To cope with these limitations, we aspire that Edge AI converged with IoT environments materializes the desired AI-led distributed and ubiquitous intelligence in real computing systems. We then need additional effort to establish and deliver the convergence of Edge AI and IoT in formatting the future Intelligent IoT. The Intelligent IoT is envisioned to involve numerous autonomous & distributed computing and AI-driven entities capable of understanding their internal status (context), the status of their environment and peers (collaborative context) and take timely optimized actions to efficiently serve modern applications, like tactile internet and augmented AI-led gaming.","","978-1-6654-9153-2","10.1109/WF-IoT54382.2022.10152257","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10152257","Edge AI;Intelligent Edge;Collaborative Context Aware Applications;Distributed AI;Edge AI Infrastructure Modelling;Computational Intelligence","Tactile Internet;Performance evaluation;Cloud computing;High performance computing;Mobile handsets;Internet of Things;Time factors","","","","0","IEEE","22 Jun 2023","","","IEEE","IEEE Conferences"
